<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>nodejs</title>
<link rel="stylesheet" href="vendors/public.css">
<link rel="stylesheet" href="vendors/SyntaxHighlighter/shCoreDefault.css"/>
</head>
<body>
<h1><a name="top">nodejs 基于node前后端全栈开发</a><small>http://nodejs.cn/api/</small></h1>

<main>
<nav>
  <ul>
    <li class="home">
      <a href="#" onclick="location = location.hostname == 'localhost' ? '../' : './';return false;">STUDY</a>
    </li>
    <li class="it"><a href="javascript:;">nodejs</a></li>
  </ul>
</nav>

<pre>
开发环境development：开发环境是用于开发的服务器,配置可以比较随意,为开发调试方便一般打开全部错误报告
测试环境test：一般是克隆一份生产环境的配置,一个程序在测试环境工作不正常,那么肯定不能把它发布到生产机上。
生产环境production：也就是通常说的真实环境,是正式提供对外服务的,一般会关掉错误报告,打开错误日志

三个环境也可以说是系统开发的三个阶段：开发->测试->上线

1字节=8二进制位,字符=不定个字节,最基础的ASCII码是给英文搞的,所以只有255(2^8-1)个,意味着8位,所以是1个字节,这就是为什么英文不会乱码的原因。但是中文等等不能表示的,只能扩展字节数来表示字符,所以长度不一,编码不对,乱码的事情也就经常发生

</pre>

<h3>nodejs异步非阻塞、事件驱动模型</h3><pre>
Node.js是运行在服务端的JavaScript
Node.js是一个事件驱动、非阻塞I/O服务端JavaScript运行环境,基于Google的V8引擎进行代码解释,v8是用C++编写的一个编译和运行JavaScript代码的库,执行Js的速度快,性能好
nodejs是轻量、可伸缩,适于实时数据交互应用
nodejs是单进程,单线程

I/O(input/output),即输入/输出端口.每个设备都会有一个专用的I/O地址,用来处理自己的输入输出信息
CPU与外部设备、存储器的连接和数据交换都需要通过接口设备来实现,前者被称为I/O接口,而后者则被称为存储器接口

Node提供一种简单的构建可伸缩网络程序的方法
1、系统线程模型
服务端只有一个线程,用户并发请求到达只能处理一个,其余的要先等待,这就是阻塞

2、多线程、线程池模型
这个模型调节服务端线程的数量来提高对并发请求的接收和响应,但并发量高的时候请求仍然需要等待
更严重的是,在Java和PHP这类语言中,服务端与客户端每建立一个连接都要为这个连接分配一套配套的资源,主要体现为系统内存资源,每个新线程可能需要2MB的配套内存,在一个拥有8GB RAM的系统上,理论上最大的并发连接数量是4000个用户。随着客户群的增长,如果希望Web应用程序支持更多用户,那么必须添加更多服务器

3、异步、事件驱动模型
nodejs更改了连接到服务器的方式,每个连接发射(emit)一个在Node引擎的进程中运行的事件放进事件队列当中,而不是为每个连接生成一个新的OS线程并为其分配一些配套内存。它绝不会死锁,因为它根本不允许使用锁,不会直接阻塞I/O调用。它的服务器能支持数万个并发连接
因此NodeJS能支持比Java、PHP程序更高的并发量
虽然维护事件队列也需要成本,再由于NodeJS是单线程,事件队列越长得到响应的时间就越长,并发量上去还是会力不从心

NodeJS非阻塞I/O,发射/监听事件来控制执行过程,遇到I/O事件会创建一个线程去执行,然后主线程会继续往下执行的
Java、PHP也有办法通过子线程实现并行请求,但NodeJS通过回调函数(Callback)和异步机制会做得很自然

NodeJS的优缺点
优点：
1、处理高并发场景性能更高(最重要的优点)
2、适合I/O密集型应用,通过异步IO来实现

缺点：
1、不适合CPU密集型应用;
CPU密集型应用给Node带来的挑战主要是：由于JavaScript单线程的原因,如果有长时间运行的计算(比如大循环),将会导致CPU时间片不能释放,使得后续I/O无法发起;
解决方案：分解大型运算任务为多个小任务,使得运算能够适时释放,不阻塞I/O调用的发起;

2、可靠性低,一旦代码某个环节崩溃,整个系统都崩溃
容错性很弱,当异步回调中出现异常,而相应的error的事件有没有被订阅,有时候根本不可能去订阅,那么整个进程都会挂掉
原因：单进程,单线程
解决方案：
(1)Nnigx反向代理,负载均衡,开多个进程,绑定多个端口;
(2)开多个进程监听同一个端口,使用cluster模块;

3、只支持单核CPU,不能充分利用CPU

Node.js的应用场景
NodeJS适合运用在高并发、I/O密集、少量业务逻辑的场景
1. RESTful API、JSON APIs
构建一个Rest/JSON API服务,Node.js可以充分发挥其非阻塞IO模型以及JavaScript对JSON的功能支持(如JSON.stringify函数)
这是NodeJS最理想的应用场景,可以处理数万条连接,本身没有太多的逻辑,只需要请求API,组织数据进行返回即可。
提供RESTful API的Web服务接收几个参数并解析它们,组合一个响应并返回(通常是较少的文本)给用户,不需要大量逻辑;它本质上只是从某个数据库中查找一些值并将它们组成一个响应。由于响应是少量文本,入站请求也是少量的文本,因此流量不高,一台机器甚至可以处理最繁忙的公司的API需求

2. 统一Web应用的UI层
MVC的架构在某种意义上来说Web开发有两个UI层,一个是在浏览器里面最终看到的,另一个在server端负责生成和拼接页面。
不讨论这种架构是好是坏,但是有另外一种实践,面向服务的架构,更好的做前后端的依赖分离。
如果所有的关键业务逻辑都封装成REST调用,就意味着在上层只需要考虑如何用这些REST接口构建具体的应用。
那些后端程序员们根本不操心具体数据是如何从一个页面传递到另一个页面的,他们也不用管用户数据更新是通过Ajax异步获取的还是通过刷新页面

3、大量Ajax请求的应用
单页面、多Ajax请求应用,如Gmail,前端有大量的异步请求,需要服务后端有极高的响应速度
例如个性化应用,每个用户看到的页面都不一样,缓存失效,要在页面加载的时候发起Ajax请求,NodeJS能响应大量的并发请求

4、Twitter队列
想像一下像Twitter这样的公司,它必须接收tweets并将其写入数据库。实际上每秒几乎有数千条tweet达到,数据库不可能及时处理高峰时段所需的写入数量。Node成为这个问题的解决方案的重要一环,Node能处理数万条入站tweet。它能快速而又轻松地将它们写入一个内存排队机制(如memcached),另一个单独进程可以从那里将它们写入数据库。Node在这里的角色是迅速收集tweet,并将这个信息传递给另一个负责写入的进程。想象一下另一种设计(常规PHP服务器会自己尝试处理对数据库本身的写入)：每个tweet都会在写入数据库时导致一个短暂的延迟,因为数据库调用正在阻塞通道。由于数据库延迟,一台这样设计的机器每秒可能只能处理2000条入站tweet。每秒处理100万条tweet则需要500个服务器。相反Node能处理每个连接而不会阻塞通道,从而能够捕获尽可能多的tweets。一个能处理50000条tweet的Node机器仅需20台服务器即可。

5、电子游戏统计数据
如果在线玩过《使命召唤》这款游戏,查看游戏统计数据时就会立即意识到一个问题：要生成那种级别的统计数据,必须跟踪海量信息。这样如果有数百万玩家同时在线玩游戏,而且他们处于游戏中的不同位置,那么很快就会生成海量信息。Node是这种场景的一种很好的解决方案,因为它能采集游戏生成的数据,对数据进行最少的合并,然后对数据进行排队,以便将它们写入数据库。使用整个服务器来跟踪玩家在游戏中发射了多少子弹看起来很愚蠢,如果使用Apache这样的服务器,可能会有一些有用的限制;但相反如果专门使用一个服务器来跟踪一个游戏的所有统计数据,就像使用运行Node的服务器所做的那样,那看起来似乎是一种明智之举。

6、基于Node.js开发Unix命令行工具
Node.js可以大量生产子进程,并以流的方式输出,这使得它非常适合做Unix命令行工具

7、流式数据
传统的Web应用,通常会将HTTP请求和响应看成是原子事件,而Node.js会充分利用流式数据这个特点构建非常酷的应用。如实时文件上传系统transloadit准实时应用系统,如聊天系统、微博系统,但Javascript是有垃圾回收机制的,这就意味着系统的响应时间是不平滑的(GC垃圾回收会导致系统这一时刻停止工作)。如果想要构建硬实时应用系统,Erlang是个不错的选择

2) 不适合
CPU使用率较重、IO使用率较轻的应用如视频编码、人工智能等Node.js的优势无法发挥
简单Web应用,此类应用的特点是流量低、物理架构简单,Node.js无法提供像Ruby的Rails或Python的Django这样强大的框架

NodeJS程序一般用node jsfile.js命令启动,如果程序出错这个进程就会退出
写程序不可能保证万无一失,肯定有些没有处理的错误,这就让很多人觉得NodeJS不稳定,容易产生很多故障。
几种方法增加NodeJS程序的稳定性、健壮性：
1.使用try{…} catch(error){…}来执行容易出错的代码段,比如解析一个外来的json字符串等。
2.使用process.on('uncaughtException', function(err){…});来处理未被捕捉的错误。
3.试用奶妈进程来启动程序,检测子进程的退出,然后自动重启该进程,比如mother.js
4.用主进程来启动子进程,如果子进程死了就重启子进程

</pre><pre class="js">
var spawn = require('child_process').spawn,
    server = null;
function startServer(){
    console.log('start server');
    server = spawn('node',['app.js']);
    console.log('node js pid is '+server.pid);
    server.on('close',function(code,signal){
        server.kill(signal);
        server = startServer();
    });
    server.on('error',function(code,signal){
        server.kill(signal);
        server = startServer();
    });
    return server;
};

startServer();

</pre><pre>
【 nodejs版本控制 】
Async functions are not supported by Node versions older than version 7.6

？？？报错,不支持windows？？？
n模块是专门用来管理nodejs版本的,全局安装命令：npm install -g n
升级到最新稳定版本：n stable
升级到最新版本：n latest
升级到指定版本：n 0.10.26

nodejs如何做到无伤更新?也就是说如果有一个版本需要更新,那么是需要重启的,对于web来说还好,但是对于游戏来说就麻烦了,要维护着长连接,重启肯定是不行的
1、做个代理,并对请求设置对应的权重,如：proxy = s1(60%) + s2(40%);
2、有更新时,降低s2的权重(降低为0则关闭连接请求),新的请求会到s1上
3、s2上已有的连接不想丢失,只能等待所有连接正常断开
4、当s2上无活动连接时可以进行更新
5、更新完成后,恢复对应的权重

小修正依赖短时的断线重连,游戏不可能不做断线重连,重启的话一瞬间全断了,然后一瞬间全重连,并发瞬间高起来了
大更新追求一致性必须停机维护

【 nodejs安装使用 】
$ node -v             查看当前的Node版本
$ node --version
$ node helloworld.js  执行helloworld.js文件

【 Node.js自带交互式解释器 REPL 】
脚本模式
交互模式：控制台敲入node并按回车键

Node.js REPL(Read Eval Print Loop:交互式解释器) 表示一个电脑的环境,类似Window系统的终端或Unix/Linux shell,可以在终端中输入命令并接收系统的响应,可以很好的调试js代码

读取 - 读取用户输入,解析输入了Javascript数据结构并存储在内存中
执行 - 执行输入的数据结构
打印 - 输出结果
循环 - 循环操作以上步骤直到用户两次按下ctrl-c按钮退出

REPL命令
ctrl + c         - 退出当前终端
ctrl + c 按两次 - 退出Node REPL
ctrl + d         - 退出Node REPL
向上/下键         - 查看输入的历史命令
tab键            - 列出当前命令
.help           - 列出使用命令
.break          - 退出多行表达式
.clear          - 退出多行表达式
.save filename  - 保存当前的Node REPL会话到指定文件
.load filename  - 载入当前Node REPL会话的文件内容,将文件的内容加载进来,如加载一个包含大量常量的文件
使用下划线(_)获取上一次表达式的运算结果

【 debug调试器 】
V8提供了强大的调试工具,Node内置这个调试工具客户端,要使用调试器须以debug参数启动Node
在代码里嵌入debugger;设置断点

cmd> node debug index.js
debug> help                     查看哪些命令可用
debug> watch("my_expression")   开始监视表达式和变量,每个断点处,监视器都会显示上下文
debug> watchers                 显示活跃的监视器
debug> unwatch("my_expression") 可以移除监视器
backtrace, bt - 打印当前执行框架的backtrace
list(5)       - 显示脚本代码的5行上下文(之前5行和之后5行)
repl          - 在所调试的脚本的上下文中,打开调试器的repl

cont, c - 继续执行
next, n - Step next
step, s - Step in
out, o  - Step out
pause   - 暂停(类似开发工具的暂停按钮)

setBreakpoint(), sb()                  - 当前行设置断点
setBreakpoint(line), sb(line)          - 在指定行设置断点
setBreakpoint('fn()'), sb(...)         - 在函数里的第一行设置断点
setBreakpoint('script.js', 1), sb(...) - 在script.js第一行设置断点。
clearBreakpoint, cb(...)               - 清除断点

run      - 运行脚本(开始调试的时候自动运行)
restart  - 重新运行脚本
kill     - 杀死脚本

scripts  - 列出所有已经加载的脚本
version  - 显示v8版本5.1.281.108

高级应用Advanced Usage
V8调试器可以用两种方法启用和访问,--debug命令启动调试,或向已经启动Node发送SIGUSR1。
一旦一个进程进入调试模式,它可以被node调试器连接。调试器可以通过pid或URI来连接。
node debug -p ${pid} - 通过pid连接进程
node debug ${URI}    - 通过URI(比如localhost:5858)连接进程

</pre>

<div id="npm">
<h2>npm cli (Node Package Manager)</h2><pre>
npm是Node的模块管理器,功能极其强大,是Node获得成功的重要原因之一
NPM是随同NodeJS一起安装的包管理工具,能解决NodeJS代码部署上的很多问题,常见的使用场景有以下几种：
允许用户从NPM服务器下载第三方包到本地使用
允许用户从NPM服务器下载并安装别人编写的命令行程序到本地使用
允许用户将自己编写的包或命令行程序上传到NPM服务器供别人使用

【 版本号 】
使用NPM下载和发布代码时都会接触到版本号,NPM使用语义版本号来管理代码
语义版本号分为X.Y.Z三位,分别代表主版本号、次版本号和补丁版本号,当代码变更时版本号按以下原则更新：
如果只是修复bug,需要更新Z位
如果是新增了功能,但是向下兼容,需要更新Y位
如果有大变动,向下不兼容,需要更新X位

【 Node模块的安装过程 】
发出npm install命令
npm向registry查询模块压缩包的网址
下载压缩包,存放在~/.npm目录
解压压缩包到当前项目的node_modules目录

npm install命令用来安装模块到node_modules目录
npm install packageName

安装之前npm install会先检查node_modules目录之中是否已经存在指定模块,如果存在就不再重新安装了,即使远程仓库已经有了一个新版本
如果希望一个模块不管是否安装过,npm都要强制重新安装,可以使用-f或--force参数
$ npm install packageName --force

npm update命令更新已安装的模块,会先到远程仓库查询最新版本,然后查询本地版本,如果本地版本不存在或者远程版本较新,就会安装
npm update packagename

npm update命令怎么知道每个模块的最新版本呢？
答案是npm模块仓库提供了一个查询服务registry
https://registry.npmjs.org/react就会看到react模块所有版本的信息,返回json对象
https://registry.npmjs.org/react/v0.14.6查看React的0.14.6版,加版本号或标签查询某个具体版本的信息
$ npm view react
$ npm info react
$ npm show react
$ npm v react

返回的JSON对象里面有一个dist.tarball属性,是该版本压缩包的网址,到这个网址下载压缩包,本地解压就得到模块的源码
npm install和npm update命令都是通过这种方式安装模块的

缓存目录
npm install或npm update命令从registry下载压缩包之后都存放在本地的缓存目录
npm config get cache   // C:\Users\lenovo\AppData\Roaming\npm-cache
每个模块的每个版本都有一个自己的子目录,里面是代码的压缩包package.tgz文件及一个描述文件package/package.json

一个模块安装以后本地其实保存了两份,一份是~/.npm目录下的压缩包,另一份是node_modules目录下解压后的代码。
但运行npm install时只会检查node_modules目录,而不会检查~/.npm目录,即如果一个模块在～/.npm下有压缩包,但是没有安装在node_modules目录中,npm依然会从远程仓库下载一次新的压缩包

npm提供了一个--cache-min参数,用于从缓存目录安装模块。
--cache-min参数指定一个时间(分钟),只有超过这个时间的模块才会从registry下载
$ npm install --cache-min 9999999 package-name  // 指定所有模块都从缓存安装,加快了下载速度
$ npm install --cache-min Infinity package-name // 等效

.npmrc
除了使用cli的npm config命令来显示修改npm配置,还可以通过npmrc文件直接修改配置
npmrc文件路径: npm config ls -l 命令查看配置 存在npmrc文件就会打印出文件路径,没有的话就使用命令配置registry,npmrc文件就会出现
registry=https://registry.npm.taobao.org
disturl=https://npm.taobao.org/dist
sass_binary_site=https://npm.taobao.org/mirrors/node-sass/
phantomjs_cdnurl=https://npm.taobao.org/mirrors/phantomjs/
electron_mirror=https://npm.taobao.org/mirrors/electron/
chromedriver_cdnurl=https://npm.taobao.org/mirrors/chromedriver
operadriver_cdnurl=https://npm.taobao.org/mirrors/operadriver
selenium_cdnurl=https://npm.taobao.org/mirrors/selenium
node_inspector_cdnurl=https://npm.taobao.org/mirrors/node-inspector
fsevents_binary_host_mirror=http://npm.taobao.org/mirrors/fsevents/

node-sass安装失败：没有安装python或node-sass
npm uninstall node-sass卸载之前安装失败的包,使用其他源或工具下载，然后将安装源指定到本地
npm i node-sass --sass_binary_site=https://npm.taobao.org/mirrors/node-sass/
cnpm install node-sass

【 常用npm命令 】
npm -v               // 查看npm版本
npm help             // 查看所有命令
npm help install     // 查看某条命令的详细帮助
npm install npm -g   // npm版本升级

npm init             // 在项目下初始化npm模块,生成package.json
npm init -y          // 自动保留待输入项的默认值
npm init -yes

npm config list
npm config ls -l      // show all defaults
npm config set prefix "E:\soft\nodejs\"         // 设置全局安装目录
npm config get prefix                           // 获取当前设置的目录
npm config set cache "E:\soft\nodejs\npm-cache" // 缓存目录
npm config get cache                     
npm config get registry                                  // 查看npm的仓库地址
npm config set registry https://registry.npm.taobao.org  // 改变默认下载地址,达到可以不安装cnpm就能永久采用淘宝镜像的目的
npm install -g cnpm --registry=https://registry.npm.taobao.org  // 安装cnpm命令,采用淘宝镜像,支持npm除了publish之外的所有命令

npm root                              // 查看本地安装的目录
npm root -g                           // 查看全局安装目录

npm install express -g --save-dev     // 全局安装express
npm install express --save-dev        // 本地项目安装express,同时将"express":"^4.14.0"写入devDependencies
npm install express --save            // 本地项目安装express,同时将"express":"^4.14.0"写入dependencies
npm install express --save --registry=https://registry.npm.taobao.org  // 使用淘宝镜像
npm i express --save                  // 简写,默认npm5+安装会自动添加dependencies,可以省略--save
npm i express -S                      // 简写
npm i express -D                      // 简写
npm i gulp-pug gulp-debug gulp-sass   // 同时安装多个模块
npm i gulp{-debug,-sass,-pug}         // 同时安装多个相同前缀的模块
npm i vue@2.5.15                      // 安装特定版本的软件包
npm i vue@beta

npm uninstall webpack                 // 卸载包,删除node_modules中webpack文件夹,但不删除模块留在package.json中的对应信息,可用rm、un或r来实现相同的效果
npm uninstall -g webpack              // 全局卸载webpack模块
npm rm webpack --no-save              // 只从node_modules文件夹中删除包文件,但仍将其作为依赖项保存在package.json文件
npm uninstall webpack --save          // 删除模块,同时删除模块留在package.json中dependencies下的对应信息
npm uninstall webpack --save-dev      // 删除模块,同时删除模块留在package.json中devDependencies下的对应信息

npm outdated                          // 查看那些包有更新
npm outdated --parseable --depth=0    // 使用目录的方式展示
npm update webpack                    // 更新webpack模块,更新操作也可写成安装操作,会覆盖的
npm update webpack -g                 // 全局更新webpack模块

npm list -g                           // 查看所有全局安装的模块
npm list                              // 查看本地安装的模块
npm list webpack                      // 查看webpack模块的版本号
npm ls                                // 查看项目依赖项列表,列出package.json文件中所有的依赖项以及它们的所有依赖项
npm ls --depth=0                      // 只列出依赖项
npm ls -g -depth 0                    // 查看所有全局安装的包的列表

npm info 模块名                        // 查看模块/包的信息

npm cache clean -f                    // npm清理缓存

npm view webpack                      // 显示webpack包的相关信息
npm v webpack                         // 显示webpack包的相关信息
npm v webpack version                 // 只想获得最新版本的软件包
npm v webpack versions                // 获得npm包完整的版本列表

npm search webpack                    // 根据关键词搜索模块
npm search gulp debug                 // 搜索包含gulp和debug的包
npm s gulp debug                      // 搜索包含gulp和debug的包

npm run tests                         // 运行测试
npm test                              // 运行测试
npm t                                 // 运行测试

npm run                               // 查看package.json文件中包含的脚本

npm i https://github.com/sindresorhus/gulp-debug  // 直接从Github仓库安装一个包
npm i sindresorhus/gulp-debug                     // 直接从Github仓库安装一个包,可以省略域名部分
npm repo create-react-app                         // 打开包的Github页面

【 npm-check 】
Check for outdated, incorrect, and unused dependencies
npm-check是一个npm包更新工具,还可以检查项目的npm依赖包是否有更新、缺失、错误及未使用等情况,主要优势如下：
1.提供图形化界面,还有emoji
2.批量更新依赖包,还检测包使用情况
3.项目下更新支持自动检测包的"dependencies" 和"devDependencies"并更新"package.json"信息

> npm install -g npm-check // 全局安装,项目下安装可自行选择
> npm install npm-check    // 项目下安装,项目根目录执行

> npm-check  // 查看包更新信息,会有emoji提示包的相关情况如需更新、缺失、错误及未使用等,通过上下键移动光标,空格键选择需要处理的包,回车直接进行处理
> npm-check -u | -update  // 更新包,分类别展示,使用空格选择包,然后enter开始更新。自动更新package.json内的相关包信息

-u, --update       显示一个交互式UI,用于选择要更新的模块,并自动更新"package.json"内包版本号信息
-g, --global       检查全局下的包
-s, --skip-unused  忽略对未使用包的更新检查
-p, --production   忽略对"devDependencies"下的包的检查
-d, --dev-only     忽略对"dependencies"下的包的检查
-i, --ignore       忽略对指定包的检查.
-E, --save-exact   将确切的包版本存至"package.json"(存储'x.y.z'而不是'^x.y.z')

npm-check更新包时是根据版本号动态生成更新语句并执行。其本质是仍然npm install指令：
所以,问题不是npm install,而是国内的问题。介于网络等因素,国内用户更倾向于使用cnpm,cnpm也比较稳定和快速。

npm-check + cnpm
1. 源码修改法
找到npm-check包下的"npm-check\lib\"和"npm-check\lib-es5\"下的cli.js文件,对文件内代码"options"的属性"installer"进行修改：
installer: process.env.NPM_CHECK_INSTALLER || 'npm'  //改前
installer: process.env.NPM_CHECK_INSTALLER || 'cnpm' //改后

2.修改环境变量值
将NPM_CHECK_INSTALLER设为cnpm
"scripts": {
  "nc-u":"set NPM_CHECK_INSTALLER=cnpm&& npm-check -u"
}

【 npm变量 】
npm run env | grep npm_   // 查看当前项目可供使用的NPM变量的完整列表
npm_config_globalconfig=E:\soft\nodejs\etc\npmrc
npm_config_init_author_email=
npm_config_init_author_name=
npm_config_init_module=C:\Users\Administrator\.npm-init.js
npm_config_init_version=1.0.0
npm_config_local_address=
npm_config_loglevel=notice
npm_config_logs_max=10
npm_config_long=
npm_config_metrics_registry=https://registry.npmjs.org/
npm_config_node_gyp=E:\soft\nodejs\node_modules\npm\node_modules\node-gyp\bin\node-gyp.js
npm_config_node_version=12.16.1
npm_config_production=
npm_config_registry=https://registry.npmjs.org/
npm_config_rollback=true
npm_config_save=true
npm_config_userconfig=C:\Users\Administrator\.npmrc
npm_config_user_agent=npm/6.13.4 node/v12.16.1 win32 x64
npm_execpath=E:\soft\nodejs\node_modules\npm\bin\npm-cli.js
npm_node_execpath=E:\soft\nodejs\node.exe
npm_package_description=xianzhonglin
npm_package_devDependencies_babel_eslint=^8.2.3
npm_package_devDependencies_babel_plugin_transform_class_properties=^6.24.1
npm_package_devDependencies_eslint_plugin_import=^2.12.0
npm_package_devDependencies_eslint_plugin_react=^7.8.2
npm_package_license=MIT
npm_package_name=app
npm_package_private=true
npm_package_scripts_build_h5=taro build --type h5
npm_package_scripts_build_weapp=taro build --type weapp
npm_package_scripts_dev_h5=npm run build:h5 -- --watch
npm_package_scripts_dev_weapp=npm run build:weapp -- --watch
npm_package_scripts_env=SET
npm_package_version=1.0.0

添加NPM变量
可以通过向package.json文件添加自己的NPM变量,可以是任何key,建议将所有NPM变量放在config key中以保持结构有序
默认npm会将变量命名以npm_package为前缀,并保持其在package.json文件中的结构,即$npm_package_config_build_folder

"config": {
  "build_folder":"./dist"
}

在NPM script中使用NPM变量
"scripts": {
  "build": "gulp build --dist $npm_package_config_build_folder"
}
一旦用npm run build运行这个命令,它将被执行为
gulp build --dist ./dist

【 npm版本控制和npm shrinkwrap命令 】
npm i express --save
npm i express --save-dev
npm i express --save --save-exact  # 将固定版本号写入dependencies,建议线上Node.js应用都采取这种锁定版本号的方式,因为不可能保证第三方模块下个小版本是没有验证bug的,即使很流行的模块
$ npm config set save-exact true  # 这样每次npm i xxx --save时会锁定依赖的版本号,相当于加了--save-exact参数

锁定依赖的版本并不能完全防止意外情况的发生,因为锁定的只是最外一层的依赖,而里层依赖的模块的package.json有可能写的是"mongoose": "*"。
为了彻底锁定依赖的版本,让应用在任何机器上安装的都是同样版本的模块(不管嵌套多少层),通过运行npm shrinkwrap会在当前目录下产生一个npm-shrinkwrap.json,里面包含了通过node_modules计算出的模块的依赖树及版本。只要目录下有npm-shrinkwrap.json则运行npm install的时候会优先使用npm-shrinkwrap.json进行安装,没有则使用package.json进行安装。
npm shrinkwrap只会生成dependencies的依赖,不会生成devDependencies的
如果node_modules下存在某个模块(如直接通过npm install xxx安装的)而package.json中没有,运行npm shrinkwrap则会报错

【 unpkg.com 】
unpkg is a fast, global content delivery network for everything on npm. Use it to quickly and easily load any file from any package using a URL like: unpkg.com/:package@:version/:file

unpkg.com/jquery
unpkg.com/lodash/
unpkg.com/react@16.7.0/umd/react.production.min.js

</pre>

<h3>npx</h3><pre>
npm从5.2版开始增加了npx命令,Node自带npm模块,所以可以直接使用npx命令,万一不能用就要手动安装
$ npm install -g npx

npx会帮助执行依赖包里的二进制文件,调用项目安装的模块,使用本地已安装的可执行工具,而不需要配置scripts,引入这个命令的目的是为了提升开发者使用包内提供的命令行工具的体验
1、调用项目内部模块:npx会自动查找当前依赖包node_modules/.bin路径中的可执行文件,不用指定$PATH,
2、如果找不到就会去环境变量$PATH里找,找到就自动执行,
3、避免全局安装模块,执行一次性命令: 如果依然找不到就会临时安装,不用全局安装,安装完成自动执行依赖包中的命令,执行完后再删除包,下次再执行还是会重新临时安装
运行时npx将依赖的模块下载到一个临时目录并调用它,而不用污染全局安装或需要多个步骤,使用以后再删除,所以以后再次执行上面的命令会重新下载依赖的模块

当想尝试一些命令行工具,需要全局安装它但只运行一次,npx能很好的解决这种麻烦。当执行npx < command >,而command并不在系统变量路径中,npx会自动从npm上下载安装这个包并且执行它。当做完这些事情后,已安装的包不会出现在全局安装中,所以不用担心长期使用所带来的全局污染。

以指定node版本、命令的版本,解决了不同项目使用不同版本的命令的问题
$ npx uglify-js@3.1.0 main.js -o ./dist/main.js  # 指定使用3.1.0版本的uglify-js压缩脚本
$ npx node@0.12.8 -v  # 使用不同版本的node,某些场景下这个方法用来切换Node版本要比nvm那样的版本管理器方便一些

只要npx后面的模块无法在本地发现就会下载同名模块,比如本地没有安装http-server模块,下面的命令会自动下载该模块,在当前目录启动一个Web服务。
$ npx http-server  # 一条目录启动一个静态服务器

由于npx会检查环境变量$PATH,所以系统命令也可以调用
$ npx ls  # 等同于 ls
Bash内置的命令不在$PATH里面,所以不能用,如cd是Bash命令,因此就不能用npx cd

npm生态越来越倾向于将devDependencies安装包作为项目本地依赖安装,而不是让用户在全局安装,这意味着像mocha、gulp、bower、webpack甚至Vue和vue-cli这种过去主要是全局安装的命令行工具,现在可以基于项目维度来管理他们的版本,现在的工具包一般都安装在局部,而不是全局,webpack官方文档建议本地安装
可以使用vue-cli@2.x,也可以使用vue-cli@3.x,本地有很多Vue项目,依赖的Vue版本都不太一样。

npx想要解决的主要问题就是调用项目内部安装的模块,比如项目内部安装了vue-cli
$ npm install -S vue-cli

在node项目中要执行一个脚本,对于本地安装的vue-cli,在初始化项目的时候在命令行下调用必须像下面这样在项目的根目录下执行：
$ node-modules/.bin/vue --version
$ ./node_modules/.bin/vue init webpack yourproject

或者在package.json的scripts字段中声明：
 "scripts": {
   "test": "echo \"Error: no test specified\" && exit 1",
   "init-mall": "vue init webpack mall",
   "init:runtime-only": "vue init webpack vue-cms",
   "init-yourproject": "vue init webpack yourproject"
 }

然后执行：
npm run init-yourproject
它其实本质还是运行vue init vue init webpack yourproject
这些init的操作都是属于一次性操作,但却需要在scripts中声明,不科学！

有了npx以后操作就变得简单了：
在一个空的文件夹中安装了本地vue-cli,然后不需要写scripts直接声明使用npx,就可以直接在命令行执行npx开头然后接要执行的内容
npx vue init webpack yourproject

【 npx的参数 】
--no-install参数让npx强制使用本地模块,不下载远程模块,如果本地不存在该模块就会报错
$ npx --no-install http-server

--ignore-existing参数忽略本地或全局已经安装了的的同名模块,强制安装使用远程模块
$ npx --ignore-existing create-react-app my-react-app

-p参数用于指定npx所要安装的模块,-p参数对于需要安装多个模块的场景很有用
$ npx -p node@0.12.8 node -v  # 先指定安装node@0.12.8,然后再执行node -v命令。
$ npx -p lolcatjs -p cowsay [command]  # 安装多个模块

【 -c参数 】
--call, -c  Execute string as if inside `npm run-script`.  [string]

npx安装多个模块时默认所执行的命令之中只有第一个可执行项会使用npx安装的模块,后面的可执行项还是会交给Shell解释。
$ npx -p lolcatjs -p cowsay 'cowsay hello | lolcatjs'
# 代码中cowsay hello | lolcatjs执行时会报错,原因是第一项cowsay由npx解释,而第二项命令localcatjs由Shell解释,但lolcatjs并没有全局安装,所以报错。

-c参数可以将所有命令都用npx解释,有了它下面代码就可以正常执行了。
$ npx -p lolcatjs -p cowsay -c 'cowsay hello | lolcatjs'

-c参数的另一个作用是将环境变量带入所要执行的命令,即-c参数可以把这些npm的环境变量带入npx命令
$ npm run env | grep npm_  # 查看npm提供当前项目的一些环境变量
$ npx -c 'echo "$npm_package_name"'  # 输出当前项目的项目名。

【 npx支持运行远程仓库的可执行文件,执行GitHub源码 】
npx还可以执行GitHub上面的模块源码,远程代码必须是一个模块,即必须包含package.json和入口脚本

# 执行Gist代码
$ npx https://gist.github.com/zkat/4bc19503fe9e9309e2bfaa2c58074d32

# 执行仓库代码
$ npx github:piuccio/cowsay hello

</pre>

<h3>package.json文件</h3><pre>
package.json位于项目根目录下,用于定义包的属性,定义项目所需要的各种模块,及项目的配置信息如名称、版本、许可证等元数据,可以手工编写或使用npm init命令自动生成
npm install命令根据这个配置文件,自动下载所需的模块,配置项目所需的运行和开发环境

</pre>package.json文件是一个JSON对象,该对象的每一个成员就是当前项目的一项设置<pre class="js">
{
  "name": "Hello World",                     // 项目名称
  "version": "0.0.1",                        // 项目版本号,遵守"大版本.次要版本.小版本"的格式
  "author": "张三",                          // 项目作者
  "description": "第一个node.js程序",         // 项目描述
  "keywords":["node.js","javascript"],       // 项目关键词,便于用户搜索
  "homepage": "http://example.com",          // 项目url主页
  "repository": {                            // 项目代码存放地方
    "type": "git",
    "url": "https://path/to/url"
  },
  "license":"MIT",                           // 项目许可证,让使用者知道是如何被允许使用此项目,默认ISC
  "engines": {"node": "0.10.x"},             // 项目需要的node或npm版本范围
  "bugs":{                                   // 项目问题反馈的Url或email配置
    "url":"http://path/to/bug",
    "email":"bug@example.com"
  },
  "contributors":[                           // 项目贡献者
    {
      "name":"李四","email":"lisi@example.com"
    }
  ],
  "scripts": {
    "start": "node index.js"
  },
  "dependencies": {                           // 项目在生产环境中依赖的包
    "express": "latest",
    "mongoose": "~3.8.3",
    "handlebars-runtime": "~1.0.12",
    "express3-handlebars": "~0.5.0",
    "MD5": "~1.2.0"
  },
  "devDependencies": {                        // 项目在开发和测试环境中依赖的包
    "bower": "~1.2.8",
    "grunt": "~0.4.1",
    "grunt-contrib-concat": "~0.3.0",
    "grunt-contrib-jshint": "~0.7.2",
    "grunt-contrib-uglify": "~0.2.7",
    "grunt-contrib-clean": "~0.5.0",
    "browserify": "2.36.1",
    "grunt-browserify": "~1.3.0",
  }
}

</pre>

<h4>package.json字段列表</h4><pre>
【 scripts字段 】
npm脚本(npm scripts):定义在package.json scripts字段里的脚本,script字段的每一个属性对应一段脚本
指定了运行脚本命令的npm命令行缩写,比如start指定了运行npm run start时所要执行的命令
npm run查看当前项目下的所有mpm脚本命令

【 npm脚本的原理 】
每当执行npm run就会自动新建一个Shell,在这个Shell里面执行指定的脚本命令,因此只要是Shell(一般是Bash)可以运行的命令就可以写在npm脚本里面
npm run新建的这个Shell会将当前目录的node_modules/.bin子目录加入PATH变量,执行结束后再将PATH变量恢复原样。
这意味着当前目录的node_modules/.bin子目录里面的所有脚本都可以直接用脚本名调用,而不必加上路径

由于npm脚本的唯一要求就是可以在Shell执行,因此不一定是Node脚本,任何可执行文件都可以写在里面。
npm脚本的退出码也遵守Shell脚本规则,如果退出码不是0,npm就认为这个脚本执行失败

由于npm脚本就是Shell脚本,因为可以使用Shell通配符,*表示任意文件名,**表示任意一层子目录
"lint": "jshint *.js"
"lint": "jshint **/*.js"
"test": "tap test/\*.js"  # 如果要将通配符传入原始命令,防止被Shell转义,要将星号转义

【 向npm脚本传入参数要使用--标明 】
"lint": "jshint **.js"
$ npm run lint --  --reporter checkstyle > checkstyle.xml

也可以在package.json里面再封装一个命令
"lint": "jshint **.js",
"lint:checkstyle": "npm run lint -- --reporter checkstyle > checkstyle.xml"

【 多个任务执行顺序 】
如果是并行执行可以使用&符号
$ npm run script1.js & npm run script2.js
如果是继发执行,即只有前一个任务成功才执行下一个任务,可以使用&&符号
$ npm run script1.js && npm run script2.js
这两个符号是Bash的功能,此外还可使用node的任务管理模块：script-runner、npm-run-all、redrun

【 默认值 】
一般来说npm脚本由用户提供,但npm对两个脚本提供了默认值,也就是说这两个脚本不用定义就可以直接使用
"start": "node server.js",
"install": "node-gyp rebuild"
npm run start的默认值是node server.js,前提是项目根目录下有server.js这个脚本
npm run install的默认值是node-gyp rebuild,前提是项目根目录下有binding.gyp文件

【 钩子 】
npm脚本有pre和post两个钩子,build脚本命令的钩子就是prebuild和postbuild。

"prebuild": "echo I run before the build script",
"build": "cross-env NODE_ENV=production webpack",
"postbuild": "echo I run after the build script"

用户执行npm run build的时候会自动按照下面的顺序执行。
npm run prebuild && npm run build && npm run postbuild

因此可以在这两个钩子里面,完成一些准备工作和清理工作
"clean": "rimraf ./dist && mkdir dist",
"prebuild": "npm run clean",
"build": "cross-env NODE_ENV=production webpack"

npm默认提供下面这些钩子
prepublish,postpublish
preinstall,postinstall
preuninstall,postuninstall
preversion,postversion
pretest,posttest
prestop,poststop
prestart,poststart
prerestart,postrestart

自定义的脚本命令也可以加上pre和post钩子,比如myscript脚本命令也有premyscript和postmyscript钩子
不过双重的pre和post无效,比如prepretest和postposttest是无效的。

【 简写形式 】
四个常用的npm脚本有简写形式:
npm start是npm run start
npm stop是npm run stop的简写
npm test是npm run test的简写
npm restart是npm run stop && npm run restart && npm run start的简写

npm restart具体的执行顺序如下:
prerestart
prestop
stop
poststop
restart
prestart
start
poststart
postrestart

设置npm run preinstall、npm run postinstall、npm run start、npm run test时所要执行的命令
"scripts": {
  "preinstall": "echo here it comes!",
  "postinstall": "echo there it goes!",
  "start": "node index.js",
  "test": "tap test/*.js"
}

声明一系列npm脚本指令
prepublish: 在包发布之前运行,也会在npm install安装到本地时运行
publish,postpublish: 包被发布之后运行
preinstall: 包被安装前运行
install,postinstall: 包被安装后运行
preuninstall,uninstall: 包被卸载前运行
postuninstall: 包被卸载后运行
preversion: bump包版本前运行
postversion: bump包版本后运行
pretest,test,posttest: 通过npm test命令运行
prestop,stop,poststop: 通过npm stop命令运行
prestart,start,poststart: 通过npm start命令运行
prerestart,restart,postrestart: 通过npm restart运行

【 变量 】
npm脚本有一个非常强大的功能就是可以使用npm的内部变量。
首先通过npm_package_前缀npm脚本可以拿到package.json里面的字段
process.env.npm_package_name通过环境变量process.env对象拿到package.json的字段值
如果是Bash脚本可以用$npm_package_name和$npm_package_version取到对应的值

</pre><pre class="js">
{
  "name": "foo",
  "version": "1.2.5",
  "scripts": {
    "view": "node view.js"
  }
}

// view.js
console.log(process.env.npm_package_name);     // foo
console.log(process.env.npm_package_version);  // 1.2.5

</pre>npm_package_前缀也支持嵌套的package.json字段<pre class="js">
"repository": {
  "type": "git",
  "url": "xxx"
},
scripts: {
  "view": "echo $npm_package_repository_type"   // git
  "install": "foo.js"
  "view1": "echo $npm_package_scripts_install"  // foo.js
}

</pre>npm提供npm_lifecycle_event变量返回当前正在运行的脚本名称,比如pretest、test、posttest等,所以可以利用这个变量在同一个脚本文件里面为不同的npm scripts命令编写代码<pre class="js">
const TARGET = process.env.npm_lifecycle_event;
if (TARGET === 'test') console.log(`Running the test task!`);
if (TARGET === 'pretest') console.log(`Running the pretest task!`);
if (TARGET === 'posttest') console.log(`Running the posttest task!`);

</pre><pre class="js">
// package.json
{
  "name": "npm-script",
  "version": "1.0.0",
  "description": "test npm script",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "server": "echo \"torun nodejs\" && node server",
    "script1": "node script1",
    "script2": "node script2",
    "create": "mkdir test && echo to test create a file > test.txt",
    "preallscript": "npm run create && echo \"dir test has been created, then run allscript\"",
    "allscript": "node script1 && node script2",
    "deldir": "rd test",
    "postallscript": "npm run deldir && echo \"ok!everything has gone,gamvoer!\"",
    "usevar": "node showscriptname"
  },
  "author": "",
  "license": "ISC"
}

// showscriptname.js
const TARGET = process.env.npm_lifecycle_event;
console.log(`Running the ${TARGET} task!`);
console.log('\n')
console.log(process.env.npm_package_name);
console.log(process.env.npm_package_version);
console.log(process.env.npm_package_description);
console.log(process.env.npm_package_scripts_usevar);
console.log('\n')
console.log(process.env.npm_config_cache)
console.log(process.env.npm_config_tag)
console.log('\n')
console.log('process.env: ', process.env);

> npm run usevar

> npm-script@1.0.0 usevar E:\wamp64\www\study\npm-script
> node showscriptname

Running the usevar task!

npm-script
1.0.0
test npm script
node showscriptname

C:\Users\lenovo\AppData\Roaming\npm-cache
latest

process.env:  { ALLUSERSPROFILE: 'C:\\ProgramData',
  APPDATA: 'C:\\Users\\lenovo\\AppData\\Roaming',
  CommonProgramFiles: 'C:\\Program Files\\Common Files',
  'CommonProgramFiles(x86)': 'C:\\Program Files (x86)\\Common Files',
  CommonProgramW6432: 'C:\\Program Files\\Common Files',
  COMPUTERNAME: 'LAPTOP-0KMQM01D',
  ComSpec: 'C:\\WINDOWS\\system32\\cmd.exe',
  configsetroot: 'C:\\WINDOWS\\ConfigSetRoot',
  C_EM64T_REDIST11: 'C:\\Program Files (x86)\\Common Files\\Intel\\Shared Files\\cpp\\',
  DriverData: 'C:\\Windows\\System32\\Drivers\\DriverData',
  HOME: 'C:\\Users\\lenovo',
  HOMEDRIVE: 'C:',
  HOMEPATH: '\\Users\\lenovo',
  INIT_CWD: 'E:\\wamp64\\www\\study\\npm-script',
  LOCALAPPDATA: 'C:\\Users\\lenovo\\AppData\\Local',
  LOGONSERVER: '\\\\LAPTOP-0KMQM01D',
  NODE: 'E:\\soft\\node\\node.exe',
  NODE_EXE: 'E:\\soft\\node\\\\node.exe',
  NPM_CLI_JS: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\npm\\bin\\npm-cli.js',
  npm_config_access: '',
  npm_config_allow_same_version: '',
  npm_config_also: '',
  npm_config_always_auth: '',
  npm_config_argv: '{"remain":[],"cooked":["run","usevar"],"original":["run","usevar"]}',
  npm_config_auth_type: 'legacy',
  npm_config_bin_links: 'true',
  npm_config_browser: '',
  npm_config_ca: '',
  npm_config_cache: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm-cache',
  npm_config_cache_lock_retries: '10',
  npm_config_cache_lock_stale: '60000',
  npm_config_cache_lock_wait: '10000',
  npm_config_cache_max: 'Infinity',
  npm_config_cache_min: '10',
  npm_config_cafile: '',
  npm_config_cert: '',
  npm_config_cidr: '',
  npm_config_color: 'true',
  npm_config_commit_hooks: 'true',
  npm_config_depth: 'Infinity',
  npm_config_description: 'true',
  npm_config_dev: '',
  npm_config_dry_run: '',
  npm_config_editor: 'notepad.exe',
  npm_config_engine_strict: '',
  npm_config_fetch_retries: '2',
  npm_config_fetch_retry_factor: '10',
  npm_config_fetch_retry_maxtimeout: '60000',
  npm_config_fetch_retry_mintimeout: '10000',
  npm_config_force: '',
  npm_config_git: 'git',
  npm_config_git_tag_version: 'true',
  npm_config_global: '',
  npm_config_globalconfig: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm\\etc\\npmrc',
  npm_config_globalignorefile: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm\\etc\\npmignore',
  npm_config_global_style: '',
  npm_config_group: '',
  npm_config_ham_it_up: '',
  npm_config_heading: 'npm',
  npm_config_https_proxy: '',
  npm_config_if_present: '',
  npm_config_ignore_prepublish: '',
  npm_config_ignore_scripts: '',
  npm_config_init_author_email: '',
  npm_config_init_author_name: '',
  npm_config_init_author_url: '',
  npm_config_init_license: 'ISC',
  npm_config_init_module: 'C:\\Users\\lenovo\\.npm-init.js',
  npm_config_init_version: '1.0.0',
  npm_config_json: '',
  npm_config_key: '',
  npm_config_legacy_bundling: '',
  npm_config_link: '',
  npm_config_local_address: '',
  npm_config_loglevel: 'notice',
  npm_config_logs_max: '10',
  npm_config_long: '',
  npm_config_maxsockets: '50',
  npm_config_message: '%s',
  npm_config_metrics_registry: 'https://registry.npmjs.org/',
  npm_config_node_gyp: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\npm\\node_modules\\npm-lifecycle\\node_modules\\node-gyp\\bin\\node-gyp.js',
  npm_config_node_options: '',
  npm_config_node_version: '8.9.1',
  npm_config_no_proxy: '',
  npm_config_offline: '',
  npm_config_onload_script: '',
  npm_config_only: '',
  npm_config_optional: 'true',
  npm_config_otp: '',
  npm_config_package_lock: 'true',
  npm_config_package_lock_only: '',
  npm_config_parseable: '',
  npm_config_prefer_offline: '',
  npm_config_prefer_online: '',
  npm_config_prefix: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm',
  npm_config_production: '',
  npm_config_progress: 'true',
  npm_config_proxy: '',
  npm_config_read_only: '',
  npm_config_rebuild_bundle: 'true',
  npm_config_registry: 'https://registry.npmjs.org/',
  npm_config_rollback: 'true',
  npm_config_save: 'true',
  npm_config_save_bundle: '',
  npm_config_save_dev: '',
  npm_config_save_exact: '',
  npm_config_save_optional: '',
  npm_config_save_prefix: '^',
  npm_config_save_prod: '',
  npm_config_scope: '',
  npm_config_scripts_prepend_node_path: 'warn-only',
  npm_config_script_shell: '',
  npm_config_searchexclude: '',
  npm_config_searchlimit: '20',
  npm_config_searchopts: '',
  npm_config_searchstaleness: '900',
  npm_config_send_metrics: '',
  npm_config_shell: 'C:\\WINDOWS\\system32\\cmd.exe',
  npm_config_shrinkwrap: 'true',
  npm_config_sign_git_tag: '',
  npm_config_sso_poll_frequency: '500',
  npm_config_sso_type: 'oauth',
  npm_config_strict_ssl: 'true',
  npm_config_tag: 'latest',
  npm_config_tag_version_prefix: 'v',
  npm_config_timing: '',
  npm_config_tmp: 'C:\\Users\\lenovo\\AppData\\Local\\Temp',
  npm_config_umask: '0000',
  npm_config_unicode: '',
  npm_config_unsafe_perm: 'true',
  npm_config_usage: '',
  npm_config_user: '',
  npm_config_userconfig: 'C:\\Users\\lenovo\\.npmrc',
  npm_config_user_agent: 'npm/5.8.0 node/v8.9.1 win32 x64',
  npm_config_version: '',
  npm_config_versions: '',
  npm_config_viewer: 'browser',
  npm_execpath: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\npm\\bin\\npm-cli.js',
  npm_lifecycle_event: 'usevar',
  npm_lifecycle_script: 'node showscriptname',
  npm_node_execpath: 'E:\\soft\\node\\node.exe',
  npm_package_author: '',
  npm_package_description: 'test npm script',
  npm_package_license: 'ISC',
  npm_package_main: 'index.js',
  npm_package_name: 'npm-script',
  npm_package_scripts_allscript: 'node script1 && node script2',
  npm_package_scripts_create: 'mkdir test && echo to test create a file > test.txt',
  npm_package_scripts_deldir: 'rd test',
  npm_package_scripts_postallscript: 'npm run deldir && echo "ok!everything has gone,gamvoer!"',
  npm_package_scripts_preallscript: 'npm run create && echo "dir test has been created, then run allscript"',
  npm_package_scripts_script1: 'node script1',
  npm_package_scripts_script2: 'node script2',
  npm_package_scripts_server: 'echo "torun nodejs" && node server',
  npm_package_scripts_start: 'node server.js',
  npm_package_scripts_test: 'echo "Error: no test specified" && exit 1',
  npm_package_scripts_usevar: 'node showscriptname',
  npm_package_version: '1.0.0',
  NPM_PREFIX_NPM_CLI_JS: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\npm\\bin\\npm-cli.js',
  NUMBER_OF_PROCESSORS: '4',
  OneDrive: 'C:\\Users\\lenovo\\OneDrive',
  OS: 'Windows_NT',
  Path: 'C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\npm\\node_modules\\npm-lifecycle\\node-gyp-bin;E:\\wamp64\\www\\study\\npm-script\\node_modules\\.bin;C:\\Program Files (x86)\\Common Files\\Intel\\Shared Files\\cpp\\bin\\Intel64;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files (x86)\\ATI Technologies\\ATI.ACE\\Core-Static;C:\\ProgramData\\ComposerSetup\\bin;C:\\WINDOWS\\System32\\OpenSSH\\;E:\\wamp64\\bin\\mysql\\mysql5.7.9\\bin;E:\\wamp64\\bin\\php\\php5.6.16;E:\\soft\\node\\;E:\\soft\\mongodb\\bin;E:\\soft\\redis\\;E:\\soft\\sublime\\Sublime Text 3;C:\\Users\\lenovo\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\lenovo\\AppData\\Roaming\\Composer\\vendor\\bin;C:\\Users\\lenovo\\AppData\\Roaming\\npm;;E:\\soft\\vscode\\Microsoft VS Code\\bin',
  PATHEXT: '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC',
  PROCESSOR_ARCHITECTURE: 'AMD64',
  PROCESSOR_IDENTIFIER: 'Intel64 Family 6 Model 61 Stepping 4, GenuineIntel',
  PROCESSOR_LEVEL: '6',
  PROCESSOR_REVISION: '3d04',
  ProgramData: 'C:\\ProgramData',
  ProgramFiles: 'C:\\Program Files',
  'ProgramFiles(x86)': 'C:\\Program Files (x86)',
  ProgramW6432: 'C:\\Program Files',
  PROMPT: '$P$G',
  PSModulePath: 'C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules',
  PUBLIC: 'C:\\Users\\Public',
  SESSIONNAME: 'Console',
  SystemDrive: 'C:',
  SystemRoot: 'C:\\WINDOWS',
  TEMP: 'C:\\Users\\lenovo\\AppData\\Local\\Temp',
  TMP: 'C:\\Users\\lenovo\\AppData\\Local\\Temp',
  USERDOMAIN: 'LAPTOP-0KMQM01D',
  USERDOMAIN_ROAMINGPROFILE: 'LAPTOP-0KMQM01D',
  USERNAME: 'lenovo',
  USERPROFILE: 'C:\\Users\\lenovo',
  VBOX_MSI_INSTALL_PATH: 'D:\\virtualbox\\',
  windir: 'C:\\WINDOWS' }

</pre><pre>
【 config 】
config字段用于添加命令行的环境变量

{
  "name" : "foo",
  "config" : { "port" : "8080" },
  "scripts" : { "start" : "node server.js" }
}

然后在server.js脚本就可以引用config字段的值
npm脚本还可以通过npm_config_前缀拿到npm的配置变量,即npm config get xxx命令返回的值,比如当前模块的发行标签可以通过process.env.npm_config_tag取到
http
  .createServer(...)
  .listen(process.env.npm_package_config_port)

用户执行npm run start命令时这个脚本就可以得到值
$ npm run start

package.json里面的config对象可以被环境变量覆盖,用户可以改变这个值
$ npm config set foo:port 80

【 dependencies 】
项目在生产环境中依赖的包

【 devDependencies 】
项目在开发和测试环境中依赖的包

它们都指向一个对象,该对象的各个成员分别由模块名和对应的版本要求组成,表示依赖的模块及其版本范围。

{
  "devDependencies": {
    "browserify": "~13.0.0",
    "karma-browserify": "~5.0.1"
  }
}

对应的版本可以加上各种限定：
1、指定版本
如1.2.2,遵循"大版本.次要版本.小版本"的格式规定,安装时只安装指定版本。
2、波浪号(tilde)+指定版本
如~1.2.2,表示安装1.2.x的最新版本(不低于1.2.2),但是不安装1.3.x,也就是说安装时不改变大版本号和次要版本号。
3、插入号(caret)+指定版本
如ˆ1.2.2,表示安装1.x.x的最新版本(不低于1.2.2),但是不安装2.x.x,也就是说安装时不改变大版本号
如果大版本号为0,则插入号的行为与波浪号相同,这是因为此时处于开发阶段,即使是次要版本号变动,也可能带来程序的不兼容。
4、latest：安装最新版本

【 peerDependencies 】
当一个主机无法require依赖包时告诉它还有哪些工具或库与这个依赖包兼容,这通常被成为一个插件,尤其是在host文档中声明的模块会暴露一个特定的接口

{
  "name": "tea-latte",
  "version": "1.3.5",
  "peerDependencies": {
    "tea": "2.x"
  }
}
这将确保tea-latte这个包只会和2.x版本的tea一起被安装。执行npm install tea-latte可能产生以下关系图：
├──tea-latte@1.3.5
└──tea@2.2.0

【 private 】
设置为true表示npm会拒绝发布它

【 engines 】
engines字段指明了该模块运行的平台,比如Node的某个版本或浏览器
声明项目需要的node或npm版本范围
{ "engines" : { "npm" : "~1.0.20" } }
{ "engines" : { "node" : "> =0.10.3 < 0.12" } }

【 bugs 】
项目问题反馈的Url或email配置
{
  "url" : "https://github.com/owner/project/issues",
  "email" : "project@hostname.com"
}

【 author,contributors 】
作者和贡献者
{
  "name" : "Barney Rubble",
  "email" : "b@rubble.com",
  "url" : "http://barnyrubble.tumblr.com/"
}

【 files 】
包含在项目中的文件数组。如果在数组里面声明了一个文件夹,那也会包含文件夹中的文件。可以声明一些规则来忽略部分文件。可以在项目根目录或子目录里声明一个.npmignore。

Certain files are always included, regardless of settings:

package.json
README (and its variants)
CHANGELOG (and its variants)
LICENSE / LICENCE
Conversely, some files are always ignored:

.git
CVS
.svn
.hg
.lock-wscript
.wafpickle-N
*.swp
.DS_Store
._*
npm-debug.log

【 main 】
main字段指定加载的入口文件,require('moduleName')就会加载这个文件,这个字段的默认值是模块根目录下面的index.js

【 bin 】
bin项用来指定各个内部命令对应的可执行文件的位置,项目用到的可执行文件配置
所有node_modules/.bin/目录下的命令都可以用npm run [命令]的格式运行
在命令行下键入npm run回车就会显示当前目录下所有可以使用的命令

"bin": {
  "someTool": "./bin/someTool.js"
}

【 man 】
指定一个单一的文件名或一个文件名数组,类似于linux命令中的man命令来查看一个命令的用法
如果只给man字段提供一个文件则安装完毕后它就是man的结果,这和此文件名无关

// 执行man foo时就会使用文件./man/doc.1
{
  "name": "foo",
  "version": "1.2.3",
  "description": "A packaged foo fooer for fooing foos",
  "main": "foo.js",
  "man": "./man/doc.1"
}

如果指定的文件名并未以包名开头,那么它会被冠以前缀

// 这将会为man foo和man foo-bar创建文件
{
  "name": "foo",
  "version": "1.2.3",
  "description": "A packaged foo fooer for fooing foos",
  "main": "foo.js",
  "man": [
    "./man/foo.1",
    "./man/bar.1"
  ]
}

man文件必须以一个数字结尾,和一个可选的.gz后缀(当它被压缩时),这个数字说明了这个文件被安装到哪个节中

// 为使用man foo和man 2 foo而创建
{
  "name": "foo",
  "version": "1.2.3",
  "description": "A packaged foo fooer for fooing foos",
  "main": "foo.js",
  "man": [
    "./man/foo.1",
    "./man/foo.2"
  ]
}

【 directories 】
CommonJS Packages规范说明了几种可以用directories对象来标示包结构的方法

【 directories.lib 】
告诉库文件夹的位置,目前没有什么地方需要用到lib文件夹,但是这是重要的元信息

【 directories.bin 】
如果在directories.bin中指定一个bin目录,在这个目录中的所有文件都会被当做在bin来使用。

由于bin指令的工作方式,同时指定一个bin路径和设置directories.bin将是一个错误。如果你想指定独立的文件,使用bin,如果想执行某个文件夹里的所有文件,使用directories.bin。
directories.doc: 把markdown文件放在这。也许某一天这些文件将被漂亮地展示出来,不过这仅仅是也许

【 directories.man 】
指定的文件夹里都是man文件,系统通过遍历这个文件夹来生成一个man的数组

【 directories.example 】
把示例脚本放在这

【 repository 】
项目代码存放地方

"repository" : {
  "type" : "git",
  "url" : "https://github.com/npm/npm.git"
}
"repository" : {
  "type" : "svn",
  "url" : "https://v8.googlecode.com/svn/trunk/"
}

【 bundledDependencies: {Array} 】
发布时会被一起打包的模块

【 optionalDependencies 】
如果一个依赖模块可以被使用,同时也希望在该模块找不到或无法获取时npm继续运行,可以把这个模块依赖放到optionalDependencies配置中。这个配置的写法和dependencies的写法一样,不同的是这里边写的模块安装失败不会导致npm install失败。当然这种模块就需要自己在代码中处理模块确实的情况

try {
    var foo = require('foo')
    var fooVersion = require('foo/package.json').version
} catch (er) {
    foo = null
}
if ( notGoodFooVersion(fooVersion) ) {
    foo = null
}
// .. then later in your program ..
if (foo) {
    foo.doFooThings()
}

【os】
指定项目将运行在什么操作系统上

【cpu】
指定项目将运行在什么cpu架构上

【preferGlobal】
如果包需要全局安装,通过命令行来运行,那么设置为true,如果这个包被本地安装则会出现一个警告
preferGlobal的值是布尔值,表示当用户不将该模块安装为全局模块时(即不用–global参数),要不要显示警告,表示该模块的本意就是安装为全局模块。

【publishConfig】

【browser字段】
browser指定该模板供浏览器使用的版本,Browserify这样的浏览器打包工具通过它就知道该打包那个文件。

"browser": {
  "tipso": "./node_modules/tipso/src/tipso.js"
},

【style字段】
style指定供浏览器使用时样式文件所在的位置,样式文件打包工具parcelify通过它知道样式文件的打包位置。

"style": [
  "./node_modules/tipso/src/tipso.css"
]

</pre>

<h3>yarn</h3><pre>
yarn是facebook发布的一款取代npm的包管理工具。

yarn的特点：
速度超快: Yarn缓存了每个下载过的包,所以再次使用时无需重复下载。同时利用并行下载以最大化资源利用率,因此安装速度更快。
超级安全: 在执行代码之前,Yarn会通过算法校验每个安装包的完整性。
超级可靠: 使用详细、简洁的锁文件格式和明确的安装算法,Yarn能够保证在不同系统上无差异的工作

使用npm安装
npm install -g yarn
yarn --version

yarn help  // 显示帮助信息,列出一系列可用的命令及参数,每一条都会配一段功能简介
yarn help COMMAND

【 yarn的配置项 】
yarn config list// 显示所有配置项
yarn config get < key>//显示某配置项
yarn config delete < key> //删除某配置项
yarn config set < key> < value> [-g|--global] //设置配置项

改变yarn全局安装位置
yarn config set global-folder [path]
yarn config set global-folder "D:\Software\yarn\global"

改变yarn缓存位置
yarn config set cache-folder [path]
使用全局安装包的时候会在“D:\Software\yarn\global”下生成node_modules\.bin目录
yarn config set cache-folder "D:\Software\yarn\cache"
需要将D:\Software\yarn\global\node_modules\.bin整个目录添加到系统环境变量中去,否则通过yarn添加的全局包在cmd中是找不到的。
检查当前yarn的bin的位置
yarn global bin
检查当前yarn的全局安装位置
$ yarn global dir

默认设置
yarn cache dir
C:\Users\Administrator\AppData\Local\Yarn\Cache\v6
yarn global dir
C:\Users\Administrator\AppData\Local\Yarn\Data\global
yarn global bin
E:\soft\nodejs\bin

Yarn淘宝源安装
yarn config set registry https://registry.npm.taobao.org -g
yarn config set sass_binary_site http://cdn.npm.taobao.org/dist/node-sass -g

C:\Users\Administrator\.yarnrc
.yarnrc files allow you to configure additional Yarn features. The config command may also be used to set these options. Yarn will merge .yarnrc files up the file tree

使用yarn.lock文件来固化依赖
Yarn利用项目根目录下的yarn.lock文件来确保依赖解析时又快又稳定,无须碰这个文件,yarn会自己搞定的。
为了保证应用的行为保持一致,应该把yarn.lock文件提交到代码仓库中

【 yarn命令 】
yarn version
Updates the package version

yarn versions
显示当前安装的 Yarn、Node.js 及他们的依赖项的版本信息。

初始化项目
yarn init // 同npm init,执行输入信息后生成package.json文件

安装包：npm install
yarn         // 安装项目的全部依赖
yarn install //安装package.json里所有包,并将包及它的所有依赖项保存进yarn.lock
yarn install --flat //安装一个包的单一版本
yarn install --force //强制重新下载所有包
yarn install --production //只安装dependencies里的包
yarn install --no-lockfile//不读取或生成yarn.lock
yarn install --pure-lockfile //不生成yarn.lock

添加包(会更新package.json和yarn.lock)：npm install [package]
yarn golbal add packageName  // 全局安装包
yarn add [package]  // 在当前的项目中添加一个依赖包,会自动更新到package.json和yarn.lock文件中
yarn add [package]@[version] // 安装指定版本的主要版本,如果需要精确到小版本使用-E参数
yarn add [package]@[tag] // 安装某个tag(比如beta、next或latest)

默认安装到dependencies里,也可以指定依赖类型：npm install [package] --save-dev
将依赖项添加到不同依赖项类别中: devDependencies、peerDependencies和optionalDependencies类别中
yarn add --dev/-D  // 加到devDependencies
yarn add --peer/-P  // 加到peerDependencies
yarn add --optional/-O  // 加到optionalDependencies

默认安装包的主要版本里的最新版本,可以指定版本：
yarn add --exact/-E  // 安装包的精确版本,如yarn add foo@1.2.3接受1.9.1版,但yarn add foo@1.2.3 --exact只会接受1.2.3版
yarn add --tilde/-T  // 安装包的次要版本里的最新版,如yarn add foo@1.2.3 --tilde接受1.2.9,但不接受1.3.0

yarn list  // List installed packages
yarn global list //获取yarn安装包列表
yarn list [--depth] [--pattern] 
yarn list --depth=0
yarn list --pattern gulp
yarn list --pattern "gulp|grunt"
yarn list --pattern "gulp|grunt" --depth=1

移除一个包: npm uninstall packageName
yarn remove [package] // 移除一个包,会自动更新package.json和yarn.lock

更新一个依赖: npm update packageName --save
yarn upgrade [package]  // 用于更新包到基于规范范围的最新版本
yarn upgrade [package]@[version]
yarn upgrade [package]@[tag]

运行脚本: npm run
yarn run  // 用来执行在package.json中scripts属性下定义的脚本

显示某个包的信息: npm view [package]
yarn info [package]  // 可以用来查看某个模块的最新版本信息
yarn info react
yarn info react --json
yarn info react@15.3.0
yarn info react description  // Selecting specific fields
yarn info react versions
yarn info react readme  // Retrieving the readme field

缓存
yarn cache 
yarn cache list  // 列出已缓存的每个包
yarn cache list --pattern gulp
yarn cache list --pattern "gulp|grunt"
yarn cache list --pattern "gulp-(match|newer)"

yarn cache dir  // 返回全局缓存位置(%LocalAppData%\Yarn)

yarn cache clean  // 清除缓存
yarn cache clean [module_name...]  // clear the global cache

发布包
yarn publish

</pre>
</div>

<!-- -----------------------------module------------------------------ -->
<div id="module">
<h2>模块系统 module</h2><pre>
为了让Node.js的文件可以相互调用,Node.js提供了一个简单的模块系统
模块是Node.js应用程序的基本组成部分,文件和模块一一对应,一个Node.js文件就是一个模块,该文件可能是Js代码、JSON或编译过的C/C++扩展

Node.js中存在4类模块(原生模块和3种文件模块),尽管require方法简单,但内部的加载十分复杂,加载优先级各自不同

</pre><img src="image/nodejs-require.jpg"><pre>

【 node模块的载入及缓存机制: 】
Node.js中模块可以通过文件路径或名字获取模块的引用
模块的引用会映射到一个js文件路径,除非它是一个Node内置模块,Node的内置模块公开了一些常用的API给开发者,并且它们在Node进程开始的时候就预加载了

其它的如通过NPM安装的第三方模块(third-party modules)或本地模块(local modules),每个模块都会暴露一个公开的API,以便开发者可以导入

require方法接受以下几种参数的传递：
http、fs、path等      原生模块
./mod或../mod       相对路径的文件模块
/pathtomodule/mod   绝对路径的文件模块
mod                 非原生模块的文件模块

1、载入内置模块(A Core Module)
Node的内置模块被编译为二进制形式,引用时直接使用名字而非文件路径,当第三方的模块和内置模块同名时会被覆盖

2、载入文件模块(A File Module)
js文件名前面需要加上路径,可以是相对路径,也可以是绝对路径
如果省略路径,node.js会加载一个核心模块,或已经安装在本地node_modules目录中的模块

3、载入文件目录模块(A Folder Module)  var myMod = require('./folder')
Node将搜索整个folder目录,Node会假设folder为一个包并试图找到包定义文件package.json
如果folder目录里没有包含package.json文件,Node会假设默认主文件为index.js
如果index.js也不存在,那么加载将失败,抛出异常

// package.json
{
    "name": "pack",
    "main": "modA.js"
}

4、载入node_modules里的模块
如果模块名不是路径,也不是内置模块,Node将试图去当前目录的node_modules文件夹里搜索
如果当前目录的node_modules里没有找到,Node会从父目录的node_modules里搜索,这样递归下去直到根目录
npm命令可很方便的去安装、卸载、更新node_modules目录

5、自动缓存已载入模块,对于已加载的模块Node会缓存下来,而不必每次都重新搜索

对于每一个被加载的文件模块,创建这个模块对象的时候,这个模块便会有一个paths属性,其值根据当前文件的路径计算得到

// modulepath.js
console.log(module.paths);

// node modulepath.js
[ 'E:\\wamp64\\www\\study\\nodejs\\module\\node_modules',
  'E:\\wamp64\\www\\study\\nodejs\\node_modules',
  'E:\\wamp64\\www\\study\\node_modules',
  'E:\\wamp64\\www\\node_modules',
  'E:\\wamp64\\node_modules',
  'E:\\node_modules' ]

整个查找过程十分类似原型链的查找和作用域的查找,但Node.js对路径查找实现了缓存机制,一旦加载成功就以模块的路径进行缓存,否则由于每次判断路径都是同步阻塞式进行,会导致严重的性能消耗

require("./test.js") 如果写了完整的文件名会准确加载这个文件
如果没有写入扩展名require("./test"),那么会尝试加载test.js,然后是test.json

</pre>

<h4>【 exports和require 】</h4><pre>
Node.js提供了exports和require两个对象

require是module.require的简写方式
require用于从外部获取一个模块的接口,即所获取模块的exports对象
require方法读取一个文件并执行,最后返回文件内部的exports对象,该对象公开的API可能是函数、对象或属性如函数,数组,甚至任意类型的JS对象

exports是module.exports的辅助写法,是模块的出口,模块公开的接口
module.exports = xxx
exports.xxx = xxx
模块中同时使用moudle.exports和exports会忽略exports的定义
module.exports必须要立即执行,否则模块不会被加载

// 不会加载
setTimeout(function() {
    module.exports = { a: "hello" };
}, 0);

module.id
模块文件的完整路径,main.js如果是主启动文件,那么它自身调用 console.log(module.id) ,只会打印出 "." 。

module.filename
和module.id功能一样,即使是main.js调用console.log(module.filename)也会打印出完整的文件路径。

module.loaded
判断模块是否被加载完成,true/false。

module.parent
得到父模块。

module.children
得到子模块

require目录的机制:
如果目录下有package.json并指定了main字段则用之
如果不存在package.json则依次尝试加载目录下的index.js和index.node

requir过的文件会加载到缓存,所以多次require同一个文件(模块)不会重复加载

判断是否是程序的入口文件有两种方式:
require.main === module(推荐)
module.parent === null

</pre>

<h4>创建模块 node.js默认后缀为.js,可省略</h4><pre class="js">
/* hello.js */
exports.world = function() {     // 通过exports对象把world作为模块的访问接口
  console.log('Hello World');
}
exports.sayHello = function(){   // hello模块里的方法
  console.log("床前明月光");
};
exports.name = "疑是地上霜";      // hello模块里的变量

/* index.js */
var hello = require('./hello');   // 引入当前目录下的hello.js文件
hello.world();
hello.sayhello();
console.log(hello.name);

</pre>把一个对象封装到模块中<pre class="js">
/* hello.js */
function Hello() {
    var name;
    this.setName = (thyName) => name = thyName;
    this.sayHello = () => console.log('Hello ' + name);
};
module.exports = Hello;

/* main.js */
var Hello = require('./hello');
hello = new Hello();
hello.setName('heiging');
hello.sayHello();            // hello heiying

</pre><pre class="js">
/* foobar.js */
function foobar(){
    this.foo = function(){ console.log('Hello foo'); }
    this.bar = function(){ console.log('Hello bar'); }
}
exports.foobar = foobar;

/* main.js */
var foobar = require('./foobar').foobar;
var test   = new foobar();
test.bar();                // 'Hello bar'

</pre>有时不需要exports返回一个对象,只需要它返回一个函数,这时就要写成module.exports<pre class="js">
module.exports = function () {
  console.log("hello world")
}

</pre>如果模块是一个特定的类型就用Module.exports。如果模块是一个典型的"实例化对象"就用exports<pre class="js">
/* 模块是一个构造函数 */
module.exports = function(name, age) {
    this.name = name;
    this.age = age;
    this.about = function() {
        console.log(this.name +' is '+ this.age +' years old');
    };
};

//可以这样应用它：
var Rocker = require('./rocker.js');
var r = new Rocker('Ozzy', 62);
r.about(); // Ozzy is 62 years old

/* 假如模块是一个数组： */
module.exports = ['Lemmy Kilmister', 'Ozzy Osbourne', 'Ronnie James Dio', 'Steven Tyler', 'Mick Jagger'];

//可以这样应用它：
var rocker = require('./rocker.js');
console.log('Rockin in heaven: ' + rocker[2]); //Rockin in heaven: Ronnie James Dio

</pre><pre class="js"></pre>
// math.js
exports.add = (a, b) => a+b;
exports.cut = (a, b) => a-b;

// math2.js
module.exports = {
  division: (a, b) => a/b;
  multipli: (a, b) => a*b;
}

// main.js
var math = require("./math");       // 加载math模块
var math2 = require("./math2");     // 加载math2模块
console.log(math.add(6,3));         // 9
console.log(math.cut(6,3));         // 3
console.log(math2.division(6,3));   // 2
console.log(math2.multipli(6,3));   // 18

</pre><pre>
var a = {name: 1}
var b = a

console.log(a)  // {name: 1}
console.log(b)  // {name: 1}

b.name = 2
console.log(a)  // {name: 2}
console.log(b)  // {name: 2}

var b = {name: 3}
console.log(a)  // {name: 2}
console.log(b)  // {name: 3}

// a是一个对象,b是对a的引用,即a和b指向同一块内存,所以前两个输出一样
// 当对b作修改时即a和b指向同一块内存地址的内容发生了改变,所以a也会体现出来,所以第三四个输出一样
// 当b被覆盖时b指向了一块新的内存,a还是指向原来的内存,所以最后两个输出不一样

</pre><pre>
exports和module.exports的区别：
module.exports初始值为一个空对象 {}
exports是指向的module.exports的引用
require()返回的是module.exports而不是exports

exports = module.exports = {...}
上面的代码等价于:
module.exports = {...}
exports = module.exports
原理很简单：module.exports 指向新的对象时,exports 断开了与 module.exports 的引用,那么通过 exports = module.exports 让 exports 重新指向 module.exports

</pre><pre>
【 利用nodejs模块缓存机制创建"全局变量" 】
nodejs引入模块分四个步骤 路径分析 文件定位 编译执行 加入内存
核心模块部分在node源代码的编译过程中就编译成了二级制文件,在node启动时就直接加载入内存,所以这部分模块引入时,前三步省略,直接加入.
nodejs的模块加载和浏览器js加载一样都有缓存机制,不同的是,浏览器仅仅缓存文件,而nodejs缓存的是编译和执行后的对象(缓存内存)

</pre><pre class="js">
/* 记录长期存在的变量.例如：我可以编写一个记录接口访问数的模块： */
var count = {}; // 因模块是封闭的,这里实际上借用了js闭包的概念
exports.count = function(name){
  count[name] ?  count[name]++:count[name] = 1;
  console.log(name + '被访问了' + count[name] + '次.');
};

/* 在路由里这样引用: */
var count = require('count');
export.index = function(req, res){
    count('index');
};

//以上便完成了对接口调用数的统计,但这只是个demo,因为数据存储在内存,服务器重启后便会清空.真正的计数器一定是要结合持久化存储器的

</pre><pre>
【 nodejs清除require缓存 delete require.cache 】
开发nodejs应用时会面临一个麻烦的事情,就是修改了配置数据之后,必须重启服务器才能看到修改后的结果.
怎么做到修改文件之后,自动重启服务器.

</pre><pre class="js">
/* server.js中的片段：*/
var port = process.env.port || 8888;
app.listen(port);
console.log("server start in " + port);
exports.app = app;

/* app.js的片段：*/
var app = require('./server.js');

/* 如果在server.js中启动了服务器,停止服务器可以在app.js中调用 */
app.app.close()

/*
重新引入server.js app =  require('./server.js')时发现并不是用的最新的server.js文件,原因是require的缓存机制,在第一次调用require('./server.js')的时候缓存下来了,解决:
*/
delete require.cache[require.resolve('./server.js')];
app = require('./server.js');

</pre>
</div>

<!-- -----------------------------global------------------------------ -->
<div id="global">
<h2>全局对象 global</h2><pre class="js">
C:\Users\lenovo>node
> global

</pre><pre>
__dirname   全局变量,存储的是文件所在的文件目录  E:\wamp64\www\study\nodejs\fs
__filename  全局变量,存储的是文件名             E:\wamp64\www\study\nodejs\fs\readdir.js

</pre>

<h3>定时器 事件队列(任务队列)</h3><pre>
【 setTimeout(callback, delay[, ...args]) 超时定时器 】 全局函数
在指定的毫秒(ms)数后执行指定函数(cb),只执行一次指定函数;...args当调用callback时要传入的可选参数
返回一个代表定时器的句柄值,返回一个定时器对象的ID,返回一个用于clearTimeout()的Timeout
callback可能不会精确地在delay毫秒被调用,Node.js不能保证回调被触发的确切时间,也不能保证它们的顺序,回调会在尽可能接近所指定的时间上调用
当delay大于2147483647或小于1时delay会被设为1
如果callback不是一个函数,则抛出TypeError

setTimeout()只是将事件插入了"任务队列",必须等到当前代码(执行栈)执行完,主线程才会去执行它指定的回调函数。要是当前代码耗时很长,有可能要等很久,所以并没有办法保证,回调函数一定会在setTimeout()指定的时间执行

</pre>此方法具有可用util.promisify()提供的promises常用变体<pre class="js">
const util = require('util');
const setTimeoutPromise = util.promisify(setTimeout);

setTimeoutPromise(40, 'foobar').then((value) => {
  // value === 'foobar' (passing values is optional)
  // This is executed after about 40 milliseconds.
});

</pre><pre>
【 clearTimeout( t )  】
全局函数,用于停止一个之前通过setTimeout()创建的定时器,参数t是通过setTimeout()函数创建的定时器
setTimeout是在某个时间间隔后执行一次,如果用递归的话也可以模拟出setInterval的效果

【 setInterval(callback, delay[, ...args]) 时间间隔定时器 】
全局函数,在指定的毫秒(ms)数后执行指定函数(cb)
返回一个代表定时器的句柄值.可以使用clearInterval(t)函数来清除定时器
setInterval()方法会不停地调用函数,直到clearInterval()被调用或窗口被关闭

当delay大于2147483647或小于1时,delay会被设为1
如果callback不是一个函数则抛出TypeError

</pre><pre class="js">
function myfunc(Interval){
    console.log("myfunc "+Interval);
}
var myInterval=setInterval(myfunc,1000,"Interval");
function stopInterval(){
    clearTimeout(myInterval);
}
setTimeout(stopInterval,5000);

</pre><pre class="js">
/* setInterval必须能确保这些函数不会被同时执行,该例函数会被同时执行,而不是按次序串行执行;使用递归 */
setInterval(function(){
    (function my_async_function(){
        setTimeout(function(){
            console.log(Date.now());
        },5000);
   })();
},1000);

</pre><pre>
【 setImmediate(callback[, ...args])  即时定时器 递归中推荐用setImmediate 】
callback  在Node.js事件循环的当前回合结束时要调用的函数。
...args   当调用callback时要传入的可选参数

预定立即执行的callback,它是在I/O事件的回调之后被触发,返回一个用于clearImmediate()的Immediate。

多次调用setImmediate()时callback函数会按照它们被创建的顺序依次执行。每次事件循环迭代都会处理整个回调队列。 如果一个立即定时器是被一个正在执行的回调排入队列的,则该定时器直到下一次事件循环迭代才会被触发。

如果callback不是一个函数则抛出TypeError

setImmediate()是将事件插入到事件队列尾部,主线程和事件队列的函数执行完成之后立即执行setImmediate指定的回调函数,和setTimeout(fn,0)的效果差不多,但是当他们同时在同一个事件循环中时,执行顺序是不定的。另外setTimeout和setImmediate也有一定的区别(还在探索...),在实际工作中我们其实她们的区别貌似不明显

process.nextTick()方法可以在当前"执行栈"的尾部-->下一次Event Loop(主线程读取"任务队列")之前-->触发process指定的回调函数。也就是说,它指定的任务总是发生在所有异步任务之前,当前主线程的末尾。(nextTick虽然也会异步执行,但是不会给其他io事件执行的任何机会)

</pre><pre class="js">
setImmediate(function(){
     console.log("延迟执行");
 });
 console.log("正常执行");

</pre><pre>
process.nextTick()的回调函数执行的优先级要高于setImmediate();
process.nextTick()属于idle观察者,setImmediate()属于check观察者.在每一轮循环检查中,idle观察者先于I/O观察者,I/O观察者先于check观察者.
在具体实现上,process.nextTick()的回调函数保存在一个数组中,
setImmediate()的结果则是保存在链表中.
在行为上,process.nextTick()在每轮循环中会将数组中的回调函数全部执行完.
而setImmediate()在每轮循环中执行链表中的一个回调函数.

</pre><pre class="js">
setImmediate(function(){
    console.log("setImmediate延迟3");
});
process.nextTick(function(){
    console.log("nextTick延迟2")
});
console.log("正常执行1");

// 正常执行1
// nextTick延迟2
// setImmediate延迟3

</pre><pre class="js">
process.nextTick(function(){
    console.log("nextTick延迟执行1");
});
process.nextTick(function(){
    console.log("nextTick延迟执行2");
});
setImmediate(function(){
    console.log("setImmediate延迟执行1");
    process.nextTick(function(){
        console.log("强势插入");
    });
});
setImmediate(function(){
    console.log("setImmediate延迟执行2");
});
console.log("正常执行");

// 正常执行
// nextTick延迟执行1
// nextTick延迟执行2
// setImmediate延迟执行1
// setImmediate延迟执行2
// 强势插入

</pre><pre class="js">
/* process.nextTick优先级高于setImmediate */

process.nextTick(() => { console.log('nextTick') })
Promise.resolve() .then(() => { console.log('then') })
setImmediate(() => { console.log('setImmediate') })
console.log('end')

// end  // nextTick  // then  // setImmediate

</pre>此方法具有可用util.promisify()提供的promises常用变体：<pre class="js">
const util = require('util');
const setImmediatePromise = util.promisify(setImmediate);

setImmediatePromise('foobar').then((value) => {
  // value === 'foobar' (passing values is optional)
  // This is executed after all I/O callbacks.
});

// or with async function
async function timerExample() {
  console.log('Before I/O callbacks');
  await setImmediatePromise();
  console.log('After I/O callbacks');
}
timerExample()

</pre>

<h3>console 用于提供控制台标准输出</h3><pre>
console 对象的方法:
1 console.log([data][, ...])   向标准输出流打印字符并以换行符结束.该方法接收若干 个参数,如果只有一个参数则输出这个参数的字符串形式.如果有多个参数则以类似于C语言printf()命令的格式输出
2 console.info([data][, ...])  该命令的作用是返回信息性消息,似console.log差别并不大
3 console.error([data][, ...]) 输出错误消息的.控制台在出现错误时会显示是红色的叉子.
4 console.warn([data][, ...])  输出警告消息.控制台出现有黄色的惊叹号.
5 console.dir(obj[, options])  用来对一个对象进行检查(inspect),并以易于阅读和打印的格式显示.
6 console.time(label)          输出时间,表示计时开始.
7 console.timeEnd(label)       结束时间,表示计时结束.
8 console.trace(message[, ...])当前执行的代码在堆栈中的调用路径
9 console.assert(value[, message][, ...])  用于判断某个表达式或变量是否为真,接收两个参数表达式和字符串.当第一参数为false,才会输出第二个参数,否则不会有任何结果

console.dir(obj, {colors: true}) 可以使用预先设置好的配色方案打印日志,更易于阅读

console.log('Hello world');         //Hello world
console.log('byvoid%diovyb');       //byvoid%diovyb
console.log('byvoid%diovyb', 1991); //byvoid1991iovyb

【 nodejs控制台彩色文字输出 】
console.log('\x1b[91m','message')          // 红色,\x1b[91m是一个ANSI escape code,这个码分为3/4 bit、8-bit、24-bit
console.log('\x1b[32m', 'msg', '\x1b[97m') // 输出绿色msg之后恢复亮白色输出

改变Shell文字样式,本质上就是用ANSI Escape Code来改变终端模拟器的行为,可以做到很多事,比如改变文字颜色,文字闪烁,改变鼠标位置,清屏等等。比如执行 echo -e '\e[2J' 来清屏,或echo -e '\e[2J\e[u' 清屏并重置鼠标位置(跟 ctrl-l 同样效果)

颜色  前景色 背景色
黑      30  40
红      31  41
绿      32  42
黄      33  43
蓝      34  44
品红    35  45
青      36  46
白      37  47
亮黑(灰) 90 100
亮红     91 101
亮绿     92 102
亮黄     93 103
亮蓝     94 104
亮品红   95 105
亮青     96 106
亮白     97 107

</pre><pre class="js">
console.log('\x1B[36m%s\x1B[0m', info);   // cyan
console.log('\x1B[33m%s\x1b[0m:', path);  // yellow
var styles = {
  'bold'          : ['\x1B[1m',  '\x1B[22m'],
  'italic'        : ['\x1B[3m',  '\x1B[23m'],
  'underline'     : ['\x1B[4m',  '\x1B[24m'],
  'inverse'       : ['\x1B[7m',  '\x1B[27m'],
  'strikethrough' : ['\x1B[9m',  '\x1B[29m'],
  'white'         : ['\x1B[37m', '\x1B[39m'],  // 灰白
  'grey'          : ['\x1B[90m', '\x1B[39m'],
  'black'         : ['\x1B[30m', '\x1B[39m'],
  'blue'          : ['\x1B[34m', '\x1B[39m'],
  'cyan'          : ['\x1B[36m', '\x1B[39m'],
  'green'         : ['\x1B[32m', '\x1B[39m'],  // console.log('\x1B[32m', info);
  'magenta'       : ['\x1B[35m', '\x1B[39m'],
  'red'           : ['\x1B[31m', '\x1B[39m'],
  'yellow'        : ['\x1B[33m', '\x1B[39m'],
  'whiteBG'       : ['\x1B[47m', '\x1B[49m'],  // 白色背景
  'greyBG'        : ['\x1B[49;5;8m', '\x1B[49m'],
  'blackBG'       : ['\x1B[40m', '\x1B[49m'],
  'blueBG'        : ['\x1B[44m', '\x1B[49m'],
  'cyanBG'        : ['\x1B[46m', '\x1B[49m'],
  'greenBG'       : ['\x1B[42m', '\x1B[49m'],
  'magentaBG'     : ['\x1B[45m', '\x1B[49m'],
  'redBG'         : ['\x1B[41m', '\x1B[49m'],
  'yellowBG'      : ['\x1B[43m', '\x1B[49m']
};

</pre><pre class="js">
C:\Users\lenovo>node
> console

</pre>
</div>

<div id="process">
<h3>process进程</h3><pre>
在node.js中通过两个模块可以控制主进程和创建子进程等操作,process和child_process
process对象是EventEmitter的实例,对于Node.js应用程序始终是可用的,无需使用require()

process是一个全局变量,即global对象的属性
它用于描述当前Node.js进程状态的对象,提供了一个与操作系统的简单接口,控制当前Node.js进程

Process进程是计算机中已运行程序的实体

node.js是单进程的,js代码在这个单进程里运行,和浏览器模式一样
但是I/O输入输出基本是异步的,也可以说是多进程的
如读取磁盘文件就是一个单独的进程负责,读取过程不会影响js的进程;当读到数据后node.js内部会激发一个事件,把数据传输给js程序

</pre><pre class="js">
var fs = require("fs");
fs.readFile("1.pdf", (err,file) => {
    console.log("second")
});
console.log("first");

</pre><pre class="js">
C:\Users\lenovo>node
>process

C:\Users\lenovo>node
> child_process

</pre><pre>
【 设置环境变量 】
环境变量是操作系统运行环境的一些参数,在开发环境或部署环境中都需要使用到。
使用命令行临时对环境变量的查看、添加、修改和删除和修改系统文件来永久设置环境变量的方法。

Windows设置环境变量

临时(cmd)
查看环境变量,添加环境变量,删除环境变量

#node中常用的到的环境变量是NODE_ENV,首先查看是否存在
set NODE_ENV
#如果不存在则添加环境变量
set NODE_ENV=production
#环境变量追加值
set 变量名=%变量名%;变量内容
set path=%path%;C:\web;C:\Tools
#某些时候需要删除环境变量
set NODE_ENV=

临时(powershell)
查看环境变量,添加环境变量,删除环境变量

#node中常用的到的环境变量是NODE_ENV,首先查看是否存在
$env:NODE_ENV
#如果不存在则添加环境变量
$env:NODE_ENV="production"
#环境变量追加值
$env:path=$env:path + ";C:\web;C:\Tools"
#某些时候需要删除环境变量
del env:NODE_ENV
#某些时候需要显示所有的环境变量
ls env:

永久
右键(此电脑) -> 属性(R) -> 高级系统设置 -> 环境变量(N)...

【 创建主进程 】
创建进程有很多方式方法,运行一个node.js程序时就已创建了一个进程了,也就是主进程。主进程通过global.process或process直接访问到

【 创建子进程的几种方法 】
有时候可能需要在主进程中,运行其他node.js程序,也就是启动一个子进程,子进程的创建和操作依靠child_process模块

</pre><pre class="js">
// main.js
var cdr = require("child_process");
cdr.fork(__dirname+"/child.js");

// child.js 子程序
console.log("子进程");

</pre><pre>
child_process.exec(command[, options][, callback])
command  要运行的命令,用空格分隔参数。例如 ls -a, ls -lah命令获取当前目录下所有的文件
options  用于自定义如何衍生进程
    cwd        子进程的当前工作目录,默认null
    env        环境变量键值对,默认null
    encoding   默认为 'utf8'
    shell      用于执行命令的shell;UNIX默认'/bin/sh',Windows默认process.env.ComSpec
    timeout    默认为 0
    maxBuffer  stdout或stderr允许的最大字节数,默认为200*1024;如果超过限制则子进程会被终止
    killSignal 默认为 'SIGTERM'
    uid        设置该进程的用户标识
    gid        设置该进程的组标识
    windowsHide Default:   false
callback 当进程终止时调用,并带上输出。
    error  Error>
    stdout string | Buffer
    stderr string | Buffer
返回: ChildProcess子进程对象

创建node.js程序子进程,也可通过 child_process.exec 执行系统程序,比如windows的exe程序等

衍生一个shell,然后在shell中执行command,且缓冲任何产生的输出
传入exec函数的command字符串会被shell直接处理,特殊字符(因 shell 而异)需要相应处理：
exec('"/path/to/test file/test.sh" arg1 arg2'); // 使用双引号这样路径中的空格就不会被解释为多个参数
exec('echo "The \\$HOME variable is $HOME"');   // 第一个 $HOME 被转义了,但第二个没有

如果提供了一个callback函数,则它被调用时会带上参数(error, stdout, stderr)。
当成功时error会是null, 当失败时error会是一个Error实例。
error.code属性会是子进程的退出码,error.signal会被设为终止进程的信号。除0以外任何退出码都被认为是一个错误

传给回调的stdout和stderr参数会包含子进程的stdout和stderr的输出。
默认情况下Node.js会解码输出为UTF-8,并将字符串传给回调。
encoding选项可用于指定用于解码stdout和stderr输出的字符编码。
如果encoding是'buffer'、或一个无法识别的字符编码,则传入 Buffer 对象到回调函数

如果timeout大于0,当子进程运行超过timeout毫秒时,父进程就会发送由killSignal属性标识的信号(默认为 'SIGTERM')

</pre><pre class="js">
//运行该程序会通过默认浏览器打开baidu
var cdr = require("child_process");
cdr.exec("start https://www.baidu.com")

// 实例
var exec = require("child_process").exec;
exec("start www.baidu.com");                     // 默认浏览器打开网站

// 实例
var exec = require("child_process").exec;
var child = exec("dir", (err,stdout,stderr) => {
    console.log(stdout);
});

</pre>不要把未经检查的用户输入传入到该函数,任何包括shell元字符的输入都可被用于触发任何命令的执行<pre class="js">
const { exec } = require('child_process');
exec('cat *.js bad_file | wc -l', (error, stdout, stderr) => {
  if (error) {
    console.error(`exec error: ${error}`);
    return;
  }
  console.log(`stdout: ${stdout}`);
  console.log(`stderr: ${stderr}`);
});

</pre><pre>
【 杀死主进程 】
通过process.exit(0)可以杀死主进程,process.abort()也可以。

【 杀死子进程 】
通过child_process.kill或child_process.disconnect()方法销毁子程序

</pre><pre class="js">
var cdr = require("child_process");
var cp = cdr.fork(__dirname+"/child");
setTimeout(function(){
    cp.kill();    // cp.disconnect()
},3000);

</pre><pre>
【 主进程与子进程之间通信交互交流 】
子进程和主进程必须都是node.js程序,也就是通过child_process.fork方法创建的子进程才能进行有效的通信

</pre><pre class="js">
// 主进程代码 main.js
var cdr = require("child_process");
var cp = cdr.fork(__dirname+"/child.js");
cp.on("message", msg => {
    console.log(msg);
    cp.send("main: HI!");
})

// 子进程代码 child.js
console.log("子进程");
process.on("message", msg => console.log(msg));
setInterval(() => process.send("child: hello"),2000);

</pre><pre>
主进程和子程序都通过监听message得到主进程发送来的数据,并通过process.send(data)方法发送数据。

child.on("message",function(message,senHandle){})
message事件的监听器

child.send(message, [sendHandle])
发送数据信息到另一个进程
message     JSON对象,不能发送Function或者是本地对象
sendHandle  数据,可以是TCP服务器或Socket对象

两个进程之间来回发送数据和接收数据,接收的数据可以是JSON对象或net.Server的对或net.Socket对象

</pre><pre class="js">
// 发送一个http.Server对象

// main.js 主进程程序
var cdr = require("child_process");
var http = require("http");
var server = http.createServer();
var cp = cdr.fork(__dirname+"/child");
server.listen(8888, () => {
    cp.send('server', server);
})

// child.js 子进程接收一个server对象
var Server = require("net").Server;
process.on("message", (msg, server) => {
    console.log(server instanceof Server); // true
})

</pre><pre>
process 表示自身进程。相对于当前进程,fork出来的都是子进程
所有process都不认为自己是子进程,而只有别的进程通过fork它时,fork它的这个所谓主进程会当作它是子进程。

process.on("message") 接收到"主进程"发来的信息。
cp.on("message")      接受"子进程"发来的信息。

每次fork都会创建一个新的子进程,当主进程调用cp.send 时,并不是所有子进程都能接收到,只有当前fork出来的能接收到
js文件是死的,fork后才生成一个进程,多次fork会生成多个子进程,而相互之间毫无关系

只要是采用node xxx.js运行的程序都有一个process,包括用child_process.fork方法启动的程序

</pre><pre>
【 process对象提供一系列属性,用于返回系统信息 】
process.pid       当前进程的进程号
process.version   Node的版本,比如v0.10.18
process.versions  Node的版本和它依赖库的版本,比如可以得到openssl和v8的版本信息
process.platform  当前系统平台,比如Linux,比如windows7 得到的结果是 win32
process.arch      得到系统架构名称,比如windows7 得到的结果是 ia32 (如：X64)
process.uptime()  node进程运行的秒数
process.title     终端名称,默认值为"node",可读写,可以自定义该值
process.argv      当前进程的命令行参数数组,数组里存放着启动这个node.js进程各个参数和命令代码
process.env       指向当前shell的环境变量,比如process.env.HOME
process.execPath  运行当前进程的可执行文件的绝对路径.当前node.js进程的启动命令路径node.exe
process.stdout    指向标准输出,命令行显示内容,控制台输出流,process.stdout.write('string')等同于console.log
process.stdin     指向标准输入
process.stderr    指向标准错误
process.memoryUsage()  进程的内存使用情况

process.getgid()    获取和设置进程的groupid和userid
process.setgid(id)
process.getuid()
process.setuid(id)

</pre><pre class="js">
// argv.js
process.argv.forEach((val, index, array) => console.log(index + ': ' + val))

// 运行node argv.js one two=three four
/*
0: E:\软件E\node\node.exe
1: E:\wamp64\www\study\nodejs\process\argv.js
2: one
3: two=three
4: four
*/

</pre><pre class="js">
process.stdin.resume();
process.stdin.setEncoding('utf8');
process.stdin.on('data', function (chunk) {
    process.stdout.write('data: ' + chunk);
});
process.stdin.on('end', function () {
    process.stdout.write('end');
});

</pre><pre>
【 process对象提供以下方法： 】
process.exit()              退出当前进程.process.exit(code=0)
process.cwd()               返回运行当前脚本的工作目录的路径
process.chdir('/home/bbb')  改变工作目录.
process._kill(pid,sig)      用于给指定pid的进程发送指定信号(类似linux下的kill命令)
var pid=process.pid;
process._kill(pid,9);

process.nextTick(callback)  异步延迟执行callback函数
比setTimeout(fn, 0)高效很多,耗时的操作可用在process.nextTick(callback)中,这样可以不阻塞整个函数执行
比如密集递归运输或大型运输,可以通过这个方法让其他代码程序有运行的机会,因为NODE.JS是单进程的,所以密集运算需要这个方法

</pre><pre class="js">
process.nextTick(function(){
    console.log("延迟执行");
});
console.log("正常执行1");
console.log("正常执行2");

// 实例
function foo() {
   // 运算......
   process.nextTick(foo);
}
foo();

// 这样形成了无限深度的tick,通过process.maxTickDepth 可以设定最大tick深度,默认是1000
process.nextTick(function foo() {
    process.nextTick(foo);
});

</pre><pre>
process.hrtime() 精准测试运行间隔

第一次运行var time1 = process.hrtime(),time1是个参考时间,格式是[秒,纳秒]
然后在另外一行代码调用var time2 = process.hrtime(time1) , time2 就是从参考时间time1到运行这段代码的时间间隔,time2的格式还是[秒,纳秒]格式,也就是时间间隔是多少秒+多少纳秒。

一纳秒是十亿分之一秒

</pre><pre class="js">
// 耗时 1128770500 纳秒, 每台电脑不同
var time = process.hrtime();
setTimeout(function() {
    var diff = process.hrtime(time);
    console.log('耗时 %d 纳秒', diff[0] * 1e9 + diff[1]);
}, 1000);

</pre><pre>
【 事件 】
beforeExit
当node清空事件循环,并且没有其他安排时触发这个事件.通常来说,当没有进程安排时node退出,但是'beforeExit'的监听器可以异步调用,这样node就会继续执行.

uncaughtException
当一个异常冒泡回到事件循环,触发这个事件.若给异常添加了监视器,默认的操作(打印堆栈跟踪信息并退出)就不会发生
预防服务器崩溃：process.on(uncaughtException, console.error);

Signal事件
当进程接收到信号时就触发.信号列表详见标准的POSIX信号名,如SIGINT、SIGUSR1等

(1)exit事件
当process退出时触发,即按"ctrl+c"时触发
当前进程退出时,会触发exit事件,可以对该事件指定回调函数.这一个用来定时检查模块的状态的好钩子(hook)(例如单元测试),当主事件循环在执行完'exit'的回调函数后将不再执行,所以在exit事件中定义的定时器可能不会被加入事件列表

</pre><pre class="js">
process.on('exit', function () {
  fs.writeFileSync('/tmp/myfile', 'This MUST be saved on exit.');
});

</pre>
(2)uncaughtException事件,当前进程抛出一个没有被捕捉的意外时,会触发uncaughtException事件<pre class="js">
 process.on('uncaughtException', function (err) {
   console.error('An uncaught error occurred!');
   console.error(err.stack);
 });

</pre><pre class="js">
process.stdin.resume();               //这句话是为了不让控制台推出
process.on('SIGINT', function () {    //SIGINT这个信号是系统默认信号,代表信号中断,就是ctrl+c
  console.log('Got SIGINT.  Press Control-D to exit.');
});

</pre><pre class="js">
process.on('SIGUSR1', function (d) { //这里监听 SIGUSR1 事件
     console.log('Bye-'+d);          //这里将输出Bye-Bye,然后推出进程
     process.exit(0);
   });
 process.emit('SIGUSR1', 'Bye');     //利用emit触发SIGUSR1,然后传参数为Bye


</pre>

<h4>process.stdin process.stdout与程序交互</h4><pre>
标准输入输出
process.stderr和process.stdout是输出流,是一个stream.Writable对象
process.stdin是输入流,是一个stream.Readable对象

</pre><pre class="js">
console.log = function (d) {
    process.stdout.write(d + '\n');
};

</pre><pre class="js">
// 监听终端输入的信息,然后通过输出流打印出去
process.stdin.on("data",function(data){
   process.stdout.write(data + "\n");
})

</pre><pre class="js">
/* 获取目录下的文件信息,并支持命令行输入索引来查看文件信息 */
var fs = require('fs');
var stdin = process.stdin,
    stdout = process.stdout;

// 异步调用获取当前工作目录下的列表
fs.readdir(__dirname, function(err, files){
    var stats = [];
    if(!files.length) return console.log('不存在任何文件列表!');
    function file(i){
        var filename = files[i];
        fs.stat(__dirname + '/' + filename, function(err, stat){
            // 保存文件属性对象
            stats[i] = stat;
            if(err) return console.log('file read error!');
            stat.isDirectory() ? console.log(`${i}、目录: ${filename}`):console.log(`${i}、文件: ${filename}`);
            i++;
            i === files.length ? done():file(i);
        });
    }
    file(0);

    // 列出文件列表之后,提示输入想查看的内容
    function done(){
        stdout.write('\n输入你选择的列表序号: ');
        stdin.resume();
        stdin.setEncoding('utf8');
        stdin.on('data', function(data){
            if(!files[+data]){
                stdout.write('输入你选择的列表序号: ');
            }else{
                stdin.pause();
                // 开始读取选择的文件夹或者文件
                var filename = files[+data];
                if(stats[+data].isDirectory()){
                    // 开始读取文件夹里的内容
                    fs.readdir(__dirname + '/' + filename, function(err, files){
                        if(!err){
                            console.log('\n');
                            console.log('(' + files.length  + '个文件' + ')');
                            files.forEach(function(v){
                                console.log('      -' + v);
                            })
                            console.log('\n');
                        }
                    });
                }else{
                    // 开始读取文件
                    fs.readFile(__dirname + '/' + filename, 'utf8',  function(err, data){
                        console.log('\n');
                        console.log(data.replace(/(.*)g/, '    $1'));
                    });
                }
            }
        });
    }
});

</pre>
</div>

<div id="callback">
<h2>异步回调 promise</h2><pre>
异步即设置一个任务后立即返回,然后加上一个监听,任务结束时就去调用监听

同步方法和异步方法的区别：在使用同步方法执行的操作结束之前,不能执行后续代码的执行;而异步方法将操作结果作为回调函数的参数进行返回,方法调用之后就可以立即执行后续的代码,读取完毕后会调用对应的回调函数

Node.js异步编程依托于回调来实现,但不能说使用了回调后程序就异步化了
回调函数在完成任务后就会被调用,Node所有API都支持回调函数,大大提高了Node.js的性能,可以处理大量的并发请求

在Node应用程序中执行异步操作的函数将回调函数作为最后一个参数,回调函数接收错误对象作为第一个参数

Node.js中回调函数的规范是：function callback(err,args0,args1 … ){}

</pre>回调函数<pre class="js">
function learn(sth){
  console.log(sth);
}
function we(sth, callback){
  sth += 'is cool';
  typeof callback === 'function' && callback(sth);
}
we('nodejs', learn);               // 命名回调

we('express', function(some){      // 匿名回调
  console.log(some);
});

</pre>异步<pre class="js">
//同步
var a = 0;
function printit(){
  console.log(a);
}
function plus(){
  a++;
}

plus();
printit();

//异步
var a = 0;
function printit(){
  console.log(a);
}
function plus(){
  setTimeout(function(){ a++; }, 1000);
}
plus();
printit();

//异步回调
var a = 0;
function printit(){
  console.log(a);
}
function plus(callback){
  setTimeout(function(){
    a++;
    callback();
  }, 1000);
}
plus(printit);

var func1 = function(callback){
  setTimeout(function(){
    console.log('foo');
    typeof(callback) === 'function' || callback();   // callback是函数作为回调函数调用
  }, 499);
};

</pre><pre>
【 非阻塞基于事件驱动的异步回调 】
阻塞按是按顺序执行的,而非阻塞是不需要按顺序的

</pre><pre class="js">
//阻塞代码实例
var fs = require("fs");
var data = fs.readFileSync('input.txt');
console.log(data.toString());
console.log("程序执行结束!");

//非阻塞代码实例
var fs = require("fs");
fs.readFile('input.txt', function (err, data) {
  if (err) return console.error(err);
  console.log(data.toString());
});
console.log("程序执行结束!");

</pre><pre class="js">
/* 模拟一个异步函数,和回调函数 */
function sumAsync(a, b, callback){
  setTimeout(function(){
    if(typeof a === "number" && typeof b === "number"){
      callback(null, a+b);
    }else{
      callback(new Error("must number"));
    }
  },200)
}
sumAsync(2,3,function callback(err,rs){
  console.log(rs);
})
console.log("first run !");

</pre><pre class="js">
//查询语句并不是立即执行,而是放入待执行的队列中就立即返回,然后继续执行后面的语句;当数据库操作结束之后,会触发某个事件,告诉nodejs数据库操作已经完成,于是nodejs就执行原先设定的回调函数,对数据库的执行结果进行处理

var send_data = function(req, res){
  sql = 'SELECT gid,name,image_url,price,create_time,describes FROM goods WHERE status=? LIMIT ?,?';
  connection.query(sql, [0,0,6], function(err, rows, fields) {
      if (err) throw err;
      console.log("输出：在这里处理数据库操作的结果");
  });
  console.log("输出：这是数据库操作后的语句");
};

</pre>

<h4 style="color:red">异步循环采用arr.forEach(function(item,index){}),不要使用闭包和let</h4><pre class="js">
//1 2 3 4
var arr = [1,2,3,4];
arr.forEach(function(item, index){
  setTimeout(function(){
    console.log(item);
  },1000)
})

//undefined undefined undefined undefined
var arr = [1,2,3,4];
for (var i = 0; i < arr.length; i++) {
  setTimeout(function(){
    console.log(i, arr[i]);
  },1000)
}

</pre><pre class="js">
const fs = require('fs');
const path = require('path');

fs.readdir(__dirname + '/testdir/', function (err, files) {
  if(err)  return console.error(err);
  console.log(files);
  files.forEach(function (file) {
    var filePath = path.normalize(__dirname + '/testdir/' + file);
    fs.stat(filePath, function (err, stat) {
      if(stat.isFile())       console.log(filePath, stats.size);
      if(stat.isDirectory())  console.log(filePath + ' is dir');
    });
  });
});

</pre><pre class="js">
/* fs.readFile的回调函数中访问到的i值都是循环结束后的值 */
var fs = require('fs');
var files = ['a.txt','b.txt','c.txt'];

for(var i=0; i < files.length; i++) {
  fs.readFile(files[i], 'utf-8', function(err, contents) {
    console.log(files[i] + ': ' + contents);
  });
}

//undefined: AAA  //undefined: BBB  //undefined: CCC

/* 利用js函数编程的特性,建立一个闭包来保存每次需要的i值 */
//由于运行时闭包的存在,该匿名函数中定义的变量(包括参数表)在它内部的函数(fs.readFile 的回调函数)执行完毕之前都不会释放,因此在其中访问到的i就分别是不同的闭包实例,这个实例是在循环体执行的过程中创建的,保留了不同的值

var fs = require('fs');
var files = ['a.txt','b.txt','c.txt'];

for(var i=0; i < files.length; i++) {
  (function(i) {
    fs.readFile(files[i], 'utf-8', function(err, contents) {
      console.log(files[i] + ': ' + contents);
    });
  })(i);
}

// 更简单的方法
var fs = require('fs');
var files = ['a.txt', 'b.txt', 'c.txt'];
files.forEach(filename => {
  fs.readFile(filename, 'utf-8', function(err, contents) {
    console.log(filename + ': ' + contents);
  });
});

</pre>

<h2>promise 断点续传</h2><pre>
promise是用来取代回调函数来进行异步操作的另一种方案

promise库：
bluebird   npm i bluebird
es6
Q库        npm i q

Promise的几种状态：
pending：初始状态,即等待操作的执行
fulfilled：成功的操作
rejected：失败的操作

pending的状态既可以转为fulfilled,也可以转为rejected,当状态发生改变时promise.then(onFulfilled, onRejected)方法将被调用

构造函数的参数Function中带有两个函数对象resolve和reject,二者都是返回一个Promise对象
resolve用在处理执行成功的场景,Promise从pending转为fulfilled状态时调用
reject用在处理执行失败的场景,Promise从pending转为rejected状态时调用

</pre><pre class="js">
var promise = new Promise(function(resolve, reject){
  //do something
  if(success){
    resolve(value);
  } else {
    reject(value);
  }
});

promise.then(function(value){
  //成功时调用
}, function(value){
  //失败时调用
});

</pre><pre class="js">
var promise = new Promise((resolve,reject)=>{
  var data = [1,2,3]
  if(data.length > 3)
    resolve(data)
  else
    reject(new Error("array length invalid"))
})
promise.then(res => {
  console.log(res)
}, err => {
  console.error(err)
})

promise.then(null, err => console.error(err))

promise.then(res => console.log(res)).catch(err => console.log(err))

Promise.resolve("resolve").then(res => console.log(res))
Promise.reject("error").catch(err => console.error(err))

</pre><pre class="js">
/* 封装异步的函数 */

1.定义函数
function sendRequest(){
  return new Promise(function(resolve, reject){
    var req = http.request(options, function(res){
      var data = '';
      res.on('data', function(chunk){
        data += chunk;
      });
      res.on('end', function(){
        resolve(data);          //成功后调用
      });
    });
    req.on('error', function(err){
      reject(err);                 //失败后调用
    });
    req.end();
  });
}

2.调用函数
sendRequest().then(function(data){
  console.log(data);
}).catch(function(err){
  console.log(err);
});

</pre>

<h4>【 Array.reduce() 解决Promise的循环串行问题,同步循环异步操作 】</h4><pre>
arr.reduce(callback[, initialValue])
接收一个函数作为累加器,数组中的每个值(从左到右)开始缩减,最终计算为一个值
initialValue初始值也可为object类型,可以是一个Promise对象,reduce函数的返回结果类型和传入的初始值相同

</pre><pre class="js">
Array.from(Array(100)).reduce(function(promise, value) {
  return promise.then(function(){
    return Promise.resolve()
  })
},Promise.resolve('init'));

</pre><pre class="js">
/* 采用回调的方式编写: 遍历当前文件夹下的文件,并输出 */

// 文件读取失败时是停止读取下一个文件,同时会报错

//async_callback.js
var fs = require("fs");
fs.readdir(".",function(err,files){
  if(err) return console.log(err);
    fs.readFile(files[0],function(err,data){
      console.log(files[0], data.length);
      fs.readFile(files[1],function(err,data){
        console.log(files[1], data.length);
        fs.readFile(files[2],function(err,data){
            console.log(files[2], data.length);
            fs.readFile(files[6],function(err,data){
              console.log(files[6], data.length);
              fs.readFile(files[4],function(err,data){
                console.log(files[4], data.length);
                fs.readFile(files[5],function(err,data){
                  console.log(files[5], data.length);
                  fs.readFile(files[3],function(err,data){
                    console.log(files[3], data.length);
                })
              })
            })
          })
        })
      })
    })
})

/* 函数封装 async_callback_dev.js */
var fs = require("fs");
var basepath = '.';

function readfile(filename, cb){
  fs.stat(`${basepath}/${filename}`, function(err, stats){
    if(err) return console.log(err);
    if(stats.isFile()){
      fs.readFile(filename, function(err, data){
        if(err) return console.log(err);
        console.log(filename, data.length);
        cb && cb();
      })
    }
  })
}

fs.readdir(basepath, function(err, files){
  if(err) return console.log(err);
  readfile(files[0], function(){
    readfile(files[1], function(){
      readfile(files[2], function(){
        readfile(files[7], function(){
          readfile(files[4], function(){
            readfile(files[5], function(){
              readfile(files[6], function(){
                readfile(files[3], function(){

                });
              });
            });
          });
        });
      });
    });
  });
})

/* promise处理 async_callback_promise.js */
var fs = require("fs");
var basepath = '.';

function promiseReadFile(filename){
  return new Promise(function(resolve, reject){
    fs.stat(`${basepath}/${filename}`, function(err, stats){
      if(err) return reject(err);
      if(stats.isFile()){
        fs.readFile(filename, function(err, data){
          if(err) reject(new Error(`错误: ${filename}`));
          console.log(filename, data.length);
          resolve();
        })
      }
    })
  })
}

fs.readdir(basepath, function(err, files){
  if(err) return console.log(err);
  promiseReadFile(files[0])
    .then(() => promiseReadFile(files[1]))
    .then(() => promiseReadFile(files[2]))
    .then(() => promiseReadFile(files[3]))
    .then(() => promiseReadFile(files[8]))
    .then(() => promiseReadFile(files[5]))
    .then(() => promiseReadFile(files[6]))
    .then(() => promiseReadFile(files[7]))
    .catch((err) => {console.log(err.message)})
})

/* arr.reduce解决promise串行异步循环 */
/* 场景：按照章节顺序下载合并 */

var fs = require("fs");
var basepath = './testdir/';

function promiseReadFile(filename){
  return new Promise(function(resolve, reject){
    fs.stat(`${basepath}${filename}`, function(err, stats){
      if(err) return reject(err);
      if(stats.isFile()){
        fs.readFile(`${basepath}${filename}`, function(err, data){
          if(err) reject(new Error(`错误: ${filename}`));
          fs.appendFile('promise_loop.txt', data.toString() + '\n\n\n', function () {
            console.log(filename, data.length);
            resolve(filename);
          });
        })
      }
    })
  })
}

fs.readdir(basepath, function(err, files){
  if(err) return console.log(err);
  files.reduce((chain, val) => {
    console.log(chain, val);
    return chain.then(() => promiseReadFile(val));
  }, Promise.resolve())
  .then(() => console.log('done'))
  .catch((err) => console.log(err))
})

/* 递归执行异步循环 */
var fs = require("fs");
var basepath = './testdir/';

function digui(files, index){
  fs.stat(`${basepath}${files[index]}`, function(err, stats){
    if(err) return console.log(err);
    if(stats.isFile()){
      fs.readFile(`${basepath}${files[index]}`, function(err, data){
        if(err) return console.log(new Error(`错误: ${files[index]}`));
        fs.appendFile('promise_loop.txt', data.toString() + '\n\n\n', function (err) {
          if (err) throw err;
          console.log(files[index], data.length);
          var next = index + 1;
          if(next < files.length) digui(files, next)
        });
      })
    }
  })
}
fs.readdir(basepath, function(err, files){
  if(err) return console.log(err);
  digui(files, 0);
})

</pre>

<h4>【 串行、并行、继发、并发、异步循环流程控制 】</h4>
<p><a href="nodejs/flowControl.js" target="_blank">并行异步代码示例：按照顺序读取文件并输出</a></p><pre>
nodejs的最大特征就是一切都是基于事件的,从而导致一切都是异步的,通过事件回调来处理请求的,从而导致了整个处理过程中不会阻塞nodejs,因此在同一时间内可以处理大量的请求,而这种优越性在请求是IO密集型的情况下表现的尤为突出

计数器：for循环调用了异步程序,记下循环的次数,每当异步程序结束时计数减一,当等于零循环结束的时候执行后面的程序

jQuery.when() 使用了计数器来监控并发异步任务的结束时刻

对于串行异步循环任务,可以使用队列或promise的高级实现版本

</pre>
</div>

<div id="buffer">
<h2>buffer 保存为整数 处理原始二进制数据 tcp/图像/文件/网络 c++</h2><pre>
Buffer(缓冲区)临时存贮区是暂时存放输入输出数据的一段内存

Js适合处理Unicode编码数据,但对二进制数据的处理并不友好;Js自身只有字符串数据类型,没有二进制数据类型,但在处理像TCP流或文件流时,对八位字节流的处理很有必要,必须使用到二进制数据

Node.js中定义了一个Buffer类用来创建一个专门存放二进制数据的缓存区,Buffer类是随Node内核一起发布的核心库,可以让Node.js处理二进制数据,每当需要在Node.js中处理I/O操作中移动的数据时就有可能使用Buffer库
原始数据存放在一个Buffer实例中,一个Buffer类似一个整数数组,但它对应于V8堆内存之外的一块原始内存

Buffer类是全局对象、全局变量类型,所以访问它不必使用require('buffer')
一个Buffer的大小是不能更改的,一旦创建了Buffer实例则无法改变大小

buffer著名的8KB载体,node把一幢大房子分成很多小房间,每个房间能容纳8个人,为了保证房间的充分使用,只有当一个房间塞满8个人后才会去开新的房间,但是当一次性有多个人来入住,node会保证要把这些人放到一个房间中,比如当前房间A有4个人住,但是一下子来了5个人,所以node不得不新开一间房间B,把这5个人安顿下来,此时又来了4个人,发现5个人的B房间也容纳不下了,只能再开一间房间C了,这样所有人都安顿下来了,但是之前的两间房A和B都各自浪费了4个和3个位置,而房间C就成为了当前的房间

当实例化一个新的Buffer类,会根据实例化时的大小去申请内存空间,如果需要的空间小于8KB则会多一次判定,判定当前的8KB载体剩余容量是否够新的buffer实例,如果够用则将新的buffer实例保存在当前的8KB载体中,并且更新剩余的空间

Buffers和js字符串对象之间转换时需要一个明确的编码方法,下面是字符串的不同编码
'ascii'     7位的ASCII数据,这种编码方式非常快,它会移除最高位内容
'utf8'      多字节编码Unicode字符,大部分网页和文档使用这类编码方式
'utf16le'   2个或4个字节,Little Endian(LE)编码Unicode字符,编码范围(U+10000到U+10FFFF)
'ucs2'      'utf16le'的子集
'base64'    Base64字符编码
'binary'    仅使用每个字符的头8位将原始的二进制信息进行编码,以后将会弃用
'hex'       每个字节都采用2进制编码

binary是二进制字节流,编码对字节是透明的,不是编码格式。
编码是指某种东西变成二进制,编码格式是指这个东西变成二进制的算法,解码是通过编码格式逆向运算,从二进制恢复
对于二进制文件,把buffer转为string,再将string转为buffer会出错;buffer.toString('binary');之后再new Buffer(str, 'binary');但是binary将会弃用,所以必须直接对buffer进行过滤操作,如'\r\n'对应ascii为13和10

typeof buffer === 'object'

buffer的释放:无法手动对buffer实例进行GC,只能依靠V8来进行,唯一能做的就是解除对buffer实例的引用

</pre><pre class="js">
var buf = new Buffer('012abc好')
console.log('012abc好'.length);             // 7
console.log(buf, buf.length);               // < Buffer 30 31 32 61 62 63 e5 a5 bd> 9
var buf = new Buffer('012abc好', 'utf8')
console.log(buf, buf.length);               // < Buffer 30 31 32 61 62 63 e5 a5 bd> 9
var buf = new Buffer('012abc好', 'base64')
console.log(buf, buf.length);               // < Buffer d3 5d 9a 6d> 4
var buf = new Buffer('012abc好', 'utf16le')
console.log(buf, buf.length);              // < Buffer 30 00 31 00 32 00 61 00 62 00 63 00 7d 59> 14
var buf = new Buffer('012abc好', 'ucs2')
console.log(buf, buf.length);              // < Buffer 30 00 31 00 32 00 61 00 62 00 63 00 7d 59> 14
var buf = new Buffer('012abc好', 'binary')
console.log(buf, buf.length);               // < Buffer 30 31 32 61 62 63 7d> 7
var buf = new Buffer('012abc好', 'hex')      //TypeError: Invalid hex string
console.log(buf, buf.length);

</pre><pre class="js">
C:\Users\lenovo>node
> buffer

</pre>

<h3>Buffer模块常用的方法</h3><pre>
三种初始化方式：number,string,array; 写入buffer缓存的数据大于length的部分不会被写入

new Buffer(size) 分配一个新的size大小单位为8位字节的buffer;size须小于kMaxLength,否则会抛异常RangeError.
new Buffer(buffer)          拷贝参数buffer的数据到Buffer实例
new Buffer(str[, encoding]) 分配一个新的buffer,其中包含着传入的str字符串,encoding编码方式默认为'utf8'
new Buffer(array)           使用一个8位字节array数组分配一个新的buffer

</pre><pre class="js">
// 分配一个2G-1字节的数据
// 单次分配内存超过此值会抛出异常 RangeError: Invalid typed array length
var buf = new Buffer(1024 * 1024 * 1024 - 1);

</pre><pre class="js">
var util = require('util');

var buf1 = new Buffer(10);      // 创建长度为 10 字节的 Buffer 实例
var buf2 = new Buffer([10, 20, 30, 40, 50]);
var buf3 = new Buffer('www.baidu.com', 'utf-8');

console.log('isBuffer:', Buffer.isBuffer(buf1));  // true
console.log('isBuffer:', util.isBuffer(buf1));    // true

console.log(buf1, buf1.toString());
//< Buffer 00 00 00 00 00 00 00 00 12 00> '\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0012\u0000'
console.log(buf2, buf2.toString());
//< Buffer 0a 14 1e 28 32> '\n\u0014\u001e(2'
console.log(buf3, buf3.toString());
//< Buffer 77 77 77 2e 62 61 69 64 75 2e 63 6f 6d> 'www.baidu.com'

var buf4 = Buffer.concat([buf2,buf3]);
console.log(buf4, buf4.toString());
//< Buffer 0a 14 1e 28 32 77 77 77 2e 62 61 69 64 75 2e 63 6f 6d> '\n\u0014\u001e(2www.baidu.com'

/*错误：直接相加*/
var buf5 = buf2 + buf3;
console.log(buf5, buf5.toString());
//(2www.baidu.com
//(2www.baidu.com


/*Buffer初始化,字符串和数组对比*/
var buf = new Buffer("string")
var buffer = new Buffer(['s','t','r','i','n','g']);
console.log(buf);            //< Buffer 73 74 72 69 6e 67>
console.log(buffer);         //< Buffer 00 00 00 00 00 00>

</pre><pre class="js">
var buf = new Buffer(7);
console.log(typeof buf);                // object
console.log(buf, buf.length);           // < Buffer 00 7c f6 8f cf 01 00> 7
buf.write('12345678')                   // 7
var len = buf.write('12345678');
console.log(len);                       // 7
console.log(buf, buf.length);           // < Buffer 31 32 33 34 35 36 37> 7

var buf = new Buffer('hello 慕课网');             //默认utf8,同utf-8,不支持gbk
var buff = new Buffer('hello 慕课网', 'base64');  // base64减少网络请求

var buf = new Buffer([1,2,3,4]);
console.log(buf, buf[1]);                // < Buffer 01 02 03 04> 2
var buf = new Buffer([1.1,2.2,3.3,4.4]);
console.log(buf, buf[1]);                // < Buffer 01 02 03 04> 2

</pre>文件base64编码,复制文件 base64减少网络请求<pre class="js">
var fs = require('fs');
fs.readFile('1.png', function(err, orign_buffer){
    console.log(Buffer.isBuffer(orign_buffer));
    fs.writeFile('1_new.png', orign_buffer, err => err&&console.log(err)); //复制

    var base64Content = orign_buffer.toString('base64');       //文件内容数据base64编码
    console.log('----------------------', base64Content);
    var base64Url = 'data:image/png;base64,' + base64Content;  //base64头信息加文件内容组成base64Url
    console.log('----------------------', base64Url);

    var decodeImage = new Buffer(base64Content, 'base64');
    console.log(Buffer.compare(orign_buffer, decodeImage));    // 0

    fs.writeFile('1_base64.png', decodeImage, err => err&&console.log(err));
});


</pre><pre>
【 buf[index] 】
获取或设置指定index位置的8位字节,返回值代表单字节,所以返回值合法范围是16进制0x00到0xFF或10进制0至255

</pre><pre class="js">
/*拷贝一个ASCII编码的string字符串到一个buffer, 一次一个byte进行拷贝*/
str = "node.js";
buf = new Buffer(str.length);
for (var i = 0; i < str.length ; i++) {
  buf[i] = str.charCodeAt(i);
}
console.log(buf);               // node.js

//例：
var buf = new Buffer(26);
for (var i = 0 ; i < 26 ; i++) {
    buf[i] = i + 97;
}
console.log( buf.toString());   //abcdefghijklmnopqrstuvwxyz

</pre><pre>
【 buf.length 】
缓冲区长度,buffer大小在初始化时就固定下来,buf.length返回这个buffer的bytes数
注意这未必是buffer里面内容的大小.length是buffer对象所分配的内存数,不会随着buffer对象内容的改变而改变

在node.js中一个字符串的长度与根据该字符串所创建的缓存区的长度并不相同,因为在计算字符串的长度时,是以文字作为一个单位,而在计算缓存区的长度时,是以字节作为一个单位

可以使用0开始的序号来取出字符串对象或缓存区中的数据.但是,在获取数据时,字符串对象是以文字作为一个单位,而缓存区对象是以字节作为一个单位.比如,针对一个引用了字符串对象的str变量来说,str[2]获取的是第三个文字,而针对一个引用了缓存区对象的buf对象来说,buf[2]获取的是缓存区中的第三个字节数据转换为整数后的数值

</pre><pre class="js">
var buffer = new Buffer('www.runoob.com');
console.log("buffer length: " + buffer.length);

var str = 'string';
var buf = new Buffer(str)
console.log(buf, buf.length);            // < Buffer 73 74 72 69 6e 67> 6
console.log(str, str.length);            // string 6
console.log(buf[0], typeof buf[0]);      // 115 'number'
console.log(str[0], typeof str[0]);      // s string

var str = '我爱编程';
var buf = new Buffer(str);
console.log(buf, buf.length);       // < Buffer e6 88 91 e7 88 b1 e7 bc 96 e7 a8 8b> 12
console.log(str, str.length);       // 我爱编程 4
console.log(buf[0], typeof buf[0]); // 230 'number'
console.log(str[0], typeof str[0]); // 我 string

var arr = [1,2,3,4];
var buf = new Buffer(arr);
console.log(buf, buf.length);        // < Buffer 01 02 03 04> 4
console.log(arr, arr.length);        // [ 1, 2, 3, 4 ] 4
console.log(buf[0], typeof buf[0]);  // 1 'number'
console.log(arr[0], typeof arr[0]);  // 1 string

</pre><pre>
【 buf.write(string[, offset[, length]][, encoding]) 】
写入缓冲区<
string    写入缓冲区的字符串.
offset    缓冲区开始写入的索引值,默认为 0 .
length    写入的字节数,默认为 buffer.length
encoding  指定写入字符串时使用的编码格式,默认是utf8格式 .
返回值    返回实际写入的大小,写入了多少8位字节流.如果buffer空间不足, 则只会写入部分字符串
第二个参数offset与第三个参数length用于指定字符串转换为字节数据的写入位置.字节数据的书写位置为从第1+offset个字节开始到offset+length个字节为止

如果要将字符串当做二进制数据来使用,只需将该字符串作为Buffer类的构造函数的参数来创建Buffer对象即可.但是有时候我们需要向已经创建好的Buffer对象中写入字符串,这时候我们可以使用Buffer对象的write方法

</pre><pre class="js">
var buf = new Buffer(256);
var len = buf.write("www.runoob.com");
console.log("写入字节数:"+  len);

</pre><pre>
【 buf.toString([encoding[, start[, end]]]) 】
从缓冲区读取数据
encoding  使用的编码.默认'utf8' .
start     指定开始读取的索引位置,默认0,以字节为单位
end       结束位置,默认为缓冲区的末尾,以字节为单位
返回值     解码缓冲区数据并使用指定的编码返回字符串.

</pre><pre class="js">
var buf = new Buffer(26);
for (var i = 0 ; i < 26 ; i++) {
  buf[i] = i + 97;                        // 97 is ASCII a
}

console.log( buf.toString('ascii'));       // 输出: abcdefghijklmnopqrstuvwxyz
console.log( buf.toString('ascii',0,5));   // 输出: abcde
console.log( buf.toString('utf8',0,5));    // 输出: abcde
console.log( buf.toString(undefined,0,5)); // 使用 'utf8' 编码, 并输出: abcde

var buf = new Buffer('我爱编程');
console.log(buf.toString());                       // 我爱编程
console.log(buf, buf.length);                      // < Buffer e6 88 91 e7 88 b1 e7 bc 96 e7 a8 8b> 12
console.log(buf.toString('utf8', 6 , 9));          // 编
console.log(buf.toString('utf8', 9, buf.length));  // 程

var buf = new Buffer([1,2,3,4]);
console.log(buf.toString());                       // 
console.log(buf, buf.length);                      // < Buffer 01 02 03 04> 4
console.log(buf.toString('utf8', 0 , 3));          // 编
console.log(buf.toString('utf8', 9, buf.length));  // 程

var buf = new Buffer(['我','爱','编','程']);
console.log(buf.toString());                       // ''
console.log(buf, buf.length);                      // < Buffer 00 00 00 00> 4
console.log(buf.toString('utf8', 0 , 3));          // 编
console.log(buf.toString('utf8', 9, buf.length));  // 程

/*编码转换*/
console.log(new Buffer('hello, world!').toString('base64'));
// 转换成base64字符串：aGVsbG8sIHdvcmxkIQ==

console.log(new Buffer('aGVsbG8sIHdvcmxkIQ==', 'base64').toString());
// 还原base64字符串：hello, world!

console.log(new Buffer('hello, world!').toString('hex'));
// 转换成十六进制字符串：68656c6c6f2c20776f726c6421

console.log(new Buffer('68656c6c6f2c20776f726c6421', 'hex').toString());
// 还原十六进制字符串：hello, world!

</pre><pre>
【 buf.toJSON() 】
将Buffer转换为JSON对象
可以使用JSON.stringify方法将Buffer对象中保存的数据转换为一个字符串,也可以使用JSON.parse方法将一个经过转换后的字符串还原为一个数组

</pre><pre class="js">
/*buf.toJSON()*/
var buf = new Buffer('test');
console.log(buf);                // < Buffer 74 65 73 74>
var json = buf.toJSON();
console.log(json);               // { type: 'Buffer', data: [ 116, 101, 115, 116 ] }

/*JSON.stringify(buf)*/
var buf = new Buffer('test');
var json = JSON.stringify(buf);
console.log(json);               // '{"type":"Buffer","data":[116,101,115,116]}'
var copy = JSON.parse(json, function(key, value) {
    return value && value.type === 'Buffer' ? new Buffer(value.data):value;
});
console.log(copy);               // < Buffer 74 65 73 74>
var jsonObj = JSON.parse(json);
console.log(jsonObj);            // { type: 'Buffer', data: [ 116, 101, 115, 116 ] }

/*JSON.parse(json)*/
var buf = new Buffer('test');
var json = JSON.stringify(buf);
var jsonObj = JSON.parse(json);
console.log(jsonObj);            // { type: 'Buffer', data: [ 116, 101, 115, 116 ] }

/*实例*/
var arr = [1,2,3,4];
var buf = new Buffer(arr);
var json = JSON.stringify(buf);
var jsonObj = JSON.parse(json);
console.log(jsonObj);           // { type: 'Buffer', data: [ 1, 2, 3, 4 ] }

////////////////////////////////////////////
Buffer.prototype.toJSON = function() {
  return {
    type: 'Buffer',
    data: Array.prototype.slice.call(this, 0)
  };
};

</pre><pre>
【 buf.equals(otherBuffer) 】
比较两个缓冲区是否相等,如果是返回true,否则返回false

【 buf.compare(otherBuffer) 】
缓冲区比较,返回一个数字,表示buf在otherBuffer之前、之后或相同
// ABC在ABCD之前
var buffer1 = new Buffer('ABC');
var buffer2 = new Buffer('ABCD');
var result = buffer1.compare(buffer2);

if(result < 0) {
   console.log(buffer1 + " 在 " + buffer2 + "之前");
}else if(result == 0){
   console.log(buffer1 + " 与 " + buffer2 + "相同");
}else {
   console.log(buffer1 + " 在 " + buffer2 + "之后");
}

</pre><pre>
【 buf.fill(value[,offset][,end]) 】
用指定value填充buffer,offset(默认0),end(默认buffer.length)

【 buf.copy(targetBuffer[, targetStart[, sourceStart[, sourceEnd]]]) 】
拷贝缓冲区,源和目标可以相同
targetBuffer 要拷贝的 Buffer 对象.
targetStart  数字, 可选, 默认: 0
sourceStart  数字, 可选, 默认: 0
sourceEnd    数字, 可选, 默认: buffer.length
返回值

</pre><pre class="js">
var buffer1 = new Buffer('ABC');
var buffer2 = new Buffer(3);
var res = buffer1.copy(buffer2);
console.log(res);                 // 3
console.log(buffer2.toString());  // ABC

//在同一个buffer中,从一个区域拷贝到另一个区域
buf = new Buffer(26);
for (var i = 0 ; i < 26 ; i++) {
  buf[i] = i + 97;                // 97 is ASCII a
}
buf.copy(buf, 0, 4, 10);
console.log(buf.toString());     // efghijghijklmnopqrstuvwxyz

</pre><pre>
【 buf.slice([start[, end]]) 】
缓冲区裁剪
start   数字, 可选, 默认: 0  负的索引是从 buffer 尾部开始计算的
end     数字, 可选, 默认: buffer.length
返回值  返回一个新的缓冲区,它和旧缓冲区指向(引用)同一块内存,但是从索引 start 到 end 的位置剪切

由于buffer对象的slice方法并不是复制缓存区中的数据,而是与该数据共享内存区域,因此,如果修改使用slice方法取出的数据,则缓存区中保存的数据也将被修改

</pre><pre class="js">
var buffer1 = new Buffer('runoob');
console.log(buffer1, buffer1.length, buffer1.toString());  // < Buffer 72 75 6e 6f 6f 62> 6 'runoob'
var buffer2 = buffer1.slice(0,2);
console.log(buffer2, buffer2.length, buffer2.toString());  // < Buffer 72 75> 2 'ru'

buffer2[0] = 0;
console.log(buffer2, buffer2.length, buffer2.toString());  // < Buffer 00 75> 2 '\u0000u'
console.log(buffer1, buffer1.length, buffer1.toString());  // < Buffer 00 75 6e 6f 6f 62> 6 '\u0000unoob'

</pre>

<h3>Buffer类方法</h3><pre>
typeof buffer === 'object'
require(util).isBuffer(obj)  返回值为Boolean,如果是Buffer返回true,否则返回false
Buffer.isBuffer(obj)  返回值为Boolean,如果是Buffer返回true,否则返回false

【 Buffer.concat(listarr[, totalLength]) 】
缓冲区合并,返回一个多个成员合并的新Buffer对象
listarr       用于合并的 Buffer 对象数组列表.
totalLength   可选,指定合并后Buffer对象的总长度之后执行速度更快

</pre><pre class="js">
var buffer1 = new Buffer('菜鸟教程 ');
var buffer2 = new Buffer('www.runoob.com');
var buffer3 = Buffer.concat([buffer1,buffer2]);
console.log(buffer3.toString());         // 菜鸟教程 www.runoob.com

</pre>data事件里的chunk拼接<pre class="js">
//chunk按照字符串拼接是不正确的,相当于进行了buffer.toString() + buffer.toString().如果buffer不是完整的,则toString出来后的string是存在问题的(如一个中文字被截断),这样出来的string就无法被iconv进行utf8和gbk正常转码

//实例1
var html = '';
response.on('data', data =>  html += data );

//实例2
var fileBuff = [];
response.on('data', function (chunk) {
  var buffer = new Buffer(chunk);
  fileBuff.push(buffer);
});
response.on('end', function() {
  var totalBuff = Buffer.concat(fileBuff);
}

/*字符串拼接比buffer拼接快很多,buffer还需要toString()操作*/
var string3 = '';
console.time('write 1024*1024*10 string')
for(j=0;j< 1024*1024*10;j++){
  var x = j+'';
  string3 += x;
}
console.timeEnd('write 1024*1024*10 string')  // 12878.057ms

console.time('write 1024*1024*10 buffer')
var bufstr3 = new Buffer(1024*1024*10)
for(j=0;j< 1024*1024*10;j++){
  var x = j+'';
  bufstr3.write(x,j);
}
console.timeEnd('write 1024*1024*10 buffer')  // 4048.780ms

</pre><pre>
Buffer.compare(buf1, buf2) 和 buf1.compare(buf2)一样. 用来对数组排序:
var arr = [Buffer('1234'), Buffer('0123')];
arr.sort(Buffer.compare);

</pre><pre>
【 Buffer.isEncoding('encoding') 】
检测一个字符串是否为一个有效的编码格式字符串,nodejs是否支持这种编码方式
encoding用于指定需要被检测的字符串,如果该字符串为有效的编码格式字符串则方法返回true,如果该字符串不是一个有效的编码格式字符串则方法返回false

Buffer.isEncoding('utf8');  //true
Buffer.isEncoding('utf-8');  //true
Buffer.isEncoding('utf');    //false

【 Buffer.byteLength(string[, encoding]) 】
返回字符串真实字节长度,和String.prototype.length不一样,因为那个方法返回这个字符串中字符的数量
string   String类型
encoding String类型,可选,默认'utf8'
返回值    Number类型

</pre><pre class="js">
str = '\u00bd + \u00bc = \u00be';
console.log(str + ": " + str.length + " characters, " +   Buffer.byteLength(str, 'utf8') + " bytes");
// ½ + ¼ = ¾: 9 characters, 12 bytes

</pre>

<h3>buffer 使用二进制数据</h3><pre>
【 buf.writeUIntBE(value, offset, byteLength[, noAssert]) 】
将value写入到buffer里,由offset和byteLength决定,最高支持48位无符号整数,大端对齐
noAssert值为true时不再验证value和offset的有效性,默认是false

将一个整形数值存储到文件中,如当前时间戳为1447656645380,当作字符串存储时占用11字节的空间,而将其转换为二进制存储时仅需6字节空间即可

</pre><pre class="js">
var buf = new Buffer(6);
buf.writeUIntBE(1447656645380, 0, 6);  // < Buffer 01 51 0f 0f 63 04>
buf.readUIntBE(0, 6);                  // 1447656645380

</pre><pre>
【 操作结构化数据 】
学生考试成绩数据库中,每条记录为学号：xxxxxx; 课程代码：xxxx; 分数：xx

在使用文本来存储这些数据时,比如使用CSV格式存储可能是这样的：
100001,1001,99
100002,1001,67
100003,1001,88

其中每条记录占用15字节的空间,而使用二进制存储时其结构将会是3字节 2字节 1字节,每一条记录仅需要6字节的空间即可,仅仅是使用文本存储的40%

</pre><pre class="js">
// 当每一条记录的结构有变化时,需要修改readRecord()和writeRecord(),重新计算每一个字段在Buffer中的偏移量,当记录的字段比较复杂时很容易出错

// 读取一条记录
// buf    Buffer对象
// offset 本条记录在Buffer对象的开始位置
// data   {number, lesson, score}
function writeRecord (buf, offset, data) {
  buf.writeUIntBE(data.number, offset, 3);
  buf.writeUInt16BE(data.lesson, offset + 3);
  buf.writeInt8(data.score, offset + 5);
}

// 写入一条记录
// buf    Buffer对象
// offset 本条记录在Buffer对象的开始位置
function readRecord (buf, offset) {
  return {
    number: buf.readUIntBE(offset, 3),
    lesson: buf.readUInt16BE(offset + 3),
    score: buf.readInt8(offset + 5)
  };
}

// 写入记录列表
// list  记录列表,每一条包含 {number, lesson, score}
function writeList (list) {
  var buf = new Buffer(list.length * 6);
  var offset = 0;
  for (var i = 0; i < list.length; i++) {
    writeRecord(buf, offset, list[i]);
    offset += 6;
  }
  return buf;
}

// 读取记录列表
// buf  Buffer对象
function readList (buf) {
  var offset = 0;
  var list = [];
  while (offset < buf.length) {
    list.push(readRecord(buf, offset));
    offset += 6;
  }
  return list;
}

var list = [
  {number: 100001, lesson: 1001, score: 99},
  {number: 100002, lesson: 1001, score: 88},
  {number: 100003, lesson: 1001, score: 77},
  {number: 100004, lesson: 1001, score: 66},
  {number: 100005, lesson: 1001, score: 55},
];
console.log(list);

var buf = writeList(list);
console.log(buf.length);   // 30

var ret = readList(buf);
console.log(ret);
/* 输出
[ { number: 100001, lesson: 1001, score: 99 },
  { number: 100002, lesson: 1001, score: 88 },
  { number: 100003, lesson: 1001, score: 77 },
  { number: 100004, lesson: 1001, score: 66 },
  { number: 100005, lesson: 1001, score: 55 } ]
*/

</pre>
</div>

<div id="stream">
<h2>stream流以buffer形式存在 暂存移动数据 大文件如视频</h2><pre class="js">
C:\Users\lenovo>node
> stream

</pre><pre>
文件流

流,在应用程序中表示一组有序的、有起点有终点的字节数据的传输手段
Stream是一个抽象接口,Node中有很多对象实现了这个接口,如对http服务器发起请求的request对象就是一个Stream,还有stdout(标准输出)
Node.js中实现了stream.Readable/stream.Writeable接口的对象进行流数据读写;以上接口都继承自EventEmitter类,是EventEmitter的实例,因此在读/写流不同状态时,触发不同事件;

data   当有数据可读时触发.
end    没有更多的数据可读时触发.
error  在接收和写入过程中发生错误时触发.
finish 所有数据已被写入到底层系统时触发

【 stream流的种类 】
readable    可读流,提供数据到buffer中缓存起来,比如fs.createReadStream() 两种模式pause() resume()
writable    可写流,消费数据,从readable流中获取数据处理,比如fs.createWriteStream()
duplex      双工流,实现了readable和writable的接口,比如net.Socket()
transform   转换流,双工流,实现了readable和writable接口,不保存数据,只负责处理流经的数据,比如zlib.createDeflate()

</pre>Duplex stream<pre class="js">
/* 客户端代码 */
var net = require('net');
var opt = {
    host: '127.0.0.1',
    port: '8888'
};
var client = net.connect(opt, function(){
    client.write('msg from client');             // 可写
});
client.on('data', function(data){                 // 可读
    console.log('client: got reply from server [%s]', data);
    client.end();
});

</pre><pre>
关于流读取：Node.js不断将文件一小块内容读入缓冲区,再从缓冲区中读取内容;
关于流写入：Node.js不断将流数据写入内在缓冲区,待缓冲区满后再将缓冲区写入到文件中;重复上面操作直到要写入内容写写完;
readFile、read、writeFile、write都是将整个文件放入内存而再操作,而流是文件一部分数据一部分数据操作;

source(readable) ->transform(writable/readable) ->destination(writable)

</pre>创建一个可读流,重写._read方法<pre class="js">
var Readable = require('stream').Readable;
var rs = new Readable;
rs.push('node');
rs.push('.js');
rs.push('\n is great \n');
rs.push(null);              //表示rs已完成输出数据
rs.pipe(process.stdout);
// node.js
// is great

/* 实例2 */
var Readable = require('stream').Readable;
var rs = new Readable;
var c = 97;
rs._read = function () {
    if (c > 'z'.charCodeAt(0)){
        rs.push("\n");
        rs.push(null);
    }else{
        setTimeout(function(){
            rs.push(String.fromCharCode(c++));
        },500)
    }
};
rs.pipe(process.stdout);                      // abcdefjhijklmnopqrstuvwxyz

/* 实例3 read(3) 每次返回3个字节的数据,如果不够3个字节,那么会打印出null,直到积攒到3个字节 */
var Readable = require('stream').Readable;
var rs = new Readable;
var c = 97;
rs._read = function () {
    if (c > 'z'.charCodeAt(0)){
        rs.push("\n");
        rs.push(null);
        return;
    }
    setTimeout(function () {
        rs.push(String.fromCharCode(c++));
    }, 100)

};
rs.on("readable",function(){
    console.log(rs.read(3));                // null null < Buffer 61 62 63> null null
})

/* 实例4 */
var Readable = require('stream').Readable;
var rs = new Readable({objectMode:true})    // objectMode属性默认为false
var c = 97;
rs._read = function () {
    if (c > 'z'.charCodeAt(0)){
        rs.push("\n");
        rs.push(null);
        return;
    }
    setTimeout(function () {
        rs.push(String.fromCharCode(c++));
    }, 100)

};

rs.on("readable",function(){
    console.log(rs.read(3));               // abcdefjhijklmnopqrstuvwxyz
})

/* 实例5 */
var Readable = require('stream').Readable;
var rs = new Readable({objectMode:true})
var c = 97;
rs._read = function () {
    if (c > 'z'.charCodeAt(0)){
        rs.push("\n");
        rs.push(null);
        return;
    }
    setTimeout(function () {
        rs.push(String.fromCharCode(c++));
    }, 100)

};
var datas = '';
rs.on('data', function(data){
    datas += data
})
rs.on('end', function(){
    console.log(datas);
})

</pre>创建一个可写流,重写._write方法<pre class="js">
var Writable = require('stream').Writable;
console.log('请输入：');
var ws = new Writable();
ws._write = function (chunk, enc, next) {
    console.dir(chunk.toString());
    next();
};

process.stdin.pipe(ws);

</pre>cmd端覆盖写入文件<pre class="js">
const fs = require('fs');
const ws = fs.createWriteStream('stdin.txt');
console.log('请输入：');
process.stdin.pipe(ws);

</pre>

<h4>流读取</h4><pre>
读取数据对象：
fs.createReadStream         读取文件
http.IncomingMessage        客户端请求或服务器端响应
net.Socket                  Socket端口对象
child.stdout                子进程标准输出
child.stdin                 子进程标准入
process.stdin               用于创建进程标准输入流
Gzip、Deflate、DeflateRaw     数据压缩

触发事件：
readable  数据可读时
data      数据读取后
end       数据读取完成时
error     数据读取错误时
close     关闭流对象时

读取数据的对象操作方法：
read          读取数据方法
setEncoding   设置读取数据的编
pause         通知对象众目停止触发data事件
resume        通知对象恢复触发data事件
pipe          设置数据通道,将读入流数据接入写入流;
unpipe        取消通道
unshift       当流数据绑定一个解析器时,此方法取消解析器

</pre>

<h4>流写入</h4><pre>
写数据对象：
fs.WriteStream             写入文件对象
http.clientRequest         写入HTTP客户端请求数据
http.ServerResponse        写入HTTP服务器端响应数据
net.Socket                 读写TCP流或UNIX流,需要connection事件传递给用户
child.stdout               子进程标准输出
child.stdin                子进程标准入
Gzip、Deflate、DeflateRaw  数据压缩

写入数据触发事件：
drain            当write方法返回false时,表示缓存区中已经输出到目标对象中,可以继续写入数据到缓存区
finish           当end方法调用,全部数据写入完成
pipe             当用于读取数据的对象的pipe方法被调用时
unpipe           当unpipe方法被调用
error            当发生错误

写入数据方法：
write            用于写入数据
end              结束写入,之后再写入会报错;

</pre>

<h4>fs.createReadStream(path, [options]) 创建读取流,创建一个将文件内容读取为流数据的ReadStream对象</h4><pre>
path     文件路径
options  flags:指定文件操作,默认'r',读操作;encoding,指定读取流编码;autoClose, 是否读取完成后自动关闭,默认true;start指定文件开始读取位置;end指定文件开始读结束位置

读取流设置编码之后读取的数据由buffer转换成string
res.on('data', chunk => console.log(typeof chunk, Buffer.isBuffer(chunk))));  // object true
readerStream.setEncoding('UTF8');  // 设置编码为 utf8
res.on('data', data => console.log(typeof data, Buffer.isBuffer(data))));     // string false

</pre><pre class="js">
var rs = fs.createReadStream(__dirname + '/test.txt', {start: 0, end: 2});  //创建可读流

//处理流事件 open data end close eror
rs.on('open', function (fd) {   //open是ReadStream对象中表示文件打开时事件,
    console.log('开始读取文件');
});

rs.on('data', function (data) {
    console.log('读取到数据：', data.toString());
});

rs.on('end', function () {
    console.log('读取文件结束')
});

rs.on('close', function () {
    console.log('文件关闭');
});

rs.on('error', function (err) {
  console.error('读取文件失败', err.stack);
});

</pre>readable事件<pre class="js">
const input = fs.createReadStream(filename);
input.on('readable', () => {
  const data = input.read();
  if (data) console.log('读取到数据：', data.toString());
  else console.log('读取文件结束')
});

</pre><pre class="js">
//不同于在一个可读流上设置的highWaterMark默认值(16 kb),该方法在相同参数下返回的流具有64 kb的默认值
//每次读取chunk.length = 65536btye,触发data事件的次数
const fs = require('fs');
var readStream = fs.createReadStream('luky.mp4');
var n = 0;
readStream
  .on('data',(chunk) => {
    n++;
    console.log(`\ndata emits：第${n}次`);
    console.log(Buffer.isBuffer(chunk)); // true
    console.log(chunk.length + 'btye');
    readStream.pause();                  //暂停读取
    console.log('readStream pause');
    setTimeout(function(){
      console.log('readStream pause end\n');
      readStream.resume();                //回复读取
    },100)
  })
  .on('readable', () => console.log('readable emits'))
  .on('end',() => console.log(`end emits ; 总共${n}次`))
  .on('close',() => console.log('close emits'))
  .on('error',(e) => console.log('error emits', e))

</pre>

<h4>fs.createWriteStream(path, [options]) 创建写入流 创建一个将流数据写入文件中的WriteStream对象</h4><pre>
path 文件路径
[options] flags:指定文件操作,默认'w',;encoding,指定读取流编码;start指定写入文件的位置

ws.write(chunk, [encoding], [callback]);
chunk       可以为Buffer对象或一个字符串,要写入的数据
encoding    编码
callback    写入后回调

ws.end([chunk], [encoding], [callback]);
chunk       要写入的数据
encoding    编码
callback    写入后回调

</pre><pre class="js">
var fs = require("fs");
var data = '菜鸟教程官网地址：www.runoob.com';
var writerStream = fs.createWriteStream('output.txt');  // 创建一个可以写入的流,写入到文件 output.txt 中
writerStream.write(data,'UTF8');                        // 使用 utf8 编码写入数据
writerStream.end();                                     // 标记文件末尾
writerStream.on('finish', function() {                  // 处理流事件 --> data, end, and error
    console.log("写入完成.");
});
writerStream.on('error', function(err){
   console.log(err.stack);
});
console.log("程序执行完毕");

</pre><pre class="js">
var fs = require('fs');
var rs = fs.createReadStream('./message.txt');
var ws = fs.createWriteStream('./anotherMessage.txt');
rs.on('data',function(data){
    ws.write(data);
});
ws.on('open',function(fd){
    console.log('需要被写入的文件已打开');
});
rs.on('end',function(){
    ws.end('再见',function(){          //将操作系统缓存区中的数据全部写入文件
        console.log('文件全部写入完毕');
        console.log('共写入'+ws.bytesWritten+'数据');
    });
});

</pre>监听writeStream对象的drain事件<pre class="js">
var fs = require('fs');
var ws = fs.createWriteStream('./test1.txt');
for(var i = 0; i < 10000; i++){
    var flag = ws.write(i.toString());  //返回布尔值,true代表缓存区已满
    console.log(flag);
}
ws.on('drain',function(){
    console.log('操作系统缓存区中的数据已全部输出');
    var ws = fs.createWriteStream('./test2.txt');
    for(var i = 0; i < 10; i++){
        var flag = ws.write(i.toString());
        console.log(flag);
    }
    ws.on('drain',function(){
        console.log('操作系统缓存区中的数据已全部输出');
    });
});

</pre><pre class="js">
var ws = fs.createWriteStream(__dirname + '/test.txt', {start: 0});
var buffer = new Buffer('我也喜欢你');
ws.write(buffer, 'utf8', function (err, buffer) {
    console.log(arguments);
    console.log('写入完成,回调函数没有参数')
});
ws.end('再见');   //最后再写入的内容

/*使用流完成复制文件操作*/
var rs = fs.createReadStream(__dirname + '/test.txt')
var ws = fs.createWriteStream(__dirname + '/test/test.txt');

rs.on('data', function (data) {
    ws.write(data)
});

ws.on('open', function (fd) {
    console.log('要写入的数据文件已经打开,文件描述符是:' + fd);
});

rs.on('end', function () {
    console.log('文件读取完成');
    ws.end('完成', function () {
        console.log('文件全部写入完成')
    });
});

</pre><pre>
WriteStream对象的write方法返回一个布尔类型,缓存区中数据全部写满时返回false,表示缓存区写满,并将立即输出到目标对象中

</pre><pre class="js">
//第一个例子
var ws = fs.createWriteStream(__dirname + '/test/test.txt');
for (var i = 0; i < 10000; i++) {
  var w_flag = ws.write(i.toString());
  console.log(w_flag);    //当缓存区写满时,输出false
}

//第二个例子
var ws = fs.createWriteStream(__dirname + '/test/untiyou.mp3');
var rs = fs.createReadStream(__dirname + '/test/Until You.mp3');
rs.on('data', function (data) {
  var flag = ws.write(data);
  console.log(flag);
});

//系统缓存区数据已经全部输出触发drain事件
ws.on('drain', function () {
  console.log('系统缓存区数据已经全部输出.')
});

</pre><pre class="js">
const fs = require('fs');
const rs = fs.createReadStream('luky.mp4');
const ws = fs.createWriteStream('luky_write.mp4');

rs.on('data', function(chunk){
    if(ws.write(chunk) === false){ //写入速度赶不上读取速度时数据流在cache中爆满
      console.log('still cached');
      rs.pause();
    }
  })
  .on('end', function(){
    ws.end();
  })

ws.on('drain', function(){
    console.log('data drain');
    rs.resume();
  })

</pre>

<h4>管道流</h4><pre>
管道提供了一个输出流到输入流的机制.通常我们用于从一个流中获取数据并将数据传递到另外一个流中,这样就慢慢的实现了大文件的复制过程

rs.pipe(destination, [options]); 管道流pipe实现流读写
destination 必须一个可写入流数据对象
[opations] end 默认为true,表示读取完成立即关闭文件;

可读流.pipe(可写流)
可写流通过pipe从可读流中获取buffer chunk数据来处理,怎么处理取决于可读流的read方法

pipe方法会自动监听data end事件,可自动控制后端压力,调度流;属于被动消费,需要时才会执行
可读流包括fs.createReadStream('23.jpg').pipe(res)和npm install request的request(远程资源).pipe(res);

fs.createReadStream('luky.mp4').pipe(fs.createWriteStream('luky_copy.mp4'));
fs.createReadStream('./sample.txt').pipe(process.stdout);                     //输出到控制台

</pre><pre class="js">
/*管道读写操作,读取 input.txt 文件内容,并将内容写入到 output.txt 文件中*/
var fs = require("fs");
var readerStream = fs.createReadStream('input.txt');   // 创建一个可读流
var writerStream = fs.createWriteStream('output.txt'); // 创建一个可写流
readerStream.pipe(writerStream);
console.log("程序执行完毕");

</pre><pre class="js">
var rs = fs.createReadStream(__dirname + '/test/Until You.mp3');
var ws = fs.createWriteStream(__dirname + '/test/untiyou.mp3');
rs.pipe(ws);
rs.on('data', function (data) {
  console.log('数据可读')
});
rs.on('end', function () {
  console.log('文件读取完成');
  //ws.end('再见')
});

</pre>链式流是通过连接输出流到另外一个流并创建多个对个流操作链的机制.链式流一般用于管道操作<pre class="js">
/* compress.js 用管道和链式来压缩和解压文件 */
var fs = require("fs");
var zlib = require('zlib');

// 压缩 input.txt 文件为 input.txt.gz
fs.createReadStream('input.txt')
  .pipe(zlib.createGzip())
  .pipe(fs.createWriteStream('input.txt.gz'));
console.log("文件压缩完成.");

// 解压 input.txt.gz 文件为 input.txt
fs.createReadStream('input.txt.gz')
  .pipe(zlib.createGunzip())
  .pipe(fs.createWriteStream('input.txt'));

console.log("文件解压完成.");

</pre><pre class="js">
var http = require('http');
var fs = require('fs');
var request = require('request');  // npm install request

http
  .createServer(function(req, res){

    //方法1
    /*fs.readFile('23.jpg', function(err, data){
      if(err){
        res.end('404,file not exist!')
      }else{
        res.writeHeader(200, {'Content-Type': 'text/html'});
        res.end(data.toString());
      }
    })*/

    //方法2
    // fs.createReadStream('23.jpg').pipe(res);

    //方法3
    request('http://img3.mukewang.com/54584ef20001deba02200220-200-200.jpg').pipe(res);
  })
  .listen(8888)

console.log('服务器开始监听...');

</pre>

<h4>大文件下载 断点续传</h4><pre>
基本原理:文件的下载断开以后客户端继续向服务器端请求时,http请求的头文件中会多一个Range参数标示当前下载的文件所断开的位置,响应头包含Content-Range字段

</pre><pre class="js">
function Transfer(req, resp) {
  this.req = req;
  this.resp = resp;
}

// 计算上次的断点信息,参数Range表示请求http头文件中的断点信息,格式(range: bytes=232323-),默认undefined,返回startPos表示开始的下载点
 Transfer.prototype._calStartPosition = function(Range) {
  var startPos = 0;
  if( typeof Range != 'undefined') {
    var startPosMatch = /^bytes=([0-9]+)-$/.exec(Range);
    startPos = Number(startPosMatch[1]);
  }
  return startPos;
}

// 配置头文件,参数Config表示头文件配置信息(包含了下载的起始位置和文件的大小)
Transfer.prototype._configHeader = function(Config) {
  var startPos = Config.startPos,
    fileSize = Config.fileSize,
    resp = this.resp;
  // 如果startPos为0,表示文件从0开始下载的,否则则表示是断点下载的。
  if(startPos == 0) {
    resp.setHeader('Accept-Range', 'bytes');
  } else {
    resp.setHeader('Content-Range', 'bytes ' + startPos + '-' + (fileSize - 1) + '/' + fileSize);
  }
  //206 客户发送了一个带有Range头的GET请求,服务器完成了它
  resp.writeHead(206, 'Partial Content', { 'Content-Type':'application/octet-stream',});
}

// 初始化配置信息,参数down表示下载开始的回调函数
Transfer.prototype._init = function(filePath, down) {
  var config = {};
  var self = this;
  fs.stat(filePath, function(error, state) {
    if(error) throw error;
    config.fileSize = state.size;
    var range = self.req.headers.range;
    config.startPos = self._calStartPosition(range);
    self.config = config;
    self._configHeader(config);
    down();
  });
}
// 生成大文件文档流,并发送
Transfer.prototype.Download = function(filePath) {
  var self = this;
  path.exists(filePath, function(exist) {
    if(exist) {
      self._init(filePath, function() {
        var config = self.config
          resp = self.resp;
        fReadStream = fs.createReadStream(filePath, {
          encoding:'binary',
          bufferSize:1024 * 1024,
          start:config.startPos,
          end:config.fileSize
        });
        fReadStream.on('data', function(chunk) {
          resp.write(chunk, 'binary');
        });
        fReadStream.on('end', function() {
          resp.end();
        });
      });
    } else {
      console.log('文件不存在！');
      return;
    }
  });
}

// 测试
var fs = require('fs')
http = require('http')
path = require('path');
var server = http.createServer(function(req, resp) {
  var transfer = new Transfer(req, resp);
  var filePath = '/Users/xukai/Downloads/love.rmvb';
  transfer.Download(filePath);
});
server.listen('8000');

</pre>
</div>

<div id="file">
<h2>File</h2><pre>
Node.js文件系统封装在fs模块中,提供了文件的读取、写入、更名、删除、遍历目录、链接等POSIX文件系统操作,fs模块中所有的操作都提供了异步的和同步的两个版本

nodejs的fs模块针对读操作提供了readFile,read,createReadStream三个方法,针对写操作提供了writeFile,write,createWriteStream三个方法

readFile方法是将要读取的文件内容完整读入缓存区,再从该缓存区中读取文件内容
writeFile方法是将要写入的文件内容完整的读入缓存区,然后一次性的将缓存区中的内容写入都文件中
Node.js将文件内容视为一个整体,为其分配缓存区并且一次性将文件内容读取到缓存区中,在这个期间,Node.js将不能执行任何其他处理.所以当读写大文件的时候,有可能造成缓存区"爆仓",在网络请求文件的时候,性能尤其明显

read或readSync方法读取文件内容是不断地将文件中的一小块内容读入缓存区,最后从该缓存区中读取文件内容
write或writeSync方法写入内容时,node.js执行以下过程：1将需要写入的数据写入到一个内存缓存区;2待缓存区写满后再将缓存区中的内容写入到文件中;3重复执行步骤1和步骤2,知道数据全部写入文件为止
以上读写操作,node.js会将文件分成一块一块逐步操作,在读写文件过程中允许执行其他操作

但有时不关心整个文件的内容,只关注从文件中读取到的某些数据及读取到数据时需要执行的处理,这时可使用文件流来处理
createReadStream方法创建一个将文件内容读取为流数据的ReadStream对象
createWriteStream方法创建一个将流数据写入文件中的WriteStream对象
以上方法可以对读写文件的过程中进行监听,并定义相关的方法pause和resume暂停或恢复文件的读取操作,可以监听写入时缓存区数据是否已满或者是否已全部输出
createReadStream是给你一个ReadableStream,可以听它的'data',一点一点儿处理文件,用过的部分会被GC,所以占内存少

</pre><pre class="js">
// 当客户请求服务器资源,服务器会读取data.txt文件到内存,然后把数据再推倒客户端,如果文件很大就会占用很多内存,如果高并发,性能会更差。

var http = require('http');
var fs = require('fs');
var server = http.createServer(function (req, res) {
  fs.readFile(__dirname + '/data.txt', function (err, data) {
    res.end(data);
  });
});
server.listen(3000);

// 用fs.createReadStream方法代替fs.readFile方法。把文件流和响应流通过pipe连起来,数据就会"缓缓的"流道客户端,不会出现大量内存被消耗的情况。内部通过监听 stream 的data和end时间,把接收到的文件块第一时间write到客户端,节省内存。

var http = require('http');
var fs = require('fs');
var server = http.createServer(function (req, res) {
  var stream = fs.createReadStream(__dirname + '/data.txt');
  stream.pipe(res);
});
server.listen(3000);

</pre><pre class="js">
C:\Users\lenovo>node
> fs

</pre><pre>
【 fs.readFile(filename,[encoding],[callback(err,data)]) 】
异步地读取一个文件的全部内容
filename(必选),表示要读取的文件名
encoding(可选),表示文件的字符编码
callback(err,data)回调函数用于接收文件的内容,data是文件内容
如果未指定字符编码则返回原始的buffer

如果不指定encoding,则callback就是第二个参数
如果指定encoding,data是一个解析后的字符串,否则data将会是以Buffer形式表示的二进制数据

当 path 是一个目录时,fs.readFile() 与 fs.readFileSync() 的行为与平台有关。 在 macOS、Linux 与 Windows 上,会返回一个错误。 在 FreeBSD 上,会返回目录内容的表示

path /
EISDIR: illegal operation on a directory, read
path /dsds
ENOENT: no such file or directory, open 'E:\wamp64\www\study\nodejs\stuwebfk\example\day01\public\dsds'
path /dsds/
ENOENT: no such file or directory, open 'E:\wamp64\www\study\nodejs\stuwebfk\example\day01\public\dsds'

</pre><pre class="js">
fs.readFile('/etc/passwd', (err, data) => {
  if (err) throw err;
  console.log(data);
});

fs.readFile('/etc/passwd', 'utf8', callback);

// 在 macOS、Linux 与 Windows 上：
fs.readFile('< directory >', (err, data) => {
  // => [Error: EISDIR: illegal operation on a directory, read < directory >]
});

//  在 FreeBSD 上：
fs.readFile('< directory >', (err, data) => {
  // => null,  < data >
});

</pre><pre class="js">
const fs = require(`fs`);
const os = require(`os`);
fs.readFile(`./split.txt`, `utf8`, (err, data) => {  // 如果没有指定编码则是buffer形式
  console.log(typeof data);                          // string
  data.split(os.EOL).forEach(line => {
    console.log(line);
  });
});

</pre><pre>
【 fs.readFileSync(filename, [encoding]) 】
是fs.readFile 同步的版本,接受的参数和fs.readFile相同
如果指定了encoding选项则该函数返回一个字符串,否则返回一个buffer。

如果有错误发生,fs将会抛出异常,需要使用try和catch捕捉并处理异常
与同步I/O函数不同,Node.js中异步函数大多没有返回值

【 fs.writeFile(filename, data[, options], [callback(err)]) 】
异步模式写入文件内容
如果文件存在,该方法写入的内容会覆盖旧的文件内容

参数使用说明如下：
filename  文件名或文件描述符.
data      要写入文件的数据,可以是 String(字符串) 或 Buffer(流) 对象.
options   该参数是一个对象,包含 {encoding, mode, flag}.默认编码为 utf8, 模式为 0666 , flag 为 'w'
callback  回调函数,回调函数只包含错误信息参数(err),在写入失败时返回

多次对同一文件使用fs.writeFile且不等待回调,是不安全的,对于这种情况强烈推荐使用fs.createWriteStream

</pre><pre class="js">
var fs = require("fs");
fs.writeFile('input.txt', '我是通过写入的文件内容！',  function(err) {
  if (err) return console.error(err);
  console.log("数据写入成功！");
  fs.readFile('input.txt', function (err, data) {
    if (err)  return console.error(err);
    console.log("异步读取文件数据: " + data.toString());
  });
});

</pre><pre>
【 fs.writeFileSync(file, data[, options]) 】
同步,返回undefined

【 fs.appendFile(filename,data,[options],callback) 】
以追加方式写文件,异步地追加数据到一个文件,如果文件不存在则创建文件

参数：
file          string/Buffer/number  文件名或文件描述符
data          string/Buffer
options       Object/string
  encoding  string/null 默认为 'utf8'
  mode      integer 默认为 0o666
  flag      string 默认为 'a'
callback(err)

</pre><pre class="js">
fs.appendFile(__dirname+'/test.txt', '追加文件内容buffer/string', function (err) {
  if (err) throw err;
  console.log('追加内容完成');
});

fs.appendFile('message.txt', 'data to append', 'utf8', callback);

</pre><pre>
【 fs.appendFileSync(file, data[, options]) 】
同步版,返回undefined

【 fs.copyFile(src, dest[, flags], callback) 】
src          string/Buffer/URL 要被拷贝的源文件名称
dest         string/Buffer/URL 拷贝操作的目标文件名
flags        number 拷贝操作修饰符 默认: 0
callback(err)

异步的将src拷贝到dest.dest将创建或覆盖
Node.js 不能保证拷贝操作的原子性。如果目标文件打开后出现错误,Node.js 将尝试删除它

</pre><pre class="js">
const fs = require('fs');
fs.copyFile('source.txt', 'destination.txt', (err) => {
  if (err) throw err;
  console.log('source.txt was copied to destination.txt');
});

</pre><pre class="js">
const fs = require('fs');
const { COPYFILE_EXCL } = fs.constants;

// 使用 COPYFILE_EXCL ,如果 destination.txt 文件存在,操作将失败。
fs.copyFile('source.txt', 'destination.txt', COPYFILE_EXCL, callback);

</pre><pre>
【 fs.copyFileSync(src, dest[, flags]) 】
同步,返回undefined

【 fs.stat(path, callback(err, stats)) 】
通过异步模式获取目录或文件信息
fs.stat()执行后,会将stats类的实例返回给其回调函数.可以通过stats类中的提供方法判断文件的相关属性.例如判断是否为文件

参数path可以是文件路径或者目录路径

不建议在调用fs.open()或fs.readFile()或fs.writeFile()之前使用fs.stat()检查一个文件是否存在。 作为替代,用户代码应该直接打开/读取/写入文件,当文件无效时再处理错误
推荐使用 fs.access()

stats类中的方法有：
stats.isFile()            如果是文件返回 true,否则返回 false.
stats.isDirectory()       如果是目录返回 true,否则返回 false.
stats.isBlockDevice()     如果是块设备返回 true,否则返回 false.
stats.isCharacterDevice() 如果是字符设备返回 true,否则返回 false.
stats.isSymbolicLink()    如果是软链接返回 true,否则返回 false.
stats.isFIFO()            如果是FIFO,返回true,否则返回 false.FIFO是UNIX中的一种特殊类型的命令管道.
stats.isSocket()          如果是 Socket 返回 true,否则返回 false

</pre><pre class="js">
var fs = require('fs');
fs.stat('../input.txt', function (err, stats) {
  console.log(stats);
  console.log("是否为文件(isFile) ? " + stats.isFile());
  console.log("是否为目录(isDirectory) ? " + stats.isDirectory());
  for(var pro in stats) console.log(`${pro}:${stats[pro]}`);       //遍历对象的属性和方法
})

Stats {
  dev: 1660614421,
  mode: 33206,
  nlink: 1,
  uid: 0,
  gid: 0,
  rdev: 0,
  blksize: undefined,
  ino: 15199648742378018,
  size: 596,                          // 和fs.readFile()回调函数的data.length相等,是文件的字节数
  blocks: undefined,
  atime: 2017-10-26T17:18:27.438Z,
  mtime: 2017-10-26T17:18:27.438Z,     //文件修改时间
  ctime: 2017-10-28T16:07:37.778Z,
  birthtime: 2017-10-26T17:18:27.438Z  //文件创建时间
}

</pre><pre>
【 fs.statSync(path) 】
异步

【 fs.exists(path, callback) 】
文件与目录是否存在 废弃的: 使用fs.stat()或fs.access()代替
path              要查看目录/文件的完整路径及名;
callback(exists)  操作完成回调函数;返回布尔值exists true存在,false表示不存在

不推荐在调用 fs.open,fs.readFile(),fs.writeFile() 之前使用 fs.exists() 检测文件是否存在。这样做会引起竞争条件,因为在两次调用之间,其他进程可能修改文件。作为替代,用户应该直接开/读取/写入文件,当文件不存在时再处理错误

</pre><pre class="js">
fs.exists(__dirname + '/te', function (exists) {
  console.log(__dirname + '/te' + (exists ? '文件存在':'文件不存在'));
});

</pre><pre class="js">
fs.open('myfile', 'r', (err, fd) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }
    throw err;
  }

  readMyData(fd);
});

</pre><pre>
【 fs.existsSync(path) 】
未废弃
path string/Buffer/URL
fs.exists()的同步版本,如果文件存在则返回true,否则返回false

</pre><pre>
【 fs.access(path[, mode], callback) 】
测试path指定的文件或目录的用户权限。 mode是一个可选的整数,指定要执行的可访问性检查。 以下常量定义了mode的可能值。 可以创建由两个或更多个值的位或组成的掩码。

fs.constants.F_OK - path 文件对调用进程可见。 这在确定文件是否存在时很有用,但不涉及 rwx 权限。 如果没指定 mode,则默认为该值。
fs.constants.R_OK - path 文件可被调用进程读取。
fs.constants.W_OK - path 文件可被调用进程写入。
fs.constants.X_OK - path 文件可被调用进程执行。 对 Windows 系统没作用(相当于 fs.constants.F_OK)

参数callback是一个回调函数,会带有一个可能的错误参数被调用。 如果可访问性检查有任何的失败则错误参数会被传入

</pre>检查 /etc/passwd 文件是否可以被当前进程读取和写入<pre class="js">
fs.access('/etc/passwd', fs.constants.R_OK | fs.constants.W_OK, (err) => {
  console.log(err ? 'no access!':'can read/write');
});

</pre><pre>
【 fs.open(path, flags, [mode], [callback(err, fd)]) 】
是POSIX open函数的封装,与C语言标准库中的fopen函数类似
flags 可以是以下值.
r ： 以读取模式打开文件,默认
r+ ：以读写模式打开文件.
w ： 以写入模式打开文件,如果文件不存在则创建.
w+ ：以读写模式打开文件,如果文件不存在则创建.
a ： 以追加模式打开文件,如果文件不存在则创建.
a+ ：以读取追加模式打开文件,如果文件不存在则创建

【 fs.openSync(path, flags[, mode]) 】

【 fs.read(fd,buffer,offset,length,position,[callback(err, bytesRead, buffer)]) 】
读取打开的文件内容到缓冲区中
fd:       通过 fs.open() 方法返回的文件描述符,读取数据并写入 buffer 指向的缓冲区对象.
offset:   是buffer 的写入偏移量.
length:   是要从文件中读取的字节数.
position: 是文件读取的起始位置,如果 position 的值为 null,则会从当前文件指针的位置读取.
callback: 回调函数传递bytesRead 和 buffer,分别表示读取的字节数和缓冲区对象

要求手动管理缓冲区和文件指针,尤其在不知道文件大小的时候很少使用

</pre><pre class="js">
var fs = require('fs');
fs.open('./message.txt','r',function(err,fd){
  var buf = new Buffer(225);
  //读取fd文件内容到buf缓存区
  fs.read(fd,buf,0,9,3,function(err,bytesRead,buffer){
    console.log(buf.slice(0,bytesRead).toString());
  });
  var buff = new Buffer(225);
  //位置设置为null会默认从文件当前位置读取
  fs.read(fd,buff,0,3,null,function(err,bytesRead,buffer){
      console.log(buff.slice(0,bytesRead).toString());
  });

  var buffer = new Buffer(225);
  //同步方法读取文件
  var bytesRead = fs.readFileSync(fd,buffer,0,9,3);
  console.log(bytesRead);
  console.log(buffer.slice(0,bytesRead).toString());
});

</pre><pre>
【 fs.readSync(fd, buffer, offset, length, position) 】
同步版本,返回bytesRead的数量

【fs.write() 】
将缓冲区内数据写入使用fs.open打开的文件
fs.write(fd, buffer[, offset[, length[, position]]], callback) 写入buffer到fd指定的文件
fs.write(fd, string[, position[, encoding]], callback)  写入string到fd指定的文件,如果string不是字符串则会被强制转换为字符串

fd        使用fs.open打开成功后返回的文件描述符
buffer    一个Buffer对象,v8引擎分配的一段内存
offset    整数,从缓存区中读取时的初始位置,以字节为单位
length    整数,从缓存区中读取数据的字节数
position  整数,写入文件初始位置;
callback(err, written, buffer), 写入操作执行完成后回调函数,written实际写入字节数,buffer被读取的缓存区对象

</pre><pre class="js">
fs.open(__dirname + '/test.txt', 'a', function (err, fd) {
  if(err) return console.error(err);
  var buffer = new Buffer('写入文件数据内容');
  //写入'入文件'三个字
  fs.write(fd, buffer, 3, 9, 12, function (err, written, buffer) {
    if(err) return console.error(err);
    console.log(buffer.toString());
    //写入'数据内'三个字
    fs.write(fd, buffer, 12, 9, null, function (err, written, buffer) {
      console.log(buffer.toString());
    })
  });
});

</pre><pre class="js">
var fs = require('fs');
var buf = new Buffer('我喜爱编程');
fs.open('./mess.txt','w',function(err,fd){
  fs.write(fd,buf,3,9,0,function(err,written,buffer){
    fs.write(fd,buf,12,3,null,function(err,written,buffer){
      if(err) console.log('写文件操作失败');
      console.log('写文件操作成功');
    });
  });
  //同步写入
  fs.writeSync(fd,buf,3,9,0);
});

</pre><pre>
【 fs.writeSync()  】
同步
fs.writeSync(fd, buffer[, offset[, length[, position]]])
fs.writeSync(fd, string[, position[, encoding]])

【 fs.close(fd, callback)  】
异步模式下关闭fs.open()打开的文件
fd         通过fs.open()方法返回的文件描述符
callback   回调函数

</pre><pre class="js">
var fs = require('fs');
fs.open('content.txt', 'r', function(err, fd) {
  if(err) return console.error(err);
  var buf = new Buffer(8);
  fs.read(fd, buf, 0, 8, null, function(err, bytesRead, buffer) {
    if(err) return console.error(err);
    console.log('bytesRead: ' + bytesRead);
    console.log(buffer);
  })
});

</pre><pre class="js">
var fs = require("fs");
var buf = new Buffer(1024);
fs.open('input.txt', 'r+', function(err, fd) {
  if (err)  return console.error(err);
  console.log("文件打开成功！准备读取文件：");

  fs.read(fd, buf, 0, buf.length, 0, function(err, bytes){
    if (err) console.log(err);
    console.log(bytes + "  字节被读取");
    if(bytes > 0){ console.log(buf.slice(0, bytes).toString()); }  // 仅输出读取的字节

    fs.close(fd, function(err){                                    // 关闭文件
      if (err) console.log(err);
      console.log("文件关闭成功");
    });
  });
});

</pre><pre>
【 fs.ftruncate(fd, len, callback)  】
异步模式下截取fs.open()打开的文件
fd         通过 fs.open() 方法返回的文件描述符
len        文件内容截取的长度
callback   回调函数

【 fs.unlink(path, callback) 】
删除文件

</pre><pre class="js">
var fs = require("fs");
fs.unlink('input.txt', function(err) {
  if (err) return console.error(err);
  console.log("文件删除成功！");
});

</pre><pre>
【 fs.unlinkSync(path) 】
异步

【 fs.mkdir(path[, mode], callback) 】
创建目录
path      文件路径.
mode      设置目录权限,默认为 0777.
callback  回调函数

</pre><pre class="js">
var fs = require("fs");
fs.mkdir("/tmp/test/",function(err){
  if (err) return console.error(err);
  console.log("目录创建成功.");
});

</pre><pre>
【 fs.mkdirSync(path[, mode]) 】
path string/Buffer/URL
mode integer,Default: 0o777
同步的 mkdir(2)。返回 undefined。

【 fs.mkdtemp(prefix[, options], callback) 】
创建一个唯一的临时目录
生成六位随机字符附加到一个要求的prefix后面,然后创建一个唯一的临时目录。

创建的目录路径会作为字符串传给回调的第二个参数。

可选的options参数可以是一个字符串并指定一个字符编码,或是一个对象且由一个encoding属性指定使用的字符编码

</pre><pre class="js">
fs.mkdtemp(path.join(os.tmpdir(), 'foo-'), (err, folder) => {
  if (err) throw err;
  console.log(folder);
  // 输出: /tmp/foo-itXde2 or C:\Users\...\AppData\Local\Temp\foo-itXde2
});

</pre><pre class="js">
// 新建的临时目录的父目录
const tmpDir = os.tmpdir();

// 该方法是 *错误的*：
fs.mkdtemp(tmpDir, (err, folder) => {
  if (err) throw err;
  console.log(folder);
  // 会输出类似于 `/tmpabc123`。
  // 注意,一个新的临时目录会被创建在文件系统的根目录,而不是在 /tmp 目录里。
});

// 该方法是 *正确的*：
const { sep } = require('path');
fs.mkdtemp(`${tmpDir}${sep}`, (err, folder) => {
  if (err) throw err;
  console.log(folder);
  // 会输出类似于 `/tmp/abc123`。
  // 一个新的临时目录会被创建在 /tmp 目录里。
});

</pre><pre>
【 fs.mkdtempSync(prefix[, options]) 】
fs.mkdtemp() 的同步版本。 返回创建的目录的路径。

【 fs.readdir(path, callback) 】
异步读取目录
path       文件路径
callback(err, files)   回调函数,files 是目录中不包括 '.' 和 '..' 的文件名的数组
console.log(files);   //[ 'test - 副本.txt', 'test.txt' ]

</pre><pre class="js">
var fs = require("fs");
fs.readdir("/tmp/",function(err, files){
  if (err) return console.error(err);
  files.forEach( function (file){
    console.log( file );
  });
});

</pre><pre class="js">
fs.readdir(__dirname + '/fsDir/', function (err, files) {
  if(err)  return console.error(err);
  files.forEach(function (file) {
    var filePath = path.normalize(__dirname + '/fsDir/' + file);
    fs.stat(filePath, function (err, stat) {
      if(stat.isFile())  console.log(filePath + ' is: ' + 'file');
      if(stat.isDirectory())  console.log(filePath + ' is: ' + 'dir');
    });
  });
  for (var i = 0; i < files.length; i++) {
    //使用闭包无法保证读取文件的顺序与数组中保存的致
    (function () {
      var filePath = path.normalize(__dirname + '/fsDir/' + files[i]);
      fs.stat(filePath, function (err, stat) {
        if(stat.isFile()) console.log(filePath + ' is: ' + 'file');
        if(stat.isDirectory()) console.log(filePath + ' is: ' + 'dir');
      });
    })();
});

</pre><pre>
【 fs.readdirSync(path[, options]) 】
同步的 readdir(3). 返回一个不包括 '.' 和 '..' 的文件名的数组

【 fs.rmdir(path, callback) 】
删除目录
在文件上(而不是目录上)使用fs.rmdir(),在Windows平台将会导致ENOENT错误,而在POSIX平台将会导致ENOTDIR错误

</pre><pre class="js">
var fs = require("fs");
fs.rmdir("/tmp/test",function(err){
  if (err) return console.error(err);
  fs.readdir("/tmp/",function(err, files){
    if (err) return console.error(err);
    files.forEach( function (file){
      console.log( file );
    });
  });
});

</pre><pre>
【 fs.rmdirSync(path) 】
同步

【 fs.rename(oldPath, newPath, callback) 】
移动/重命名文件或目录
oldPath       原目录/文件的完整路径及名;
newPath       新目录/文件的完整路径及名;如果新路径与原路径相同,而只文件名不同,则是重命名
callback(err) 操作完成回调函数;err操作失败对象

</pre><pre class="js">
fs.rename(__dirname + '/test', __dirname + '/fsDir', function (err) {
  if(err) return console.error(err);
  console.log('重命名成功')
});

fs.rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  fs.stat('/tmp/world', (err, stats) => {
    if (err) throw err;
    console.log(`stats: ${JSON.stringify(stats)}`);
  });
});

</pre><pre>
【 fs.renameSync(oldPath, newPath) 】
同步的 rename(2)。返回 undefined

【 fs.fsync(fd, [callback]) 】
刷新缓存区
fd  使用fs.open打开成功后返回的文件描述符
callback(err, written, buffer) 写入操作执行完成后回调函数,written实际写入字节数,buffer被读取的缓存区对象

使用fs.write写入文件时,操作系统是将数据读到内存,再把数据写入到文件中,当数据读完时并不代表数据已经写完,因为有一部分还可能在内在缓冲区内.
因此可以使用fs.fsync方法将内存中数据写入文件;--刷新内存缓冲区

</pre><pre class="js">
fs.open(__dirname + '/test.txt', 'a', function (err, fd) {
  if(err) throw err;
  var buffer = new Buffer('我爱nodejs编程');
  fs.write(fd, buffer, 0, 9, 0, function (err, written, buffer) {
    console.log(written.toString());
    fs.write(fd, buffer, 9, buffer.length - 9, null, function (err, written) {
      console.log(written.toString());
      fs.fsync(fd);
      fs.close(fd);
    })
  });
});

</pre><pre>
【 fs.utimes(path, atime, mtime, callback) 】
修改文件访问时间与修改时间
path           要查看目录/文件的完整路径及名;
atime          新的访问时间
ctime          新的修改时间
callback(err)  操作完成回调函数;err操作失败对象

</pre><pre class="js">
fs.utimes(__dirname + '/test.txt', new Date(), new Date(), function (err) {
  if(err) throw err;
  fs.stat(__dirname + '/test.txt', function (err, stat) {
    console.log('访问时间: ' + stat.atime.toString() + '; \n修改时间：' + stat.mtime);
    console.log(stat.mode);
  })
});

</pre><pre>
【 fs.chmod(path, mode, callback) 】
修改文件或目录的操作权限
path           要查看目录/文件的完整路径及名;
mode           指定权限,如：0666 8进制,权限：所有用户可读、写, 1执行2写4读  0777 第一个数就是0
callback(err)  操作完成回调函数;err操作失败对象

文件权限的数字类型
文件的基本权限有9个,分别是owner、group、others三种身份各有自己的read、write、execute权限.

将r、w和x分别用4、2、1来代表,没有授予权限的则为0,然后把权限相加,如下
原始权限    转换为数字      数字表示法
rwx rwx rwx (421)(421)(421) 777
rw- rw- rw- (420)(420)(420) 666
rwx rwx r-x (421)(421)(401) 775
rwx r-x r-x (421)(401)(401) 755

</pre><pre class="js">
fs.chmod(__dirname + '/fsDir', 0666, function (err) {
  if(err) return console.error(err);
  console.log('修改权限成功')
});

</pre><pre>
【 fs.watchFile(filename, [options], listener) 】
对文件进行监视,并且在监视到文件被修改时执行处理
filename 完整路径及文件名;
options  persistent true表示持续监视,不退出程序;interval 单位毫秒,表示每隔多少毫秒监视一次文件
listener 文件发生变化时回调,有两个参数：curr为被修改后fs.Stat对象,prev修改前fs.Stat对象

</pre><pre class="js">
fs.watchFile(__dirname + '/test.txt', {interval: 20}, function (curr, prev) {
  if(Date.parse(prev.ctime) == 0) {
    console.log('文件被创建!');
  } else if(Date.parse(curr.ctime) == 0) {
    console.log('文件被删除!')
  } else if(Date.parse(curr.mtime) != Date.parse(prev.mtime)) {
    console.log('文件有修改');
  }
});
fs.watchFile(__dirname + '/test.txt', function (curr, prev) {
  console.log('这是第二个watch,监视到文件有修改');
});


</pre><pre>
【 fs.unwatchFile(filename, [listener]) 】
取消对文件进行监视
filename  完整路径及文件名;
listener  要取消的监听器事件,如果不指定,则取消所有监听处理事件

</pre><pre class="js">
var listener = function (curr, prev) {
  console.log('我是监视函数')
}
fs.unwatchFile(__dirname + '/test.txt', listener);

</pre><pre>
【 fs.watch(filename, [options], [listener]) 】
对文件或目录进行监视,并且在监视到修改时执行处理
filename, 完整路径及文件名或目录名;
listener(event, filename], 监听器事件,参数event 为rename表示指定的文件或目录中有重命名、删除或移动操作或change表示有修改,filename表示发生变化的文件路径

fs.watch返回一个fs.FSWatcher对象,拥有一个close方法,用于停止watch操作;
当fs.watch有文件变化时,会触发fs.FSWatcher对象的change(err, filename)事件,err错误对象,filename发生变化的文件名

</pre><pre class="js">
var fsWatcher = fs.watch(__dirname + '/test', function (event, filename) {
  //console.log(event)
});

//console.log(fsWatcher instanceof FSWatcher);

fsWatcher.on('change', function (event, filename) {
  console.log(filename + ' 发生变化')
});

//30秒后关闭监视
setTimeout(function () {
  console.log('关闭')
  fsWatcher.close(function (err) {
    if(err) {
      console.error(err)
    }
    console.log('关闭watch')
  });
}, 30000);


</pre>
</div>

<!-- --------------events------------------------------ -->
<div id="events">
<h2>events 事件 事件循环</h2><pre class="js">
> events
{ [Function: EventEmitter]
  EventEmitter: [Circular],
  usingDomains: true,
  defaultMaxListeners: [Getter/Setter],
  init: [Function],
  listenerCount: [Function] }

</pre><pre>
Node.js是单进程单线程应用程序,但是通过事件和回调支持并发,所以性能非常高
Node.js的每一个API都是异步的,并作为一个独立线程运行,使用异步函数调用并处理并发
Node.js基本上所有的事件机制都是用设计模式中观察者模式实现
Node.js单线程类似进入一个while(true)的事件循环,直到没有事件观察者退出,每个异步事件都生成一个事件观察者,如果有事件发生就调用该回调函数

事件驱动程序
Node.js 使用事件驱动模型,当web server接收到请求,就把它关闭然后进行处理,然后去服务下一个web请求
当这个请求完成,它被放回处理队列,当到达队列开头,这个结果被返回给用户
这个模型非常高效可扩展性非常强,因为webserver一直接受请求而不等待任何读写操作.(这也被称之为非阻塞式IO或者事件驱动IO)
在事件驱动模型中,会生成一个主循环来监听事件,当检测到事件时触发回调函数

包括fs、net、 http在内的,只要是支持事件响应的核心模块都是EventEmitter的子类

events模块只提供了一个对象:events.EventEmitter.EventEmitter的核心就是事件触发与事件监听器功能的封装
Node.js所有的异步 I/O 操作在完成时都会发送一个事件到事件队列
Node.js里面的许多对象都会分发事件：一个net.Server对象会在每次有新连接时分发一个事件, 一个fs.readStream对象会在文件被打开的时候发出一个事件,所有这些产生事件的对象都是events.EventEmitter的实例

当继承EventEmitter,成为其子类就具备了emit激发事件方法和addListener添加监听器的方法。在node.js核心库中很多类都继承自EventEmitter

</pre><pre class="js">
var EventEmitter = require("events").EventEmitter;
var inherits = require("util").inherits;

// 定义一个EventEmitter子类
function User(name){
  EventEmitter.call(this);
  this._name = name;
}

inherits(User,EventEmitter);

User.prototype.changeName = function(name){
  this._name = name;
  this.emit("change name",name);      // 激发change name事件
}

var me = new User("leo");               // 创建一个User对象
me.on("change name", newName => console.log("名字被改成成 ---> " + newName));
me.changeName("brighthas");

</pre><pre>
【 EventEmitter对象的属性和方法 】
addListener(event, listener)   为指定事件添加一个监听器到监听器数组的尾部
on(event, listener)            为指定事件注册一个监听器,接受一个字符串event和一个回调函数
once(event, listener)          为指定事件注册一个单次监听器,即监听器最多只会触发一次,触发后立刻解除该监听器
removeListener(event,listener) 移除指定事件的某个监听器,监听器须是该事件已注册的监听器
removeAllListeners([event])    移除所有事件的所有监听器,如果指定事件,则移除指定事件的所有监听器
setMaxListeners(n)             默认若添加的监听器超过10个会输出警告信息,该函数用于提高监听器的默认限制的数量
listeners(event)               返回指定事件的监听器数组
emit(event,[arg1],[arg2],[...]) 按参数的顺序执行每个监听器,如果事件有注册监听返回true,否则返回false

【 EventEmitter类方法 】
EventEmitter.listenerCount(emitter, event)   返回emitter的指定事件的监听器数量

【 事件 】
EventEmitter对象如果在实例化时发生错误,会触发error事件
当添加新的监听器时,newListener 事件会触发
当监听器被移除时,removeListener 事件被触发

newListener事件
当通过emitter.on / emitter.once添加监听器时会触发该事件
event - 字符串,事件名称
listener - 处理事件函数

removeListener事件
当通过emitter.removeAllListeners / emitter.removeListener删除监听器时会触发该事件
从指定监听器数组中删除一个监听器,此操作将会改变处于被删监听器之后监听器的索引
event - 字符串,事件名称
listener - 处理事件函数

</pre><pre class="js">
var EventEmitter = require("events").EventEmitter;
var inherits = require("util").inherits;

function User(name){                              // 定义一个EventEmitter子类
  EventEmitter.call(this);
  this._name = name;
}
inherits(User,EventEmitter);

User.prototype.changeName = function(name){
  this._name = name;
  this.emit("change name",name);                // 激发change name事件
}

var me = new User("leo");                         // 创建一个User对象

function handle1(name){                           // 第一个监听器
  console.log("handle1 --- > 新名字："+name);
}

function handle2(name){                           // 第二个监听器
  console.log("handle2 --- > 新名字："+name);
}

me.on("newListener",function(event,listener){     // 添加 newListener事件监听
  console.log(event + "事件添加了一个监听器")
})

me.on("removeListener",function(event,listener){  // 添加 removeListener事件监听器
  console.log(event+"事件删除了一个监听器");
})

me.on("change name",handle1);
me.on("change name",handle2);
me.removeAllListeners();                          // 删除全部事件监听器
me.changeName("brighthas");

</pre><pre class="js">
var events = require('events');                   // 引入events模块
var eventEmitter = new events.EventEmitter();     // 创建eventEmitter对象
eventEmitter.on('eventName', eventHandler);       // 绑定事件及事件的处理程序,注册事件eventName的监听器
eventEmitter.emit('eventName');                   // 触发事件,调用eventName的监听器

server.once('connection', function (stream) {
  console.log('Ah, we have our first user!');
});

var callback = function(stream) {
  console.log('someone connected!');
};
server.on('connection', callback);
server.removeListener('connection', callback);

</pre><pre>
EventEmitter的每个事件由一个事件名和若干个参数组成,事件名是一个字符串,通常表达一定的语义
对于每个事件,EventEmitter支持若干个事件监听器.
当事件触发时,注册到这个事件的事件监听器被依次调用,事件参数作为回调函数参数传递

</pre><pre class="js">
var events = require('events');
var emitter = new events.EventEmitter();
emitter.on('someEvent', function(arg1, arg2) {
    console.log('listener1', arg1, arg2);
});
emitter.on('someEvent', function(arg1, arg2) {
    console.log('listener2', arg1, arg2);
});
emitter.emit('someEvent', 'arg1 参数', 'arg2 参数');

</pre><pre class="js">
var EventEmitter = require('events').EventEmitter;
var life = new EventEmitter();
life.setMaxListeners(11);                    // 同一事件最大监听量默认为10,这里可以自定义,不宜过大
life.on('finish', function(what){
  console.log(`${what} is finish`);
});
var finishE = life.emit('finish', 'nodejs');  // 返回该事件是否被监听
console.log(finishE);                         // true

</pre><pre class="js">
var events = require('events');
var eventEmitter = new events.EventEmitter();
var connectHandler = function connected() {   // 创建事件处理程序
  console.log('连接成功.');
  eventEmitter.emit('data_received');
}
eventEmitter.on('data_received', function(){   // 使用匿名函数绑定 data_received 事件
  console.log('数据接收成功.');
});
eventEmitter.on('connection', connectHandler);
eventEmitter.emit('connection');
console.log("code end");

//连接成功
//数据接收成功
//code end

</pre><pre class="js">
var events = require('events');
var eventEmitter = new events.EventEmitter();

var listener1 = function listener1() {                // 监听器 #1
  console.log('监听器 listener1 执行.');
}
var listener2 = function listener2() {                // 监听器 #2
  console.log('监听器 listener2 执行.');
}
eventEmitter.addListener('connection', listener1);     // 绑定 connection 事件,处理函数为 listener1
eventEmitter.on('connection', listener2);              // 绑定 connection 事件,处理函数为 listener2

var eventListeners = require('events').EventEmitter.listenerCount(eventEmitter,'connection');
console.log(eventListeners + " 个监听器监听连接事件.");

eventEmitter.emit('connection');                       // 处理 connection 事件

eventEmitter.removeListener('connection', listener1);  // 移除监绑定的 listener1 函数
console.log("listener1 不再受监听.");

eventEmitter.emit('connection');                       // 触发连接事件

eventListeners = require('events').EventEmitter.listenerCount(eventEmitter,'connection');
console.log(eventListeners + " 个监听器监听连接事件.");

console.log("程序执行完毕.");

</pre>

<h4>error事件</h4><pre>
EventEmitter 定义了一个特殊的事件error,它包含了错误的语义,在遇到异常的时候通常会触发error事件
当error被触发时,EventEmitter规定如果没有响应的监听器,Node.js会把它当作异常,退出程序并输出错误信息
一般要为会触发error事件的对象设置监听器,避免遇到错误后整个程序崩溃

if(err) return console.log(err.stack);
if(err) return console.log(err.message);
if(err) throw err;

fs.writeFile('23_base64.jpg', decodeImage, err => err&&console.log(err));

</pre><pre class="js">
> Error
{ [Function: Error]
  captureStackTrace: [Function: captureStackTrace],
  stackTraceLimit: 10 }

fs.stat(file, (err, stats) => console.log(err))
{ Error: ENOENT: no such file or directory, stat 'E:\wamp64\www\study\nodejs\promise\undefined'
    at Error (native)
  errno: -4058,
  code: 'ENOENT',
  syscall: 'stat',
  path: 'E:\\wamp64\\www\\study\\nodejs\\promise\\undefined' }

</pre><pre class="js">
var events = require('events');
var emitter = new events.EventEmitter();
emitter.emit('error');

</pre><pre>
【 Error类 】
一个通用的JavaScript Error对象,它不表示错误发生的具体情况。 Error对象会捕捉一个"堆栈跟踪",详细说明被实例化的Error对象在代码中的位置,并可能提供错误的文字描述

所有由Node.js产生的错误,包括所有系统的和js的错误都实例化自或继承自Error类

new Error(message)
新建一个Error实例,并设置error.message属性以提供文本信息
如果message传的是一个对象,则会调用message.toString()生成文本信息

error.message属性是错误的字符串描述,通过调用new Error(message)设置
error.code属性是标识错误类别的字符标签,错误码
error.stack属性是一个字符串,描述代码中Error被实例化的位置;堆栈跟踪是基于V8的堆栈跟踪API的。 堆栈跟踪只会取(a)异步代码执行的开头或(b)Error.stackTraceLimit 属性给出的栈帧中的最小项

系统错误类
error.code属性是一个表示错误码的字符串,总是 E 带上一串大写字母
error.errno属性是一个数值或字符串,如果返回一个数值则数值是一个负数,对应libuv错误处理 中定义的错误码;如果返回一个字符串则同error.code
error.syscall属性是一个字符串,描述失败的 系统调用
错误出现时(比如在fs或child_process),error.path属性是一个字符串,包含了相关不可用路径名
错误出现时(比如在net或dgram),error.path是一个链接端口不可用的端口值

</pre>

<h3>常见的系统错误</h3><pre>
EACCES (拒绝访问): 试图以被一个文件的访问权限禁止的方式访问一个文件。

EADDRINUSE (地址已被使用): 试图绑定一个服务器(net、http 或 https)到本地地址,但因另一个本地系统的服务器已占用了该地址而导致失败。

ECONNREFUSED (连接被拒绝): 无法连接,因为目标机器积极拒绝。 这通常是因为试图连接到外部主机上的废弃的服务。

ECONNRESET (连接被重置): 一个连接被强行关闭。 这通常是因为连接到远程 socket 超时或重启。 常发生于 http 和 net 模块。

EEXIST (文件已存在): 一个操作的目标文件已存在,而要求目标不存在。

EISDIR (是一个目录): 一个操作要求一个文件,但给定的路径是一个目录。

EMFILE (系统打开了太多文件): 已达到系统文件描述符允许的最大数量,且描述符的请求不能被满足直到至少关闭其中一个。 当一次并行打开多个文件时会发生这个错误,尤其是在进程的文件描述限制数量较低的操作系统(如 macOS)。 要解决这个限制,可在运行 Node.js 进程的同一 shell 中运行 ulimit -n 2048。

ENOENT (无此文件或目录): 通常是由 fs 操作引起的,表明指定的路径不存在,即给定的路径找不到文件或目录。

ENOTDIR (不是一个目录): 给定的路径虽然存在,但不是一个目录。 通常是由 fs.readdir 引起的。

ENOTEMPTY (目录非空): 一个操作的目标是一个非空的目录,而要求的是一个空目录。 通常是由 fs.unlink 引起的。

EPERM (操作不被允许): 试图执行一个需要更高权限的操作。

EPIPE (管道损坏): 写入一个管道、socket 或 FIFO 时没有进程读取数据。 常见于 net 和 http 层,表明远端要写入的流已被关闭。

ETIMEDOUT (操作超时): 一个连接或发送的请求失败,因为连接方在一段时间后没有做出合适的响应。 常见于 http 或 net。 往往标志着 socket.end() 没有被正确地调用。

define UV_ERRNO_MAP(XX)
XX( -1, UNKNOWN, "unknown error")
XX( 0, OK, "success")
XX( 1, EOF, "end of file")
XX( 2, EADDRINFO, "getaddrinfo error")
XX( 3, EACCES, "permission denied")
XX( 4, EAGAIN, "resource temporarily unavailable")
XX( 5, EADDRINUSE, "address already in use")
XX( 6, EADDRNOTAVAIL, "address not available")
XX( 7, EAFNOSUPPORT, "address family not supported")
XX( 8, EALREADY, "connection already in progress")
XX( 9, EBADF, "bad file descriptor")
XX( 10, EBUSY, "resource busy or locked")
XX( 11, ECONNABORTED, "software caused connection abort")
XX( 12, ECONNREFUSED, "connection refused")
XX( 13, ECONNRESET, "connection reset by peer")
XX( 14, EDESTADDRREQ, "destination address required")
XX( 15, EFAULT, "bad address in system call argument")
XX( 16, EHOSTUNREACH, "host is unreachable")
XX( 17, EINTR, "interrupted system call")
XX( 18, EINVAL, "invalid argument")
XX( 19, EISCONN, "socket is already connected")
XX( 20, EMFILE, "too many open files")
XX( 21, EMSGSIZE, "message too long")
XX( 22, ENETDOWN, "network is down")
XX( 23, ENETUNREACH, "network is unreachable")
XX( 24, ENFILE, "file table overflow")
XX( 25, ENOBUFS, "no buffer space available")
XX( 26, ENOMEM, "not enough memory")
XX( 27, ENOTDIR, "not a directory")
XX( 28, EISDIR, "illegal operation on a directory")
XX( 29, ENONET, "machine is not on the network")
XX( 31, ENOTCONN, "socket is not connected")
XX( 32, ENOTSOCK, "socket operation on non-socket")
XX( 33, ENOTSUP, "operation not supported on socket")
XX( 34, ENOENT, "no such file or directory")
XX( 35, ENOSYS, "function not implemented")
XX( 36, EPIPE, "broken pipe")
XX( 37, EPROTO, "protocol error")
XX( 38, EPROTONOSUPPORT, "protocol not supported")
XX( 39, EPROTOTYPE, "protocol wrong type for socket")
XX( 40, ETIMEDOUT, "connection timed out")
XX( 41, ECHARSET, "invalid Unicode character")
XX( 42, EAIFAMNOSUPPORT, "address family for hostname not supported")
XX( 44, EAISERVICE, "servname not supported for ai_socktype")
XX( 45, EAISOCKTYPE, "ai_socktype not supported")
XX( 46, ESHUTDOWN, "cannot send after transport endpoint shutdown")
XX( 47, EEXIST, "file already exists")
XX( 48, ESRCH, "no such process")
XX( 49, ENAMETOOLONG, "name too long")
XX( 50, EPERM, "operation not permitted")
XX( 51, ELOOP, "too many symbolic links encountered")
XX( 52, EXDEV, "cross-device link not permitted")
XX( 53, ENOTEMPTY, "directory not empty")
XX( 54, ENOSPC, "no space left on device")
XX( 55, EIO, "i/o error")
XX( 56, EROFS, "read-only file system")
XX( 57, ENODEV, "no such device")
XX( 58, ESPIPE, "invalid seek")
XX( 59, ECANCELED, "operation canceled") \

</pre>
</div>

<!-- --------------------net--------------------------------- -->
<div id="net">
<h2>net</h2><pre>
Net模块提供用于底层的网络通信的小工具,包含了创建服务器/客户端的方法,建立TCP连接需要用到NET模块
var net = require("net")

最基础的两个模块是NET和HTTP,前者是基于TCP的封装,后者本质还是TC层,只不过做了比较多的数据封装

通过网络可以让电脑通过IP相互连接,从而相互传递信息,数据传输的方式分为TCP和UDP,socket是建立在TCP和IP之上的,通过它发送数据和接收数据。HTTP协议中的数据是利用TCP协议传输的,所以支持HTTP也就一定支持TCP

net模块可以建立TCP的服务器端和Socket客户端
http模块是建立http的服务器端和客户端,http模块建立在net模块之上
https可以建立https的服务器端和客户端,https模块建立在http模块和tls模块之上,tls模块在"加密解密"
dgram模块对应的是UDP协议的操作

socket通常也称作"套接字",应用程序通常通过"套接字"向网络发出请求或应答网络请求

</pre><pre class="js">
C:\Users\lenovo>node
> net

</pre><pre>
http.Server继承了net.Server,此外http客户端与http服务端的通信均依赖于socket(net.Socket)

net模块主要包含两部分：
net.Server：TCP server,内部通过socket来实现与客户端的通信。
net.Socket：tcp/本地socket的node版实现,它实现了全双工的stream接口。

</pre><pre class="js">
/* TCP服务器端 */
var net = require('net');
var port = 8888;
var host = '127.0.0.1';
var server = net.createServer(function(socket){    // 双工流,可读可写
  console.log('收到来自客户端的请求');
  socket.on('data', function(data){
    console.log(`收到客户端数据,内容为${data}`);
    socket.write('hello,this is server');
  })
  socket.pipe(socket);                          // 接收到的数据传回去
  socket.on('close', () => console.log('客户端断开连接'))
  socket.on("error", () => console.log('客户端断开连接'))
  socket.on("end", () => console.log('客户端断开连接'))
})

server.listen(port, host, () => console.log(`server ${host}:${port} is listenning...`))

/* TCP客户端 */
var net = require('net');
var port = 8888;
var host = '127.0.0.1';
var client = net.createConnection(port, host);
client.on('connect', () => console.log('已经与服务器端建立连接'))
client.on('data', (data) => console.log(`收到服务器数据,内容为${data}`))
client.on('close', () => console.log('断开连接'))
client.end('你好,我是客户端');

</pre><pre class="js">
/* server.js */
var net = require('net');
var server = net.createServer(function(socket) {
  console.log('client connected');
  socket.write('Hello client!\r\n');
  socket.on('data', data => console.log(`【 client 】: ${data}`))
  socket.on('end', () => console.log('客户端关闭连接'));

  process.stdin.on("data",function(str){
    if(str.toString("utf8").trim() == "quit"){   // 当输入quit时关闭服务端
      process.exit(1);                         // 退出服务端
    }else{
      socket.write(str);                       // 把数据发送到客户端
    }
  })
});
server.listen(8888, () => console.log('server is listening ...'));

/* client.js */
var net = require('net');
var client = net.connect({port: 8888}, () => {
  console.log('已经连接到服务器！');
  client.write('hello server!');
  process.stdin.on("data",function(str){
    if(str.toString("utf8").trim() == "quit"){   // 当输入quit时关闭客户端
      process.exit(1);                         // 退出客户端
    }else{
      client.write(str);                       // 把数据发送到服务器端
    }
  })
});
client.on('data', data => console.log(`【 server 】: ${data.toString()}`));
client.on('end', () => console.log('断开与服务器的连接'));

</pre><pre class="js">
/* http.Server继承了net.Server */
var net = require('net');
var server = net.createServer(function(socket){
  console.log('Connected: ' + socket.remoteAddress + ':' + socket.remotePort);
  socket.on('data', function(data){
    console.log('DATA ' + socket.remoteAddress + ': ' + data);
    console.log('Data is: ' + data);
    socket.write('Data from you is  "' + data + '"');
  });
  socket.on('close', function(){
    console.log('CLOSED: ' + socket.remoteAddress + ' ' + socket.remotePort);
  });
});
server.listen(8888, '127.0.0.1');
console.log(server instanceof net.Server);  // true

</pre>

<h3>net.Server server对象</h3>
<h4>创建服务器,server对象实例</h4><pre>
net.createServer([options][, connectionListener])
创建一个TCP服务器
参数connectionListener自动给connection事件创建监听器,有客户端连接时触发connect事件
connectionListener缺省时,执行server.on("connection",function(socket){})等效

</pre>

<h4>server对象的属性方法</h4><pre>
server.listen(port, [host], [backlog], [callback])
启动服务器的监听
port     打开一个服务器端的监听端口,0表示由系统分配一个随机端口
host     允许连入的客户端主机,可以是ip或域名。
backlog  表示同时访问的最大数,默认511
callback 表示server对象产生listening事件的监听器,产生listening事件表示server已准备好,要接受客户端请求了

server.close([callback])
保留现有连接,停止接收新的客户端请求
对正在处理中的客户端请求,服务器会等待它们处理完(或超时),然后再正式关闭
callback是服务器的"close"事件的监听器
正常关闭的同时,callback会被执行,触发close事件
异常关闭的同时,callback也会执行,触发close事件,同时将对应的error作为参数传入。如没有启动监听或者监听没有准备好时调用server.close()

已调用server.listen()：正常关闭,close事件触发,然后callback执行,error参数为undefined
未调用server.listen()：异常关闭,close事件触发,然后callback执行,error为具体的错误信息。(注意,error 事件没有触发)

close事件的产生有几种情况
第一种情况是当产生error事件时也会产生close事件
第二种情况是调用过server.close方法后,已有的连接都断开连接后,会产生close事件

</pre><pre class="js">
/* tcp服务端正常关闭 */
var net = require('net');
var server = net.createServer(function(){});
server.listen(8888, '127.0.0.1', () => {
  server.close(error => {
    error?console.log(`close回调：服务端异常：${error.message}`):console.log(`close回调：服务端正常关闭`);
  });
});
server.on('close', () => console.log( 'close事件：服务端关闭' ));
server.on('error', error => console.log( 'error事件：服务端异常：' + error.message ));

// close事件：服务端关闭
// close回调：服务端正常关闭

/* tcp服务端异常关闭 */
var net = require('net');
var server = net.createServer(function(){});
// server.listen(8888, '127.0.0.1');        // 没有正式启动请求监听
server.on('close', () => console.log( 'close事件：服务端关闭' ));
server.on('error', error => console.log( 'error事件：服务端异常：' + error.message ));
server.close(error => {
  error?console.log(`close回调：服务端异常：${error.message}`):console.log(`close回调：服务端正常关闭`);
});

// close事件：服务端关闭
// close回调：服务端异常：Not running

</pre><pre>
server.address();    //{ port: 3000, family: 'IPv4', address: '127.0.0.1' }
返回服务端的地址信息

server.getConnections((err, count) => {})
异步获取当前连接数,count是当前连接数

net.isIP(input)
检查input字符串是否是IP,return 0 表示无效,return 4 表示IPv4,return 6表示IPv6。

net.ipIPv4(input)
检查input是否是IPv4 ,return true/false。

net.ipIPv6(input)
检查input是否是IPv6 ,return true/false

server.ref()/server.unref();
主要用于将server加入事件循环/从事件循环里面剔除,影响就在于会不会影响进程的退出

</pre><pre class="js">
var net = require("net");
console.log(net.isIP("12.444.22.2"));                 // 0
console.log(net.isIP("112.11.22.122"));               // 4
console.log(net.isIP("fe80::dc15:8005:801c:82bb"));   // 6
console.log(net.isIPv4("22.212.12.122"));             // true
console.log(net.isIPv6("22.212.12.122"));             // false
console.log(net.isIPv6("fe80::dc15:8005:801c:82bb")); // true

</pre>

<h4>server对象的事件</h4><pre>
listening： 调用server.listen(),服务器准备好接受客户端请求,正式开始监听请求的时候触发
close：     服务端关闭的时候触发
error：     服务出错的时候触发,比如监听了已经被占用的端口
connection：当有新的请求进来时触发,参数为请求相关的 socket

有新的客户端连接产生时,net.createServer(callback) 中的callback回调会被调用,同时 connection 事件注册的回调函数也会被调用。事实上,net.createServer(callback) 中的 callback 在node内部实现中 也是加入了做为 connection事件 的监听函数

</pre><pre class="js">
/* connection事件触发 */
var net = require('net');
var server = net.createServer(function(socket){
  socket.write('1. connection 触发\n');
});
server.on('connection', function(socket){
  socket.end('2. connection 触发\n');
});
server.listen(8888, '127.0.0.1');

//1. connection 触发
//2. connection 触发

</pre>

<h3>net.socket类实现了stream.Duplex双工接口,具有了读写的能力</h3>
<h4>创建Socket实例</h4><pre>
Socket是一个管道两端的口,一个管道必然有两个socket,无论关闭任何一端的socket,对应的也就kill

1、new net.Socket()
2、net.connect()/net.createConnect()
3、服务端有客户端连接时会在服务端创建一个对象的socket; net.createServer([connectionListener(socket){}])

</pre><pre class="js">
const net = require('net');
const socket = new net.Socket();
socket.connect(8888, () => console.log(socket.address()))   // { address: '127.0.0.1', family: 'IPv4', port: 60905 }

</pre>

<h4>socket对象属性</h4><pre>
 ✈ 连接相关
socket.connect()：有3种不同的参数,用于不同的场景

socket.setTimeout(timeout, [callback])
用来进行连接超时设置,设定空闲超时,只会产生timeout事件,不会断开连接
timeout   单位为毫秒,若timeout=0,将撤销先前设置的超时
callback  超时监听器,当有timeout事件时会被调用
可使用socket.on('timeout', callback)的方式进行监听

socket.setKeepAlive()：用来设置长连接。
socket.destroy()、socket.destroyed：当错误发生时用来销毁socket,确保这个socket上不会再有其他的IO操作

 ✈ 数据读、写相关
socket.write(data, [encoding], [callback])
data为字符串或buffer类型;encoding默认utf8,data为字符串时有效;callback写入成功后回调

socket.end([data], [encoding])
socket.end()就是发出FIN信号,告诉另一端socket结束了,然后自己也会结束生命周期,而另一端会触发"end"事件
有data参数时相当于
socket.write(data,[encoding],function(){
 socket.end();
})

socket.destroy()
结束生命周期,服务端不会触发end事件,另一端会触发error事件

socket.pause()
暂停接受读取数据的动作,即暂停触发socket.on('data', data => {})

socket.resume()
恢复读取动作

socket.setEncoding()
socket.setNoDelay()

 ✈ 数据属性相关
socket.bufferSize
socket.bytesRead      累积接收到的字节数
socket.bytesWritten   累积发送的字节数

 ✈ 事件循环相关
socket.ref()
socket.unref()

 ✈ 地址相关
socket.address()       本地socket地址对象{ address: '::ffff:127.0.0.1', family: 'IPv6', port: 8888 }
socket.remoteAddress   远程socket地址    ::ffff:127.0.0.1
socket.remoteFamily                      IPv6
socket.remotePort      远程socket端口    60729
socket.localAddress    本地socket地址    ::ffff:127.0.0.1
socket.localPort       本地socket端口    888

</pre>

<h4>socket对象的事件</h4><pre>
data：   当收到另一端传来的数据时触发,事件监听器会接收到数据
connect：当连接建立时触发
error：  当有错误发生时就会触发,参数为error,一旦产生这个事件,内部也会产生"close"事件
close：  连接断开时触发。如果回调函数的参数是布尔值,值是true则表示是因为传输错误导致的连接断开
timeout：提示用户,socket已经空闲超时,需要手动关闭连接
drain：  当调用socket.write方法时,会发送数据,内部有个缓冲区,每次清空缓冲区后都会产生drain事件
lookup： 域名解析完成时触发
end：    当另一端socket调用end()方法即发送FIN包时触发。
         默认情况下(allowHalfOpen == false),socket会完成自我销毁操作。但也可以把allowHalfOpen设置为true,这样就可以继续往socket里写数据,当然最后需要手动调用socket.end()

----------------------------------------------------------------------------------

net.connect(options[, connectionListener])
返回一个新的 'net.Socket',并连接到指定的地址和端口.
当socket建立的时候,将会触发'connect'事件

net.createConnection(options[, connectionListener])
建一个到端口port和主机host的TCP连接
参数host默认'localhost'

net.connect(port[, host][, connectListener])
创建一个端口为port和主机为host的TCP连接
参数host默认为 'localhost'.参数connectListener将会作为监听器添加到'connect'事件.返回'net.Socket'

net.createConnection(port[, host][, connectListener])
创建一个端口为port和主机为host的TCP连接
参数host 默认为'localhost'.参数connectListener将会作为监听器添加到'connect'事件.返回'net.Socket'

net.connect(path[, connectListener])
创建连接到path的unix socket
参数connectListener将会作为监听器添加到'connect'事件上.返回'net.Socket'

net.createConnection(path[, connectListener])
创建连接到 ath的unix socket
参数connectListener将会作为监听器添加到'connect'事件.返回'net.Socket'

net.isIP(input)    检测输入的是否为IP地址,IPV4返回4,IPV6返回6,其他情况返回0
net.isIPv4(input)  如果输入的地址为IPV4,返回true,否则返回false
net.isIPv6(input)  如果输入的地址为IPV6,返回true,否则返回false

【 net.Server通常用于创建一个 TCP 或本地服务器 】
server.listen(port[, host][, backlog][, callback])
监听指定端口port和主机host连接
默认情况下host接受任何IPv4地址(INADDR_ANY)的直接连接.端口port为0时则会分配一个随机端口

server.listen(path[, callback])    通过指定path的连接,启动一个本地socket服务器

server.listen(handle[, callback])  通过指定句柄连接

server.listen(options[, callback])
options的属性：端口port, 主机host, 和backlog, 以及可选参数callback函数, 他们在一起调用server.listen(port, [host], [backlog], [callback]).还有参数path可以用来指定UNIX socket

server.close([callback])
服务器停止接收新的连接,保持现有连接.这是异步函数,当所有连接结束的时候服务器会关闭,并会触发'close'事件

server.address()      操作系统返回绑定的地址,协议族名和服务器端口

server.unref()        如果这是事件系统中唯一一个活动的服务器,调用unref将允许程序退出

server.ref()
与unref相反,如果这是唯一的服务器,在之前被unref了的服务器上调用ref将不会让程序退出(默认行为).如果服务器已经被 ref,则再次调用ref并不会产生影响

server.getConnections(callback)
异步获取服务器当前活跃连接的数量.当socket发送给子进程后才有效;回调函数有2个参数err和count

【 事件 】
listening   当服务器调用 server.listen 绑定后会触发.
connection  当新连接创建后会被触发.socket 是 net.Socket实例.
close       服务器关闭时会触发.注意,如果存在连接,这个事件不会被触发直到所有的连接关闭.
error       发生错误时触发.'close' 事件将被下列事件直接调用

【 net.Socket 】
net.Socket 对象是 TCP 或 UNIX Socket 的抽象.net.Socket 实例实现了一个双工流接口. 他们可以在用户创建客户端(使用 connect())时使用, 或者由 Node 创建它们,并通过 connection 服务器事件传递给用户.

【 net.Socket事件 】
1 lookup  在解析域名后,但在连接前,触发这个事件.对 UNIX sokcet 不适用.
2 connect 成功建立 socket 连接时触发.
3 data    当接收到数据时触发.
4 end     当 socket 另一端发送 FIN 包时,触发该事件.
5 timeout 当 socket 空闲超时时触发,仅是表明 socket 已经空闲.用户必须手动关闭连接.
6 drain   当写缓存为空得时候触发.可用来控制上传.
7 error   错误发生时触发.
8 close   当 socket 完全关闭时触发.参数 had_error 是布尔值,它表示是否因为传输错误导致 socket 关闭.

【 net.Socket 提供了很多有用的属性,便于控制 socket 交互 】
1 socket.bufferSize      该属性显示了要写入缓冲区的字节数.
2 socket.remoteAddress   远程的 IP 地址字符串,例如：'74.125.127.100' or '2001:4860:a005::68'.
3 socket.remoteFamily    远程IP协议族字符串,比如 'IPv4' or 'IPv6'.
4 socket.remotePort      远程端口,数字表示,例如：80 or 21.
5 socket.localAddress    网络连接绑定的本地接口 远程客户端正在连接的本地 IP 地址,字符串表示.例如,如果你在监听'0.0.0.0'而客户端连接在'192.168.1.1',这个值就会是 '192.168.1.1'.
6 socket.localPort       本地端口地址,数字表示.例如：80 or 21.
7 socket.bytesRead       接收到得字节数.
8 socket.bytesWritten    发送的字节数.

【 方法 】
new net.Socket([options])
构造一个新的 socket 对象

socket.connect(port[, host][, connectListener])
指定端口port和主机host,创建socket连接,连接服务器
参数host默认localhost
参数connectListener是connect事件监听器,连接建立触发connect事件,连接失败时触发error事件

socket.connect(path[, connectListener])
打开指定路径的 unix socket.通常情况不需要使用 net.createConnection 打开 socket.只有你实现了自己的 socket 时才会用到

socket.setEncoding([encoding])
设置编码

socket.write(data[, encoding][, callback])
在socket上发送数据.二个参数指定了字符串的编码,默认是UTF8

socket.end([data][, encoding])
半关闭 socket.例如,它发送一个 FIN 包.可能服务器仍在发送数据.

socket.destroy()
确保没有 I/O 活动在这个套接字上.只有在错误发生情况下才需要.(处理错误等等).

socket.pause()
暂停读取数据.就是说,不会再触发 data 事件.对于控制上传非常有用.

socket.resume()
调用 pause() 后想恢复读取数据

socket.setTimeout(timeout[, callback])
socket 闲置时间超过 timeout 毫秒后 ,将 socket 设置为超时.

socket.setNoDelay([noDelay])
禁用纳格(Nagle)算法.默认情况下 TCP 连接使用纳格算法,在发送前他们会缓冲数据.将 noDelay 设置为 true 将会在调用 socket.write() 时立即发送数据.noDelay 默认值为 true.

socket.setKeepAlive([enable][, initialDelay])
禁用/启用长连接功能,并在发送第一个在闲置 socket 上的长连接 probe 之前,可选地设定初始延时.默认为 false. 设定 initialDelay (毫秒),来设定收到的最后一个数据包和第一个长连接probe之间的延时.将 initialDelay 设为0,将会保留默认(或者之前)的值.默认值为0.

socket.address()
操作系统返回绑定的地址,协议族名和服务器端口.返回的对象有3个属性,如{ port:12346,family:'IPv4',address: '127.0.0.1'}

socket.unref()
如果这是事件系统中唯一一个活动的服务器,调用 unref 将允许程序退出.如果服务器已被 unref,则再次调用 unref 并不会产生影响

socket.ref()
与 unref 相反,如果这是唯一的服务器,在之前被 unref 了的服务器上调用 ref 将不会让程序退出(默认行为).如果服务器已经被 ref,则再次调用 ref 并不会产生影响

</pre><pre class="js">
/* 数据量过大,客户端被强制断开连接,先触发end undefined,后触发close flase;服务端没影响,触发 close false*/
/* 设置超时,客户端被强制断开连接;服务端没影响,触发 close false */

// server.js
var net = require('net');
var server = net.createServer();
server.on("connection",socket => {
  console.log("有新的连接");
  socket.write("警告：10秒空闲就会被踢出！")
  socket.setTimeout(10*1000, () => {
   socket.write("踢出！！");
   socket.destroy();
  })
  socket.on("data",data => {
    if(socket.bytesRead > 500*1024){
      socket.pause();
      socket.write("数据量大于500K,3秒内自动关闭socket连接,您将会被踢出！");
      setTimeout(() => socket.destroy(),3000);
    }
  })
  socket.on('close', err => console.log('close', err))      // 触发
  socket.on('error', err => console.log('error', err))
  socket.on('end', err => console.log('end', err))
})
server.listen(8888, () => console.log('服务器已启动！'));

// client.js
var net = require('net');
var fs = require("fs");
var filedata = fs.readFileSync(__dirname+"/../stream/luky.mp4");
var socket = net.connect(8888,"localhost",() => socket.write(filedata));
socket.on('data', data => console.log(data.toString()));
socket.on('close', err => console.log('close', err))      // 后触发close flase
socket.on('error', err => console.log('error', err))
socket.on('end', err => console.log('end', err))          // 先触发end undefined

</pre>
</div>

<!-- ---------------http------------------------------ -->
<div id="http">
<h2>Node.js自带的http模块</h2><pre>
浏览器访问服务端时,除了请求目标资源之外,还会自动请求 /favicon.ico
浏览器后退按钮不会发起请求

Web服务器的基本功能是提供Web信息浏览服务,只需支持HTTP协议、HTML文档格式及URL,与客户端的网络浏览器配合
目前最主流的三个Web服务器是Apache、Nginx、IIS

Web应用架构
Client
客户端,一般指浏览器,浏览器可以通过HTTP协议向服务器请求数据.mobile browser/web browser/application
Server
服务端,一般指Web服务器,可以接收客户端请求,并向客户端发送响应数据.web server
Business
业务层,通过Web服务器处理应用程序,如与数据库交互,逻辑运算,调用外部程序等.application server/file system
Data
数据层,一般由数据库组成.database/external system

Server会监听端口,而Client去访问端口,形成服务器和客户端的交互
Unix/Linux系统跟 windows不同,可以去监听端口,也可以去监听文件,即可以把端口和文件都当做对外交流的摊铺。那么Client 可以通过访问一个文件与Server建立起 pipe

</pre>

<h3>https模块</h3><pre>
HTTPS是HTTP基于TLS/SSL的版本
http tcp ip
http ssl/tls tcp ip

</pre><pre class="js">
//https.js
const https = require('https');
const fs = require('fs');

const options = {
  key: fs.readFileSync('test/fixtures/keys/agent2-key.pem'),   // 用来加密和解密
  cert: fs.readFileSync('test/fixtures/keys/agent2-cert.pem')
};

https.createServer(options, (req, res) => {
  res.writeHead(200);
  res.end('hello world\n');
}).listen(8000);

</pre>

<h3>http模块</h3><pre>
net.createServer建立的服务器浏览器无法连接,因为http模型可以处理http请求响应,而net是很低级的数据的传输,http模块都已封装好复杂的http协议的解析

http客户端发起请求,创建端口
http服务器在端口监听客户端请求
http服务器向客户端返回状态和内容(错误信息,json数据,HTML文件等)

域名解析
chrome搜索自身DNS缓存,看有没有某域名缓存,有缓存的话有没有过期 chrome://net-internals/#dns
搜索操作系统的DNS缓存
读取本地HOST文件
浏览器发起一个DNS的一个系统调用

宽带运营服务商查看本身缓存
运营服务商发起一个迭代DNS解析的请求
运营服务商把结果返回操作系统内核,同时缓存起来
操作系统把结果返回浏览器
最终浏览器拿到了url对应的ip地址

tcp请求
浏览器获得域名对应的ip地址后发起http三次握手

tcp/ip连接建立起来之后,浏览器就可以向服务器发送http请求了
服务器接收请求之后,根据路径参数,经过后端处理把处理后的结果数据返回给浏览器
浏览器接收数据,解析渲染页面

</pre><pre class="js">
C:\Users\lenovo>node
> http

</pre><pre class="js">
const http = require('http')
const server = http.createServer((req, res) => {
  res.statusCode = 200
  res.setHeader('Content-Type', 'text/plain')
  res.end('Hello World\n')
})

server.listen(8888, '127.0.0.1', () => console.log(`Server running at http://${hostname}:${port}/`))

</pre><pre>
server服务器对象是http.Server实例,http.Server是net.Server的子类
incomingMsg 传入的信息(请求信息)对象是http.IncomingMessage实例
response    响应对象是http.ServerResponse实例

</pre><pre class="js">
// http.server继承net.server的属性和方法

const http = require('http');
const util = require('util');
const server = http.createServer((req, res) => {
  if(req.url == '/favicon.ico') return;
  res.end('ok');
  console.log(require('util').inspect(server, true));
  console.log(server.address());
  server.getConnections((err, count) => {
    if(err) return console.log(err);
    console.log(count);
  })
}).listen(8888, () => console.log('server start on localhost:8888'))

/*
Server {
  domain: null,
  _events:
   { request: { [Function] [length]: 2, [name]: '' },
     connection:
      { [Function: connectionListener]
        [length]: 1,
        [name]: 'connectionListener',
        [prototype]: [Object] } },
  _eventsCount: 2,
  _maxListeners: undefined,
  _connections: 1,
  [connections]: [Getter/Setter],
  _handle:
   TCP {
     reading: false,
     owner: [Circular],
     onread: null,
     onconnection: { [Function: onconnection] [length]: 2, [name]: 'onconnection', [prototype]: [Object] },
     writeQueueSize: 0 },
  _usingSlaves: false,
  _slaves: [ [length]: 0 ],
  _unref: false,
  allowHalfOpen: true,
  pauseOnConnect: false,
  httpAllowHalfOpen: false,
  timeout: 120000,
  keepAliveTimeout: 5000,
  _pendingResponseData: 0,
  maxHeadersCount: null,
  _connectionKey: '6::::8888',
  [Symbol(asyncId)]: 6 }
{ address: '::', family: 'IPv6', port: 8888 }
1
*/

</pre>
</div>

<div id="reqresfield">
<h3>常见请求头响应头字段</h3><pre>
-----常用标准请求头字段-----

Accept 设置接受的内容类型
Accept: text/plain

Accept-Charset 设置接受的字符编码
Accept-Charset: utf-8

Accept-Encoding 设置接受的编码格式
Accept-Encoding: gzip, deflate

Accept-Datetime 设置接受的版本时间
Accept-Datetime: Thu, 31 May 2007 20:35:00 GMT

Accept-Language 设置接受的语言
Accept-Language: en-US

Authorization 设置HTTP身份验证的凭证
Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==

Cache-Control 设置请求响应链上所有的缓存机制必须遵守的指令
Cache-Control: no-cache

Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项
Connection: keep-alive
Connection: Upgrade

Content-Length 设置请求体的字节长度
Content-Length: 348

Content-MD5 设置基于MD5算法对请求体内容进行Base64二进制编码
Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==

Content-Type 设置请求体的MIME类型(适用POST和PUT请求)
Content-Type: application/x-www-form-urlencoded

Cookie 设置服务器使用Set-Cookie发送的http cookie
Cookie: $Version=1; Skin=new;

Date 设置消息发送的日期和时间
Date: Tue, 15 Nov 1994 08:12:31 GMT

Expect 标识客户端需要的特殊浏览器行为
Expect: 100-continue

Forwarded 披露客户端通过http代理连接web服务的源信息
Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43
Forwarded: for=192.0.2.43, for=198.51.100.17

From 设置发送请求的用户的email地址
From: user@example.com

Host 设置服务器域名和TCP端口号,如果使用的是服务请求标准端口号,端口号可以省略
Host: en.wikipedia.org:8080
Host: en.wikipedia.org

If-Match 设置客户端的ETag,当时客户端ETag和服务器生成的ETag一致才执行,适用于更新自从上次更新之后没有改变的资源
If-Match: "737060cd8c284d8af7ad3082f209582d

If-Modified-Since 设置更新时间,从更新时间到服务端接受请求这段时间内如果资源没有改变,允许服务端返回304 Not Modified
If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT

If-None-Match 设置客户端ETag,如果和服务端接受请求生成的ETage相同,允许服务端返回304 Not Modified
If-None-Match: "737060cd8c284d8af7ad3082f209582d"

If-Range 设置客户端ETag,如果和服务端接受请求生成的ETage相同,返回缺失的实体部分;否则返回整个新的实体
If-Range: "737060cd8c284d8af7ad3082f209582d"

If-Unmodified-Since 设置更新时间,只有从更新时间到服务端接受请求这段时间内实体没有改变,服务端才会发送响应
If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT

Max-Forwards 限制代理或网关转发消息的次数
Max-Forwards: 10

Origin 标识跨域资源请求(请求服务端设置Access-Control-Allow-Origin响应字段)
Origin: http://www.example-social-network.com

Pragma 设置特殊实现字段,可能会对请求响应链有多种影响
Pragma: no-cache

Proxy-Authorization 为连接代理授权认证信息
Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==

Range 请求部分实体,设置请求实体的字节数范围,具体可以参见HTTP/1.1中的Byte serving
Range: bytes=500-999

Referer 设置前一个页面的地址,并且前一个页面中的连接指向当前请求,意思就是如果当前请求是在A页面中发送的,那么referer就是A页面的url地址(轶事：这个单词正确的拼法应该是"referrer",但是在很多规范中都拼成了"referer",所以这个单词也就成为标准用法)
Referer: http://en.wikipedia.org/wiki/Main_Page

TE 设置用户代理期望接受的传输编码格式,和响应头中的Transfer-Encoding字段一样
TE: trailers, deflate

Upgrade 请求服务端升级协议
Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket

User-Agent 用户代理的字符串值
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0

Via 通知服务器代理请求
Via: 1.0 fred, 1.1 example.com (Apache/1.1)

Warning 实体可能会发生的问题的通用警告
Warning: 199 Miscellaneous warning

-----常用非标准请求头字段-----

X-Requested-With 标识Ajax请求,大部分js框架发送请求时都会设置它为XMLHttpRequest
X-Requested-With: XMLHttpRequest

DNT 请求web应用禁用用户追踪
DNT: 1 (Do Not Track Enabled)
DNT: 0 (Do Not Track Disabled)

X-Forwarded-For 一个事实标准,用来标识客户端通过HTTP代理或者负载均衡器连接的web服务器的原始IP地址
X-Forwarded-For: client1, proxy1, proxy2
X-Forwarded-For: 129.78.138.66, 129.78.64.103

X-Forwarded-Host 一个事实标准,用来标识客户端在HTTP请求头中请求的原始host,因为主机名或者反向代理的端口可能与处理请求的原始服务器不同
X-Forwarded-Host: en.wikipedia.org:8080
X-Forwarded-Host: en.wikipedia.org

X-Forwarded-Proto 一个事实标准,用来标识HTTP原始协议,因为反向代理或者负载均衡器和web服务器可能使用http,但是请求到反向代理使用的是https
X-Forwarded-Proto: https

Front-End-Https 微软应用程序和负载均衡器使用的非标准header字段 Front-End-Https: on
X-Http-Method-Override 请求web应用时,使用header字段中给定的方法(通常是put或者delete)覆盖请求中指定的方法(通常是post),如果用户代理或者防火墙不支持直接使用put或者delete方法发送请求时,可以使用这个字段
X-HTTP-Method-Override: DELETE

X-ATT-DeviceId 允许更简单的解析用户代理在AT&T设备上的MakeModel/Firmware
X-Att-Deviceid: GT-P7320/P7320XXLPG

X-Wap-Profile 设置描述当前连接设备的详细信息的xml文件在网络中的位置
x-wap-profile: http://wap.samsungmobile.com/uaprof/SGH-I777.xml

Proxy-Connection 早起HTTP版本中的一个误称,现在使用标准的connection字段
Proxy-Connection: keep-alive

X-UIDH 服务端深度包检测插入的一个唯一ID标识Verizon Wireless的客户
X-UIDH: ...

X-Csrf-Token,X-CSRFToken,X-XSRF-TOKEN 防止跨站请求伪造
X-Csrf-Token: i8XNjC4b8KVok4uw5RftR38Wgp2BFwql

X-Request-ID,X-Correlation-ID 标识客户端和服务端的HTTP请求
X-Request-ID: f058ebd6-02f7-4d3f-942e-904344e8cde5

-----常用标准响应头字段-----

Access-Control-Allow-Origin 指定哪些站点可以参与跨站资源共享
Access-Control-Allow-Origin: *

Accept-Patch 指定服务器支持的补丁文档格式,适用于http的patch方法
Accept-Patch: text/example;charset=utf-8

Accept-Ranges 服务器通过byte serving支持的部分内容范围类型
Accept-Ranges: bytes

Age 对象在代理缓存中暂存的秒数
Age: 12

Allow 设置特定资源的有效行为,适用方法不被允许的http 405错误
Allow: GET, HEAD

Alt-Svc 服务器使用"Alt-Svc"(Alternative Servicesde的缩写)头标识资源可以通过不同的网络位置或者不同的网络协议获取
Alt-Svc: h2="http2.example.com:443"; ma=7200

Cache-Control 告诉服务端到客户端所有的缓存机制是否可以缓存这个对象,单位是秒
Cache-Control: max-age=3600

Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项
Connection: close

Content-Disposition 告诉客户端弹出一个文件下载框,并且可以指定下载文件名
Content-Disposition: attachment; filename="fname.ext"

Content-Encoding 设置数据使用的编码类型
Content-Encoding: gzip

Content-Language 为封闭内容设置自然语言或者目标用户语言
Content-Language: en

Content-Length 响应体的字节长度
Content-Length: 348

Content-Location 设置返回数据的另一个位置
Content-Location: /index.htm

Content-MD5 设置基于MD5算法对响应体内容进行Base64二进制编码
Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==

Content-Range 标识响应体内容属于完整消息体中的那一部分
Content-Range: bytes 21010-47021/47022

Content-Type 设置响应体的MIME类型
Content-Type: text/html; charset=utf-8

Date 设置消息发送的日期和时间
Date: Tue, 15 Nov 1994 08:12:31 GMT

ETag 特定版本资源的标识符,通常是消息摘要
ETag: "737060cd8c284d8af7ad3082f209582d"

Expires 设置响应体的过期时间
Expires: Thu, 01 Dec 1994 16:00:00 GMT

Last-Modified 设置请求对象最后一次的修改日期
Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT

Link 设置与其他资源的类型关系
Link: < /feed>; rel="alternate"

Location 在重定向中或者创建新资源时使用
Location: http://www.w3.org/pub/WWW/People.html

P3P 以P3P:CP="your_compact_policy"的格式设置支持P3P(Platform for Privacy Preferences Project)策略,大部分浏览器没有完全支持P3P策略,许多站点设置假的策略内容欺骗支持P3P策略的浏览器以获取第三方cookie的授权

P3P: CP="This is not a P3P policy! See http://www.google.com/support/accounts/bin/answer.py?hl=en&answer=151657 for more info."

Pragma 设置特殊实现字段,可能会对请求响应链有多种影响
Pragma: no-cache

Proxy-Authenticate 设置访问代理的请求权限
Proxy-Authenticate: Basic

Public-Key-Pins 设置站点的授权TLS证书
Public-Key-Pins: max-age=2592000; pin-sha256="E9CZ9INDbd+2eRQozYqqbQ2yXLVKB9+xcprMF+44U1g=";

Refresh "重定向或者新资源创建时使用,在页面的头部有个扩展可以实现相似的功能,并且大部分浏览器都支持
< meta http-equiv="refresh" content="5; url=http://example.com/">
Refresh: 5; url=http://www.w3.org/pub/WWW/People.html

Retry-After 如果实体暂时不可用,可以设置这个值让客户端重试,可以使用时间段(单位是秒)或者HTTP时间
Example 1: Retry-After: 120
Example 2: Retry-After: Fri, 07 Nov 2014 23:59:59 GMT

Server 服务器名称
Server: Apache/2.4.1 (Unix)

Set-Cookie 设置HTTP Cookie
Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1

Status 设置HTTP响应状态
Status: 200 OK

Strict-Transport-Security 一种HSTS策略通知HTTP客户端缓存HTTPS策略多长时间以及是否应用到子域
Strict-Transport-Security: max-age=16070400; includeSubDomains

Trailer 标识给定的header字段将展示在后续的chunked编码的消息中
Trailer: Max-Forwards

Transfer-Encoding 设置传输实体的编码格式,目前支持的格式： chunked, compress, deflate, gzip, identity
Transfer-Encoding: chunked

TSV Tracking Status Value,在响应中设置给DNT(do-not-track),可能的取值
  "!" — under construction
  "?" — dynamic
  "G" — gateway to multiple parties
  "N" — not tracking
  "T" — tracking
  "C" — tracking with consent
  "P" — tracking only if consented
  "D" — disregarding DNT
  "U" — updated
TSV: ?

Upgrade 请求客户端升级协议
Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket

Vary 通知下级代理如何匹配未来的请求头已让其决定缓存的响应是否可用而不是重新从源主机请求新的
Example 1: Vary: *
Example 2: Vary: Accept-Language

Via 通知客户端代理,通过其要发送什么响应
Via: 1.0 fred, 1.1 example.com (Apache/1.1)

Warning 实体可能会发生的问题的通用警告
Warning: 199 Miscellaneous warning

WWW-Authenticate 标识访问请求实体的身份验证方案
WWW-Authenticate: Basic

X-Frame-Options 点击劫持保护：
  deny frame中不渲染
  sameorigin 如果源不匹配不渲染
  allow-from 允许指定位置访问
  allowall 不标准,允许任意位置访问
X-Frame-Options: deny

-----常用非标准响应头字段-----

X-XSS-Protection 过滤跨站脚本
X-XSS-Protection: 1; mode=block

Content-Security-Policy, X-Content-Security-Policy,X-WebKit-CSP 定义内容安全策略
X-WebKit-CSP: default-src 'self'

X-Content-Type-Options 唯一的取值是"",阻止IE在响应中嗅探定义的内容格式以外的其他MIME格式
X-Content-Type-Options: nosniff

X-Powered-By 指定支持web应用的技术
X-Powered-By: PHP/5.4.0

X-UA-Compatible 推荐首选的渲染引擎来展示内容,通常向后兼容,也用于激活IE中内嵌chrome框架插件
< meta http-equiv="X-UA-Compatible" content="chrome=1" />
X-UA-Compatible: IE=EmulateIE7
X-UA-Compatible: IE=edge
X-UA-Compatible: Chrome=1

X-Content-Duration 提供音视频的持续时间,单位是秒,只有Gecko内核浏览器支持
X-Content-Duration: 42.666

Upgrade-Insecure-Requests 标识服务器是否可以处理HTTPS协议
Upgrade-Insecure-Requests: 1

X-Request-ID,X-Correlation-ID 标识一个客户端和服务端的请求
X-Request-ID: f058ebd6-02f7-4d3f-942e-904344e8cde5

</pre>
</div>

<div id="server">
<!-- -----------server对象----------------------------------- -->
<h3>http.Server server对象</h3>
<h4>http.Server server对象的属性方法</h4><pre>
✈ server.listen(port, [hostname], [backlog], [callback])
port     打开一个服务器端的监听端口,0表示由系统分配一个随机端口
host     表示主机名,设置localhost或127.0.0.1
backlog  表示同时访问的最大数,默认511。
callback 回调函数,http server已经准备妥当时调用

✈ server.close([callback])
同net.Server的server对象

✈ server.setTimeout(msecs,callback)
设置客户端空闲超时的监听器,不是设置服务器超时,而是指客户端与服务器建立的socket超时。
msecs以毫秒为单位
callback(socket) 是超时监听器,监听器会获得一个socket参数
server.timeout值默认是120000毫秒

</pre><pre class="js">
var http = require("http");
var Socket = require("net").Socket;
var server = http.createServer();
server.on("request",function(req,res){
  //res.end();这里不调用res.end从而模拟超时
})
server.timeout = 3000;
server.on("timeout",function(s){
  console.log(s instanceof Socket) // true
})
server.listen(8080);

// 第二种写法

var http = require("http");
var Socket = require("net").Socket;
var server = http.createServer();
server.on("request",function(req,res){
  //res.end();
})
server.setTimeout(5000,function(s){
  console.log(s instanceof Socket) // true
})
server.listen(8080)

</pre>

<h4>http.Server server对象的事件</h4><pre>
http.Server是一个基于事件的服务器,继承自EventEmitter

✈ request事件
当客户端请求到来时触发,提供两个参数req和res,事件的监听器可接收两个参数,incomingMessage和responsehttp.createServer(function(incomingMsg,response)...) 也是加入一个监听器
server.on('request', (msg, response) => { })

✈ connection事件
当TCP连接建立时触发,提供一个参数socket,是net.Socket的实例
监听器会接收到一个socket,和net.Server一致,也可通过incomingMessage.socket得到
server.on('connection', socket => { })

✈ close事件
当服务器关闭时触发事件,不是在用户断开连接时触发
server.on('close', () => { })

✈ clientError事件
客户端出现异常时抛出,这里的异常并不能通过request.destroy来模拟,只能通过throw抛出异常来模拟

</pre><pre class="js">
// 服务器
var http = require("http");
var server = http.createServer();
server.on("clientError",function(exception,socket){  // exception是异常原因,socket是抛出异常的socket
 console.log("客户端有错误")
})
server.listen(8080)

// 客户端
var http = require("http");
var req = http.request(8080)
setTimeout(function(){
 throw new Error(); // 抛出异常
},1000);

</pre><pre>
✈ upgrade事件
当请求头部信息有upgrade属性时产生,如html5 websocket协议,客户端const socket = new WebSocket('ws://localhost:8080');时触发

request < http.IncomingMessage> HTTP请求的参数,与request事件中的一样。
socket < stream.Duplex> 服务器与客户端之间的网络套接字。
head < Buffer> 升级后的流的第一个数据包(可能为空)。

每次客户端请求HTTP升级时发出,监听此事件是可选的,客户端无法坚持更改协议。
触发此事件后,请求的套接字将没有data事件监听器,这意味着它需要绑定才能处理发送到该套接字上的服务器的数据。
此事件保证传入< net.Socket> 类(< stream.Duplex>的子类)的实例,除非用户指定了< net.Socket>以外的套接字类型

✈ checkContinue事件
当客户端发送Expect:100-continue请求时产生的事件,客户端是先要请求一下服务器是否同意继续发送主体内容

✈ connect事件
当客户请求方法是"CONNECT"时会产生的事件
CONNECT方法并不是浏览器支持的,所以浏览器访问就不会被接收到

</pre><pre class="js">
// 服务器
var http = require("http");
var server = http.createServer();
server.on("connect",function(req,socket,head){
   ......
})
server.listen(8080)

// 客户端
var http = require("http");
var req = http.request({port:8080, method:"CONNECT"},res => {
    ......
})
req.end();


</pre><pre>
request事件的参数req和res分别是http.IncomingMessage和http.ServerResponse的实例

http.IncomingMessage是HTTP请求的信息,是后端开发者最关注的内容,一般由http.Server的request事件发送,并作为第一个参数传递,http请求一般可以分为两部分：请求头和请求体,其提供了3个事件
1、data：当请求体数据到来时,该事件被触发,该事件提供一个参数chunk,表示接受的数据,如果该事件没有被监听,则请求体会被抛弃,该事件可能会被调用多次(这与nodejs是异步的有关系)
2、end：当请求体数据传输完毕时,该事件会被触发,此后不会再有数据
3、close：用户当前请求结束时,该事件被触发,不同于end,如果用户强制终止了传输,也是用close

http.ServerResponse是返回给客户端的信息,决定了用户最终看到的内容,一般也由http.Server的request事件发送,并作为第二个参数传递,它有三个重要的成员函数,用于返回响应头、响应内容以及结束请求

</pre><pre class="js">
var http = require('http');
http.createServer(function (request, response) {
  response.writeHead(200, {'Content-Type': 'text/plain'});
  response.end('Hello World\n');
}).listen(8888);
console.log('Server running at http://127.0.0.1:8888/');

</pre><pre class="js">
var http = require('http');
var server = http.createServer();
server.on("request",function(req,res){
  fs.createReadStream("hello.html").pipe(res);
})

</pre><pre class="js">
var http=require("http");
var server=new http.Server();
server.on("request",function(req,res){
  res.writeHead(200,{"content-type":"text/plain"});
  res.write("hello nodejs");
  res.end();
});
server.listen(8888);

</pre><pre class="js">
/* path 模块应用及301重定向 */

if(path.extname(pathName) === ''){                    //如果路径中没有扩展名
  if (pathName.charAt(pathName.length-1) != "/"){   //如果不是以/结尾的,加/并作301重定向
    pathName += "/";
    var redirect = "http://"+request.headers.host + pathName;
    response.writeHead(301, { location:redirect });
    response.end();
  }
  pathName += "index.html";      //添加默认的访问页面,但这个页面不一定存在,后面会处理
  hasExt = false;                //标记默认页面是程序自动添加的
}

/* fs读取文件列表及404页面 */
fs.exists(filePath,function(exists){
  if(exists){
    response.writeHead(200, {"content-type":contentType});
    var stream = fs.createReadStream(filePath,{flags:"r",encoding:null});
    stream.on("error", function() {
      response.writeHead(500,{"content-type": "text/html"});
      response.end("<h1>500 Server Error</h1>");
    });
    stream.pipe(response);    //返回文件内容
  }else {                       //文件名不存在的情况
    if(hasExt){               //如果这个文件不是程序自动添加的,直接返回404
      response.writeHead(404, {"content-type": "text/html"});
      response.end("<h1>404 Not Found</h1>");
    }else{
      //如果文件是程序自动添加的且不存在,则表示用户希望访问的是该目录下的文件列表
      var html = "< head>< meta charset='utf-8'></ head>";
      try{
        //用户访问目录
        var filedir = filePath.substring(0,filePath.lastIndexOf('\\'));
        //获取用户访问路径下的文件列表
        var files = fs.readdirSync(filedir);
        //将访问路径下的所以文件一一列举出来,并添加超链接,以便用户进一步访问
        for(var i in files){
          var filename = files[i];
          html += "<div><a  href='"+filename+"'>"+filename+"</a></div>";
        }
      }catch (e){
        html += "<h1>您访问的目录不存在</h1>"
      }
      response.writeHead(200, {"content-type": "text/html"});
      response.end(html);
    }
  }
});

</pre><pre class="js">
var http = require('http');
var server = http.createServer(function(req,res){
  if(req.url == '/'){                             //请求主页
    res.writeHead(200,{ 'Content-type':"text/html"});
    res.write('< meta http-equiv="Content-Type" content="text/html; charset=utf-8" />' +'床前明月光');
    res.end();
  }else {
    res.writeHead(404,{ 'Content-type':"text/html"});
    res.write('< meta http-equiv="Content-Type" content="text/html; charset=utf-8" />' +'错误404：网页没找到');
    res.end();
  }
});
server.listen(8888,() => console.info("正在监听8888端口")); //启动Http服务器

</pre><pre class="js">
/*创建服务器*/
var http = require('http');
var fs = require('fs');
var url = require('url');

http.createServer( function (request, response) {                 // 创建服务器
  var pathname = url.parse(request.url).pathname;                // 解析请求,包括文件名
  console.log("Request for " + pathname + " received.");         // 输出请求的文件名
  fs.readFile(pathname.substr(1), function (err, data) {         // 从文件系统中读取请求的文件内容
    if (err) {
      console.log(err);
      response.writeHead(404, {'Content-Type': 'text/html'});
    }else{
      response.writeHead(200, {'Content-Type': 'text/html'});
      response.write(data.toString());                          // 响应文件内容
    }
    response.end();                                              //  发送响应数据
  });
}).listen(8888);
console.log('Server running at http://127.0.0.1:8888/');

</pre>

<h3>http.IncomingMessage类</h3><pre>
http.IncomingMessage类的实例是被动产生的,是服务器端监听到的请求信息或者客户端接收到的响应信息;
可以理解为另一端socket发送来或返回来的数据,所以http.IncomingMessage是stream.Readable的子类,也就是只读的

</pre><pre class="js">
//这里的request就是incomingMessage对象
var server = http.createServer(function(request,response){ ... })

var server = http.createServer();
server.on("request",function(request,response){ ... })

// response 是incomingMessage对象
var request = http.request(options, function(response) { ... })

var request = http.request(options);
request.on("response",function(response){ ... })

var request = http.get(options,function(response){})

</pre>

<h4>http.IncomingMessage实例的事件</h4><pre>
data事件
当接收到数据时触发,事件监听器会接收到数据;如果不对这个事件添加监听器则数据会丢失
incomingMessage.on('data',function(chunk){ ... });  // chunk 是个数据片段,Buffer类型

end事件
以后不会再产生数据时触发,end事件只发生一次
incomingMessage.on('end',function(){ ... })

close事件
这个事件的产生是当服务器端response.end()调用之前客户端关闭造成的

</pre><pre class="js">
// 这里的res.end()不会被调用,当浏览器访问服务器,然后关闭浏览器,这时req就会发出close事件

var http = require("http");
var server = http.createServer();
server.on("request", (req,res) => {
  req.on("close", () => console.log("close"))
  res.write("hello!");
  // res.end();
})
server.listen(8080);

</pre>

<h4>http.IncomingMessage实例的属性</h4><pre>
http.IncomingMessage实例,在server端：获取请求发送方的信息,比如请求方法、路径、传递的数据等。 在client端：获取 server 端发送过来的信息,比如请求方法、路径、传递的数据等

http.IncomingMessage实例有三个属性需要注意：method、statusCode、statusMessage。
method：只在server端的实例有(也就是 serverReq.method)
statusCode/statusMessage：只在client端的实例有(也就是 clientRes.method)

✈ incomingMessage.headers
得到头部信息

</pre><pre class="js">
// nodejs获取客户端IP Address
function getClientIp(req) {
  return req.headers['x-forwarded-for'] ||
  req.connection.remoteAddress ||
  req.socket.remoteAddress ||
  req.connection.socket.remoteAddress;
};

第一段判断是否有反向代理IP(头信息：x-forwarded-for),在判断connection的远程IP,以及后端的socket的IP

var ip = req.headers['x-real-ip'] ? req.headers['x-real-ip']:req.ip.replace(/::ffff:/, '');

</pre><pre class="js">
// 服务器
var http = require("http");
var server = http.createServer();
server.on("request", (req,res) => console.log(req.headers))
server.listen(8080)

</pre><pre>
服务端接收到的请求头信息：
host
客户端指定自己想访问的WEB服务器的域名/IP 地址和端口号。

connection
有两个值
close(告诉WEB服务器或者代理服务器,在完成本次请求的响应后,断开连接,不要等待本次连接的后续请求了
keepalive(告诉WEB服务器或者代理服务器,在完成本次请求的响应后,保持连接,等待本次连接的后续请求)

accept
告诉WEB服务器自己接受什么介质类型,/ 表示任何类型,type/* 表示该类型下的所有子类型,type/sub-type。

user-agent
浏览器表明自己的身份(是哪种浏览器)

accept-encoding
浏览器申明自己接收的编码方法,通常指定压缩方法,是否支持压缩,支持什么压缩方法  (gzip,deflate)

accept-language
浏览器申明自己接收的语言跟字符集的区别。

accept-charset
浏览器申明自己接收的字符集

</pre><pre class="js">
// 客户端
var http = require("http");
var req = http.get("http://www.google.com/", function(res){
  console.log(res.headers)
})

</pre><pre>
【 客户端接收到的响应头信息 】

Cache- Control
指定请求和响应遵循的缓存机制。
在请求消息或响应消息中设置 Cache-Control并不会修改另一个消息处理过程中的缓存处理过程。
请求时的缓存指令包括no-cache、no-store、max-age、 max-stale、min-fresh、only-if-cached,
响应消息中的指令包括public、private、no-cache、no- store、no-transform、must-revalidate、proxy-revalidate、max-age。

各个消息中的指令含义如下：
Public指示响应可被任何缓存区缓存。
Private指示对于单个用户的整个或部分响应消息,不能被共享缓存处理。这允许服务器仅仅描述当用户的部分响应消息,此响应消息对于其他用户的请求无效。
no-cache指示请求或响应消息不能缓存
no-store用于防止重要的信息被无意的发布。在请求消息中发送将使得请求和响应消息都不使用缓存。
max-age指示客户机可以接收生存期不大于指定时间(以秒为单位)的响应。
min-fresh指示客户机可以接收响应时间小于当前时间加上指定时间的响应。
max-stale指示客户机可以接收超出超时期间的响应消息。如果指定max-stale消息的值,那么客户机可以接收超出超时期指定值之内的响应消息。

Location
响应头用于重定向接收者到一个新URI地址。

Content-Type
实体头用于向接收方指示实体的介质类型。

set-cookie
设置和页面关联的Cookie

expires
指定应该在什么时候认为文档已经过期,从而不再缓存它。

server
服务器名字。

content-length
表示内容长度。

x-xss-protection
XSS筛选器,主要用于防御反射型跨站攻击,网站一般都会设置为 0 。googog

x-frame-options
可用于指示是否应该允许浏览器呈现在一个页面FRAME 或 IFRAME 中。 以确保网站内容是不是嵌入到其它网站。使用X-Frame-Options 有两种可能的值：DENY ：该页无法显示在一个框架中。SAMEORIGHT ：页面只能显示在页面本网站的框架中

✈ message.httpVersion
http版本 1.1或1.0,基本都是1.1了

✈ incomingMessage.socket
底层的net.Socket对象

✈ incomingMessage.method
请求方法,这个只存在于请求对象中。 GET/POST

✈ incomingMessage.url
请求url,这只存在于请求对象中

✈ incomingMessage.statusCode
✈ incomingMessage.statusMessage
响应状态代码/状态信息,只存在于响应对象中

</pre><pre class="js">
// 通过浏览器访问 http://localhost:8080/article?id=1221212 , 控制台会打印：/article?id=1221212
var http = require("http");
var server = http.createServer();
server.on("request",function(req,res){
  console.log(req.url)
})
server.listen(8080)


</pre>

<h4>http.IncomingMessage实例的方法</h4><pre>
✈ incomingMessage.setEncoding([encoding])
✈ incomingMessage.pause()
✈ incomingMessage.resume()

</pre>

<h3>ServerResponse响应对象</h3><pre>
之所以叫服务器端响应对象是区别于客户端响应对象的,因为客户端的响应对象res是个IncomingMessage对象,也就是只读对象,而InomingMessage是stream.Readable子类,而服务器端响应对象res是http.ServerResponse对象,是可写对象,而ServerResponse是stream.Writable子类

服务端通过http.ServerResponse实例,来给请求方发送数据,包括发送响应表头、响应主体等

</pre><pre class="js">
// 响应的buffer和string效果相同

http.createServer((req, res) => {
  fs.readFile('form.html', (err, data) => {
    if (err) {
      res.writeHead(500);
      return res.end('Error loading');
    }
    res.writeHead(200, {'Content-Type': 'text/html'});
    if(req.url == 'buffer'){
      res.write(data);
    }else{
      res.write(data.toString());
    }
    res.end();
  });
}).listen(8888, () => console.log('server start on 8888'))

</pre><pre class="js">
// 浏览器页面每秒钟增加一个时间字符串

require('http').createServer(function(req,res){
  console.log(req.url+' '+'connected');
  // 每秒发送一个当前时间
  var itv=setInterval(function(){
    res.write(new Date+'\n');
  },1000);
  // 捕捉客户端断开事件,捕捉连接的关闭事件
  req.connection.on('close',function(){
    console.log(req.url+' '+'disconnected');
    clearInterval(itv);
  });
  // 不释放请求,保持长连接
}).listen(8888);

</pre><pre>
close事件
当客户端非正常关闭所产生的,res.end不会造成close事件
response对象只有一个close事件

</pre><pre class="js">
//由于没有res.end()代码,所以浏览器始终处于等待数据状态,这时关闭浏览器,服务端就有打印出close

var http = require("http");
var server = http.createServer();
server.on("request",function(req,res){
  res.on("close",function(){
    console.log("close")
  })
})
server.listen(8888)

</pre><pre>
【 response.writeHead(statusCode, [reasonPhrase], [headers]) 】
向请求的客户端发送响应头,在发送body主体之前调用,在一个请求中最多调用一次,如果不调用会自动生成一个响应头

参数：
statusCode   状态码,也可通过response.statusCode = 404 设置
  1xx  请求已被接受,需要继续处理
  2xx  请求已成功被服务器接收、理解、并接受
  3xx  重定向
  4xx  请求错误
  5xx  服务器错误。

resonPhrase  字符串,用于简单说明的,比如："服务器因为维护暂时无法正常访问...."
headers      Object对象, 类似关联数组的对象,表示响应头的每个属性,设置响应头信息,
             也可通过response.setHeader(name, value)方式进行设置

当客户端访问的资源不存在时,设置404就不会让服务器崩溃,而浏览器接收到404就知道资源不存在,展示给客户一个不存在的提示页面
if(err){
  console.log(err.message);
  response.statusCode = 404;
}else{
  response.write(data);
}
response.end();

</pre><pre class="js">
var http = require("http");
var server = http.createServer();
server.on("request", (req, res) => {
  var body = new Buffer("你好啊");
  res.writeHead(200,"成功！", { "Content-Length":body.length, "Content-Type":"text/plain"});
  res.write(body,"utf8");
  res.end();
})
server.listen(8080)

</pre><pre class="js">
response.writeHead(200, {'content-Type': 'text/html'});
response.write(`<h3>The page requested: ${pathname}</h3>\n`);  // h3标签会被渲染,\n换行

response.writeHead(200, {'content-Type': 'text/plain'});
response.write(`<h3>The page requested: ${pathname}</h3>\n`);  // h3标签不会被渲染,\n换行

response.write('<h1>hello world</h1>');                        // 不设置响应头也会渲染

</pre><pre>
【 response.write(chunk, [encoding]) 】
和socket.write和stream.write方法很类似,尤其是和request.write使用方法一样
向请求的客户端发送响应内容,chunk是一个buffer或者字符串,如果data是字符串,则需要制定编码方式,默认为utf-8,在res.end调用之前可以多次调用
当调用这个方法时,内部会检查response.headersSent,即判断是否头部信息已经发送出去了,如果没发送就会先发送头部信息,然后再发送chunk数据块

fs.createReadStream(currFile);
  .on("data",(chunk) => res.write(chunk,"binary"));
  .on("end",() => res.end() );

【 response.end([data], [encoding]) 】
和request.end()一致,结束响应,告诉客户端所有消息已经发送,当所有要返回的内容发送完毕时该函数必须被调用一次;若不调用该函数,客户端将永远处于等待状态。

参数：
data      end()执行完毕后要输出的字符,如果指定了data的值,那就意味着在执行完response.end() 之后会接着执行一条response.write(data , encoding);
encoding  对应data的字符编码

【 response.setTimeout(msecs, callback)  】
这个监听器如果被触发 server设置的监听器

</pre><pre class="js">
// 模拟超时时,浏览器请求,一直在等待服务端响应结束,res timeout/server timeout/server timeout
// 取消超时时,server timeout

var http = require("http");
var server = http.createServer();
server.on("request", (req, res) => {
  console.log('有客户端新的请求');
  res.write('hello');
  //res.end();   // 模拟超时
  res.setTimeout(3000, () => console.log("res timeout"));
})
server.setTimeout(10*1000, () => console.log("server timeout"))
server.listen(8080)

</pre><pre>
【 response.headersSent 】
只读属性,表示响应头是否被发送出去了,true/false

</pre><pre class="js">
var http = require("http");
var server = http.createServer();
server.on("request",function(req,res){
  console.log(res.headersSent);        // false
  res.write("hello")
  console.log(res.headersSent);        // true
  res.end();
})
server.listen(8080)

</pre><pre>
【 response.sentDate 】
属性默认是true,表示发送头部时会把发送响应时间信息加入到头部信息中

【 response.setHeader(name, value)  】
【 response.setHeader(name)  】
【 response.removeHeader(name) 】
设置头部,获取和删除头部信息的,这个不同于 response.writeHead方法,这两个方法并没有真的把头部信息发送出去,发送头部信息只能通过调用 response.writeHead或response.write才会发送出去

</pre><pre class="js">
var http = require("http");
var server = http.createServer();
server.on("request",function(req,res){
  var body = new Buffer("hello world");
  res.setHeader("Content-Length",body.length);
  res.setHeader("Content-Type","text/plain");
  console.log(res.headersSent) // false
  res.write(body);
  console.log(res.headersSent) // true
  res.end();
})
server.listen(8080)

</pre><pre>
【 response.resume() 】

response.getHeader(name)
Reads out a header that's already been queued but not sent to the client. Note that the name is case insensitive.

response.getHeaderNames()
Returns an array containing the unique names of the current outgoing headers. All header names are lowercase

response.getHeaders()
response.hasHeader(name)

</pre><pre class="js">
// 静态文件服务器

var http=require('http');
var fs=require('fs');
var url=require('url');
var path=require('path');
var PORT=9090;

//添加MIME类型
var MIME_TYPE = {
  "css": "text/css",
  "gif": "image/gif",
  "html": "text/html",
  "ico": "image/x-icon",
  "jpeg": "image/jpeg",
  "jpg": "image/jpeg",
  "js": "text/javascript",
  "json": "application/json",
  "pdf": "application/pdf",
  "png": "image/png",
  "svg": "image/svg+xml",
  "swf": "application/x-shockwave-flash",
  "tiff": "image/tiff",
  "txt": "text/plain",
  "wav": "audio/x-wav",
  "wma": "audio/x-ms-wma",
  "wmv": "video/x-ms-wmv",
  "xml": "text/xml"
};

var server = http.createServer(serverStatic);
function serverStatic(req,res){
  var filePath = req.url==="/" ? "index.html": "./" + url.parse(req.url).pathname;
  fs.exists(filePath,function(exists){
    if(!exists) return res.end("<h1>404</h1><p>file not found</p>");
    var ext = path.extname(filePath);
    ext = ext ? ext.slice(1) : 'unknown';
    var contentType = MIME_TYPE[ext] || "text/plain";
    fs.readFile(filePath,function(err,data){
      if(err) return res.end("<h1>500</h1>服务器内部错误！");
      res.writeHead(200,{'content-type':contentType});
      res.end(data.toString());
    });
  })
}
server.listen(PORT, ()=>console.log("Server runing at port: " + PORT + "."));

</pre>
</div>

<div id="httpProxy">
<h3>http代理</h3><pre class="js">
// 简单的http代理
'use strict'
const express = require('express');
const request = require('request');
const app = express();

app.use((req, res) => {
  let originalUrl = req.originalUrl;
  req.pipe(request(originalUrl).on('error', err => {})).pipe(res)
}).listen(8888)

</pre>
</div>

<div id="request">
<h3>http客户端</h3><pre>
http模块提供两个函数http.request和http.get,功能是创建http客户端,作为客户端向http服务器发起请求

</pre><pre class="js">
C:\Users\lenovo>node
> request

</pre><pre>
可以利用这个http的request来提交评论获取网站的一些评论接口,通过上面options可以配置请求的headers信息,进行网站的灌水评论
通过这个方法可以写一些网站灌水插件,自动发布网站评论等等！但现在网站大多都有防止灌水的机制

</pre>

<h4>http.request(options[,callback]) 作为客户端向HTTP服务器发起Get或Post请求</h4><pre>
option 类似关联数组的对象或字符串,若是字符串会自动被url.parse()解析;包含以下请求参数：
protocol:    Protocol to use. Defaults to 'http:'.
host:        表示请求网站的域名或IP地址,默认为'localhost'
hostname:    服务器名称,主机名称,优先于host。To support url.parse() hostname is preferred over host.
port:        请求网站的端口,默认80
localAddress:建立网络连接的本地,Local interface to bind for network connections
socketPath:  Unix Domain Socket(Domain套接字路径),Unix Domain Socket (use one of host:port or socketPath)
method:      HTTP请求方法,默认是'GET'
path:        请求的相对于根的路径,默认'/'。QueryString应该包含在其中。例如：/index.html?page=12
headers:     请求头对象
auth:        Basic认证(基本身份验证),这个值将被计算成请求头中的 Authorization 部分
family:      IP address family to use when resolving host and hostname. 4 or 6. When unspecified, both IP v4 and v6 will be used.
agent:       Controls Agent behavior. When an Agent is used request will default to Connection: keep-alive.
  Possible values:
  undefined (default): use http.globalAgent for this host and port.
  Agent object:        explicitly use the passed in Agent.
  false:               opts out of connection pooling with an Agent, defaults request to Connection: close.
keepAliveMsecs

callback:回调,传递一个参数response,为 http.ClientResponse的实例,是一个http.IncomingMessage对象
callback其实就是"response"事件监听器

http.request 返回一个 http.ClientRequest 的实例,ClientRequest对象是stream.Writable子类

其中options可以是带有请求的目的地址的一条字符串或一系用于发起请求的列详细参数,用于对请求进行更精确的控制

callback参数就是回调函数,这个回调函数会接受一个入参,res的入参监听了两个事件,分别是data和end事件,并且还有一个setEncoding方法,并且还有statusCode和headers两个成员属性。res是一个stream.Readable类型的子类的变量,那两个事件监听和setEncoding方法就是继承自这个类型,而那两个成员属性是子类扩展的,http请求Api返回一个可读数据流是很常见的做法。res的真实类型是http.IncomingMessage。

http.request Api是一个异步接口,调用这个Api之后会立即返回一个http.ClientRequest类型变量这个变量可以接受error事件,来对请求异常的情况进行处理。但这时候不会马上发起请求。我们这时候可以设置req的error事件的监听回调,如果是POST请求的话,还可以调用req.write方法来设置请求消息体,然后调用req.end方法来结束此次请求的发送过程。当收到响应时,严格的说是确认接收完响应头时,就会调用callback回调函数,在这个回调函数中,可以通过读取res.statusCode和res.headers获取响应的返回状态码和头部信息,其中头部信息包含了重要的字段content-length,表示响应消息体的总长度。由于响应消息体可能很长,服务端需要把消息体拆分成多个tcp封包来发送,客户端在接收到tcp封包后还要进行消息体的重组,所以这里采用一个数据流对象来对返回的消息体做读取操作,需要注册data和end事件监听,分别处理链路层缓冲区接收了若干字节的消息体封包并且拼接完成回调上层协议处理和tcp连接拆线时的事务

在同步阻塞运行模型的语言中(java, c, python),将远程连接传输过来的数据先缓存在内存里,待接收完整或或缓存了一定长度的数据之后再一次性写入硬盘的做法,以达到减少写磁盘操作次数来提高性能或者延长磁盘寿命的目的。但是如果在每一次从远程连接接中读取到数据之后立即将数据写入硬盘,也不会有什么问题(tcp协议已经帮我们将数据包排好序),这是因为在同步阻塞运行模型中,读tcp连接和写磁盘这两个动作必然不可能同时执行,而是读tcp -> 写磁盘 -> 读tcp -> 写磁盘...这样的串行执行,在上一个操作完成之后,下一个操作才会开始。这样的执行方式也许效率会比较低,但是写入的磁盘的数据并不会混乱

如果不采用一次性写入,在nodejs的异步非阻塞运行机制下,这样存入磁盘的数据会混乱,导致不堪入目的后果
异步非阻塞世界中来,在这个世界中,远程读取的操作是通过事件回调的方式发生的,res的data事件任何一个时间片内都可能触发,你无法预知,无法控制,甚至触发频率都和你无关,那取决于本次连接的带宽。而我们的写磁盘操作fs.appendFile和Nodejs的大部分Api一样是一个异步非阻塞的调用,它会非常快的返回,但是它所执行的写文件操作,则会慢的多,而进程不会阻塞在那里等待这个操作完成。在常识里,远程连接的下载速度比本地硬盘的写入速度要慢,但这并不是绝对的,随着网速的提高,现在一块高速网卡,在高速的网络中带来的下载速度超过一块老旧的机械硬盘的写入速度并非不可能发生。除此之外,即使在较长的一段时间内,网络的平均连接速度并没有快的那么夸张,但是我们知道在tcp/ip协议栈中,链路层下层的网络层中前后两个ip报文的到达时间间隔也是完全无法确定的,有可能它们会在很短的时间间隔内到达,被tcp协议重组之后上抛给应用层协议,在我们的运行环境中以很短的间隔两次触发data事件,而这个间隔并不足够磁盘将前一段数据写入
此时要想写入的数据保持有序不混乱,只能寄希望于机械硬盘的一面只有一个磁头来从物理层面保证原子操作了。但是很可惜我们知道现代机械硬盘每一面至少都有两个磁头。

有着很多java或者c++编程经验的你也许会想在这里加一个同步锁,不过Nodejs作为一个表面宣称的单线程环境(底层的V8引擎肯定还是有多线程甚至多进程调度机制实现的),在语法和Api层面并没有锁这个概念。

所以为了保证最终写入磁盘的数据不混乱,在data事件的回调中不可以再用异步的方式处理数据了,于是有了现在这种先写入缓存列表中,在数据接收完整后再一次性写文件的做法。由于new Buffer(chunk)和fileBuff.push(buffer)都是同步操作,并且执行的速度非常快;即使下一个data事件到来的比这两个操作还要快,由于单线程运行模型的限制,也必须等待这两个操作完成后才会开始第二次回调。所以能保证数据有序的缓存到内存中,再有序的写入硬盘

</pre><pre class="js">
// 异常处理：对req的异常处理和对res的异常处理

// 如果访问的url是需要登录的才能下载的(返回重定向305到登陆界面),可以用http请求模拟浏览器的登陆操作,这里涉及到cookie和session的一些知识

(function() {
  "use strict";
  const http = require("http");
  const fs = require("fs");
  const path = require("path");

  const urlList = [
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-12217.jpg',
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-23215.jpg',
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-3N92.jpg',
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-46362.jpg',
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-51348.jpg',
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-Cb6.jpg',
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-I109.jpg',
  'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-W4S.jpg' ];

/*
作为http.request的回调函数callback,它的声明原型决定的它只可以接受唯一一个参数res,
但是在callback函数中我们需要明确知道下载下来的数据在硬盘上存放的路径,
这个路径取决于startDownloadTask的入参dirName和index。
所以函数getHttpReqCallback就是用于创建一个闭包,将dirName和index的值写入这个闭包中。
其实我们原本并不需要getHttpReqCallback这个函数来显示的返回一个闭包,
而是可以直接使用内联匿名函数的方法实现http.request的callback
这样写的问题在于,一段异步代码强行插入原本连贯的同步代码中,但是后面加入了异常处理的代码,这一块看起来就会非常糟糕了
*/
  function getHttpReqCallback(imgSrc, dirName, index) {
    var fileName = index + "-" + path.basename(imgSrc);
    var callback = function(res) {
      console.log("request: " + imgSrc + " return status: " + res.statusCode);
      // 首先需要获取包体的总长度
      var contentLength = parseInt(res.headers['content-length']);
      var fileBuff = [];
      res.on('data', chunk => fileBuff.push(new Buffer(chunk)));
      res.on('end', () => {
        console.log("end downloading " + imgSrc);
        if (isNaN(contentLength)) {
          console.log(imgSrc + " content length error");
          return;
        }
        var totalBuff = Buffer.concat(fileBuff);
        console.log("totalBuff.length = " + totalBuff.length + " " + "contentLength = " + contentLength);
        // 在end事件的回调中,用接收到的数据总长度和响应头中的包体长度进行比较,验证响应信息是否接收完全
        // 如果收到的响应数据的长度比content-length中标记的短,通常是由于请求超时造成的,在这里我重新发起了一次请求,你也可以根据你的实际情况采取其他的做法
        if (totalBuff.length < contentLength) {
          console.log(imgSrc + " download error, try again");
          startDownloadTask(imgSrc, dirName, index);
          return;
        }
        fs.appendFile(dirName + "/" + fileName, totalBuff, function(err){});
      });
    };

    return callback;
  }

  var startDownloadTask = function(imgSrc, dirName, index) {
    console.log("start downloading " + imgSrc);
    var req = http.request(imgSrc, getHttpReqCallback(imgSrc, dirName, index));
    req.on('error', function(e){
      console.log("request " + imgSrc + " error, try again");
      // 一旦在请求阶段出现异常会自动重新发起请求,也可以在这里自行添加重试次数retryTimes上限
      startDownloadTask(imgSrc, dirName, index);
    });
    req.end();

    // 给请求设置了一个一分钟的超时时间
    // 一旦在一分钟之内下载还没有完成,则会强制终止此次请求,这会立即触发res的end事件
    req.setTimeout(60 * 1000, function() {
      console.log("reqeust " + imgSrc " timeout, abort this reqeust");
      req.abort();
    })
  }

  urlList.forEach(function(item, index, array) {
    startDownloadTask(item, './crawler-pic4/', index);
  })
})();

// 用一个Promise开始重构,Promise封装后的结构更贴近同步代码的思维模式
// 对http.request的调用被放到了Promise的主体里面,而http.request的回调放到了Promise的then函数里
// 进一步的实现了请求的发起和请求结果处理之间的解耦
// 最终的结果就是这样,我们有了三个各自独立的函数：startRequest、solveResponse、solveResData,每一个函数各自处理从请求的发起,到接收响应,到保存最终响应结果中的某一个阶段。由于拆成了3个函数,所以每一个函数的结构都不是很复杂难懂。最后通过一组Promise链式调用将3个实际是并发执行的过程用一个看似串联的结构组织起来

(function() {
  "use strict";
  const http = require("http");
  const fs = require("fs");
  const path = require("path");

  const urlList = [
    "http://content.battlenet.com.cn/wow/media/wallpapers/patch/fall-of-the-lich-king/fall-of-the-lich-king-1920x1080.jpg",
    "http://content.battlenet.com.cn/wow/media/wallpapers/patch/black-temple/black-temple-1920x1200.jpg",
    "http://content.battlenet.com.cn/wow/media/wallpapers/patch/zandalari/zandalari-1920x1200.jpg",
    "http://content.battlenet.com.cn/wow/media/wallpapers/patch/rage-of-the-firelands/rage-of-the-firelands-1920x1200.jpg",
    "http://content.battlenet.com.cn/wow/media/wallpapers/patch/fury-of-hellfire/fury-of-hellfire-3840x2160.jpg",
  ];

  function getHttpReqCallback(imgSrc, dirName, index) {
    var fileName = index + "-" + path.basename(imgSrc);
    var callback = function(res) {
      console.log("request: " + imgSrc + " return status: " + res.statusCode);
      var contentLength = parseInt(res.headers['content-length']);
      var fileBuff = [];
      res.on('data', function (chunk) {
        var buffer = new Buffer(chunk);
        fileBuff.push(buffer);
      });
      res.on('end', function() {
        console.log("end downloading " + imgSrc);
        if (isNaN(contentLength)) {
          console.log(imgSrc + " content length error");
          return;
        }
        var totalBuff = Buffer.concat(fileBuff);
        console.log("totalBuff.length = " + totalBuff.length + " " + "contentLength = " + contentLength);
        if (totalBuff.length < contentLength) {
          console.log(imgSrc + " download error, try again");
          startDownloadTask(imgSrc, dirName, index);
          return;
        }
        fs.appendFile(dirName + "/" + fileName, totalBuff, function(err){});
      });
    };

    return callback;
  }

  var startDownloadTask = function(imgSrc, dirName, index) {

    function startRequest(imgSrc) {
      return new Promise(function(resolve, rej) {
        var req = http.request(imgSrc, resolve);
        req.on('error', function(e){
          console.log("request " + imgSrc + " error, try again");
          startDownloadTask(imgSrc, dirName, index);
        });
        req.end();
      });
    }

    function solveResponse(res) {
      console.log("request: " + imgSrc + " return status: " + res.statusCode);
      var contentLength = parseInt(res.headers['content-length']);
      var fileBuff = [];
      return new Promise(function(resolve, rej){
        res.on('data', function (chunk) {
          var buffer = new Buffer(chunk);
          fileBuff.push(buffer);
        });
        res.on('end', function() {
          resolve({"contentLength": contentLength, "fileBuff": fileBuff})
        });
      });
    }

    function solveResData(data) {
      var contentLength = data.contentLength;
      var fileBuff = data.fileBuff;
      var fileName = index + "-" + path.basename(imgSrc);
      console.log("end downloading " + imgSrc);
      if (isNaN(contentLength)) {
        console.log(imgSrc + " content length error");
        return;
      }
      var totalBuff = Buffer.concat(fileBuff);
      console.log("totalBuff.length = " + totalBuff.length + " " + "contentLength = " + contentLength);
      if (totalBuff.length < contentLength) {
        console.log(imgSrc + " download error, try again");
        startDownloadTask(imgSrc, dirName, index);
        return;
      }
      fs.appendFile(dirName + "/" + fileName, totalBuff, function(err){});
    }

    console.log("start downloading " + imgSrc);

    startRequest(imgSrc)
      .then(solveResponse)
      .then(solveResData);

  }

  urlList.forEach(function(item, index, array) {
    startDownloadTask(item, './', index);
  })
})();

</pre>

<h4>ClientRequest对象的事件</h4><pre>
response事件
当服务器有响应时触发,事件监听器接收一个响应对象,是http.incomingMessage对象

</pre><pre class="js">
var http = require("http");
var req = http.request({host:"www.google.com"})
req.on("response",function(res){
   ... ...
})
req.end();

</pre><pre>
socket事件
请求对象建立好后内部创建一个net.socket对象,然后激发该事件;socket事件的监听器接收的参数就是该socket对象,该事件无论是否调用req.end()都会产生
req.on("socket",function(socket){ ... })

connect事件
upgrade事件
continue事件
同HTTP服务器的connect,upgrade和continue事件部分,客户端通过connect,upgrade或continue方式访问服务器,如果收到服务器的回应,就会激发对应的事件。

req.on('connect', function(res, socket, head) {
  console.log('got connected!');
}
req.on('upgrade', function(res, socket, head) {
  console.log('got upgraded!');
}
req.on('continue',function(){

})

</pre>

<h4>ClientRequest对象的方法</h4><pre>
request.write(chunk, [encoding])
发送一大块的数据chunk
chunk     可以是Buffer或String类型,可多次调用
encoding  chunk是字符串时是通过这个参数进行编码后发送出去的,默认utf8

request.end([data], [encoding])
完成请求的发送

request.abort()
终止请求

【 http.ClientRequest 】
http.ClientRequest是由http.request或者是http.get返回产生的对象,表示一个已经产生而且正在进行中的HTPP请求,提供一个response事件,也就是我们使用http.get和http.request方法中的回调函数所绑定的对象,我们可以显式地绑定这个事件的监听函数

http.ClientRequest也提供了write和end函数,用于向服务器发送请求体,通常用于POST、PUT等操作,所有写操作都必须调用end函数来通知服务器,否则请求无效。此外,这个对象还提供了abort()、setTimeout()等方法

【 http.ClientReponse 】
与http.ServerRequest相似,提供了三个事件,data、end、close,分别在数据到达、传输结束和连接结束时触发,其中data事件传递一个参数chunk

response.setEncoding([encoding])：设置默认的编码,当data事件被触发时,数据将会以encoding编码,默认值是null,也就是不编码,以buffer形式存储
response.pause()：暂停结束数据和发送事件,方便实现下载功能
response.resume()：从暂停的状态中恢复

</pre><pre class="js">
/* 创建客户端 */
var http = require('http');
var options = {                          // 用于请求的选项
  host: 'localhost',
  port: '8081',
  path: '/index.htm'
};
var callback = function(response){        // 处理响应的回调函数
  var body = '';
  response.on('data', function(data) {   // 不断更新数据
    body += data;
  });
  response.on('end', function() {         // 数据接收完成
    console.log(body);
  });
}
var req = http.request(options, callback); // 向服务端发送请求
req.end();

</pre><pre class="js">
var http=require("http");
var options={
  hostname:"cn.bing.com",
  port:80
}

var req=http.request(options);
req.on("response",function(res){
  res.setEncoding("utf-8");
  res.on("data",function(chunk){
      console.log(chunk.toString())
  });
  console.log(res.statusCode);
})

req.on("error",function(err){
  console.log(err.message);
});
req.end();

</pre><pre class="js">
var reqUrl = 'http://pickeke3.ke12345.net/picss/2017/allimg/171022/22125111-1-W4S.jpg';
var req = http.request(reqUrl, function(res){
  console.log(res);
});
req.on('error', function(e){
  console.log("request " + imgSrc + " error, try again");
  startDownloadTask(imgSrc, dirName);
});
req.end();

</pre>http.request发送Get请求<pre class="js">
var http=require('http');
var querystring=require('querystring');
var data={
  age:13,
  time:new Date().getTime()
};
var content=querystring.stringify(data);
var options={
  hostname:'www.gongjuji.net',
  port:80,
  path:'/',
  method:'GET'
}
//创建请求
var req=http.request(options,function(res){
  console.log('STATUS:'+res.statusCode);
  console.log('HEADERS:'+JSON.stringify(res.headers));
  res.setEncoding('utf-8');
  res.on('data',function(chunk){
    console.log('数据片段分隔-----------------------\r\n');
    console.log(chunk);
  });
  res.on('end',function(){
    console.log('响应结束********');
  });
});
req.on('error',function(err){
  console.error(err);
});
req.end();

</pre>http.request发送post请求<pre class="js">
var options = {
  hostname: 'www.google.com',
  port: 80,
  path: '/upload',
  method: 'POST'
};

var req = http.request(options, function(res) {
  console.log('STATUS: ' + res.statusCode);
  console.log('HEADERS: ' + JSON.stringify(res.headers));
  res.setEncoding('utf8');
  res.on('data', function (chunk) {
    console.log('BODY: ' + chunk);
  });
});

req.on('error', function(e) {
  console.log('problem with request: ' + e.message);
});

req.write('data\n');   // write data to request body
req.write('data\n');   // write data to request body
req.end();

</pre><pre class="js">
var http=require('http');
var querystring=require('querystring');

var postData = querystring.stringify({
  'msg':'Hello World!'
});
var options = {
  hostname: 'www.google.com',
  port: 80,
  path: '/upload',
  method: 'POST',
  headers: {            // http请求头使用headers指定
    'Content-Type':'application/x-www-form-urlencoded; charset=UTF-8',
    'Content-Length':Buffer.byteLength(postData)
  }
};

var req = http.request(options, (res) => {
  console.log(`STATUS: ${res.statusCode}`);
  console.log(`HEADERS: ${JSON.stringify(res.headers)}`);
  res.setEncoding('utf8');
  res.on('data', (chunk) => {
    console.log(`BODY: ${chunk}`);
  });
  res.on('end', () => {
    console.log('No more data in response.')
  })
});

req.on('error', (e) => {
  console.log(`problem with request: ${e.message}`);
});

req.write(postData);    // write data to request body
req.end();

</pre><pre class="js">
var http=require("http");
var querystring=require("querystring");

var postData=querystring.stringify({
  "content":"我真的只是测试一下",
  "mid":8837
});

var options={
  hostname:"www.imooc.com",
  port:80,
  path:"/course/document",
  method:"POST",
  headers:{
    "Accept":"application/json, text/javascript, */*; q=0.01",
    "Accept-Encoding":"gzip, deflate",
    "Accept-Language":"zh-CN,zh;q=0.8",
    "Connection":"keep-alive",
    "Content-Length":postData.length,
    "Content-Type":"application/x-www-form-urlencoded; charset=UTF-8",
    "Cookie":"imooc_uuid=6cc9e8d5-424a-4861-9f7d-9cbcfbe4c6ae; imooc_isnew_ct=1460873157; loginstate=1; apsid=IzZDJiMGU0OTMyNTE0ZGFhZDAzZDNhZTAyZDg2ZmQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjkyOTk0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGNmNmFhMmVhMTYwNzRmMjczNjdmZWUyNDg1ZTZkMGM1BwhXVwcIV1c%3DMD; PHPSESSID=thh4bfrl1t7qre9tr56m32tbv0; Hm_lvt_f0cfcccd7b1393990c78efdeebff3968=1467635471,1467653719,1467654690,1467654957; Hm_lpvt_f0cfcccd7b1393990c78efdeebff3968=1467655022; imooc_isnew=2; cvde=577a9e57ce250-34",
    "Host":"www.imooc.com",
    "Origin":"http://www.imooc.com",
    "Referer":"http://www.imooc.com/video/8837",
    "User-Agent":"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2763.0 Safari/537.36",
    "X-Requested-With":"XMLHttpRequest",
  }
}

var req=http.request(options,function(res){
  res.on("data",function(chunk){
    console.log(chunk);
  });
  res.on("end",function(){
    console.log("评论完毕！");
  });
  console.log(res.statusCode);
});

req.on("error",function(err){
  console.log(err.message);
})
req.write(postData);
req.end();

</pre>http.reqest方法封装<pre class="js">
var http = require('http');
var url  = require('url');

var request = function(reqUrl, data, cb, headers) {
  var dataType = typeof data;
  if(dataType == 'function') {
    headers = cb;
    cb   = data;
    rawData = null;
  }else if(dataType == 'object') {
    rawData = JSON.stringify(data);
  }else{
    rawData = data;
  }

  var urlObj = url.parse(reqUrl);
  var options = {
    hostname : urlObj.hostname,
    port   : urlObj.port,
    path   : urlObj.pathname,
    method  : rawData ? 'post' : 'get'
  }
  headers && (options.headers = headers);

  var req = http.request(options, function(res) {
    var chunks = [];
    if (res.statusCode !== 200) {
      cb && cb(new Error(`Request Failed,statusCode: ${res.statusCode} - ${reqUrl}`));
      return;
    }

    res.on('data', chunk => chunks.push(chunk));
    res.on('end', () => cb && cb(null, res, Buffer.concat(chunks)));
  })

  req.on('error', err => cb && cb(err));
  rawData && req.write(rawData);
  req.end();
}

</pre>
</div>

<div id="get">
<h3>http.get(options,callback)方法</h3><pre>
http.request方法的简化版,唯一区别是http.get自动将请求方法设为GET请求,且不需要手动调用req.end()
但如果使用http.request方法时没有调用end方法,服务器将不会收到信息。因为http.get和http.request方法都是返回一个http.ClientRequest对象,

写网页爬虫爬取数据,对爬来的数据进行筛选和整合可以引用cheerio,可以配合nodejs的Promise对象

</pre><pre class="js">
var http = require("http");
var req = http.get("http://www.google.com", res => {
  console.log(res.headers)
})

// 等效
var http = require("http");
var req = http.request({host:"www.google.com"}, res => {
  console.log(res.headers)
})
req.end();

</pre><pre class="js">
const http = require("http")
const url = "http://www.haorooms.com/post/nodejs_rmyyong"
http.get(url, res => {
  var html = ""
  res.on("data", data => html+=data )
  res.on("end",() => console.log(html) )
}).on("error", e=> console.log(`获取数据失败: ${e.message}`))

</pre><pre class="js">
var callback = function(res) {
  var chunks = [];
  var size = 0;
  req.on('data', function(chunk){
    chunks.push(chunk);
    size += chunk.length;
  });

  req.on("end", () => {
    var buffer = Buffer.concat(chunks, size);
    fs.appendFile(__dirname + "/download/" + fileName, buffer, function(err){});
  })
};

const http = require("http")
const url = "http://www.haorooms.com/post/nodejs_rmyyong"
http.get(url, callback).on("error", e=> console.log(`获取数据失败: ${e.message}`))

</pre>【 http.get基础 】<pre class="js">
const http = require('http');
const fs = require('fs');
const path = require('path');
const targetUrl = 'http://localhost/study/seoimg/socket.jpg';
const file = path.join(__dirname, path.basename(targetUrl));

function spider(targetUrl, i){
  return new Promise((resolve, reject) => {
  // 不是http开头加上域名,正则验证是否是常见URL格式,防止死链
    http.get(targetUrl, res => {
      // res.destroy();        // 触发client res close pipe只接收了部分数据,不触发res.end事件
      aboutNetSocket(res.socket, 'res.socket');
      // res.socket.destroy(); // 触发client res close pipe只接收了部分数据,不触发res.end事件
      if (res.statusCode !== 200) {
        console.log(`down ${targetUrl}: ${res.statusCode}`);
      } else {
        console.log(`down ${targetUrl}: ${res.statusCode}`);
        // 响应码200才下载文件,服务端关闭连接触发close事件
        res.pipe(fs.createWriteStream(file)).on('close', () => {
          // callback(null, file);
          console.log(`pipe-close done: ${file}`)
        });
      }
      let chunks = [];
      res.on('data', chunk => {
        console.log(`res data, data-length: ${chunk.length}`);
        chunks.push(new Buffer(chunk));
      });
      res.on('end', () => {
        let fileBuf = Buffer.concat(chunks);
        console.log('res end！buffer', fileBuf.toString().length, fileBuf);
      });
      res.on("close", () => console.log("client res close"))
      res.on('error', () => console.log('stream error 数据读取错误'));
      // 服务器没开启时触发req的error事件
      // err.code：ECONNREFUSED - err.message：connect ECONNREFUSED 127.0.0.1:80
    })

    .on('error', err => {
      if(!err) return;
      console.log(`req error ${targetUrl}: ${err.code} - ${err.message}`)
      reject(err);
    })
    .on('finish', () => {
      console.log('stream finish');
      resolve();
    })
    .on("socket", socket => {
      aboutNetSocket(socket, 'req socket');
      // socket.destroy(); // 触发req.error: ECONNRESET(err.code) = socket hang up(err.message)
    })
  })
}

spider(targetUrl).then(r => r && console.log(r)).catch(e => console.error(e))

function aboutNetSocket(socket, info){
  console.log(`=======================
    ${info}
累积接收到的字节数: ${socket.bytesRead}
累积发送的字节数: ${socket.bytesWritten}
远程socket地址、端口: ${socket.remoteAddress} ：${socket.remotePort}
本地socket地址、端口: ${socket.localAddress} ：${socket.localPort}
=======================`)
}

</pre><pre>
nodejs 控制并发数 concurrent connections\性能测试
Nodejs HTTP请求的超时处理
nodejs爬虫连接超时卡住了怎么处理

read ECONNRESET和connect ETIMEDOUT
底层的error事件, close事件都得对应做相应的处理, 来实现断开自动重连, 消息发送失败自动重试, 重试次数或频率超过最大值需要destory等

http.get有时会一直等待响应,所以一定要判断下,超时则认为出错,要不程序就卡住了
req.on('error', function(err){
  if(err.code === 'ETIMEOUT'){
    // blabla
  }
})

</pre><pre>
【 Nodejs HTTP请求的超时处理(Nodejs HTTP Client Request Timeout Handle) 】
Nodejs原生的http.request方法是不支持设置超时参数的,
而网络请求经常会遇到超时的情况,特别是对于外部网络,如果不处理超时,发起的请求将会一直卡住,消耗的系统资源也不能及时被释放。

解决方案(新,有问题,socket会重用,设置超时会有问题)：扩展http.ClientRequest,增加setTimeout方法
利用socket.setTimeout可以为http.ClientRequest增加超时设置方法

</pre><pre class="js">
var http = require('http');
http.ClientRequest.prototype.setTimeout = function(timeout, callback){
  var self = this;
  if(callback) self.on('timeout', callback);
  self.connection.setTimeout(timeout, function(){
    self.abort();
    self.emit('timeout');
  });
};

</pre><pre>
解决方案(旧)
定时器：通过定时器,当timeout事件触发的时候,主动调用req.abort() 终止请求,然后返回超时异常。

Request Timeout & Response Timeout
请求超时(Request Timeout)：HTTP客户端发起请求到接受到HTTP服务器端返回响应头的这段时间, 如果超出设定时间,则表示请求超时。
响应超时(Response Timeout)：HTTP服务器端开始发送响应数据到HTTP客户端接收全部数据的这段时间, 如果超出设定时间,则表示响应超时

</pre><pre class="php">
var http = require('http');

var request_timer = null, req = null;
// 请求5秒超时
request_timer = setTimeout(function() {
  req.abort();
  console.log('Request Timeout.');
}, 5000);

var options = {
  host: 'www.google.com',
  port: 80,
  path: '/'
};
req = http.get(options, function(res) {
  clearTimeout(request_timer);

  // 等待响应60秒超时
  var response_timer = setTimeout(function() {
    res.destroy();
    console.log('Response Timeout.');
  }, 60000);

  console.log("Got response: " + res.statusCode);
  var chunks = [], length = 0;
  res.on('data', function(chunk) {
    length += chunk.length;
    chunks.push(chunk);
  });
  res.on('end', function() {
    clearTimeout(response_timer);
    var data = new Buffer(length);
    // 延后copy
    for(var i=0, pos=0, size=chunks.length; i < size; i++) {
      chunks[i].copy(data, pos);
      pos += chunks[i].length;
    }
    console.log('Body:\r\n');
    console.log(data.toString());
  });
}).on('error', function(e) {
  // 响应头有错误
  clearTimeout(request_timer);
  console.log("Got error: " + e.message);
});

</pre>【 http.get错误处理 】<pre class="js">
let uri = 'http://pic.keke1sassds2345.info/asdsdfds';
require('http').get(uri, res => {
  console.log(res.statusCode, res.headers);
}).on('error', err => {
  if(err) console.log(err);
})

/*
url域名段正确,某个页面不存在时返回404错误
let uri = 'http://pic.keke12345.info/picss/2017/allimg/171122/22213327-1-16294.jpg';
404 { 'content-type': 'text/html',
  server: 'Microsoft-IIS/7.5',
  'x-powered-by': 'ASP.NET',
  date: 'Tue, 06 Feb 2018 17:36:34 GMT',
  connection: 'close',
  'content-length': '1163' }
*/

/*
url域名段错误
let uri = 'http://www.csdsdsdsdsd.com';
{ Error: getaddrinfo ENOTFOUND www.badsdsdidu.com www.badsdsdidu.com:80
    at errnoException (dns.js:50:10)
    at GetAddrInfoReqWrap.onlookup [as oncomplete] (dns.js:92:26)
  code: 'ENOTFOUND',
  errno: 'ENOTFOUND',
  syscall: 'getaddrinfo',
  hostname: 'www.badsdsdidu.com',
  host: 'www.badsdsdidu.com',
  port: 80 }
*/

</pre><pre class="js">
/*下载图片*/
// request module
var fs = require('fs'),
  request = require('request');

var download = function(uri, filename, callback){
  request.head(uri, function(err, res, body){
    console.log('content-type:', res.headers['content-type']);
    console.log('content-length:', res.headers['content-length']);

    request(uri).pipe(fs.createWriteStream(filename)).on('close', callback);
  });
};

download('https://www.google.com/images/srpr/logo3w.png', 'google.png', function(){
  console.log('done');
});

// using Stream to merge the chunks together
var http = require('http'),
  Stream = require('stream').Transform,
  fs = require('fs');

var url = 'http://www.google.com/images/srpr/logo11w.png';

http.request(url, function(response) {
  var data = new Stream();

  response.on('data', function(chunk) {
    data.push(chunk);
  });

  response.on('end', function() {
    fs.writeFileSync('image.png', data.read());
  });
}).end();

</pre>

<h3 id="crawler">crawler spider downloader</h3><pre>
爬虫就是一个http客户端,通过http协议和远程http服务器通信,获取html页面内容或者其他的种子文件,pdf文件等等。和浏览器不同的一点就是爬虫不会把抓取的内容渲染出来,而是解析页面内容然后保存到数据库里面

动态数据的获取
如ajax方式获取;用Nodejs中http模块的get方法去获取JSON数据,然后解析该JSON数据从而获得想要的数据
如底部加载更多按钮,模拟ajax请求截取剩余页面的数据
图片数据懒加载

Promise.all(arr)的状态由p1、p2、p3决定,分成两种情况:
1、只有p1、p2、p3状态都变成fulfilled,最终状态才会变成fulfilled,p1、p2、p3返回值组成数组传递给p的回调函数
2、只要p1、p2、p3中有一个被rejected,最终状态就变成rejected,第一个被reject的实例的返回值会传递给p的回调函数

</pre><pre class="js">
/* 使用Promise对象来包装获取到页面的html的方法  */
function getPageAsync(url){
  return new Promise(function (resolve,reject){
    console.log('正在爬取 ' + url + '\n');
    http.get(url, res => {
      var html = '';
      res.on('data', (data) => html += data);
      res.on('end', () => resolve(html));
    }).on('error', err => {
      reject(err);
      console.log(`获取${url}数据出错！`);
    })
  })
}

//针对每个url地址返回的页面HTML源码并发操作进行爬取
Promise.all(fetchPageUrl).then(function (Pages) { ... })

</pre><pre>
【 简单的反爬虫技术 】
1、判断headers中的参数,比如user-agent不是浏览器的不允许访问;refer不是来源于特定域名的也不行(反盗链常用技术);Authorization,这是最常见的反爬虫技术
2、检查用户cookies,需要登录的网站常采用,比如论坛、微博、雪球等,以上两个可以通过手动设计headers和cookies搞定
3、复杂的登陆流程,以前是验证码登陆,现在是滑动条登陆
4、采用实名制或手机验证登陆,登陆之后每天限制爬3条
5、数据用图片显示,增加识别难度
6、蜜罐,在网页上故意放一些不存在的普通用户一般不会点击的链接,而爬虫却会,通过一定时间内访问这些链接的频率就认定是爬虫

还有一些比较复杂的技术：
1. 数据通过ajax异步加载,返回的是加密数据或者通过js混淆处理,而js处理过程可以写的很复杂,以至于爬虫程序员没法分析
2. 数据通过flash和服务器端交互,例如船讯网http://www.shipxy.com中请求船舶信息部分
3. 通过ip或者特定账号单位时间内请求数量来限制访问,基本无解,比如google scholar

对于反爬,可以通过技术过滤普通爬虫,最关键的还是提高爬虫的成本,如果爬虫付出的成本高于获取的数据,那么谁也不愿意去爬取数据

</pre>
</div>

<div id="concurrent">
<h3>concurrent connections 并发数与性能测试</h3><pre>
并发连接数-SBC(Simultaneous Browser Connections)
并发连接数指的是客户端向服务器发起请求,并建立了TCP连接。
每秒钟服务器链接的总TCP数量,就是并发连接数。

请求数-QPS(Query Per Second)/RPS(Request Per Second)
请求数有2个缩写,可以叫QPS也可以叫RPS。单位是每秒多少请求。Query=查询,也相当于请求。请求数指的是客户端在建立完连接后,向http服务发出GET/POST/HEAD数据包,服务器返回了请求结果后有两种情况：
· http数据包头包含Close字样(非持久连接),关闭本次TCP连接;
· http数据包头包含Keep-Alive字样,本次连接不关闭,可继续通过该连接继续向http服务发送请求,用于减少TCP并发连接数

以Chrome为例,假设服务器设置的是Close(非持久连接),浏览器打开网页后,首先打开4个并发加载数据,在这些请求完成后关闭4个连接,再打开4个并发连接加载数据。也就是说,并不是这个网页有100个请求就会产生100并发,而是4个并发连接并行。假设服务器设置的是keep-alive(持久连接),浏览器打开网页后,首先打开4个并发加载数据,在这些请求完成后不关闭连接,而是继续发出请求,节约重新打开连接的时间

并发用户
在同一时刻与服务器进行了交互的在线用户数量,这种交互既可以是单向的传输数据,也可以是双向的传送数据

通常情况下测试的是QPS,也就是每秒请求数。不过为了衡量服务器的总体性能,测试时最好一起测试并发连接数和请求数

测试原理
· 测试并发连接数采用每个并发1请求,多个并发进行;
· 测试请求数采用多并发、每个并发多个请求进行,总的请求数将会=并发数*单并发请求数,需要注意的是不同的并发和单并发请求数得出来的结果会不同,因此最好测试多次取平均值

用eventproxy控制下并发数,以免再被封

</pre><pre class="js">
// node是单线程的,while死循环导致异步任务没法进行,tasks–也就无法执行到
var tasks = 0;       //当前并发数量
function foo(url){
  while(tasks > 2){  //并发超过2,无限循环等前面的任务执行结束
    continue;
  }
  tasks++;
  http.get(url,function(){
    tasks--;          //任务执行完毕,tasks-1
  })
}
var urls = [....]
for(var i in urls) {
  foo(urls[i]);
}

</pre><pre>
关闭套接字池
Node.js的http客户端会自动地使用套接字池：默认地,它会限制每台主机只能有5个套接字。虽然套接字的重复使用可能会让资源的增加在控制之下,但如果你需要处理许多数据来自于同一主机的并发请求时,将会导致一系列的瓶颈。在这种情况下,增大maxSockets 的值或关闭套接字池是个好主意：
// Disable socket pooling

var http = require('http');
var options = {.....};
options.agent = false;
var req = http.request(options)

</pre>
</div>

<div id="udp">
<h3>UDP</h3><pre>
TCP的可靠保证是其三次握手机制,保证校验了数据;而UDP没,所以不可靠
不过UDP的速度是TCP比不了的,而且UDP的反应速度更快,QQ就是用UDP协议传输的
HTTP是用TCP协议传输的,是建立在TCP协议之上的

node.js也提供了UDP协议支持的模块,通过var dgram = require('dgram')可以加载该模块

建立UDP客户端和服务器端是一样的,因为互相之间只是简单的知道对方的ip和端口号,然后把数据丢过去而已

</pre><pre class="js">
// 服务器代码
var dgram = require("dgram");
var server = dgram.createSocket('udp4');
server.bind(8888);
server.on("message", (msg,rinfo) => {
  console.log(msg.toString());
  console.log(rinfo);
})

// 客户端代码
var dgram = require("dgram");
var client = dgram.createSocket("udp4");
process.stdin.on("data", data => {
  client.send(data, 0, data.length, 8888, "localhost");
});

</pre><pre>
dgram.createSocket(type, [callback])
创建一个UDP的socket对象。
type      可以是udp4或udp6,对应ipv4和ipv6,现在还是以ipv4为主,所以都选用udp4
callback  message事件的监听器
返回值    socket对象,不是net.Socket类型,而是dgram.Socket对象,是专门为了UDP协议重新设计重写的

</pre><pre class="js">
var udp = require("dgram");
var serverSocket = udp.createSocket('udp4', msg => console.log(msg.toString()));
serverSocket.bind(8080);

</pre><pre>
message事件
message事件监听器会接收到两个参数 callback(msg,rinfo)
msg     接收到的数据,是Buffer类型
rinfo   json对象  { address: '127.0.0.1', family: 'IPv4', port: 50889, size: 8 }
        address表示发送信息主机的ip地址
        port表示发送信息主机的端口
        size表示信息的byte数量

listening事件
当socket准备好接收信息时会触发
socket.on("listening", () => { ... })

close事件
当调用socket.close() 时激发close事件

error 事件
当socket内部发生错误时,会激发error事件

socket.send(buf, offset, length, port, address, [callback(err, bytes)])
发送信息
buf       要发送的信息,是Buffer类型
offset    发送buf的起始位置
length    发送buf的长度
port      发送到目标主机端口
address   发送到目标主机的地址
callback  回调函数,但发送完成后调用这个回调函数,err表示错误信息,bytes表示发送出去的字节数量。

socket.address()
得到本地socket信息,信息类似于 { address: '0.0.0.0', family: 'IPv4', port: 8080 }
但调用这个方法必须是激发listening事件之后,否则会抛出异常

socket.setTTL(ttl)
ttl 是 1～255的一个值,单位是毫秒ms。ttl是IP协议包中的一个值,它告诉网络,数据包在网络中的时间是否太长而应被丢弃。就是一个信息发送出去,数据在传输过程中ttl会递减,等到0时,就会死亡,当然在死亡之前数据到达目标主机就算成功了,默认是64

socket.setBroadcast(flag)
设置是否UDP广播,即发送一条信息,本地局域网内的UDP主机能收到这条消息,广播地址是 255.255.255.255 。
但调用这个方法也必须是激发listening事件之后,否则会抛出异常

</pre><pre class="js">
// 接收方
var udp = require("dgram");
var socket = udp.createSocket('udp4', msg => console.log(msg.toString()));
socket.bind(8888);

// 广播端
var udp = require("dgram");
var client = udp.createSocket("udp4",function(){});
client.on("listening", () => client.setBroadcast(true))
process.stdin.on("data", data => {
  client.send(data, 0, data.length, 8888, "255.255.255.255");
});

</pre>
</div>

<div id="getpost">
<h3>获取GET/POST请求内容</h3><pre>
【 获取GET请求内容 】
由于GET请求直接被嵌入在路径中,URL是完整的请求路径,包括了?后面的部分,因此可以手动解析后面的内容作为GET请求的参数
node.js中url模块中的parse函数提供了这个功能

</pre><pre class="js">
var http = require('http');
var url = require('url');
var util = require('util');

http.createServer(function(req, res){
  res.writeHead(200, {'Content-Type': 'text/plain; charset=utf-8'});
  var params = url.parse(req.url, true).query;                        // 解析 url 参数
  res.write("网站名：" + params.name + "\n");
  res.write("网站URL：" + params.url);
  res.end();
}).listen(8888);

</pre><pre>
【 获取POST请求内容 】
POST请求的内容全部的都在请求体中,http.ServerRequest并没有一个属性内容为请求体,原因是等待请求体传输可能是一件耗时的工作。
比如上传文件,而很多时候可能并不需要理会请求体的内容,恶意的POST请求会大大消耗服务器的资源,
所以node.js默认是不会解析请求体的,需要的时候需要手动来做

reqest.header["content-length"]

</pre><pre class="js">
/* 表单通过POST提交并输出数据,post到当前页面 */

var http = require('http');
var querystring = require('querystring');

var postHTML = `
  ＜!doctype html＞＜html＞
  ＜head＞＜meta charset="utf-8"＞＜title＞post＜/title＞＜/head＞
  ＜body＞
  ＜form action="" method="post"＞
      ＜p＞＜input type="text" name="name"/＞＜/p＞
      ＜p＞＜input type="text" name="url" /＞＜/p＞
      ＜p＞＜input  type="submit" /＞＜/p＞
  ＜/form＞
  ＜/body＞＜/html＞`;

http.createServer((req, res) => {
  var chunks = [];
  var size = 0;
  req.on('data', chunk => {
    chunks.push(chunk);
    size += chunk.length;
  });
  req.on('end', () => {
    var buffer = Buffer.concat(chunks, size);
    body = querystring.parse(buffer.toString());                      // 解析参数,post请求体
    res.writeHead(200, {'Content-Type': 'text/html; charset=utf8'});  // 设置响应头部信息及编码
    if(body.name && body.url) {                                       // 输出提交的数据
      res.write("网站名：" + body.name + "<br>");
      res.write("网站 URL：" + body.url);
    } else {                                                          // 输出表单
      res.write(postHTML);
    }
    res.end(body);
  });
}).listen(8888);

</pre>
</div>

<div id="upload">
<h3>post文件上传</h3><pre>
文件实际上包括两部分,控制信息和内容信息。纯文本文件仅仅是没有控制格式信息罢了;实际上也是一种特殊的二进制文件

从文件编码的方式来看,文件可分为ASCII码文件和二进制码文件两种。
ASCII文件也称为文本文件,这种文件在磁盘中存放时每个字符对应一个字节,用于存放对应的ASCII码,ASCII码文件可在屏幕上按字符显示,因此能读懂文件内容
例如,数5678的存储形式共占用4个字节
二进制文件是按二进制的编码方式来存放文件的.例如,数5678的存储形式为： 00010110 00101110只占二个字节。
二进制文件虽然也可在屏幕上显示,但其内容无法读懂

一个文件可以以文本模式或二进制模式打开,这两种的区别是：在文本模式中回车被当成一个字符'/n',而二进制模式认为它是两个字符0x0D,0x0A;如果在文件中读到0x1B,文本模式会认为这是文件结束符,也就是二进制模型不会对文件进行处理,而文本方式会按一定的方式对数据作相应的转换

post提交包含上传文件控件的表单,请求头中只有content-type属性不同,请求体则完全不同
请求体中的信息头和信息体之间是 \r\n\r\n 分隔,以此来切割分类post上传的数据

在nodejs中流以buffer的形式传输,二进制流buffer转换成字符串之后再转换成buffer,数据结构就不一样了

var buf = new Buffer([0,1,21,0]);
console.log(buf);       // < Buffer 00 01 15 00>

var buf2 = new Buffer(buf.toString("ascii"),"ascii");
console.log(buf2);      // < Buffer 20 01 15 20>

</pre><pre class="js">
const http = require('http');
const querystring = require('querystring');
const os = require('os');

http.createServer((req, res) => {
  if(req.url == '/'){
    var updatahtml = `
＜!doctype html＞
＜html＞
  ＜head＞＜title＞post＜/title＞＜/head＞
  ＜body＞
      ＜form action="http://localhost:8888/postfile" enctype="multipart/form-data" method="post"＞
          ＜p＞＜input type="text" name="title" placeholder="title"/＞＜/p＞
          ＜p＞＜input type="text" name="content" placeholder="content"/＞＜/p＞
          ＜p＞＜input type="file" name="img"/＞＜/p＞
          ＜input  type="submit" value="postfile"/＞
      ＜/form＞
      ＜form action="http://localhost:8888/post" method="post"＞
          ＜p＞＜input type="text" name="title" placeholder="title"/＞＜/p＞
          ＜p＞＜input type="text" name="content" placeholder="content"/＞＜/p＞
          ＜input  type="submit" value="post"/＞
      ＜/form＞
  ＜/body＞
＜/html＞
      `;
      res.end(updatahtml);
  }else if(req.url == '/postfile'){
    console.log(req.headers);

    var chunks = [];
    var size = 0;
    req.on('data', chunk => {
      chunks.push(chunk);
      size += chunk.length;
    });
    req.on('end', () => {
      var buffer = Buffer.concat(chunks, size);
      var body = buffer.toString();
      console.log(body);
      res.end();
    });

  }else if(req.url == '/post'){
    console.log(req.headers);
    var chunks = [];
    var size = 0;
    req.on('data', chunk => {
      chunks.push(chunk);
      size += chunk.length;
    });
    req.on('end', () => {
      var buffer = Buffer.concat(chunks, size);
      var body_data = buffer.toString();
      console.log(body_data);               // title=sd&content=sd
      res.end();
    });
  }

}).listen(8888)

/*
'content-type': 'application/x-www-form-urlencoded'
'content-type': 'multipart/form-data; boundary=----WebKitFormBoundarysbHAJUwdYRfvQpyT'

{ host: 'localhost:8888',
  connection: 'keep-alive',
  'content-length': '31294',
  'cache-control': 'max-age=0',
  origin: 'http://localhost:8888',
  'upgrade-insecure-requests': '1',
  'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',
  'content-type': 'multipart/form-data; boundary=----WebKitFormBoundarysbHAJUwdYRfvQpyT',
  accept: 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,* /*;q=0.8',
  referer: 'http://localhost:8888/',
  'accept-encoding': 'gzip, deflate, br',
  'accept-language': 'zh-CN,zh;q=0.8',
  cookie: 'Hm_lvt_9c975eeec1197cd1210a40e18a2b2f54=1510056953,1510281340,1510486680,1510910488; Hm_lpvt_9c975eeec1197cd1210a40e18a2b2f54=1511166947' }

------WebKitFormBoundarysbHAJUwdYRfvQpyT \r\n
Content-Disposition: form-data; name="title" \r\n\r\n

sd \r\n
------WebKitFormBoundarysbHAJUwdYRfvQpyT \r\n
Content-Disposition: form-data; name="content" \r\n\r\n

sd \r\n
------WebKitFormBoundarysbHAJUwdYRfvQpyT \r\n
Content-Disposition: form-data; name="img"; filename="3434344.jpg" \r\n
Content-Type: image/jpeg \r\n\r\n

................. \r\n
------WebKitFormBoundarysbHAJUwdYRfvQpyT-- \r\n

表单字段信息头
Content-Disposition: form-data; name="title" \r\n\r\n

二进制文件信息头
Content-Disposition: form-data; name="img"; filename="favicon2.ico" \r\n
Content-Type: image/x-icon \r\n\r\n

*/

</pre>文本文件的上传<pre class="js">
const http = require('http');
const fs = require('fs');
const querystring = require('querystring');
const os = require('os');

http.createServer((req, res) => {
  if(req.url == '/'){
      var updatahtml = `
＜!doctype html＞
＜html＞
    ＜head＞＜title＞post＜/title＞＜/head＞
    ＜body＞
        ＜form action="http://localhost:8888/postfile" enctype="multipart/form-data" method="post"＞
            ＜p＞＜input type="text" name="title" placeholder="title"/＞＜/p＞
            ＜p＞＜input type="text" name="content" placeholder="content"/＞＜/p＞
            ＜p＞＜input type="file" name="imgs[]"/ multiple="multiple" accept＞＜/p＞
            ＜input  type="submit" value="postfile"/＞
        ＜/form＞
        ＜form action="http://localhost:8888/post" method="post"＞
            ＜p＞＜input type="text" name="title" placeholder="title"/＞＜/p＞
            ＜p＞＜input type="text" name="content" placeholder="content"/＞＜/p＞
            ＜input  type="submit" value="post"/＞
        ＜/form＞
    ＜/body＞
＜/html＞
    `;
    res.end(updatahtml);
  }else if(req.url === '/postfile' || req.url === '/post'){
    var bodys = {};
    var files = {};     // 保存请求体内容

    var chunks = [];
    var size = 0;
    req.on('data', chunk => {
      chunks.push(chunk);
      size += chunk.length;
    })
    req.on('end', () => {
      var body_data = Buffer.concat(chunks, size);
      body_data = body_data.toString();
      console.log(body_data);
      var contentType = req.headers["content-type"];
      var isMulti = /(boundary=)/gi.test(contentType);     // 判断是否有文件上传
      if(isMulti){
        var boundary = RegExp["$'"];                     // 获取边界字符串
        var boundaryStandard = "--"+boundary+os.EOL;
        var boundaryEnd = boundaryStandard+"--";         // 去掉头尾边界字符串
        body_data = body_data.substring(boundaryStandard.length,body_data.length-boundaryEnd.length);
        var fields = body_data.split(boundaryStandard);  // 利用边界字符串分割获得字段信息数组,信息头和字段以\r\n\r\n分隔

        var RN = os.EOL+os.EOL;
        fields.forEach(field => {
          var index = field.indexOf(RN);
          var header = field.substring(0, index);              // 获得信息头
          /name=\"(.*?)\"/g.test(header);
          var fieldName = RegExp.$1;                           // 获得字段名

          var body = field.substring(index + RN.length);
          body = body.substring(0, body.length - RN.length/2); // 获取数据体

          var isFile = /filename=\"(.+?)\"/g.test(header);     // 判断是文件字段还是普通表单字段
          if(isFile){
            var onefile = {"filename": RegExp.$1, "content": body};
            files[fieldName] ? files[fieldName].push(onefile):files[fieldName] = [onefile];
          }else{
            bodys[fieldName] = body;                         // 普通字段和文件字段分开
          }
        })
      }else{
        bodys = querystring.parse(body_data);
      }
      console.log(files);
      console.log(bodys);
      res.end();
    })
  }

}).listen(8888)

</pre>

<h4>文件上传 预览 base64 FileReader对象</h4><pre class="js">
// index.js
const http = require('http');
const fs = require('fs');

http.createServer((req, res) => {
  switch(req.url){
    case '/index.html':
    case '/':
      fs.createReadStream(__dirname + '/index.html').pipe(res);
      break;
    case '/upload':
      var chunks = [];
      var size = 0;
      req.on('data' , function(chunk){
        chunks.push(chunk);
        size+=chunk.length;
      });

      req.on("end",function(){
          var buffer = Buffer.concat(chunks, size);
          var str = buffer.toString();
          console.log(str);
          var json = JSON.parse(str);
          json.files.forEach(file =>{
            var {filename, filecontent} = file;
            var decodeImage = new Buffer(filecontent.substring(filecontent.indexOf(',') + 1), 'base64');
            fs.writeFile(json.savedir + filename, decodeImage, err => {
              err&&console.log(err);
              console.log(`${filename}已保存`);
            });
          })

          res.end('ok');
      })
      break;
    default:;
  }
}).listen(8888, () => console.log('server start ...'))

// index.html
＜form action="/upload" method="post" enctype="multipart/form-data"＞
  ＜fieldset＞
    ＜legend＞上传文件：＜/legend＞
    ＜div id="form"＞
      ＜p＞＜input type="text" name="name" placeholder="说明"＞＜/p＞
      ＜p＞＜input type="text" name="description" placeholder="描述"＞＜/p＞
      ＜p＞＜input type="text" name="savedir" placeholder="保存目录默认file/" data-savedir="file/"＞＜/p＞
      ＜p＞＜input type="file" name="files[]" id="Files" multiple=""＞＜/p＞
      ＜p＞＜input type="button" value="上传"＞＜/p＞
    ＜/div＞
    ＜div id="show"＞
      ＜div id="Preview"＞
        ＜div class="txt"＞ + 预览区＜/div＞
      ＜/div＞
      ＜ul id="Errors"＞＜/ul＞
    ＜/div＞
  ＜/fieldset＞
＜/form＞

var postData = {'name': '', 'description': '', 'savedir': '', 'files': []};

function fileSelect(e) {
  e = e || window.event;
  var files = e.target.files;  //FileList Objects
  var ireg = /image\/.*/i;
  var p = document.getElementById('Preview');
  var ul = document.getElementById('Errors');
  for(var i = 0, f; f = files[i]; i++) {
    if(!f.type.match(ireg)) {
      //设置错误信息
      var li = document.createElement('li');
      li.innerHTML = '<li>' + f.name +'不是图片文件.</li>';
      ul.appendChild(li);
      continue;
    }

    var reader = new FileReader();
    reader.onload = (function(file) {
      return function(e) {
        var span = document.createElement('span');
        span.innerHTML='< img class="thumb" src="' + this.result +'" alt="'+file.name +'">';
        p.insertBefore(span, null);
        postData.files.push({'filename': file.name, 'filecontent': this.result})
      };
    })(f);
    //读取文件内容
    reader.readAsDataURL(f);
  }
}

function uploadform(){
  postData.name = document.querySelector('input[name=name]').value;
  postData.description = document.querySelector('input[name=description]').value;
  postData.savedir = document.querySelector('input[name=savedir]').value || 'file/';
  console.log(JSON.stringify(postData));

  var request=new XMLHttpRequest();
  request.open("POST","/upload");
  request.setRequestHeader("Content-Type","application/x-www-form-urlencoded");
  request.send(JSON.stringify(postData));
  request.onreadystatechange=function(){
    if(request.readyState===4){
      if(request.status===200){
        console.log(request.responseText);
      }else{
        alert("发生错误："+request.status);
      }
    }
  }
}

if(window.File && window.FileList && window.FileReader && window.Blob) {
  document.getElementById('Files').addEventListener('change', fileSelect, false);
} else {
  document.write('您的浏览器不支持File Api');
}

document.querySelector('input[type=button]').addEventListener('click', uploadform, false);

</pre>
</div>

<!-- ----------------url--------------------- -->
<div id="url">
<h2>url</h2><pre class="js">
> url
{ parse: [Function: urlParse],
  resolve: [Function: urlResolve],
  resolveObject: [Function: urlResolveObject],
  format: [Function: urlFormat],
  Url: [Function: Url] }

</pre><pre class="js">
> url.parse('http://www.imooc.com/search/course?words=nodejs#sd555');
Url {
  protocol: 'http:',
  slashes: true,
  auth: null,
  host: 'www.imooc.com',
  port: null,
  hostname: 'www.imooc.com',
  hash: '#sd555',
  search: '?words=nodejs',
  query: 'words=nodejs',
  pathname: '/search/course',
  path: '/search/course?words=nodejs',
  href: 'http://www.imooc.com/search/course?words=nodejs#sd555' }

</pre>url.parse方法二参true表示参数采用queryString模式,而不是url模式<pre class="js">
> url.parse('http://www.imooc.com/search/course?words=nodejs#sd555', true);
Url {
  protocol: 'http:',
  slashes: true,
  auth: null,
  host: 'www.imooc.com',
  port: null,
  hostname: 'www.imooc.com',
  hash: '#sd555',
  search: '?words=nodejs',
  query: { words: 'nodejs' },
  pathname: '/search/course',
  path: '/search/course?words=nodejs',
  href: 'http://www.imooc.com/search/course?words=nodejs#sd555' }

</pre>url.parse方法三参在没有protocal时解析url<pre class="js">
> url.parse('//www.imooc.com/search/course?words=nodejs#sd555',true,true);
Url {
  protocol: null,
  slashes: true,
  auth: null,
  host: 'www.imooc.com',
  port: null,
  hostname: 'www.imooc.com',
  hash: '#sd555',
  search: '?words=nodejs',
  query: { words: 'nodejs' },
  pathname: '/search/course',
  path: '/search/course?words=nodejs',
  href: '//www.imooc.com/search/course?words=nodejs#sd555' }

</pre>url.format<pre class="js">
> url.format({
  protocol: 'http:',
  slashes: true,
  auth: null,
  host: 'www.imooc.com',
  port: null,
  hostname: 'www.imooc.com',
  hash: '#sd555',
  search: '?words=nodejs',
  query: 'words=nodejs',
  pathname: '/search/course',
  path: '/search/course?words=nodejs',
  href: 'http://www.imooc.com/search/course?words=nodejs#sd555' });
'http://www.imooc.com/search/course?words=nodejs#sd555'

</pre>url.resolve<pre class="js">
> url.resolve('http://www.imooc.com', '/search/course?words=nodejs#sd555');
'http://www.imooc.com/search/course?words=nodejs#sd555'

</pre>
</div>

<div id="path">
<h2>const path = require('path') 提供处理和转换文件路的工具</h2><pre class="js">
> path
{ resolve: [Function: resolve],          //从源地址 from 到目的地址 to 的绝对路径
  normalize: [Function: normalize],      //标准化路径字符串,处理冗余的".."、"."、"/"字符
  isAbsolute: [Function: isAbsolute],
  join: [Function: join],                //将多个路径结合在一起,并转换为标准化的路径
  relative: [Function: relative],        //获取从 from 到 to 的相对路径
  _makeLong: [Function: _makeLong],
  dirname: [Function: dirname],          //获取路径
  basename: [Function: basename],        //获取文件名
  extname: [Function: extname],          //获取扩展名
  format: [Function: format],            //路径组合
  parse: [Function: parse],              //路径解析
  sep: '\\',                             //平台的文件路径分隔符,'\\' 或 '/'
  delimiter: ';',                        //平台的分隔符, ; or ':'.
  win32: [Circular],                     //path相关属性、接口的win32实现
  posix:                                 //path相关属性、接口的linux实现
   { resolve: [Function: resolve],
     normalize: [Function: normalize],
     isAbsolute: [Function: isAbsolute],
     join: [Function: join],
     relative: [Function: relative],
     _makeLong: [Function: _makeLong],
     dirname: [Function: dirname],
     basename: [Function: basename],
     extname: [Function: extname],
     format: [Function: format],
     parse: [Function: parse],
     sep: '/',
     delimiter: ':',
     win32: [Circular],
     posix: [Circular]
   }
 }

</pre><pre>
【 文件路径分解/组合 】
path.format(pathObject)：将pathObject的root、dir、base、name、ext属性,按照一定的规则,组合成一个文件路径.
path.parse(filepath)：path.format()方法的反向操作

</pre><pre class="js">
console.log(path.format({root: '/tmp/', base: 'hello.js'}))         // /tmp/hello.js;
console.log(path.format({dir: '/tmp', name: 'hello',ext: '.js'}));  // /tmp\hello.js

console.log(path.parse('/home/user/dir/file.txt'));
{
  root: '/',
  dir: '/home/user/dir',
  base: 'file.txt',
  ext: '.txt',
  name: 'file'
}
console.log(path.parse('./home/user/dir/file.txt'));
{
  root: '',
  dir: './home/user/dir',
  base: 'file.txt',
  ext: '.txt',
  name: 'file'
}


</pre><pre>
【 获取路径/文件名/扩展名 】
path.dirname(p)         返回路径中除去文件名的部分
path.basename(p, [ext]) 返回路径中的最后一部分,并不会判断是否文件名,ext 为需要截掉的尾缀内容
path.extname(p)         返回路径文件中的扩展名(若存在)

</pre><pre class="js">
console.log(path.dirname('http://pickeke3.ke12345.net/171022/22125111-1-W4S.jpg')); //'http://pickeke3.ke12345.net/171022'
console.log(path.basename('http://pickeke3.ke12345.net/171022/22125111-1-W4S.jpg'));//'22125111-1-W4S.jpg'
console.log(path.extname('http://pickeke3.ke12345.net/171022/22125111-1-W4S.jpg')); //'.jpg'

console.log( path.basename('/tmp/demo/js/test.js') );        //test.js
console.log( path.basename('/tmp/demo/js/test/') );          //test
console.log( path.basename('/tmp/demo/js/test') );           //test

console.log( path.basename('/tmp/demo/js/test.js', '.js') ); //test
console.log( path.basename('/tmp/demo/js/test/', '.js') );   //test
console.log( path.basename('/tmp/demo/js/test', '.js') );    //test

console.log(path.extname('/foo/bar/baz/asdf/a.txt'));        // .txt
console.log(path.extname('/foo/bar/baz/asdf/a.txt.html'));   // .html
console.log(path.extname('/foo/bar/baz/asdf/a.'));           // .
console.log(path.extname('C:/vajoy/test/.'));                //
console.log(path.extname('C:/vajoy/test/a'));                //
console.log(path.extname('.index'));                         //

</pre>【 path.normalize(filepath)  标准化路径字符串,处理冗余的".."、"."、"/"字符 】<pre class="js">
console.log(path.normalize('a/b/c/../user/vajoy/bin'));            // a\b\user\vajoy\bin\
console.log(path.normalize('a/b/c///../user/vajoy/bin/'));         // a\b\user\vajoy\bin\
console.log(path.normalize('a/b/c/.././///../user/vajoy/bin/..')); // a\user\vajoy
console.log(path.normalize('a/b/c/../../user/vajoy/bin/../../'));  // a\user\
console.log(path.normalize('a/../../user/vajoy/bin/../../../../'));// ..\..\
console.log(path.normalize('./a/.././user/vajoy/bin/./'));         // user\vajoy\bin\

</pre><pre>
【 path.join([...paths]) 】
将多个路径结合在一起,并转换为标准化的路径
使用平台特定的分隔符把全部给定的path片段连接到一起,并规范化生成的路径

</pre><pre class="js">
path.join(__dirname, './02art-template.js');  // 'C:\Users\lenove\Node\5.path\02.art-template.js'
path.join('/foo', 'bar', './baz');            // '/foo/bar/baz'
path.join('/foo', 'bar', '/baz', '..');       // '/foo/bar'
console.log(path.join('////./a', 'b////c', 'user/', 'vajoy', '..'));   // \a\b\c\user
console.log(path.join('a', '../../', 'user/', 'vajoy', '..'));         // ..\user
console.log(path.join('a', '../../', {}, 'vajoy', '..'));              // 存在非路径字符串,故抛出异常

</pre><pre>
【 path.isAbsolute(path) 】
判断path是否绝对路径 如'E:/abc'或以"/"开头的路径

</pre><pre class="js">
console.log(path.isAbsolute('../testFiles/secLayer'));     // false
console.log(path.isAbsolute('./join.js'));                 // false
console.log(path.isAbsolute('temp'));                      // false
console.log(path.isAbsolute('/temp/../..'));               // true
console.log(path.isAbsolute('E:/github/nodeAPI/abc/efg')); // true
console.log(path.isAbsolute('///temp123'));                // true

</pre><pre>
【 path.resolve([from ...], to) 】
把一个路径或路径片段的序列解析为一个绝对路径,将to参数解析为绝对路径

给定的路径的序列是 "从右往左" 被处理的,后面每个path被依次解析,直到构造完成一个绝对路径
如果某个from或to参数是绝对路径(如'E:/abc'或以"/"开头的路径)则将忽略之前的from参数
console.log(path.resolve('foo', '/baz', 'bar'));     // C:\baz\bar

如果处理完全部给定的path片段后还未生成一个绝对路径则当前工作目录(绝对路径)会被用上
console.log(path.resolve('bar', 'baz', 'foo'));       // C:\Users\lenovo\Desktop\bar\baz\foo

生成的路径是规范化后的,且末尾的斜杠会被删除,除非路径被解析为根目录
console.log(path.resolve('/foo', 'bar/', 'baz/'));    // C:\foo\bar\baz,foo前'/'代表根目录即'C:';且baz末尾的斜线会删除
console.log(path.resolve('/'));                       // C:\ 如果路径为根路径,末尾的斜线不会删除

长度为零的path片段会被忽略
console.log(path.resolve('foo', '/baz', '', 'bar'));  // C:\baz\bar

如果没有传入path片段,则resolve会返回当前工作目录的绝对路径
console.log(path.resolve());                          // C:\Users\lenovo\Desktop

</pre><pre class="js">
console.log(path.resolve('.', 'testFiles/..', 'trdLayer'));   //E:\wamp64\www\study\nodejs\fs\trdLayer
console.log(path.resolve('..', 'testFiles', 'a.txt'));        //E:\wamp64\www\study\nodejs\testFiles\a.txt
console.log(path.resolve('D:/vajoy', 'abc', 'D:/a'));         //D:\a
console.log(path.resolve('abc', 'vajoy', 'ok.gif'));      //E:\wamp64\www\study\nodejs\fs\abc\vajoy\ok.gif
console.log(path.resolve('abc', '/vajoy', '..', 'a/../subfile'));  //E:\subfile

</pre><pre>
【 path.relative(from, to) 】
获取从from到to的相对路径,可以看作path.resolve的相反实现

</pre><pre class="js">
path.resolve(from, path.relative(from, to)) == path.resolve(to)

console.log(path.relative('C:\\vajoy\\test\\aaa', 'C:\\vajoy\\impl\\bbb'));      // ..\..\impl\bbb
console.log(path.relative('C:/vajoy/test/aaa', 'C:/vajoy/bbb'));                 // ..\..\bbb
console.log(path.relative('C:/vajoy/test/aaa', 'D:/vajoy/bbb'));                 // D:\vajoy\bbb
console.log(path.relative('/data/orandea/test/aaa', '/data/orandea/impl/bbb'));  // ..\..\impl\bbb
console.log(path.relative('/data/demo', '/data/demo'));        // ''
console.log(path.relative('/data/demo', ''));                  // ..\..\wamp64\www\study\nodejs\fs

</pre>
</div>

<div id="querystring">
<h2>querystring模块</h2><pre>
查询字符串,一般是对http请求所带的数据进行解析,参数处理

var querystring = require('querystring')

</pre><pre class="js">
> querystring
{ unescapeBuffer: [Function: unescapeBuffer],
  unescape: [Function: qsUnescape],
  escape: [Function: qsEscape],
  stringify: [Function: stringify],
  encode: [Function: stringify],
  parse: [Function: parse],
  decode: [Function: parse] }

</pre><pre>
【 querystring.stringify参数对象序列化 】
二参为连接符默认&,三参为key value连接符默认=

> querystring.stringify({name: 'heiying', course: ['jade', 'node'], from: ''});
'name=heiying&course=jade&course=node&from='

【 querystring.parse参数字符串反序列化,参数对应stringify 】
> querystring.parse('name=heiying&course=jade&course=node&from=');
{ name: 'heiying', course: [ 'jade', 'node' ], from: '' }

【 querystring.escape参数转义,同js escape函数 】
该方法不会对ASCII字母和数字进行编码,也不会对下面这些ASCII标点符号进行编码* @ - _ + . / ,其他所有的字符都会被转义序列替换

encodeURI()函数可把字符串作为URI进行编码
返回值URIstring的副本,其中的某些字符将被十六进制的转义序列进行替换
该方法不会对ASCII字母和数字进行编码,也不会对这些ASCII标点符号进行编码： - _ . ! ~' ( ) .
该方法的目的是对URI进行完整的编码,因此对以下在URI中具有特殊含义的ASCII标点符号,encodeURI() 函数是不会进行转义的：;/?:@&=+$,#
如果URI组件中含有分隔符,比如 ? 和 #,则应当使用encodeURIComponent()方法分别对各组件进行编码

因为有效的URI不能包含某些字符如空格,encodeURI()方法用于将这个字符转换成浏览器可以接受的UTF-8编码
var suil = 'www.oseschool.com/pro file/a.html';
console.log(encodeURI(suil));//www.oseschool.com/pro%20file/a.html
// www.oseschool.com/pro%20file/a.html 即将空格编码成%20

decodeURI() 函数可对 encodeURI() 函数编码过的 URI 进行解码

encodeURIComponent() 函数 与 encodeURI() 函数的区别之处,前者假定它的参数是 URI 的一部分(比如协议、主机名、路径或查询字符串).因此 encodeURIComponent() 函数将转义用于分隔 URI 各个部分的标点符号

</pre><pre class="js">
> querystring.escape('name=heiying&course=jade&course=node&from=');
'name%3Dheiying%26course%3Djade%26course%3Dnode%26from%3D'
> querystring.escape('<哈哈>');
'%3C%E5%93%88%E5%93%88%3E'
> querystring.escape('abcdefgh');
'abcdefgh'
> querystring.escape('abcdefgh*--/++++abc');
'abcdefgh*--%2F%2B%2B%2B%2Babc'

</pre><pre>
【 querystring.unescape参数反转义 】
> querystring.unescape('name%3Dheiying%26course%3Djade%26course%3Dnode%26from%3D');
'name=heiying&course=jade&course=node&from='

</pre><pre class="js">
//查询url解析
var str = 'https://github.com/ruanyf/es6tutorial/search?utf8=%E2%9C%93&q=%E5%87%BD%E6%95%B0';
var urlto = querystring.unescape(str);
console.log(urlto);    // https://github.com/ruanyf/es6tutorial/search?utf8=✓&q=函数

url.parse(urlto);
{
  protocol: 'https:',
  slashes: true,
  auth: null,
  host: 'github.com',
  port: null,
  hostname: 'github.com',
  hash: null,
  search: '?utf8=✓&q=函数',
  query: 'utf8=✓&q=函数',
  pathname: '/ruanyf/es6tutorial/search',
  path: '/ruanyf/es6tutorial/search?utf8=✓&q=函数',
  href: 'https://github.com/ruanyf/es6tutorial/search?utf8=✓&q=函数'
}

path.dirname(urlto);   // 'https://github.com/ruanyf/es6tutorial'
path.basename(urlto);  // 'search?utf8=✓&q=函数'
path.extname(urlto);   // ''
path.parse(urlto);
{ root: '',
  dir: 'https://github.com/ruanyf/es6tutorial',
  base: 'search?utf8=✓&q=函数',
  ext: '',
  name: 'search?utf8=✓&q=函数'
}

</pre>
</div>

<!------------------------ util------------------------ -->
<div id="util">
<h2>util</h2><pre>
util是一个Node.js核心模块,提供常用函数的集合,用于弥补核心JS的功能过于精简的不足,JS的面向对象特性是基于原型复制

</pre><pre class="js">
> console.log(util.inspect(util,false,2,true))
{ format: [Function],
  deprecate: [Function],
  debuglog: [Function],
  inspect:
   { [Function: inspect]
     colors:
      { bold: [Object],
        italic: [Object],
        underline: [Object],
        inverse: [Object],
        white: [Object],
        grey: [Object],
        black: [Object],
        blue: [Object],
        cyan: [Object],
        green: [Object],
        magenta: [Object],
        red: [Object],
        yellow: [Object] },
     styles:
      { special: 'cyan',
        number: 'yellow',
        boolean: 'yellow',
        undefined: 'grey',
        null: 'bold',
        string: 'green',
        symbol: 'green',
        date: 'magenta',
        regexp: 'red' },
     custom: Symbol(util.inspect.custom) },
  isArray: [Function: isArray],
  isBoolean: [Function: isBoolean],
  isNull: [Function: isNull],
  isNullOrUndefined: [Function: isNullOrUndefined],
  isNumber: [Function: isNumber],
  isString: [Function: isString],
  isSymbol: [Function: isSymbol],
  isUndefined: [Function: isUndefined],
  isRegExp: [Function: isRegExp],
  isObject: [Function: isObject],
  isDate: [Function: isDate],
  isError: [Function: isError],
  isFunction: [Function: isFunction],
  isPrimitive: [Function: isPrimitive],
  isBuffer: [Function: isBuffer],
  log: [Function],
  inherits: [Function],
  _extend: [Function],
  print: [Function: deprecated],
  puts: [Function: deprecated],
  debug: [Function: deprecated],
  error: [Function: deprecated],
  _errnoException: [Function],
  _exceptionWithHostPort: [Function] }

</pre><pre>
【 util.inherits(constructor, superConstructor) 】
实现对象间原型继承,继承原型的方法和属性,构造函数内定义的方法和属性不会继承

</pre><pre class="js">
var util = require('util');
function Base() {
  this.name = 'base';
  this.sayHello = () => console.log('Hello ' + this.name);
}
Base.prototype.age = 18;
Base.prototype.showName = function() {
  console.log(this.name);
};
function Sub() {
  this.name = 'sub';
}
util.inherits(Sub, Base);
var objBase = new Base();
objBase.showName();        // base
objBase.sayHello();        // Hello base
console.log(objBase);      // Base { name: 'base', sayHello: [Function] }
var objSub = new Sub();
objSub.showName();          // sub
console.log(objSub.age);    // 18
console.log(objSub);        // Sub { name: 'sub' }
objSub.sayHello();          // TypeError

</pre><pre>
【 util.inspect(object,[showHidden],[depth],[colors]) 将任意对象转换为字符串,对象序列化 】
showHidden 是一个可选参数,如果值为 true,将会输出更多隐藏信息
depth      最大递归的层数,默认递归2层,null表示不限递归层数完整遍历对象
color      值为true输出格式将会以ANSI颜色编码,通常用于在终端显示更漂亮的效果

console.log(util.inspect(util, { showHidden: true, depth: null }));

自定义 util.inspect 颜色
util.inspect属性用于自定义输出的颜色和样式,可以通过util.inspect.styles 和util.inspect.colors 属性设置.
util.inspect.colors可定义的颜色有：white, grey, black, blue, cyan, green, magenta, red 和 yellow.
util.inspect.styles可定义的样式有:bold, italic, underline 和 inverse

</pre><pre class="js">
var util = require('util');
function Person() {
  this.name = 'byvoid';
  this.toString = function() {
    return this.name;
  };
}
var obj = new Person();
console.log(util.inspect(obj));        // Person { name: 'byvoid', toString: [Function] }
console.log(util.inspect(obj, true));

//Person {
  name: 'byvoid',
  toString:
   { [Function]
     [length]: 0,
     [name]: '',
     [arguments]: null,
     [caller]: null,
     [prototype]: { [constructor]: [Circular] }} }

</pre><pre>
【 util.promisify(original) 】
让一个遵循通常的Node.js回调风格的函数,即(err, value) => ... 回调函数是最后一个参数,返回一个返回值是一个promise版本的函数
如果原本就有original[util.promisify.custom]属性, promisify会返回它的值

promisify()会在所有情况下假定original是一个最后的参数是回调函数的函数,如果它不是,那么返回的函数的返回值为undefined

</pre><pre class="js">
const util = require('util');
const fs = require('fs');

const stat = util.promisify(fs.stat);
stat('.').then((stats) => {
  // Do something with `stats`
}).catch((error) => {
  // Handle the error.
});

</pre><pre class="js">
//使用async function获得等效的效果:
const util = require('util');
const fs = require('fs');

const stat = util.promisify(fs.stat);
async function callStat() {
  const stats = await stat('.');
  console.log(`This directory is owned by ${stats.uid}`);
}

</pre><pre class="js">
const fs = require('fs');
const { promisify } = require('util');  // 对象解构

const readFileAsync = promisify(fs.readFile);

async function read() {
  const content = await readFileAsync('./test.js', 'utf-8');
  return content;
}

read().then(v => {
  console.log(v);
});

</pre><pre>
【 util.format(str[, ...]) 字符串格式化后返回 】
根据第一个参数,返回一个格式化字符串,类似printf的格式化输出.
传入的第一个参数是一个字符串,其中包含零个或多个占位符,format方法会将其中的每一个占位符被替换为与其对应的值后,输出结果.
format方法支持的占位符有:

%s - 字符串.
%d - 数字 (整型和浮点型).
%j - JSON. 如果这个参数包含循环对象的引用,将会被替换成字符串 '[Circular]'.
%% - 单独一个百分号('%').不会占用一个参数.

console.log(util.format('%s:%s:%d', 'foo', 'bar', 'baz')); // foo:bar:NaN
console.log(util.format('%s:%s', 'foo'));                  // 'foo:%s'
console.log(util.format('%s:%s', 'foo', 'bar', 'baz'));    // 'foo:bar baz'
console.log(util.format(1, 2, 3));                         // '1 2 3'
console.log(util.format('%% %s'));                         // '%% %s'
console.log(util.format("a json object:%j",{name:"jk"}));//  a json object:{"name":"jk"}
console.log(util.format("aa","bb","cc"));                  // aa bb cc

【 util.log(string) 在控制台标准输出 】
用于在控制台stdout输出,输出带有时间戳.
util.log('这是一个stout输出');      // 4 Nov 20:09:03 - 这是一个stout输出

【 util.isArray(object)   是否是数组,返回布尔值 】
var util = require('util');
util.isArray([])         // true
util.isArray(new Array)  // true
util.isArray({})         // false

【 util.isRegExp(object) 是否是正则表达式返回布尔值 】
var util = require('util');
util.isRegExp(/some regexp/)                // true
util.isRegExp(new RegExp('another regexp')) // true
util.isRegExp({})                           // false

【 util.isDate(object) 是否是日期,返回布尔值 】
var util = require('util');
util.isDate(new Date())  // true
util.isDate(Date())      // false (without 'new' returns a String)
util.isDate({})          // false

【 util.isError(object) 是否是错误对象,返回布尔值 】
var util = require('util');
util.isError(new Error())     // true
util.isError(new TypeError()) // true
util.isError({ name: 'Error', message: 'an error occurred' }) // false

【 util.isBuffer(object) 是否是Buffer对象,返回布尔值 】
var buf = new Buffer(10);
util.isBuffer(buf)         //true

</pre>
</div>

<!------------------------ crypto------------------------ -->
<div id="crypto">
<h2>crypto模块导入加密解密库 var crypto = require("crypto");</h2><pre>
crypto模块提供了加密功能,包括对OpenSSL的哈希、HMAC、加密、解密、签名以及验证功能的一整套封装

Crypto库是随Nodejs内核一起打包发布的,利用OpenSSL库来实现加密技术,提供OpenSSL中的一系列哈希方法,包括hmac、cipher、decipher、签名和验证等方法的封装

加密算法就是把明文变成人家看不懂的东西,然后送给自己想要的送到的地方,接收方用配套的解密算法又把密文解开成明文,这样就不怕密文给人家截获而泄密。

加密算法的种类大致分为2类,一种是基于key的,一种不是基于key的。

不基于key的算法就是消息双方都通过一定的加密和解密算法来进行通信,这种算法缺点很明显如果加密算法被破解了就泄露了。

基于key的加密算法,key可以是一个随机产生的数字或一个单词等,只要用的算法认为选来做key的东西合法就行

所以基于key的加密算法又分为2类：对称加密和不对称加密。

对称加密算法的原理是通信一方用KEK加密明文,另一方收到之后用同样的KEY来解密就可以得到明文。

不对称加密指双方用不同的KEY加密和解密明文,通信双方都要有自己的公共密钥和私有密钥。假设通信双方A和B,A拥有KEY_A1,KEY_A2,其中KEY_A1是A的私有密钥,KEY_A2是A的公共密钥。 B拥有KEY_B1,KEY_B2,其中KEY_B1是B的私有密钥,KEY_B2是B的公共密钥。公共密钥和私有密钥的特点是,经过其中任何一把加密过的明文,只能用另外一把才能够解开。也就是说经过KEY_A1加密过的明文,只有KEY_A2才能够解密,反之亦然

不对称加密算法通信过程：
A-------->;KEY_A2------------>B
A<--------KEY_B2<------------A
这个过程叫做公共密钥交换keyexchange。之后A和B就分别用对方的公共密钥解密,用自己的私有密钥加密。
一般公共密钥是要发布出去的,这就是SSL使用的验证机制(注意不是数据传输机制),常用的不对称加密一般有RSA,DSA,DH等,一般使用RSA

【 关于SSL 】
一般情况下的网络协议应用中,数据在机器中经过简单的由上到下的几次包装,就进入网络,如果这些包被截获的话,那么可以很容易的根据网络协议得到里面的数据.由网络监听工具可以很容易的做到这一点。

SSL就是为了加密这些数据而产生的协议,位与应用层和 TCP/IP之间的一层,数据经过它流出的时候被加密再往TCP/IP送,而数据从TCP/IP流入之后先进入它这一层被解密,同时它也能够验证网络连接两端的身份(根据不对称加密算法只是可知)。

SSL协议包含2个子协议,一个是包协议,一个是握手协议。包协议位于握手协议更下一层。SSL握手过程说简单点就是：通信双方通过不对称加密算法来协商好一个对称加密算法以及使用的key,然后用这个算法加密以后所有的数据完成应用层协议的数据交换。

SSL通信流程：
握手一般都是由client发起的,SSL也不例外。
1、client送给server它自己本身使用的ssl的version(ssl一共有三个version),加密算法的一些配置,和一些随机产生的数据,以及其他在SSL协议中需要用到的信息。
2、server送给client它自己的SSL的version,加密算法的配置,随机产生的数据,还会用自己的私有密钥加密SERVER-HELLO信息。Server还同时把自己的证书文件给送过去。同时有个可选的项目,就是server可以要求需要客户的certificate。
3、client就用server送过来的certificate来验证server的身份。如果server身份验证没通过,本次通信结束。通过证书验证之后,得到server的公共密钥,解开server送来的被其用私有密钥加密过的SERVER-HELLO信息,看看对头与否。如果不对,说明对方只有该server的公共密钥而没有私有密钥,必是假的。通信告吹。
4、client使用到目前为止所有产生了的随机数据(sharedsecret),client产生本次握手中的premastersecret(这个步骤是有可能有server的参与的,由他们使用的加密算法决定),并且把这个用server的公共密钥加密,送回给server.如果server要求需要验证client,那么client也需要自己把自己的证书送过去,同时送一些自己签过名的数据过去。
RSA就是我们上一章说过的一种不对称加密算法。首先server把自己的RSA公共密钥送给client,client于是用这个key加密一个随机产生的值(这个随机产生的值就是sharedsecret),再把结果送给server.
5、Server验证完client的身份之后,然后用自己的私有密钥解密得到premastersecret然后双方利用这个premastersecret来共同协商,得到mastersecret.
6、双方用master一起产生真正的sessionkey,着就是他们在剩下的过程中的对称加密的key了。这个key还可以用来验证数据完整性。双方再交换结束信息,握手结束。

openssl就是实现ssl的一个软件

公开密钥加密包括4个类,Cipher, Decipher,Sign, and Verify,即加密,解密,签名,验证

</pre>

<h3>Hash算法</h3><pre>
哈希算法是指将任意长度的二进制值映射为较短的固定长度的二进制值,这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。如果散列一段明文而且哪怕只更改该段落的一个字母,随后的哈希都将产生不同的值。要找到散列为同一个值的两个不同的输入,在计算上是不可能的,所以数据的哈希值可以检验数据的完整性,一般用于快速查找和加密算法。

通常登陆密码都是使用Hash算法进行加密,典型的哈希算法包括 'md5'、'sha'、'sha1'、'sha256'、'sha512'、'RSA-SHA'
MD5是最常用的,但是有一定的碰撞问题,可以使用更新的sha1算法

crypto.getHashes()
获取当前node.js版本支持的算法,返回值为一个数组

</pre><pre class="js">
var crypto = require("crypto");
console.log(crypto.getHashes());

[ 'DSA',
  'DSA-SHA',
  'DSA-SHA1',
  'DSA-SHA1-old',
  'RSA-MD4',
  'RSA-MD5',
  'RSA-MDC2',
  'RSA-RIPEMD160',
  'RSA-SHA',
  'RSA-SHA1',
  'RSA-SHA1-2',
  'RSA-SHA224',
  'RSA-SHA256',
  'RSA-SHA384',
  'RSA-SHA512',
  'dsaEncryption',
  'dsaWithSHA',
  'dsaWithSHA1',
  'dss1',
  'ecdsa-with-SHA1',
  'md4',
  'md4WithRSAEncryption',
  'md5',
  'md5WithRSAEncryption',
  'mdc2',
  'mdc2WithRSA',
  'ripemd',
  'ripemd160',
  'ripemd160WithRSA',
  'rmd160',
  'sha',
  'sha1',
  'sha1WithRSAEncryption',
  'sha224',
  'sha224WithRSAEncryption',
  'sha256',
  'sha256WithRSAEncryption',
  'sha384',
  'sha384WithRSAEncryption',
  'sha512',
  'sha512WithRSAEncryption',
  'shaWithRSAEncryption',
  'ssl2-md5',
  'ssl3-md5',
  'ssl3-sha1',
  'whirlpool' ]

</pre><pre>
Hash类是用于创建数据哈希值的工具类,能用以下方法使用：
1、作为一个stream既可读又可写,数据被写入要在可读的方面生成一个计算散列摘要
2、使用hash.update()和hash.digest()方法产生计算后的哈希

crypto.createHash(algorithm[, options])
创建Hash实例,Hash不能直接使用new关键字创建对象
参数algorithm算法,返回Hash对象即生成器,生成器是生成一小段字符串,用来验证数据完整性

hash.update(data[, inputEncoding])
Updates the hash content with the given data, the encoding of which is given in inputEncoding and can be 'utf8', 'ascii' or 'latin1'. If encoding is not provided, and the data is a string, an encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or DataView, then inputEncoding is ignored.

This can be called many times with new data as it is streamed

hash.digest([encoding])
默认返回的是2进制的数据,hash.digest('hex')表示返回16进制字符串数据,digest()方法被调用之后hash对象就被清空了是不能被重用的,需要重新调用createHash方法
Calculates the digest of all of the data passed to be hashed (using the hash.update() method). The encoding can be 'hex', 'latin1' or 'base64'. If encoding is provided a string will be returned; otherwise a Buffer is returned.

The Hash object can not be used again after hash.digest() method has been called. Multiple calls will cause an error to be thrown.

</pre>对string进行sha1算法<pre class="js">
function sha1(str){
  return crypto.createHash('sha1').update(str).digest('hex');
}

</pre>通过某种手段把数据通过多次或一次性的加入到md5生成器中,然后调用digest方法得到一小段字符串<pre class="js">
var crypto = require("crypto");          // 导入加密解密库
var md5hash = crypto.createHash("md5");  // 创建一个md5生成工具对象
var str = "admin";                       // 测试用的字符串
md5hash.update(str);                     // 把字符串md5生成器,可多次调用
var hexstr = md5hash.digest("hex");      // 生成最终的md5值
console.log(hexstr);                     // 21232f297a57a5a743894a0e4a801fc3

// 第二次生成同样的字符串
md5hash = crypto.createHash("md5");      // 创建一个md5生成工具对象;若已调用过digest,必须重新生成md5hash
md5hash.update(str);                     // 把字符串md5生成器,可多次调用
hexstr = md5hash.digest("hex");          // 第二次生成最终的md5值
console.log(hexstr);                     // 21232f297a57a5a743894a0e4a801fc3

// 第三次生成
md5hash = crypto.createHash("md5");
md5hash.update(str);                     // 把字符串md5生成器,可多次调用
md5hash.update("leo");
hexstr = md5hash.digest("hex");          // 第三次生成最终的md5值
console.log(hexstr);                     // 4d8c5483d3e039053c2de6d3a79108a0

</pre>目标字符串分开、合并调用update()方法时效果一致<pre class="js">
var crypto = require("crypto");
var sha = crypto.createHash("sha");
sha.update("my name is ")
sha.update("利奥")
console.log(sha.digest("hex"))           // 99bf7b8a87fe68b4f690e0deaf8b474e32b40385

var crypto = require("crypto");
var sha = crypto.createHash("sha");
sha.update("my name is 利奥")
console.log(sha.digest("hex"))          // 99bf7b8a87fe68b4f690e0deaf8b474e32b40385

</pre><pre class="js">
// 使用Hash对象作为流:
const crypto = require('crypto');
const hash = crypto.createHash('sha256');

hash.on('readable', () => {
  const data = hash.read();
  if (data) console.log(data.toString('hex'));
  // 6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50
});

hash.write('some data to hash');
hash.end();

// 使用Hash和管道流
const crypto = require('crypto');
const fs = require('fs');
const hash = crypto.createHash('sha256');

const input = fs.createReadStream(process.argv[2]);
input.pipe(hash).pipe(process.stdout);  // ȶ�1=z� �JA�L�@��D.[۬�w�

// generating the sha256 sum of a file specified by the process argv
const filename = process.argv[2];
const crypto = require('crypto');
const fs = require('fs');

const hash = crypto.createHash('sha256');

const input = fs.createReadStream(filename);
input.on('readable', () => {
  const data = input.read();
  if (data) hash.update(data)
  else console.log(`${hash.digest('hex')} ${filename}`)
    // f745c593835e9a8ff5349385d1b0107d642884e805e91e89016fdb545981c979 hash.js
});

</pre>测试哈希算法的加密计算时间和编码长度<pre class="js">
var crypto = require('crypto');
var fs = require('fs');

function hashAlgorithm(algorithm){
  var t =new Date();
  var file = 'md5.js';
  var rs = fs.createReadStream(file);
  var shasum = crypto.createHash(algorithm);
  rs.on('data', data => shasum.update(data));
  rs.on('end', () => {
    var res = shasum.digest('hex');
    console.log(algorithm + ', ' + (new Date() - t) + ', ' + res);
  })
}

function dohash(hashs){
  hashs.forEach(hash => hashAlgorithm(hash))
}

var hashs = [ 'md5','sha','sha1','sha256','sha512','RSA-SHA','RSA-SHA1','RSA-SHA256','RSA-SHA512'];
dohash(hashs);

/*
md5, 7, 39fb4932cfec812a3a342f90c647bbc6
sha, 9, 30051f783aa122e92b73ce3ab2b4820cd59d2035
sha1, 13, cef34f60d267d2dc8ac1cc347c7ec5dd5b5e9a9a
sha256, 15, 56858efb6859edbaf005276d1b62d91466cc7b8658e018cb1083f3618dd7423b
sha512, 15, 0c4df8cb08c1c80721d9ac271a4567cda8ae5693cab475664ee056a97c2b5de57071b4931b22c6a1bb87ddd08a401f915b0884cd90aeeee1eee90ee0764917d6
RSA-SHA, 18, 30051f783aa122e92b73ce3ab2b4820cd59d2035
RSA-SHA1, 19, cef34f60d267d2dc8ac1cc347c7ec5dd5b5e9a9a
RSA-SHA256, 20, 56858efb6859edbaf005276d1b62d91466cc7b8658e018cb1083f3618dd7423b
RSA-SHA512, 21, 0c4df8cb08c1c80721d9ac271a4567cda8ae5693cab475664ee056a97c2b5de57071b4931b22c6a1bb87ddd08a401f915b0884cd90aeeee1eee90ee0764917d6
*/

</pre><pre>
【 crypto.randomBytes(size, [callback]) 】
生成加密用的伪随机码,支持2种方法,当传递cb的话就是异步方法,不传cb就是同步方法：

</pre>生成256位伪随机码,类型位Buffer<pre class="js">
// async
crypto.randomBytes(256, (err, buf) => {
  if (err) throw err;
  console.log(buf);
});

// sync
try {
  var buf = crypto.randomBytes(256);
  console.log(buf);
} catch (ex) {
  throw err;
}

</pre><pre>
【 salt算法 】
如果直接对密码进行散列,黑客可以对通过获得这个密码散列值,然后通过查散列值字典(如MD5密码破解网站)得到某用户的密码

盐(Salt)在密码学中是指通过在密码任意固定位置插入特定的字符串,让散列后的结果和使用原始密码的散列结果不相符,这种过程称之为"加盐"。
加盐后的散列值可以极大的降低由于用户数据被盗而带来的密码泄漏风险,即使通过彩虹表寻找到了散列后的数值所对应的原始内容,但是由于经过了加盐,插入的字符串扰乱了真正的密码,使得获得真实密码的概率大大降低。

加盐的实现过程通常是在需要散列的字段的特定位置增加特定的字符打乱原始的字串,使其生成的散列结果产生变化
比如用户使用密码：123465, 经过MD5散列后可以得出结果：3d9188577cc9bfe9291ac66b5cc872b7
但是由于用户密码位数不足,短密码的散列结果很容易被彩虹表破解,因此在用户的密码末尾添加特定字串：
123465abcdefghijklmnopqrstuvwxyz
因此加盐后的密码位数更长了,散列的结果也发生了变化：
27e20c64ccb8cce9ad68b8ccff6252cf

</pre>salt算法<pre class="js">
var crypto = require('crypto');
var md5 = crypto.createHash('md5');
var txt = "123465";
md5.update(txt);
console.log(md5.digest('hex'));

md5 = crypto.createHash('md5');
var salt = "abcdefghijklmnopqrstuvwxyz";
md5.update(txt+salt);
console.log(md5.digest('hex'));

</pre><pre>
可以不用动手加盐,而使用crypto.pbkdf2()函数,默认会调用hmac算法,用sha1的散列函数,并且可以设置迭代次数和密文长度

crypto.pbkdf2(password, salt, iterations, keylen, digest, callback)
异步的方法,通过伪随机码来加密迭代数次,利用sha1算法生成一个更加强壮的加密串。结合crypto.randomBytes来生成一个强壮的加密串

</pre><pre class="js">
crypto.pbkdf2('secret', 'salt', 100000, 64, 'sha512', (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});

</pre><pre class="js">
crypto.randomBytes(128, (err, salt) => {
  if (err) throw err;
  salt = new Buffer(salt).toString('hex');
  crypto.pbkdf2('123456', salt, 7000, 256, (err,hash) => {
    if (err) throw err;
    hash = new Buffer(hash).toString('hex');
    console.log(hash);
  })
})

</pre><pre class="js">
var crypto = require('crypto');
var txt = "123465";
var salt = "abcdefghijklmnopqrstuvwxyz";

// 生成密文,默认HMAC函数是sha1算法,生成256位的密文
crypto.pbkdf2(txt, salt, 4096, 256, function (err, hash) {
  if (err) throw err;
  console.log(hash.toString('hex'));
})

// 29c7de002d942ebcbf3afe05f3eb0ff620f0515fe6b8f19176736273cd70805afdfcc828a6f227152dfa4d0c4f96da184fbd060d4d4c86a5deb8d704699c3e8653acdb0e5bc3e584e0890a44206bb2926f0289fc8e0abe49fd1876461fcc50f06dc7991c4b93cc4e80076529c73b2f2c56f16b5b319368edf017f3d3583a33aa44fd30f89801f0d8877eb8262925f5fdc40a5c57f1b275e5674784dca635c75bc58b6c22264e0f29e363eb25dedf1a242429084e3e17d344b59cab3b9723db03ee4838b632786d1a9eb968f2523404286e5d0a41a1707577650cc3cc2f1ab65714a4cb31f068e4aefa259c6be68174e0a475d5610168305a4935a14bb221a516

</pre><pre>
如果加盐每次都是固定的值也会不安全,还可以利用随机randomBytes()函数,配合pbkdf2()函数,让每次都是不同的salt,生成安全级别更高的密文
把salt和密文一起进行存储,保证用户密码的安全性

</pre><pre class="js">
// 通过伪随机码生成salt,进行加密
crypto.randomBytes(128, function (err, salt) {
  if (err) throw err;
  salt = salt.toString('hex');
  console.log(salt);     //生成salt

  crypto.pbkdf2(txt, salt, 4096, 256, function (err,hash) {
    if (err) throw err;
    hash = hash.toString('hex');
    console.log(hash);
  })
})

/*
# 随机生成的salt
78e59de99f16697e3eb684dcfa8efa086db0940c7cd47d33f9311e3bfcf9d58bf30915f54b3f72793b5c8568d32f1f15c55cc87affd043d96f1ed1f56c25a8054b3d83a306636f3b9e3bc9e48c3303aff54da006f92e370023165857fce0a1d1ff0b89178ae8c1416747275daba25652ea864d52a80427658ea69dbe500a7261

# 通过salt生成的密文
48943eb51ea702b436f95bf1dacc7f64bc41cf7cfa4cb40d101d5550c28caafc58ca720934352238430634f21fd5a6a4ef63fe5828c2665362e9902adc0305f93d2523fbd28521ad00947a74ff8229f63ad5796f2e12677cbed6af02b9973ee0187a69ad67e86790471d95f18d6d2c43ef904f7d17a5d8264f8236f227363a016ae2c14559c17236d540e06c5fd443af740721897f76bdbd9711c8499d7a34cae2e917f900fc364f72f9afaf301845c6e0b5c37def949b4af62336a39dbd1e829405d6189536092c7769a5d7e427b8e97419988da4e1bad49c69f25ac4e96f74a0ce3eab9e1433277568105b1dcc0cf9e1f9c91a7ed391c5825eefcd71ef5ca1
*/

</pre>

<h3>Hmac算法</h3><pre>
HMAC是密钥相关的哈希运算消息认证码(Hash-based Message Authentication Code),HMAC运算利用哈希算法,以一个密钥和一个消息为输入,生成一个消息摘要作为输出。HMAC可以有效防止一些类似md5的彩虹表等攻击,比如一些常见的密码直接MD5存入数据库的,可能被反向破解。

定义HMAC需要一个加密用散列函数(表示为H,可以是MD5或SHA-1)和一个密钥K。用B来表示数据块的字节数。(以上所提到的散列函数的分割数据块字长B=64),用L来表示散列函数的输出数据字节数(MD5中L=16,SHA-1中L=20)。鉴别密钥的长度可以是小于等于数据块字长的任何正整数值。应用程序中使用的密钥长度若是比B大,则首先用使用散列函数H作用于它,然后用H输出的L长度字符串作为在HMAC中实际使用的密钥。一般情况下推荐的最小密钥K长度是L个字节

由于Hmac有了第二参数key,所以比单独的hash加密登陆密码有更好的安全性上的保证

对于网站登陆密码的设计,可做成2个字段存储,password字段存密文,passkey字段存储key,把算法直接封装到程序里面
{
  username: 'xxxx'
  password: 'aead69a72da77d0615a854dda1086d885807574a',
  passkey:'abc'
}
就算数据库被攻击,黑客也只是拿了密文和key,密码明文并没有被泄露,并且在不知道加密算法的情况下,也很难通过彩虹表进行攻击

Hmac类是用于创建加密Hmac摘要的工具,有两种用法:
1、作为stream,它既可读又可写,数据被写入要在可读的方面生成一个经过计算的HMAC摘要。
2、使用hmac.update()和hmac.digest()方法产生计算后的HMAC摘要

crypto.createHmac(algorithm, key[, options])
创建Hmac实例,Hmac不能直接使用new关键字创建对象
参数algorithm算法
参数key不同获取到的字符串也不同
返回Hmac对象,即生成器

hmac.update(data[, inputEncoding])
hmac.digest([encoding])

采用Hmac方式只知道验证字符串还不够,还得知道key,才能确定数据是否一致

</pre><pre class="js">
function sh1_hmac(str, key){
  return crypto.createHmac("sha1", key).update(str).digest("hex")
}

</pre><pre class="js">
var crypto = require("crypto");
var sha = crypto.createHmac("sha","nodejs");
sha.update("admin")
console.log(sha.digest("hex"))           // 4376696a091657d4f615b02aa6d97ce92962f927
var sha = crypto.createHmac("sha","js");
sha.update("admin")
console.log(sha.digest("hex"))           // fa065523b6ead13dcdb9f61a62c6d06c061fb715

</pre><pre class="js">
var crypto = require('crypto');
var fs = require('fs');
var pem = fs.readFileSync('key.pem');
var key = pem.toString('ascii');       // 通过fs.readFileSync方法读取了key.pem密钥,然后将它转为ascii码
var hmac = crypto.createHmac('sha1', key);
hmac.update('foo');
hmac.digest('hex');                    // 生成一串密钥字符串
// '7b058f2f33ca28da3ff3c6506c978825718c7d42'

</pre>generating the sha256 HMAC of a file<pre class="js">
const filename = process.argv[2];
const crypto = require('crypto');
const fs = require('fs');

const hmac = crypto.createHmac('sha256', 'a secret');

const input = fs.createReadStream(filename);
input.on('readable', () => {
  const data = input.read();
  if (data) hmac.update(data);
  else console.log(`${hmac.digest('hex')} ${filename}`);
  // 93cfa3727d36ac96617304858eb65fd4f6b52612abca8fb173235fe501b18ec2 hash.js
});

</pre>使用Hmac对象作为流<pre class="js">
const crypto = require('crypto');
const hmac = crypto.createHmac('sha256', 'a secret');

hmac.on('readable', () => {
  const data = hmac.read();
  if (data) console.log(data.toString('hex'));
  // 7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77e
});

hmac.write('some data to hash');
hmac.end();

// 使用Hmac和管道流
const crypto = require('crypto');
const fs = require('fs');
const hmac = crypto.createHmac('sha256', 'a secret');

const input = fs.createReadStream('test.js');
input.pipe(hmac).pipe(process.stdout);

</pre>测试hmac算法的加密计算时间和编码长度<pre class="js">
var crypto = require('crypto');
var fs = require('fs');

function hmacAlgorithm(algorithm, key){
  var t =new Date();
  var file = 'md5.js';
  var rs = fs.createReadStream(file);
  var shasum = crypto.createHmac(algorithm, key);
  rs.on('data', data => shasum.update(data));
  rs.on('end', () => {
    var res = shasum.digest('hex');
    console.log(algorithm + ', ' + (new Date() - t) + ', ' + res);
  })
}

function doHmac(hashs, key){
  console.log(`\nKey : ${key} \n===============================`);
  hashs.forEach(hash => hmacAlgorithm(hash, key))
}

var hashs = [ 'md5','sha','sha1','sha256','sha512','RSA-SHA','RSA-SHA1','RSA-SHA256','RSA-SHA512'];

// 短key测试
setTimeout(() => doHmac(hashs, 'abc'), 1);
// 长key测试
setTimeout(() => doHmac(hashs, 'jifdkd;adkfaj^&fjdifefdafda,ijjifdkd;adkfaj^&fjdifefdafdaljifdkd;adkfaj^&fjdifefdafda'), 2*1000);

/*
Key : abc
===============================
md5, 6, d839b63bb37b1f8ca1a559957f93fc2b
sha, 7, 2fbc426f327260d7930b000074b102d90d959898
sha1, 8, d3b6bfa87d35926a57d8b1f1004e6507ef5aadb5
sha256, 8, b72b1ea0c751e2153cd95e4e477572adf8d1af81baaf66ac917875823620fe79
sha512, 10, 7dad7f82e880dae5fbef7a429006ea20a82d0558a74d8655e85c981f007701473800ad375ad2ac7f4fbc4ad7197efa02c8e185978220fe8b98899b434a9027fd
RSA-SHA, 11, 2fbc426f327260d7930b000074b102d90d959898
RSA-SHA1, 12, d3b6bfa87d35926a57d8b1f1004e6507ef5aadb5
RSA-SHA256, 12, b72b1ea0c751e2153cd95e4e477572adf8d1af81baaf66ac917875823620fe79
RSA-SHA512, 13, 7dad7f82e880dae5fbef7a429006ea20a82d0558a74d8655e85c981f007701473800ad375ad2ac7f4fbc4ad7197efa02c8e185978220fe8b98899b434a9027fd

Key : jifdkd;adkfaj^&fjdifefdafda,ijjifdkd;adkfaj^&fjdifefdafdaljifdkd;adkfaj^&fjdifefdafda
===============================
md5, 2, 9292ab58eaa3a42a7c03b78edc133f09
sha, 2, 8cd5fa5be4d092fe45cf0d2421f79f8d50963b1e
sha1, 3, 338aac61a72190b2e68b897190163ac5fe53e8de
sha256, 4, 0b5cb71b67c2fbfbd191d39fbe8b7f00172b468ec1c17b9a520d9e3f318f994b
sha512, 5, 5664e7adecc33a412ae20040801241c05c97a94f9b5ee968bb714234dedc6f759642798401f5f3198c2fd361b94a4c4c1c1bc28d7b3e77ab9e0f2d74adc8045d
RSA-SHA, 6, 8cd5fa5be4d092fe45cf0d2421f79f8d50963b1e
RSA-SHA1, 7, 338aac61a72190b2e68b897190163ac5fe53e8de
RSA-SHA256, 9, 0b5cb71b67c2fbfbd191d39fbe8b7f00172b468ec1c17b9a520d9e3f318f994b
RSA-SHA512, 10, 5664e7adecc33a412ae20040801241c05c97a94f9b5ee968bb714234dedc6f759642798401f5f3198c2fd361b94a4c4c1c1bc28d7b3e77ab9e0f2d74adc8045d
*/

</pre><pre>
【 openssl 关于key.pem 】
OpenSSL是一个安全套接字层密码库,囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议,并提供丰富的应用程序供测试或其它目的使用

SSL是Secure Sockets Layer(安全套接层协议),可以在Internet上提供秘密性传输。Netscape公司在推出第一个Web浏览器的同时,提出了SSL协议标准,其目标是保证两个应用间通信的保密性和可靠性,可在服务器端和用户端同时实现支持。已经成为Internet上保密通讯的工业标准

SSL能使用户/服务器应用之间的通信不被攻击者窃听,并且始终对服务器进行认证,还可选择对用户进行认证。SSL协议要求建立在可靠的传输层协议(TCP)之上。SSL协议的优势在于它是与应用层协议独立无关的,高层的应用层协议(例如：HTTP,FTP,TELNET等)能透明地建立于SSL协议之上。SSL协议在应用层协议通信之前就已经完成加密算法、通信密钥的协商及服务器认证工作。在此之后应用层协议所传送的数据都会被加密,从而保证通信的私密性

OpenSSL是一个开源项目,其组成主要包括一下三个组件：
openssl：多用途的命令行工具
libcrypto：加密算法库
libssl：加密模块应用库,实现了ssl及tls

HTTPS是一种协议,等于HTTP+TLS(由于历史原因,SSL3.0之后就被TLS1.0替代了)

【 Windows下openssl安装与配置 】
下载ActivePerl,网址: http://www.activestate.com/activeperl/
配置过程中需要生成一些mak文件,这些生成代码用perl脚本生成,所以要安装一个ActivePerl

下载openssl,网址 http://www.openssl.org/
参照INSTALL.W32文件安装

【 openssl可以实现：秘钥证书管理、对称加密和非对称加密   】
1、对称加密
对称加密需要使用的标准命令为enc,用法如下：
openssl enc -ciphername [-in filename] [-out filename] [-pass arg] [-e] [-d] [-a/-base64]
       [-A] [-k password] [-kfile filename] [-K key] [-iv IV] [-S salt] [-salt] [-nosalt] [-z] [-md]
       [-p] [-P] [-bufsize number] [-nopad] [-debug] [-none] [-engine id]

常用选项有：
-in filename：指定要加密的文件存放路径
-out filename：指定加密后的文件存放路径
-salt：自动插入一个随机数作为文件内容加密,默认选项
-e：可以指明一种加密算法,若不指的话将使用默认加密算法
-d：解密,解密时也可以指定算法,若不指定则使用默认算法,但一定要与加密时的算法一致
-a/-base64：使用-base64位编码格式

示例：
加密：]# openssl enc -e -des3 -a -salt -in fstab -out jiami
解密：]# openssl enc -d -des3 -a -salt -in fstab -out jiami

2、单向加密
单向加密需要使用的标准命令为dgst
openssl dgst [-md5|-md4|-md2|-sha1|-sha|-mdc2|-ripemd160|-dss1] [-c] [-d] [-hex] [-binary]
       [-out filename] [-sign filename] [-keyform arg] [-passin arg] [-verify filename] [-prverify
       filename] [-signature filename] [-hmac key] [file...]

常用选项有：
[-md5|-md4|-md2|-sha1|-sha|-mdc2|-ripemd160|-dss1] ：指定一种加密算法
-out filename：将加密的内容保存到指定文件中

单向加密除了openssl dgst工具还有： md5sum,sha1sum,sha224sum,sha256sum ,sha384sum,sha512sum

3、生成密码
生成密码需要使用的标准命令为passwd
openssl passwd [-crypt] [-1] [-apr1] [-salt string] [-in file] [-stdin] [-noverify] [-quiet] [-table] {password}

常用选项有：
-1：使用md5加密算法
-salt string：加入随机数,最多8位随机数
-in file：对输入的文件内容进行加密
-stdion：对标准输入的内容进行加密

4、生成随机数
生成随机数需要用到的标准命令为rand
openssl rand [-out file] [-rand file(s)] [-base64] [-hex] num

常用选项有：
-out file：将生成的随机数保存至指定文件中
-base64：使用base64 编码格式
-hex：使用16进制编码格式

5、生成秘钥对
首先需要先使用genrsa标准命令生成私钥,然后再使用rsa标准命令从私钥中提取公钥。

genrsa的用法：
openssl genrsa [-out filename] [-passout arg] [-des] [-des3] [-idea] [-f4] [-3] [-rand file(s)] [-engine id] [numbits]

常用选项：
-out filename：将生成的私钥保存至指定的文件中
-des|-des3|-idea：不同的加密算法
numbits：指定生成私钥的大小,默认是2048

一般情况下秘钥文件的权限一定要控制好,只能自己读写,因此可以使用umask命令设置生成的私钥权限

利用opensll命令来创建一个key.pem
# openssl genrsa -out server.pem 1024
# vi server.pem
-----BEGIN RSA PRIVATE KEY-----
MIICXQIBAAKBgQCoWUIOtZAA4EB/bBpKBiHzDRdPCsSqTkR0Bva5kUUjVQ/2y6mi
eZl244GGTwfiFtbHdu0eum4MkIes6IL/kJ8IDeyg4za26fEcO2mfty6BQbSo2SRr
ZdIGVCZ2atvuc2ObzgVpJ+p1GGoFeNS1HOhw0Hq2GoeKt2rMdXceklXaLQIDAQAB
AoGASC/t+Wy1UQrX3Uu3giJbEGN+qTAO4JArHi2WQkAei2YAMG1oUfkeazJm6fad
hL8SXfmK9/AtHEolQ2l4MqoK5rD5kvoLNOWs+sIOd1Zi9jLow8F8x+ctphn5FdZz
J444Mk3M3ua5ZS1YCy12pEbdO6urNMgUpqYcEla0BHIJ8MECQQDaxG9UyId5CgOH
PCXy2oT3dSAa3XJeQ7fC5Tl4Tb4lKezho0Lk/g369cU3O6LWM9g65QQk/Vewtbpe
fKoOtQcFAkEAxQAciOPbASojxZDiyy0CTbgj4PGaPBFwJis/wetAyBQcOKOM7l1h
wHg8fUSXNYLHi6paDqtjaOvVfDOnRdMfCQJBAJg/4WNV88JvD6mMWLS9E5DMeL15
pGCqLDd9JBPvtwdSOEOIRcPsc3pWlRwtatQ8XJ4QSGQd1Gts7flYNVnq7qkCQQC0
3txUBrfNwu3i95pyppll1/oBDnHoUq5gLPc1yRPKX0Rl8Ct1soEMYJhQ/wfBlpg1
MCvNKih0bYqtpRMgNa1ZAkAT5kLpwW5Rb0OxVkHLwtOvixgKABPeGg8JuQS/POHS
lEWvqaaUKdcVcje5YgMg6hDjWHTFJRQ1UEUubYTLFU/D
-----END RSA PRIVATE KEY-----

# openssl genrsa -des3 -out server.key 1024
genras表示生成RSA私有密钥文件,-des3表示用DES3加密该文件,1024是key的长度。一般用512就可以了,784可用于商业行为了,1024可以用于军事用途了。生成server.key的时候会要输入一个密码,这个密钥用来保护server.key文件,这样即使人家偷走server.key文件,也打不开,拿不到私有密钥。

ras的用法：
openssl rsa [-inform PEM|NET|DER] [-outform PEM|NET|DER] [-in filename] [-passin arg] [-out filename] [-passout arg]
       [-sgckey] [-des] [-des3] [-idea] [-text] [-noout] [-modulus] [-check] [-pubin] [-pubout] [-engine id]

常用选项：
-in filename：指明私钥文件
-out filename：指明将提取出的公钥保存至指定文件中
-pubout：根据私钥提取出公钥

7、创建CA和申请证书
使用openssl工具创建CA证书和申请证书时,需要先查看配置文件,因为配置文件中对证书的名称和存放位置等相关信息都做了定义,具体可参考 /etc/pki/tls/openssl.cnf 文件

</pre>

<h3>Cipher加密和Decipher解密算法</h3><pre>
登陆密码是不需要考虑解密的,通常都会用不可逆的算法如md5、sha1等。但对有安全性要求的数据来说是需要加密存储,然后解密使用的,这时需要用到可逆的加密算法。对于这种基于KEY算法可以分为对称加密和不对称加密

对称加密算法的原理很容易理解,通信一方用KEY加密明文,另一方收到之后用同样的KEY来解密就可以得到明文。
不对称加密算法使用两把完全不同但又是完全匹配的一对Key:公钥和私钥。在使用不对称加密算法加密文件时,只有使用匹配的一对公钥和私钥才能完成对明文的加密和解密过程。
对于这种类型的操作,Crypto包也提供了大量的算法支持: Ciphers

</pre><pre class="js">
var crypto = require('crypto');
console.log(crypto.getCiphers());

/*
[ 'aes-128-cbc',
  'aes-128-cbc-hmac-sh
  'aes-128-cbc-hmac-sh
  'aes-128-ccm',
  'aes-128-cfb',
  'aes-128-cfb1',
  'aes-128-cfb8',
  'aes-128-ctr',
  'aes-128-ecb',
  'aes-128-gcm',
  'aes-128-ofb',
  'aes-128-xts',
  'aes-192-cbc',
  'aes-192-ccm',
  'aes-192-cfb',
  'aes-192-cfb1',
  'aes-192-cfb8',
  'aes-192-ctr',
  'aes-192-ecb',
  'aes-192-gcm',
  'aes-192-ofb',
  'aes-256-cbc',
  'aes-256-cbc-hmac-sh
  'aes-256-cbc-hmac-sh
  'aes-256-ccm',
  'aes-256-cfb',
  'aes-256-cfb1',
  'aes-256-cfb8',
  'aes-256-ctr',
  'aes-256-ecb',
  'aes-256-gcm',
  'aes-256-ofb',
  'aes-256-xts',
  'aes128',
  'aes192',
  'aes256',
  'bf',
  'bf-cbc',
  'bf-cfb',
  'bf-ecb',
  'bf-ofb',
  'blowfish',
  'camellia-128-cbc',
  'camellia-128-cfb',
  'camellia-128-cfb1',
  'camellia-128-cfb8',
  'camellia-128-ecb',
  'camellia-128-ofb',
  'camellia-192-cbc',
  'camellia-192-cfb',
  'camellia-192-cfb1',
  'camellia-192-cfb8',
  'camellia-192-ecb',
  'camellia-192-ofb',
  'camellia-256-cbc',
  'camellia-256-cfb',
  'camellia-256-cfb1',
  'camellia-256-cfb8',
  'camellia-256-ecb',
  'camellia-256-ofb',
  'camellia128',
  'camellia192',
  'camellia256',
  'cast',
  'cast-cbc',
  'cast5-cbc',
  'cast5-cfb',
  'cast5-ecb',
  'cast5-ofb',
  'des',
  'des-cbc',
  'des-cfb',
  'des-cfb1',
  'des-cfb8',
  'des-ecb',
  'des-ede',
  'des-ede-cbc',
  'des-ede-cfb',
  'des-ede-ofb',
  'des-ede3',
  'des-ede3-cbc',
  'des-ede3-cfb',
  'des-ede3-cfb1',
  'des-ede3-cfb8',
  'des-ede3-ofb',
  'des-ofb',
  'des3',
  'desx',
  'desx-cbc',
  'id-aes128-CCM',
  'id-aes128-GCM',
  'id-aes128-wrap',
  'id-aes192-CCM',
  'id-aes192-GCM',
  'id-aes192-wrap',
  'id-aes256-CCM',
  'id-aes256-GCM',
  'id-aes256-wrap',
  'id-smime-alg-CMS3DE
  'idea',
  ... 19 more items ]
*/

</pre><pre>
Cipher类的实例用于加密数据,这个类可以用在以下两种方法中的一种:
1、作为stream,既可读又可写,未加密数据的编写是为了在可读的方面生成加密的数据,或者
2、使用cipher.update()和cipher.final()方法产生加密的数据。

crypto.createCipher()或crypto.createCipheriv()方法用于创建Cipher实例,Cipher对象不能直接使用new关键字创建
crypto.createCipher(algorithm, password[, options])
crypto.createCipher(algorithm, password)
crypto.createCipheriv(algorithm, key, iv)
第一个参数algorithm表示用何种加密算法,可用openssl list-cipher-algorithms命令来查看系统支持哪些加密算法
password和key, iv表示密钥,即利用何种密钥加密,password是用来派生key和iv的,key的话是算法原生的key,iv表示初始化向量

cipher.update(data[, inputEncoding][, outputEncoding])
往cipher实例中添加数据,用data更新密码。
data参数是使用指定编码的字符串
inputEncoding表示传入数据的格式,可以是'utf8'、'ascii'或'binary',默认是'binary';
如果不给出inputEncoding的参数则data必须是Buffer、TypedArray或DataView。如果data是一个Buffer、TypedArray或DataView,那么inputEncoding就被忽略了。
outputEncoding指定加密数据的输出格式,可以是'latin1', 'base64'或'hex'。如果指定了outputEncoding则返回使用指定编码的字符串。如果没有outputEncoding被提供则会返回Buffer。
cipher.update()方法可以用新数据多次调用,直到cipher.final()被调用,在cipher.final()之后调用cipher.update()将抛出错误

cipher.final([outputEncoding])
返回任何未加密的内容。如果outputEncoding参数是'latin1/base64/hex'返回字符串。如果没有提供 outputEncoding,则返回Buffer
一旦cipher.final()方法已被调用,Cipher对象就不能再用于加密数据。如果试图再次调用cipher.final(),将会抛出一个错误

</pre><pre class="js">
// 使用Cipher对象作为流:
const crypto = require('crypto');
const cipher = crypto.createCipher('aes192', 'a password');
let encrypted = '';
cipher.on('readable', () => {
  const data = cipher.read();
  if(data) encrypted += data.toString('hex');
});
cipher.on('end', () => console.log(encrypted)) // ca981be48e90867604588e75d04feabb63cc007a8f8ad89b10616ed84d815504
cipher.write('some clear text data');          // 要加密的字符串
cipher.end();

// 使用Cipher和管道流:
const crypto = require('crypto');
const fs = require('fs');
const cipher = crypto.createCipher('aes192', 'a password');
const input = fs.createReadStream('test.js');
const output = fs.createWriteStream('test.enc');
input.pipe(cipher).pipe(output);

</pre>使用cipher.update()和cipher.final()方法<pre class="js">
const crypto = require('crypto');
const cipher = crypto.createCipher('aes192', 'a password');
let encrypted = cipher.update('some clear text data', 'utf8', 'hex');
encrypted += cipher.final('hex');
console.log(encrypted);    // ca981be48e90867604588e75d04feabb63cc007a8f8ad89b10616ed84d815504

</pre><pre>
Decipher类的实例用于解密数据,这个类可以用在以下两种方法中的一种:
1、作为stream,既可读又可写,加密数据的编写是为了在可读的方面生成未加密的数据
2、使用decipher.update()和decipher.final()方法产生未加密的数据

crypto.createDecipher()或crypto.createDecipheriv()的方法 用于创建Decipher实例。Decipher对象不能直接使用new关键字创建
crypto.createDecipher(algorithm, password[, options])

decipher.update(data[, inputEncoding][, outputEncoding])
decipher.final([outputEncoding])

</pre>使用Decipher对象作为流<pre class="js">
const crypto = require('crypto');
const decipher = crypto.createDecipher('aes192', 'a password');
let decrypted = '';
decipher.on('readable', () => {
  const data = decipher.read();
  if (data) decrypted += data.toString('utf8');
});
decipher.on('end', () => console.log(decrypted)) // Prints: some clear text data
const encrypted = 'ca981be48e90867604588e75d04feabb63cc007a8f8ad89b10616ed84d815504';
decipher.write(encrypted, 'hex');     // 要解密的字符串
decipher.end();

// 使用Decipher和管道流:
const crypto = require('crypto');
const fs = require('fs');
const decipher = crypto.createDecipher('aes192', 'a password');
const input = fs.createReadStream('test.enc');
const output = fs.createWriteStream('test.js');
input.pipe(decipher).pipe(output);

</pre>使用decipher.update()和decipher.final()方法<pre class="js">
const crypto = require('crypto');
const decipher = crypto.createDecipher('aes192', 'a password');
const encrypted = 'ca981be48e90867604588e75d04feabb63cc007a8f8ad89b10616ed84d815504';
let decrypted = decipher.update(encrypted, 'hex', 'utf8');
decrypted += decipher.final('utf8');
console.log(decrypted);              // some clear text data

</pre><pre class="js">
var crypto = require('crypto');
var fs = require('fs');
var pem = fs.readFileSync('key.pem');
var key = pem.toString('ascii');
var cipher = crypto.createCipher('blowfish', key);
// 通过随机内存中的4byte字节的内容填充进去,没有block返回是因为4byte不够生成一个block
cipher.update(new Buffer(4), 'binary', 'hex');   // ''
cipher.update(new Buffer(4), 'binary', 'hex');   // 'ff57e5f742689c85'
cipher.update(new Buffer(4), 'binary', 'hex');   // ''
cipher.final('hex')                              // '96576b47fe130547'

</pre>测试ciphers加密解密的计算时间<pre class="js">
var crypto = require('crypto');
var fs = require('fs');

//加密
function cipher(algorithm, key, buf ,cb){
  var encrypted = "";
  var cip = crypto.createCipher(algorithm, key);
  encrypted += cip.update(buf, 'binary', 'hex');
  encrypted += cip.final('hex');
  cb(encrypted);
}

//解密
function decipher(algorithm, key, encrypted,cb){
  var decrypted = "";
  var decipher = crypto.createDecipher(algorithm, key);
  decrypted += decipher.update(encrypted, 'hex', 'binary');
  decrypted += decipher.final('binary');
  cb(decrypted);
}

function cipherDecipherFile(filename,algorithm, key){
  fs.readFile(filename, "utf-8", (err, data) => {
    if (err) throw err;
    var s1 = new Date();
    cipher(algorithm, key, data, encrypted => {
      var s2 = new Date();
      console.log('cipher: '+algorithm+', '+(s2-s1));
      decipher(algorithm, key, encrypted, txt => {
        var s3 = new Date();
        console.log('decipher: '+algorithm+', '+(s3-s2));
        if(algorithm == 'rc4'){
          console.log(typeof encrypted, encrypted.length);       // string 83660
          console.log(typeof txt, txt.length);                   // string 41830
        }
      });
    });
  });
}

var algs = ['blowfish','aes-256-cbc','cast','des','des3','idea','rc2','seed','rc4'];
var key = "abc";
var filename = "test.txt";
algs.forEach(name => cipherDecipherFile(filename,name,key))

/*
cipher: blowfish, 2
decipher: blowfish, 5
cipher: cast, 1
decipher: cast, 3
cipher: aes-256-cbc, 1
decipher: aes-256-cbc, 1
cipher: des3, 3
decipher: des3, 4
cipher: des, 1
decipher: des, 3
cipher: idea, 1
decipher: idea, 3
cipher: rc2, 1
decipher: rc2, 3
cipher: seed, 2
decipher: seed, 2
cipher: rc4, 0
decipher: rc4, 2
*/

</pre><pre>
在选中的这几个算法中,rc4和aes-256-cbc是表现不错的算法,加密和解密时间都比较短,加密时间:解密时间=1:3;其他的算法总体时间相对较长,有的加密时间:解密时间=1:1。所以怎么选算法另外的一个标准就要看业务需求了。如果业务上解密操作的次数远大于加密操作的次数,而且是在服务器计算,那么最好找到加密时间:解密时间=N:1,N>1的算法;如果加密在服务器端,解密在客户端完成,那么aes-256-cbc算法的计算时间比例就非常适合了。

</pre>

<h3>Sign签名和Verify验证算法</h3><pre>
除了对数据进行加密和解密,还需要判断数据在传输过程中,是否真实和完整,是否被篡改了,那么就需要用到签名和验证的算法,利用不对称加密算法,通过私钥进行数字签名,公钥验证数据的真实性

现实数字签名的制作和验证过程的操作流程,由于证书是自己制作的,不打算对外公开,没有到CA进行认证,所以下过程将不包括公钥伪造,再到CA认证的过程
先用openSSL命令先生成私钥server.pem和公钥cert.pem

"Sign"类是生成签名的实用工具,有两种使用方式:
1、作为一个可写的stream,在这里,要签署的数据是写出来的,sign.sign()方法用于生成并返回签名
2、使用sign.update()和sign.sign()方法生产签名

crypto.createSign()方法用于创建Sign实例。Sign实例不能直接使用new关键字创建
crypto.createSign(algorithm[, options])
Creates and returns a Sign object that uses the given algorithm. Use crypto.getHashes() to obtain an array of names of the available signing algorithms. Optional options argument controls the stream.Writable behavior

sign.update(data[, inputEncoding])
sign.sign(privateKey[, outputFormat])

</pre><pre class="js">
// 使用sign对象作为流:
const crypto = require('crypto');
const sign = crypto.createSign('SHA256');

sign.write('some data to sign');
sign.end();

const privateKey = getPrivateKeySomehow();  // 须自定义的方法
console.log(sign.sign(privateKey, 'hex'));
// Prints: the calculated signature using the specified private key and SHA-256. For RSA keys, the algorithm is RSASSA-PKCS1-v1_5 (see padding parameter below for RSASSA-PSS). For EC keys, the algorithm is ECDSA.

// 使用sign.update()和sign.sign()方法：
const crypto = require('crypto');
const sign = crypto.createSign('SHA256');
sign.update('some data to sign');
const privateKey = getPrivateKeySomehow();
console.log(sign.sign(privateKey, 'hex'));  // Prints: the calculated signature

</pre>签名验证算法,利用生成私钥生成数学签名,然后再用公钥验证数据,是否被篡改<pre class="js">
# 生成私钥
~ D:\workspace\javascript\nodejs-crypto>openssl genrsa -out server.pem 1024
Generating RSA private key, 1024 bit long modulus
..................++++++
..................++++++
e is 65537 (0x10001)

# 生成公钥
~ D:\workspace\javascript\nodejs-crypto>openssl req -key server.pem -new -x509 -out cert.pem
You are about to be asked to enter information that will be incorporated into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [AU]:
State or Province Name (full name) [Some-State]:
Locality Name (eg, city) []:
Organization Name (eg, company) [Internet Widgits Pty Ltd]:
Organizational Unit Name (eg, section) []:
Common Name (eg, YOUR name) []:
Email Address []:

// signer.js
var crypto = require('crypto')
var fs = require('fs');

function signer(algorithm, key, data){
  return crypto.createSign(algorithm).update(data).sign(key, 'hex');
}

function verify(algorithm,pub,sig,data){
  return crypto.createVerify(algorithm).update(data).verify(pubkey, sig, 'hex')
}

var algorithm = 'RSA-SHA256';
var data = "abcdef";                            // 传输的数据
var privatePem = fs.readFileSync('server.pem'); // 私钥
var key = privatePem.toString();
var sig = signer(algorithm,key,data);           // 数字签名

var publicPem = fs.readFileSync('cert.pem');
var pubkey = publicPem.toString();
console.log(verify(algorithm,pubkey,sig,data));         //验证数据,通过公钥、数字签名 =》是原始数据
console.log(verify(algorithm,pubkey,sig,data+"2"));     //验证数据,通过公钥、数字签名  =》不是原始数据

// true false

两行输出结果,第一行验证的结果是true,表示数据在传输过程中,没有被篡改;第二行验证的结果是false,表示数据在传输过程中被篡改,不是原始的数据。当然,如何保证私钥和公钥的匹配,需要CA第三方来认证,与Crypto库无关本文不再介绍

</pre>
</div>

<!------------------------ DNS------------------------ -->
<div id="dns">
<h2>DNS 模块用于解析域名 var dns = require("dns")</h2><pre class="js">
C:\Users\lenovo>node
> dns

</pre><pre>
常用方法和属性

dns.lookup(hostname[, options], callback)
将域名(如 'runoob.com')解析为第一条找到的记录A(IPV4)或AAAA(IPV6).
参数 options可以是一个对象或整数.如果没有提供 options,IP v4 和 v6 地址都可以.如果 options 是整数,则必须是4或6

dns.lookupService(address, port, callback)  使用getnameinfo 解析传入的地址和端口为域名和服务.

dns.resolve(hostname[, rrtype], callback)   将域名(如'runoob.com')解析为一个rrtype 指定记录类型的数组.

dns.resolve4(hostname, callback)   和 dns.resolve()类似, 仅能查询IPv4 (A 记录).
addresses IPv4 地址数组 (比如,['74.125.79.104', '74.125.79.105', '74.125.79.106']).

dns.resolve6(hostname, callback)   和dns.resolve4()类似, 仅能查询 IPv6( AAAA 查询)

dns.resolveMx(hostname, callback)  和dns.resolve()类似, 仅能查询邮件交换(MX 记录).

dns.resolveTxt(hostname, callback) 和dns.resolve()类似, 仅能进行文本查询 (TXT 记录).
addresses 是 2-d 文本记录数组.(比如,[ ['v=spf1 ip4:0.0.0.0 ', '~all' ] ]). 每个子数组包含一条记录的 TXT 块.根据使用情况可以连接在一起,也可单独使用.

dns.resolveSrv(hostname, callback)  和dns.resolve()类似, 仅能进行服务记录查询 (SRV 记录).
addresses 是 hostname可用的 SRV 记录数组. SRV 记录属性有优先级(priority),权重(weight), 端口(port), 和名字(name) (比如,[{'priority': 10, 'weight': 5, 'port': 21223, 'name': 'service.example.com'}, ...]).

dns.resolveSoa(hostname, callback)  和dns.resolve()类似, 仅能查询权威记录(SOA 记录).

dns.resolveNs(hostname, callback)   和dns.resolve()类似, 仅能进行域名服务器记录查询(NS 记录).
addresses 是域名服务器记录数组(hostname 可以使用) (比如, ['ns1.example.com', 'ns2.example.com']).

dns.resolveCname(hostname, callback) 和dns.resolve()类似, 仅能进行别名记录查询 (CNAME记录).
addresses 是对 hostname 可用的别名记录数组 (比如,, ['bar.example.com']).

dns.reverse(ip, callback)            反向解析 IP 地址,指向该 IP 地址的域名数组.

dns.getServers()                     返回一个用于当前解析的 IP 地址数组的字符串.

dns.setServers(servers)              指定一组 IP 地址作为解析服务器.

【 dns.resolve()方法中有效的rrtypes值 】
'A'     IPV4 地址, 默认
'AAAA'  IPV6 地址
'MX'    邮件交换记录
'TXT'   text 记录
'SRV'   SRV 记录
'PTR'   用来反向 IP 查找
'NS'    域名服务器记录
'CNAME' 别名记录
'SOA'   授权记录的初始值

【 错误码 】
每次 DNS 查询都可能返回以下错误码：
dns.NODATA:      无数据响应.
dns.FORMERR:     查询格式错误.
dns.SERVFAIL:    常规失败.
dns.NOTFOUND:    没有找到域名.
dns.NOTIMP:      未实现请求的操作.
dns.REFUSED:     拒绝查询.
dns.BADQUERY:    查询格式错误.
dns.BADNAME:     域名格式错误.
dns.BADFAMILY:   地址协议不支持.
dns.BADRESP:     回复格式错误.
dns.CONNREFUSED: 无法连接到 DNS 服务器.
dns.TIMEOUT:     连接 DNS 服务器超时.
dns.EOF:         文件末端.
dns.FILE:        读文件错误.
dns.NOMEM:       内存溢出.
dns.DESTRUCTION: 通道被摧毁.
dns.BADSTR:      字符串格式错误.
dns.BADFLAGS:    非法标识符.
dns.NONAME:      所给主机不是数字.
dns.BADHINTS:    非法HINTS标识符.
dns.NOTINITIALIZED:          c c-ares 库尚未初始化.
dns.LOADIPHLPAPI:            加载 iphlpapi.dll 出错.
dns.ADDRGETNETWORKPARAMS:    无法找到 GetNetworkParams 函数.
dns.CANCELLED:               取消 DNS 查询.

DNS查询结果

Node不缓存DNS返回的结果,所以一次又一次地查询同一个URL时其实已经浪费了很多宝贵的时间。这种情况下完全可以调用dns.lookup()并缓存结果的

</pre><pre class="js">
dns.lookup(`www.myApi.com`, 4, (err, address) => {
    cacheThisForLater(address);
});

</pre><pre class="js">
var dns = require('dns');

dns.lookup('www.github.com', function onLookup(err, address, family) {
  console.log('ip 地址:', address);
  dns.reverse(address, function (err, hostnames) {
    if(err) return  console.log(err.stack);
    console.log('反向解析 ' + address + ': ' + JSON.stringify(hostnames));
  });
});

</pre>
</div>

<!-- ----------------os-------------------- -->
<div id="os">
<h2>OS模块提供基本的系统操作函数</h2><pre>
var os = require("os")

常用属性和方法：
os.EOL          定义了操作系统的行尾符的常量,在 Windows 操作系统上为'\r\n',在其它系统上是'\n'
os.userInfo()   //{ uid: -1, gid: -1, username: 'lenovo', homedir: 'C:\\Users\\lenovo', shell: null }
os.homedir()                                              // 'C:\\Users\\lenovo'
os.tmpdir()     返回操作系统的默认临时文件夹.            // 'C:\\Users\\lenovo\\AppData\\Local\\Temp'
os.endianness() 返回 CPU 的字节序,可能的是 "BE" 或 "LE".
os.hostname()   返回操作系统的主机名.                    // 'LAPTOP-0KMQM01D'
os.type()       返回操作系统名                            // 'Windows_NT'
os.platform()   返回操作系统名                            // 'win32'
os.arch()       返回操作系统 CPU 架构,可能的值有 "x64"、"arm" 和 "ia32".
os.release()    返回操作系统的发行版本.                  // '10.0.14393'
os.uptime()     返回操作系统运行的时间,以秒为单位.      // 510534.6397398
os.loadavg()    返回一个包含 1、5、15 分钟平均负载的数组.// [ 0, 0, 0 ]
os.totalmem()   返回系统内存总量,单位为字节.            // 4205264896
os.freemem()    返回操作系统空闲内存量,单位是字节.      // 1515499520
os.cpus()       返回一个对象数组,包含所安装的每个CPU/内核的信息：型号、速度(单位MHz)、时间(一个包含 user、nice、sys、idle 和 irq 所使用 CPU/内核毫秒数的对象)
os.networkInterfaces()       获得网络接口列表.


</pre><pre class="js">
C:\Users\lenovo>node
> os

</pre><pre class="js">
/* nodejs在Windows下获取内网ip地址 */
function getIPAdress(){
  var interfaces = require('os').networkInterfaces();
  for(var devName in interfaces){
    var iface = interfaces[devName];
    for(var i=0;i< iface.length;i++){
      var alias = iface[i];
      if(alias.family === 'IPv4' && alias.address !== '127.0.0.1' && !alias.internal){
        console.log(alias.address);
        //return alias.address;        // 192.168.0.103
      }
    }
  }
}

</pre>
</div>

<!-- --------------------router--------------------------------- -->
<div id="router">
<h2>router 路由 URL映射</h2><pre>
web应用的流程：客户端发起请求,通过url标识将请求发送给服务端,请求经过一系列全局处理(验证、授权、url解析等),然后定位到某个具体程序进行业务处理,最后将处理的结果响应给客户端,客户端将响应的数据结合视图模板呈现除合适的样式
路由即是如何定位到服务端某个具体处理程序的过程,url到handler有个路由处理的过程

要为路由提供请求的URL和其他需要的GET及POST参数,随后路由需要根据这些数据来执行相应的代码
这些数据都会包含在request对象中,该对象作为onRequest()回调函数的第一个参数传递。但是为了解析这些数据,需要额外的Node.JS模块url和querystring模块

路由路径和请求方法一起定义了请求的端点,它可以是字符串、字符串模式或者正则表达式。后端在获取路由后,可通过一系列类似中间件的函数去执行事务
字符串：
'/'
'/about'
'/random.txt'

字符串模式：
'/ab?cd'
'/ab(cd)?e'

正则：
/.*fly$/

//路由表
{
  "/my/**/*":         "func:testFun",
  "index":            "url:index.html",
  "test?v=*":         "url:my*.html",
  "/public/bi*/**/*": "url:public/**/*"
}

文件路由：根据不同的请求url响应不同的处理方式
服务器有多个事件处理方法,每个方法对应一个或一种URL格式,无法处理的URL应该抛出错误处理

</pre><pre class="js">
/* server.js 通过请求的URL路径来区别不同请求 */
var http = require("http");
var url = require("url");

function start(route, handle) {
  function onRequest(request, response) {
    var pathname = url.parse(request.url).pathname;
    console.log(`Request for ${pathname}`);                   // 区分不同的get请求
    route(pathname);                                          // 执行route
    response.writeHead(200, {"Content-Type": "text/plain"});
    response.write("Hello World\n");
    response.end();
  }
  http.createServer(onRequest).listen(8888, () => console.log("Server is listening on port 8888 ...\n"));
}
exports.start = start;

/* router.js */
function route(pathname) {
  console.log(`About to route a request for ${pathname}\n`);
}
exports.route = route;

/* requestHandlers.js */
function start(){
  console.log("Request handler 'start' was called.");
  function sleep(milliSeconds){
    var startTime=new Date().getTime();
    while(new Date().getTime() < startTime+milliSeconds);
  }
  sleep(10000);
  return "Hello Start";
}
function upload(){
  console.log("Request handler 'upload' was called.");
  return "Hello Upload";
}

exports.start=start;
exports.upload=upload;

/* index.js */
var server = require('./server');
var router = require('./router');
var requestHandlers = require('./requestHandlers');
var handle = {};
handle["/"] = requestHandlers.start;
handle["/start"] = requestHandlers.start;
handle["/upload"] = requestHandlers.upload;

server.start(router.route, handle);

</pre><pre class="js">
/* router.js */
var http = require('http');
var url = require('url');
var fs = require('fs');
http.createServer(function(req,res){
  var pathname = url.parse(req.url).pathname;
  console.log('Request for ' + pathname + ' received.');
    function showPaper(path,status){
      var content = fs.readFileSync(path);
      res.writeHead(status, {'Content-Type': 'text/html;charset=utf-8'});
      res.write(content);
      res.end();
    }
    switch(pathname){
      case '/':
      case '/home':
        showPaper('./view/home.html',200);
        break;
      case '/about':
        showPaper('./view/about.html',200);
        break;
      default:
        showPaper('./view/404.html',404);
        break;
  }
}).listen(8888, '127.0.0.1');

</pre><pre>
【 泛式路由 】
*通配URL
'/test/*' ->  /test/.......

/:id的占位标识符URL
'/test/:userid'  ->  '/test/12'
"/user/:id(\d+)" ->  限制用户id为数字

例：
"/user/:id"
/user/12

"/users/:id?"
/users/5
/users

"/files/*"
/files/jquery.js
/files/javascripts/jquery.js

"/file/*.*"
/files/jquery.js
/files/javascripts/jquery.js

"/user/:id/:operation?"
/user/1
/user/1/edit

"/products.:format"
/products.json
/products.xml

"/products.:format?"
/products.json
/products.xml
/products

"/user/:id.:format?"
/user/12
/user/12.json

路由是一个可以被内部编译成正则表达式的简单字符串,比如当/user/:id被编译后,被内部编译后的正则表达式字符串：\/user\/(\d+)\/? (正则捕获组)

</pre>
</div>

<!-- --------------------------------------- -->
<div id="express">
<h2>express</h2><pre>
Express是一个简洁而灵活的node.js Web应用框架,提供了一系列强大特性帮助你创建各种Web应用和丰富的HTTP工具,使用Express可以快速地搭建一个完整功能的网站。
Express框架建立在Nodejs内置的Http模块上,并对Http模块再包装,从而实现Web请求处理的功能

Express框架核心特性：
可以设置中间件来响应HTTP请求。
定义了路由表用于执行不同的HTTP请求动作。
可以通过向模板传递参数来动态渲染HTML页面。

cmd> npm install express --save
cmd> npm install body-parser --save    中间件,用于处理 JSON, Raw, Text 和 URL 编码的数据
cmd> npm install cookie-parser --save  通过req.cookies可以取到传过来的cookie,并把它们解析转成对象
cmd> npm install multer --save  中间件,处理enctype="multipart/form-data"(设置表单MIME编码)表单数据

【 应用生成器工具 】
cmd> npm install express-generator -g     // 通过应用生成器工具express可快速创建一个应用的骨架
cmd> express -e myapp                     // 创建名为myapp的应用, -e声明使用ejs作为模板引擎
cmd> cd myapp && npm install              // 安装所有依赖包
cmd> SET DEBUG=myapp:* & npm start        // 启动应用
访问: http://localhost:3000/

expressdemo目录结构：
app.js            // 项目入口文件,默认app.js,可改;应用核心配置文件
node_modules/     // 存放npm安装到本地依赖包,依赖包在package.json文件中声明,使用npm install指令安装
*bin               // 存放启动项目的脚本文件,可执行文件
  ->www           // 使用npm start启动网站时会调用www,也是一个node的脚本,用于分离配置和启动程序
package.json      // npm依赖配置文件
public            // 存放静态资源文件, jquery等静态库会方这里,当然自己编写的前端代码也可以放这里
  ->images
  ->javascrits
  ->stylesheets
    ->style.css
routes            // 路由文件(MVC中的C,controller)
  ->index.js
  ->uses.js
views             // 视图模板文件,express默认jade,也可用haml,JES,coffeeKup, jQueryTemplate等模板引擎
  ->error.ejs
  ->index.ejs
 MVC 模型(model/操作数据库的文件)－视图(view)－控制器(controller/route) 的开发模式

nodejs启动服务器：http.createSever 的回调函数。app是express贯穿整个流程的函数。其实整个express 执行过程就是往req,res这两个对象不停的修改属性,添加属性。直到完成请求。中间件也就是通过app做为回调,进而修改req,res。从而实现可插拔的效果
把所有的方法直接放到app这个函数上去了,函数在js中就是对象,除了本身是可以执行以外,和对象是没有什么区别的。app既做为一个中间件,还要做为一个公共方法的载体

【 express运行原理 】
expressjs是在nodejs的TCP 监听器上封装了一层管道处理机制,可以把nodejs收到请求到响应之间的全过程暴露出来,该管道通过.use(path,fun)方法一节一节添加组成,中间件是否调用了next(),此方法相当于中间件的阀门,控制是否有必要继续流向到下一节管道

expressjs运行过程如下：
1.运行bin/www
2.生成app对象：该对象复制了application模块中所有成员和EventEmitter成员,并且set了一些默认配置
3.通过app.use()把中间件(一节管道)封装成layer对象,并push到router对象(该对象已被赋给app对象的属性：_router)的stack数组中
4.监听tcp端口
5.收到请求
6.触发APP对象的handle(req,res,next),其中调用_rooter属性的handle(req,res,done),遍历stack数组并取出中间件执行

【 设置环境变量 】
exppress模块默认配置：express\lib\application.js 70
// default settings
app.enable('x-powered-by');
app.set('etag', 'weak');
app.set('env', process.env.NODE_ENV || 'development');
app.set('query parser', 'extended');
app.set('subdomain offset', 2);
app.set('trust proxy', false);
app.set('jsonp callback name', 'callback');
if (env === 'production') {
  app.enable('view cache');
}

process.env.NODE_ENV = 'development';
console.log(process.env.NODE_ENV);

app.set('env', 'test')
res.locals.error = req.app.get('env') === 'development' ? err : {};

var env = opts.env || process.env.NODE_ENV || 'development'

// 所有环境
app.set('title', 'My Application');

// 只用于开发环境
if ('development' == app.get('env')) {
  app.set('db uri', 'localhost/dev');
}

// 只用于生产环境
if ('production' == app.get('env')) {
  app.set('db uri', 'n.n.n.n/prod');
}

【 创建一个Express应用 】
</pre><pre class="js">
var express = require('express');
var app = express();
app.get('/', function(req, res){
  console.log(req.ip);
  res.send('hello world');
});
app.listen(8888, () => console.log("server on http://%s:%s", server.address().address, server.address().port));

</pre>【 使用Express搭建HTTPs加密服务器 】<pre class="js">
var fs = require('fs');
var options = {
  key: fs.readFileSync('E:/ssl/myserver.key'),
  cert: fs.readFileSync('E:/ssl/myserver.crt'),
  passphrase: '1234'
};

var https = require('https');
var express = require('express');
var app = express();

app.get('/', function(req, res){
  res.send('Hello World Expressjs');
});

https.createServer(options, app).listen(8888, ()=>console.log('Server is running on port 8888'));

</pre>
</div>

<div id="reqobj">
<h3>request对象</h3><pre>
The req object represents the HTTP request and has properties for the request query string, parameters, body, HTTP headers, and so on. In this documentation and by convention(公约), the object is always referred to as(被称为) req (and the HTTP response is res) but its actual name is determined(确定) by the parameters to the callback function in which you're working

Request对象 - request对象表示HTTP请求,包含了请求查询字符串,参数,内容,HTTP头部等属性。常见属性有：
app
protocol
secure
hostname
subdomains
ips
ip
get()
is()
accepts()
acceptsCharsets()
acceptsEncodings()
acceptsLanguages()
fresh
stale
xhr
originalUrl
baseUrl
path
route
params
query
body
cookies
signedCookies

【 req.app 】
当callback为外部文件时,用req.app访问express的实例
This property holds a reference to the instance of the express application that is using the middleware.
If you follow the pattern in which you create a module that just exports a middleware in order for requiring it in your main file, then the middleware can access the express instance via req.app

</pre><pre class="js">
//index.js
app.get("/viewdirectory", require("./mymiddleware.js"));

//mymiddleware.js
module.exports = function (req, res) {
  res.send("The views directory is " + req.app.get("views"));
});

</pre><pre>
【 req.protocol 】
获取协议类型
The request protocol string, "http" or "https" when requested with TLS. When the "trust proxy" setting trusts the socket address, the value of the "X-Forwarded-Proto" header ("http" or "https") field will be trusted and used if present.
req.protocol        // => "http"

【 req.secure 】
A Boolean that is true if a TLS connection is established. Equivalent to:
'https' == req.protocol;

【 req.hostname 】
获取主机名,Contains the hostname from the "Host" HTTP header.

// Host: "example.com:3000"
req.hostname         // => "example.com"

【 req.subdomains 】
获取子域名
An array of subdomains in the domain name of the request.

// Host: "tobi.ferrets.example.com"
req.subdomains       // => ["ferrets", "tobi"]

【 req.ips 】
When the trust proxy setting is true, this property contains an array of IP addresses specified in the "X-Forwarded-For" request header. Otherwise, it contains an empty array

For example, if "X-Forwarded-For" is "client, proxy1, proxy2", req.ips would be  ["client", "proxy1", "proxy2"], where "proxy2" is the furthest downstream

【 req.ip 】
获取主机IP地址,The remote IP address of the request.
If the trust proxy is setting enabled, it is the upstream address; see Express behind proxies for more information.
req.ip    // => "127.0.0.1"

【 req.get(field) 】
Aliased as req.header(field)
Returns the specified HTTP request header field (case-insensitive大小写不敏感 match). The Referrer and Referer fields are interchangeable.

req.get('Content-Type');      // => "text/plain"
req.get('content-type');      // => "text/plain"
req.get('Something');         // => undefined

【 req.is(type) 】
Returns true if the incoming request's "Content-Type" HTTP header field matches the MIME type specified by the type parameter. Returns false otherwise.

</pre><pre class="js">
// With Content-Type: text/html; charset=utf-8
req.is('html');
req.is('text/html');
req.is('text/*');
// => true

// When Content-Type is application/json
req.is('json');
req.is('application/json');
req.is('application/*');
// => true

req.is('html');
// => false

</pre><pre>
【 req.accepts(types) 】
检查可接受的请求的文档类型
Checks if the specified content types are acceptable, based on the request's Accept HTTP header field. The method returns the best match, or if none of the specified content types is acceptable, returns  undefined (in which case, the application should respond with 406 "Not Acceptable").

The type value may be a single MIME type string (such as "application/json"), an extension name such as "json", a comma-delimited list, or an array. For a list or array, the method returns the best match (if any).

</pre><pre class="js">
// Accept: text/html
req.accepts('html');              // => "html"

// Accept: text/*, application/json
req.accepts('html');              // => "html"
req.accepts('text/html');         // => "text/html"
req.accepts(['json', 'text']);    // => "json"
req.accepts('application/json');  // => "application/json"

// Accept: text/*, application/json
req.accepts('image/png');
req.accepts('png');               // => undefined

// Accept: text/*;q=.5, application/json
req.accepts(['html', 'json']);    // => "json"

</pre><pre>
【 req.acceptsCharsets(charset [, ...]) 】
返回指定字符集的第一个可接受字符编码
Returns the first accepted charset of the specified character sets, based on the request's Accept-Charset HTTP header field. If none of the specified charsets is accepted, returns false.

【 req.acceptsEncodings(encoding [, ...]) 】
Returns the first accepted encoding of the specified encodings, based on the request's Accept-Encoding HTTP header field. If none of the specified encodings is accepted, returns false.

【 req.acceptsLanguages(lang [, ...]) 】
Returns the first accepted language of the specified languages, based on the request's Accept-Language HTTP header field. If none of the specified languages is accepted, returns false.

【 req.fresh 】
判断请求是否还「新鲜」
Indicates(表明) whether the request is "fresh." It is the opposite(相反) of req.stale.

It is true if the cache-control request header doesn't have a no-cache directive(指令) and any of the following is true:
The if-modified-since request header is specified and last-modified request header is equal to or eariler than the modified response header.
The if-none-match request header is *.
The if-none-match request header, after being parsed into its directives, does not match the etag response header.
req.fresh     // => true

【 req.stale 】
判断请求是否「不新鲜」
Indicates whether the request is "stale," and is the opposite of req.fresh. For more information, see req.fresh
req.stale     // => true

【 req.xhr 】
A Boolean value that is true if the request's "X-Requested-With" header field is "XMLHttpRequest", indicating(标示) that the request was issued(发布) by a client library such as jQuery.
req.xhr      // => true

【 req.url 】
req.url is not a native Express property, it is inherited from Node's http module
req.url = req.originalUrl - req.baseUrl

【 req.originalUrl 】
获取原始请求URL,用于备份最初的请求url,从而可以随意重写req.url来到处跳转,而不用担心丢失初始的url
This property is much like req.url; however, it retains the original request URL, allowing you to rewrite req.url freely for internal(内部) routing purposes(目的).
For example, the "mounting" feature of app.use() will rewrite req.url to strip(带) the mount point.

// GET /search?q=something
req.originalUrl             // /search?q=something

【 req.baseUrl 】
存储当前router挂载的路径字符串
The URL path on which a router instance was mounted

Even if you use a path pattern or a set of path patterns to load the router, the baseUrl property returns the matched string, not the pattern(s). In the following example, the greet router is loaded on two path patterns.

app.use(['/gre+t', '/hel{2}o'], greet); // load the router on '/gre+t' and '/hel{2}o'

When a request is made to /greet/jp, req.baseUrl is "/greet". When a request is made to /hello/jp, req.baseUrl is "/hello".

req.baseUrl is similar to the mountpath property of the app object, except app.mountpath returns the matched path pattern(s).

【 req.path 】
获取请求路径
Contains the path part of the request URL
When called from a middleware, the mount point is not included in req.path

// example.com/users?sort=desc
req.path                         // => "/users"

</pre><pre class="js">
// http://localhost:8888/home/blog/hot.html?index=23#xx

const http = require('http');
http.createServer((req, res) => {
  console.log(req.url);           // /home/blog/hot.html?index=23
  res.end('test');
}).listen(8888)

/* express */

const express = require('express');
const app = express();

// http://localhost:8888/secret/sss/dd

app.all('/*', function (req, res, next) {
  console.log(req.url);           // /secret/sss/dd
  console.log(req.originalUrl);   // /secret/sss/dd
  console.log(req.baseUrl);       //
  console.log(req.path);          // /secret/sss/dd
  res.end('all');
});

// GET http://localhost:8888/admin/news/article.html?name=hy&age=29

app.get('/admin/*', (req, res, next) => {
  console.log(req.url);             // /admin/news/article.html?name=hy&age=29
  console.log(req.originalUrl);     // /admin/news/article.html?name=hy&age=29
  console.log(req.baseUrl);         //
  console.log(req.path);            // /admin/news/article.html
  res.end('test');
});

// http://localhost:8888/home/blog/hot.html?index=23#xx

app.use('/home/*', (req, res, next) => {
  console.log(req.url);             // /?index=23
  console.log(req.originalUrl);     // /home/blog/hot.html?index=23
  console.log(req.baseUrl);         // /home/blog/hot.html
  console.log(req.path);            // /
  res.end('test');
})

// http://localhost:8888/greet/jp/new.html?index=23#hh

var greet = express.Router();
greet.get('/jp/*', function(req, res){
  console.log(req.url);             // /jp/new.html?index=23
  console.log(req.originalUrl);     // /greet/jp/new.html?index=23
  console.log(req.baseUrl);         // /greet
  console.log(req.path);            // /jp/new.html
  res.send('test');
});
app.use('/greet', greet);           // load the router on '/greet'

app.listen(8888)

</pre><pre>
【 req.route 】
获取当前匹配的路由
The currently-matched route, a string. For example:

</pre><pre class="js">
app.get('/user/:id?', function userIdHandler(req, res) {
  console.log(req.route);
  res.send('GET');
})

// Example output from the previous snippet:

{ path: '/user/:id?',
  stack:
   [ { handle: [Function: userIdHandler],
       name: 'userIdHandler',
       params: undefined,
       path: undefined,
       keys: [],
       regexp: /^\/?$/i,
       method: 'get' } ],
  methods: { get: true } }

</pre><pre>
【 req.params 】
获取路由的parameters
An object containing properties mapped to the named route "parameters". For example, if you have the route /user/:name, then the "name" property is available as req.params.name. This object defaults to {}.

// GET /user/tj
req.params.name     // => "tj"

When you use a regular expression for the route definition, capture groups are provided in the array using req.params[n], where n is the nth capture group. This rule is applied to unnamed wild card matches with string routes such as /file/*:

// GET /file/javascripts/jquery.js
req.params[0]       // => "javascripts/jquery.js"

【 req.query 】
获取URL的查询参数串
An object containing a property for each query string parameter in the route. If there is no query string, it is the empty object, {}.

// GET /search?q=tobi+ferret
req.query.q          // => "tobi ferret"

// GET /shoes?order=desc&shoe[color]=blue&shoe[type]=converse
req.query.order      // => "desc"
req.query.shoe.color // => "blue"
req.query.shoe.type  // => "converse"

【 req.body 】
获得「请求主体」
Contains key-value pairs of data submitted in the request body. By default, it is undefined, and is populated(填充) when you use body-parsing middleware such as body-parser and multer.

This example shows how to use body-parsing middleware to populate req.body.

</pre><pre class="js">
var app = require('express')();
var bodyParser = require('body-parser');
var multer = require('multer');

app.use(bodyParser.json());                         // for parsing application/json
app.use(bodyParser.urlencoded({ extended: true })); // for parsing application/x-www-form-urlencoded
app.use(multer());                                  // for parsing multipart/form-data

app.post('/', function (req, res) {
  console.log(req.body);
  res.json(req.body);
})

</pre><pre>
【 req.files 】
In Express 4, req.files is no longer available on the req object by default.
To access uploaded files on the req.files object, use a multipart-handling middleware like busboy, multer, formidable, multiparty, connect-multiparty, or pez

【 req.cookies 】
获得Cookies
When using cookie-parser middleware, this property is an object that contains cookies sent by the request. If the request contains no cookies, it defaults to {}
For more information, issues(问题), or concerns(担忧), see cookie-parser

// Cookie: name=tj
req.cookies.name      // => "tj"

【 req.signedCookies 】
When using cookie-parser middleware, this property contains signed cookies sent by the request, unsigned and ready for use. Signed cookies reside(存在) in a different object to show developer(开发员) intent(意图); otherwise, a malicious(恶意) attack could be placed on req.cookie values (which are easy to spoof(恶搞)). Note that signing a cookie does not make it "hidden" or encrypted; but simply prevents tampering(篡改) (because the secret used to sign is private). If no signed cookies are sent, the property defaults to {}.

// Cookie: user=tobi.CP7AWaXDfAKIRfH49dQzKJx7sKzzSoPq7/AcBBRVwlI3
req.signedCookies.user   // => "tobi"

</pre><pre>
req.accepts()       检查可接受的请求的文档类型
req.acceptsCharsets   返回指定字符集的第一个可接受字符编码
req.acceptsEncodings  返回指定字符集的第一个可接受字符编码
req.acceptsLanguages返回指定字符集的第一个可接受字符编码
req.get()           获取指定的HTTP请求头
req.is()            判断请求头Content-Type的MIME类型
req.files           用于获取上传的文件

</pre>
</div>

<div id="middleware">
<h3>中间件 middleware</h3><pre>
在express应用中,一切皆中间件。各种应用逻辑,如请求参数解析、cookie解析、会话处理、日志记录、权限校验、gzip等,都是通过中间件来完成的

中间件middleware就是在收到请求后和发送响应之前这个阶段处理HTTP请求的函数。一个中间件处理完,再传递给下一个中间件。App实例在运行过程中,会调用一系列的中间件。

中间件函数的原型：function (req, res, next)
每个中间件可以从App实例接收三个参数,依次为request对象、response对象、next回调函数(代表下一个中间件)用来驱动中间件调用链。每个中间件都可以对HTTP请求(request对象)进行加工,并且决定是否调用next方法,将request对象再传给下一个中间件。
如果想让后面的中间件继续处理请求,就需要调用next方法
如果next带有参数,则代表抛出一个错误,参数为错误文本;抛出错误以后后面的中间件将不再执行,直到发现一个错误处理函数为止
如果当前中间件没有终结请求-响应循环,则必须调用next()方法将控制权交给下一个中间件,否则请求就会挂起

中间件的功能包括：
执行任何代码
修改请求和响应对象
终结请求-响应循环
调用堆栈中的下一个中间件

根据作用范围划分：
应用级中间件   app.use()、app.METHODS()接口中使用的中间件
路由级中间件   router.use()、router.METHODS()接口中使用的中间件
第三方中间件   可以在应用级加载,也可以在路由级加载,如cookie-parser

【 express.static(root, [options]) 内置中间件 】
express内置的唯一中间件,负责托管Express应用内的静态资源
参数root,是要处理的静态资源的根目录,可以是绝对路径,也可以是相对路径
[options]可选参数用来指定一些选项,比如maxAge、lastModified等

dotfiles      是否对外输出文件名以点.开头的文件,可选值为allow/deny/ignore,类型String,默认ignore
etag          是否启用etag生成,类型Boolean,默认true
extensions    设置文件扩展名备份选项,类型Array,默认[]
index         发送目录索引文件,设置为false禁用目录索引,类型Mixed,默认"index.html"
lastModified  设置Last-Modified头为文件在操作系统上的最后修改日期,类型Boolean,默认true
maxAge        以毫秒或者其字符串格式设置Cache-Control头的max-age属性。类型Number,默认0
redirect      当路径为目录时重定向至"/",类型Boolean,默认true
setHeaders    设置HTTP头以提供文件的函数,类型Function

</pre><pre class="js">
/* 静态资源存放在多个目录下,可以多次调用 */
app.use(express.static(path.join(__dirname, 'public')));
app.use(express.static(path.join(__dirname, 'files')));

//  npm install bootstrap@3 --save-dev 加载bootstrap
app.use(express.static(path.join(__dirname, 'node_modules')));
// http://localhost:3000/stylesheets/style.css
// ＜link rel='stylesheet' href='/bootstrap/dist/css/bootstrap.css' />
// ＜script src="/bootstrap/dist/js/bootstrap.js">＜/script>

/* 虚拟virtual目录,可以通过为静态资源目录指定一个挂载路径的方式来实现 */
app.use('/static', express.static(path.join(__dirname, 'public')));
// http://localhost:3000/static/stylesheets/style.css

</pre><pre class="js">
// 当前路径下的public目录作为静态文件,并且为Cache-Control头部的max-age选项为1天
var options = {
  dotfiles: 'ignore',
  etag: false,
  extensions: [],
  index: ['htm', 'html'],
  maxAge: '1d',
  redirect: false,
  setHeaders: function(res, path, stat) {
    res.set('x-timestamp', Date.now());
  }
}
app.use(express.static('public', options));

</pre>服务器会拦截所有public开头的uri,然后到static目录下去寻找静态资源,找到就返回。实际上在服务器上是没有public目录,这里的public可以很好的隐藏静态资源在服务器上的实际目录,另一方面也可以对静态进行分类存放<pre class="js">
const express = require("express");
const app = express();
const path = require("path");
app.use(express.static('public', path.join(__dirname,'/static')));
app.listen(8080, err => {
  if(err) throw err;
  console.log('server is listening on port 8080')
})

</pre><pre>
【 错误处理中间件 】
有4个参数,定义错误处理中间件时必须使用这4个参数。即使不需要next对象,也必须在签名中声明它,否则中间件会被识别为一个常规中间件,不能处理错误。

next(new Error('handle error'))应用程序为我们自动返回了错误栈信息(express 内置了一个默认的错误处理器),假如我们想手动控制返回的错误内容,则需要加载一个自定义错误处理的中间件

</pre><pre class="js">
app.use(function(err, req, res, next) {
  console.error(err.stack);
  res.status(500).send('Something broke!');
});

</pre><pre>
【 常用中间件: http://expressjs.com/en/resources/middleware.html 】
express                web 框架
express-session        session中间件
connect-mongo          将session存储于mongodb,结合express-session使用
connect-flash          页面通知的中间件,基于session实现
ejs                    模板
body-parser
compression
serve-static
cookie-parser
morgan
express-formidable     接收表单及文件上传的中间件
config-lite            读取配置文件
marked                 markdown解析,textarea: '内容1' => '< p >内容1< /p >\n'
moment                 时间格式化
mongolass              mongodb 驱动
objectid-to-timestamp  根据ObjectId生成时间戳
sha1                   sha1加密,用于密码加密
winston                日志
express-winston        express的winston日志中间件

应用级中间件和路由级中间件是完全等同的,只是使用场景不同。同一个中间件,既可以是应用级中间件、也可以是路由级中间件

【 app.use() 】
app.use([path,] function [, function...])  在一条路由的处理链上插入中间件
Mounts the middleware function(s) at the path. If path is not specified, it defaults to "/"

path can be a string representing a path, a path pattern, a regular expression to match paths, or an array of combinations thereof.

如果某个路径安装挂载了中间件,则当以该路径为基础的路径被访问时,都会应用该中间件,执行中间件的函数
Middleware functions are executed sequentially, therefore the order of middleware inclusion is important.

Disable logging for static content requests by loading the logger middleware after the static middleware:
app.use(express.static(__dirname + '/public'));
app.use(logger());

以app.use()挂载的路径开头的url都能执行该app.use的中间件,app.methods()则必须匹配路由路径才会执行

</pre><pre class="js">
var express = require('express');
var app = express();
var user = express.Router();

app.use(function(req, res, next){                    // 应用级
  console.log('收到请求,地址为：' + req.url);
  next();
});

app.get('/profile', function(req, res, next){        // 应用级
  res.send('profile');
});

user.use('/list', function(req, res, next){          // 路由级
  res.send('/user/list');
});

user.get('/detail', function(req, res, next){        // 路由级
  res.send('/user/detail');
});

app.use('/user', user);

app.listen(3000);

</pre><pre class="js">
var express = require("express");
var http = require("http");
var app = express();

app.use(function(request, response, next) {
  console.log("In comes a " + request.method + " to " + request.url);
  next();
});

app.use(function(request, response) {
  response.writeHead(200, { "Content-Type": "text/plain" });
  response.end("Hello world!\n");
});

function uselessMiddleware(req, res, next){  // 一个不进行任何操作、只传递request对象的中间件
  next();
}

function uselessMiddleware(req, res, next){
  next('出错了！');
}

function logger(req, res, next){
  doSomeBusinessLogic();                  // 业务逻辑处理,比如权限校验、数据库操作、设置cookie等
  next();                                 // 如果需要进入下一个中间件进行处理,则调用next();
}

http.createServer(app).listen(8888);

</pre><pre>
use方法内部可以对访问路径进行判断,实现简单的路由,根据不同的请求网址,返回不同的网页内容

</pre><pre class="js">
var express = require("express");
var http = require("http");
var app = express();

app.use(function(request, response, next) {
  if (request.url == "/") {
    response.writeHead(200, { "Content-Type": "text/plain" });
    response.end("Welcome to the homepage!\n");
  } else {
    next();
  }
});

app.use(function(request, response, next) {
  if (request.url == "/about") {
    response.writeHead(200, { "Content-Type": "text/plain" });
  } else {
    next();
  }
});

app.use(function(request, response) {
  response.writeHead(404, { "Content-Type": "text/plain" });
  response.end("404 error!\n");
});

http.createServer(app).listen(8888);

</pre><pre>
除了在回调函数内部判断请求的网址,use方法也允许将请求网址写在第一个参数。代表只有请求路径匹配这个参数,后面的中间件才会生效
app.use('/path', someMiddleware);

</pre><pre class="js">
// http://localhost:8888/random/110
// Time: 1514378075865

// http://localhost:8888/user/110
// Time: 1514378002902
// app.use /user/:id
// app.get /user/:id

// http://localhost:8888/user/110/hh
// Time: 1514378119610
// app.use /user/:id

/* 以app.use()挂载的路径开头的url都能执行该app.use的中间件,app.methods()则必须匹配路由路径才会执行 */

var express = require('express');
var app = express();

// 没有挂载路径的中间件默认'/',应用的每个请求都会执行该中间件
app.use(function (req, res, next) {
  console.log('Time:', Date.now());
  next();
});

app.use("/about", function(req, res, next) {
  res.writeHead(200, { "Content-Type": "text/plain" });
  res.end("Welcome to the about page!\n");
});

// 挂载至 /user/:id 的中间件,任何指向 /user/:id 的请求都会执行它
app.use('/user/:id', function (req, res, next) {
  console.log('app.use /user/:id');
  next();
});

// 路由和句柄函数(中间件系统),处理指向/user/:id的GET请求
app.get('/user/:id', function (req, res, next) {
  console.log('app.get /user/:id');
  res.send(req.params.id);
});

app.listen(8888);

</pre><pre class="js">
var app = express();

// 没有挂载路径的中间件默认'/',应用的每个请求都会执行该中间件
app.use(function (req, res, next) {
  console.log('Time:', Date.now());
  next();
});

// 挂载至 /user/:id 的中间件,任何指向 /user/:id 的请求都会执行它
app.use('/user/:id', function (req, res, next) {
  console.log('Request Type:', req.method);
  next();
});

// 路由和句柄函数(中间件系统),处理指向/user/:id的GET请求
app.get('/user/:id', function (req, res, next) {
  res.send('USER');
});

</pre><pre>
function can be a middleware function, a series of middleware functions, an array of middleware functions, or a combination of all of them.
Since router and app implement(实现) the middleware interface, you can use them as you would any other middleware function

</pre> Single Middleware <pre class="js">
// You can define and mount a middleware function locally.
app.use(function (req, res, next) {
  next();
})

// A router is valid middleware.
var router = express.Router();
router.get('/', function (req, res, next) {
  next();
})
app.use(router);

// An Express app is valid middleware.
var subApp = express();
subApp.get('/', function (req, res, next) {
  next();
})
app.use(subApp);

</pre> Series of Middleware <pre class="js">

// You can specify more than one middleware function at the same mount path.
var r1 = express.Router();
r1.get('/', function (req, res, next) {
  next();
})

var r2 = express.Router();
r2.get('/', function (req, res, next) {
  next();
})

app.use(r1, r2);

</pre> Array <pre class="js">

// Use an array to group middleware logically. If you pass an array of middleware as the first or only middleware parameters, then you _must_ specify the mount path.
var r1 = express.Router();
r1.get('/', function (req, res, next) {
  next();
})

var r2 = express.Router();
r2.get('/', function (req, res, next) {
  next();
})

app.use('/', [r1, r2]);

</pre> Combination <pre class="js">

// You can combine all the above ways of mounting middleware.
function mw1(req, res, next) { next(); }
function mw2(req, res, next) { next(); }

var r1 = express.Router();
r1.get('/', function (req, res, next) { next(); });

var r2 = express.Router();
r2.get('/', function (req, res, next) { next(); });

var subApp = express();
subApp.get('/', function (req, res, next) { next(); });

app.use(mw1, [mw2, r1, r2], subApp);

</pre><pre class="js">
/* 在一个挂载点装载一组中间件 */

// 一个中间件栈,对任何指向 /user/:id 的HTTP请求打印出相关信息
app.use('/user/:id', function(req, res, next) {
  console.log('Request URL:', req.originalUrl);
  next();
}, function (req, res, next) {
  console.log('Request Type:', req.method);
  next();
});

/* 为指向/user/:id的GET请求定义两个路由,第二个路永远不会被调用,因为第一个路由已经终止了请求-响应循环 */
// 一个中间件栈,处理指向 /user/:id 的 GET 请求
app.get('/user/:id', function (req, res, next) {
  console.log('ID:', req.params.id);
  next();
}, function (req, res, next) {
  res.send('User Info');
});

// 处理 /user/:id, 打印出用户 id
app.get('/user/:id', function (req, res, next) {
  res.end(req.params.id);
});

</pre><pre>
如果需要在中间件栈中跳过剩余中间件,调用next('route')方法将控制权交给下一个路由
注意： next('route') 只对使用 app.VERB() 或 router.VERB() 加载的中间件有效。
</pre><pre class="js">

// 一个中间件栈,处理指向 /user/:id 的 GET 请求
app.get('/user/:id', function (req, res, next) {
  if (req.params.id == 0) next('route');   // 如果 user id 为 0, 跳到下一个路由
  else next();                             // 否则将控制权交给栈中下一个中间件
}, function (req, res, next) {
  res.render('regular');                   // 渲染常规页面
});

// 处理 /user/:id, 渲染一个特殊页面
app.get('/user/:id', function (req, res, next) {
  res.render('special');
});

</pre>
</div>

<div id="Application">
<h2>application</h2><pre>
The app object conventionally denotes(通常表示) the Express application. Create it by calling the top-level express() function exported by the Express module:

</pre><pre class="js">
var express = require('express');
var app = express();
app.get('/', function(req, res){
  res.send('hello world');
});
app.listen(3000);

</pre><pre>
The app object has methods for
- Routing HTTP requests; see app.METHOD and app.param.
- Configuring middleware; see app.route.
- Rendering HTML views; see app.render.
- Registering a template engine; see app.engine.
- has settings (properties) that affect how the application behaves; see Application settings.

</pre>

<h3>application properties</h3><pre>
【 app.locals 】
The app.locals object is a JS object, and its properties are local variables within the application
Once set, the value of app.locals properties persist throughout the life of the application
in contrast with res.locals properties that are valid only for the lifetime of the request

render(name, options, callback)
express传入要渲染的模板,优先级：res.render传入的对象 > res.locals对象 > app.locals对象
app.locals 和 res.locals都用来渲染模板,使用上的区别在于：
app.locals 上通常挂载常量信息(如博客名、描述、作者这种不会变的信息)
res.locals 上通常挂载变量信息,即每次请求可能的值都不一样
如请求者信息,res.locals.user = req.session.user
user、success、error

You can access local variables in templates rendered within the application. This is useful for providing helper functions to templates, as well as app-level data. Note, however, that you cannot access local variables in middleware

app.locals.title = 'My App';
app.locals.strftime = require('strftime');
app.locals.email = 'me@myapp.com';

【 app.mountpath 】
ExpressJS的4.X版本增加了app.mountpath方法,取代原来的app.route,实际上就是多层级路由模式
The app.mountpath property is the path pattern(s) on which a sub app was mounted(安装、嵌入)
A sub app is an instance of express which may be used for handling the request to a route.

</pre><pre class="js">
var express = require('express');
var app = express();                  // the main app
var admin = express();                // the sub app

admin.get('/', function (req, res){
  console.log(admin.mountpath);       // /admin
  res.send('Admin Homepage');
})

app.use('/admin', admin);              // mount the sub app

</pre><pre>
It is similar to(类似于) the baseUrl property of the req object, except req.baseUrl returns the matched URL path, instead of(而不是) the matched pattern(s).

If a sub-app is mounted on multiple path patterns, app.mountpath returns the list of patterns it is mounted on, as shown in the following example.

</pre><pre class="js">
// 创建两个express对象,先把secret绑定到admin上,再把admin绑定到主app上,这样就形成了多层级路由分发
var express = require('express');
var app = express();

var admin = express();
admin.get('/', function (req, res) {
  console.log(admin.mountpath);        // [ '/adm*n', '/manager' ]
  res.send('Admin Homepage');
})

var secret = express();
secret.get('/', function (req, res) {
  console.log(secret.mountpath);        // /secr*t
  res.send('Admin Secret');
});

// load the 'secret' router on '/secr*t', on the 'admin' sub app
admin.use('/secr*t', secret);
// load the 'admin' router on '/adm*n' and '/manager', on the parent app
app.use(['/adm*n', '/manager'], admin);

app.listen(8888)

</pre><pre>
【 app事件 mount events 】
app.on('mount', callback(parent))
The mount event is fired on a sub-app, when it is mounted on a parent app. The parent app is passed to the callback function

</pre><h3>application method</h3><pre>

【 app.listen(port, [hostname], [backlog], [callback]) 】
Binds and listens for connections on the specified host and port. This method is identical(同) to Node's http.Server.listen()

</pre><pre class="js">
var express = require('express');
var app = express();
app.listen(3000);

</pre><pre>
The app returned by express() is in fact a JavaScript Function, designed to be passed to Node's HTTP servers as a callback to handle requests. This makes it easy to provide both HTTP and HTTPS versions of your app with the same code base, as the app does not inherit from these (it is simply a callback):

</pre><pre class="js">
var express = require('express');
var https = require('https');
var http = require('http');
var app = express();
http.createServer(app).listen(80);
https.createServer(options, app).listen(443);

</pre><pre>
The app.listen() method is a convenience(方便) method for the following (for HTTP only):

</pre><pre class="js">
app.listen = function() {
  var server = http.createServer(this);
  return server.listen.apply(server, arguments);
};

</pre><pre>
【 app.engine(engineExt, engineFunc) 】
注册开发模板引擎 Registers the given template engine callback as ext

By default, Express will require() the engine based on the file extension. For example, if you try to render a "foo.jade" file, Express invokes(调用) the following internally(内部), and caches the require() on subsequent(后续) calls to increase performance(提供性能)

app.engine('jade', require('jade').__express);

Use this method for engines that do not provide .__express out of the box, or if you wish to "map"(绘制、地图、比对) a different extension to the template engine.
For example, to map the EJS template engine to ".html" files

app.engine('html', require('ejs').renderFile);

In this case, EJS provides a .renderFile() method with the same signature that Express expects: (path, options, callback), though note that it aliases this method as ejs.__express internally so if you're using ".ejs" extensions you don't need to do anything

engineExt：模板文件后缀名。比如jade。
engineFunc：模板引擎核心逻辑的定义,一个带三个参数的函数
filepath: 模板文件的路径
options：渲染模板所用的参数
callback：渲染完成回调,参数一：渲染过程的错误,如成功,则为null;参数二：渲染出来的字符串

</pre><pre class="js">
/* 使用后缀为tmpl的模板引擎 */
app.engine('tmpl', function(filepath, options, callback){
    return callback(null, 'Hello World');
});
app.set('views', './views');
app.set('view engine', 'tmpl');

</pre><pre>
【 app.set方法用于指定变量的值 】
Assigns setting name to value, where name is one of the properties from the app settings table
Calling app.set('foo', true) for a Boolean property is the same as calling app.enable('foo'). Similarly, calling app.set('foo', false) for a Boolean property is the same as calling app.disable('foo')

使用set方法为系统变量"views"和"view engine"指定值
app.set("views", __dirname + "/views");
app.set("view engine", "jade");          // 指定模板文件的后缀名

app.get(name)
Retrieve(检索) the value of a setting with app.get()
若调用app.get()时只有一个参数则认为是取设置值,否则认为是注册路由

app.get('title');             // => undefined
app.set('title', 'My Site');
app.get('title');             // => "My Site"
app.get(path, callback [, callback ...])
app.get('/', function (req, res) {
  res.send('GET request to homepage');
});

// 所有环境
app.set('title', 'My Application');

// 只用于开发环境
if ('development' == app.get('env')) {
  app.set('db uri', 'localhost/dev');
}

// 只用于生产环境
if ('production' == app.get('env')) {
  app.set('db uri', 'n.n.n.n/prod');
}

</pre><pre class="js">
// Application Settings affects the behavior of the application

Property && Type && Value && Default
case sensitive routing 大小写敏感
Boolean
Enable case sensitivity(灵敏度)
Disabled. Treats "/Foo" and "/foo" as the same.

env
String
Environment mode.
process.env.NODE_ENV (NODE_ENV environment variable) or "development".

etag(Entity Tag 实体标签,用来帮助服务器控制Web端的缓存验证)
Varied(多种多样)
Set the HTTP1.1 ETag response header. For possible values, see the etag options table
No default
ETag: "3f80f-1b6-3e1cb03b"
原理:当浏览器请求服务器的某项资源(A)时, 服务器根据A算出一个哈希值(3f80f-1b6-3e1cb03b)并通过 ETag 返回给浏览器,浏览器把"3f80f-1b6-3e1cb03b" 和 A 同时缓存在本地,当下次再次向服务器请求A时,会通过类似 If-None-Match: "3f80f-1b6-3e1cb03b" 的请求头把ETag发送给服务器,服务器再次计算A的哈希值并和浏览器返回的值做比较,如果发现A发生了变化就把A返回给浏览器(200),如果发现A没有变化就给浏览器返回一个304未修改。这样通过控制浏览器端的缓存,可以节省服务器的带宽,因为服务器不需要每次都把全量数据返回给客户端
通常情况下,ETag更类似于资源指纹(fingerprints),如果资源发生变化了就会生成一个新的指纹,这样可以快速的比较资源的变化。在服务器端实现中,很多情况下并不会用哈希来计算ETag,这会严重浪费服务器端资源,很多网站默认是禁用ETag的。有些情况下,可以把ETag退化,比如通过资源的版本或者修改时间来生成ETag。
如果通过资源修改时间来生成ETag,那么效果和HTTP协议里面的另外一个控制属性(Last-Modified)就雷同了,使用 Last-Modified 的问题在于它的精度在秒(s)的级别,比较适合不太敏感的静态资源

jsonp callback name
String
Specifies the default JSONP callback name.
?callback=

json replacer
String
JSON replacer callback.
null

json spaces
Number
When set, sends prettified JSON string indented(缩进) with the specified amount of spaces.
Disabled.

query parser
String
The query parser to use, either "simple" or "extended". The simple query parser is based on Node's native query parser, querystring. The extended query parser is based on qs.
"extended"

strict routing
Boolean
Enable strict routing.
Disabled. Treats "/foo" and "/foo/" as the same by the router.

subdomain offset
Number
The number of dot-separated parts of the host to remove to access subdomain.
2

trust proxy
Varied
Indicates(表明) the app is behind a front-facing proxy, and to use the X-Forwarded-* headers to determine(确定) the connection and the IP address of the client.
NOTE: X-Forwarded-* headers are easily spoofed(欺骗) and the detected IP addresses are unreliable(检测到的ip不可靠)
trust proxy is disabled by default. When enabled, Express attempts(try) to determine the IP address of the client connected through the front-facing proxy, or series of proxies. The req.ips property, then, contains an array of IP addresses the client is connected through. To enable it, use the values described in the trust proxy options table.
The trust proxy setting is implemented(实现) using the proxy-addr package
Disabled.

views
String or Array
A directory or an array of directories for the application's views. If an array, the views are looked up in the order they occur in the array.
process.cwd() + '/views'

view cache
Boolean
Enables view template compilation caching.
true in production.

view engine
String
The default engine extension to use when omitted.

x-powered-by
Boolean
Enables the "X-Powered-By: Express" HTTP header.
true

// Options for `trust proxy` setting

Type  Value
Boolean
If true, the client's IP address is understood as the left-most entry in the X-Forwarded-* header.
If false, the app is understood as directly facing the Internet and the client's IP address is derived from req.connection.remoteAddress. This is the default setting.

IP addresses
An IP address, subnet, or an array of IP addresses, and subnets to trust. The following is the list of pre-configured subnet names.
  loopback - 127.0.0.1/8, ::1/128
  linklocal - 169.254.0.0/16, fe80::/10
  uniquelocal - 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16, fc00::/7
Set IP addresses in any of the following ways:
app.set('trust proxy', 'loopback') // specify a single subnet
  app.set('trust proxy', 'loopback, 123.123.123.123') // specify a subnet and an address
  app.set('trust proxy', 'loopback, linklocal, uniquelocal') // specify multiple subnets as CSV
  app.set('trust proxy', ['loopback', 'linklocal', 'uniquelocal']) // specify multiple subnets as an array
When specified, the IP addresses or the subnets are excluded from the address determination process, and the untrusted IP address nearest to the application server is determined as the client's IP address.

Number
Trust the nth hop from the front-facing proxy server as the client.

Function
Custom trust implementation. Use this only if you know what you are doing.
app.set('trust proxy', function (ip) {
  if (ip === '127.0.0.1' || ip === '123.123.123.123') return true; // trusted IPs
  else return false;
})

// Options for `etag` setting

Type  Value
Boolean
true enables weak ETag. This is the default setting.
false disables ETag altogether.

String
If "strong", enables strong ETag.
If "weak", enables weak ETag.

Function
Custom ETag function implementation. Use this only if you know what you are doing.
app.set('etag', function (body, encoding) {
  return generateHash(body, encoding); // consider the function is defined
})

</pre><pre>
【 app.disable(name) app.set(name, false) 】
Sets the Boolean setting name to false, where name is one of the properties from the app settings table. Calling app.set('foo', false) for a Boolean property is the same as calling app.disable('foo')

app.disable('trust proxy');
app.get('trust proxy');        // => false

【 app.disabled(name) 】
Returns true if the Boolean setting name is disabled (false), where name is one of the properties from the app settings table

app.disabled('trust proxy');   // => true

app.enable('trust proxy');
app.disabled('trust proxy');
// => false

【 app.enable(name) 】
Sets the Boolean setting name to true, where name is one of the properties from the app settings table. Calling app.set('foo', true) for a Boolean property is the same as calling app.enable('foo')

app.enable('trust proxy');
app.get('trust proxy');      // => true

【 app.enabled(name) 】
Returns true if the setting name is enabled (true), where name is one of the properties from the app settings table.

app.enabled('trust proxy');  // => false

app.enable('trust proxy');
app.enabled('trust proxy');  // => true

【 app.render(view, [locals], callback) 】
把app.render当成一个生成视图的工具,而且res.render内部也是调用了app.render
app.render只负责生成视图,没能力把视图响应给客户端(浏览器),只有res.render可以把视图响应给客户端

Returns the rendered HTML of a view via the callback function. It accepts an optional parameter that is an object containing local variables for the view. It is like res.render(), except it cannot send the rendered view to the client on its own

Think of app.render() as a utility function for generating rendered view strings. Internally res.render() uses app.render() to render views.
The local variable cache is reserved(保留) for enabling view cache. Set it to true, if you want to cache view during development; view caching is enabled in production by default.

</pre><pre class="js">
// res.render的伪代码可以看做如下:

res.render = function(view, locals, cb){
  app.render(view, locals, function(err, html){
    if(typeof cb !== 'undefined') return cb(err, html);
    res.send(html);
  });
};

</pre><pre class="js">
app.render('email', function(err, html){
  // ...
});

app.render('email', { name: 'Tobi' }, function(err, html){
  // ...
});

</pre><pre>
动态页面静态化
需要一个编译过程：模板 + 数据 —> 静态html文件
ejs,jade,nunjucks,swig等等所有的模板引擎最后吐出的东西都是编译完成的,需要把这些保存成文件

一是直接将原来的jade编译,保留动态数据;
二是现将动态数据剔除,再编译为html,由ajax页面加载后请求数据

可以考虑用nginx来做代理做静态资源服务器
把静态资源用nginx存起来,这样用户如果请求资源可以直接从nginx服务器缓存中读取 而不需要再占用服务器资源

view cache: express/lib/application.js 118
if (env === 'production') {
  this.enable('view cache');
}

设置app.set('view cache', true)

客户端缓存和服务端缓存
处理web应用程序的时,可使用当前所有浏览器都支持的响应头来进行客户端缓存,从而提升页面加载效率\但当一个内容非常繁杂的页面需要2s来进行HTML输出时,即使启用客户端缓存该页面,服务器仍然需要针对每一个来访用户进行页面渲染。想想一个大型的新闻门户网站首页,难道他们要针对每一个用户一遍又一遍地处理HTML吗？
这时候服务器缓存就派上用场了。使用服务器缓存的目标是对相同的客户端请求返回相同的内容

</pre><pre>
【 app.path() 】
Returns the canonical(规范) path of the app, a string
The behavior of this method can become very complicated(复杂) in complex cases of mounted apps: it is usually(通常) better to use req.baseUrl to get the canonical path of the app

</pre><pre class="js">
var app = express();
var blog = express();
var blogAdmin = express();

app.use('/blog', blog);
blog.use('/admin', blogAdmin);

console.log(app.path()); // ''
console.log(blog.path()); // '/blog'
console.log(blogAdmin.path()); // '/blog/admin'

</pre><pre class="js">
var admin = express();

admin.on('mount', function (parent) {
  console.log('Admin Mounted');
  console.log(parent); // refers to the parent app
});

admin.get('/', function (req, res) {
  res.send('Admin Homepage');
});

app.use('/admin', admin);

</pre><pre>

【 app.param([name], callback) 】
app.param方法用于验证参数,对地址栏参数进行过滤,针对不同参数作出不同响应,结合正则表达式使用更强大
param回调在请求-响应周期中只会调用一次,即使这个参数匹配多个路由

Add callback triggers(触发器) to route parameters, where name is the name of the parameter or an array of them, and function is the callback function. The parameters of the callback function are the request object, the response object, the next middleware, and the value of the parameter, in that order.

If name is an array, the callback trigger is registered for each parameter declared(声明) in it, in the order in which they are declared. Furthermore, for each declared parameter except the last one, a call to next inside the callback will call the callback for the next declared parameter. For the last parameter, a call to next will call the next middleware in place for the route currently being processed, just like it would if name were just a string.

For example, when :user is present in a route path, you may map user loading logic(逻辑) to automatically provide req.user to the route, or perform validations on the parameter input.

</pre><pre class="js">
app.param('user', function(req, res, next, id) {
  // try to get the user details from the User model and attach it to the request object
  User.find(id, function(err, user) {
    if (err) {
      next(err);
    } else if (user) {
      req.user = user;
      next();
    } else {
      next(new Error('failed to load user'));
    }
  });
});

</pre><pre>
Param callback functions are local to the router on which they are defined. They are not inherited by mounted apps or routers. Hence, param callbacks defined on app will be triggered only by route parameters defined on app routes.

All param callbacks will be called before any handler of any route in which the param occurs, and they will each be called only once in a request-response cycle, even if the parameter is matched in multiple routes, as shown in the following examples.

</pre><pre class="js">
// GET /user/42

app.param('id', function (req, res, next, id) {
  console.log('CALLED ONLY ONCE');
  next();
})

app.get('/user/:id', function (req, res, next) {
  console.log('although this matches');
  next();
});

app.get('/user/:id', function (req, res) {
  console.log('and this matches too');
  res.end();
});

</pre><pre class="js">
// GET /user/42/3

app.param(['id', 'page'], function (req, res, next, value) {
  console.log('CALLED ONLY ONCE with', value);
  next();
})

app.get('/user/:id/:page', function (req, res, next) {
  console.log('although this matches');
  next();
});

app.get('/user/:id/:page', function (req, res) {
  console.log('and this matches too');
  res.end();
});

</pre><pre class="js">
// 只有在地址栏输入http://localhost:3000/user/1337的情况下,页面才会显示"参数通过检验"

var express = require('express');
var app = express();
app.param('id', function (req, res, next, id) {
  if(id==1337) next();
  else res.sendStatus(404);
});
app.get('/user/:id', (req, res) => res.send('参数通过检验'));

app.listen(3000, () => console.log('Ready'));

</pre>
</div>

<div id="route">
<h3>路由 路由级中间件</h3><pre>
路由是指如何定义应用的端点URIs以及如何响应客户端的请求
路由决定如何响应处理客户端HTTP请求中的路径部分,为不同的访问路径指定不同的处理方法响应客户端的请求
路由是由一个URI、HTTP 请求(GET、POST等)和若干个句柄组成
在HTTP请求中通过路由提取出请求的URL以及GET/POST参数

【 all方法和HTTP动词方法 】
针对不同类型的请求,Express提供了use方法的一些别名

【 app.all(path, callback [, callback ...]) 】
app.all()是一个特殊的路由方法,对于一个路径上的所有请求都必须通过该中间件,参数中的"*"表示对所有路径有效

This method is like the standard app.METHOD() methods, except it matches all HTTP verbs.

It's useful for mapping "global" logic for specific path prefixes or arbitrary(任意) matches.
For example, if you put the following at the top of all other route definitions, it requires that all routes from that point on require authentication, and automatically load a user.
Keep in mind that these callbacks do not have to act as end-points(端点): loadUser can perform a task, then call next() to continue matching subsequent(后续) routes.

app.all('*', requireAuthentication, loadUser);

Or the equivalent:
app.all('*', requireAuthentication)
app.all('*', loadUser);

Another example is white-listed(白名单) "global" functionality. The example is much like before, however it only restricts paths that start with "/api":
app.all('/api/*', requireAuthentication);

【 app.METHOD(path, callback [, callback ...]) 】
1、app是express对象的一个实例
2、METHOD: 路由方法源于HTTP请求方法,和express实例相关联,是一个HTTP请求方法
get/post/put/head/delete/options/trace/copy/lock/mkcol/move/purge/propfind/proppatch/unlock/report/mkactivity/checkout/merge/m-search/notify/subscribe/unsubscribe/patch/search/connect
3、path: 路由路径,是服务器上的路径,查询字符串不是路由路径的一部分
路由路径和请求方法一起定义了请求的端点,可以是字符串、字符串模式、正则表达式或者这些模式组成的数组
若URL中没有给出path,默认"/"(通常由浏览器或其它HTTP客户端完成补充上)
Express使用path-to-regexp匹配路由路径,除了绝对匹配以外,Express允许模式匹配
如果在模式参数后面加上问号,表示该参数可选
4、callback是当路由匹配时要执行的函数

app.get(path, callback [, callback ...])
get方法则是只有GET动词的HTTP请求通过该中间件
调用app.get()就为网站添加了一条路由,一参是请求的路径,指定'/'这个路径由get的第二个参数所代表的函数来处理

app.post(path, callback [, callback ...])
Routes HTTP POST requests to the specified path with the specified callback functions

app.put(path, callback [, callback ...])
Routes HTTP PUT requests to the specified path with the specified callback functions
app.put('/', function (req, res) {
  res.send('PUT request to homepage');
});

app.delete(path, callback [, callback ...])
Routes HTTP DELETE requests to the specified path with the specified callback functions.
app.delete('/', function (req, res) {
  res.send('DELETE request to homepage');
});

http://forbeslindesay.github.io/express-route-tester/  测试基本Express路径工具,但不支持模式匹配

最直接的路由配置方法,就是调用app.get()、app.post()一条一条的配置,不适用于需要处理大量路由的网站来讲
实际开发中需要结合路由参数(query string、正则表达式、自定义的参数、post参数)来减小工作量提高可维护性

</pre><pre class="js">
// 由于get方法的回调函数没有调用next方法,所以只要有一个中间件被调用了,后面的中间件就不会再被调用了

var express = require("express");
var http = require("http");
var app = express();

app.all("*", function(req, res, next) {
  res.writeHead(200, { "Content-Type": "text/plain" });
  next();
});

app.all('/secret', function (req, res, next) {
  console.log('Accessing the secret section ...');
  next();
});

app.get("/", function(req, res) {
  res.end("Welcome to the homepage!");
});

app.get("/about", function(req, res) {
  res.end("Welcome to the about page!");
});

app.get("*", function(req, res) {
  res.end("404!");
});

app.get('*', function (req, res) {       // 响应所有的请求
  res.send('Hello World!');
});

/* 使用字符串的路由路径 */

app.post('/', function (req, res) {
  res.send('POST request to the homepage');
});

app.get('/about', function (req, res) {
  res.send('about');
});

app.get('/random.text', function (req, res) {
  res.send('random.text');
});

/* 使用字符串模式的路由路径 */

app.get('/ab?cd', function(req, res) {     // 匹配 acd 和 abcd
  res.send('ab?cd');
});

app.get('/ab+cd', function(req, res) {     // 匹配 abcd、abbcd、abbbcd等
  res.send('ab+cd');
});

app.get('/ab*cd', function(req, res) {     // 匹配 abcd、abxcd、abRABDOMcd、ab123cd等
  res.send('ab*cd');
});

app.get('/user/*man', function(req, res, next){
    res.send('user');                      // 比如： /user/man, /user/woman
});

app.get('/ab(cd)?e', function(req, res) {  // 匹配 /abe 和 /abcde
  res.send('ab(cd)?e');
});

/* 使用正则表达式的路由路径 */
app.get(/a/, function(req, res) {          // 匹配任何路径中含有a的路径：
  res.send('/a/');
});

app.get(/.*fly$/, function(req, res) {
  res.send('/.*fly$/');
});

app.get(/animals?$/, function(req, res, next){
    res.send('animal');                    // 比如： /animal, /animals
});

/* 使用数组的路由路径 */
// will match paths starting with /abcd, /xyza, /lmn, and /pqr
app.use(['/abcd', '/xyza', /\/lmn|\/pqr/], (req, res, next) => {
  next();
})

/* 路由：命名参数 */
app.get('/employee/:uid/:age', function(req, res, next){
    res.json(req.params);                  // 比如：/111/30,返回 {"uid": 111, "age": 30}
});

http.createServer(app).listen(1337);

</pre><pre class="js">
// 将匹配"/hello/alice",alice将被捕获作为req.params.who属性的值。捕获后需要对网址进行检查,过滤不安全字符
app.get("/hello/:who", function(req, res) {
  res.end("Hello, " + req.params.who + ".");
});

</pre><pre class="js">
app.get('/hello/:who?',function(req,res){
  if(req.params.who){
    res.end("Hello, " + req.params.who + ".");
  }else {
    res.send("Hello, Guest.");
  }
});

</pre><pre class="js">
app.get('/forum/:fid/thread/:tid', middleware)

// 匹配/commits/71dbb9c或/commits/71dbb9c..4c084f9这样的git格式的网址
app.get(/^\/commits\/(\w+)(?:\.\.(\w+))?$/, function(req, res){
  var from = req.params[0];
  var to = req.params[1] || 'HEAD';
  res.send('commit range ' + from + '..' + to);
});

</pre><pre class="js">
var express = require('express');
var app = express();

app.get('/', function (req, res) {          //  主页输出 "Hello World"
  console.log("主页 GET 请求");
  res.send('Hello GET');
})

app.post('/', function (req, res) {         //  POST 请求
  console.log("主页 POST 请求");
  res.send('Hello POST');
})

app.get('/del_user', function (req, res) {   //  /del_user 页面响应
  console.log("/del_user 响应 DELETE 请求");
  res.send('删除页面');
})

app.get('/list_user', function (req, res) {  //  /list_user 页面 GET 请求
  console.log("/list_user GET 请求");
  res.send('用户列表页面');
})

app.get('/ab*cd', function(req, res) {       // 对页面 abcd, abxcd, ab123cd, 等响应 GET 请求
  console.log("/ab*cd GET 请求");
  res.send('正则匹配');
})

var server = app.listen(8081, function () {
  var host = server.address().address
  var port = server.address().port
  console.log("应用实例,访问地址为 http://%s:%s", host, port)
})

</pre><pre>
【 路由句柄 】
可以为请求处理提供多个回调函数,其行为类似中间件.唯一的区别是这些回调函数有可能调用next('route')方法而略过其他路由回调函数。可以利用该机制为路由定义前提条件,如果在现有路径上继续执行没有意义,则可将控制权交给剩下的路径。

路由句柄有多种形式,可以是一个函数、一个函数数组,或者是两者混合

</pre><pre class="js">
/* 使用一个回调函数处理路由 */
app.get('/example/a', function (req, res) {
  res.send('Hello from A!');
});

/* 使用多个回调函数处理路由(记得指定 next 对象) */
app.get('/example/b', function (req, res, next) {
  console.log('response will be sent by the next function ...');
  next();
}, function (req, res) {
  res.send('Hello from B!');
});

/* 使用回调函数数组处理路由 */
var cb0 = function (req, res, next) {
  console.log('CB0');
  next();
}

var cb1 = function (req, res, next) {
  console.log('CB1');
  next();
}

var cb2 = function (req, res) {
  res.send('Hello from C!');
}

app.get('/example/c', [cb0, cb1, cb2]);

/* 混合使用函数和函数数组处理路由 */
var cb0 = function (req, res, next) {
  console.log('CB0');
  next();
}

var cb1 = function (req, res, next) {
  console.log('CB1');
  next();
}

app.get('/example/d', [cb0, cb1], function (req, res, next) {
  console.log('response will be sent by the next function ...');
  next();
}, function (req, res) {
  res.send('Hello from D!');
});

</pre><pre>
【 app.route() 】
Returns an instance of a single route, which you can then use to handle HTTP verbs(动词) with optional middleware. Use app.route() to avoid(避免) duplicate(重复的) route names and thus(因此) typo(输入错误) errors

app.route()创建路由路径的链式路由句柄,路径在一个地方指定,助于创建模块化的路由,减少了代码冗余和拼写错误

app.route实际上是express.Router()的缩写形式,除了直接挂载到根路径

app.route方法会返回一个Route实例,可以继续使用所有的HTTP方法。因此对同一个路径指定get和post方法的回调函数,可以写成链式形式

</pre><pre class="js">
app.route('/login')
  .get(function(req, res, next) {
    res.send('this is the login form');
  })
  .post(function(req, res, next) {
    console.log('processing');
    res.send('processing the login form!');
  });

</pre><pre class="js">
app.route('/book')
  .get(function(req, res) {
    res.send('Get a random book');
  })
  .post(function(req, res) {
    res.send('Add a book');
  })
  .put(function(req, res) {
    res.send('Update the book');
  });

</pre>


<h3 id="express.router">Express.Router类 创建模块化、可挂载的路由句柄</h3><pre>
从Express 4.0开始,路由器功能成了一个单独的组件Express.Router
Router 实例是一个完整的中间件和路由系统,因此常称其为一个 mini app,有自己的use、get、param和route方法

A router object is an isolated(孤立的) instance of middleware and routes. You can think of it as a "mini-application," capable(有能力) only of performing middleware and routing functions. Every Express application has a built-in app router.

A router behaves like middleware itself, so you can use it as an argument to app.use() or as the argument to another router's use() method.

The top-level express object has a Router() function that creates a new router object

Express.Router是一个构造函数,调用后返回一个路由器实例。然后使用该实例的HTTP动词方法,为不同的访问路径,指定回调函数;最后挂载到某个路径

【 var router = express.Router([options]); 】

The optional options parameter specifies the behavior of the router

options:
1、caseSensitive
Enable case sensitivity
Disabled by default, treating "/Foo" and "/foo" as the same.

2、mergeParams
Preserve(保存) the req.params values from the parent router. If the parent and the child have conflicting(冲突) param names, the child's value take precedence(优先级)
default to false

3、strict
Enable strict routing
Disabled by default, "/foo" and "/foo/" are treated the same by the router.

串行路由和并行路由

You can add middleware and HTTP method routes (such as get, put, post, and so on) to router just like an application
You can then use a router for a particular root URL in this way separating your routes into files or even mini-apps

</pre><pre class="js">
var router = express.Router();    // 创建一个Router实例

// 可以像使用app一样使用router,invoked for any requests passed to this router
router.use(function(req, res, next) {
  console.log(req.url);
  next();
});

// will handle any request that ends in /events depends on where the router is "use()'d"
router.get('/events', function(req, res, next) {
  // ..
});

// 定义了router后也可以将其作为中间件传递给app.use
// 针对URL中"/calendar"路径应用router,在router对象上配置的各种路由策略和中间件都会被在合适的时候应用
// only requests to /calendar/* will be sent to our "router"
app.use('/calendar', router);

</pre><pre class="js">
/* 创建一个路由模块,并加载了一个中间件,定义了一些路由,并且将它们挂载至应用的路径上 */
/* 可处理发自 /birds 和 /birds/about 的请求,并且调用为该路由指定的 timeLog 中间件 */

/* birds.js */
var express = require('express');
var router = express.Router();

// 该路由使用的中间件
router.use(function timeLog(req, res, next) {
  console.log('Time: ', Date.now());
  next();
});
// 定义网站主页的路由
router.get('/', function(req, res) {
  res.send('Birds home page');
});
// 定义 about 页面的路由
router.get('/about', function(req, res) {
  res.send('About birds');
});

module.exports = router;

/* 在应用中加载路由模块 */
var birds = require('./birds');
app.use('/birds', birds);

</pre><pre class="js">
// 先定义了两个访问路径,然后将它们挂载到/admin目录,相当于为/admin和/admin/about这两个路径指定回调函数
var router = express.Router();
router.get('/', function(req, res) {
  res.send('首页');
});
router.get('/about', function(req, res) {
  res.send('关于');
});
app.use('/admin', router);

</pre><pre>
【 router.use([path], [function, ...] function) 】
use方法为router对象指定中间件,即在数据正式发给用户之前,对数据进行处理
函数体中的next(),表示将数据传递给下一个中间件

中间件的放置顺序很重要,等同于执行顺序,而且中间件必须放在HTTP动词方法之前,否则不会执行

Uses the given middleware function, with optional mount path 'path', that defaults to "/".

This method is similar to app.use(). A simple example and usecase is described below

Middleware is like a plumbing(管道) pipe, requests start at the first middleware you define and work their way "down" the middleware stack processing for each path they match

The router.use() method also supports named parameters so that your mount points for other routers can benefit(好处) from preloading using named parameters.

</pre><pre class="js">
router.use(function(req, res, next) {
  console.log(req.method, req.url);
  next();
});

</pre><pre class="js">
// app.use挂载的路径是baseUrl,必须localhost:8888/foo开头才会进入该router路由
// router.use('/bar', middleware)挂载的路径必须是localhost:8888/foo/bar开头的任意路径

// http://localhost:8888/foo/bar/new

var express = require('express');
var app = express();
var router = express.Router();

// simple logger for this router's requests,all requests to this router will first hit this middleware
router.use(function(req, res, next) {
  console.log('%s %s %s', req.method, req.url, req.path);
  next();
});

// this will only be invoked if the path starts with /bar from the mount point
router.use('/bar', function(req, res, next) {
  // ... maybe some additional /bar logging ...
  console.log('router.use /bar');
  next();
});

// always invoked
router.use(function(req, res, next) {
  res.send('Hello World');
});

app.use('/foo', router);
app.listen(8888);

</pre><pre>
The "mount" path is stripped(剥夺) and is not visible to the middleware function. The main effect of this feature is that mounted middleware may operate without code changes regardless(不管) of its "prefix" pathname.

The order in which you define middleware with router.use() is very important. They are invoked sequentially, thus the order defines middleware precedence(优先级). For example, usually(通常) a logger is the very first middleware you would use, so every request is logged.

</pre><pre class="js">
var logger = require('morgan');
router.use(logger());
router.use(express.static(__dirname + '/public'));
router.use(function(req, res){
  res.send('Hello');
});

</pre><pre>
Now suppose(假如) you wanted to ignore(忽略) logging requests for static files, but to continue logging routes and middleware defined after logger(). You would simply move static() above:

</pre><pre class="js">
router.use(express.static(__dirname + '/public'));
router.use(logger());
router.use(function(req, res){
  res.send('Hello');
});

</pre><pre>
Another concrete example is serving files from multiple directories, giving precedence to "./public" over the others:

</pre><pre class="js">
app.use(express.static(__dirname + '/public'));
app.use(express.static(__dirname + '/files'));
app.use(express.static(__dirname + '/uploads'));

</pre><pre class="js">
var express = require('express');
var app = express();
var router = express.Router();

// 没有挂载路径的中间件,通过该路由的每个请求都会执行该中间件
router.use(function (req, res, next) {
  console.log('Time:', Date.now());
  next();
});

// 一个中间件栈,显示任何指向 /user/:id 的 HTTP 请求的信息
router.use('/user/:id', function(req, res, next) {
  console.log('Request URL:', req.originalUrl);
  next();
}, function (req, res, next) {
  console.log('Request Type:', req.method);
  next();
});

// 一个中间件栈,处理指向 /user/:id 的 GET 请求
router.get('/user/:id', function (req, res, next) {
  if (req.params.id == 0) next('route');  // 如果 user id 为 0, 跳到下一个路由
  else next();                            // 负责将控制权交给栈中下一个中间件
}, function (req, res, next) {
  res.render('regular');                  // 渲染常规页面
});

// 处理 /user/:id, 渲染一个特殊页面
router.get('/user/:id', function (req, res, next) {
  console.log(req.params.id);
  res.render('special');
});

// 将路由挂载至应用
app.use('/', router);

</pre><pre>
【 router.all(path, [callback, ...] callback) 】

</pre><pre class="js">
router.all('*', requireAuthentication, loadUser);

// Or the equivalent
router.all('*', requireAuthentication)
router.all('*', loadUser);
router.all('/api/*', requireAuthentication);

</pre><pre>
【 router.METHOD(path, [callback, ...] callback) 】

</pre><pre class="js">
router.get('/', function(req, res){
  res.send('hello world');
});

router.get(/^\/commits\/(\w+)(?:\.\.(\w+))?$/, function(req, res){
  var from = req.params[0];
  var to = req.params[1] || 'HEAD';
  res.send('commit range ' + from + '..' + to);
});

</pre><pre>
【 router.param([name,] callback) 】
router对象的param方法用于对路径参数的处理,param方法必须放在HTTP动词方法之前

</pre><pre class="js">
// http://localhost:8888/hello/jack
// router.param
// jack
// router.get
// print hello ! how are you ?jack!

// http://localhost:8888/jack
// print Cannot GET /jack

// http://localhost:8888/admin/hello/jack
// print Cannot GET /admin/hello/jack

var express = require('express');
var app = express();
var router = express.Router();

router.param('name', function(req, res, next, name) {
  // 对name进行验证或其他处理……
  console.log('router.param');
  console.log(name);
  req.name = '! how are you ?' + name;
  next();
});

router.get('/hello/:name', function(req, res) {
  console.log('router.get');
  res.send('hello ' + req.name + '!');
});

app.use(router);
app.listen(8888);

</pre><pre class="js">
router.param('user', function(req, res, next, id) {
  // try to get the user details from the User model and attach it to the request object
  User.find(id, function(err, user) {
    if(err){
      next(err);
    }else if(user){
      req.user = user;
      next();
    }else{
      next(new Error('failed to load user'));
    }
  });
});

</pre><pre class="js">
// http://localhost:8888/user/1/2
// although this matches
// and this matches too

// 文档案例,router.param数组参数可能错误

router.param(['id', 'page'], function (req, res, next, value) {
  console.log('CALLED ONLY ONCE with', value);
  next();
})

app.get('/user/:id/:page', function (req, res, next) {
  console.log('although this matches');
  next();
});

app.get('/user/:id/:page', function (req, res) {
  console.log('and this matches too');
  res.end();
});

app.use(router);

</pre><pre class="js">
// http://localhost:8888/user/1/2
// CALLED ONLY ONCE with id 1
// CALLED ONLY ONCE with page 2
// although this matches
// and this matches too

router.param(['id', 'page'], function (req, res, next, value) {
  console.log('CALLED ONLY ONCE with all', value);
  next();
})

router.param('id', function (req, res, next, value) {
  console.log('CALLED ONLY ONCE with id', value);
  next();
})

router.param('page', function (req, res, next, value) {
  console.log('CALLED ONLY ONCE with page', value);
  next();
})

router.get('/user/:id/:page', function (req, res, next) {
  console.log('although this matches');
  next();
});

router.get('/user/:id/:page', function (req, res) {
  console.log('and this matches too');
  res.end();
});

app.use(router);

</pre><pre>
【 router.route(path) 】
router实例对象的router.route()方法,可以接受访问路径作为参数

</pre><pre class="js">
var router = express.Router();
router.route('/api')
  .post(function(req, res) {
    // ...
  })
  .get(function(req, res) {
    Bear.find(function(err, bears) {
      if (err) res.send(err);
      res.json(bears);
    });
  });
app.use('/', router);

</pre><pre class="js">
var router = express.Router();
router.param('user_id', function(req, res, next, id) {
  req.user = { id: id, name: 'TJ' };
  next();
});

router.route('/users/:user_id')
  .all(function(req, res, next) {
    next();
  })
  .get(function(req, res, next) {
    res.json(req.user);
  })
  .put(function(req, res, next) {
    req.user.name = req.params.name;
    res.json(req.user);
  })
  .post(function(req, res, next) {
    next(new Error('not implemented(实现)'));
  })
  .delete(function(req, res, next) {
    next(new Error('not implemented'));
  })

</pre><pre>
【 路由拆分 】
当应用越来越复杂,不可避免的,路由规则也会越来越复杂。此时对路由进行拆分是个不错的选择

</pre><pre class="js">
// 路由拆分前,新增还是修改路由,都要带着/user前缀
var express = require('express');
var app = express();

app.get('/user/list', function(req, res, next){
  res.send('/list');
});

app.get('/user/detail', function(req, res, next){
  res.send('/detail');
});

app.listen(3000);

// 路由拆分后
var express = require('express');
var app = express();
var user = express.Router();

user.get('/list', function(req, res, next){
  res.send('/list');
});

user.get('/detail', function(req, res, next){
  res.send('/detail');
});

app.use('/user', user); // mini app,通常做应用拆分

app.listen(3000);

</pre>
</div>

<div id="resobj">
<h2>响应属性和方法</h2><pre>
如果在路由句柄中一个方法也不调用,来自客户端的请求会一直挂起

Response对象 - response对象表示HTTP响应,即在接收到请求时向客户端发送的HTTP响应数据
response对象属性：
app
headersSent
locals
cookie()
clearCookie()
status()
sendStatus()
end()
set()
get()
append()
type()
vary()
links()
location()
redirect()
render()
send()
json()
jsonp()
format()
sendFile()
download()
attachment()

【 res.app 】
只是用于保存哪个express应用实例在使用中间件,res.app和req.app是应答中是一样的
This property holds a reference to the instance of the express application that is using the middleware.
res.app is identical to the req.app property in the request object.

【 res.headersSent: 】
boolean值,res对象发送后会变为true,如res.send();之后
Boolean property that indicates if the app sent HTTP headers for the response

</pre><pre class="js">
app.get('/', function (req, res) {
  console.log(res.headersSent); // false
  res.send('OK');
  console.log(res.headersSent); // true
})

</pre><pre>
【 res.locals 】
一个JavaScript对象,它可以用于获取并保存req中的信息,并且生命周期在整个应答周期中

An object that contains response local variables scoped to the request, and therefore(因此) available only to the view(s) rendered during that request / response cycle (if any). Otherwise, this property is identical to app.locals.

This property is useful for exposing(暴露) request-level information such as the request path name, authenticated user, user settings, and so on.

</pre><pre class="js">
app.use(function(req, res, next){
  res.locals.user = req.user;
  res.locals.authenticated = ! req.user.anonymous;
  next();
});

</pre><pre>
【 res.cookie(name,value[,options]) 】
设置cookie,value应该是字符串或者能转换为JSON的对象,options参数是一个对象并含有下列属性

domain   String     cookie的域名,默认为app的名称
expires  Date       cookie的有效期,没有指定或设为0,创建的有效期为此次会话
httpOnly Boolean    标志cookie只能被web服务器使用
maxAge   String     方便的通过毫秒设置cookie的有效期
path     String     cookie的path,默认是"/".
secure   Boolean    表示这个cookie只能用于HTTPS
signed   Boolean    指出该cookie是否被标记

All res.cookie() does is set the HTTP Set-Cookie header with the options provided. Any option not specified defaults to the value stated in RFC 6265.

When using cookie-parser middleware, this method also supports signed cookies. Simply include the signed option set to true. Then res.cookie() will use the secret passed to cookieParser(secret) to sign the value.
Later you may access this value through the req.signedCookie object
res.cookie('name', 'tobi', { signed: true });

</pre><pre class="js">
res.cookie('name', 'tobi', { domain: '.example.com', path: '/admin', secure: true });
res.cookie('rememberme', '1', { expires: new Date(Date.now() + 900000), httpOnly: true });
res.cookie('rememberme', '1', { maxAge: 900000, httpOnly: true })

</pre><pre>
You can pass an object as the value parameter; it is then serialized as JSON and parsed by bodyParser() middleware.

</pre><pre class="js">
res.cookie('cart', { items: [1,2,3] });
res.cookie('cart', { items: [1,2,3] }, { maxAge: 900000 });

</pre><pre>
【 res.clearCookie(name[,options]) 】
Clears the cookie specified by name

res.cookie('name', 'tobi', { path: '/admin' });
res.clearCookie('name', { path: '/admin' });

</pre><pre>
【 res.status(code) 】    设置HTTP状态码
Use this method to set the HTTP status for the response. It is a chainable alias of Node's response.statusCode

res.status(403).end();
res.status(400).send('Bad Request');
res.status(404).sendFile('/absolute/path/to/404.png');

【 res.sendStatus(statusCode) 】
设置响应状态代码,并将其以字符串形式作为响应体的一部分发送
Set the response HTTP status code to statusCode and send its string representation(表示) as the response body
If an unsupported status code is specified, the HTTP status is still set to statusCode and the string version of the code is sent as the response body

</pre><pre class="js">
res.sendStatus(200); // equivalent to res.status(200).send('OK')
res.sendStatus(403); // equivalent to res.status(403).send('Forbidden')
res.sendStatus(404); // equivalent to res.status(404).send('Not Found')
res.sendStatus(500); // equivalent to res.status(500).send('Internal Server Error')
res.sendStatus(2000); // equivalent to res.status(2000).send('2000')

</pre><pre>
【 res.end([data] [, encoding]) 】  终结响应处理流程
Ends the response process. This method actually comes from Node core, specifically the response.end() method of http.ServerResponse.

Use to quickly end the response without any data. If you need to respond with data, instead use methods such as res.send() and res.json().

res.end();
res.status(404).end();

【 res.set(field [, value]) 】
设置响应头,如果之前有设置则会被覆盖,传入一个参数为对象/两个参数为相对应的头部和值
Aliased as res.header(field [, value])

Sets the response's HTTP header field to value. To set multiple fields at once, pass an object as the parameter

</pre><pre class="js">
res.set('Content-Type', 'text/plain');

res.set({
  'Content-Type': 'text/plain',
  'Content-Length': '123',
  'ETag': '12345'
})

</pre><pre>
【 res.get(field) 】  返回指定的http头
Returns the HTTP response header specified by field. The match is case-insensitive.
res.get('Content-Type');  // => "text/plain"

【 res.append(field[,value]) 】
对HTTP应答头部追加特别的值,值能为字符串或数组,在之后使用res.set()会重置之前所有的值

Appends the specified value to the HTTP response header field. If the header is not already set, it creates the header with the specified value. The value parameter can be a string or an array.

Note: calling res.set() after res.append() will reset the previously-set(之前) header value.

</pre><pre class="js">
res.append('Link', ['<http://localhost/>', '<http://localhost:3000/>']);
res.append('Set-Cookie', 'foo=bar; Path=/; HttpOnly');
res.append('Warning', '199 Miscellaneous warning');

</pre><pre>
【 res.type(type) 】
Sets the Content-Type HTTP header to the MIME type as determined(确定) by mime.lookup() for the specified type. If type contains the "/" character, then it sets the Content-Type to type.

res.type('.html');              // => 'text/html'
res.type('html');               // => 'text/html'
res.type('json');               // => 'application/json'
res.type('application/json');   // => 'application/json'
res.type('png');                // => image/png:

【 res.vary(field) 】
在没有Vary应答头部时增加Vary应答头部
Adds the field to the Vary response header, if it is not there already.

res.vary('User-Agent').render('docs');

【 res.links(links) 】  设置Link应答头部
Joins the links provided as properties of the parameter to populate the response's Link HTTP header field

res.links({
  next: 'http://api.example.com/users?page=2',
  last: 'http://api.example.com/users?page=5'
});

// Link:< http://api.example.com/users?page=2>; rel="next", < http://api.example.com/users?page=5>; rel="last"

【 res.location(path) 】
只设置HTTP响应的location头部,不设置状态码或者close response
返回状态码302时自动跳转到location的链接上,设置为"back"则跳转到前一个页面
Sets the response Location HTTP header to the specified path parameter
A path value of "back" has a special meaning, it refers to the URL specified in the Referer header of the request. If the Referer header was not specified, it refers to "/"

res.location('/foo/bar');
res.location('http://example.com');
res.location('back');

Express passes the specified URL string as-is(原样) to the browser in the Location header, without any validation or manipulation, except in case of back (除了在back的情况下)

Browsers take the responsibility(责任) of deriving(推导) the intended(目标) URL from the current URL or the referring URL, and the URL specified in the Location header; and redirect the user accordingly(相应)

</pre><pre>
【 res.redirect([status,] path) 】
Redirects to the URL dervied(源自) from the specified path, with specified HTTP status code status. If you don't specify status, the status code defaults to "302 "Found"

重定向请求,允许网址的重定向,设置响应的Location HTTP头,status默认302
似res.location()+res.status(302).end(),path支持back字符串来回退到referer,".."来回退上一个目录

res.redirect('/foo/bar');                 // Redirects can be relative to the root of the host name

// from http://example.com/blog/ to http://example.com/blog/post/new
// from http://example.com/blog to http://example.com/post/new
res.redirect('post/new');                 // Redirects can be relative to the current URL

res.redirect('http://example.com');       // redirecting to a different site
res.redirect(301, 'http://example.com');

res.redirect('..');                      // Path-relative redirects
res.redirect('../login');

// A back redirection redirects the request back to the referer, defaulting to / when the referer is missing
res.redirect('back');

</pre><pre>
【 res.render(view [, locals] [, callback]) 】
渲染视图模板,渲染是指将数据代入模板的过程
render方法的参数就是模板的文件名,默认放在子目录views之中,app.set('view engine', 'ejs');指定后缀名为ejs
第二个参数,表示模板变量绑定的数据

Renders a view and sends the rendered HTML string to the client. Optional parameters:
locals: an object whose properties define local variables for the view.
callback: a callback function. If provided, the method returns both the possible error and rendered string, but does not perform an automated response. When an error occurs, the method invokes next(err) internally(在内部)
The local variable cache enables view caching. Set it to true, to cache the view during development; view caching is enabled in production by default.

</pre><pre class="js">
res.render('index');

// 使用render方法,将message变量传入index模板,渲染成HTML网页
app.get("/", function(req, res) {
  res.render("index", { message: "Hello World" });
});

// if a callback is specified, the rendered HTML string has to be sent explicitly(显式)
res.render('index', function(err, html) {
  // 可以在callback函数中进行渲染后模板的拼接或修改
  res.send(html);
});

// pass a local variable to the view and render
res.render('user', {name: 'Tobi'}, function(err, html) {
  res.send(html);
});

</pre><pre>
【 res.send([body]) 】
Sends the HTTP response
body参数有以下几个选项,如果之前没有定义Content-Type,根据参数不同有不同的Content-Type
对象       -> JSON
数组       -> JSON
字符串     -> 响应头Content-type字段是"text/html"
Buffer对象 -> 响应头Content-type字段是"application/octet-stream",除非明确的指定
数字       -> 根据数字对应状态码的不同返回字符,200->OK,404->Not Found

该方法主要特点在于在non-streaming应答时能自动的完成对header的添加.如HTTP缓存和Content-Length

</pre><pre class="js">
res.send(new Buffer('whoop'));
res.send({ user: 'tobi' });
res.send([1,2,3]);
res.send('<p>some html</p>');
res.status(404).send('Sorry, we cannot find that!');
res.status(500).send({ error: 'something blew up' });

res.set('Content-Type', 'text/html');
res.send(new Buffer('<p>some html</p>'));

</pre><pre>
【 res.json([body]) 】
Sends a JSON response.
This method is identical(同) to res.send() with an object or array as the parameter.
However, you can use it to convert other values to JSON, such as null and undefined. (although these are technically not valid JSON)

res.json(null)
res.json({ user: 'tobi' })
res.status(500).json({ error: 'message' })

【 res.jsonp([body]) 】
发送一个支持JSONP的JSON格式的响应
Sends a JSON response with JSONP support. This method is identical to res.json(), except that it opts-in to JSONP callback support

res.jsonp(null)
res.jsonp({ user: 'tobi' })
res.status(500).jsonp({ error: 'message' })

By default, the JSONP callback name is simply callback. Override this with the jsonp callback name setting.
The following are some examples of JSONP responses using the same code:

// ?callback=foo
res.jsonp({ user: 'tobi' })

app.set('jsonp callback name', 'cb');

// ?cb=foo
res.status(500).jsonp({ error: 'message' })

【 res.format(object) 】
调用req.accepts()来获取请求的类型,并根据请求类型执行不同的函数,在无匹配的情况下默认执行default函数

</pre><pre class="js">
res.format({
  'text/plain': function(){
    res.send('hey');
  },
  'text/html': function(){
    res.send('<p>hey</p>');
  },
  'application/json': function(){
    res.send({ message: 'hey' });
  },
  'default': function() {
    res.status(406).send('Not Acceptable');
  }
});

res.format({
  text: function(){
    res.send('hey');
  },
  html: function(){
    res.send('<p>hey</p>');
  },
  json: function(){
    res.send({ message: 'hey' });
  }
});

</pre><pre>
【 res.sendFile(path [, options] [, fn]) 】
以八位字节流的形式发送指定路径的文件,作为响应显示在页面,而不是下载
响应头Content-Type字段是依据文件后缀extension,除非root在options中已被设置了,不然path是文件的绝对路径
在传输完成或者错误发生后,将会调用fn(err)

options：
maxAge
Sets the max-age property of the Cache-Control header in milliseconds or a string in ms format,默认0

root
Root directory for relative filenames

lastModified
Sets the Last-Modified header to the last modified date of the file on the OS. Set false to disable it,默认Enabled

headers
Object containing HTTP headers to serve with the file

dotfiles
Option for serving dotfiles. Possible values are "allow", "deny", "ignore",默认"ignore"

The method invokes(调用) the callback function fn(err) when the transfer is complete or when an error occurs. If the callback function is specified and an error occurs, the callback function must explicitly handle the response process either by ending the request-response cycle, or by passing control to the next route

</pre><pre class="js">
app.get('/file/:name', function (req, res, next) {
  var options = {
    root: __dirname + '/public/',
    dotfiles: 'deny',
    headers: {
      'x-timestamp': Date.now(),
      'x-sent': true
    }
  };

  var fileName = req.params.name;
  res.sendFile(fileName, options, err => {
    if (err) {
      console.log(err);
      res.status(err.status).end();
    }else {
      console.log('Sent:', fileName);
    }
  });
})

</pre>res.sendFile provides fine-grained(细粒度) support for file serving as illustrated(说明) in the following example<pre class="js">
app.get('/user/:uid/photos/:file', function(req, res){
  var uid = req.params.uid;
  var file = req.params.file;
  req.user.mayViewFilesFrom(uid, function(yes){
    if(yes) res.sendFile('/uploads/' + uid + '/' + file);
    else  res.status(403).send('Sorry! you cant see that.');
  });
});

</pre><pre>
【 res.download(path [, filename] [, fn]) 】
Transfers the file at path as an "attachment". Typically(通常), browsers will prompt the user for download. By default, the Content-Disposition header "filename=" parameter is path (this typically appears in the brower dialog). Override(覆盖) this default with the filename parameter.

When an error ocurrs or transfer is complete, the method calls the optional callback function fn. This method uses res.sendFile() to transfer the file

页面不会跳转,不须调用结束响应的代码
</pre><pre class="js">
res.download('./new.png');
// Content-Disposition:attachment; filename="new.png"
// Content-Length:3250
// Content-Type:image/png

res.download('./new.png', '1.png');
// Content-Disposition:attachment; filename="1.png"
// Content-Length:3250
// Content-Type:image/png

res.download('./new.png', '1.png', function(err){
  if (err) {
    // Handle error, but keep in mind the response may be partially-sent,so check res.headersSent
  } else {
    // decrement a download credit(减少下载积分或统计下载数), etc.
  }
});
// Content-Disposition:attachment; filename="1.png"
// Content-Length:3250
// Content-Type:image/png

</pre><pre>
【 res.attachment([filename]) 】
Sets the HTTP response Content-Disposition header field to "attachment".
If a filename is given, then it sets the Content-Type based on the extension name via res.type(), and sets the Content-Disposition "filename=" parameter.

必须调用结束响应的代码res.send()/res.end()
</pre><pre class="js">
res.attachment();
// Content-Disposition: attachment
// Content-Length:3
// Content-Type:text/html; charset=utf-8
// 提示下载响应的html页面,下载.html

res.attachment('/new.png');
// Content-Disposition: attachment; filename="new.png"
// Content-Length:3
// Content-Type: image/png; charset=utf-8
// 提示下载new.png,但是文件显示错误

</pre><pre>
Content-disposition 是 MIME 协议的扩展,MIME 协议指示 MIME 用户代理如何显示附加的文件。当 Internet Explorer 接收到头时,它会激活文件下载对话框,它的文件名框自动填充了头中指定的文件名。(请注意,这是设计导致的;无法使用此功能将文档保存到用户的计算机上,而不向用户询问保存位置。)
服务端向客户端游览器发送文件时,如果是浏览器支持的文件类型,一般会默认使用浏览器打开,比如txt、jpg等,会直接在浏览器中显示,如果需要提示用户保存,就要利用Content-Disposition进行一下处理,关键在于一定要加上attachment：
res.setHeader('Content-Disposition', 'attachment;filename=filename.ext')
这样浏览器会提示保存还是打开,即使选择打开,也会使用相关联的程序比如记事本打开,而不是IE直接打开了
Content-Disposition就是当用户想把请求所得的内容存为一个文件的时候提供一个默认的文件名

当然filename参数可以包含路径信息,但User-Agnet会忽略掉这些信息,只会把路径信息的最后一部分做为文件名。当你在响应类型为application/octet- stream情况下使用了这个头信息的话,那就意味着你不想直接显示内容,而是弹出一个"文件下载"的对话框,接下来就是由你来决定"打开"还是"保存" 了

当代码里面使用Content-Disposition来确保浏览器弹出下载对话框的时候。 response.addHeader("Content-Disposition","attachment");一定要确保没有做过关于禁止浏览器缓存的操作。如下：

response.setHeader("Pragma", "No-cache");
response.setHeader("Cache-Control", "No-cache");
response.setDateHeader("Expires", 0);

不然会发现下载功能在opera和firefox里面好好的没问题,在IE下面就是不行,就是找不到文件

</pre><pre class="js">
res.attachment();
// Content-Disposition: attachment

res.attachment('path/to/logo.png');
// Content-Disposition: attachment; filename="logo.png"
// Content-Type: image/png

</pre>
</div>

<div id="cookie_session">
<h3>Cookie session 管理</h3><pre>
HTTP协议和TCP/IP协议组中其它协议相同,用于客户端和服务器端之间的通信,HTTP是一种无状态协议,及协议本身不保存客户端和服务端的通信状态,也就是说在HTTP这个级别,协议不会对请求或响应做持久化处理,这是为了更快的处理大量事务,确保协议的可伸缩性

为了解决HTTP的无状态,引入了Cookie技术,Cookie技术通过在请求和响应报文中写入cookie信息来控制客户端的状态
为了跟踪客户端的状态,服务器端借助于客户端的cookie和后端存储实现的会话状态。所以说,Session机制决定了当前客户只会获取到自己的Session,而不会获取到别人的Session

web应用是基于HTTP协议的,而HTTP协议是一种无状态协议;cookie和session用于关联同一用户的连续的请求,保持状态,保持会话
cookie将状态数据保存在客户端,session则保存在服务端

【 cookie 】 离线数据
首先声明,cookie是浏览器提供的一种机制,是客户端用来存储数据的一种选项,既可在客户端设置也可以在服务器端设置

Cookie面向的主要是服务器,localstorage面向的是页面端js。页面所需的业务数据可以放在localstorage里,但是认证相关的信息还是需要放在Cookie里的

cookie是一小段文本信息,伴随着用户请求在web服务器和浏览器之间传递,每当同一台计算机通过浏览器请求某个页面时,cookie会跟随任意HTTP请求一起发送
cookie是存于用户计算机硬盘的一个文件,该文件通常对应于一个域名,即cookie可以跨越一个域名下的多个网页,但不能跨越多个域名使用

C:\Users\你的用户名\AppData\Local\Microsoft\Windows\Temporary Internet Files 属于系统隐藏文件
C:\Users\lenovo\AppData\Local\Microsoft\Windows\INetCache internet选项设置->网站数据设置

在HTTP协议中,制定了Cookie机制,用于实现客户端和服务器之间的状态共享。
Cookie是解决HTTP无状态性的有效手段,服务器可以设置(set-cookie)或读取cookie中所包含的信息

【 实现原理 】
Cookie定义了HTTP请求头和HTTP响应头,客户端和服务器端通过这些头信息进行状态交互。

cookie是存在用户硬盘中,用户每次访问站点时,Web应用程序都可以读取Cookie包含的信息。当用户再次访问这个站点时,浏览器就会在本地硬盘上查找与该URL相关联的Cookie。如果该Cookie存在,浏览器就将它添加到request header的Cookie字段中,与http请求一起发送到该站点。

客户端第一次请求：服务器端如果需要记录用户信息,才会在响应信息中返回Set-cookie响应头
客户端会根据响应头中set-cookie设置并存储Cookie信息
客户端再次请求：会在请求头上带上存储的cookie信息,服务端通过解析cookie信息识别用户

【 cookie用途 】
cookie 将信息存储于用户硬盘,因此可以作为全局变量,这是它最大的一个优点。最根本的用途是Cookie能够帮助Web 站点保存有关访问者的信息

列举cookie的几种小用途
1)保存用户登录信息
当您访问一个需要登录的界面,例如微博、百度及一些论坛,在登录过后一般都会有类似"下次自动登录"的选项,勾选过后下次就不需要重复验证。这种就可以通过cookie保存用户的id

2)创建购物车
购物网站通常把已选物品保存在cookie中,这样可以实现不同页面之间数据的同步(同一个域名下是可以共享cookie的),同时在提交订单的时候又会把这些cookie传到后台。

3)跟踪用户行为
例如百度联盟会通过cookie记录用户的偏好信息,然后向用户推荐个性化推广信息,所以浏览其他网页的时候经常会发现旁边的小广告都是自己最近百度搜过的东西。这是可以禁用的,这也是cookie的缺点之一。

【 cookie类别 】
cookie总是存储在客户端(通常指浏览器),根据其存储位置可以分为：内存式cookie、硬盘式cookie

内存式：存储在内存中,浏览器关闭后清除,也非持久存储(会话cookie)
cookie不包含到期日期,则可视为会话cookie。会话 cookie存储在内存中,决不会写入磁盘。当浏览器关闭时,cookie 将从此永久丢失

硬盘式：保存在硬盘中,浏览器关闭后不会清除,除非手动清除或到了过期时间,也叫持久存储(持久cookie)
cookie包含到期日期,则可视为持久性cookie。在指定的到期日期,cookie将从磁盘中删除
注：通常我们可以通过 expires 到期时间来做区分

【 客户端设置 】
cookie将document对象的cookie属性提供给JavaScript,可以使用JavaScript来创建和取回cookie的值,因此可以通过document.cookie访问cookie

客户端设置cookie的格式和Set-Cookie头中使用的格式一样。如下：
document.cookie = "name=value[; expires=GMTDate][; domain=domain][; path=path][; secure]"
若想要添加多个cookie只能重复执行document.cookie。这可能和平时写的js不太一样,一般重复赋值是会覆盖的,
但对于cookie重复执行document.cookie并「不覆盖」,而是「添加」(针对「不同名」的)

document.cookie = "test1=myCookie1;"
document.cookie = "test2=myCookie2; domain=.google.com.hk; path=/webhp"
document.cookie = "test3=myCookie3; domain=.google.com.hk; expires=Sat, 04 Nov 2017 16:00:00 GMT; secure"
document.cookie = "test4=myCookie4; domain=.google.com.hk; max-age=10800;"

【 服务器端设置 】
服务器通过发送一个名为Set-Cookie的HTTP头来创建一个cookie,作为Response Headers的一部分
每个Set-Cookie表示一个cookie,如果有多个cookie,需写多个Set-Cookie
每个属性也是以名/值对的形式(除了secure)属性间以分号加空格隔开

cookie的格式和常见的属性　
字符串规律：
(1)每个cookie都以名/值对的形式,即name=value
(2)名称和值都必须是URL编码的
(3)且两对cookie间以 分号 和 空格 隔开

只有cookie的名字和值是必需的,name、value是cookie的名和值
Set-Cookie: name=value[; expires=GMTDate][; domain=domain] [; path=path][; secure][; HttpOnly]

</pre><pre class="js">
res.writeHead(200, {
  'Set-Cookie': 'myCookie=test',
  'Content-Type': 'text/html'
});

</pre><pre>
同时设置两个Set-Cookie头信息无效,只有最后一条有效
res.setHeader('Set-Cookie', 'age=18');
res.setHeader('Set-Cookie', 'sex=man');

cookie后面的age=18无效
res.setHeader('Set-Cookie', 'sex=man; age=18');

domain设置localhost,访问127.0.0.1的cookie无效,只能localhost访问
res.setHeader('Set-Cookie', 'sex=man; max-age=10800; domain=localhost; path=/ ');
res.setHeader('Set-Cookie', 'sex=man; max-age=10800; domain=127.0.0.1; path=/ ');

一个set-cookie头只能设置一个cookie,要设多个cookie需要设置多set-cookie头
在response响应中设置两次相同的header属性,比如设置两个cookie(Set-Cookie),但writeHead或setHead出现两个相同的属性时会被覆盖并合并成一个。
可以通过一个数组来实现

</pre><pre class="js">
res.writeHead(200, [
  ['Set-Cookie', 'mycookie1=value1'],
  ['Set-Cookie', 'mycookie2=value2']
]);
res.writeHead(200, {
  'Set-Cookie': ["aaa=bbb","ccc=ddd","eee=fff"]
});
res.setHeader('Set-Cookie', ['mycookie1=value1', 'mycookie2=value2']);

</pre><pre>
HttpOnly属性
httponly属性是用来限制客户端脚本对cookie的访问
默认情况是不指定httponly,即可以通过js去访问
由于cookie中可能存放身份验证信息,放在cookie中容易泄露
将cookie设置成httponly,那么通过程序(JS脚本、Applet等)将无法读取到Cookie信息,这样能有效的防止XSS攻击(跨站脚本攻击Cross Site Scripting)攻击的危害,防止cookie被窃取,以增强cookie的安全性

</pre><pre class="js">
res.writeHead(200, {
  'Set-Cookie': 'SSID=Ap4GTEq; Expires=Wed, 13-Jan-2021 22:23:01 GMT;HttpOnly ',
  'Content-Type': 'text/html'
})
res.end('console\n< script >console.log(document.Cookie)</ script >');

</pre><pre>
Secure属性：仅在HTTPS安全通行时才会发送cookie
默认为空,不指定secure选项,即不论是http请求还是https请求,均会发送cookie
当设置为true时,表示创建的Cookie会以安全形式向服务器传输,即只能在HTTPS连接中被浏览器传递到服务器端进行会话验证,如果是HTTP连接则不会传递该信息,所以不会被窃取到Cookie的具体内容,在客户端无法在document.Cookie找到被设置了Secure=true的Cookie键值对。
Secure属性是防止信息在传递的过程中被监听捕获后信息泄漏,HttpOnly属性的目的是防止程序获取Cookie后进行攻击,可以把Secure=true看成比HttpOnly更严格的访问控制
是cookie的安全标志,是cookie中唯一的一个非键值对的部分。指定后cookie只有在使用SSL连接(如HTTPS请求或其他安全协议请求的)时才会发送到服务器

domain和path这两个选项共同决定了cookie能被哪些页面共享。
Cookie只区分域名,是不管端口的,同一域名下不同端口的应用共享cookie

domain属性： domain=域名,默认创建cookie的服务器域名
用来控制cookie对哪个域有效,默认为设置cookie的那个域。这个值可以包含子域,也可以不包含它
指定可访问Cookie的主机名.主机名是指同一个域下的不同主机,例如：www.google.com和gmail.google.com就是两个不同的主机名。默认情况下,一个主机中创建的Cookie在另一个主机下是不能被访问的, 但可以通过domain参数来实现对其的控制,其语法格式为："name=value; domain=CookieDomain";
以google为例,要实现跨主机访问,可以写为： "name=value;domain=.google.com";这样所有google.com下的主机都可以访问该Cookie

path属性：默认文档所在的文件目录
在域名的基础下,指定可以访问cookie的路径,默认为"/",表示指定域下的所有路径都能访问
如cookie设置为"domain=.google.com.hk; path=/webhp",那么只有".google.com.hk/webhp"及"/webhp"下的任一子目录如"/webhp/aaa"或"/webhp/bbb"会发送cookie信息,而".google.com.hk"就不会发送,即使它们来自同一个域。
如："userId=320; path=/shop";就表示当前Cookie仅能在shop目录下使用

expries/max-age 失效时间,用来决定cookie的生命周期的,也就是cookie何时会被删除
Expires属性：表示的是失效过期时间,准确讲是时刻;默认浏览器关闭前为止,即session
格式为"name=value;expires=GMT_String"; 其中GMT_String是以GMT格式表示的时间字符串,超过这个时间,Cookie将消失,不可访问

</pre><pre class="js">
//将userId和userName两个Cookie设置为10天后过期
var date = new Date();
var expireDays = 10;
date.setTime(date.getTime() + expireDays*24*3600*1000);
res.writeHead(200, {
  'Set-Cookie': "userId=828; userName=hulk; expire=" + date.toGMTString(),
  'Content-Type': 'text/html'
});

new Date(new Date().getTime() + 10*24*60*60*10000).toGMTString()

</pre><pre>
Max-Age属性：表示的是生效的时间段
用于代替Expires,Max-Age的值可以为正数表示此Cookie从创建到过期所能存在的时间,以秒为单位,此Cookie会存储到客户端电脑,以Cookie文件形式保存,不论关闭浏览器或关闭电脑,直到时间到才会过期
如设置"max-age=10800;",也就是生效时间是3个小时,那么cookie将在三小时后失效
可以为负数表示此Cookie只是存储在浏览器内存里,只要关闭浏览器,此Cookie就会消失,在浏览器会话结束后失效
maxAge默认值为-1,还可以为0表示从客户端电脑或浏览器内存中删除此Cookie

</pre><pre class="js">
const http = require('http');
http.createServer((req, res) => {
  var cookies = {};
  console.log(typeof req.headers.cookie, req.headers.cookie);

  req.headers.cookie && req.headers.cookie.split(';').forEach(cookie =>{
    var parts = cookie.split('=');
    cookies[parts[0].trim()] = parts[1].trim();
  })
  console.log(cookies);

  /* 设置单条cookie */
  res.writeHead(200, {
    'Set-Cookie': 'myCookie=test',
    'Content-Type': 'text/html'
  });

  /* headers数组形式设置多条cookie */
  res.writeHead(200, [
    ['Set-Cookie', 'mycookie1=value1'],
    ['Set-Cookie', 'mycookie2=value2']
  ]);

  var date = new Date();
  var expireDays = 10;
  date.setTime(date.getTime() + expireDays*24*3600*1000);
  res.writeHead(200, [
    ['Content-Type', 'text/html'],
    ['Set-Cookie', 'localhost=localhost'],
    ['Set-Cookie', 'SSID=Ap4GTEq; Expires=Wed, 13-Jan-2021 22:23:01 GMT;HttpOnly '],
    ['Set-Cookie', 'sessionid=sessionid; max-age=10800 '],
      ['Set-Cookie', "userId=828; userName=hulk; expires=" + date.toGMTString()],
      ['Set-Cookie', "Id=1; name=bbb; expires=" + new Date(new Date().getTime() + 10*24*60*60*10000).toGMTString()],
      ['Set-Cookie', ["aaa=bbb","ccc=ddd","eee=fff"]]
  ]);

  /*
  Set-Cookie:userId=828; userName=hulk; expires=Mon, 25 Dec 2017 14:52:45 GMT
  Set-Cookie:Id=1; name=bbb; expires=Sun, 25 Mar 2018 14:52:45 GMT
  Set-Cookie:aaa=bbb
  Set-Cookie:SSID=Ap4GTEq; Expires=Wed, 13-Jan-2021 22:23:01 GMT;HttpOnly
  Set-Cookie:eee=fff
  Set-Cookie:localhost=localhost
  Set-Cookie:sessionid=sessionid; max-age=10800
  Set-Cookie:ccc=ddd

  Name      Value     Domain    Path Expires/Max-Age              Size    Http
  Id        1         localhost  /   018-03-25T14:52:45.874Z      3
  SSID      Ap4GTEq   localhost  /   2021-01-13T22:23:01.874Z     11       ✓
  aaa       bbb       localhost  /   Session                      6
  ccc       ddd       localhost  /   Session                      6
  eee       fff       localhost  /   Session                      6
  localhost localhost localhost  /   Session                      18
  sessionid sessionid localhost  /   2017-12-15T17:52:45.874Z     18
  userId    828       localhost  /   2017-12-25T14:52:45.874Z     9
  */

  /* Set-Cookie以数组形式设置多条cookie */
  res.writeHead(200, {
    'Content-Type': 'text/html',
    'Set-Cookie':
    [
      'SSID=Ap4GTEq; Expires=Wed, 13-Jan-2018 22:03:01 GMT; HttpOnly ',
      'uid=1; max-age=10800; domain=localhost; path=/p1 ',
        "uname=heiying6958; path=/p1/p2; expires=" + new Date(new Date().getTime() + 10*24*60*60*1000).toGMTString(),
        "uage=29; expires=" + new Date(new Date().getTime() + 10*24*60*60*1000).toGMTString(),
        ["aaa=bbb","ccc=ddd","eee=fff"]
    ]
  });

  /* 设置多条cookie的首选方法 */
  if(!cookies.uid){
    res.setHeader('Set-Cookie', [
      'SSID=Ap4GTEq; Expires=Wed, 13-Jan-2018 22:03:01 GMT; HttpOnly ',
      'uid=1; max-age=10800; domain=localhost; path=/p1 ',
        "uname=heiying6958; path=/p1/p2; expires=" + new Date(new Date().getTime() + 10*24*60*60*1000).toGMTString(),
        "uage=29; expires=" + new Date(new Date().getTime() + 10*24*60*60*1000).toGMTString(),
        ["aaa=bbb","ccc=ddd","eee=fff"]
    ]);
  }
  res.writeHead(200, {'Content-Type': 'text/html'})

  /*
  Set-Cookie:SSID=Ap4GTEq; Expires=Wed, 13-Jan-2018 22:03:01 GMT; HttpOnly
  Set-Cookie:uid=1; max-age=10800; domain=localhost; path=/p1
  Set-Cookie:uname=heiying6958; path=/p1/p2; expires=Mon, 25 Dec 2017 15:04:44 GMT
  Set-Cookie:uage=29; expires=Mon, 25 Dec 2017 15:04:44 GMT
  Set-Cookie:aaa=bbb,ccc=ddd,eee=fff

  Name    Value               Domain    Path    Expires/Max-Age          Size    Http
  SSID    Ap4GTEq             localhost /p1     2018-01-13T22:03:01.799Z  11     ✓
  SSID    Ap4GTEq             localhost /       2018-01-13T22:03:01.926Z  11     ✓
  aaa     bbb,ccc=ddd,eee=fff localhost /p1     Session                   22
  aaa     bbb,ccc=ddd,eee=fff localhost /       Session                   22
  uage    29                  localhost /       2017-12-25T15:04:44.927Z  6
  uage    29                  localhost /p1     2017-12-25T15:04:44.799Z  6
  uid     1                   localhost /p1     2017-12-15T18:04:44.927Z  4
  uname heiying6958           localhost /p1/p2  2017-12-25T15:04:44.927Z  16
  */

  res.end('console\n< script>console.log(document.cookie)</ script>');
}).listen(8888, 'localhost', () => console.log('Server started on port 8888'))

</pre><pre>
【 cookie的缺点 】
安全性：由于cookie在http中是明文传递的,其中包含的数据都可以被他人访问,可能会被篡改、盗用
大小限制：cookie的大小限制在4kb左右,不适合大量存储,浏览器之间各有不同
增加流量：cookie每次请求都会被自动添加到Request Header中,无形中增加了流量。cookie信息越大,对服务器请求的时间越长。每次往服务器提交请求时,都会带上cookie,无论是你访问的是不是静态图片

对于cookie的使用,最重要的就是要控制cookie的大小,不要放入无用的信息,也不要放入过多信息

【 cookie限制 】
一、每个客户端最多保持三百个cookie,浏览器允许每个域名所包含的Cookie数：
Microsoft 指出Internet Explorer 8增加Cookie限制为每个域名50个,但IE7似乎也允许每个域名50个Cookie
Firefox   每个域名 Cookie 限制为 50 个
Opera     每个域名 Cookie 限制为 30 个
Safari/WebKit 貌似没Cookie限制,但如果Cookie很多则会使header大小超过服务器的处理的限制,会导致错误发生。

二、当很多的Cookie被设置浏览器如何去响应,除Safari(可以设置全部Cookie,不管数量多少),有两个方法：
最少最近使用least recently used (LRU)的方法
当Cookie已达到限额自动踢除最老的Cookie,以使给最新的Cookie一些空间,IE和Opera使用此方法
Firefox：虽然最后的设置的Cookie始终保留,但似乎随机决定哪些Cookie被保留

三、不同浏览器间Cookie总大小也不同
Firefox和Safari允许Cookie多达4097个字节, 包括名(name)、值(value)和等号。
Opera允许Cookie多达4096个字节, 包括：名(name)、值(value)和等号。
Internet Explorer允许Cookie多达4095个字节, 包括：名(name)、值(value)和等号。
注：多字节字符计算为两个字节。在所有浏览器中,任何Cookie大小超过限制都被忽略,且永远不会被设置

【 cookie加密 】
可以研究一下csdn的自动登陆,像FireSheep这样的工具用来嗅探和劫持cookie是轻而易举的

用Cookie或者Session来保存登录信息
Cookie的使用是涉及到用户的权限、帐户等敏感信息的,所以一旦决定使用Cookie来存放用户的登陆或配置信息,一定要注意对COOKIE的加密等操作

记住密码和下次自动登录这样的功能必须要用到cookie来保存用户状态

cookie一般情况下用于记录用户登录状态的,比如userid,千万不要记录密码,由于cookie是存储在客户端的,所以cookie很容易被人劫持修改。比如登录成功后在客户端写入cookie('userid') = 1,在服务器读取cookie userid的值,如果userid在数据库用户表中可以找到则证明当前用户userid为1且合法登录,显然这样是不可行的。如果用户自行修改userid为2或者其它用户的userid,那么服务器就认为当前合法登录的用户userid为2,这样用户就不需要知道userid为2的密码就合法登录了,修改cookie可以通过直接修改浏览器cookie文件或者通过javascript修改cookie值达到欺骗服务器的目的,所以需要对存储在客户端的cookie要进行加密

不但要对值进行加密,对字段名也要同样进行加密

DES加密算法

使用一次MD5加密很容易使用在线暴力破解工具解密,特别是简单的纯数字
对userid进行两次MD5加密或者加一个复杂的key,因为越复杂MD5暴力破解就越慢
使用已知加密算法(如MD5)还是有漏洞的,最好的是自己编写一套加密算法,这样用户就无法伪造其它用户

用户登录之后,通过加密的cookie来存储一些敏感的信息。cookie有个过期的问题。可以通过把cookie加密后存储在服务器端,然后使用'set-cookie'头,这样就可以了,这样甚至可以做到无限期的保存
一个例子就是在线支付,交易是存储在网络的,但是实际的银行账户信息是通过加密的cookie来访问的。将cookie存储在服务端,然后在本地解密,银行信息就可以在程序的上下文中进行,但是也保证了用户的隐私

可以通过抓包获取其它用户的cookie的,毕竟cookie是在网络中传输的;可以用https协议代替普通http协议,这样恶意用户抓到的报文已经是密文了,也就不知道cooki

</pre><pre class="js">
var crypto = require('crypto');

function encrypt(str,secret) {
  var cipher = crypto.createCipher('aes192', secret);
  var enc = cipher.update(str,'utf8','hex');
  enc += cipher.final('hex');
  return enc;
}
function decrypt(str,secret) {
  var decipher = crypto.createDecipher('aes192', secret);
  var dec = decipher.update(str,'hex','utf8');
  dec += decipher.final('utf8');
  return dec;
}

</pre><pre>
【 签名Cookie 】
set-cookie时加上防篡改验证码,但还是可能被劫持,最安全的做法是cookie不存放敏感数据
发送 HTTP 请求,除了浏览器,还有各种代理。
即使设置了httpOnly,这一限制只对浏览器有效,我们同样可以把cookie拿过来更改,利用其他工具发送请求。
设置signed cookie后,signed cookie的生成和校验都是在服务器端处理,对客户端不可见,因此也就达到防止篡改cookie的目的

如：user_name=alex|bj95ef23cc6daecc475de
防篡改验证码的生成规则可以很简单：md5(cookieValue+key)或sha1(cookieValue+key),key可以是服务器端掌握的一个固定字符串,也可以很复杂
服务器端得到客户端送上来的cookie后,重新计算一下验证码,如一致则未篡改

加密实例：
在保存用户信息阶段,主要的工作是对用户的信息进行加密并保存到客户端。加密用户的信息较为繁琐的,大致上可分为以下几个步聚：
① 得到用户名、经MD5加密后的用户密码、cookie有效时间
② 自定义的一个webKey,这个Key是为网站定义的一个字符串常量
③ 将上两步得到的四个值得新连接成一个新的字符串,再进行MD5加密,这样就得到了一个MD5明文字符串
④ 将用户名、cookie有效时间、MD5明文字符串使用"："间隔连接起来,再对这个连接后的新字符串进行Base64编码
⑤ 设置一个cookieName,将cookieName和上一步产生的Base64编码写入到客户端。

其实弄明白了保存原理,读取及校验原理就很容易做了。读取和检验可以分为下面几个步骤：
① 根据设置的cookieName,得到cookieValue,如果值为空,就不帮用户进行自动登陆;否则执行读取方法
② 将cookieValue进行Base64解码,将取得的字符串以split(":")进行拆分,得到一个String数组cookieValues,得到三个值：
cookieValues[0] ---- 用户名
cookieValues[1] ---- cookie有效时间
cookieValues[2] ---- MD5明文字符串
③ 判断cookieValues的长度是否为3,如果不为3则进行错误处理。
④ 如果长度等于3,取出第二个,即cookieValues[1],此时将会得到有效时间,将有效时间与服务器系统当前时间比较,如果小于当前时间,则说明cookie过期,进行错误处理
⑤ 如果cookie没有过期,就取cookieValues[0],这样就可以得到用户名了,然后去数据库按用户名查找用户。
⑥ 如果上一步返回为空,进行错误处理。如果不为空,那么将会得到一个已经封装好用户信息的User实例对象user
⑦ 取出实例对象user的用户名、密码、cookie有效时间(即cookieValues[1])、webKey,然后将四个值连接起来,然后进行MD5加密,这样做也会得到一个MD5明文字符串(此操作与保存阶段的第3步类似)
⑧ 将上一步得到MD5明文与cookieValues[2]进行equals比较,如果是false,进行错误处理;如果是true,则将user对象添加到session中,帮助用户完成自动登陆

【 cookie-parser 】
cookie-parser是node中用于操作cookie的中间件,使用cookie-signature来解密
cookieParser(secret, options)

var cookieParse = require('cookie-parse');
app.use(cookieParse())    // 挂载中间件,实例化

// 创建
res.cookie(name, value, [,options])
{
  maxAge: 90000,  // 有效时长(毫秒)
  signed: false   // 默认false,是否签名
}

name: cookie名
value：cookie值(字符串或json对象)
options: Set-Cookie选项
domain：cookie在声明域名下有效,String,默认网站域名
expires：cookie过期时间,Date,如果没设置或设为0则关闭浏览器后删除
httpOnly: 只能被web server访问,Boolean
maxAge:   实现expires功能,设置过期时间,指明从现在开始多少毫秒之后cookie到期,String
path: cookie在什么路径下有效,String,默认'/'
secure: 只能被HTTPS使用,Boolean,默认false
signed: 使用签名,Boolean,默认false(express会使用req.secret来完成签名,需要cookie-parse配合使用)

// 获取cookie
var cookies = req.cookies;
var value = req.cookies.key;       // 获取名称为key的cookie的值

// 删除cookie
res.clearCookie(name [, options])  // name是cookie名,options与创建cookie是所传一致

// 签名提高安全性,使用签名生成cookie
app.use(cookieParse('yog'));       // 传一个自定义字符串作为secret
res.cookie(name, value, {signed: true})
var cookies = req.signedCookies;   // 获取cookie集合
var value = req.signedCookies.key; // 获取名称为key的cookie的值

使用中间件向Node.js服务器发送cookie信息,以下代码输出了客户端发送的cookie信息

</pre><pre class="js">
// express_cookie.js
var express      = require('express')
var cookieParser = require('cookie-parser')

var app = express()
app.use(cookieParser())

app.get('/', function(req, res) {
  console.log("Cookies: ", req.cookies)
})

app.listen(8888)

</pre><pre class="js">
var cookie = require('cookie');
var escapeHtml = require('escape-html');

function onRequest(req, res) {
  var query = require('url').parse(req.url, true, true).query;
  if (query && query.name) {
    res.setHeader('Set-Cookie', cookie.serialize('name', String(query.name), {
      httpOnly: true,
      maxAge: 60 * 60 * 24 * 7
    }));

    // Redirect back after setting cookie
    res.statusCode = 302;
    res.setHeader('Location', req.headers.referer || '/');
    res.end();
    return;
  }

  // Parse the cookies on the request
  var cookies = cookie.parse(req.headers.cookie || '');

  // Get the visitor name set in the cookie
  var name = cookies.name;

  res.setHeader('Content-Type', 'text/html; charset=UTF-8');

  if (name) res.write('<p>Welcome back, <b>' + escapeHtml(name) + '</b>!</p>');
  else res.write('<p>Hello, new visitor!</p>');

  res.write('<form method="GET"><input placeholder="enter name" name="name"/><input type="submit" value="Set Name"/></form>');
  res.end();
}

require('http').createServer(onRequest).listen(3000);

</pre>

<h3>express-session会话模块</h3><pre>
无论使用何种服务端技术,只要发送回的HTTP响应中包含如Set-cookie:name=value;expires=date;path='/linkage'的头信息,则视为服务器要求浏览器设置一个cookie;
支持cookie的浏览器都会创建cookie文件或内存cookie并保存,用户以后在每次发出请求时,浏览器都要判断当前所有的cookie中有没有没失效(根据expires属性判断)并且匹配了path属性的cookie信息,如果有则会以(Cookie: name="zj"; Path="/linkage")形式加入到请求头中发回服务端;服务端的动态脚本会对其进行分析,并做出相应的处理或者选择直接忽略

【 cookie VS session 】
session和cookie的作用是一样的,都是存储用户信息
session的认证机制必须依赖cookie,Session需要借助Cookie实现,Session数据存储在服务端,类似于服务器缓存,session数据不会保存在cookie本身,而只在Cookie中存储一个SessionId,可以保证安全性和降低服务器负载

Cookie的典型应用场景是Remember Me服务,即用户的账户信息通过cookie的形式保存在客户端,当用户再次请求匹配的URL的时候,账户信息会被传送到服务端,交由相应的程序完成自动登录等功能。也可以保存一些客户端信息如页面布局以及搜索历史等等
Session的典型应用场景一般用于用户的身份验证;用户登录某网站之后,将其登录信息放入session,在以后的每次请求中查询相应的登录信息即利用sessionID判断用户是否合法,当然还是有购物车等等经典场景

安全性
cookie将信息保存在客户端,如果不进行加密的话会暴露一些隐私信息,安全性很差,一般情况下敏感信息是经过加密后存储在cookie中,但还是容易被窃取。而session只会将信息存储在服务端,如果存储在文件或数据库中,也有被窃取的可能,只是可能性比cookie小了太多
Session安全性方面比较突出的是存在会话劫持的问题,总体来讲,session的安全性要高于cookie
中间代理人攻击即是通过代理服务器(如无线路由)盗取会话Cookie(SessionID等),从而访冒身份
因此Google建议网站全部采用HTTPS协议,加密传输内容,并提高了纯HTTPS网站的权重

性能
Cookie存储在客户端,消耗的是客户端的I/O和内存,而session存储在服务端,消耗的是服务端的资源。但是session对服务器造成的压力比较集中,而cookie很好地分散了资源消耗,就这点来说,cookie是要优于session的;

时效性
Cookie可以通过设置有效期使其较长时间内存在于客户端,而session一般只有比较短的有效期(用户主动销毁session或关闭浏览器后引发超时)

其他
Cookie的处理在开发中没有session方便。而且cookie在客户端是有数量和大小的限制的,而session的大小却只以硬件为限制,能存储的数据无疑大了太多。

session的基本原理是服务端为每一个session维护一份会话信息数据,而客户端和服务端依靠一个全局唯一的标识来访问会话信息数据。用户访问web应用时,服务端程序决定何时创建session,创建session可以概括为三个步骤：
1.当客户端访问web服务器时会生成一个全局唯一标识(sessionid);
2.开辟数据存储空间。一般会在内存中创建相应的数据结构,但这种情况下,系统一旦掉电,所有的会话数据就会丢失,如果是电子商务网站,这种事故会造成严重的后果。也可以写到文件里(php session文件时二进制的)甚至存储在数据库中,虽会增加I/O开销,但session可以实现某种程度的持久化,而且更有利于session的共享;
3.将session的全局唯一标示符发送给客户端。
服务端发送这个session的唯一标识的数据给浏览器,可以放到请求行、头域或Body里,一般来说会有两种常用的方式：cookie和URL重写

Cookie:服务端只要设置Set-cookie头就可以将session的标识符传送到客户端,而客户端此后的每一次请求都会带上这个标识符,由于cookie可以设置失效时间,所以一般包含session信息的cookie会设置失效时间为0,即浏览器进程有效时间

URL重写:在返回用户请求的页面之前,将页面内所有的URL后面全部以get参数的方式加上session标识符(或者加在path info部分等等),这样用户在收到响应之后,无论点击哪个链接或提交表单,都会在再带上session的标识符,从而就实现了会话的保持。如果客户端禁用了cookie的话,URL重写将会是首选

服务器会返回一个set-cookie的消息,通知浏览器要设置cookie了,于是浏览器会根据set-cookie里的字段来设置信息

express-session中间件将会话数据存储在服务器上,它仅将会话标识(而非会话数据)保存在cookie中。从1.5.0版本开始,express-session不再依赖cookie-parser,直接通过req/res读取/写入;默认存储位置内存存储(服务器端)

一旦将express-session中间件用use挂载后,可以很方便的通过req参数来存储和访问session对象的数据
req.session是一个JSON格式的JavaScript对象,可以在使用的过程中随意的增加成员,这些成员会自动的被保存到option参数指定的地方,默认内存中去

session中间件会在req上添加session对象,即req.session初始值为{},登录后服务端设置req.session.user=用户信息,记录用户的信息然后存储到该session中,返回浏览器的头信息中会带上set-cookie将session id写到浏览器cookie中
用户下次请求时请求头中就会带上cookie,cookie的值是就是session id,服务端就可以查找到该用户,并将用户信息保存到req.session.user

【 做一个完整的登陆 】
1 客户端
一般来说应该使用https,而且密码绝不能在网络中明文传输,因此在往服务器传输时就应该先加密,常见的md5,但md5被破解,因此可以用SHA512或SHA256来加密

2 服务端
服务端需要对密码再进行加密,因为所有客户端的东西都是不安全的,以防网络被监听,因此会进行SHA512(username+SHA512(password)+sault)的加密,sault为随机数,防止被脱库了后被猜出密码,所以需要附加一个随机数,这个sault最好是存放到另外的数据库中,防止因为存到一个库中被脱库中猜出

通过引入express-session中间件实现对会话的支持：
app.use(session([options]))
options常见的有：cookie,name,resave,saveUninitialized,secret,store等具体可查看express-session。cookie是一个对象,里面的属性可以有maxAge、domain、expires、httpOnly、path等

options可选参数:
1. name
cookie的名字,默认'connect.sid'

2. store
session存储实例

3. secret
用来对session数据进行签名加密的字符串,防止篡改这个属性值为必须指定的属性

4. cookie
session cookie设置,默认：{ path: '/', httpOnly: true,secure: false, maxAge: null })

5. genid
生成新session ID的函数,默认使用uid2库

6. rolling
在每次请求时强行设置cookie,将重置cookie过期时间,默认false

7. resave
默认true,每次请求都重新设置session cookie,假设cookie是6000毫秒过期,每次请求都会再设置6000毫秒

8. proxy
当设置了secure cookies(通过"x-forwarded-proto" header)时信任反向代理。当设定为true时"x-forwarded-proto" header 将被使用。当设定为false时所有headers将被忽略;当该属性没有被设定时将使用Express的trust proxy

9. saveUninitialized: false
强制将未初始化的session存储,当新建一个session且未设定属性或值时就处于
未初始化状态。默认true
无论有没有session cookie,每次请求都设置个session cookie,默认标示为connect.sid

Forces(强制) a session that is "uninitialized" to be saved to the store.
A session is uninitialized when it is new but not modified(修改).
Choosing false is useful for implementing(实现) login sessions, reducing server storage usage, or complying(服从) with laws that require permission(许可) before setting a cookie.
Choosing false will also help with race conditions where a client makes multiple parallel(并行) requests without a session.

The default value is true, but using the default has been deprecated(弃用), as the default will change in the future. Please research into this setting and choose what is appropriate to your use-case.

10. unset
控制req.session是否取消,例如通过delete或者将它的值设置为null。这可以使session保持存储
状态但忽略修改或删除的请求;默认keep

</pre><pre class="js">
var session = require(express-session);

// 创建session同时会创建cookie来保存sessionId,所以options中的cookie.maxAge可看作是session的有效时长
var options = {
  secret: 'yog',                   // 签名,session存储的密码,与cookie设置的签名字符串一致
  name: 'name',
  cookie: {maxAge: 60000},
  resave: false,
  saveUninitialized: false,
}
app.use(session(options));

req.session.key = value;            // 创建session
req.session = {                     // 创建多个session
  key1: value1,
  key2: value2
}

var session = req.session;          // 获取session集合
var value = req.session.key;        // 获取名为key的session值

req.session.lastpage = lastPage;    // 写入至session
res.redirect(req.session.lastpage); // 从session中读取

req.session.key = null;
delete req.session;
req.session.destroy(callback)       // 清空所有session
req.session.key.destroy()           // 销毁名为key的session的值

Session.destroy(callback)           // 删除session,当检测到客户端关闭时调用
Session.reload(callback)            // 当session有修改时,刷新session
Session.regenerate(callback)        // 将已有session初始化
Session.save(callback)              // 保存session

</pre><pre class="js">
app.use(session({
  secret:'my app secret',         // 用来对session id相关的cookie进行签名
  name:'test',                    // cookie的name,默认值是：connect.sid
  saveUninitialized:false,        // 是否自动保存未初始化的会话,建议false
  resave:false,                   // 是否每次都重新保存会话,建议false
  store: new MongoStore({         // 创建新的mongodb数据库存储session
    host: 'localhost',            // 数据库的地址,本机的话就是127.0.0.1,也可以是网络主机
    port: 27017,                  // 数据库的端口号
    db: 'test-app'                // 数据库的名称。
  }),
  cookie:{maxAge:10*1000}
}));

</pre><pre class="js">
// session 内存存储

var express = require('express')
var url = require('url')
var session = require('express-session')
var app = express()
app.use(session({
  secret: 'keyboard cat',
  resave: false,
  saveUninitialized: true
}))

app.use(function (req, res, next) {
  var views = req.session.views
  if (!views) views = req.session.views = {}
  var pathname = url.parse(req.url).pathname
  views[pathname] = (views[pathname] || 0) + 1
  next()
})

app.get('/foo', function (req, res, next) {
  res.send('you viewed this page ' + req.session.views['/foo'] + ' times')
})

app.get('/bar', function (req, res, next) {
  res.send('you viewed this page ' + req.session.views['/bar'] + ' times')
})

</pre><pre class="js">
// session 内存存储

var express = require('express');
var session = require('express-session');
var cookieParser = require('cookie-parser');
var app = express();
app.use(cookieParser());
app.use(session({
  secret: '12345',
  name: 'testapp',           //这里的name值得是cookie的name,默认cookie的name是：connect.sid
  cookie: {maxAge: 80000 },  //设置maxAge是80000ms,即80s后session和相应的cookie失效过期
  resave: false,
  saveUninitialized: false,
}));

app.get('/awesome', function(req, res){
  if(req.session.lastPage) console.log('Last page was: ' + req.session.lastPage + ".");
  req.session.lastPage = '/awesome'; //每一次访问时session对象的lastPage会自动保存或更新内存中session
  res.send("You're Awesome. And the session expired time is: " + req.session.cookie.maxAge);
});

app.get('/radical', function(req, res){
  if (req.session.lastPage) console.log('Last page was: ' + req.session.lastPage + ".");
  req.session.lastPage = '/radical';
  res.send('What a radical visit! And the session expired time is: ' + req.session.cookie.maxAge);
});

app.get('/tubular', function(req, res){
  if (req.session.lastPage){console.log("Last page was: " + req.session.lastPage + ".");
  req.session.lastPage = '/tubular';
  res.send('Are you a suffer? And the session expired time is: ' + req.session.cookie.maxAge);
});

app.listen(8888);

</pre>

<h3>session持久化存储 mongodb和redis</h3><pre>
session存在的问题：Session默认保存在服务端内存中,在程序重启、多进程运行、负载均衡、跨域等情况时会出现Session丢失或多进程、多个负载站点间状态不能共享的情况

若需要session的生命周期长一点,如网站有个免密码两周内自动登录的功能;基于这个需求session必须寻找内存之外的存储载体,数据库能提供完美的解决方案
mongodb数据库作为一个NoSQL数据库,其基础数据对象是database-collection-document对象模型,针对node.js提供了丰富的驱动和API
express框架提供了针对mongodb的中间件：connect-mongo,只需在挂载session的时候在options中传入mongodb的参数即可,程序运行的时候express app会自动管理session的存储、更新和删除

客户端与服务会使用一个Sessionid的Cookie值来进行客户端和服务器端会话的匹配,这个Cookie一般是服务器端读/写的,并在Http请求响应的Header中的Set-Cookie属性设置：
HTTP/1.1 200 OK
Server: nginx
Date: Wed, 14 Jan 2015 02:29:09 GMT
Content-Type: text/html
Transfer-Encoding: chunked
Proxy-Connection: Keep-Alive
Connection: Keep-Alive
Content-Encoding: gzip
Set-Cookie: sessionid=i4w3axuzyj4nwwg75y6k5us2; path=/; domain=.ourjs.com; httponly

path=/             表示这个cookie是设置在根目录的
httponly           属性禁止客户端JavaScript的访问,防止当前会话(sessionid)被恶意的js脚本盗取
domain=.ourjs.com  表示将sessionid存放到主域名下,各个二级域名域名均使用此Cookie (sessionid)

当Express服务器突然重启后,用户仍然可以使用当前Cookie中的SessionID从数据库中获取到他的会话状态,做到会话不丢失,在一定程度上提高网站的键壮性

使用数据库来集中管理session,存放Session内容,并在各个子域名跨域共享Cookies(SessionID),即可实现为每一个子域分配一个独立的node.js Web服务器,各个服务程序均可依据sessionid从数据库中寻找到同一Session,从而实现不同Web Server中的会话同步,从而实现一定程度上的负载均衡。
要想实现完全意义的负载均衡还需要将Web服务做到完全状态无关,不仅仅是Session,所有的中间缓存数据都要转移到与服务器无关的缓存层中,这正是Redis最善长的地方,存放在Redis中要比MongoDB中好
如果NodeJS网站上的所有缓存数据都转移到了Redis后,就可做到完全状态无关,按需扩展网站的规模
可水平扩展的NodeJS网站服务器集群(非cluster模块不同,它们是相互独立的,可分布在不同的物理服务器上),这样的架构对于应对超大规模并发也是有好处的

MongoDB 是一个基于文档的数据库,所有数据是从磁盘上进行读写的。MongoDB善长的是对无模式JSON数据的查询。
Redis是一个基于内存的键值数据库,由C语言实现的,与Nginx/NodeJS工作原理近似,同样以单线程异步的方式工作,先读写内存再异步同步到磁盘,读写速度上比MongoDB有巨大的提升。
因此目前很多超高并发的网站/应用都使用Redis做缓存层,普遍认为其性能明显好于MemoryCache。当并发达到一定程度时,即可考虑使用Redis来缓存数据和持久化Session。

</pre><pre class="js">
var express = require('express');
var session = require('express-session')
var app = express();

// 设置 Cookie
app.use(express.cookieParser('keyboard cat'));

/* session持久化配置 */
// 设置 redis 存储 session
var RedisStore = require('connect-redis')(session);
app.use(session({
  store: new RedisStore({
    host: "192.168.108.46",
    port: 6379,
    db: "test_session"
  }),
  secret: 'keyboard cat'
}))

// 设置monogdb存储session
var MongoStore = require('connect-mongo')(session);
app.use(session({
  secret: "keyboard cat",
  cookie: {maxAge: 1000 * 60 * 60 * 24 * 30},
  resave: false,
  saveUninitialized: true,
  store: new MongoStore({
    db: "my_database",
    host: "localhost",
    port: 27017
  })
}));

app.get("/", function(req, res) {
  var session = req.session;
  session.count = session.count || 0;
  var n = session.count++;
  res.send('hello, session id:' + session.id + ' count:' + n);
});

app.listen(3002, () => console.log('Web server has started on http://127.0.0.1:3002/'));

</pre><pre>
【 将Session存放到MongoDB 】
使用connect-mongo即用来将Express中的Session持久化到Mongodb的一个中间件,也可以在connect上使用

</pre><pre class="js">
var express = require('express');
var session = require('express-session');
var cookieParser = require('cookie-parser');
var MongoStore = require('connect-mongo')(session);
var app = express();

app.use(cookieParser());
app.use(session({
  secret: '12345',
  name: 'testapp',
  cookie: {maxAge: 80000 },
  resave: false,
  saveUninitialized: true,
  store: new MongoStore({   //创建新的mongodb数据库
    host: 'localhost',      //数据库的地址,本机的话就是127.0.0.1,也可以是网络主机
    port: 27017,            //数据库的端口号
    db: 'test-app'          //数据库的名称。
  })
}));

app.get('/awesome', function(req, res){
  if(req.session.lastPage) console.log('Last page was: ' + req.session.lastPage + ".");
  req.session.lastPage = '/awesome';
  res.send("You're Awesome. And the session expired time is: " + req.session.cookie.maxAge);
});

app.get('/radical', function(req, res){
  if(req.session.lastPage) console.log('Last page was: ' + req.session.lastPage + ".");
  req.session.lastPage = '/radical';
  res.send('What a radical visit! And the session expired time is: ' + req.session.cookie.maxAge);
});

app.get('/tubular', function(req, res){
  if(req.session.lastPage) console.log("Last page was: " + req.session.lastPage + ".");
  req.session.lastPage = '/tubular';
  res.send('Are you a suffer? And the session expired time is: ' + req.session.cookie.maxAge);
});

app.listen(8888);

</pre><pre>
【 NodeJS中使用Redis缓存数据 】
Redis数据库采用极简的设计思想,最新版的源码包还不到2Mb,其在使用上也有别于一般的数据库

redis驱动程序多使用node_redis　
此模块可搭载官方的hiredis C语言库,同样是非阻塞的,比使用JS内置的解释器性能稍好
可选择将hiredis与redis一同安装,如果hiredis安装成功,node_redis会默认使用hiredis,否则使用JS的解释器

npm install hiredis redis

Redis的一个Key不仅可以对应一个String类型的值,还支持hashes, lists, sets, sorted sets, bitmaps等。

为一个Key一次设置多个哈希键/值, 多用于JSON对象的写入(序列化的SESSION)
HMSET key field value [field value ...]
读取一个Key的所有哈希键/值,多用于JSON对象读取
HGETALL key

</pre><pre class="js">
var redis = require("redis");
var client = redis.createClient();

//写入JSON对象
client.hmset('sessionid', { username: 'kris', password: 'password' }, function(err){
  if(err) console.log(err)
})

//读取JSON对象
client.hgetall('sessionid', function(err, object){
  console.log(object)
})

</pre><pre>
Redis没有严格意义上的表名和字段名,以Key-Value键值对的方式存储,因此一般采用schema:key形式做为键值
schema:  可理解为传统数据库中的表名
key: 　　可理解为表中的主键

因此使用redis存放session时,需要一个schema前辍,比如这个key：sessionid:i4w3axuzyj4nwwg75y6k5us2

Redis仅能对Key进行检索,尚不支持对Key所存放的Hash Key的检索,如要检索到所有session只需匹配sessionid:*即可

</pre><pre class="js">
client.keys('session:*', function (err, keys) {
  console.log(keys)
})

</pre>因此在采用Redis缓存与检索数据时要使用一些独特的数据类型如集合(Sets)<pre class="js">
> sadd myset 1 2 3    //添加1 2 3到集合myset
(integer) 3
> smembers myset      //列出集合的所有成员
1. 3
2. 1
3. 2
> sismember myset 30  //判断30是否是集合myset的成员
(integer) 0           //不存在

</pre><pre>
Redis集合不允许添加相同成员,多次添加同一元素到集合中最终只会包含一个元素。多个集合之间可以进行连接/交集这样的操作,从而实现类似传统数据库中索引、条件和连接查询的效果。

</pre><pre class="js">
# 添加 3 个用户和信息
hmset user:1 user_name lee age 21
hmset user:2 user_name david age 25
hmset user:3 user_name chris age 25

# 维护age索引
sadd age:21 1
sadd age:25 2 3

# 维护name索引
sadd name:lee 1
sadd name:david 2
sadd name:chris 3

# 查找  age = 25 和 name = lee 的用户
sinter age:25 name:lee
  -> 会返回一个空集合

</pre><pre>
【 将Session存放到Redis中 】
connect-redis是Redis版的session存储器,使用node_redis作为驱动,以此在Express中启用Redis来持久化Session
$ npm install connect-redis
Redis是一个高性能的key-value数据库,使用redis存储session的好处在于：
1.多进程间session可以共存
2.网站重启用session依旧还在

参数
client     可以复用现有的redis客户端对象, 由redis.createClient()创建
host       Redis服务器名
port       Redis服务器端口
socket     Redis服务器的unix_socket
ttl        Redis session TTL过期时间 (秒)
disableTTL 禁用设置的 TTL
db         使用第几个数据库
pass       Redis数据库的密码
prefix     数据表前辍即schema, 默认为"sess:"

</pre><pre class="js">
var session = require('express-session');
var redis = require('redis');
var RedisStore = require('connect-redis')(session);
var redisClient = redis.createClient(6379, '127.0.0.1', {auth_pass: 'password'}); // 创建redis客户端
app.use(session({                                                   // 设置express的session存储中间件
  store: new RedisStore({client: redisClient}),
  secret: 'keyboard cat',
  resave: false,
  saveUninitialized: false
}));

// 检验测试
app.use(function (req, res, next) {
  if (!req.session) return next(new Error('oh no'))   // handle error
  next()                                              // otherwise continue
})

</pre><pre>
【 反向代理 】
反向代理(Reverse Proxy)方式是指以代理服务器来接受Internet上的连接请求,然后将请求转发给内部网络上的服务器;并将从服务器上得到的结果返回给Internet上请求连接的客户端,此时代理服务器对外就表现为一个服务器。

反向代理服务器对于客户端而言它就像是原始服务器,并且客户端不需要进行任何特别的设置。客户端向反向代理 的命名空间(name-space)中的内容发送普通请求,接着反向代理将判断向何处(原始服务器)转交请求,并将获得的内容返回给客户端,就像这些内容原本就是它自己的一样

利用nginx的反向代理来解决cookie跨域问题,其实是通过"欺骗"浏览器来实现的,通过nginx可以将不同工程的cookie放到nginx域下,通过nginx反向代理就可以取到不同工程写入的cookie

</pre>
</div>

<!-- ------------------------------------------------------------------- -->
<div id="third-part">
<h2>express常用第三方中间件</h2><pre>
third-part middleware list:
config-lite
morgan
connect-flash
bodyparse
multer
Formidable
express-formidable

</pre>

<h3>debug | express自带模块 | 打印所有debug：set DEBUG=* </h3><pre>
npm install debug

一般在nodejs需要进行调试的时候,可以使用console.log()方法来将调试信息输出到控制台,当发布到生产环境的时候,需要将这些调试信息都注释掉,为了方便切换而不需要改动程序代码,可以使用nodejs的debug模块

debug模块功能：
定义log模块,选择特定模块log输出
模块文字颜色高亮
log时间记录
输出log到文件等功能

A tiny小 JavaScript debugging utility实用程序 modelled模仿 after Node.js core's debugging technique技术. Works in Node.js and web browsers

debug是根据环境变量来判断打印日志的内容
可以设置打印的信息来自哪个哪个模块
在发布到外网的情况下,可以用发布模式,这时debug里打印信息将不会在显示

morgan:打印的nodejs 服务器接受到的请求的信息
debug：打印的是开发者自己在控制台打印的信息,目的是要代替console.log()

</pre><pre class="js">
var debug = require('debug')('mydebug:main');
debug('现在的时间是 %s' , new Date());

set DEBUG=mydebug:* & node app.js mydebug:work
set DEBUG=mydebug:* & node app.js mydebug:work > debug.log  // 把日志输出到文件

var debug = require('debug')('mydebug');
debug('现在的时间是 %s' , new Date());
set DEBUG=mydebug & node app.js mydebug:work

var debug = require('debug')('app');
debug('hello');
// 运行 set DEBUG=app & node debug_module.js
// 输出：app hello +0ms

</pre><pre>
【 命名空间 】
当项目程序变得复杂,我们需要对日志进行分类打印,debug支持命令空间
DEBUG=app,api：表示同时打印出命名空间为app、api的调试日志。
DEBUG=a*：支持通配符,所有命名空间为a开头的调试日志都打印出来
DEBUG=-account*表示排除所有以account开头的命名空间的调试日志

</pre><pre class="js">
var debug = require('debug');
var appDebug = debug('app');
var apiDebug = debug('api');
appDebug('hello');
apiDebug('hello');
// set DEBUG=app & node debug_module.js
// set DEBUG=api & node debug_module.js
// set DEBUG=app,api & node debug_module.js
// set DEBUG=a* & node debug_module.js

// 输出
// app hello +0ms
// api hello +6ms

</pre><pre class="js">
var debug = require('debug');
var listDebug = debug('app:list');
var profileDebug = debug('app:profile');
var loginDebug = debug('account:login');
listDebug('hello');
profileDebug('hello');
loginDebug('hello');

// set DEBUG=* & node debug_module.js
// set DEBUG=*,-account* & node debug_module.js

// 输出
// app:list hello +0ms
// app:profile hello +11ms
// account:login hello +4ms

</pre>【 自定义格式化输出 】<pre class="js">
var createDebug = require('debug')
createDebug.formatters.h = function(v) {
  return v.toUpperCase();
};
var debug = createDebug('foo');
debug('My name is %h', 'chying');
// set DEBUG=foo & node debug_module.js
// 输出
// foo My name is CHYINGP +0ms

</pre>

<h3>config-lite 配置模块</h3><pre>
将配置与代码分离是一个非常好的做法,通常将配置写到一个项目的根目录下配置文件里,如config.js/config.json/config.conf/config.node/config.yaml
但实际开发时我们会有许多环境,如本地开发环境、测试环境和线上环境等,不同环境的配置不同(如MongoDB 的地址),不可能每次部署时都要去修改引用config.test.js或者config.production.js

config-lite 是一个轻量的读取配置文件的模块。config-lite 会根据环境变量(NODE_ENV)的不同加载 config目录下不同的配置文件。如果不设置NODE_ENV,则读取默认的default配置文件,如果设置了 NODE_ENV则会合并指定的配置文件和default配置文件作为配置,config-lite支持 .js、.json、.node、.yml、.yaml 后缀的文件。

如果程序以NODE_ENV=test node app启动,则config-lite会依次降级查找config/test.js、config/test.json、config/test.node、config/test.yml、config/test.yaml 并合并 default 配置
如果程序以NODE_ENV=production node app启动,则 config-lite 会依次降级查找 config/production.js、config/production.json、config/production.node、config/production.yml、config/production.yaml 并合并 default 配置。

config-lite 还支持冒泡查找配置,即从传入的路径开始,从该目录不断往上一级目录查找 config 目录,直到找到或者到达根目录为止。

const config = require('config-lite')(__dirname);

</pre>

<h3>Forever进程管理器</h3><pre>
服务器管理是系统上线后必须要面对的问题。最好有一个软件可以提供整套的服务器运行解决方案：要求运行稳定,支持高并发,启动/停止命令简单,支持热部署,宕机重启,监控界面和日志,集群环境

npm install forever --save -g   模块forever要求安装到全局环境下

Forever is a simple CLI tool for ensuring that a given script runs continuously (forever). Its simple interface makes it ideal(理想的) for running smaller deployments(部署) of Node apps and scripts

forever是一个简单的命令式nodejs的守护进程,能够启动,停止,重启App应用。forever完全基于命令行操作,在forever进程之下,创建node的子进程,通过monitor监控node子进程的运行情况,一旦文件更新,或者进程挂掉,forever会自动重启node服务器,确保应用正常运行

分别记录输出和错误日志,比如可以在js中作为api使用

throw new Error('App is error from inner!');代码可以模拟服务器内部错误退出,是node进程挂掉

【 Basic use 】
forever -h       查看帮助

</pre><pre class="js">
usage: forever [action] [options] SCRIPT [script-options]

Monitors the script specified in the current process or as a daemon

actions:
  start               Start SCRIPT as a daemon
  stop                Stop the daemon SCRIPT by Id|Uid|Pid|Index|Script
  stopall             Stop all running forever scripts
  restart             Restart the daemon SCRIPT
  restartall          Restart all running forever scripts
  list                List all running forever scripts
  config              Lists all forever user configuration
  set key val         Sets the specified forever config key
  clear key           Clears the specified forever config key
  logs                Lists log files for all forever processes
  logs script|index   Tails the logs for script|index
  columns add col     Adds the specified column(指标) to the output in `forever list`
  columns rm col      Removed the specified column from the output in `forever list`
  columns set cols    Set all columns for the output in `forever list`
  columns reset       Resets all columns to defaults for the output in `forever list`
  cleanlogs           [CAREFUL] Deletes all historical forever log files

options:
  -m  MAX          Only run the specified script MAX times
  -l  LOGFILE      Logs the forever output to LOGFILE
  -o  OUTFILE      Logs stdout from child script to OUTFILE
  -e  ERRFILE      Logs stderr from child script to ERRFILE
  -p  PATH         Base path for all forever related files (pid files, etc.)
  -c  COMMAND      COMMAND to execute (defaults to node)
  -a, --append     Append logs
  -f, --fifo       Stream logs to stdout
  -n, --number     Number of log lines to print
  --pidFile        The pid file
  --uid            Process uid, useful as a namespace for processes (must wrap in a string)
                   e.g. forever start --uid "production" app.js
                       forever stop production
  --sourceDir      The source directory for which SCRIPT is relative to
  --workingDir     The working directory in which SCRIPT will execute
  --minUptime      Minimum uptime (millis) for a script to not be considered "spinning"
  --spinSleepTime  Time to wait (millis) between launches of a spinning script.
  --colors         --no-colors will disable output coloring
  --plain          alias of --no-colors
  -d, --debug      Forces forever to log debug output
  -v, --verbose    Turns on the verbose messages from Forever
  -s, --silent     Run the child script silencing stdout and stderr
  -w, --watch      Watch for file changes
  --watchDirectory Top-level directory to watch from
  --watchIgnore    To ignore pattern when watch is enabled (multiple option is allowed)
  -t, --killTree   Kills the entire child process tree on `stop`
  --killSignal     Support exit signal customization (default is SIGKILL)
                   used for restarting script gracefully e.g. --killSignal=SIGTERM
  -h, --help       You're staring at it

[Long Running Process]
  The forever process will continue to run outputting log messages to the console.
  ex. forever -o out.log -e err.log my-script.js

[Daemon]
  The forever process will run as a daemon which will make the target process start
  in the background. This is extremely useful for remote starting simple node.js scripts
  without using nohup. It is recommended to run start with -o -l, & -e.
  ex. forever start -l forever.log -o out.log -e err.log my-daemon.js
      forever stop my-daemon.js

</pre><pre>
To start a script, use the forever start command and specify the path of the script:
This will run the script in daemon(守护进程) mode (in the background).
$ forever start script.js

To run the script attached to the terminal(终端), omit(省略) start:
$ forever script.js

It is a good idea to log output from forever and the script using the logging options -l, -o, -e, as shown this example:
$ forever start -l forever.log -o out.log -e err.log script.js

myblog 项目 forever命令配置
forever -p . -l ./foreverlogs/access.log -o ./foreverlogs/out.log -e ./foreverlogs/error.log -a -w --watchDirectory . start index.js

-l 指定forever信息输出文件,默认~/.forever/forever.log
-o 就是console.log输出的信息
-e 就是console.error输出的信息

追加日志,forever默认是不能覆盖上次的启动日志,所以如果第二次启动不加-a,则会不让运行
forever start -l forever.log -a app.js

监听当前文件夹下的所有文件改动,文件改动监听并自动重启
forever start -w --watchDirectory .app.js

重启守护进程
forever restart

重启所有守护进程
forever restartall

To view the list of scripts started by forever:
$ forever list

To stop a script started by forever use the forever stop command and specify the process index (as listed by the forever list command).
$ forever stop 1
Alternatively, specify the path of the file:
$ forever stop script.js

To stop all the scripts started by forever:
$ forever stopall

Forever has many more options, and it also provides a programmatic API

// 开发环境下建议配置  NODE_ENV=development
forever -p . -l ./logs/access.log -e ./logs/error.log -a -w start app.js
// 线上环境下建议配置  NODE_ENV=production
forever start -l ~/.forever/forever.log -e ~/.forever/err.log -w -a app.js
forever -p /home/conan/nodejs/nodejs-forever -l /var/log/nodejs/project/access.log -e /var/log/nodejs/project/error.log -o /var/log/nodejs/project/out.log -a --pidFile /var/log/nodejs/project/forever.pid start /home/conan/nodejs/nodejs-forever/app.js

/*脚本代码*/
export LOG=/home/jyootai/log/nodejs
export APP_PATH=/home/jyootai/www/cdquery
export APP=$APP_PATH/app.js
forever -p $APP_PATH -l $LOG/access.log -e $LOG/error.log -o $LOG/out.log  -aw --watchDirectory $APP_PATH start $APP

【 配置文件启动forever：JSON Configuration Files 】
In addition to(除了) passing forever the path to a script (along沿着 with accompanying陪同 options, described above), you may also pass forever the path to a JSON file containing these options. For example, consider考虑 an application with the following file structure:

├── forever
│   └── production.json
└── index.js

// forever/production.json
{
  // Comments are supported
    "uid": "app",
    "append": true,
    "watch": true,
    "script": "index.js",
    "sourceDir": "/home/myuser/app"
}

This application could be started with forever, as shown below:
forever start ./forever/production.json
Absolute paths to such configuration files are also supported:
forever start /home/myuser/app/forever/production.json

【 forever管理多项目配置文件 】
// web.json 日志文件以配置文件中的uid作为文件名

[
  {
    // HTTP Server
    "uid": "http",
    "append": true,
    "watch": true,
    "script": "http.js",
    "sourceDir": "/root/web/http"
  },
  {
    // Domain Name Sale
    "uid": "sale",
    "append": true,
    "watch": true,
    "script": "sale.js",
    "sourceDir": "/root/web/sale"
  }
]

// forever start web.json

【 常见错误 】
error: Forever detected(检测到) script exited with code: 1
error: Could not read .foreverignore file.
在项目文件下添加.foreverignore, 告诉forever忽略检测哪些文件的改动,类似git工具的.gitignore文件
添加-w选项时必须也要添加--watchDirectory选项,必须要告知检测变动文件的目录
error: restarting script because change changed

【 forever-monitor 】
The core monitoring(监控) functionality of forever without the CLI
he forever module is the Command Line Interface and the package forever-monitor is the core monitoring functionality without the CLI so you can use it programatically(编程)

You should use the forever module when you want to use the CLI(starting something manually(手动) for example).
You should use the forever-monitor when you are writing a program that should control the application you are starting. For example an app where you start other apps in via an interface or if you want to spawn something that should be restarted on failure in your app.

If you are using forever _programmatically_ you should install [forever-monitor][0].
cd /path/to/your/project && npm install forever-monitor

</pre><pre class="js">
var forever = require('forever-monitor');
var child = new (forever.Monitor)('your-filename.js', {
  max: 3,
  silent: true,
  args: []
});

child.on('exit', function () {
  console.log('your-filename.js has exited after 3 restarts');
});

child.start();

</pre>

<h3>supervisor</h3><pre>
npm i -g supervisor

运行 supervisor index 启动程序, 或者 supervisor --harmony index

supervisor 会监听当前目录下 node 和 js 后缀的文件,当这些文件发生改动时,supervisor 会自动重启程序

supervisor -h

Options available after start:
rs - restart process.
Useful for restarting supervisor eaven if no file has changed

</pre>

<h3>morgan 日志模块</h3><pre>
npm install morgan --save

morgan是express默认的日志中间件,也可以脱离express,作为node.js的日志组件单独使用

morgan(format, options);
format表示日志的格式,morgan预定义了一些日志格式,用常量字符串表示,如'combined', 'common', 'short', 'dev'等
options表示可选选项,比如将日志输出到终端或者文件,缺省时默认输出到终端{stream: process.stdout}

日志同时输出到终端和文件
同时加载输出到终端和文件的morgan对象,如：
app.use(morgan('combined'));
app.use(morgan('common', {stream: accessLogStream}));

日志输出到终端

</pre><pre class="js">
var express = require('express');
var morgan = require('morgan');
var app = express();
app.use(morgan('short'));
app.get('/to-stdout', function(req, res, next) {
    res.send('done.');
});
app.listen(3000);

</pre>日志输出到文件,文件输出流<pre class="js">
var express = require('express');
var morgan = require('morgan');
var fs = require('fs');
var path = require('path');
var app = express();
var accessLogStream = fs.createWriteStream(path.join(__dirname, 'access.log'));
app.use(morgan('common', {stream: accessLogStream}));
app.get('/to-file', function(req, res) {
  res.send('done!');
});
app.listen(3000);

</pre>日志输出到文件并按天轮转,需要用到file-stream-rotator模块来创建一个轮转的文件流<pre class="js">
var express = require('express');
var morgan = require('morgan');
var fs = require('fs');
var path =  require('path');
var fileStreamRotator = require('file-stream-rotator');
var app = express();
var logDir = path.join(__dirname, 'logs');
fs.existsSync(logDir) || fs.mkdirSync(logDir);       // ensure log directory exists
var accessLogStream = fileStreamRotator.getStream({  // create a rotating write stream
  date_format: 'YYYYMMDD',
  filename: path.join(logDir, 'access-%DATE%.log'),
  frequency: 'daily',
  verbose: true
});
app.use(morgan('common', {stream: accessLogStream}));
app.get('/to-rotate-file', function(req, res) {
  res.send('done!');
});
app.listen(3000);

</pre><pre>
自定义日志格式
使用uuid标识每一个请求,日志如下：
a08516c4-201a-4d8a-9f22-d1b6de5e225f GET /customized-format 3.118 ms

</pre><pre class="js">
var express = require('express');
var morgan = require('morgan');
var uuid = require('node-uuid');
morgan.token('id', function(req) {
  return req.id;
});
function assignId(req, res, next) {
  req.id = uuid.v4();
  next();
};
var app = express();
app.use(assignId);
app.use(morgan(':id :method :url :response-time ms'));
app.get('/customized-format', function(req, res) {
  res.send('done!');
});
app.listen(3000);

</pre><h3>winston 日志模块</h3><pre>
npm i -s winston
npm i -s express-winston

A multi-transport async logging library for node.js
Each instance of a winston logger can have multiple transports configured at different levels.
For example,one may want error logs to be stored in a persistent remote location (like a database), but all logs output to the console or a local file

There also seemed to be a lot of logging libraries out there that coupled their implementation of logging (i.e. how the logs are stored / indexed) to the API that they exposed to the programmer. This library aims to目标是 decouple解耦 those parts of the process to make it more flexible and extensible

There are two different ways to use winston: directly via the default logger, or by instantiating your own Logger

</pre><pre class="js">
var winston=require('winston');
var logger = new (winston.Logger)({
  transports: [
    new (winston.transports.Console)(),
    new (winston.transports.File)({
      filename: './apkAnalysis.log',
      timestamp:'true',
      maxsize: 10485760, //日志文件的大小
      maxFiles: 10
    })
  ]
});

logger.log('info', 'Test LogMessage', { anything: 'This is metadata' });

</pre><pre class="js">
// 为了方便在项目目录下面新建一个config文件夹,然后在config文件夹里新建了一个文件logger.js
var winston=require('winston');
var logger = new (winston.Logger)({
  transports: [
    new (winston.transports.Console)(),
    new (winston.transports.File)({
      filename: './apkAnalysis.log',
      timestamp:'true',
      maxsize: 10485760,
      maxFiles: 10
    })
  ]
});
exports.logger=logger;

// 之后在其他js文件调用它就很方便了,例如在app.js中调用
var logs=require('./config/logger.js');
logs.logger.log('info',"Express server listeningon port  3000" );

</pre><h3>express-winston winston middleware for express.js</h3><pre>
express-winston provides middlewares for request and error logging of your express.js application. It uses 'whitelists' to select properties from the request and response objects

【 Request Logging 】
</pre><pre class="js">
var winston = require('winston');
var expressWinston = require('express-winston');
var router = require('./my-express-router');

app.use(expressWinston.logger({
  transports: [
    new winston.transports.Console({ json: true, colorize: true })
  ],
  meta: true,
  msg: "HTTP {{req.method}} {{req.url}}",
  expressFormat: true,
  colorize: true,
  ignoreRoute: function (req, res) { return false; }
}));

app.use(router); // notice how the router goes after the logger

</pre><pre>
Options
transports: [WinstonTransport]
list of all winston transports instances to use

winstonInstance: WinstonLogger
a winston logger instance. If this is provided the transports option is ignored.

level: String or function(req, res) { return String; }
log level to use, the default is "info". Assign a  function to dynamically set the level based on request and response, or a string to statically set it always at that level. statusLevels must be false for this setting to be used

msg: String
customize the default logging message. E.g. "{{res.statusCode}} {{req.method}} {{res.responseTime}}ms {{req.url}}", "HTTP {{req.method}} {{req.url}}".

expressFormat: Boolean
Use the default Express/morgan request formatting. Enabling this will override any msg if true. Will only output colors when colorize set to true

colorize: Boolean
Color the text and status code, using the Express/morgan color palette颜料 (text: gray, status: default green, 3XX cyan, 4XX yellow, 5XX red)

meta: Boolean
control whether you want to log the meta data about the request (default to true).

baseMeta: Object
default meta data to be added to log, this will be merged with the meta data.

metaField: String
if defined, the meta data will be added in this field instead of the meta root object.

statusLevels: Boolean or Object
different HTTP status codes caused log messages to be logged at different levels (info/warn/error), the default is false. Use an object to control the levels various status codes are logged at. Using an object for statusLevels overrides any setting of options.level

ignoreRoute: function (req, res) { return false; }
A function to determine if logging is skipped, defaults to returning false. Called _before_ any later middleware

skip: function(req, res) { return false; }
A function to determine if logging is skipped, defaults to returning false. Called _after_ response has already been sent

requestFilter: function (req, propName) { return req[propName]; }
A function to filter/return request values, defaults to returning all values allowed by whitelist. If the function returns undefined, the key/value will not be included in the meta.

responseFilter: function (res, propName) { return res[propName]; }
A function to filter/return response values, defaults to returning all values allowed by whitelist. If the function returns undefined, the key/value will not be included in the meta

requestWhitelist: [String]
Array of request properties to log. Overrides global requestWhitelist for this instance

responseWhitelist: [String]
Array of response properties to log. Overrides global responseWhitelist for this instance

bodyWhitelist: [String]
Array of body properties to log. Overrides global bodyWhitelist for this instance

bodyBlacklist: [String]
Array of body properties to omit from logs. Overrides global bodyBlacklist for this instance

ignoredRoutes: [String]
Array of paths to ignore/skip logging. Overrides global ignoredRoutes for this instance

dynamicMeta: function(req, res) { return [Object]; }
Extract additional meta data from request or response (typically req.user data if using passport). meta must be true for this function to be activated

</pre>【 Error Logging 】<pre class="js">
var router = require('./my-express-router');
app.use(router); // notice how the router goes first.
app.use(expressWinston.errorLogger({
  transports: [
    new winston.transports.Console({
      json: true,
      colorize: true
    })
  ]
}));

</pre><pre>
The logger needs to be added AFTER the express router(app.router)) and BEFORE any of your custom error handlers(express.handler). Since express-winston will just log the errors and not handle them, you can still use your custom error handler like express.handler, just be sure to put the logger before any of your handlers

Options

transports: [WinstonTransport]
list of all winston transports instances to use.

winstonInstance: WinstonLogger
a winston logger instance. If this is provided the transports option is ignored

msg: String
customize the default logging message. E.g. "{{err.message}} {{res.statusCode}} {{req.method}}".

baseMeta: Object
default meta data to be added to log, this will be merged with the error data.

metaField: String
if defined, the meta data will be added in this field instead of the meta root object.

requestFilter: function (req, propName) { return req[propName]; }
A function to filter/return request values, defaults to returning all values allowed by whitelist. If the function returns undefined, the key/value will not be included in the meta.

requestWhitelist: [String]
Array of request properties to log. Overrides global requestWhitelist for this instance

level: String or function(req, res, err) { return String; }
custom log level for errors (default is 'error'). Assign a function to dynamically set the log level based on request, response, and the exact error.

dynamicMeta: function(req, res, err) { return [Object]; }
Extract additional meta data from request or response (typically req.user data if using passport). meta must be true for this function to be activated

</pre><pre class="js">
var express = require('express');
var expressWinston = require('express-winston');
var winston = require('winston'); // for transports.Console
var app = module.exports = express();

app.use(express.bodyParser());
app.use(express.methodOverride());

// Let's make our express `Router` first.
var router = express.Router();
router.get('/error', function(req, res, next) {
  // here we cause an error in the pipeline so we see express-winston in action.
  return next(new Error("This is an error and it should be logged to the console"));
});

app.get('/', function(req, res, next) {
  res.write('This is a normal request, it should be logged to the console too');
  res.end();
});

// express-winston logger makes sense BEFORE the router.
app.use(expressWinston.logger({
  transports: [
    new winston.transports.Console({
      json: true,
      colorize: true
    })
  ]
}));

// Now we can tell the app to use our routing code:
app.use(router);

// express-winston errorLogger makes sense AFTER the router.
app.use(expressWinston.errorLogger({
  transports: [
    new winston.transports.Console({
      json: true,
      colorize: true
    })
  ]
}));

// Optionally you can include your custom error handler after the logging.
app.use(express.errorLogger({
  dumpExceptions: true,
  showStack: true
}));

app.listen(3000, function(){
  console.log("express-winston demo listening on port %d in %s mode", this.address().port, app.settings.env);
});

</pre>

<h3>connect-flash 页面跳转通知模块</h3><pre>
connect-flash是基于session实现的
原理很简单：
设置初始值req.session.flash={}
通过req.flash(name, value)设置这个对象下的字段和值,设置req.session.flash字段值
通过req.flash(name)获取这个对象下的值,同时删除这个字段,实现了只显示一次刷新后消失的功能

The flash is a special area of the session used for storing messages. Messages are written to the flash and cleared after being displayed to the user. The flash is typically used in combination with redirects, ensuring that the message is available to the next page that is to be rendered

Flash messages are stored in the session. First, setup sessions as usual by enabling cookieParser and session middleware. Then, use flash middleware provided by connect-flash.

</pre><pre class="js">
var flash = require('connect-flash');
var app = express();

app.configure(function() {
  app.use(express.cookieParser('keyboard cat'));
  app.use(express.session({ cookie: { maxAge: 60000 }}));
  app.use(flash());
});

</pre>With the flash middleware in place, all requests will have a req.flash() function that can be used for flash messages><pre class="js">
/* connect-flash.ejs code */

<p>
  <a href="/flash">Flash</a> |
  <a href="/no-flash">No Flash</a> |
  <a href="/multiple-flash">multiple-flash</a>
</p>
<% if (message) { %>
  <% if(Array.isArray(message)){ %>
    <% message.forEach( msg => { %>
      <p><%= msg %></p>
    <% }) %>
  <% }else{ %>
    <p><%= message %></p>
  <% } %>
<% } %>


/* connect-flash.js code */
var express = require('express');
var session = require('express-session');
var flash = require('connect-flash');
var app = express();
app.set('views', __dirname + '/views');
app.set('view engine', 'ejs');
app.use(session({
  name: 'sid',
  secret: 'sid',
  saveUninitialized: false,
  resave: true,
  cookie: { maxAge: 60000 }
}))
app.use(flash());
app.use(/\/[\w|-]+/ ,(req, res, next) => {
  req.session.user = req.originalUrl;
  next();
})

app.get('/', function(req, res){
  console.log(req.session);
  res.render('connect-flash', { message: req.flash('info') });
  console.log(req.session.flash);   // session的flash字段在获取之后就删除了,print {}
});

app.get('/flash', function(req, res){
  req.flash('info', 'Hi there!')
  res.redirect('/');
});

app.get('/no-flash', function(req, res){
  res.redirect('/');
});

app.get('/multiple-flash', function(req, res){
  req.flash('info', ['Welcome', 'Please Enjoy']);
  res.redirect('/');
});
app.listen(8888);

/*
1、
Session {cookie:{path:'/',_expires:2017-12-29T09:45:06.111Z,originalMaxAge:60000,httpOnly:true}}

2、
Session {cookie:{path:'/',_expires:2017-12-29T09:45:07.567Z,originalMaxAge:60000,httpOnly:true},
flash: { info: [ 'Hi there!' ] },
user: '/flash' }

3、
Session {cookie:{path:'/',_expires:2017-12-29T09:45:08.384Z,originalMaxAge:60000,httpOnly:true},
flash: {},
user: '/no-flash' }

4、
Session {cookie:{path:'/',_expires:2017-12-29T09:45:09.326Z,originalMaxAge:60000,httpOnly:true},
flash: { info: [ 'Welcome', 'Please Enjoy' ] },
user: '/multiple-flash' }

5、
Session {cookie:{path:'/',_expires:2017-12-29T09:45:10.357Z,originalMaxAge:60000,httpOnly:true},
flash: { info: [ 'Hi there!' ] },
user: '/flash' }
*/

</pre>

<h3>express用于处理请求体的中间件：bodyparser,multer,formidable</h3><pre>
表单get方法
var urlParsed = url.parse(request.url);
var getData = querystring.parse(urlParsed.query);
//getData 为object类型 同名表单为array

1、普通表单请求头
Content-Type:application/x-www-form-urlencoded

2、文件上传请求头
Content-Type:multipart/form-data; boundary=----WebKitFormBoundaryFBGcCPOaYHe5YKwn

3、提交json格式的数据
application/json

4、提交xml格式的数据
text/xml

在实际开发中,很明显可以用bodyparser和multer来分别处理表单和文件,也可以只用formidable,按需取用即可

【 Bodyparser中间件 】
用于处理第1,3种content-type 的body非常的方便,但不能用于处理multipart类型的body
提供了四种方法
bodyParser.json() 将body解析为json
bodyParser.text() 将body解析为文本
bodyParser.raw() 将body解析为二进制
bodyParser.urlencoded() 将编码为URLEncoder的body解析出来

【 multer 文件上传 】
只处理类型是multipart/form-data的body
主要功能是： .single('photo') .array('photos', 12) .fields([])分别对应处理上传文件,批量上传和分类上传,同时也带有处理纯文字的功能,用上面三个方法不带参数即可

</pre><pre class="js">
/* index.html */
<form action="/file_upload" method="post" enctype="multipart/form-data">
  <input type="file" name="image" size="50" />
  <input type="submit" value="上传文件" />
</form>

/* server.js */
var express = require('express');
var app = express();
var fs = require("fs");
var bodyParser = require('body-parser');
var multer  = require('multer');

app.use(express.static('public'));
app.use(bodyParser.urlencoded({ extended: false }));
app.use(multer({ dest: '/tmp/'}).array('image'));

app.get('/', function (req, res) {
   res.sendFile( __dirname + "/" + "upload-index.htm" );
})

app.post('/file_upload', function (req, res) {
   console.log(req.files[0]);                    // 上传的文件信息
   var des_file = __dirname + "/" + req.files[0].originalname;
   fs.readFile( req.files[0].path, function (err, data) {
      fs.writeFile(des_file, data, function (err) {
        if(err) return console.log( err );
        response = {
          message:'File uploaded successfully',
          filename:req.files[0].originalname
        };
        res.end( JSON.stringify( response ) );
      });
   });
})

var server = app.listen(8888, () => console.log("地址为 http://%s:%s", server.address().address, server.address().port))

/*
{ fieldname: 'image',
  originalname: 'ajax-loader.gif',
  encoding: '7bit',
  mimetype: 'image/gif',
  destination: '/tmp/',
  filename: '57b35d635efebab049e6b38c12f246f3',
  path: '\\tmp\\57b35d635efebab049e6b38c12f246f3',
  size: 3951
}
*/

</pre><pre class="js">
var express = require('express');
var router = express.Router();
var multer = require('multer');

var uploading = multer({
  dest: __dirname + '../public/uploads/',
  limits: {fileSize: 1000000, files:1},  // 设定限制,每次最多上传1个文件,文件大小不超过1MB
})

router.post('/upload', uploading, function(req, res) { })

module.exports = router

</pre><pre>
【 Formidable 】
A Node.js module for parsing form data, especially(尤其是) file uploads

Features：
Fast (~500mb/sec), non-buffering multipart parser
Automatically writing file uploads to disk
Low memory footprint(足迹)
Graceful(优雅地) error handling
Very high test coverage

【 API 】
var form = new formidable.IncomingForm()
Creates a new incoming form.

form.encoding = 'utf-8';
Sets encoding for incoming form fields.

form.uploadDir = "/my/dir";
Sets the directory for placing file uploads in. You can move them later on using fs.rename(). The default is os.tmpdir().

form.keepExtensions = false;
If you want the files written to form.uploadDir to include the extensions of the original files, set this property to true.

form.type
Either 'multipart' or 'urlencoded' depending on the incoming request.

form.maxFieldsSize = 2 * 1024 * 1024;
Limits the amount of memory all fields together (except files) can allocate in bytes. If this value is exceeded, an 'error' event is emitted. The default size is 2MB.

form.maxFields = 1000;
Limits the number of fields that the querystring parser will decode. Defaults to 1000 (0 for unlimited).

form.hash = false;
If you want checksums calculated for incoming files, set this to either 'sha1' or 'md5'.

form.multiples = false;
If this option is enabled, when you call form.parse, the files argument will contain arrays of files for inputs which submit multiple files using the HTML5 multiple attribute.

form.bytesReceived
The amount of bytes received for this form so far.

form.bytesExpected
The expected number of bytes in this form.

form.parse(request, [cb]);
Parses an incoming node.js request containing form data. If cb is provided, all fields and files are collected and passed to the callback:

form.parse(req, function(err, fields, files) {
  // ...
});

form.onPart(part);
You may overwrite this method if you are interested in directly accessing the multipart stream. Doing so will disable any 'field' / 'file' events processing which would occur otherwise, making you fully responsible for handling the processing.

form.onPart = function(part) {
  part.addListener('data', function() {
    // ...
  });
}

If you want to use formidable to only handle certain parts for you, you can do so:
form.onPart = function(part) {
  if (!part.filename) {
    // let formidable handle all non-file parts
    form.handlePart(part);
  }
}
Check the code in this method for further inspiration(灵感)

【 Formidable.File 】
file.size = 0
The size of the uploaded file in bytes. If the file is still being uploaded (see 'fileBegin' event), this property says how many bytes of the file have been written to disk yet.

file.path = null
The path this file is being written to. You can modify this in the 'fileBegin' event in case you are unhappy with the way formidable generates a temporary path for your files.

file.name = null
The name this file had according to the uploading client.

file.type = null
The mime type of this file, according to the uploading client.

file.lastModifiedDate = null
A date object (or null) containing the time this file was last written to. Mostly here for compatibility with the W3C File API Draft.

file.hash = null
If hash calculation was set, you can read the hex digest out of this var.

Formidable.File#toJSON()
This method returns a JSON-representation of the file, allowing you to JSON.stringify() the file which is useful for logging and responding to requests.

【 Events 】
'progress'
Emitted after each incoming chunk of data that has been parsed. Can be used to roll your own progress bar.
form.on('progress', function(bytesReceived, bytesExpected) {});

'field'
Emitted whenever a field / value pair has been received.
form.on('field', function(name, value) {});

'fileBegin'
Emitted whenever a new file is detected in the upload stream. Use this event if you want to stream the file to somewhere else while buffering the upload on the file system.
form.on('fileBegin', function(name, file) {});

'file'
Emitted whenever a field / file pair has been received. file is an instance of File.
form.on('file', function(name, file) {});

'error'
Emitted when there is an error processing the incoming form. A request that experiences an error is automatically paused, you will have to manually call request.resume() if you want the request to continue firing 'data' events.
form.on('error', function(err) {});

'aborted'
Emitted when the request was aborted by the user. Right now this can be due to a 'timeout' or 'close' event on the socket. After this event is emitted, an error event will follow. In the future there will be a separate 'timeout' event (needs a change in the node core).
form.on('aborted', function() {});

'end'
form.on('end', function() {});
Emitted when the entire request has been received, and all contained files have finished flushing to disk. This is a great place for you to send your response.

</pre><pre class="js">
var formidable = require('formidable');
var http = require('http');
var util = require('util');
http.createServer(function(req, res) {
  if (req.url == '/upload' && req.method.toLowerCase() == 'post') {
    var form = new formidable.IncomingForm();
    form.keepExtensions = true;
    form.uploadDir = "./databox";
    form.multiples = true;
    form.parse(req, function(err, fields, files) {
      res.writeHead(200, {'content-type': 'text/plain'});
      res.end('success');
      console.log(util.inspect(fields));
      console.log(util.inspect(files));
    });
    return;
  }
  res.writeHead(200, {'content-type': 'text/html'});
  res.end(
    '<form action="/upload" enctype="multipart/form-data" method="post">'+
    '<input type="text" name="title"><br>'+
    '<input type="file" name="upload" multiple="multiple"><br>'+
    '<input type="submit" value="Upload">'+
    '</form>'
  );
}).listen(8888);

/*
{ title: '&#26631;&#39064;' }
{ upload:
   [ File {
       domain: null,
       _events: {},
       _eventsCount: 0,
       _maxListeners: undefined,
       size: 172406,
       path: 'databox\\upload_b3aedab0dc77c0dd65ed6a43a7224de3.png',
       name: '4.16check.png',
       type: 'image/png',
       hash: null,
       lastModifiedDate: 2017-12-29T05:24:24.170Z,
       _writeStream: [Object] },
     File {
       domain: null,
       _events: {},
       _eventsCount: 0,
       _maxListeners: undefined,
       size: 3951,
       path: 'databox\\upload_527f2516639c39fd56bc8c6a6b1d0502.gif',
       name: 'ajax-loader.gif',
       type: 'image/gif',
       hash: null,
       lastModifiedDate: 2017-12-29T05:24:24.171Z,
       _writeStream:
      WriteStream {
        _writableState: [Object],
        writable: false,
        domain: null,
        _events: {},
        _eventsCount: 0,
        _maxListeners: undefined,
        path: 'databox\\upload_527f2516639c39fd56bc8c6a6b1d0502.gif',
        fd: null,
        flags: 'w',
        mode: 438,
        start: undefined,
        autoClose: true,
        pos: undefined,
        bytesWritten: 3951,
        closed: true
      }
    }
  ]
}
*/

</pre><pre>
【 express-formidable 】
Formidable is a Node.js module
for parsing form data, including `multipart/form-data` file upload.

express-formidable is something like a bridge between express and Formidable,
specifically(具体的) an Express middleware implementation(实现) of Formidable

express-formidable can basically parse form types Formidable can handle, including application/x-www-form-urlencoded, application/json, and multipart/form-data

</pre><pre class="js">
const express = require('express');
const formidable = require('express-formidable');
var app = express();
var opts = {
  encoding: 'utf-8',
  uploadDir: '/my/dir',
  multiples: true,      // req.files to be a array of files
  keepExtensions: true
}
app.use(formidable(opts));
app.post('/upload', (req, res) => {
  req.fields;       // contains non-file fields
  req.files;        // contains files
});

</pre><pre class="js">
var express = require('express');
var router = express.Router();
var fs = require('fs');
var path= require("path");
var formidable = require('formidable');
/* GET home page. */
router.get('/', function(req, res, next) {
  res.render('index', { title: 'Express+EJS+mysql+s2' });
});

router.post('/file-upload', function(req, res, next) {
  console.log('开始文件上传....');
  var form = new formidable.IncomingForm();
  form.encoding = 'utf-8';                //设置编辑
  form.uploadDir = "./public/images/";    //设置文件存储路径
  form.keepExtensions = true;             //保留后缀
  form.maxFieldsSize = 2 * 1024 * 1024;   //设置单文件大小限制
  form.maxFields = 1000;                  //设置所以文件的大小总和

  form.parse(req, function(err, fields, files) {
    console.log(fields);
    console.log(files.thumbnail.path);
    console.log('文件名:'+files.thumbnail.name);
    var t = (new Date()).getTime();
    var ran = parseInt(Math.random() * 8999 +10000);   //生成随机数
    var extname = path.extname(files.thumbnail.name);   //拿到扩展名

    path.normalize('./path//upload/data/../file/./123.jpg'); 规范格式文件名
    var oldpath = path.normalize(files.thumbnail.path);
    let newfilename=t+ran+extname;
    var newpath =  './public/images/'+newfilename;
    console.warn('oldpath:'+oldpath+' newpath:'+newpath);
    fs.rename(oldpath,newpath,function(err){
      if(err){
            console.error("改名失败"+err);
      }
      res.render('index', { title: '文件上传成功:', imginfo: newfilename });
    });
    //res.end(util.inspect({fields: fields, files: files}));
  });
});

/* supervisor ./bin/www  */
module.exports = router;

/* html code */
＜!DOCTYPE html>
＜html>
＜head>
＜title><%= title %>＜/title>
＜link rel='stylesheet' href='/stylesheets/style.css' />
＜/head>
＜body>
＜h5>这里变量没有输出但没有报销:<%= locals.title %>＜/h5>
＜p>Welcome to <%= title %>＜/p>

＜img src='./images/<%= locals.imginfo %>' width='200'/>

＜form method="post" enctype="multipart/form-data" action="/file-upload">
  ＜input type="text" name="username">
  ＜input type="password" name="password">
  ＜input type="file" name="thumbnail">
  ＜input type="submit">
＜/form>
＜/body>
＜/html>

</pre>

<h3>项目测试</h3><pre>
【 assert 】
assert模块是Node内置模块,主要用于断言。如果表达式不符合预期,就抛出一个错误,可用于测试模块功能
assert模块提供简单的断言测试功能,主要用来内部使用,也可能require('assert')后在外部进行使用。
assert模块的API为locked状态,将不会再有添加或修改

assert 模块提供了断言测试的函数,用于测试不变式

assert(value[,message])
assert.ok(value[, message]) 同assert()
如果value的值为true,那么什么也不会发生。如果value为false,将抛出一个信息为message的错误。

assert.equal(actual, expected[, message])
判断实际值(actual)与期望徝(expected)是否相等(==),如果不相等,则抛出一个message的错误
使用相等运算符(==)测试 actual 参数与 expected 参数是否相等
如果两个值不相等,则抛出一个带有 message 属性的 AssertionError,其中 message 属性的值等于传入的 message 参数的值。 如果 message 参数为 undefined,则赋予默认的错误信息

assert.notEqual(actual, expected[, message])

assert.deepEqual(actual, expected[, message])
如果本身属性及子对象属性都相等时通过。否则会抛出错误。
测试 actual 参数与 expected 参数是否深度相等。 原始值使用相等运算符(==)比较。
只测试本身属性及子对象可枚举的自身属性,不测试对象的原型、连接符、或不可枚举的属性

如果两个值不相等,则抛出一个带有 message 属性的 AssertionError,其中 message 属性的值等于传入的 message 参数的值。 如果 message 参数为 undefined,则赋予默认的错误信息

</pre><pre class="js">
// 不会抛出AssertionError,因为RegExp对象的属性不是可枚举的：
assert.deepEqual(/a/gi, new Date());

const assert = require('assert');
const obj1 = {a: {b: 1}};
const obj2 = {a: {b: 2}};
const obj3 = {a: {b: 1}};
const obj4 = Object.create(obj1);
assert.deepEqual(obj1, obj1);   // 测试通过,对象与自身相等
assert.deepEqual(obj1, obj2);   // 抛出AssertionError:{a:{b:1}} deepEqual {a:{b: 2}}
assert.deepEqual(obj1, obj3);   // 测试通过,两个对象相等
assert.deepEqual(obj1, obj4);   // 不测试原型,抛出AssertionError:{a: {b: 1}} deepEqual {}

</pre><pre>
assert.notDeepEqual(actual, expected[, message])

assert.strictEqual(actual, expected[, message])
用法与assert.deepEqual()一样,判断条件为是否完全相等(===)

assert.notStrictEqual(actual, expected[, message])

assert.deepStrictEqual(actual, expected[, message])

</pre><pre class="js">
与assert.deepEqual()大致相同,但有一些区别：
原始值使用全等运算符(===)比较。Set 的值与 Map 的键使用 SameValueZero 比较。
对象的原型也使用全等运算符比较。
对象的类型标签要求相同。
比较[对象包装器][]时,其对象和里面的值要求相同

const assert = require('assert');
assert.deepEqual({ a: 1 }, { a: '1' });
// 测试通过,因为 1 == '1'。

assert.deepStrictEqual({ a: 1 }, { a: '1' });
// 抛出AssertionError: { a: 1 } deepStrictEqual { a: '1' }
// 因为使用全等运算符 1 !== '1'。

// 以下对象都没有自身属性
const date = new Date();
const object = {};
const fakeDate = {};
Object.setPrototypeOf(fakeDate, Date.prototype);
assert.deepEqual(object, fakeDate);
// 测试通过,不测试原型。
assert.deepStrictEqual(object, fakeDate);
// 抛出 AssertionError: {} deepStrictEqual Date {},因为原型不同。

assert.deepEqual(date, fakeDate);
// 测试通过,不测试类型标签。
assert.deepStrictEqual(date, fakeDate);
// 抛出 AssertionError: 2017-03-11T14:25:31.849Z deepStrictEqual Date {},因为类型标签不同

assert.deepStrictEqual(new Number(1), new Number(2));
// 测试不通过,因为数值对象包装器里面的数值也会被比较。
assert.deepStrictEqual(new String('foo'), Object('foo'));
// 测试通过,因为这两个对象和里面的字符串都是相同的

</pre><pre>
assert.notDeepStrictEqual(actual, expected[, message])

assert.fail(message)
assert.fail(actual, expected, message, operator)
判断message是否是错误的(falsy),如果是错误的(falsy)则抛出错误信息：实际值 操作operator 期望值。　
如果message为正确的(Truthy),那么抛出信息为message的错误信息

assert.ifError(value)
判断value是否为false,如果为false则通过,如果为ture则抛出信息为value的错误
如果 value 为真,则抛出 value。 可用于测试回调函数的 error 参数。

</pre><pre class="js">
const assert = require('assert');
assert.ifError(0);             // 测试通过。
assert.ifError(1);             // 抛出 1。
assert.ifError('error');       // 抛出 'error'。
assert.ifError(new Error());   // 抛出 Error。

</pre><pre>
assert.throws(block[, error][, message])

assert.doesNotThrow(block[, error][, message])
断言 block 函数不会抛出错误。
当 assert.doesNotThrow() 被调用时,它会立即调用 block 函数。
如果抛出错误且错误类型与 error 参数指定的相同,则抛出 AssertionError。 如果错误类型不相同,或 error 参数为 undefined,则抛出错误

【 单元测试 】
单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作

比如对函数abs(),我们可以编写出以下几个测试用例：
输入正数,比如1、1.2、0.99,期待返回值与输入相同;
输入负数,比如-1、-1.2、-0.99,期待返回值与输入相反;
输入0,期待返回0;
输入非数值类型,比如null、[]、{},期待抛出Error。
把上面的测试用例放到一个测试模块里,就是一个完整的单元测试

测试框架就是运行测试的工具。通过它可以为JavaScript应用添加测试,从而保证代码的质量

Mocha摩卡诞生于2011年,是JavaScript的一种单元测试框架,既可以在浏览器环境和Node.js环境下运行
使用mocha,只需要专注于编写单元测试本身,然后让mocha去自动运行所有的测试,并给出测试结果。

mocha的特点主要有：
既可以测试简单的JavaScript函数,又可以测试异步代码,因为异步是JavaScript的特性之一;
可以自动运行所有测试,也可以只运行特定的测试;
可以支持before、after、beforeEach和afterEach来编写初始化代码

【 mocha & suptertest 】
mocha和suptertest是常用的测试组合,通常用来测试restful的api接口
npm i mocha supertest --save-dev

pakeage.json
"scripts": { "test": "mocha test" }

测试覆盖率,即被测试覆盖到的代码行数占总代码行数的比例
即使测试覆盖率达到 100% 也不能说明你的测试覆盖了所有的情况,只能说明基本覆盖了所有的情况

istanbul是一个常用的生成测试覆盖率的库,会将测试的结果报告生成html页面,并放到项目根目录的 coverage目录下
npm i istanbul --save-dev

配置istanbul,修改package.json,将istanbul和mocha结合使用,运行npm test终端会打印
"test": "istanbul cover _mocha"

istanbul cover {your_npm_path}\npm\node_modules\mocha\bin\_mocha

</pre>
</div>

<div id="access">
<h2>权限控制</h2><pre>
把用户状态的检查封装成一个中间件,在每个需要权限控制的路由加载该中间件,即可实现页面的权限控制

</pre><pre class="js">
module.exports = {
  checkLogin: function checkLogin(req, res, next){
    if(!req.session.user){
      req.flash('error', '未登录');
      return res.rederict('/singin');
    }
    next();
  }
  checkNotLogin: function checkNotLogin(req, res, next){
    if(req.session.user){
      req.flash('error', '已登录');
      return res.rederict('back');  // 返回之前的页面
    }
    next();
  }
}

</pre>

<h3>express debug调试</h3><pre>
Express 内部使用 debug 模块记录路由匹配、使用到的中间件、应用模式以及请求-响应循环。
debug 有点像改装过的 console.log,不同的是,您不需要在生产代码中注释掉 debug。它会默认关闭,而且使用一个名为 DEBUG 的环境变量还可以打开

【 404处理 】
在Express中,404并不是一个错误error,错误处理器中间件并不捕获404,404只是意味着某些功能没有实现。也就是说Express执行了所有中间件、路由之后还是没有获取到任何输出。需要做的就是在所有其他中间件的后面添加一个处理404的中间件

app.use(function(req, res, next) {
  res.status(404).send('Sorry cant find that!');
});

</pre>
</div>

<div id="example">
<h3>express 项目</h3><pre>
进程管理
会话管理
日志管理
性能优化
错误处理
负载均衡
数据库支持
HTTPS支持
业务实践

【 使用gzip压缩 】
通过Gzip压缩有助于显著降低响应主体的大小,从而提高Web应用程序的速度
可使用压缩中间件进行Express应用程序中的gzip压缩

var compression = require('compression');
var express = require('express');
var app = express();
app.use(compression());

对于生产环境中的大流量网站,实施压缩的最佳位置是在反向代理层级(请参阅使用反向代理)。在此情况下,不需要使用压缩中间件。有关在 Nginx 中启用 gzip 压缩的详细信息,请参阅 Nginx 文档中的 ngx_http_gzip_module 模块

【 不使用同步函数 】
同步函数和方法会阻止执行进程的运行,直至其返回。对同步函数的每次调用可能在数微秒或数毫秒后返回,但是在大流量网站中,这些调用的累积返回时间也相当可观,会影响到应用程序的性能。因此应避免在生产环境中使用同步函数。

虽然 Node 和许多模块提供函数的同步和异步版本,但是在生产环境中请始终使用异步版本。只有在初始启动时才适合使用同步函数

【 正确进行日志记录 】
一般而言,从应用程序进行日志记录有两个原因：出于调试目的和出于记录应用程序活动目的(基本上就是除调试以外的其他所有事项)。通过使用 console.log() 或 console.err() 在终端上显示日志消息是开发过程中的常见做法。但是,如果目标是终端或文件,这些函数就是同步的,因此,除非要将输出通过管道传到另一个程序,否则上述函数就不适合用于生产环境。

出于调试目的
如果您出于调试目的进行日志记录,请使用 debug 这样的特殊调试模块,而不要使用 console.log()。此模块支持您使用 DEBUG 环境变量来控制将哪些调试消息(如果有)发送到 console.err()。为了确保应用程序完全采用异步方式,仍需要将 console.err() 通过管道传到另一个程序。但您并不会真的希望在生产环境中进行调试,对吧？

出于应用程序活动目的
如果要对应用程序活动进行日志记录(例如,跟踪流量或 API 调用),请使用 Winston 或 Bunyan 之类的日志记录库,而不要使用 console.log()。

【 正确处理异常 】
Node 应用程序在遇到未捕获的异常时会崩溃。不处理异常并采取相应的措施会导致 Express 应用程序崩溃并脱机。如果您按照以下确保应用程序自动重新启动中的建议执行,那么应用程序可以从崩溃中恢复。幸运的是,Express 应用程序的启动时间一般很短。然而,应当首先立足于避免崩溃,为此,需要正确处理异常。

要确保处理所有异常,请使用以下方法：

使用 try-catch
使用 promise
在深入了解这些主题之前,应该对 Node/Express 错误处理有基本的了解：使用 error-first 回调并在中间件中传播错误。Node 将"error-first 回调"约定用于从异步函数返回错误,回调函数的第一个参数是错误对象,后续参数中包含结果数据。为了表明没有错误,可将 null 值作为第一个参数传递。回调函数必须相应地遵循"error-first"回调约定,以便有意义地处理错误。在 Express 中,最佳做法是使用 next() 函数,通过中间件链来传播错误。

【 请勿侦听 uncaughtException 事件 】
当异常像气泡一样在事件循环中一路回溯时,就会发出该事件。为 uncaughtException 添加事件侦听器将改变进程遇到异常时的缺省行为;进程将继续运行而不理会异常。这貌似是防止应用程序崩溃的好方法,但是在遇到未捕获的异常之后仍继续运行应用程序是一种危险的做法,不建议这么做,因为进程状态可能会变得不可靠和不可预测。

此外,uncaughtException 被公认为比较粗糙,建议从内核中将其移除。所以侦听 uncaughtException 并不是个好主意。这就是为何我们推荐诸如多个进程和虚拟机管理器之类的方案：崩溃后重新启动通常是从错误中恢复的最可靠方法

【 将NODE_ENV设置为"production" 】
NODE_ENV 环境变量指定运行应用程序的环境(通常是开发或者生产环境)。为了改进性能,最简单的方法是将 NODE_ENV 设置为"production"。

将 NODE_ENV 设置为"production"会使 Express：

高速缓存视图模板。
高速缓存从CSS扩展生成的CSS文件。
生成简短的错误消息。
测试表明仅仅这样做就可以使应用程序性能提高3倍多

如果您需要编写特定于环境的代码,可以使用process.env.NODE_ENV来检查NODE_ENV 的值。请注意,检查任何环境变量的值都会导致性能下降,所以应该三思而行。

在开发中通常会在交互式shell中设置环境变量,例如使用export或.bash_profile文件。但是一般而言不应在生产服务器上执行此操作;而是应当使用操作系统的初始化系统(systemd或Upstart)。设置NODE_ENV对于性能非常重要(且易于操作),所以会在此重点介绍。

对于Upstart请使用env关键字,例如：
# /etc/init/env.conf
 env NODE_ENV=production

【 确保应用程序能够自动重新启动 】
在生产环境中,需要确保在应用程序崩溃的情况下以及服务器自身崩溃的情况下应用程序都能够重新启动

使用进程管理器在应用程序(和 Node)崩溃时将其重新启动。
在操作系统崩溃时,使用操作系统提供的初始化系统重新启动进程管理器。还可以在没有进程管理器的情况下使用初始化系统。

Node应用程序在遇到未捕获的异常时会崩溃。您需要确保应用程序经过彻底测试,能够处理所有异常,这一点最为重要;但是作为一种防故障措施,请实施一种机制确保应用程序崩溃后可以自动重新启动。

1、使用进程管理器
在开发中只需在命令行从node server.js或类似项启动应用程序。但是在生产环境中执行此操作会导致灾难。如果应用程序崩溃,它会脱机,直到其重新启动为止。为了确保应用程序在崩溃后可以重新启动,请使用进程管理器。进程管理器是一种应用程序"容器",用于促进部署,提供高可用性,并支持用户在运行时管理应用程序。

除了在应用程序崩溃时将其重新启动外,进程管理器还可以执行以下操作：
获得对运行时性能和资源消耗的洞察。
动态修改设置以改善性能。
控制集群(StrongLoop PM 和 pm2)

Node的最流行进程管理器包括：
StrongLoop Process Manager
PM2
Forever

这三种进程管理器的逐个功能的比较参阅http://strong-pm.io/compare/,更详细介绍参阅Express应用程序的进程管理器。

即使应用程序会不时崩溃,使用其中任何进程管理器都足以使其成功启动。

但StrongLoop PM有许多专门针对生产部署的功能。可以使用该管理器以及相关的StrongLoop工具执行以下功能：
在本地构建和打包应用程序,然后将其安全地部署到生产系统。
在应用程序由于任何原因而崩溃时自动将其重新启动。
远程管理集群。
查看 CPU 概要文件和堆快照,以优化性能和诊断内存泄漏。
查看应用程序的性能指标。
轻松地扩展到具有 Nginx 负载均衡器集成控制的多个主机。
如以下所述,在使用初始化系统将 StrongLoop PM 作为操作系统服务安装后,StrongLoop PM 会在系统重新启动时自动重新启动。这样,就可以确保应用程序进程和集群持久保持运行。

2、使用初始化系统
下一层的可靠性是确保在服务器重新启动时应用程序可以重新启动。系统仍然可能由于各种原因而宕机。为了确保在服务器崩溃后应用程序可以重新启动,请使用内置于操作系统的初始化系统。目前主要使用两种初始化系统：systemd 和 Upstart。

有两种方法将初始化系统用于 Express 应用程序：

在进程管理器中运行应用程序,使用初始化系统将进程管理器安装为服务。进程管理器将在应用程序崩溃时将其重新启动,初始化系统则在操作系统重新启动时重新启动进程管理器。这是建议使用的方法。
通过初始化系统直接运行应用程序(和 Node)。这样做要简单些,但是无法发挥使用进程管理器的额外优点。

Systemd
Systemd是一个Linux系统和服务管理器。大多数主要Linux分发版采用systemd作为其缺省初始化系统。

systemd服务配置文件称为单元文件,扩展名为.service。以下是一个用于直接管理Node应用程序的单元文件示例(请将粗体文本替换为系统和应用程序的值)：

[Unit]
Description=Awesome Express App

[Service]
Type=simple
ExecStart=/usr/local/bin/node /projects/myapp/index.js
WorkingDirectory=/projects/myapp

User=nobody
Group=nogroup

# Environment variables:
Environment=NODE_ENV=production

# Allow many incoming connections
LimitNOFILE=infinity

# Allow core dumps for debugging
LimitCORE=infinity

StandardInput=null
StandardOutput=syslog
StandardError=syslog
Restart=always

[Install]
WantedBy=multi-user.target

作为systemd服务的StrongLoop PM
可以轻松地将StrongLoop Process Manager作为systemd服务安装。这样做之后,当服务器重新启动时,它会自动重新启动StrongLoop PM,后者又会重新启动所管理的所有应用程序。

要将StrongLoop PM作为systemd服务安装：
$ sudo sl-pm-install --systemd

使用以下命令启动此服务：
$ sudo /usr/bin/systemctl start strong-pm

Upstart
Upstart是在许多Linux分发版上提供的一种系统工具,用于在系统启动期间启动某些任务和服务,在系统关闭期间停止这些任务和服务,以及对这些任务和服务进行监督。可以将 Express 应用程序或进程管理器配置为服务,这样Upstart会在其崩溃时自动将其重新启动。

Upstart服务以作业配置文件(也称为"作业")形式定义,扩展名为.conf。以下示例说明如何为名为"myapp"的应用程序创建名为"myapp"的作业,其主文件位于 /projects/myapp/index.js。

在/etc/init/中创建名为myapp.conf的文件,其中包含以下内容(请将粗体文本替换为系统和应用程序的值)：
# When to start the process
start on runlevel [2345]

# When to stop the process
stop on runlevel [016]

# Increase file descriptor limit to be able to handle more requests
limit nofile 50000 50000

# Use production mode
env NODE_ENV=production

# Run as www-data
setuid www-data
setgid www-data

# Run from inside the app dir
chdir /projects/myapp

# The process to start
exec /usr/local/bin/node /projects/myapp/index.js

# Restart the process if it is down
respawn

# Limit restart attempt to 10 times within 10 seconds
respawn limit 10 10

注：此脚本需要Ubuntu 12.04-14.10上受支持的Upstart 1.4或更新版本。

由于此作业配置为在系统启动时运行,因此应用程序将随操作系统一起启动,并在应用程序崩溃或者系统宕机后自动重新启动。

除了自动重新启动此应用程序,Upstart 还支持使用以下命令：
start myapp - 启动应用程序
restart myapp - 重新启动应用程序
stop myapp - 停止应用程序。

作为Upstart服务的StrongLoop PM
可以轻松地将StrongLoop Process Manager作为Upstart服务安装。这样做之后,当服务器重新启动时,它会自动重新启动StrongLoop PM,后者又会重新启动所管理的所有应用程序。

要将StrongLoop PM作为Upstart 1.4服务安装：
$ sudo sl-pm-install

使用以下命令运行此服务：
$ sudo /sbin/initctl start strong-pm

注：在不支持Upstart 1.4的系统上,这些命令略有不同

【 在集群中运行应用程序 】
在多核系统中,可以通过启动进程的集群,将Node应用程序的性能提升多倍。一个集群运行此应用程序的多个实例,理想情况下一个CPU核心上运行一个实例,从而在实例之间分担负载和任务。

重要信息：由于应用程序实例作为单独的进程运行,因此它们不会共享同一内存空间。也就是说,对象位于应用程序每个实例的本地。因此,无法在应用程序代码中保存状态。然而可以使用Redis之类的内存中数据存储器来存储与会话相关的数据和状态。此警告适用于几乎所有形式的水平扩展(无论是多个进程的集群还是多个物理服务器的集群)。

在集群应用程序中,个别工作进程的崩溃并不会影响其余的进程。除了性能优势,故障隔离是运行应用程序进程集群的另一原因。每当工作进程崩溃时,请确保始终使用cluster.fork()来记录事件并生成新进程。

使用Node的集群模块
可以使用Node的集群模块来建立集群。这使主进程可以生成工作进程并在工作进程之间分配传入连接。然而使用可以自动执行此操作的众多工具中的一种(例如node-pm或cluster-service),要比直接使用此模块好得多。

使用StrongLoop PM
如果将应用程序部署到StrongLoop Process Manager (PM),那么可以利用集群而不必修改应用程序代码。

如果使用StrongLoop Process Manager (PM)运行应用程序,它会在集群中自动运行此应用程序,所生成的工作进程数等于系统中的CPU核心数。可以使用slc命令行工具手动更改集群中工作进程的数量,而不必停止应用程序。

例如假设要将应用程序部署到prod.foo.com,并且StrongLoop PM正在端口8701(缺省值)上侦听,那么可使用slc将集群大小设置为 8：
$ slc ctl -C http://prod.foo.com:8701 set-size my-app 8

【 高速缓存请求结果 】
提高生产环境性能的另一种策略是对请求的结果进行高速缓存,以便应用程序不需要为满足同一请求而重复执行操作。

使用Varnish或Nginx Caching之类的高速缓存服务器,可以显著提高应用程序的速度和性能。

【 使用负载均衡器 】
无论应用程序如何优化,单个实例都只能处理有限的负载和流量。扩展应用程序的一种方法是运行此应用程序的多个实例,并通过负载均衡器分配流量。设置负载均衡器可以提高应用程序的性能和速度,并使可扩展性远超单个实例可以达到的水平。

负载均衡器通常是逆向代理,用于编排进出多个应用程序实例和服务器的流量。可以使用Nginx或HAProxy轻松地为应用程序设置负载均衡器。

对于负载均衡功能,可能必须确保与特定会话标识关联的请求连接到产生请求的进程。这称为会话亲缘关系或者粘性会话,可通过以上的建议来做到这一点：将 Redis 之类的数据存储器用于会话数据(取决于您的应用程序)。要了解相关讨论,请参阅 Using multiple nodes。

将StrongLoop PM与Nginx负载均衡器一起使用
StrongLoop Process Manager与Nginx Controller集成,从而能够方便地配置多主机生产环境配置

使用逆向代理
逆向代理位于Web应用程序之前,除了将请求转发给应用程序外,还对请求执行支持性操作。它还可以处理错误页、压缩、高速缓存、文件服务和负载均衡等功能。

通过将无需了解应用程序状态的任务移交给逆向代理,可以使Express腾出资源来执行专门的应用程序任务。因此建议在生产环境中在Nginx或HAProxy之类的逆向代理背后运行Express。

</pre>

<h3>项目开发实例</h3><pre class="js">
// express基本用法

/* /index.js */
const express = require('express');
const app = express();
const path = require('path');

const indexRouter = require('./routes/index');
const usersRouter = require('./routes/users');

app.set('views', path.join(__dirname, 'views'));
app.set('view engine', 'ejs');

app.use('/', indexRouter);
app.use('/users', usersRouter);
app.use('/err', (req, res, next) => next(new Error('handle error')))

//错误处理
app.use(function (err, req, res, next) {
  console.error(err.stack)
  res.status(500).send('Something broke!')
})

app.listen(3000, () => console.log('server start on 3000'))

/* routes/index.js */
const express = require('express');
const router = express.Router();
router.get('/', (req, res) => res.send('hello express'));
module.exports = router;

/* routes/users.js */
const express = require('express');
const router = express.Router();
router.get('/:name', (req, res, next) => {
  res.locals.title = "uses";
  res.render('users', {
    name: req.params.name,
    code1: '<h3>html=code</h3>',
    code2: '<h3>html-code</h3>'
  })
})
module.exports = router;

/* views/users.ejs */
＜!DOCTYPE html>
＜html>
＜head>
＜title><%= title %>＜/title>
＜style type="text/css">
  body {padding: 50px;font: 14px "Lucida Grande", Helvetica, Arial, sans-serif;}
＜/style>
＜/head>
＜body>
  ＜h1><%= name.toUpperCase() %>＜/h1>
  ＜p>hello, <%= name %>＜/p>
  ＜p><%= code1 %>＜/p>
  ＜p><%- code2 %>＜/p>
＜/body>
＜/html>

</pre><pre class="js">
1、先建立一个项目目录(假定这个目录叫做demo)
2、进入该目录,新建一个package.json文件,写入项目的配置信息
package.json用于项目依赖配置及开发者信息,scripts属性是用于定义操作命令的,可以非常方便的增加启动命令,比如默认的start,用npm start代表执行node ./bin/www命令
{
   "name": "demo",
   "description": "My First Express App",
   "version": "0.0.1",
   "private": true,
   "scripts": {
      "start": "node ./bin/www"
    },
    "dependencies": {
      "express": "4.x"
    }
}

3、在项目目录中新建文件app.js,接着设定express实例的参数
var express = require('express');
var app = express();

// 设定port变量,意为访问端口
app.set('port', process.env.PORT || 3000);

// 设定views变量,意为视图存放的目录
app.set('views', path.join(__dirname, 'views'));

// 设定view engine变量,意为网页模板引擎
app.set('view engine', 'jade');

app.use(express.favicon());
app.use(express.logger('dev'));
app.use(express.bodyParser());
app.use(express.methodOverride());
app.use(app.router);

// 设定静态文件目录,比如本地文件
// 目录为demo/public/images,访问网址则显示为http://localhost:3000/images
app.use(express.static(path.join(__dirname, 'public')));
// 调用实例方法listen,让其监听事先设定的端口
app.listen(app.get('port'));

4、配置路由
app.get('/', function(req, res) {
   res.send('Hello World');
});

// 如需指定HTTP头信息,回调函数就必须换一种写法,要使用setHeader方法与end方法。
app.get('/', function(req, res){
  var body = 'Hello World';
  res.setHeader('Content-Type', 'text/plain');
  res.setHeader('Content-Length', body.length);
  res.end(body);
});

app.get('/api', function(request, response) {
   response.send({name:"张三",age:40});
});

/* 也可以把app.get的回调函数,封装成模块 */
// routes/api.js
exports.index = function (req, res){
  res.json(200, {name:"张三",age:40});
}

// app.js
var api = require('./routes/api');
app.get('/api', api.index);

6、静态网页模板
var express = require('express');
var app = express();

app.get('/', function (req, res) {
  res.sendFile(__dirname + '/views/index.html');
});

app.get('/about', (req, res) => {
  res.sendFile(__dirname + '/views/about.html');
});

app.get('/article', (req, res) => {
  res.sendFile(__dirname + '/views/article.html');
});

app.listen(8888);

7、动态网页模板,模板引擎
var express = require('express');
var app = express();

app.set('views', path.join(__dirname, 'views'));
// 指定模板文件的后缀名为html
app.set('view engine', 'ejs');

app.get('/', function (req, res){
  res.render('index');  // 把子目录views下面的index.html文件,交给模板引擎渲染
});

app.get('/about', function(req, res) {
  res.render('about');
});

app.get('/article', function(req, res) {
  res.render('article');
});

8、动态数据渲染
// blog.js 数据文件
var entries = [
  {"id":1, "title":"第一篇", "body":"正文", "published":"6/2/2013"},
  {"id":2, "title":"第二篇", "body":"正文", "published":"6/3/2013"},
  {"id":3, "title":"第三篇", "body":"正文", "published":"6/4/2013"},
  {"id":4, "title":"第四篇", "body":"正文", "published":"6/5/2013"},
  {"id":5, "title":"第五篇", "body":"正文", "published":"6/10/2013"},
  {"id":6, "title":"第六篇", "body":"正文", "published":"6/12/2013"}
];

exports.getBlogEntries = function (){
   return entries;
}

exports.getBlogEntry = function (id){
   for(var i=0; i < entries.length; i++){
      if(entries[i].id == id) return entries[i];
   }
}

// app.js
// 加载依赖库
var express = require('express');
var path = require('path');
var favicon = require('serve-favicon');
var logger = require('morgan');
var cookieParser = require('cookie-parser');
var bodyParser = require('body-parser');

var app = express();

// 设定port变量,意为访问端口
app.set('port', process.env.PORT || 8888);

// 设定views变量,意为视图存放的目录
app.set('views', path.join(__dirname, 'views'));

// 设定view engine变量,意为网页模板引擎
app.set('view engine', 'ejs');

// uncomment after placing your favicon in /public
// 定义icon图标
// app.use(favicon(path.join(__dirname, 'public', 'favicon.ico')));
// 定义日志和输出级别
app.use(logger('dev'));
// 定义数据解析器
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: false }));
// 定义cookie解析器
app.use(cookieParser());
// 定义静态文件目录
app.use(express.static(path.join(__dirname, 'public')));
// 加载bootstrap
app.use(express.static(path.join(__dirname, 'node_modules')));

var blog_data = require('./blog_data');
app.get('/', (req, res)=>{
  res.render('index', {title: '首页', entries: blog_data.getBlogEntries()})
})

app.get('/article/:id', (req, res)=>{
  var id = req.params.id;
  if(id){
    res.render('article', {title: '内容页', entry: blog_data.getBlogEntry(id)})
  }else{
    res.redirect("/");
  }

})

// 设定静态文件目录,比如本地文件
// 目录为demo/public/images,访问网址则显示为http://localhost:3000/images
app.use(express.static(path.join(__dirname, 'public')));
// 调用实例方法listen,让其监听事先设定的端口
app.listen(app.get('port'));

/* layout_head.ejs */
＜!DOCTYPE html>
＜html>
＜head>
＜title><%= title %>＜/title>
＜style>.content{padding: 1rem; border: 1px dashed #000;}＜/style>
＜/head>
＜body>

/* layout_foot.ejs */
＜/body>
＜/html>

/* index.ejs */
<%include layout_head%>
<h1>文章列表</h1>
<% for(var i = 0; i < entries.length; i++){ %>
  <p>
    ＜a href="/article/<%= entries[i]['id'] %>"><%= entries[i]['title'] %>＜/a>
    published: <%= entries[i]['published'] %>
  </p>
<% } %>
<%include layout_foot%>

/* article.ejs */
<%include layout_head%>
<h1><%= entry['title'] %></h1>
<p><%= entry['published'] %></p>
<div class="content"><%= entry['body'] %></div>

<%include layout_foot%>

</pre>
</div>

<div id="koa">
<h2>koa  > npm i koa  > npm i koa@2.0.0</h2><pre>
koa是Express的下一代基于Node.js的web框架,目前有1.x和2.0两个版本
Express是第一代最流行的web框架,对Node.js的http进行了封装,是基于ES5的语法,通过回调实现异步代码
Express的团队基于ES6的generator重新编写了下一代web框架koa1.0,使用generator实现异步,代码看起来像同步的
koa2基于ES7开发,使用Promise并配合async来实现异步,出于兼容性考虑,目前koa2仍支持generator的写法

Koa就是一种简单好用的Web框架,特点是优雅、简洁、表达力强、自由度高,本身代码只有1000多行,所有功能都通过插件实现,很符合Unix哲学

Koa要求使用node7.6以上的版本

koa源码文件
├── lib
│   ├── application.js: 整个koa2的入口文件,封装了context、request、response及最核心的中间件处理流程
│   ├── context.js: 处理应用上下文,里面直接封装部分request.js和response.js的方法
│   ├── request.js: 处理http请求
│   └── response.js: 处理http响应
└── package.json

koa2特性
1、只提供封装好http上下文、请求、响应,以及基于async/await的中间件容器
2、利用ES7的async/await的来处理传统回调嵌套问题和代替koa@1的generator,但要在node.js 7.x的harmony模式下才能支持async/await
3、中间件只支持async/await封装的,如果要使用koa@1基于generator中间件,需要通过中间件koa-convert封装一下才能使用

Koa.js 是一个极其精简的Web框架,只提供一下两种功能：
1、HTTP服务
处理HTTP请求request
处理HTTP响应response

2、中间件容器
中间件的加载
中间件的执行

剩下的其他Web服务所需的能力,就根据开发者的需求去自定义开发,留下了很大的灵活空间,提高了Web服务的开发成本。Koa.js的灵活度带来的开发成本有以下两种：
框架的设计
中间件的选择

【 koa和express对比 】
核心Koa模块只是中间件内核,而Express包含一个完整的应用程序框架,具有路由和模板等功能。Koa确实有这些功能的选项,但它们是单独的模块。因此Koa的模块化程度更高,只需包含所需的模块即可。核心KOA模块只有大约2千行代码,因此如果只需要核心请求应答上下文对象,则Koa占用空间非常小。相比较而言Express较为庞大,内置了一整套中间件功能,好处是对于大部分应用场合可以省掉自己选择和组合模块的时间

【 koa和Node.js的http原生模块 】
Koa.js是基于中间件模式的HTTP服务框架,底层原理是离不开Node.js的http原生模块

http服务构成：
1、服务容器,是整个HTTP服务的基石,跟apache和nginx提供的能力是一致的:
建立了通信连接
指定了通信端口
提供了可自定内容服务容器,也就是服务的回调函数的容器

2、服务回调,可以理解成服务内容,主要提供服务的功能。
解析服务的请求 req
对请求内容作出响应 res

主要HTTP服务内容是在服务回调”中处理的,根据不同连接拆分一下就形成了路由router,根据路由内容的拆分就形成了控制器controller

</pre><pre class="js">
const http = require('http');
const PORT = 3001;

// 控制器
const controller = {
  index(req, res) {
    res.end('This is index page')
  },
  home(req, res) {
    res.end('This is home page')
  },
  _404(req, res) {
    res.end('404 Not Found')
  }
}

// 路由器
const router = (req, res) => {
  if( req.url === '/' ) {
    controller.index(req, res)
  } else if( req.url.startsWith('/home') ) {
    controller.home(req, res)
  } else {
    controller._404(req, res)
  }
}

// 服务
const server = http.createServer(router)
server.listen(PORT, () => console.log(`the server is started at port ${PORT}`))

</pre>
</div>

<div id="koa-ctx">
<h4>Context API</h4><pre>
【 Context对象 】
Koa提供一个Context对象,表示一次对话的上下文(包括HTTP请求和HTTP回复),通过加工这个对象就可以控制返回给用户的内容

Koa将Node的request和response对象都封装到了context中,每次请求都会创建一个ctx,并且在中间件中作为接收器使用

即便没有给ctx.body设置响应数据或访问不存在的路由,页面也会显示Not Found,这是koa底层做了处理,不像原生Node或Express一样页面会一直处于响应状态

</pre><pre class="js">
const Koa = require('koa');  // 导入koa,和koa1不同,在koa2中导入的是一个class,因此用大写的Koa表示
const app = new Koa();       // 创建一个Koa对象表示web app本身

const main = ctx => ctx.response.body = 'Hello World';  // main函数用来设置ctx.response.body即发送给用户的内容
app.use(main);                                          // 使用app.use方法加载main函数

// 等效于
app.use(ctx => {
  ctx.body = 'hello koa';                                // ctx.body即发送给用户的内容
  console.log(ctx);
})

// 监听端口、启动程序
app.listen(3000, () => console.log('server start on 3000'))
app.listen(3000, err => {
  if (err) throw err;
  console.log('runing...');
})

{
  request: {
    method: 'GET',
    url: '/',
    header: {
      host: 'localhost:3000',
      connection: 'keep-alive',
      'upgrade-insecure-requests': '1',
      'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',
      accept: 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
      'accept-encoding': 'gzip, deflate, br',
      'accept-language': 'zh-CN,zh;q=0.9',
      cookie: 'Hm_lvt_9c975eeec1197cd1210a40e18a2b2f54=1560527839,1560731176; Hm_lpvt_9c975eeec1197cd1210a40e18a2b2f54=1560741673'
    }
  },
  response: {
    status: 200,
    message: 'OK',
    header: {
      'content-type': 'text/plain; charset=utf-8',
      'content-length': '9'
    }
  },
  app: { subdomainOffset: 2, proxy: false, env: 'development' },
  originalUrl: '/',
  req: '< original node req>',
  res: '< original node res>',
  socket: '< original node socket>'
}

</pre>add additional properties to ctx by editing app.context,adding properties or methods to ctx to be used across your entire app<pre class="js">
app.context.db = db();

app.use(async ctx => {
  console.log(ctx.db);
});

</pre>

<h4>ctx API</h4><pre>
【 ctx.req 】
Node's request object

【 ctx.res 】
Node's response object

Bypassing Koa's response handling is not supported. Avoid using the following node properties:
res.statusCode
res.writeHead()
res.write()
res.end()

即便使用ctx.res.write()也不会得到预期结果,比如：ctx.res.write('hello'),结果是hellook,会把message的值拼接上

【 ctx.request 】
A Koa Request object,ctx的请求对象

【 ctx.response 】
A Koa Response object,ctx的响应对象

【 ctx.state属性 】
The recommended(推荐的) namespace for passing information through middleware and to your frontend views.
ctx.state.user = await User.find(id);

比如每个页面都要用到用户信息,那就可以挂载在ctx.state,类似于添加全局属性。
ctx.state.userInfo = {
  name: 'Jack',
  age: 18
}

【 ctx.app 】
Application instance reference,应用程序实例引用

【 ctx.app.emit 】
Koa applications extend an internal EventEmitter. ctx.app.emit emits an event with a type, defined by the first argument. For each event you can hook up "listeners", which is a function that is called when the event is emitted. Consult the error handling docs for more information.

【 ctx.cookies.get(name, [options]) 】
Get cookie name with options:
signed: the cookie requested should be signed
Koa uses the cookies module where options are simply passed.

【 ctx.cookies.set(name, value, [options]) 】
Set cookie name to value with options:
maxAge a number representing the milliseconds from Date.now() for expiry
signed sign the cookie value
expires a Date for cookie expiration
path cookie path, '/' by default
domain cookie domain
secure secure cookie
httpOnly server-accessible cookie, true by default
overwrite a boolean indicating whether to overwrite previously set cookies of the same name (false by default). If this is true, all cookies set during the same request with the same name (regardless of path or domain) are filtered out of the Set-Cookie header when setting this cookie.

Koa uses the cookies module where options are simply passed.

【 ctx.throw([status], [msg], [properties]) 】
Helper method to throw an error with a .status property defaulting to 500 that will allow Koa to respond appropriately. The following combinations are allowed:

ctx.throw(400);
ctx.throw(400, 'name required');                  // status code:400, text/plain:name required
ctx.throw(400, 'name required', { user: user });

ctx.throw(400, 'name required') is equivalent to:
const err = new Error('name required');
err.status = 400;
err.expose = true;
throw err;

these are user-level errors and are flagged with err.expose meaning the messages are appropriate for client responses, which is typically not the case for error messages since you do not want to leak failure details.

You may optionally pass a properties object which is merged into the error as-is, useful for decorating machine-friendly errors which are reported to the requester upstream.

ctx.throw(401, 'access_denied', { user: user });

Koa uses http-errors to create errors. status should only be passed as the first parameter.

【 ctx.assert(value, [status], [msg], [properties]) 】
Helper method to throw an error similar to .throw() when !value. Similar to node's assert() method.
ctx.assert(ctx.state.user, 401, 'User not found. Please login!');
Koa uses http-assert for assertions.

【 ctx.respond 】
To bypass Koa's built-in response handling, you may explicitly set ctx.respond = false;. Use this if you want to write to the raw res object instead of letting Koa handle the response for you.

Note that using this is not supported by Koa. This may break intended functionality of Koa middleware and Koa itself. Using this property is considered a hack and is only a convenience to those wishing to use traditional fn(req, res) functions and middleware within Koa.

【 Request aliases 】
The following accessors and alias Request equivalents:
ctx.header
ctx.headers
ctx.method
ctx.method=
ctx.url
ctx.url=
ctx.originalUrl
ctx.origin
ctx.href
ctx.path
ctx.path=
ctx.query
ctx.query=
ctx.querystring
ctx.querystring=
ctx.host
ctx.hostname
ctx.fresh
ctx.stale
ctx.socket
ctx.protocol
ctx.secure
ctx.ip
ctx.ips
ctx.subdomains
ctx.is()
ctx.accepts()
ctx.acceptsEncodings()
ctx.acceptsCharsets()
ctx.acceptsLanguages()
ctx.get()

【 Response aliases 】
The following accessors and alias Response equivalents:
ctx.body
ctx.body=
ctx.status
ctx.status=
ctx.message
ctx.message=
ctx.length=
ctx.length
ctx.type=
ctx.type
ctx.headerSent
ctx.redirect()
ctx.attachment()
ctx.set()
ctx.append()
ctx.remove()
ctx.lastModified=
ctx.etag=

</pre>
</div>

<div id="koa-request">
<h4>koa Request API</h4><pre>
【 ctx.request.header 】
Request header object. This is the same as the headers field on node's http.IncomingMessage

【 ctx.request.header= 】
Set request header object.

【 ctx.request.headers 】
Request header object. Alias as request.header

【 ctx.request.headers= 】
Set request header object. Alias as request.header=

【 ctx.request.method 】
Request method

【 ctx.request.method= 】
Set request method, useful for implementing middleware such as methodOverride()

【 ctx.request.length 】
Return request Content-Length as a number when present, or undefined

【 ctx.request.url 】
Get request URL

【 ctx.request.url= 】
Set request URL, useful for url rewrites

【 ctx.request.originalUrl 】
Get request original URL

【 ctx.request.origin 】
Get origin of URL, include protocol and host
ctx.request.origin // => http://example.com

【 ctx.request.href 】
Get full request URL, include protocol, host and url
ctx.request.href;  // => http://example.com/foo/bar?q=1

【 ctx.request.path 】
Get request pathname

【 ctx.request.path= 】
Set request pathname and retain query-string when present

【 ctx.request.querystring 】
Get raw query string void of ?

【 ctx.request.querystring= 】
Set raw query string

【 ctx.request.search 】
Get raw query string with the ?

【 ctx.request.search= 】
Set raw query string

【 ctx.request.host 】
Get host (hostname:port) when present. Supports X-Forwarded-Host when app.proxy is true, otherwise Host is used

【 ctx.request.hostname 】
Get hostname when present. Supports X-Forwarded-Host when app.proxy is true, otherwise Host is used
If host is IPv6, Koa delegates parsing to WHATWG URL API, Note This may impact performance

【 ctx.request.URL 】
Get WHATWG parsed URL object

【 ctx.request.type 】
Get request Content-Type void of parameters such as "charset"
const ct = ctx.request.type;  // => "image/png"

【 ctx.request.charset 】
Get request charset when present, or undefined:
ctx.request.charset;  // => "utf-8"

【 ctx.request.query 】
Get parsed query-string, returning an empty object when no query-string is present. Note that this getter does not support nested parsing.
For example "color=blue&size=small":
{
  color: 'blue',
  size: 'small'
}

【 ctx.request.query= 】
Set query-string to the given object. Note that this setter does not support nested objects.
ctx.query = { next: '/login' };

【 ctx.request.fresh 】
Check if a request cache is "fresh", aka the contents have not changed. This method is for cache negotiation between If-None-Match / ETag, and If-Modified-Since and Last-Modified. It should be referenced after setting one or more of these response headers.

</pre><pre class="js">
// freshness check requires status 20x or 304
ctx.status = 200;
ctx.set('ETag', '123');

// cache is ok
if (ctx.fresh) {
  ctx.status = 304;
  return;
}

// cache is stale
// fetch new data
ctx.body = await db.find('something');

</pre><pre>
【 ctx.request.stale 】
Inverse of request.fresh

【 ctx.request.protocol 】
Return request protocol, "https" or "http". Supports X-Forwarded-Proto when app.proxy is true

【 ctx.request.secure 】
Shorthand for ctx.protocol == "https" to check if a request was issued via TLS.

【 ctx.request.ip 】
Request remote address. Supports X-Forwarded-For when app.proxy is true

【 ctx.request.ips 】
When X-Forwarded-For is present and app.proxy is enabled an array of these ips is returned, ordered from upstream -> downstream. When disabled an empty array is returned

【 ctx.request.subdomains 】
Return subdomains as an array.
Subdomains are the dot-separated parts of the host before the main domain of the app. By default, the domain of the app is assumed to be the last two parts of the host. This can be changed by setting app.subdomainOffset.
For example, if the domain is "tobi.ferrets.example.com": If app.subdomainOffset is not set, ctx.subdomains is ["ferrets", "tobi"]. If app.subdomainOffset is 3, ctx.subdomains is ["tobi"].

【 ctx.request.is(types...) 】
Check if the incoming request contains the "Content-Type" header field, and it contains any of the give mime types. If there is no request body, null is returned. If there is no content type, or the match fails false is returned. Otherwise, it returns the matching content-type.

</pre><pre class="js">
// With Content-Type: text/html; charset=utf-8
ctx.is('html');                  // => 'html'
ctx.is('text/html');             // => 'text/html'
ctx.is('text/*', 'text/html');   // => 'text/html'

// When Content-Type is application/json
ctx.is('json', 'urlencoded');    // => 'json'
ctx.is('application/json');      // => 'application/json'
ctx.is('html', 'application/*'); // => 'application/json'
ctx.is('html');                  // => false

</pre>For example if you want to ensure that only images are sent to a given route:<pre class="js">
if (ctx.is('image/*')) {
  // process
} else {
  ctx.throw(415, 'images only!');
}

</pre><pre>
Content Negotiation
Koa's request object includes helpful content negotiation utilities powered by accepts and negotiator. These utilities are:
request.accepts(types)
request.acceptsEncodings(types)
request.acceptsCharsets(charsets)
request.acceptsLanguages(langs)

If no types are supplied, all acceptable types are returned.

If multiple types are supplied, the best match will be returned. If no matches are found, a false is returned, and you should send a 406 "Not Acceptable" response to the client.

In the case of missing accept headers where any type is acceptable, the first type will be returned. Thus, the order of types you supply is important.

【 ctx.request.accepts(types) 】
Check if the given type(s) is acceptable, returning the best match when true, otherwise false. The type value may be one or more mime type string such as "application/json", the extension name such as "json", or an array ["json", "html", "text/plain"].

</pre><pre class="js">
// Accept: text/html
ctx.accepts('html');            // => "html"

// Accept: text/*, application/json
ctx.accepts('html');            // => "html"
ctx.accepts('text/html');       // => "text/html"
ctx.accepts('json', 'text');    // => "json"
ctx.accepts('application/json');// => "application/json"

// Accept: text/*, application/json
ctx.accepts('image/png');
ctx.accepts('png');             // => false


// Accept: text/*;q=.5, application/json
ctx.accepts(['html', 'json']);
ctx.accepts('html', 'json');    // => "json"

// No Accept header
ctx.accepts('html', 'json');    // => "html"
ctx.accepts('json', 'html');    // => "json"

</pre>You may call ctx.accepts() as many times as you like, or use a switch:<pre class="js">
switch (ctx.accepts('json', 'html', 'text')) {
  case 'json': break;
  case 'html': break;
  case 'text': break;
  default: ctx.throw(406, 'json, html, or text only');
}

</pre><pre>
【 ctx.request.acceptsEncodings(encodings) 】
Check if encodings are acceptable, returning the best match when true, otherwise false. Note that you should include identity as one of the encodings!
When no arguments are given all accepted encodings are returned as an array

// Accept-Encoding: gzip
ctx.acceptsEncodings('gzip', 'deflate', 'identity');    // => "gzip"
ctx.acceptsEncodings(['gzip', 'deflate', 'identity']);  // => "gzip"
ctx.acceptsEncodings();                                 // => ["gzip", "deflate", "identity"]

Note that the identity encoding (which means no encoding) could be unacceptable if the client explicitly sends identity;q=0. Although this is an edge case, you should still handle the case where this method returns false.

【 ctx.request.acceptsCharsets(charsets) 】
Check if charsets are acceptable, returning the best match when true, otherwise false
When no arguments are given all accepted charsets are returned as an array

// Accept-Charset: utf-8, iso-8859-1;q=0.2, utf-7;q=0.5
ctx.acceptsCharsets('utf-8', 'utf-7');     // => "utf-8"
ctx.acceptsCharsets(['utf-7', 'utf-8']);   // => "utf-8"
ctx.acceptsCharsets();                     // => ["utf-8", "utf-7", "iso-8859-1"]

【 ctx.request.acceptsLanguages(langs) 】
Check if langs are acceptable, returning the best match when true, otherwise false.
When no arguments are given all accepted languages are returned as an array

// Accept-Language: en;q=0.8, es, pt
ctx.acceptsLanguages('es', 'en');   // => "es"
ctx.acceptsLanguages(['en', 'es']); // => "es"
ctx.acceptsLanguages();             // => ["es", "pt", "en"]

【 ctx.request.idempotent 】
ctx.idempotent
Check if the request is idempotent(幂等)

HTTP请求方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用

HTTP GET方法用于获取资源,不应有副作用,所以是幂等的。比如：GET http://www.bank.com/account/123456,不会改变资源的状态,不论调用一次还是N次都没有副作用。这里强调的是一次和N次具有相同的副作用,而不是每次GET的结果相同。GET http://www.news.com/latest-news这个HTTP请求可能会每次得到不同的结果,但它本身并没有产生任何副作用,因而是满足幂等性的。

HTTP DELETE方法用于删除资源,有副作用,但它应该满足幂等性。比如：DELETE http://www.forum.com/article/4231,调用一次和N次对系统产生的副作用是相同的,即删掉id为4231的帖子,因此调用者可以多次调用或刷新页面而不必担心引起错误。

比较容易混淆的是HTTP POST和PUT,POST和PUT的区别容易被简单地误认为“POST表示创建资源,PUT表示更新资源”;而实际上二者均可用于创建资源,更为本质的差别是在幂等性方面

POST所对应的URI并非创建的资源本身,而是资源的接收者。比如：POST http://www.forum.com/articles的语义是在http://www.forum.com/articles下创建一篇帖子,HTTP响应中应包含帖子的创建状态以及帖子的URI。两次相同的POST请求会在服务器端创建两份资源,它们具有不同的URI,所以POST方法不具备幂等性。

PUT所对应的URI是要创建或更新的资源本身。比如：PUT http://www.forum/articles/4231的语义是创建或更新ID为4231的帖子。对同一URI进行多次PUT的副作用和一次PUT是相同的,因此PUT方法具有幂等性

【 ctx.request.socket 】
Return the request socket

【 ctx.request.get(field) 】
Return request header

</pre>
</div>

<div id="koa-response">
<h4>koa response API</h4><pre>
【 ctx.response.header 】
Response header object

【 ctx.response.headers 】
Response header object. Alias as response.header

【 ctx.response.socket 】
Request socket

【 ctx.response.status 】
Get response status. By default, response.status is set to 404 unlike node's res.statusCode which defaults to 200.

【 ctx.response.status= 】
Set response status via numeric code:
100 "continue"
101 "switching protocols"
102 "processing"
200 "ok"
201 "created"
202 "accepted"
203 "non-authoritative information"
204 "no content"
205 "reset content"
206 "partial content"
207 "multi-status"
208 "already reported"
226 "im used"
300 "multiple choices"
301 "moved permanently"
302 "found"
303 "see other"
304 "not modified"
305 "use proxy"
307 "temporary redirect"
308 "permanent redirect"
400 "bad request"
401 "unauthorized"
402 "payment required"
403 "forbidden"
404 "not found"
405 "method not allowed"
406 "not acceptable"
407 "proxy authentication required"
408 "request timeout"
409 "conflict"
410 "gone"
411 "length required"
412 "precondition failed"
413 "payload too large"
414 "uri too long"
415 "unsupported media type"
416 "range not satisfiable"
417 "expectation failed"
418 "I'm a teapot"
422 "unprocessable entity"
423 "locked"
424 "failed dependency"
426 "upgrade required"
428 "precondition required"
429 "too many requests"
431 "request header fields too large"
500 "internal server error"
501 "not implemented"
502 "bad gateway"
503 "service unavailable"
504 "gateway timeout"
505 "http version not supported"
506 "variant also negotiates"
507 "insufficient storage"
508 "loop detected"
510 "not extended"
511 "network authentication required"

【 ctx.response.message 】
Get response status message. By default, response.message is associated with response.status.

【 ctx.response.message= 】
Set response status message to the given value

【 ctx.response.length= 】
Set response Content-Length to the given value

【 ctx.response.length 】
Return response Content-Length as a number when present, or deduce from ctx.body when possible, or undefined

【 ctx.response.body 】
Get response body

【 ctx.response.body= 】
Set response body to one of the following:
string written
Buffer written
Stream piped
Object || Array json-stringified
null no content response

If response.status has not been set, Koa will automatically set the status to 200 or 204.

Koa doesn't guard against everything that could be put as a response body -- a function doesn't serialise meaningfully, returning a boolean may make sense based on your application, and while an error works, it may not work as intended as some properties of an error are not enumerable. We recommend adding middleware in your app that asserts body types per app. A sample middleware might be:

</pre><pre class="js">
app.use(async (ctx, next) => {
  await next()
  ctx.assert.equal('object', typeof ctx, 500, 'some dev did something wrong')
})

</pre><pre>
1、String
The Content-Type is defaulted to text/html or text/plain, both with a default charset of utf-8. The Content-Length field is also set.

2、Buffer
The Content-Type is defaulted to application/octet-stream, and Content-Length is also set.

3、Stream
The Content-Type is defaulted to application/octet-stream.

Whenever a stream is set as the response body, .onerror is automatically added as a listener to the error event to catch any errors. In addition, whenever the request is closed (even prematurely), the stream is destroyed. If you do not want these two features, do not set the stream as the body directly. For example, you may not want this when setting the body as an HTTP stream in a proxy as it would destroy the underlying connection.

See: https://github.com/koajs/koa/pull/612 for more information.

</pre>Here's an example of stream error handling without automatically destroying the stream:<pre class="js">
const PassThrough = require('stream').PassThrough;
app.use(async ctx => {
  ctx.body = someHTTPStream.on('error', ctx.onerror).pipe(PassThrough());
});

</pre><pre>
4、Object
The Content-Type is defaulted to application/json. This includes plain objects { foo: 'bar' } and arrays ['foo', 'bar'].

【 ctx.response.get(field) 】
Get a response header field value with case-insensitive field.
const etag = ctx.response.get('ETag');

【 ctx.response.set(field, value) 】
Set response header field to value:
ctx.set('Cache-Control', 'no-cache');

【 ctx.response.append(field, value) 】
Append additional header field with value val.
ctx.append('Link', '＜http://127.0.0.1/>');

【 ctx.response.set(fields) 】
Set several response header fields with an object:
ctx.set({ 'Etag': '1234', 'Last-Modified': date });

This delegates to setHeader which sets or updates headers by specified keys and doesn't reset the entire header.

【 ctx.response.remove(field) 】
Remove header field

【 ctx.response.type 】
Get response Content-Type void of parameters such as "charset".
const ct = ctx.type;  // => "image/png"

【 ctx.response.type= 】
Set response Content-Type via mime string or file extension.
ctx.type = 'text/plain; charset=utf-8';
ctx.type = 'image/png';
ctx.type = '.png';
ctx.type = 'png';
Note: when appropriate a charset is selected for you, for example response.type = 'html' will default to "utf-8". If you need to overwrite charset, use ctx.set('Content-Type', 'text/html') to set response header field to value directly.

Koa默认的返回HTTP Response类型是text/plain,如果想返回其他类型的内容可以先用ctx.request.accepts()判断一下客户端希望接受什么数据(根据 HTTP Request 的Accept字段),然后使用ctx.response.type指定返回类型

</pre><pre class="js">
const main = ctx => {
  if (ctx.request.accepts('xml')) {
    ctx.response.type = 'xml';
    ctx.response.body = '<data>Hello World</data>';
  } else if (ctx.request.accepts('json')) {
    ctx.response.type = 'json';
    ctx.response.body = { data: 'Hello World' };
  } else if (ctx.request.accepts('html')) {
    ctx.response.type = 'html';
    ctx.response.body = '<p>Hello World</p>';
  } else {
    ctx.response.type = 'text';
    ctx.response.body = 'Hello World';
  }
};

</pre><pre class="js">
app.use(async (ctx, next) => {
  await next();
  ctx.response.type = 'xml';
  ctx.response.body = fs.createReadStream('really_large.xml');
});

</pre><pre>
【 ctx.response.is(types...) 】
Very similar to ctx.request.is(). Check whether the response type is one of the supplied types. This is particularly useful for creating middleware that manipulate responses.

</pre>this is a middleware that minifies all HTML responses except for streams<pre class="js">
const minify = require('html-minifier');
app.use(async (ctx, next) => {
  await next();
  if (!ctx.response.is('html')) return;
  let body = ctx.body;
  if (!body || body.pipe) return;
  if (Buffer.isBuffer(body)) body = body.toString();
  ctx.body = minify(body);
});

</pre><pre>
【 ctx.response.redirect(url, [alt]) 】
Perform a [302] redirect to url.

The string "back" is special-cased to provide Referrer support, when Referrer is not present alt or "/" is used.
ctx.redirect('back');
ctx.redirect('back', '/index.html');
ctx.redirect('/login');
ctx.redirect('http://google.com');

To alter the default status of 302, simply assign the status before or after this call. To alter the body, assign it after this call:
ctx.status = 301;
ctx.redirect('/cart');
ctx.body = 'Redirecting to shopping cart';

【 ctx.response.attachment([filename], [options]) 】
Set Content-Disposition to "attachment" to signal the client to prompt for download. Optionally specify the filename of the download and some options

【 ctx.response.headerSent 】
Check if a response header has already been sent. Useful for seeing if the client may be notified on error.

【 ctx.response.lastModified 】
Return the Last-Modified header as a Date, if it exists.

【 ctx.response.lastModified= 】
Set the Last-Modified header as an appropriate UTC string. You can either set it as a Date or date string.
ctx.response.lastModified = new Date();

【 ctx.response.etag= 】
Set the ETag of a response including the wrapped "s. Note that there is no corresponding response.etag getter.
ctx.response.etag = crypto.createHash('md5').update(ctx.body).digest('hex');

【 ctx.response.vary(field) 】
Vary on field

【 response.flushHeaders() 】
Flush any set headers, and begin the body

</pre>
</div>

<div id="koa-middleware">
<h4>中间件</h4><pre>
Koa的最大特色也是最重要的一个设计就是中间件(middleware),就是在匹配路由之前和匹配路由之后执行函数

</pre>实现Logger(打印日志)功能最简单的写法就是在main函数里面增加一行<pre class="js">
const main = ctx => {
  console.log(`${Date.now()} ${ctx.request.method} ${ctx.request.url}`);
  ctx.response.body = 'Hello World';
};

</pre>上一个例子里面的Logger功能可以拆分成一个独立函数<pre class="js">
const logger = (ctx, next) => {
  console.log(`${Date.now()} ${ctx.request.method} ${ctx.request.url}`);
  next();
}
app.use(logger);

</pre><pre>
像上面代码中的logger函数就叫做"中间件"(middleware),因为它处在HTTP Request和HTTP Response中间,用来实现某种中间功能,app.use()用来加载中间件。

基本上Koa所有的功能都是通过中间件实现的,koa把很多async函数组成一个处理链,每个async函数都可以做一些自己的事情,然后用await next()来调用下一个async函数。把每个async函数称为middleware,这些middleware可以组合起来,完成很多有用的功能

每个中间件默认接受两个参数,第一个参数是Context对象,第二个参数是next函数,只要调用next函数就可以把执行权转交给下一个中间件,如果中间件内部没有调用next函数则执行权就不会传递下去

</pre>Middleware options<pre class="js">
function logger(format) {
  format = format || ':method ":url"';
  return async function (ctx, next) {
    const str = format.replace(':method', ctx.method).replace(':url', ctx.url);
    console.log(str);
    await next();
  };
}
app.use(logger());
app.use(logger(':method :url'));

</pre>async中间件开发<pre class="js">
// ./middleware/logger-async.js
function log( ctx ) {
    console.log( ctx.method, ctx.header.host + ctx.url )
}

module.exports = function () {
  return async function ( ctx, next ) {
    log(ctx);
    await next()
  }
}

// 使用
const Koa = require('koa') // koa v2
const loggerAsync  = require('./middleware/logger-async')
const app = new Koa()

app.use(loggerAsync())

app.use(( ctx ) => {
  ctx.body = 'hello world!'
})

app.listen(3000)
console.log('the server is starting at port 3000')

</pre><pre>
【 异步中间件 】
迄今为止所有例子的中间件都是同步的,不包含异步操作。如果有异步操作(比如读取数据库),中间件就必须写成async函数

</pre><pre class="js">
const Koa = require('koa');
const app = new Koa();

const main = async function (ctx, next) {
  ctx.response.type = 'html';
  ctx.response.body = await require('fs.promised').readFile('./demos/template.html', 'utf8'); // fs.promised模块
};

app.use(main);
app.listen(3000);

</pre>异步中间件的同步写法<pre class="js">
app.use((ctx, next) => {
  const start = Date.now();
  return next().then(() => {
    const ms = Date.now() - start;
    console.log(`${ctx.method} ${ctx.url} - ${ms}ms`);
  });
});

</pre>查看一个中间件的执行时间<pre class="js">
const Koa = require('koa');
const app = new Koa();

app.use(async (ctx, next) => {
  console.log(`${ctx.request.method} ${ctx.request.url}`);
  await next();
  const rt = ctx.response.get('X-Response-Time');
  console.log(`${ctx.method} ${ctx.url} - ${rt}`);
});

async function responseTime(ctx, next) {
  const start = Date.now();
  await next();
  const ms = Date.now() - start;
  ctx.set('X-Response-Time', `${ms}ms`);   // 设置自定义响应头
  console.log(`Time: ${ms}ms`);
}
app.use(responseTime);

// 对于任何请求,app将调用该异步函数处理请求
app.use(async (ctx, next) => {
  await next();                           // next是koa传入的将要处理的下一个异步函数,用await next();处理下一个异步函数
  ctx.response.type = 'text/html';        // 设置response的Content-Type
  ctx.response.body = '<h1>Hello, koa2!</h1>'; // 设置response的内容
});

app.listen(3000);  // 在端口3000监听:
console.log('app started at port 3000...');

</pre><pre class="js">
const fs = require('mz/fs');
app.use(async function (ctx, next) {
  const paths = await fs.readdir('docs');
  const files = await Promise.all(paths.map(path => fs.readFile(`docs/${path}`, 'utf8')));
  ctx.type = 'markdown';
  ctx.body = files.join('');
});

</pre><pre>
【 中间件栈 】
多个中间件会形成一个栈结构(middle stack),以"先进后出"(first-in-last-out)的顺序执行

1、最外层的中间件首先执行。
2、调用next函数,把执行权交给下一个中间件。
3、...
4、最内层的中间件最后执行。
5、执行结束后,把执行权交回上一层的中间件。
6、...
7、最外层的中间件收回执行权之后,执行next函数后面的代码。

</pre><pre class="js">
const one = (ctx, next) => {
  console.log('>> one');
  next();
  console.log('<< one');
}

const two = (ctx, next) => {
  console.log('>> two');
  next();
  console.log('<< two');
}

const three = (ctx, next) => {
  console.log('>> three');
  next();
  console.log('<< three');
}

app.use(one);
app.use(two);
app.use(three);

// 列出app所使用的中间件数组列表
console.log(app.middleware);  // [ [Function: one], [Function: two], [Function: three] ]

输出：
>> one
>> two
>> three
<< three
<< two
<< one

</pre><pre>
每收到一个http请求,koa就会调用通过app.use()注册的async函数,并传入ctx和next参数。

middleware的顺序很重要,也就是调用app.use()的顺序决定了middleware的顺序

如果一个middleware没有调用await next(),则后续的middleware将不再执行
检测用户权限的middleware可以决定是否继续处理请求,还是直接返回403错误

</pre><pre class="js">
app.use(async (ctx, next) => {
  if (await checkUserPermission(ctx)) {
    await next();
  } else {
    ctx.response.status = 403;
  }
});

</pre><pre>
【 中间件的合成 】
koa-compose内置模块可以将多个中间件合成为一个

koa中间件的执行顺序主要是Koa.js的一个中间件引擎 koa-compose模块来实现的,也就是Koa.js实现洋葱模型的核心引擎

</pre><pre class="js">
const compose = require('koa-compose');

const logger = (ctx, next) => {
  console.log(`${Date.now()} ${ctx.request.method} ${ctx.request.url}`);
  next();
}

const main = ctx => {
  ctx.response.body = 'Hello World';
};

const middlewares = compose([logger, main]);
app.use(middlewares);

</pre><pre class="js">
const compose = require('koa-compose');

async function random(ctx, next) {
  if ('/random' == ctx.path) {
    ctx.body = Math.floor(Math.random() * 10);
  } else {
    await next();
  }
};

async function backwards(ctx, next) {
  if ('/backwards' == ctx.path) {
    ctx.body = 'sdrawkcab';
  } else {
    await next();
  }
}

async function pi(ctx, next) {
  if ('/pi' == ctx.path) {
    ctx.body = String(Math.PI);
  } else {
    await next();
  }
}

const all = compose([random, backwards, pi]);
app.use(all);

</pre><pre>
【 中间件分类 】
1、应用级中间件:任何路由都会先经过应用级中间件,当执行完成next后再去匹配相应的路由

2、路由级中间件

3、第三方中间件:类似于koa-router、koa-bodyparser等

4、错误处理中间件
路由在匹配成功并执行完相应的操作后还会再次进入应用级中间件执行next之后的逻辑,所以对于404、500等错误可以在最外层的(第一个)应用级中间件的next之后做相应的处理。如果只有一个应用级中间件的话,顺序就无所谓所有路由中间件之前和之后了

</pre><pre class="js">
const Koa = require('koa');
const router = require('koa-router')();
const app = new Koa();

// 错误处理中间件
app.use(async (ctx, next)=> {
  await next();
  if(ctx.status === 404) ctx.body="404页面"
});

// 应用级中间件
app.use(async (ctx, next) => {
  await next();
})

router.get('/', async ctx => {
  ctx.body = 'hello koa';
})

// 路由匹配过程中,对于相同路由会从上往下依次执行中间件,直到最后一个没有next参数的中间件为止,以下3个路由依次打印111、222、333
router.get('/user', async (ctx, next) => {
  console.log(111)
  await next();
})

router.get('/user', async (ctx, next) => {
  console.log(222)
  await next();
})

router.get('/user', async ctx => {
  console.log(333)
  ctx.body = 'Hello'
})

app.use(router.routes()).use(router.allowedMethods());

app.listen(3000, err => {
  if (err) throw err;
  console.log('runing...')
})

</pre><pre>
【 中间件原理 】
洋葱模型可以看出,中间件的在await next()前后的操作很像数据结构的一种场景——“栈”,先进后出,同时又有统一上下文管理操作数据,综上所述可以总结出一下特性:
有统一context
操作先进后出
有控制先进后出的机制 next
有提前结束机制

需要的步骤:
中间件队列
处理中间件队列,并将上下文context传进去
中间件的流程控制器next
异常处理

根据分析中间的原理可以抽象出:
每一个中间件需要封装一个Promise
洋葱模型的先进后出操作,对应Promise.resolve的前后操作

</pre>单纯用Promise做个简单的实现<pre class="js">
let context = {
  data: []
};

async function middleware1(ctx, next) {
  console.log('action 001');
  ctx.data.push(1);
  await next();
  console.log('action 006');
  ctx.data.push(6);
}

async function middleware2(ctx, next) {
  console.log('action 002');
  ctx.data.push(2);
  await next();
  console.log('action 005');
  ctx.data.push(5);
}

async function middleware3(ctx, next) {
  console.log('action 003');
  ctx.data.push(3);
  await next();
  console.log('action 004');
  ctx.data.push(4);
}

Promise.resolve(middleware1(context, async () => {
  return Promise.resolve(middleware2(context, async () => {
    return Promise.resolve(middleware3(context, async () => {
      return Promise.resolve();
    }));
  }));
}))
.then(() => {
  console.log('end');
  console.log('context = ', context);
});

// 结果显示
// "action 001"
// "action 002"
// "action 003"
// "action 004"
// "action 005"
// "action 006"
// "end"
// "context = { data: [1, 2, 3, 4, 5, 6]}"

</pre>【 模拟koa2中间件 】<pre class="js">
class Koa2 {
  constructor() {
    this.middlewareList = []
  }
  // 核心方法,注册中间件函数
  use(fn) {
    this.middlewareList.push(fn)  // 存储所有的中间件函数
    return this                   // 实现链式操作如app.use(fn1).use(fn2).use(fn3)
  }
  // 将req、res组合成为ctx
  createContext(req, res) {
    const ctx = { req, res }      // 简单模拟koa的ctx
    return ctx
  }
  // 传入中间件列表,通过compose函数来组合中间件以及实现next机制,将中间件一个一个的串起来
  function compose(middlewareList) {
    // 返回一个函数,接收ctx
    return function (ctx) {

      // 定义一个派发器,这里面就实现了next机制
      function dispatch(i) {
        const fn = middlewareList[i]             // 获取当前中间件
        try {
          return Promise.resolve(                // 用Promise.resolve封装起来是为了保证函数执行的结果必须是Promise类型
            fn(ctx, dispatch.bind(null, i + 1))  // 通过i + 1获取下一个中间件,传递给next参数
          )
        } catch (err) {
          return Promise.reject(err)
        }
      }

      // 开始派发第一个中间件
      return dispatch(0)
    }
  }
  // 生成http.createServer需要的回调函数
  callback() {
    const fn = this.compose(this.middlewareList)
    return (req, res) => {
      const ctx = this.createContext(req, res)
      return fn(ctx)
    }
  }
  // 最后使用app.listen(3000)启动服务监听,可以转化为nodejs原生的http处理方式
  listen(...args) {
    const server = require('http').createServer(this.callback())
    return server.listen(...args);
  }
}
module.exports = Koa2

// test
const Koa = require('./koa2');
const app = new Koa();
// logger
app.use(async (ctx, next) => {
  await next();
  const rt = ctx['X-Response-Time'];
  console.log(`${ctx.req.method} ${ctx.req.url} - ${rt}`);
});
// x-response-time
app.use(async (ctx, next) => {
  const start = Date.now();
  await next();
  const ms = Date.now() - start;
  ctx['X-Response-Time'] = `${ms}ms`;
});
// response
app.use(async ctx => {
  ctx.res.end('hello world')
});
app.listen(8000);

</pre>
</div>

<div id="koa-router">
<h4>路由</h4><pre class="js">
const main = async (ctx, next) => {
  if (ctx.path === '/favicon.ico') return;
  await next();
}
app.use(main);

app.use(async (ctx, next) => {
  await next();
  if (!ctx.body) return;
})

app.use(async (ctx, next) => {
  await next();
  if (!ctx.body) ctx.throw(400, 'this page is not found!');;
})

// router.get('/favicon.ico', ctx => ctx.body = null);

// serve files from ./public,该目录下有表单页面index.html、404.html,koa-router会自动将/重定向到index.html,但是koa不会
app.use(serve(path.join(__dirname, '/public')));

</pre><pre>
【 原生路由 】
网站一般都有多个页面,通过ctx.request.path或ctx.request.url可以获取用户请求的路径,通过一定的判断或正则匹配就可以定制出所需要的路由
ctx.request.url === ctx.request.path

</pre><pre class="js">
const main = ctx => {
  if (ctx.request.path !== '/') {
    ctx.response.type = 'html';
    ctx.response.body = '< a href="/">Index Page< /a>';
  } else {
    ctx.response.body = 'Hello World';
  }
};

</pre>对不同的URL调用不同的处理函数返回不同的结果<pre class="js">
app.use(async (ctx, next) => {
  if (ctx.request.path === '/') {
    ctx.response.body = 'index page';
  } else {
    await next();
  }
});

app.use(async (ctx, next) => {
  if (ctx.request.path === '/test') {
    ctx.response.body = 'TEST page';
  } else {
    await next();
  }
});

app.use(async (ctx, next) => {
  if (ctx.request.path === '/error') {
    ctx.response.body = 'ERROR page';
  } else {
    await next();
  }
});

</pre><pre class="js">
const Koa = require('koa')
const fs = require('fs')
const app = new Koa()

// 用Promise封装异步读取文件方法
function render(page) {
  return new Promise((resolve, reject) => {
    fs.readFile(`./view/${page}`, "binary", (err, data) => err ? reject(err) : resolve(data))
  })
}

// 根据URL获取HTML内容
async function route(url) {
  let view = '404.html'
  switch (url) {
    case '/': view = 'index.html'; break;
    case '/index': view = 'index.html'; break;
    case '/todo': view = 'todo.html'; break;
    case '/404': view = '404.html'; break;
    default: break;
  }
  return await render(view)
}

app.use(async ctx => ctx.body = await route(ctx.request.url))

app.listen(3000)
console.log('[demo] route-simple is starting at port 3000')

</pre><pre>
【 重定向 】
有些场合服务器需要重定向redirect访问请求,比如用户登陆以后将他重定向到登陆前的页面。ctx.response.redirect()方法可以发出一个302跳转,将用户导向另一个路由

301和302重定向状态码区别:302为临时重定向,301永久重定向,Koa中默认为302

字符串“back”是特别提供Referrer支持的,当Referrer不存在时使用alt或/
ctx.redirect('back');
ctx.redirect('back', '/login');
ctx.redirect('/login');

要更改302的默认状态,只需在该调用之前或之后分配状态,要变更主体请在此调用之后:
ctx.status = 301;
ctx.redirect('/cart');
ctx.body = 'Redirecting to shopping cart';

</pre><pre class="js">
const redirect = ctx => {
  ctx.response.redirect('/');
  ctx.response.body = '< a href="/">Index Page< /a>';
};

app.use(route.get('/redirect', redirect));

</pre><pre>
【 koa-route模块 】
原生路由用起来不太方便,可以使用封装好的koa-route模块

</pre><pre class="js">
const route = require('koa-route');

const about = ctx => {
  ctx.response.type = 'html';
  ctx.response.body = '< a href="/">Index Page< /a>';
};

const main = ctx => {
  ctx.response.body = 'Hello World';
};

app.use(route.get('/', main));        // 根路径/的处理函数是main
app.use(route.get('/about', about));  // /about路径的处理函数是about

</pre><pre>
【 koa-router模块 】
npm i koa-router
引入koa-router这个middleware来处理URL映射

用router.get('/path', async fn)处理的是get请求
用router.post('/path', async fn)处理post请求
类似的put、delete、head请求也可以由router处理

用post请求处理URL时,post请求通常会发送一个表单或JSON作为request的body发送,但无论是Node.js提供的原始request对象还是koa提供的request对象都不提供解析request的body的功能,需要引入一个middleware koa-bodyparser来解析原始request请求,再把解析后的参数绑定到ctx.request.body
koa-bodyparser必须在router之前被注册到app对象上

</pre><pre class="js">
const Koa = require('koa');
// 直接调用的方式
const router = require('koa-router')();
// 或单独创建router的实例
const Router = require('koa-router');
const router = new Router();

router.get('/', async ctx => ctx.body = 'Hello Router')

// 启动路由,官方推荐方式,allowedMethods用在routes之后,作用是根据ctx.status设置response header
app.use(router.routes()).use(router.allowedMethods())

app.listen(3000, err => {
  if (err) throw err;
  console.log('runing...');
});

</pre><pre class="js">
const Koa = require('koa');
const router = require('koa-router')();       // require('koa-router')返回的是函数,函数调用
const bodyParser = require('koa-bodyparser');
const app = new Koa();

app.use(bodyParser());

app.use(async (ctx, next) => {
  console.log(`Process ${ctx.request.method} ${ctx.request.url}...`);
  await next();
});

// add url-route:
router.get('/hello/:name', async (ctx, next) => {
  var name = ctx.params.name;
  ctx.response.body = `<h1>Hello, ${name}!</h1>`;
});

// 注册一个GET请求
router.get('/about', async (ctx, next) => {
  ctx.response.body = '<h1>about</h1>';
});

router.get('/', async (ctx, next) => {
  ctx.response.body = `<h1>Index</h1>
    <form action="/signin" method="post">
      <p>Name: <input name="name" value="koa"></p>
      <p>Password: <input name="password" type="password"></p>
      <p><input type="submit" value="Submit"></p>
    </form>`;
});

router.post('/signin', async (ctx, next) => {
  var name = ctx.request.body.name || '';
  var password = ctx.request.body.password || '';
  console.log(`signin with name: ${name}, password: ${password}`);
  if (name === 'koa' && password === '12345') {
    ctx.response.body = `<h1>Welcome, ${name}!</h1>`;
  } else {
    ctx.response.body = `<h1>Login failed!</h1><p><a href="/">Try again</a></p>`;
  }
});

// add router middleware:
app.use(router.routes());

app.listen(3000);
console.log('app started at port 3000...');

</pre>子路由<pre class="js">
const Koa = require('koa')
const fs = require('fs')
const Router = require('koa-router')
const app = new Koa()

let home = new Router()

// 子路由1
home.get('/', async ctx => {
  ctx.body = `
    <ul>
      <li><a href="/page/helloworld">/page/helloworld</a></li>
      <li><a href="/page/404">/page/404</a></li>
    </ul>
  `
})

// 子路由2
let page = new Router()
page.get('/404', async ctx => ctx.body = '404 page!').get('/helloworld', async ctx => ctx.body = 'helloworld page!')

// 装载所有子路由
let router = new Router()
router.use('/', home.routes(), home.allowedMethods())
router.use('/page', page.routes(), page.allowedMethods())

// 加载路由中间件
app.use(router.routes()).use(router.allowedMethods())

app.listen(3000, () => console.log('[demo] route-use-middleware is starting at port 3000'))

</pre>路由控制器模块化<pre class="js">
// 模块/controllers/hello.js
var fn_hello = async (ctx, next) => {
  var name = ctx.params.name;
  ctx.response.body = `<h1>Hello, ${name}!</h1>`;
};

module.exports = {
  'GET /hello/:name': fn_hello
};

// 模块/controllers/index.js
var fn_index = async (ctx, next) => {
  ctx.response.body = `<p>＜a href="hello/koa">hello＜/a></p><p>＜a href="signin">signin＜/a></p>`;
};

module.exports = {
  'GET /': fn_index,
  'GET /index': fn_index
};

// 模块/controllers/signin.js
var get_signin = async (ctx, next) => {
  ctx.response.body = `<h1>signin</h1>
    ＜form action="/signin" method="post">
      <p>Name: <input name="name" value="koa"></p>
      <p>Password: <input name="password" type="password"></p>
      <p><input type="submit" value="Submit"></p>
    ＜/form>`;
};

var post_signin = async (ctx, next) => {
  var name = ctx.request.body.name || '';
  var password = ctx.request.body.password || '';
  console.log(`signin with name: ${name}, password: ${password}`);
  if (name === 'koa' && password === '12345') {
    ctx.response.body = `<h1>Welcome, ${name}!</h1>`;
  } else {
    ctx.response.body = `<h1>Login failed!</h1>
    <p>＜a href="/">Try again＜/a></p>`;
  }
};

module.exports = {
  'GET /signin': get_signin,
  'POST /signin': post_signin
};

// 模块/controller.js
// // 导入fs模块然后用readdirSync列出文件,这里可以用sync是因为启动时只运行一次,不存在性能问题
// var files = fs.readdirSync(__dirname + '/controllers');
// // 过滤出.js文件:
// var jsFiles = files.filter(f => f.endsWith('.js'));
// // 处理每个js文件:
// for (var f of jsFiles) {
//   console.log(`process controller: ${f}...`);
//   // 导入js文件:
//   let mapping = require(__dirname + '/controllers/' + f);
//   for (var url in mapping) {
//     if (url.startsWith('GET ')) {          // 如果url类似"GET xxx":
//       var path = url.substring(4);
//       router.get(path, mapping[url]);
//       console.log(`register URL mapping: GET ${path}`);
//     } else if (url.startsWith('POST ')) {  // 如果url类似"POST xxx":
//       var path = url.substring(5);
//       router.post(path, mapping[url]);
//       console.log(`register URL mapping: POST ${path}`);
//     } else {                                // 无效的URL:
//      console.log(`invalid URL: ${url}`);
//     }
//   }
// }

const fs = require('fs');

function addMapping(router, mapping) {
  for (var url in mapping) {
    if (url.startsWith('GET ')) {
      var path = url.substring(4);
      router.get(path, mapping[url]);
      console.log(`register URL mapping: GET ${path}`);
    } else if (url.startsWith('POST ')) {
      var path = url.substring(5);
      router.post(path, mapping[url]);
      console.log(`register URL mapping: POST ${path}`);
    } else {
      console.log(`invalid URL: ${url}`);
    }
  }
}

function addControllers(router) {
  var files = fs.readdirSync(__dirname + '/controllers');
  var jsFiles = files.filter(f => f.endsWith('.js'));
  for (var f of jsFiles) {
    console.log(`process controller: ${f}...`);
    let mapping = require(__dirname + '/controllers/' + f);
    addMapping(router, mapping);
  }
}

module.exports = function (dir) {
  let controllersDir = dir || 'controllers'; // 如果不传参数,扫描目录默认为'controllers'
  let router = require('koa-router')();
  addControllers(router, controllersDir);
  return router.routes();
};

// app.js
const Koa = require('koa');
const router = require('koa-router')();       // require('koa-router')返回的是函数,函数调用
const bodyParser = require('koa-bodyparser');
const app = new Koa();

app.use(bodyParser());

// log request URL:
app.use(async (ctx, next) => {
  console.log(`Process ${ctx.request.method} ${ctx.request.url}...`);
  await next();
});

const controller = require('./controller');  // 导入controller middleware
app.use(controller());                       // add router middleware

app.listen(3000);
console.log('app started at port 3000...');

</pre>
</div>

<div id="koa-error">
<h4>错误处理</h4><pre class="js">
// 如果代码运行过程中发生错误,需要把错误信息返回给用户,HTTP协定约定这时要返回500状态码,Koa提供了ctx.throw()方法用来抛出错误,ctx.throw(500)就是抛出500错误
const main = ctx => {
  ctx.throw(500);
};

// 如果将ctx.response.status设置成404,就相当于ctx.throw(404),返回404错误
const main = ctx => {
  ctx.response.status = 404;
  ctx.response.body = 'Page Not Found';
};

</pre><pre>
【 处理错误的中间件 】
为了方便处理错误,最好使用try...catch将其捕获,但是为每个中间件都写try...catch太麻烦,可以让最外层的中间件,负责所有中间件的错误处理

</pre><pre class="js">
app.use(async (ctx, next) => {
  try {
    await next();
  } catch (err) {
    err.status = err.statusCode || err.status || 500;
    throw err;
  }
});

</pre><pre class="js">
const handler = async (ctx, next) => {
  try {
    await next();
  } catch (err) {
    ctx.response.status = err.statusCode || err.status || 500;
    ctx.response.body = { message: err.message };
  }
};

const main = ctx => ctx.throw(500);

app.use(handler);
app.use(main);

</pre><pre>
【 error事件的监听 】
运行过程中一旦出错,Koa会触发一个error事件,监听这个事件也可以处理错误

</pre><pre class="js">
const main = ctx => ctx.throw(500);

app.on('error', (err, ctx) => console.error('server error', err));

</pre><pre>
【 释放error事件 】
如果错误被try...catch捕获就不会触发error事件,这时必须调用ctx.app.emit()手动释放error事件才能让监听函数生效

</pre>main函数抛出错误被handler函数捕获,catch代码块里使用ctx.app.emit()手动释放error事件才能让监听函数监听到<pre class="js">
const handler = async (ctx, next) => {
  try {
    await next();
  } catch (err) {
    ctx.response.status = err.statusCode || err.status || 500;
    ctx.response.type = 'html';
    ctx.response.body = '<p>Something wrong, please contact administrator.</p>';
    ctx.app.emit('error', err, ctx);
  }
};

const main = ctx => ctx.throw(500);
app.use(main);

app.use(async function() {
  throw new Error('boom boom');
});

app.on('error', function(err) {
  console.log('logging error ', err.message);
  console.log(err);
});

</pre>
</div>

<div id="koa-query-upload">
<h4>获取请求数据</h4><pre>
【 GET传值 】
Koa中GET传值通过request接收,有两种方式：
query：返回的是参数对象,{name: 'jack', age: 12}
querystring：返回的是请求字符串,name=jack&age=12

query和querystring可以从request中获取,也可以直接从ctx中获取。

</pre><pre class="js">
app.use( async ( ctx ) => {
  let url = ctx.url

  // 从上下文的request对象中获取
  let request = ctx.request
  let req_query = request.query
  let req_querystring = request.querystring

  // 从上下文中直接获取
  let ctx_query = ctx.query
  let ctx_querystring = ctx.querystring

  ctx.body = {url, req_query, req_querystring, ctx_query, ctx_querystring}
})

</pre><pre>
【 POST传值 】
通过post传递的值可以通过原生Node封装或通过第三方模块接收。

koa2没有封装获取POST请求参数的方法,需要通过解析上下文context中的原生node.js请求对象req,将POST表单数据解析成query string(例如：a=1&b=2&c=3),再将query string解析成JSON格式(例如：{"a":"1", "b":"2", "c":"3"})

ctx.request是context经过封装的请求对象,ctx.req是context提供的node.js原生HTTP请求对象,同理ctx.response是context经过封装的响应对象,ctx.res是context提供的node.js原生HTTP请求对象。

</pre>自定义封装<pre class="js">
module.exports = ctx => {
  return new Promise((resolve, reject) => {
    try {
      let data = '';
      ctx.req.on('data', chunk => data += chunk );              // ctx.req实际上就是原生node中的req
      ctx.req.on('end', () => resolve(require('querystring').parse(data)));// 事件监听的on可以改为addListener
    }catch(err) {
      reject(err);
    }
  })
}

</pre><pre class="js">
const Koa = require('koa')
const app = new Koa()

app.use( async ( ctx ) => {
  if (ctx.url === '/' && ctx.method === 'GET'){
    ctx.body = `
      <form method="POST" action="/">
        <p>userName</p> <input name="userName" /><br/>
        <p>nickName</p> <input name="nickName" /><br/>
        <p>email</p> <input name="email" /><br/>
        <button type="submit">submit</button>
      </form>
    `
  } else if (ctx.url === '/' && ctx.method === 'POST'){
    ctx.body = await parsePostData( ctx )
  } else {
    ctx.body = '<h1>404！！！ o(╯□╰)o</h1>'
  }
})

// 解析上下文里node原生请求的POST参数
function parsePostData( ctx ) {
  return new Promise((resolve, reject) => {
    try {
      let postdata = "";
      ctx.req.addListener('data', data => postdata += data)
      ctx.req.addListener("end", () => resolve(parseQueryStr(postdata))
    } catch ( err ) {
      reject(err)
    }
  })
}

// 将POST请求参数字符串解析成JSON,作用同require('querystring').parse(queryStr)
function parseQueryStr( queryStr ) {
  let queryData = {}
  let queryStrList = queryStr.split('&')
  console.log( queryStrList )
  for (let [ index, queryStr ] of queryStrList.entries()) {
    let itemList = queryStr.split('=')
    queryData[itemList[0]] = decodeURIComponent(itemList[1])
  }
  return queryData
}

app.listen(3000, () => console.log('[demo] request post is starting at port 3000'))

</pre><pre>
【 使用koa-bodyparser模块 】
npm install --save koa-bodyparser@3

用post请求处理URL时,post请求通常会发送一个表单或JSON作为request的body发送,但无论是Node.js提供的原始request对象还是koa提供的request对象都不提供解析request的body的功能

需要引入一个middleware koa-bodyparser来解析原始request请求,再把解析后的参数绑定到ctx.request.body
对于POST请求的处理,koa-bodyparser中间件可以把koa2上下文的formData数据解析到ctx.request.body中

koa-bodyparser必须在router之前被注册到app对象上

</pre><pre class="js">
const bodyParser = require('koa-bodyparser');
app.use(bodyParser());
console.log(ctx.request.body);   // 获取

</pre><pre class="js">
const Koa = require('koa')
const app = new Koa()
const bodyParser = require('koa-bodyparser')

app.use(bodyParser());   // 使用ctx.body解析中间件

app.use( async ctx => {
  if ( ctx.url === '/' && ctx.method === 'GET' ) {
    ctx.body = `
      <form method="POST" action="/">
        <p>userName</p> <input name="userName" /><br/>
        <p>nickName</p> <input name="nickName" /><br/>
        <p>email</p> <input name="email" /><br/>
        <button type="submit">submit</button>
      </form>`
  } else if ( ctx.url === '/' && ctx.method === 'POST' ) {
    ctx.body = ctx.request.body
  } else {
    ctx.body = '<h1>404！！！ o(╯□╰)o</h1>'
  }
})

app.listen(3000, () => console.log('[demo] request post is starting at port 3000'))

</pre><pre>
【 使用koa-body模块处理表单和上传文件 】
Web应用离不开处理表单,本质上表单就是POST方法发送到服务器的键值对,koa-body模块可用来从POST请求的数据体里面提取键值对

npm install koa-body

A full-featured koa body parser middleware. Supports multipart, urlencoded, and json request bodies. Provides the same functionality as Express's bodyParser - multer

使用koa-body代替koa-bodyparser和koa-multer
处理post请求使用的是koa-bodyparser,同时如果是图片上传使用的是koa-multer,但koa-multer和koa-route存在不兼容的问题

koa-body can handle three type requests:
multipart/form-data
application/x-www-urlencoded
application/json

koa-body Options
Options available for koa-body. Four custom options, and others are from raw-body and formidable.
1、patchNode {Boolean} Patch request body to Node's ctx.req, default false
将请求体打到原生node.js的ctx.req中

2、patchKoa {Boolean} Patch request body to Koa's ctx.request, default true
将请求体打到koa的ctx.request中

3、jsonLimit {String|Integer} The byte (if integer) limit of the JSON body, default 1mb

4、formLimit {String|Integer} The byte (if integer) limit of the form body, default 56kb

5、textLimit {String|Integer} The byte (if integer) limit of the text body, default 56kb

6、encoding {String} Sets encoding for incoming form fields,表单的默认编码, default utf-8

7、multipart {Boolean} Parse multipart bodies,是否支持multipart-formdate表单即上传文件, default false

8、urlencoded {Boolean} Parse urlencoded bodies,是否支持urlencoded的表单, default true

9、text {Boolean} Parse text bodies,是否解析text/plain的表单, default true

10、json {Boolean} Parse json bodies,是否解析json请求体, default true

11、jsonStrict {Boolean} Toggles co-body strict mode; if set to true - only parses arrays or objects,是否使用json 严格模式,true会只处理数组和对象, default true

12、includeUnparsed {Boolean} Toggles co-body returnRawBody option; if set to true, for form encodedand and JSON requests the raw, unparsed requesty body will be attached to ctx.reqeust.body using a Symbol, default false

13、formidable {Object} Options to pass to the formidable multipart parser,配置更多的关于multipart的选项

14、onError {Function} Custom error handle, if throw an error, you can customize the response - onError(error, context), default will throw

15、strict {Boolean} DEPRECATED If enabled, don't parse GET, HEAD, DELETE requests,严格模式,启用后不会解析  GET, HEAD, DELETE 请求, default true

16、parsedMethods {String[]} Declares the HTTP methods where bodies will be parsed, default ['POST', 'PUT', 'PATCH']. Replaces strict option.

formidable的相关配置参数
maxFields: 限制字段的数量,type: Integer, default 1000
maxFieldsSize: 限制字段的最大大小,type: Integer , default 2 * 1024 * 1024
uploadDir: 文件上传的文件夹,type: String, default os.tmpDir()
keepExtensions: 保留原来的文件后缀,type: Boolean, default false
hash: 如果要计算文件的hash则可以选择md5/sha1, type: String  , default false
multipart: 是否支持多文件上传,type: Boolean , default true
onFileBegin: 文件上传前的一些设置操作, type: Function, default function(name,file){}

</pre><pre class="js">
// 生成文件夹名称
function getUploadDirName(){
  const date = new Date();
  let month = Number.parseInt(date.getMonth()) + 1;
  month = month.toString().length > 1 ? month : `0${month}`;
  const dir = `${date.getFullYear()}${month}${date.getDate()}`;
  return dir;
}

// 检查文件夹路径是否存在,如果不存在则创建文件夹
const path = require('path');
const fs = require('fs');

function checkDirExist(p) {
  if (!fs.existsSync(p)) {
    fs.mkdirSync(p);
  }
}

// 获取文件的后缀,如果使用默认文件上传后的名字则不需要这个方法,因为koa-body配置formidable：{keepExtensions: true,}之后会直接保留原始的文件后缀
function getUploadFileExt(name) {
  let ext = name.split('.');
  return ext[ext.length - 1];
}

// 在onFileBegin中进行属性重赋值
app.use(koaBody({
  multipart:true,
  encoding:'gzip',
  formidable:{
    uploadDir:path.join(__dirname,'public/upload'),
    keepExtensions: true,            // 保留原始的文件后缀
    maxFieldsSize:2 * 1024 * 1024,
    // onFileBegin会传递两个参数,一个是name即表单的name属性传递过来的,而file是一个File类型的对象,其属性size:文件大小, path:文件上传的路径(不是最终的路径), name:文件的原始名称, type:文件类型, hash:如果配置了hash之后会有值, lastModifiedDate:最近修改时间
    onFileBegin:(name, file) => {
      const ext = getUploadFileExt(file.name);                                 // 获取文件后缀
      const dir = path.join(__dirname,`public/upload/${getUploadDirName()}`);  // 最终要保存到的文件夹目录
      checkDirExist(dir);                                                      // 检查文件夹不存在则新建文件夹
      const fileName = getUploadFileName(ext);                                 // 获取文件名称
      file.path = `${dir}/${fileName}`;                                        // 重新覆盖file.path属性
      app.context.uploadpath = app.context.uploadpath || {};
      app.context.uploadpath[name] = `${dirName}/${fileName}`;
    },
    onError: err => console.log(err)
  }
}));

router.post('/',async (ctx)=>{
  console.log(ctx.request.files);
  console.log(ctx.uploadpath);
  ctx.body = JSON.stringify(ctx.request.files);
});

</pre><pre class="js">
const Koa = require('koa');
const koaBody = require('koa-body');
const app = new Koa();

const main = async function(ctx) {
  const body = ctx.request.body;
  if (!body.name) ctx.throw(400, '.name required');
  ctx.body = { name: body.name };
};

app.use(koaBody());
app.use(main);
app.listen(3000);

$ curl -X POST --data "name=Jack" 127.0.0.1:3000
{"name":"Jack"}

$ curl -X POST --data "name" 127.0.0.1:3000
name required

</pre>koa-body模块用来处理文件上传,koa-static,koa-router<pre class="js">
const logger = require('koa-logger');
const fs        = require('fs');
const path      = require('path');
const Koa       = require('koa');
const app       = new Koa();
const router    = require('koa-router')();
const koaBody   = require('koa-body');
const serve     = require('koa-static');
const port      = process.env.PORT || 3000;
const host      = process.env.HOST || 'http://localhost';

// log requests
app.use(logger());

router.get('/favicon.ico', ctx => ctx.body = null);

// serve files from ./public,该目录下有表单页面index.html,404.html
app.use(serve(path.join(__dirname, '/public')));

// Accepts only urlencoded and json bodies.
router.post('/post/users', koaBody(), ctx => {
    const body = ctx.request.body;
    console.log('body', body); // => POST body object
    ctx.body = JSON.stringify(body, null, 2);
  }
);

// Accepts `multipart`, `json` and `urlencoded` bodies.
router.post('/post/upload', koaBody({ multipart: true, /*formidable: { uploadDir: __dirname + '/public' }*/ }), ctx => {
    const fields = ctx.request.body;         // 表单字段组成的对象,default { username: '', title: '' }
    const files = ctx.request.files || {};   // 上传的fileList对象,default undefined
    // files对象的upload属性名是input的name属性值
    // 上传一张图时files.upload是file对象,multiple="multiple"多图上传时files.upload是file对象数组
    console.log(JSON.stringify({fields, files}, null, 2));
    /*
    {
      "fields": {
        "username": "haha",
        "title": "new.jpg"
      },
      "files": {
        "uploads": [
          {
            "size": 153936,
            "path": "C:\\Users\\lenovo\\AppData\\Local\\Temp\\upload_387ea5d5b076865c46bc3341cdbf0387",
            "name": "1545334.jpg",
            "type": "image/jpeg",
            "mtime": "2019-06-19T16:35:24.668Z"
          },
          {
            "size": 70816,
            "path": "C:\\Users\\lenovo\\AppData\\Local\\Temp\\upload_ed31bc4c37c636fb7bcc30d571e9dcf8",
            "name": "liqin.jpg",
            "type": "image/jpeg",
            "mtime": "2019-06-19T16:35:24.703Z"
          }
        ]
      }
    }

    // 单图上传
    {
      "fields": {
        "username": "",
        "title": ""
      },
      "files": {
        "uploads": {
          "size": 371706,
          "path": "C:\\Users\\lenovo\\AppData\\Local\\Temp\\upload_c715798169ef7c3b69a657d23918a3eb",
          "name": "2323.jpg",
          "type": "image/jpeg",
          "mtime": "2019-06-19T16:44:19.308Z"
        }
      }
    }
    */

    const filePaths = [];
    const mimeType = {"image/gif":"gif","image/png":"png","image/jpeg":"jpg"}
    for (let key in files) {
      const file = files[key];
      const tmpdir = require('os').tmpdir();
      if(Array.isArray(file)){   // 多图上传
        file.forEach((item, index) => {
          const filePath = path.join(tmpdir, fields.title + mimeType[item.type]  || item.name);
          fs.createReadStream(item.path).pipe(fs.createWriteStream(filePath));
          filePaths.push(filePath);
        })
      }else{                    // 单图上传
        const filePath = path.join(tmpdir, fields.title + mimeType[file.type] || file.name);
        fs.createReadStream(file.path).pipe(fs.createWriteStream(filePath));
        filePaths.push(filePath);
      }
    }
    ctx.body = filePaths;
  }
)

// koa-body通过配置可自动实现文件上传,无须手动执行
router.post('/post/upload', koaBody({
  multipart: true,
  formidable: {
    uploadDir: __dirname + '/public',
    keepExtensions: true,
    onFileBegin:(name, file) => {
      file.path = __dirname + '/public' + `/${file.name}`;   // 重置file.path属性
      app.context.uploadpath = app.context.uploadpath || {};
      if(!app.context.uploadpath[name]) app.context.uploadpath[name] = [];
      app.context.uploadpath[name].push(file.path);
    },
    onError: err => console.log(err)
  }
}), ctx => {
    const fields = ctx.request.body;         // 表单字段组成的对象,default { username: '', title: '' }
    const files = ctx.request.files || {};   // 上传的fileList对象,default undefined
    // files对象的upload属性名是input的name属性值
    // 上传一张图时files.upload是file对象,multiple="multiple"多图上传时files.upload是file对象数组
    ctx.body = JSON.stringify({fields, files}, null, 2);
    console.log(ctx.uploadpath);
    /*
    {
      uploads:
      [
        'E:\\wamp64\\www\\study\\nodejs\\koa-module/public/12212.jpg',
        'E:\\wamp64\\www\\study\\nodejs\\koa-module/public/1545334.jpg'
      ]
    }
    */
  }
)

app.use(router.routes());
app.listen(port, () => console.log(`server is starting at port ${port}`));

console.log('Visit %s:%s/ in browser.', host, port);
console.log();
console.log('Test with executing this commands:');
console.log('curl -i %s:%s/post/users -d "user=admin"', host, port);
console.log('curl -i %s:%s/post/upload -F "uploads=@%s"', host, port, __dirname + '/path/to/file');
// ["C:\\Users\\lenovo\\AppData\\Local\\Temp\\9.jpg"]
console.log('curl -i %s:%s/post/upload -F "uploads=@%s" -F "newname=%s"', host, port, "9.jpg", "hello.jpg");
// ["C:\\Users\\lenovo\\AppData\\Local\\Temp\\hello.jpg"]
console.log('curl -i %s:%s/post/upload -F upload=@9.jpg -F upload=@10.jpg -F "newname=hello.jpg"', host, port);
// ["C:\\Users\\lenovo\\AppData\\Local\\Temp\\hello-0.jpg","C:\\Users\\lenovo\\AppData\\Local\\Temp\\hello-1.jpg"]
console.log();
console.log('Press CTRL+C to stop...');
console.log();

/* public/index.html */
<form action="/post/upload" enctype="multipart/form-data" method="post">
  <input type="text" name="username" placeholder="username"><br><br>
  <input type="text" name="title" placeholder="title of file"><br><br>
  <input type="file" name="uploads" accept="image/png,image/gif,image/jpeg" multiple="multiple"><br><br>
  <button type="submit">Upload</button>
</form>

</pre><pre class="js">
const log     = console.log;
const Koa     = require('koa');
const app     = new Koa();
const koaBody = require('../index');
const port    = process.env.PORT || 4290;
const host    = 'http://localhost';

app
  .use(koaBody({
    multipart: true,
    formLimit: 15,
    formidable: {
      uploadDir: __dirname + '/uploads'
    }
  }))
  .use((ctx) => {
    if (ctx.request.method === 'POST') {
      log(ctx.request.body);
      // => POST body object
      ctx.body = JSON.stringify(ctx.request.body, null, 2);
    }
  })
  .listen(port);


log('Visit %s:%s/ in browser.', host, port);
log();
log('Test with executing this commands:');
log('curl -i %s:%s/whatever -d "name=charlike"', host, port);
log('curl -i %s:%s/whatever -d "name=some-long-name-for-error"', host, port);
log('curl -i %s:%s/whatever -F "source=@%s/avatar.png"', host, port, __dirname);
log();
log('Press CTRL+C to stop...');

</pre>koa-body和koa-static上传文件<pre class="js">
const serve = require('koa-static');
const koaBody = require('koa-body');
const fs = require('fs');
const os = require('os');
const path = require('path');
const Koa = require('koa');
const app = new Koa();

app.use(koaBody({ multipart: true }));

// custom 404
app.use(async function(ctx, next) {
  await next();
  if (ctx.body || !ctx.idempotent) return;   // post请求且有响应内容则忽略,否则重定向到404页面
  ctx.redirect('/404.html');
});

// serve files from ./public,该目录下有index.html,404.html
app.use(serve(path.join(__dirname, '/public')));

// handle uploads
app.use(async function(ctx, next) {
  if ('POST' != ctx.method) return await next();  // ignore non-POSTs
  console.log(ctx.request.files);
  const file = ctx.request.files.file;
  const stream = fs.createWriteStream(path.join(require('os').tmpdir(), file.name));
  fs.createReadStream(file.path).pipe(stream);
  console.log('uploading %s -> %s', file.name, stream.path);
  ctx.redirect('/');
});

app.listen(3000, () => console.log('listening on port 3000'));

</pre><pre>
【 busboy模块解析POST请求 】
npm install --save busboy
busboy模块是用来解析POST请求,node原生req中的文件流,busboy是用来解析出请求中文件流

</pre><pre class="js">
const inspect = require('util').inspect
const path = require('path')
const fs = require('fs')
const Busboy = require('busboy')

// req为node原生请求
const busboy = new Busboy({ headers: req.headers })

// ...

// 监听文件解析事件
busboy.on('file', function(fieldname, file, filename, encoding, mimetype) {
  console.log(`File [${fieldname}]: filename: ${filename}`)
  file.pipe(fs.createWriteStream('./upload'));                                           // 文件保存到特定路径
  file.on('data', data => console.log(`File [${fieldname}] got ${data.length} bytes`));  // 开始解析文件流
  file.on('end', () => console.log(`File [${fieldname}] Finished`));                     // 解析文件结束
})

// 监听请求中的字段
busboy.on('field', function(fieldname, val, fieldnameTruncated, valTruncated) {
  console.log(`Field [${fieldname}]: value: ${inspect(val)}`)
})

// 监听结束事件
busboy.on('finish', function() {
  console.log('Done parsing form!')
  res.writeHead(303, { Connection: 'close', Location: '/' })
  res.end()
})
req.pipe(busboy)

</pre>busboy上传文件简单实现<pre class="js">
const inspect = require('util').inspect
const path = require('path')
const os = require('os')
const fs = require('fs')
const Busboy = require('busboy')

// 同步创建文件目录
function mkdirsSync( dirname ) {
  if (fs.existsSync( dirname )) {
    return true
  } else {
    if (mkdirsSync( path.dirname(dirname)) ) {
      fs.mkdirSync( dirname )
      return true
    }
  }
}

// 获取上传文件的后缀名
function getSuffixName( fileName ) {
  let nameList = fileName.split('.')
  return nameList[nameList.length - 1]
}

// 上传文件,options 文件上传参数 fileType文件类型, path文件存放路径
function uploadFile( ctx, options) {
  let req = ctx.req
  let res = ctx.res
  let busboy = new Busboy({headers: req.headers})

  let fileType = options.fileType || 'common';       // 获取类型,common or album
  let filePath = path.join( options.path, fileType)
  let mkdirResult = mkdirsSync( filePath )

  return new Promise((resolve, reject) => {
    console.log('文件上传中...')
    let result = { success: false, formData: {}}

    // 解析请求文件事件
    busboy.on('file', function(fieldname, file, filename, encoding, mimetype) {
      let fileName = Math.random().toString(16).substr(2) + '.' + getSuffixName(filename)
      let _uploadFilePath = path.join( filePath, fileName )
      let saveTo = path.join(_uploadFilePath)
      file.pipe(fs.createWriteStream(saveTo));  // 文件保存到制定路径
      file.on('end', () => {                    // 文件写入事件结束
        result.success = true
        result.message = '文件上传成功'
        console.log('文件上传成功！')
        resolve(result)
      })
    })

    // 解析表单中其他字段信息
    busboy.on('field', function(fieldname, val, fieldnameTruncated, valTruncated, encoding, mimetype) {
      console.log('表单字段数据 [' + fieldname + ']: value: ' + inspect(val));
      result.formData[fieldname] = inspect(val);
    });

    // 解析结束事件
    busboy.on('finish', function( ) {
      console.log('文件上结束')
      resolve(result)
    })

    // 解析错误事件
    busboy.on('error', function(err) {
      console.log('文件上出错')
      reject(result)
    })
    req.pipe(busboy)
  })
}

module.exports =  { uploadFile }

/* 入口文件 */
const Koa = require('koa')
const path = require('path')
const app = new Koa()
// const bodyParser = require('koa-bodyparser')

const {uploadFile} = require('./util/upload')

// app.use(bodyParser())

app.use(async ctx => {
  if (ctx.url === '/' && ctx.method === 'GET'){
    ctx.body = `
      <form method="POST" action="/upload.json" enctype="multipart/form-data">
        <p>file upload</p>
        <span>picName:</span><input name="picName" type="text" /><br/>
        <input name="file" type="file" /><br/><br/>
        <button type="submit">submit</button>
      </form>
    `
  } else if ( ctx.url === '/upload.json' && ctx.method === 'POST' ) {
    let result = { success: false }
    let serverFilePath = path.join( __dirname, 'upload-files' )
    result = await uploadFile( ctx, {          // 上传文件事件
      fileType: 'album',                       // common or album
      path: serverFilePath
    })
    ctx.body = result
  } else {
    ctx.body = '<h1>404！！！ o(╯□╰)o</h1>'
  }
})

app.listen(3000, () => console.log('[demo] upload-simple is starting at port 3000'))

</pre>异步上传图片实现<pre class="js">
├── index.js # 后端启动文件
├── node_modules
├── package.json
├── static # 静态资源目录
│   ├── image # 异步上传图片存储目录
│   └── js
│       └── index.js # 上传图片前端js操作
├── util
│   └── upload.js # 后端处理图片流操作
└── view
    └── index.ejs # ejs后端渲染模板

/* 后端代码 */
/* 入口文件 demo/upload-async/index.js */
const Koa = require('koa')
const views = require('koa-views')
const path = require('path')
const convert = require('koa-convert')
const static = require('koa-static')
const { uploadFile } = require('./util/upload')

const app = new Koa()

// 使用第三方中间件 start
app.use(views(path.join(__dirname, './view'), { extension: 'ejs' }))
const staticPath = './static';    // 静态资源目录对于相对入口文件index.js的路径
app.use(convert(static( path.join( __dirname,  staticPath) ))); // koa-static目前不支持koa2,所以只能用koa-convert封装一下
// 使用第三方中间件 end

app.use( async ( ctx ) => {
  if ( ctx.method === 'GET' ) {
    await ctx.render('index', { title: 'upload pic async' })
  } else if ( ctx.url === '/api/picture/upload.json' && ctx.method === 'POST' ) {
    // 上传文件请求处理
    let result = { success: false }
    let serverFilePath = path.join( __dirname, 'static/image' )
    // 上传文件事件
    result = await uploadFile( ctx, { fileType: 'album', path: serverFilePath })
    ctx.body = result
  } else {
    ctx.body = '<h1>404！！！ o(╯□╰)o</h1>'
  }
})

app.listen(3000, () => console.log('[demo] upload-pic-async is starting at port 3000'))

/* 后端上传图片流写操作 入口文件 demo/upload-async/util/upload.js */
const inspect = require('util').inspect
const path = require('path')
const os = require('os')
const fs = require('fs')
const Busboy = require('busboy')

// 同步创建文件目录
function mkdirsSync( dirname ) {
  if (fs.existsSync( dirname )) {
    return true
  } else {
    if (mkdirsSync( path.dirname(dirname)) ) {
      fs.mkdirSync( dirname )
      return true
    }
  }
}

// 获取上传文件的后缀名
function getSuffixName( fileName ) {
  let nameList = fileName.split('.')
  return nameList[nameList.length - 1]
}

// 上传文件, options 文件上传参数 fileType文件类型, path文件存放路径
function uploadFile( ctx, options) {
  let req = ctx.req
  let res = ctx.res
  let busboy = new Busboy({headers: req.headers})
  let fileType = options.fileType || 'common';   // 获取类型
  let filePath = path.join( options.path,  fileType)
  let mkdirResult = mkdirsSync( filePath )
  return new Promise((resolve, reject) => {
    console.log('文件上传中...')
    let result = { success: false, message: '', data: null }

    // 解析请求文件事件
    busboy.on('file', function(fieldname, file, filename, encoding, mimetype) {
      let fileName = Math.random().toString(16).substr(2) + '.' + getSuffixName(filename)
      let _uploadFilePath = path.join( filePath, fileName )
      let saveTo = path.join(_uploadFilePath)

      file.pipe(fs.createWriteStream(saveTo));   // 文件保存到制定路径

      // 文件写入事件结束
      file.on('end', function() {
        result.success = true
        result.message = '文件上传成功'
        result.data = { pictureUrl: `//${ctx.host}/image/${fileType}/${fileName}` }
        console.log('文件上传成功！')
        resolve(result)
      })
    })

    // 解析结束事件
    busboy.on('finish', function( ) {
      console.log('文件上结束')
      resolve(result)
    })

    // 解析错误事件
    busboy.on('error', function(err) {
      console.log('文件上出错')
      reject(result)
    })

    req.pipe(busboy)
  })
}

module.exports =  { uploadFile }

/* 前端代码 */
<button class="btn" id="J_UploadPictureBtn">上传图片</button>
<hr/>
<p>上传进度<span id="J_UploadProgress">0</span>%</p>
<p>上传结果图片</p>
<div id="J_PicturePreview" class="preview-picture"></div>

< script src="/js/index.js">< /script>
// 上传操作代码
(function(){
  let btn = document.getElementById('J_UploadPictureBtn')
  let progressElem = document.getElementById('J_UploadProgress')
  let previewElem = document.getElementById('J_PicturePreview')
  btn.addEventListener('click', function(){
    uploadAction({
      success: function( result ) {
        console.log( result )
        if ( result && result.success && result.data && result.data.pictureUrl ) {
          previewElem.innerHTML = '< img src="'+ result.data.pictureUrl +'" style="max-width: 100%">'
        }
      },
      progress: function( data ) {
        if ( data && data * 1 > 0 ) progressElem.innerText = data
      }
    })
  })

  // 类型判断
  let UtilType = {
    isPrototype: data => Object.prototype.toString.call(data).toLowerCase(),
    isJSON: function( data ) {
      return this.isPrototype( data ) === '[object object]';
    },
    isFunction: function( data ) {
      return this.isPrototype( data ) === '[object function]';
    }
  }

  // form表单上传请求事件
  function requestEvent( options ) {
    try {
      let formData = options.formData
      let xhr = new XMLHttpRequest()
      xhr.onreadystatechange = function() {
        if ( xhr.readyState === 4 && xhr.status === 200 ) {
          options.success(JSON.parse(xhr.responseText))
        }
      }

      xhr.upload.onprogress = function(evt) {
        let loaded = evt.loaded
        let tot = evt.total
        let per = Math.floor(100 * loaded / tot)
        options.progress(per)
      }
      xhr.open('post', '/api/picture/upload.json')
      xhr.send(formData)
    } catch ( err ) {
      options.fail(err)
    }
  }

  // 上传事件
  function uploadEvent ( options ){
    let file
    let formData = new FormData()
    let input = document.createElement('input')
    input.setAttribute('type', 'file')
    input.setAttribute('name', 'files')

    input.click()
    input.onchange = function () {
      file = input.files[0]
      formData.append('files', file)
      requestEvent({
        formData,
        success: options.success,
        fail: options.fail,
        progress: options.progress
      })
    }
  }

  // 上传操作
  function uploadAction( options ) {
    if ( !UtilType.isJSON( options ) ) {
      console.log( 'upload options is null' )
      return
    }
    let _options = {}
    _options.success = UtilType.isFunction(options.success) ? options.success : function() {}
    _options.fail = UtilType.isFunction(options.fail) ? options.fail : function() {}
    _options.progress = UtilType.isFunction(options.progress) ? options.progress : function() {}

    uploadEvent(_options)
  }
})()

</pre>
</div>

<div id="koa-static">
<h4>静态资源</h4><pre>
一个http请求访问web服务静态资源,一般响应结果有三种情况
访问文本,例如js,css,png,jpg,gif
访问静态目录
找不到资源,抛出404错误

</pre>原生koa2实现静态资源服务器<pre class="js">
├── static # 静态资源目录
│   ├── css/
│   ├── image/
│   ├── js/
│   └── index.html
├── util # 工具代码
│   ├── content.js # 读取请求内容
│   ├── dir.js # 读取目录内容
│   ├── file.js # 读取文件内容
│   ├── mimes.js # 文件类型列表
│   └── walk.js # 遍历目录内容
└── index.js # 启动入口文件

/* index.js */
const Koa = require('koa')
const path = require('path')
const content = require('./util/content')
const mimes = require('./util/mimes')

const app = new Koa()

const staticPath = './static';  // 静态资源目录对于相对入口文件index.js的路径

// 解析资源类型
function parseMime(url) {
  let extName = path.extname( url )
  extName = extName ? extName.slice(1) : 'unknown'
  return  mimes[extName]
}

app.use( async ctx => {
  let fullStaticPath = path.join(__dirname, staticPath);  // 静态资源目录在本地的绝对路径
  let _content = await content(ctx, fullStaticPath );     // 获取静态资源内容,有可能是文件内容、目录或404
  let _mime = parseMime(ctx.url);                         // 解析请求内容的类型
  if (_mime) ctx.type = _mime;                            // 如果有对应的文件类型,就配置上下文的类型

  // 输出静态资源内容
  if (_mime && _mime.indexOf('image/') >= 0) {            // 如果是图片则用node原生res输出二进制数据,其他则输出文本
    ctx.res.writeHead(200)
    ctx.res.write(_content, 'binary')
    ctx.res.end()
  } else {
    ctx.body = _content
  }
})

app.listen(3000, () => console.log('[demo] static-server is starting at port 3000'))

/* util/content.js */
const path = require('path')
const fs = require('fs')
const dir = require('./dir');   // 封装读取目录内容方法
const file = require('./file'); // 封装读取文件内容方法

// 获取静态资源内容
async function content( ctx, fullStaticPath ) {
  let reqPath = path.join(fullStaticPath, ctx.url);  // 封装请求资源的完绝对径
  let exist = fs.existsSync( reqPath );              // 判断请求路径是否为存在目录或者文件
  let content = ''
  if(!exist) {                                       // 如果请求路径不存在则返回404
    content = '404 Not Found! o(╯□╰)o！'
  } else {
    let stat = fs.statSync(reqPath);                 // 判断访问地址是文件夹还是文件
    if(stat.isDirectory()) {
      content = dir(ctx.url, reqPath);               // 如果为目录则渲读取目录内容
    } else {
      content = await file( reqPath );               // 如果请求为文件则读取文件内容
    }
  }
  return content
}

module.exports = content

/* util/dir.js */
const url = require('url')
const fs = require('fs')
const path = require('path')
const walk = require('./walk');       // 遍历读取目录内容方法

// 封装目录内容
function dir (url, reqPath) {
  let contentList = walk( reqPath );  // 遍历读取当前目录下的文件、子目录
  let html = `<ul>`
  for ( let [ index, item ] of contentList.entries() ) {
    html = `${html}<li><a href="${url === '/' ? '' : url}/${item}">${item}</a>`
  }
  html = `${html}</ul>`
  return html
}

module.exports = dir

/* util/file.js */
const fs = require('fs')

// 读取文件方法
function file ( filePath ) {
  let content = fs.readFileSync(filePath, 'binary' )
  return content
}

module.exports = file

/* util/walk.js */
const fs = require('fs')
const mimes = require('./mimes')

// 遍历读取目录内容(子目录,文件名)
function walk( reqPath ){
  let files = fs.readdirSync( reqPath );
  let dirList = [], fileList = [];
  for( let i=0, len=files.length; i< len; i++ ) {
    let item = files[i];
    let itemArr = item.split("\.");
    let itemMime = ( itemArr.length > 1 ) ? itemArr[ itemArr.length - 1 ] : "undefined";
    if( typeof mimes[ itemMime ] === "undefined" ) {
      dirList.push( files[i] );
    } else {
      fileList.push( files[i] );
    }
  }
  return dirList.concat( fileList );
};

module.exports = walk;

/* util/mime.js */
let mimes = {
  'css': 'text/css',
  'less': 'text/css',
  'gif': 'image/gif',
  'html': 'text/html',
  'ico': 'image/x-icon',
  'jpeg': 'image/jpeg',
  'jpg': 'image/jpeg',
  'js': 'text/javascript',
  'json': 'application/json',
  'pdf': 'application/pdf',
  'png': 'image/png',
  'svg': 'image/svg+xml',
  'swf': 'application/x-shockwave-flash',
  'tiff': 'image/tiff',
  'txt': 'text/plain',
  'wav': 'audio/x-wav',
  'wma': 'audio/x-ms-wma',
  'wmv': 'video/x-ms-wmv',
  'xml': 'text/xml'
}

module.exports = mimes

</pre><pre>
【 koa-static中间件 】
如果网站提供静态资源如图片、字体、样式表、脚本deng,没必要很麻烦为它们一个个写路由,koa-static模块封装了这部分的请求,koa-static处理完静态资源之后不再将请求传递给下一个中间件,默认会处理/favicon.ico,

npm i koa-static
app.use(require('koa-static')(root, opts));

Options
1、maxage： Browser cache max-age in milliseconds. defaults to 0
2、hidden： Allow transfer of hidden files. defaults to false
3、index： Default file name, defaults to 'index.html'
4、defer： If true, serves after return next(), allowing any downstream middleware to respond first.
5、gzip： Try to serve the gzipped version of a file automatically when gzip is supported by a client and if the requested file with .gz extension exists. defaults to true.
6、br： Try to serve the brotli version of a file automatically when brotli is supported by a client and if the requested file with .br extension exists (note, that brotli is only accepted over https). defaults to true.
7、setHeaders： Function to set custom headers on response.
8、extensions： Try to match extensions from passed array to search for file when no extension is sufficed in URL. First found is served. (defaults to false)

配置静态资源目录为static的4种方式:
app.use(require('koa-static')('static'))
app.use(require('koa-static')('./static'))
app.use(require('koa-static')(__dirname + '/static'))
app.use(require('koa-static')(path.join(__dirname, 'static'))); // static前的/可加可不加,该方法会内部会做处理

app.use(serve('.'));                          // $ GET /package.json
app.use(serve('test/fixtures'));              // $ GET /hello.txt
app.use(serve(__dirname + '/test/fixtures')); // or use absolute paths

在模板中即可访问：
< link rel="stylesheet" href="/css/header.css">
< img src="/image/account.eb695dc.png"/>

</pre><pre class="js">
const Koa = require('koa')
const path = require('path')
const static = require('koa-static')
const app = new Koa()
app.use(static('.'))                                // 处理/favicon.ico,favicon.ico放根目录
const staticPath = './static';                      // 静态资源目录对于相对入口文件index.js的路径
app.use(static(path.join( __dirname,  staticPath))) // 处理其他静态资源
app.use( async ( ctx ) => ctx.body = 'hello world')
app.listen(3000, () => console.log('[demo] static-use-middleware is starting at port 3000'))

</pre><pre>
【 serve-favicon中间件 】
var favicon = require('serve-favicon');
// uncomment after placing your favicon in /public
app.use(favicon(path.join(__dirname, 'public', 'favicon.ico')));

</pre>
</div>

<div id="koa-template">
<h3>网页模板</h3><pre>
实际开发中返回给用户的网页往往都写成模板文件,可以让Koa先读取模板文件,然后将这个模板返回给用户

</pre><pre class="js">
const main = ctx => {
  ctx.response.type = 'html';
  ctx.response.body = require('fs').createReadStream('./demos/template.html');
};

</pre>

<h3>模板引擎 Nunjucks</h3><pre>
模板引擎就是基于模板配合数据构造出字符串输出的一个组件

模板引擎最常见的输出就是输出网页即HTML文本,也可以输出任意格式的文本如Text,XML,Markdown等
Js的模板字符串可以实现模板功能,但是必须写在js代码中,要想写出复杂的页面非常困难

koa生态的模板引擎挺多的,比如ejs、art-template等,性能上art-template比ejs快很多,开发中用的最多的还是art-template

【 koa-ejs中间件模块 】
npm i koa-ejs
Koa ejs view render middleware. support all feature of ejs

Features:
Control flow with <% %>
Escaped output with <%= %> (escape function configurable)
Unescaped raw output with <%- %>
Newline-trim mode ('newline slurping') with -%> ending tag
Whitespace-trim mode (slurp all whitespace) for control flow with <%_ _%>
Custom delimiters (e.g., use <? ?> instead of <% %>)
Includes
Client-side support
Static caching of intermediate JavaScript
Static caching of templates
Complies with the Express view system

syntax：
<% 'Scriptlet' tag, for control-flow, no output
<%_ 'Whitespace Slurping' Scriptlet tag, strips all whitespace before it
<%= Outputs the value into the template (escaped)
<%- Outputs the unescaped value into the template
<%# Comment tag, no execution, no output
<%% Outputs a literal '<%'
%%> Outputs a literal '%>'
%> Plain ending tag
-%> Trim-mode ('newline slurp') tag, trims following newline
_%> 'Whitespace Slurping' ending tag, removes all whitespace after it

</pre><pre class="js">
const Koa = require('koa');
const render = require('koa-ejs');
const path = require('path');
const app = new Koa();

// 配置
render(app, {
  root: path.join(__dirname, 'view'),  // 视图根目录view
  layout: 'template',                  // global layout file, default is layout, set false to disable layou
  viewExt: 'html',                     // view file extension, default html
  cache: false,                        // cache compiled templates, default true
  debug: true                          // 如果开启debug模式则会在终端实时打印信息,default false
  delimiter: %,                        // character to use with angle brackets for open / close, default %
  async: false                         // When true, EJS will use an async function for rendering, Depends on async/await support in the JS runtime
});

// ejs support ctx.state in koa
app.use(function (ctx, next) {
  ctx.state = ctx.state || {};
  ctx.state.now = new Date();
  ctx.state.ip = ctx.ip;
  ctx.state.version = '2.0.0';
  return next();
});

app.use(async function (ctx) {
  const users = [{ name: 'Dead Horse' }, { name: 'Jack' }, { name: 'Tom' }];
  await ctx.render('content', { users });
  // await ctx.render('content');
  // await ctx.render(str, data, options); // Rendered HTML string
  // renderFile(filename, data, options, function(err, str){}); // str => Rendered HTML string
});

if (process.env.NODE_ENV === 'test') {
  module.exports = app.callback();
} else {
  app.listen(7001, () => console.log('open http://localhost:7001'));
}

app.on('error', err => console.log(err.stack));

/* view/template.html */
< html>
< head>
< title>koa ejs< /title>
< /head>
< body>
  <%- body %>
< /body>
< /html>

/* view/content.html */
<div>
  <p>request ip is: <%= ip %></p>
  <% include user.html %>
</div>

/* view/user.html */
<ul>
  <% if (users) { %>
    <% users.forEach(function (user) {%>
      <li><%= user.name %></li>
    <% })%>
  <% }%>
</ul>

/* view/async.html */
<%= await sayHello('Jack') %>

</pre><pre>
【 art-template中间件模块 】
npm install --save art-template
npm install --save koa-art-template

配置
const render = require('koa-art-template');

// 配置模板引擎
render(app, {
  root: path.join(__dirname, 'views'), // 视图目录
  extname: '.html',
  debug: process.env.NODE_ENV !== 'production'
});

使用方式和ejs一样
await ctx.render(templateName [, data]);

</pre><pre class="js">
// 模板引擎函数：替换模板字符串中的变量
function examResult (data) {
  return `${data.name}同学一年级期末考试语文${data.chinese}分,数学${data.math}分,位于年级第${data.ranking}名。`
}

examResult({
  name: '小明',
  chinese: 78,
  math: 87,
  ranking: 999
});

</pre><pre>
输出HTML有几个特别重要的问题需要考虑：

转义
对特殊字符要转义,避免受到XSS攻击。比如变量name的值不是小明,而是小明< script >...< /script >,模板引擎输出的HTML到了浏览器就会自动执行恶意JavaScript代码

格式化
对不同类型的变量要格式化,比如货币需要变成12,345.00的格式,日期需要变成2016-01-01这样的格式

简单逻辑
模板还需要能执行一些简单逻辑,比如要按条件输出内容

【 Nunjucks > npm i -s nunjucks 】
Nunjucks是Mozilla开发的一个纯Js编写的模板引擎,既可以用在Node环境下,又可以运行在浏览器端,但主要还是运行在Node环境下,因为浏览器端有更好的模板解决方案,例如MVVM框架(Vue.js)

function render(view, model) {
  // TODO:...
}
view是模板的名称(又称为视图),因为可能存在多个模板,需要选择其中一个
model就是数据,在Js中就是一个简单的Object,用来渲染模板
render函数返回一个字符串,就是模板的html输出

模板引擎是可以独立使用的,并不需要依赖koa

Nunjucks模板引擎最强大的功能在于模板的继承
子模板可以有选择地对块进行重新定义,没有重定义则使用父模板的内容

Nunjucks的性能
对于模板渲染本身来说,速度是非常非常快的,因为就是拼字符串嘛,纯CPU操作。
性能问题主要出现在从文件读取模板内容这一步。这是一个IO操作,在Node.js环境中,我们知道,单线程的JavaScript最不能忍受的就是同步IO,但Nunjucks默认就使用同步IO读取模板文件。
好消息是Nunjucks会缓存已读取的文件内容,也就是说,模板文件最多读取一次,就会放在内存中,后面的请求是不会再次读取文件的,只要我们指定了noCache: false这个参数。
在开发环境下,可以关闭cache,这样每次重新加载模板,便于实时修改模板。在生产环境下,一定要打开cache,这样就不会有性能问题。
Nunjucks也提供了异步读取的方式,但是这样写起来很麻烦,有简单的写法我们就不会考虑复杂的写法。保持代码简单是可维护性的关键

</pre><pre class="js">
const nunjucks = require('nunjucks');

function createEnv(path, opts) {
  var autoescape = opts.autoescape === undefined ? true : opts.autoescape;
  var noCache = opts.noCache || false;
  var watch = opts.watch || false;
  var throwOnUndefined = opts.throwOnUndefined || false;
  var env = new nunjucks.Environment(
    // 创建一个文件系统加载器,从views目录读取模板
    new nunjucks.FileSystemLoader('views', {noCache,watch: watch}),
    {autoescape, throwOnUndefined}
  );
  if (opts.filters) {
    for (var f in opts.filters) {
      env.addFilter(f, opts.filters[f]);
    }
  }
  return env;
}

var env = createEnv('views', {
  watch: true,
  filters: { hex: n => '0x' + n.toString(16) }
});

var fruits = ['apple', 'banana'];
var s = env.render('hello.html', { name: '小明', fruits: fruits});
console.log(s); // <h1>Hello 小明</h1>
var s = env.render('hello.html', { name: '< script>alert("小明")</ script>' });
console.log(s); // <h1>Hello & lt; script & gt;alert(& quot;小明& quot;)& lt;/script& gt;</h1>
var s = env.render('extend.html', { header: 'Hello', body: 'bla bla bla...' })
console.log(s);

/* views/hello.html */
<h1>Hello {{ name }}</h1>
<h3>Fruits List</h3>
{% for f in fruits %}
  <p>{{ f }}</p>
{% endfor %}

/* views/base.html */
{% block header %}
  <h3>Unnamed</h3>
{% endblock %}

{% block body %}
  <div>No body</div>
{% endblock %}

{% block footer %}
  <div>copyright</div>
{% endblock %}

/* views/extend.html */
{% extends 'base.html' %}

{% block header %}
  <h1>{{ header }}</h1>
{% endblock %}

{% block body %}
  <p>{{ body }}</p>
{% endblock %}

</pre><pre>
【 koa & MVC 】
当用户通过浏览器请求一个URL时,koa将调用某个异步函数处理该URL,在这个异步函数内部执行代码
ctx.render('home.html', { name: 'Michael' });
ctx.render(view, model);
通过Nunjucks把数据用指定的模板渲染成HTML,然后输出给浏览器,用户就可以看到渲染后的页面了

异步函数是C：Controller,Controller负责业务逻辑,比如检查用户名是否存在,取出用户信息等
包含变量{{name}}的模板就是V,View负责显示逻辑,通过简单地替换一些变量,最终输出的就是用户看到的HTML
Model是用来传给View的,这样View在替换变量的时候就可以从Model中取出相应的数据

【 koa-views koa2加载模板引擎 】
# 安装koa模板使用中间件
npm install koa-views --save --registry=https://registry.npm.taobao.org
koa-views模块是一个视图管理模块,对需要进行视图模板渲染的应用是个不可缺少的中间件,支持ejs, nunjucks等众多模板引擎

views(root, opts)
root: Where your views are located. Must be an absolute path. All rendered views are relative to this path
opts (optional)
opts.autoRender: Whether to use ctx.body to receive the rendered template string. Defaults to true
opts.extension: Default extension for your views
opts.map: Map a file extension to an engine
opts.engineSource: replace consolidate as default engine source
opts.options: These options will get passed to the view engine. This is the time to add partials and helpers etc

# 安装ejs模板引擎
npm install ejs --save --registry=https://registry.npm.taobao.org
ejs是一个嵌入的Javascript模板引擎,通过编译生成HTML的代码

</pre>使用模板引擎<pre class="js">
├── package.json
├── index.js
└── view
    └── index.ejs

/* ./index.js文件 */
const Koa = require('koa')
const views = require('koa-views')
const path = require('path')
const app = new Koa()

// 加载模板引擎
app.use(views(path.join(__dirname, './view'), { extension: 'ejs' }))

app.use(async ctx => {
  let data = {title: "koa", user: {name: "john", age: 23}};
  await ctx.render('index', data);   // render渲染方法,这里加载到views/index.ejs文件,第二参数是传参到模版
  await next()
})

app.listen(3000)

/* ./view/index.ejs 模板 */
< !DOCTYPE html>
< html>
< head>
  < title><%= data.title %>< /title>   // 读取变量
< /head>
< body>
  < h1><%= data.title %>< /h1>
  < p>
    EJS Welcome to <%= title %>,
    <% if (data.user) {%>               // 控制流程
      I am <%= data.user.name %>
    <%}%>
  < /p>
< /body>
< /html>

</pre><pre class="js">
var views = require('koa-views');

// Must be used before any router is used
app.use(views(__dirname + '/views', {
  map: { html: 'nunjucks' }
}));

app.use(async ctx => {
  ctx.state = { session: this.session, title: 'app' };
  await ctx.render('user', { user: 'John' });
});

</pre><pre class="js">
const app = new Koa()
  .use(views(__dirname, {
    map: { hbs: 'handlebars' },
    options: {
      helpers: {
        uppercase: (str) => str.toUpperCase()
      },

      partials: {
        subTitle: './my-partial'   // requires ./my-partial.hbs
      },

      cache: true                   // cache the template string or not
    }
  }))
  .use(function (ctx) {
    ctx.state = { title: 'my title', author: 'queckezz' }
    return ctx.render('./my-view.hbs')
  })

</pre>
</div>

<div id="koa-cookie-session">
<h4>cookie & session</h4><pre>
【 Cookies内置模块 】
http是无状态的。比如访问淘宝首页并登录账号后,当再打开淘宝其他页面时,因为每一次的访问都是独立的,服务器并不知道你已经登录,所以还是不能下单或者加购物车之类的操作。
cookie是当第一次访问服务器的时候,服务器在下行HTTP报文时给浏览器分配一个具有特殊标识的字段,此后当浏览器再次访问同一域名的,将该字段t通过请求头携带到服务器。第一次访问服务器是不可能携带cookie的

koa提供了从上下文直接读取、写入cookie的方法
ctx.cookies.get(name, [options]) 读取上下文请求中的cookie
ctx.cookies.set(name, value, [options]) 在上下文中写入cookie

koa2中操作的cookies是使用了npm的cookies模块,所以在读写cookie的使用参数与该模块的使用一致

ctx.cookies用来读写Cookie

Koa中获取cookie
ctx.cookies.get(name, [options])
通过 options 获取 cookie name:
signed所请求的cookie应该被签名

设置cookie
ctx.cookies.set(name, value, [options])
通过options设置cookie name的value:
maxAge： 一个数字表示从Date.now()得到的毫秒数
signed： cookie签名值
expires： cookie过期的Date
path： cookie路径,默认是'/'
domain： cookie域名
secure： 安全cookie
httpOnly： 服务器可访问cookie, 默认是true
overwrite： 一个布尔值,表示是否覆盖以前设置的同名的cookie (默认是false),如果是true则在同一个请求中设置相同名称的所有Cookie(不管路径或域)是否在设置此Cookie时从Set-Cookie标头中过滤掉。

设置中文cookie
通过buffer转成base64存进去,取出来是再转回中文
Buffer.from('张三').toString('base64');  // 转base64
Buffer.from(buf, 'base64').toString();   // 转回中文

</pre><pre class="js">
const main = ctx => {
  const n = Number(ctx.cookies.get('view') || 0) + 1;
  ctx.cookies.set('view', n);
  ctx.response.body = n + ' views';
}

</pre><pre>
Set signed cookie keys.

These are passed to KeyGrip, however you may also pass your own KeyGrip instance. For example the following are acceptable:
app.keys = ['im a newer secret', 'i like turtle'];
app.keys = new KeyGrip(['im a newer secret', 'i like turtle'], 'sha256');

These keys may be rotated and are used when signing cookies with the { signed: true } option:
ctx.cookies.set('name', 'tobi', { signed: true });

</pre><pre class="js">
app.use(async ctx => {
  if (ctx.url === '/index') {
    ctx.cookies.set(
      'cid',
      'hello world',
      {
        domain: 'localhost',              // 写cookie所在的域名
        path: '/index',                   // 写cookie所在的路径
        maxAge: 10 * 60 * 1000,           // cookie有效时长
        expires: new Date('2017-02-15'),  // cookie失效时间
        httpOnly: false,                  // 是否只用于http请求中获取
        overwrite: false                  // 是否允许重写
      }
    )
    ctx.body = 'cookie is ok'
  } else {
    ctx.body = 'hello world'
  }
})

</pre><pre>
【 session 】
session是另一种记录客户状态的机制
cookie是存放在客户端浏览器中,不是很安全,用户可以自己手动把cookie种在客户端以欺骗服务器
session是存储在服务端的,所以对于较重要的数据存储在session。

session的工作机制
当浏览器第一次请求服务器时,服务器端会创建一个session对象,生成一个类似于key-value的键值对,然后将key(cookie)下发到浏览器客户端,浏览器再访问时携带key(cookie)找到对应的session(value),生产中用户的信息都保存在session中

koa2原生功能只提供了cookie的操作,但是没有提供session操作,session就只用自己实现或通过第三方中间件实现。在koa2中实现session的方案有一下几种
1、如果session数据量很小,可以直接存在内存中
2、如果session数据量很大,则需要存储介质存放session数据

数据库存储方案
1、将session存放在MySQL数据库中
2、需要用到中间件
koa-session-minimal：适用于koa2的session中间件,提供存储介质的读写接口 。
koa-mysql-session：为koa-session-minimal中间件提供MySQL数据库的session数据读写操作。
将sessionId和对应的数据存到数据库
3、将数据库的存储的sessionId存到页面的cookie中
4、根据cookie的sessionId去获取对于的session信息

</pre><pre class="js">
const Koa = require('koa')
const session = require('koa-session-minimal')
const MysqlSession = require('koa-mysql-session')

const app = new Koa()

// 配置存储session信息的mysql
let store = new MysqlSession({
  host: '127.0.0.1',
  database: 'koa_demo',
  user: 'root',
  password: 'abc123',
})

// 存放sessionId的cookie配置
let cookie = {
  maxAge: '',   // cookie有效时长
  expires: '',  // cookie失效时间
  path: '',     // 写cookie所在的路径
  domain: '',   // 写cookie所在的域名
  httpOnly: '', // 是否只用于http请求中获取
  overwrite: '',// 是否允许重写
  secure: '',
  sameSite: '',
  signed: '',
}

// 使用session中间件
app.use(session({ key: 'SESSION_ID', store, cookie}))

app.use( async ( ctx ) => {
  if ( ctx.url === '/set' ) {      // 设置session
    ctx.session = { user_id: Math.random().toString(36).substr(2), count: 0 }
    ctx.body = ctx.session
  } else if ( ctx.url === '/' ) {  // 读取session信息
    ctx.session.count += 1
    ctx.body = ctx.session
  }
})

app.listen(3000, () => console.log('[demo] session is starting at port 3000'))

</pre><pre>
【 koa-session中间件 】
npm i koa-session

koa-session是采用cookie来实现session

</pre>session中保存页面访问次数,每次请求的时候增加计数再把结果返回给用户<pre class="js">
const Koa = require('koa');
const session = require('koa-session');
const app = new Koa();

app.keys = ['some secret hurr'];

const CONFIG = {
  // string,返给浏览器cookie的key默认是'kao:sess',常用
  key: 'koa:sess',

  // number || 'session',cookie的过期时间maxAge in ms,default is 1 days,常用
  // 'session' will result in a cookie that expires when session/browser is closed
  // If a session cookie is stolen, this cookie will never expire
  maxAge: 86400000,

  // boolean,自动给客户端下发cookie并设置session,automatically commit headers,default true
  autoCommit: true,

  // boolean,是否可以覆盖之前同名的cookie,default true
  overwrite: true,

  // boolean,httpOnly or not,default true
  httpOnly: true,

  // boolean,signed or not,default true
  signed: true,

  // boolean,在每次响应时强制设置session标识符cookie,到期时被重置设置过期倒计时,default false
  // Force a session identifier cookie to be set on every response. The expiration is reset to the original maxAge, resetting the expiration countdown
  rolling: false,

  // boolean,当session快过期时更新session,这样就可以始终保持用户登录,默认是false
  renew: false,
};

app.use(session(CONFIG, app));
// app.use(session(app));       // prefer all default config

app.use(ctx => {
  if (ctx.path === '/favicon.ico') return;  // ignore favicon
  let n = ctx.session.views || 0;
  ctx.session.views = ++n;
  ctx.body = n + ' views';
});

app.listen(3000, () =>　console.log('listening on port 3000'));

</pre>用koa-session实现登录状态验证<pre class="js">
const Koa = require('koa');
const session = require('koa-session');
const router = require('koa-router')();
const views = require('koa-views')
const app = new Koa();

app.use(session(app));

// 加载模板引擎
app.use(views(path.join(__dirname, './view'), { extension: 'ejs' }))

// 校验是否已经登录
app.use(async (ctx, next) => {
  if (!ctx.session.user) ctx.response.redirect('/login');  // 校验ctx.session.user不存在则跳转到登录页面
  await next();
})

// 退出登录
router.get('/logout', async (ctx, next) => {
  ctx.session = null;                                      // 将登录信息清空
  ctx.response.redirect('/');                              // 跳转到登录页或网站首页
})
// 定义登录的路由
router.post('/login', async (ctx, next) => {
  const {username, password} = ctx.request.body;
  if (username=='123' && password==='123') {               //保存登录状态,在浏览器中生成一个cookie
    ctx.session.user = username;
    ctx.body = { success: true, msg: '登录成功！' };
  }else{
    ctx.body = { success: false, msg: '账号或密码错误！' };
  }
})
router.get('/home', async (ctx, next) => {
  await ctx.render('home.html', { title: 'home' });          // 已登录,则继续渲染页面
  await next()
})

app.use(router.routes()).use(router.allowedMethods());

app.listen(3000, () =>　console.log('listening on port 3000'));

// 前端
$.post('/login', { username: '123', password: '123456' },  data => {
  data.success ? console.log(data.msg) : alert(data.msg);
});

</pre><pre>
External Session Stores
对于session的存储方式,koa-session同时支持cookie和外部存储
默认配置下会使用cookie来存储session信息即实现了一个"cookie session",这种方式对服务端是比较轻松的,不需要额外记录任何session信息,但是也有不少限制比如大小的限制以及安全性上的顾虑。用cookie保存时实现上非常简单,就是对session(包括过期时间)序列化后做一个简单的base64编码,其结果类似
koa:sess=eyJwYXNzcG9ydCI6eyJ1c2VyIjozMDM0MDg1MTQ4OTcwfSwiX2V4cGlyZSI6MTUxNzI3NDE0MTI5MiwiX21heEFnZSI6ODY0MDAwMDB9;

在实际项目中会话相关信息往往需要再服务端持久化,因此一般都会使用外部存储来记录session信息。外部存储可以是任何的存储系统,可以是内存数据结构、本地的文件或远程的数据库,但这不意味着不需要cookie了,由于http协议的无状态特性,依然需要通过cookie来获取session的标识(这里叫externalKey)。koa-session里的external key默认是一个时间戳加上一个随机串,因此cookie的内容类似
koa:sess=1517188075739-wnRru1LrIv0UFDODDKo8trbmFubnVmMU;

要实现一个外置的存储,用户需要自定义get(), set()和destroy()函数,分别用于获取、更新和删除session。一个最简单的实现就采用一个object来存储session,那么可以这么来配置

get(key, maxAge, { rolling }): get session object by key
set(key, sess, maxAge, { rolling, changed }): set session object for key, with a maxAge (in ms)
destroy(key): destroy session for key

</pre><pre class="js">
let store = {
  storage: {},
  get (key, maxAge) {
    return this.storage[key]
  },
  set (key, sess, maxAge) {
    this.storage[key] = sess
  },
  destroy (key) {
    delete this.storage[key]
  }
}
app.use(session({store}, app))

</pre>koa-session持久化<pre class="js">
// 使用mongoose链接数据库
const mongoose = require('mongoose');
const config = require('config-lite')({ filename: 'default', config_basedir: __dirname, config_dir: 'config' });
const chalk = require('chalk');

mongoose.connect(config.url, { dbName: config.db, useNewUrlParser: true, autoIndex: false });

const connect = mongoose.connection;

connect.once('open', () => console.log(chalk.green('connect db success！')));

connect.on('error', error => {
  console.error( chalk.red('Error in MongoDb connection: ' + error) );
  mongoose.disconnect();
});

connect.on('close', () => {
    console.log( chalk.red('the db is disconnect ,reconnect...') );
    mongoose.connect(config.url, { server: { autoReconnect: true } });
});

module.exports = connect;

/* store.js */
const { Store } = require('koa-session2');
module.exports = class extends Store {
  constructor(con) {
    super();
    this.collection = con.collection('sessions');
    console.log("session start ");
  }
  async get(sid) {
    return await this.collection.findOne({ sid });
  }
  async set(session, opts) {
    try {
      if (!opts.sid) opts.sid = this.getID(24);
      await this.collection.findOneAndUpdate({ sid: opts.sid }, { $set: session }, { upsert: true });
    } catch (error) {
      console.log("error", error);
    }
    return opts.sid;
  }
  async destory(sid) {
    await this.collection.findAndModify({ sid }, [], {}, { removed: true });
  }
}

/* app.js */
const session = require("koa-session2");
const sessionStore = require('./middlewares/seesionStore/store');
app.use(session({
  key: config.session.key,
  maxAge: config.session.maxAge,
  domain: config.session.domain,
  store: new sessionStore(connect)
}));

</pre><pre>
session安全性
如果session采用外部存储的方式,安全性是比较容易保证的,因为cookie中保存的只是session的external key,默认实现是一个时间戳加随机字符串,因此不用担心被恶意篡改或者暴露信息。当然如果cookie本身被窃取,那么在过期之前还是可以被用来访问session信息(当然可以在标识中加入更多的信息,比如ip地址,设备id等信息,从而增加更多校验来减少风险)。

如果session完全保存在cookie中就需要额外注意安全性的问题。在session的默认实现中对cookie的编码只是简单的base64,因此理论上客户端很容易解析和修改。

因此在koa-session的config中有一个httpOnly的选项就是不允许浏览器中的js代码来获取cookie,避免遭到一些恶意代码的攻击。

但是假如cookie被窃取,攻击者还是可以很容易的修改cookie,比如把maxAge设为无限就可以一直使用cookie了,这种情况如何处理呢？其实是koa的cookie本身带了安全机制,也就是config里的signed设为true的时候会自动给cookie加上一个sha256的签名,类似koa:sess.sig=pjadZtLAVtiO6-Haw1vnZZWrRm8,从而防止cookie被篡改。

如何处理session的信息被泄露的问题呢？其实koa-session允许用户在config中配置自己的编码和解码函数,因此完全可以使用自定义的加密解密函数对session进行编解码,类似
encode: json => CryptoJS.AES.encrypt(json, "Secret Passphrase"),
decode: encrypted => CryptoJS.AES.decrypt(encrypted, "Secret Passphrase");

【 session和token 】
session和token都常常用来作为用户鉴权的机制,很多情况下session和token两种方式都会一起来使用

大部分情况下session鉴权指的是这样一个流程:
1、用户登录的时候服务端生成一个会话和一个id标识
2、会话id在客户端和服务端之间通过cookie进行传输
3、服务端通过会话id可以获取到会话相关的信息,然后对客户端的请求进行响应;如果找不到有效的会话,那么认为用户是未登陆状态
4、会话会有过期时间,也可以通过一些操作(比如登出)来主动删除

token的典型流程为：
1、用户登录的时候服务端生成一个token返回给客户端
2、客户端后续的请求都带上这个token
3、服务端解析token获取用户信息,并响应用户的请求
4、token会有过期时间,客户端登出的时候也会废弃token,但是服务端不需要任何操作

两种方式的区别在于：
1、session要求服务端存储信息,并且根据id能够检索,而token不需要。在大规模系统中,对每个请求都检索会话信息可能是一个复杂和耗时的过程,但服务端要通过token来解析用户身份也需要定义好相应的协议。

2、session一般通过cookie来交互,而token方式更加灵活,可以是cookie或其他header,也可以放在请求的内容中。不使用cookie可以带来跨域上的便利性。

3、token的生成方式更加多样化,可以由第三方服务来提供

【 koa-csrf模块 】
npm install koa-csrf

Options
1、invalidTokenMessage (String or Function) - defaults to Invalid CSRF token, but can also be a function that accepts one argument ctx (useful for i18n translation, e.g. using ctx.request.t('some message') via @ladjs/i18n
2、invalidTokenStatusCode (Number) - defaults to 403
3、excludedMethods (Array) - defaults to [ 'GET', 'HEAD', 'OPTIONS' ]
4、disableQuery (Boolean) - defaults to false

</pre><pre class="js">
// Add middleware in Koa app (default options are shown)
const bodyParser = require('koa-bodyparser');
const session = require('koa-session');
const CSRF = require('koa-csrf');
const Koa = require('koa');
const app = new Koa();

app.keys = [ 'a', 'b' ];     // set the session keys
app.use(session(app));       // add session support
app.use(bodyParser());       // add body parsing

// add the CSRF middleware
app.use(new CSRF({
  invalidTokenMessage: 'Invalid CSRF token',
  invalidTokenStatusCode: 403,
  excludedMethods: [ 'GET', 'HEAD', 'OPTIONS' ],
  disableQuery: false
}));

// your middleware here (e.g. parse a form submit)
app.use((ctx, next) => {
  if (![ 'GET', 'POST' ].includes(ctx.method)) return next();
  if (ctx.method === 'GET') {
    ctx.body = ctx.csrf;
    return;
  }
  ctx.body = 'OK';
});

app.listen();

// Add the CSRF token in your template forms, ejs template
<form action="/register" method="POST">
  <input type="hidden" name="_csrf" value="<%= csrf %>" />
  <input type="email" name="email" placeholder="Email" />
  <input type="password" name="password" placeholder="Password" />
  <button type="submit">Register</button>
</form>

</pre>
</div>

<div id="koa-jsonp">
<h4>koa JSONP</h4><pre>
【 原生koa2实现jsonp 】
在项目复杂的业务场景,有时候需要在前端跨域获取数据,这时候提供数据的服务就需要提供跨域请求的接口,通常是使用JSONP的方式提供跨域接口

解析原理
JSONP跨域输出的数据是可执行的JavaScript代码
ctx输出的类型应该是'text/javascript'
ctx输出的内容为可执行的返回数据JavaScript代码字符串
需要有回调函数名callbackName,前端获取后会通过动态执行JavaScript代码字符,获取里面的数据

</pre><pre class="js">
const Koa = require('koa')
const app = new Koa()

app.use( async ctx => {
  if ( ctx.method === 'GET' && ctx.url.split('?')[0] === '/getData.jsonp') {
    let callbackName = ctx.query.callback || 'callback';  // 获取jsonp的callback
    let returnData = {
      success: true,
      data: {
        text: 'this is a jsonp api',
        time: new Date().getTime(),
      }
    }
    let jsonpStr = `;${callbackName}(${JSON.stringify(returnData)})`;  // jsonp的script字符串
    ctx.type = 'text/javascript';   // 用text/javascript,让请求支持跨域获取
    ctx.body = jsonpStr;            // 输出jsonp字符串
  } else {
    ctx.body = 'hello jsonp';
  }
})

app.listen(3000, () => console.log('[demo] jsonp is starting at port 3000'))

</pre><pre>
【 koa-jsonp中间件 】
npm install --save koa-jsonp

</pre><pre class="js">
const Koa = require('koa')
const jsonp = require('koa-jsonp')
const app = new Koa()

// 使用中间件
app.use(jsonp())

app.use( async ( ctx ) => {
  let returnData = {
    success: true,
    data: {
      text: 'this is a jsonp api',
      time: new Date().getTime(),
    }
  }
  ctx.body = returnData;  // 直接输出JSON
})

app.listen(3000, () => console.log('[demo] jsonp is starting at port 3000'))

</pre>
</div>

<div id="koa-vhost">
<h4>vhost</h4><pre>
修改hosts文件

/* app.js */
const compose = require('koa-compose');
const Koa = require('koa');
const app = module.exports = new Koa();

// compose koa apps and middleware arrays to be used later in our host switch generator
function composer(app) {
  const middleware = app instanceof Koa ? app.middleware : app;
  return compose(middleware);
}

// virtual host apps
const wwwSubdomain = composer(require('./apps/koa'));
const barSubdomain = composer(require('./apps/array'));

// look ma, global response logging for all our apps!
app.use(async function(ctx, next) {
  const start = new Date();
  await next();
  const ms = new Date() - start;
  if ('test' != process.env.NODE_ENV) console.log('%s %s %s - %sms', ctx.host, ctx.method, ctx.url, ms);
});

// switch between appropriate hosts calling their composed middleware with the appropriate context.
app.use(async function(ctx, next) {
  switch (ctx.hostname) {
    case 'example.com':
    case 'www.example.com':
      // displays `Hello from main app` and sets a `X-Custom` response header
      return await wwwSubdomain.apply(this, [ctx, next]);
    case 'bar.example.com':
      // displays `Howzit? From bar middleware bundle` and sets a `X-Response-Time` response header
      return await barSubdomain.apply(this, [ctx, next]);
  }

  // everything else, eg: 127.0.0.1:3000 will propagate to 404 Not Found
  return await next();
});

if (!module.parent) app.listen(3000);

/* apps/koa.js */
const Koa = require('koa');
const app = new Koa();

app.use(async function(ctx, next) {
  await next();
  ctx.set('X-Custom', 'Dub Dub Dub App');
});

app.use(async function(ctx, next) {
  await next();
  if ('/' != ctx.url) return;
  ctx.body = 'Hello from www app';
});

module.exports = app;

/* array.js */
// rather than koa apps we can also use array bundles of middleware to the same effect.

async function responseTime(ctx, next) {
  const start = new Date();
  await next();
  const ms = new Date() - start;
  ctx.set('X-Response-Time', ms + 'ms');
}

async function index(ctx, next) {
  await next();
  if ('/' != ctx.url) return;
  ctx.body = 'Howzit? From bar middleware bundle';
}

module.exports = [ responseTime, index];

</pre>
</div>

<div id="koa-modules">
<h4>koa-logger模块</h4><pre>
npm i koa-logger -S

koa-logger提供了输出请求日志的功能,包括请求的url、状态码、响应时间、响应体大小等信息,对于调试和跟踪应用程序特别有帮助,koa-bunyan-logger提供了更丰富的功能。

Param `str` is output string with ANSI Color, and you can get pure text with other modules like `strip-ansi`
Param `args` is a array by `[format, method, url, status, time, length]`

</pre><pre class="js">
const logger = require('koa-logger')
const Koa = require('koa')

const app = new Koa()
app.use(logger())

app.use(logger((str, args) => {
  // redirect koa logger to other output pipe,default is process.stdout(by console.log function)
}))

app.use(logger({
  transporter: (str, args) => {
    // ...
  }
}))

</pre>

<h4>koa-basic-auth模块</h4><pre>
const Koa = require('koa');
const auth = require('koa-basic-auth');
const app = module.exports = new Koa();

app.use(async (ctx, next) => {
  try {
    await next();
  } catch (err) {
    if (err.status === 401) {
      ctx.status = 401;
      ctx.set('WWW-Authenticate', 'Basic');
      ctx.body = 'cant haz that';
    } else {
      throw err;
    }
  }
});

app.use(auth({ name: 'tj', pass: 'tobi' }));

app.use(async ctx => ctx.body = 'secret');

if (!module.parent) app.listen(3000);

</pre>

<h4>koa-jwt模块</h4><pre>
npm install koa-jwt@2

随着网站前后端分离方案的流行,越来越多的网站从Session Base转为使用Token Base,JWT(Json Web Tokens)作为一个开放的标准被很多网站采用,koa-jwt中间件使用JWT认证HTTP请求

签发token一般放在注册和登录方法里面

首先用户登录时,输入用户名和密码后请求服务器登录接口,服务器验证用户名密码正确后生成token并返回给前端,前端存储token,并在后面的请求中把token带在请求头中传给服务器,服务器验证token有效,返回正确数据
curl -X GET http://localhost:3200/api/users -H 'authorization: Bearer token' -H 'cache-control: no-cache'

This module lets you authenticate HTTP requests using JSON Web Tokens in your Koa (node.js) applications
koa-jwt主要提供路由权限控制的功能,对需要限制的资源请求进行检查,默认将token添加在HTTP Header Authorazition: Bearer token名为Authorization的键值对中,koa-jwt也是在该位置获取token的,也可以使用Cookie来提供令牌

koa-jwt依赖于jsonwebtoken和koa-unless两个库,koa-jwt中间件针对Koa对jsonwebtoken进行了封装,使用起来更加方便
jsonwebtoken用于生成token下发给浏览器,jsonwebtoken随koa-jwt而自动安装,在koa2以后的版本不再提供jsonwebtoken的方法,所以需要另行安装

JWT可以使用HMAC算法或RSA的公钥密钥对进行签名

安全性
如果JWT的加密密钥泄露的话,那么就可以通过密钥生成token,随意的请求API。因此密钥绝对不能存在前端代码中,不然很容易就能被找到。
在HTTP请求中token放在header中,中间者很容易可以通过抓包工具抓取到header里的数据。而HTTPS即使能被抓包,但是它是加密传输的,所以也拿不到token,就会相对安全了

Usage
The JWT authentication middleware authenticates callers using a JWT token. If the token is valid, ctx.state.user (by default) will be set with the JSON object decoded to be used by later middleware for authorization and access control

secret的值
secret是用于加密的key,可以是字符串,可以使用函数来产生动态的加密秘钥,也可以是一个文件
var publicKey = fs.readFileSync('/path/to/public.pub');
app.use(jwt({ secret: publicKey }));

add the passthrough option to always yield next, even if no valid Authorization header was found,This lets downstream middleware make decisions based on whether ctx.state.user is set
通过添加一个passthrough选项来保证始终传递到下一个中间件
app.use(jwt({ secret: 'shared-secret', passthrough: true }));

If you prefer to use another ctx key for the decoded data, just pass in key,This makes the decoded data available as ctx.state.jwtdata
app.use(jwt({ secret: 'shared-secret', key: 'jwtdata' }));

You can specify audience and/or issuer as well:
app.use(jwt({ secret: 'shared-secret', audience: 'http://myapi/protected', issuer: 'http://issuer' }));

You can specify an array of secrets.
The token will be considered valid if it validates successfully against any of the supplied secrets. This allows for rolling shared secrets, for example:
app.use(jwt({ secret: ['old-shared-secret', 'new-shared-secret'] }));

unless()用于设置哪些api是不需要通过token验证、无需登录就能访问的api即public api
// 设置/register和/login两个api无需token检查
const secert = 'jwt_secret'
app.use(jwt({secret}).unless({path: [/\/register/, /\/login/]}))

</pre>只有/public/目录可以无限制访问<pre class="js">
var jwt = require('koa-jwt');
var Koa = require('koa');
var app = new Koa();

// Custom 401 handling if you don't want to expose koa-jwt errors to users
app.use(function(ctx, next){
  return next().catch((err) => {
    if (401 == err.status) {
      ctx.status = 401;
      ctx.body = 'Protected resource, use Authorization header to get access\n';
    } else {
      throw err;
    }
  });
});

// Unprotected middleware
app.use(function(ctx, next){
  if (ctx.url.match(/^\/public/)) {
    ctx.body = 'unprotected\n';
  } else {
    return next();
  }
});

// Middleware below this line is only reached if JWT token is valid
app.use(jwt({ secret: 'shared-secret' }));

// Protected middleware
app.use(function(ctx){
  if (ctx.url.match(/^\/api/)) {
    ctx.body = 'protected\n';
  }
});

app.listen(3000);

</pre>Alternatively you can conditionally run the jwt middleware under certain conditions<pre class="js">
var jwt = require('koa-jwt');
var koa = require('koa');
var app = new Koa();

// Middleware below this line is only reached if JWT token is valid unless the URL starts with '/public'
app.use(jwt({ secret: 'shared-secret' }).unless({ path: [/^\/public/] }));

// Unprotected middleware
app.use(function(ctx, next){
  if (ctx.url.match(/^\/public/)) {
    ctx.body = 'unprotected\n';
  } else {
    return next();
  }
});

// Protected middleware
app.use(function(ctx){
  if (ctx.url.match(/^\/api/)) {
    ctx.body = 'protected\n';
  }
});

app.listen(3000);

</pre>通过koa-jwt中间件来验证token<pre class="js">
import bodyParser from 'koa-bodyparser'
import logger from 'koa-logger'
import mongoose from 'mongoose'
import helmet from 'koa-helmet'
import cors from 'koa-cors'
import koajwt from 'koa-jwt'
import Koa from 'koa'
const userModel = require('../models/userModel.js');
const router = require('koa-router')();
const app = new koa();

// 错误处理,请求时没有token或token过期或token验证失败则返回401抛出401错误,因此需要添加错误处理,而且要放在app.use(koajwt())之前,否则不执行
app.use((ctx, next) => {
  return next().catch((err) => {
    if(err.status === 401){
      ctx.status = 401;
      ctx.body = { error: err.originalError ? err.originalError.message : err.message, };
    }else{
      throw err;
    }
  })
})

// 通过app.use来调用该中间件,并传入密钥 {secret: 'my_token'},unless可以指定哪些URL不需要进行token验证
app
  .use(koajwt({ secret: 'my_token'}).unless({ path: [/\/register/, /\/login/] }))
  .use(logger())
  .use(bodyParser())
  .use(helmet())
  .use(cors())

// 注册实现,这里只是简单的将密码加密将信息存入数据库,实际项目中还需要对用户输入的字段进行验证。
// curl -X POST http://localhost:3000/register  -H 'cache-control: no-cache' -H 'content-type: application/x-www-form-urlencoded'  -d 'username=admin&password=123456'
router.post('/register', async ctx => {
  const { body } = ctx.request;
  const { username, password } = body;
  try {
    if (!username || !password) {
      ctx.body = { status: 400, message: `expected an object with username, password but got: ${body}` }
      return;
    }
    body.password = await bcrypt.hash(password, 5)
    let user = await userModel.find({ username: username });
    if (!user.length) {
      const newUser = new userModel(body);
      user = await newUser.save();
      ctx.body = { status: 200, message: '注册成功', user }
    } else {
      ctx.body = { status: 406, message: '用户名已经存在' }
    }
  } catch (error) {
    ctx.throw(500)
  }
})

// /login路由用于用户登录时获取token
// 用户输入用户名和密码登录,如果用户名和密码正确则使用jsonwebtoken.sign()生成token并返回给客户端。客户端将token存储在本地存储,在每次的HTTP请求中都将token添加在HTTP Header Authorazition: Bearer token中,然后后端每次去验证该token的正确与否,只有token正确后才能访问到对应的资源
router.post('/login', async ctx => {
  const {name, password} = ctx.request.body;
  if(!name || !password){
    ctx.body = { status: 401, message: '参数不合法' }
    return;
  }
  const user = await userModel.findOne({ name, password })
  if(user !== null){
    // 在验证了用户名密码正确之后调用jsonwebtoken的sign()方法来生成token,接收三个参数,第一个是载荷,用于编码后存储在token中的数据,也是验证token后可以拿到的数据;第二个是密钥,自己定义的,验证的时候也是要相同的密钥才能解码,secret必须要与前面设置jwt()中的secret一致;第三个是options,可以设置token的过期时间
    delete user.password;
    const token = jwt.sign({ data: user }, 'my_token', { expiresIn: '2h' });
    ctx.body = { status: 200, message: '登录成功', user, toekn }
  }else{
    ctx.body = { status: 401, message: '用户名或密码错误' }
    return;
  }
});

app.use(router.routes()).use(route.allowedMethods({ throw: true }))

app.listen(3000, () => console.log(`✅  The server is running at http://localhost:3000/`))

// 前端获取token,使用axios进行请求,请求成功之后拿到token保存到localStorage中。这里登录成功后还把当前时间存了起来,除了判断token是否存在之外,还可简单的判断当前token是否过期,如果过期则跳登录页面

axios.post('/login', {
  name: username,
  password: password
}).then(res => {
  if(res.status === 200){
    localStorage.setItem('user', res.user);
    localStorage.setItem('token', res.token);
    localStorage.setItem('token_exp', new Date().getTime());
  }else{
    alert(res.message);
  }
})

然后请求服务器端API的时候,把token带在请求头中传给服务器进行验证。每次请求都要获取localStorage中的token,这样很麻烦,这里使用了axios的请求拦截器,对每次请求都进行了取token放到headers中的操作。

axios.interceptors.request.use(config => {
  const token = localStorage.getItem('token');
  config.headers.common['Authorization'] = 'Bearer ' + token;
  return config;
})

</pre>解析koa-jwt<pre class="js">
// resolvers/auth-header.js
// 判断请求头中是否带了authorization,如果有则将token从authorization中分离出来。如果没有则代表了客户端没有传token到服务器,这时候就抛出401错误状态
module.exports = function resolveAuthorizationHeader(ctx, opts) {
  if (!ctx.header || !ctx.header.authorization) return;
  const parts = ctx.header.authorization.split(' ');
  if (parts.length === 2) {
    const scheme = parts[0];
    const credentials = parts[1];
    if (/^Bearer$/i.test(scheme)) return credentials;
  }
  if (!opts.passthrough) {
    ctx.throw(401, 'Bad Authorization header format. Format is "Authorization: Bearer < token >"');
  }
};

// verify.js
// 使用jsonwebtoken提供的verify()方法进行验证返回结果。jsonwebtoken的sign()方法来生成token的,而verify()方法则是用来认证和解析token。如果token无效则会在此方法被验证出来
const jwt = require('jsonwebtoken');
module.exports = (...args) => {
  return new Promise((resolve, reject) => {
    jwt.verify(...args, (error, decoded) => error ? reject(error) : resolve(decoded));
  });
};

// index.js
// 调用verify.js的方法进行验证并解析token,拿到上面进行sign()的数据{name: result.name, _id: result._id},并赋值给ctx.state.user,在控制器中便可以直接通过ctx.state.user拿到name和_id
const decodedToken = await verify(token, secret, opts);
if (isRevoked) {
    const tokenRevoked = await isRevoked(ctx, decodedToken, token);
    if (tokenRevoked) {
        throw new Error('Token revoked');
    }
}
ctx.state[key] = decodedToken;  // 这里的key = 'user'
if (tokenKey) ctx.state[tokenKey] = token;

</pre>

<h4>koa-convert模块</h4><pre>
对于比较老的使用Generate函数的koa中间件(< koa2),官方提供了一个灵活的工具可以将他们转为基于Promise的中间件供Koa2使用,同样也可以将新的基于Promise的中间件转为旧式的Generate中间件

</pre>

<h4>koa-helmet模块</h4><pre>
网络安全得到越来越多的重视,helmet 通过增加如Strict-Transport-Security, X-Frame-Options, X-Frame-Options等HTTP头提高Express应用程序的安全性,koa-helmet为koa程序提供了类似的功能

安全性相关的HTTP头
Strict-Transport-Security：强制使用安全连接(SSL/TLS之上的HTTPS)来连接到服务器。
X-Frame-Options：提供对于“点击劫持”的保护。
X-XSS-Protection：开启大多现代浏览器内建的对于跨站脚本攻击(XSS)的过滤功能。
X-Content-Type-Options： 防止浏览器使用MIME-sniffing来确定响应的类型,转而使用明确的content-type来确定。
Content-Security-Policy：防止受到跨站脚本攻击以及其他跨站注入攻击。

</pre><pre class="js">
var Koa = require('koa');
var helmet = require('koa-helmet');
var app = new Koa();
app.use(helmet());

</pre>

<h4>koa2-cors模块</h4><pre>
const cors = require('koa2-cors');
CORS是一个W3C标准,全称是"跨域资源共享"(Cross-origin resource sharing)

</pre><pre class="js">
app.use(cors({
  origin: function (ctx) {
    if (ctx.url === '/test') {
      return "*"; // 允许来自所有域名请求
    }
    return 'http://localhost:8080';  // 这样就能只允许http://localhost:8080这个域名的请求了
  },
  exposeHeaders: ['WWW-Authenticate', 'Server-Authorization'],
  maxAge: 5,
  credentials: true,
  allowMethods: ['GET', 'POST', 'DELETE'],
  allowHeaders: ['Content-Type', 'Authorization', 'Accept'],
}))

</pre>
</div>

<div id="websocket">
<h3>nodejs websocket</h3><pre>
WebSocket是HTML5新增的协议,在浏览器和服务器之间建立一个不受限的双向通信的通道,比如服务器可以在任意时刻发送消息给浏览器

为什么传统的HTTP协议不能做到WebSocket实现的功能？这是因为HTTP协议是一个请求－响应协议,请求必须先由浏览器发给服务器,服务器才能响应这个请求,再把数据发送给浏览器。浏览器不主动请求,服务器是没法主动发数据给浏览器的。
这样一来要在浏览器中搞一个实时聊天,在线炒股(不鼓励),或者在线多人游戏的话就没法实现了,只能借助Flash这些插件。

HTTP协议其实也能利用比如轮询或Comet来实现
轮询是指浏览器通过Js启动一个定时器,然后以固定的间隔给服务器发请求,询问服务器有没有新消息,这个机制的缺点一是实时性不够,二是频繁的请求会给服务器带来极大的压力。

Comet本质上也是轮询,但是在没有消息的情况下,服务器先拖一段时间,等到有消息了再回复。这个机制暂时地解决了实时性问题,但是它带来了新的问题：以多线程模式运行的服务器会让大部分线程大部分时间都处于挂起状态,极大地浪费服务器资源。另外一个HTTP连接在长时间没有数据传输的情况下,链路上的任何一个网关都可能关闭这个连接,而网关是网站管理者不可控的,这就要求Comet连接必须定期发一些ping数据表示连接"正常工作"

以上两种机制都治标不治本,所以HTML5推出了WebSocket标准,让浏览器和服务器之间可以建立无限制的全双工通信,任何一方都可以主动发消息给对方。

WebSocket协议并不是全新的协议,而是利用了HTTP协议来建立连接

首先WebSocket连接必须由浏览器发起,因为请求协议是一个标准的HTTP请求,格式如下：
GET ws://localhost:3000/ws/chat HTTP/1.1
Host: localhost
Upgrade: websocket
Connection: Upgrade
Origin: http://localhost:3000
Sec-WebSocket-Key: client-random-string
Sec-WebSocket-Version: 13

该请求和普通的HTTP请求有几点不同：
GET请求的地址不是类似/path/,而是以ws://开头的地址;
请求头Upgrade: websocket和Connection: Upgrade表示这个连接将要被转换为WebSocket连接;
Sec-WebSocket-Key是用于标识这个连接,并非用于加密数据;
Sec-WebSocket-Version指定了WebSocket的协议版本

随后服务器如果接受该请求就会返回如下响应：
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: server-random-string

该响应代码101表示本次连接的HTTP协议即将被更改,更改后的协议就是Upgrade: websocket指定的WebSocket协议。

版本号和子协议规定了双方能理解的数据格式以及是否支持压缩等。如果仅使用WebSocket的API,就不需要关心这些。

现在一个WebSocket连接就建立成功,浏览器和服务器就可以随时主动发送消息给对方。消息有两种：文本或二进制数据,通常可以发送JSON格式的文本,这样在浏览器处理起来就十分容易。

为什么WebSocket连接可以实现全双工通信而HTTP连接不行呢？实际上HTTP协议是建立在TCP协议之上的,TCP协议本身就实现了全双工通信,但是HTTP协议的请求－应答机制限制了全双工通信。WebSocket连接建立以后,其实只是简单规定了一下：接下来通信就不使用HTTP协议了,直接互相发数据

安全的WebSocket连接机制和HTTPS类似,首先浏览器用wss://xxx创建WebSocket连接时会先通过HTTPS创建安全的连接,然后该HTTPS连接升级为WebSocket连接,底层通信走的仍然是安全的SSL/TLS协议。

要支持WebSocket通信,浏览器得支持这个协议,这样才能发出ws://xxx的请求,目前支持WebSocket的主流浏览器如下：
Chrome、 Firefox、IE >= 10、 Sarafi >= 6、 Android >= 4.4、 iOS >= 8

使用WebSocket的关键在于服务器端支持,由于WebSocket是一个协议,服务器具体怎么实现取决于所用编程语言和框架本身。
Node.js本身支持的协议包括TCP协议和HTTP协议,要支持WebSocket协议,需要对Node.js提供的HTTPServer做额外的开发,已经有若干基于Node.js的稳定可靠的WebSocket实现则直接用npm安装使用即可。

【 ws模块 npm i -s ws 】
ws一个使用简单,速度极快,稳定的websocket客户端和服务端的Node.js实现

</pre><pre class="js">
/* 服务端代码 /ws/app.js */
const WebSocket = require('ws');                // 导入websocket模块
const wss = new WebSocket.Server({port: 3000})  // 在3000端口打开一个WebSocketServer

// 有websocket请求进入,wss对象响应connection事件来处理这个websocket
// connection事件中,回调函数会传入一个WebSocket的实例表示这个WebSocket连接
// 通过响应message事件,在收到消息后再返回一个ECHO: xxx的消息给客户端
wss.on('connection', ws => {
  console.log(`[SERVER] connection`);
  ws.on('message', message => {
    console.log(`[SERVER] Received: ${message}`);
    ws.send(`ECHO: ${message}`, err => err && console.log(`[SERVER] error: ${err}`));
  })
  ws.on('close', err => console.log('websocket close', err))
  ws.on('error', err => console.log('websocket 通信中断', err))
})

/* 客户端代码 /ws/client.js */
const WebSocket = require('ws');                    // 直接用ws模块提供的WebSocket来充当客户端
let ws = new WebSocket('ws://localhost:3000/test');

ws.on('open', () => {                               // 打开WebSocket连接后立刻发送一条消息
  console.log(`[CLIENT] open()`);
  ws.send('Hello!');
});

ws.on('message', message => console.log(`[CLIENT] Received: ${message}`) );  // 响应收到的消息

/* 浏览器端js代码 /ws/client.html */
// Create WebSocket connection,打开socket
const socket = new WebSocket('ws://localhost:3000/test');

// Connection opened,发送一个初始化消息
socket.addEventListener('open', event => socket.send('hi, I am the client!'));

// Listen for messages监听消息,看设置多个监听器
socket.addEventListener('message', event => console.log(event.data));
socket.addEventListener('message', event => {
  console.log(event);
  // MessageEvent {isTrusted: true, data: "ECHO: hi, I am the client!", origin: "ws://localhost:3000", lastEventId: "", source: null…}
});

// 监听Socket的error
socket.addEventListener('error', err => console.log('Client notified socket has error:',err));

// 监听Socket的关闭
socket.addEventListener('close', event => console.log('Client notified socket has closed',event));

</pre><pre>
同源策略
WebSocket协议本身不要求同源策略(Same-origin Policy),即可以发生跨域请求,但是浏览器会发送Origin的HTTP头给服务器,服务器可以根据Origin拒绝这个WebSocket请求,所以是否要求同源要看服务器端如何检查。

路由
服务器在响应connection事件时并未检查请求的路径,因此在客户端打开ws://localhost:3000/any/path可以写任意的路径。
实际应用中还需要根据不同的路径实现不同的功能

</pre>
</div>


<div id="mysql">
<h2>使用Node.js来连接MySQL</h2><pre>
#安装node.js的mysql模块
npm install --save mysql

mysql模块是node操作MySQL的引擎,可以在node.js环境下对MySQL数据库进行建表,增、删、改、查等操作

</pre><pre>
【 创建数据库会话 】
var connection = mysql.createConnection('mysql://user:pass@host/db?debug=true&charset=BIG5_CHINESE_CI&timezone=-0700');

1、Every method you invoke on a connection is queued and executed in sequence.
2、Closing the connection is done using end() which makes sure all remaining queries are executed before sending a quit packet to the mysql server

Connection options：
host
The hostname of the database you are connecting to, Default: localhost

port
The port number to connect to, Default: 3306

localAddress
The source IP address to use for TCP connection,此IP用于TCP连接,Optional

socketPath
The path to a unix domain socket to connect to. When used host and port are ignored.连接到unix域路径,当使用host和port时会被忽略

user
The MySQL user to authenticate as.

password
The password of that MySQL user.

database
Name of the database to use for this connection, Optional

charset
连接字符集,The charset for the connection. This is called "collation" in the SQL-level of MySQL (like utf8_general_ci). If a SQL-level charset is specified (like utf8mb4) then the default collation for that charset is used, Default: 'UTF8_GENERAL_CI'

timezone
The timezone configured on the MySQL server. This is used to type cast server date/time values to JS Date object and vice versa. This can be 'local', 'Z', or an offset in the form +HH:MM or -HH:MM, Default: 'local'

connectTimeout
连接超时,The milliseconds before a timeout occurs during the initial connection to the MySQL server,efault: 10000, 单位毫秒

stringifyObjects
是否序列化对象, Stringify objects instead of converting to values, Default: false

insecureAuth
Allow connecting to MySQL instances that ask for the old (insecure) authentication method, Default: false

typeCast
是否将列值转化为本地JS类型值,Determines if column values should be converted to native JS types, Default: true

queryFormat
自定义query语句格式化方法,A custom query format function. See Custom format

supportBigNumbers
数据库支持bigint或decimal类型列时需要设此option为true,When dealing with big numbers (BIGINT and DECIMAL columns) in the database, you should enable this option,Default: false

bigNumberStrings
supportBigNumbers和bigNumberStrings启用强制bigint或decimal列以JS字符串类型返回(默认false)
Enabling both supportBigNumbers and bigNumberStrings forces big numbers (BIGINT and DECIMAL columns) to be always returned as JavaScript String objects (Default: false). Enabling supportBigNumbers but leaving bigNumberStrings disabled will return big numbers as String objects only when they cannot be accurately represented with [JavaScript Number objects] (http://ecma262-5.com/ELS5_HTML.htm#Section_8.5) (which happens when they exceed the [-2^53, +2^53] range), otherwise they will be returned as Number objects. This option is ignored if supportBigNumbers is disabled.

dateStrings
强制timestamp,datetime,data类型以字符串类型返回,而不是Js Date类型,Default: false
Force date types (TIMESTAMP, DATETIME, DATE) to be returned as strings rather than inflated into JavaScript Date objects. Can be true/false or an array of type names to keep as strings.

debug
开启调试,Prints protocol details to stdout. Can be true/false or an array of packet type names that should be printed,Default: false

trace
Generates stack traces on Error to include call site of library entrance ("long stack traces"). Slight performance penalty for most calls, Default: true

multipleStatements
是否许一个query中有多个MySQL语句,Allow multiple mysql statements per query. Be careful with this, it could increase the scope of SQL injection attacks, Default: false

flags
用于修改连接标志,List of connection flags to use other than the default ones. It is also possible to blacklist default ones. For more information, check Connection Flags

ssl
object with ssl parameters or a string containing name of ssl profile. See SSL options.
使用ssl参数(与crypto.createCredenitals参数格式一致)或一个包含ssl配置文件名称的字符串,目前只捆绑Amazon RDS的配置文件

</pre><pre class="js">
var mysql      = require('mysql');
var connection = mysql.createConnection({
  host     : 'localhost',
  user     : 'admin',
  password : '',
  database : 'my_db01'
});

connection.connect();
connection.connect(err => {
  if (err) return console.error('error connecting: ' + err.stack);
  // Getting the connection ID
  console.log('connected as id ' + connection.threadId);
});

connection.query('select uid, username from user where age = 22', (error, results, fields) => {
  if (error) throw error;
  console.log(results, fields);
  /* [
    RowDataPacket { uid: 2, username: '刘六' },
    RowDataPacket { uid: 4, username: '王五' }
  ]

  [
    FieldPacket { catalog: 'def', db: 'my_db01', table: 'user', orgTable: 'user', name: 'uid', orgName: 'uid', charsetNr: 63, length: 11, type: 3, flags: 16899, decimals: 0, default: undefined, zeroFill: false, protocol41: true },
    FieldPacket { catalog: 'def', db: 'my_db01', table: 'user', orgTable: 'user', name: 'username', orgName: 'username', charsetNr: 33, length: 150, type: 253, flags: 16388, decimals: 0, default: undefined, zeroFill: false, protocol41: true }
    ]
  */
});

// Getting the id of an inserted row
connection.query('INSERT INTO posts SET ?', {title: 'test'}, function (error, results, fields) {
  if (error) throw error;
  console.log(results.insertId);
});

// Getting the number of affected rows from an insert, update or delete statement
connection.query('DELETE FROM posts WHERE title = "wrong"', function (error, results, fields) {
  if (error) throw error;
  console.log('deleted ' + results.affectedRows + ' rows');
})

// Getting the number of changed rows from an update statement
connection.query('UPDATE posts SET ...', function (error, results, fields) {
  if (error) throw error;
  console.log('changed ' + results.changedRows + ' rows');
})

connection.end();
connection.end(err => err && console.error(err));
connection.destroy();    // no callback

</pre>不执行connection.connect(),直接通过connection.query隐式创建连接,这样方便处理连接错误<pre class="js">
const mysql = require('mysql')
const connection = mysql.createConnection('mysql://admin:@localhost/my_db01');
connection.query('select uid, username from user where age = 22',  (error, results, fields) => {
  if (error) throw error
  console.log(results);
  connection.end();
});

</pre><pre>
【 创建数据连接池,并行执行sql语句 】
一般情况下操作数据库是很复杂的读写过程,不只是一个会话,如果直接用会话操作就需要每次会话都要配置连接参数,所以这时候就需要连接池管理会话。

Closing all the connections in a pool:
// Once pool.end is called, pool.getConnection and other operations can no longer be performed
pool.end()
pool.end(err => console.log('all connections in the pool have ended");

Pool events:
pool.on('acquire', connection => console.log('Connection %d acquired', connection.threadId));
pool.on('connection', connection => connection.query('SET SESSION auto_increment_increment=1'));
pool.on('enqueue', () => console.log('Waiting for available connection slot'));
pool.on('release', connection => console.log('Connection %d released', connection.threadId));

Pool options:
acquireTimeout
The milliseconds before a timeout occurs during the connection acquisition. This is slightly different from connectTimeout, because acquiring a pool connection does not always involve making a connection. If a connection request is queued, the time the request spends in the queue does not count towards this timeout, Default: 10000

waitForConnections
Determines the pool's action when no connections are available and the limit has been reached. If true, the pool will queue the connection request and call it when one becomes available. If false, the pool will immediately call back with an error, Default: true

connectionLimit
The maximum number of connections to create at once, Default: 10

queueLimit
The maximum number of connection requests the pool will queue before returning an error from getConnection. If set to 0, there is no limit to the number of queued connection requests, Default: 0

</pre><pre class="js">
var mysql = require('mysql');
// 创建数据池
var pool  = mysql.createPool({
  connectionLimit : 10,
  host     : 'localhost',
  user     : 'admin',
  password : '',
  database : 'my_db01'
});
// 在数据池中进行会话操作
pool.query('select uid, username from user where age = 22', function (error, results, fields) {
  if (error) throw error;
  console.log(results);
});

</pre><pre class="js">
const mysql = require('mysql')

// 创建数据池
const pool  = mysql.createPool({
  connectionLimit : 10,
  host     : 'localhost',
  user     : 'admin',
  password : '',
  database : 'my_db01'
})

// 在数据池中进行会话操作
pool.getConnection((err, connection) => {
  if (err) throw err;
  connection.query('SELECT * FROM my_table',  (error, results, fields) => {
    if (error) throw error
    console.log(results);
    connection.release();  // 结束会话
  })
})

</pre>Promise封装mysql模块连接池<pre class="js">
// Promise封装 ./async-db.js
const mysql = require('mysql')
const pool = mysql.createPool({
  host     :  '127.0.0.1',
  user     :  'admin',
  password :  '',
  database :  'my_db01'
})

let query = function( sql, values ) {
  return new Promise(( resolve, reject ) => {
    pool.getConnection(function(err, connection) {
      if (err) return reject( err );
      connection.query(sql, values, (err, results) => {
        err ? reject(err) : resolve(results);
        connection.release();
      })
    })
  })
}

module.exports = { query };

// async/await使用
const { query } = require('./async-db')
async function selectAllData( ) {
  let sql = 'SELECT * FROM my_table'
  let dataList = await query( sql )
  return dataList
}

console.log(selectAllData());

</pre>PoolCluster集群<pre class="js">
// create
var poolCluster = mysql.createPoolCluster();

// add configurations (the config is a pool config object)
poolCluster.add(config); // add configuration with automatic name
poolCluster.add('MASTER', masterConfig); // add a named configuration
poolCluster.add('SLAVE1', slave1Config);
poolCluster.add('SLAVE2', slave2Config);

// remove configurations
poolCluster.remove('SLAVE2'); // By nodeId
poolCluster.remove('SLAVE*'); // By target group : SLAVE1-2

// Target Group : ALL(anonymous, MASTER, SLAVE1-2), Selector : round-robin(default)
poolCluster.getConnection(function (err, connection) {});

// Target Group : MASTER, Selector : round-robin
poolCluster.getConnection('MASTER', function (err, connection) {});

// Target Group : SLAVE1-2, Selector : order
// If can't connect to SLAVE1, return SLAVE2. (remove SLAVE1 in the cluster)
poolCluster.on('remove', function (nodeId) {
  console.log('REMOVED NODE : ' + nodeId); // nodeId = SLAVE1
});

// A pattern can be passed with *  as wildcard
poolCluster.getConnection('SLAVE*', 'ORDER', function (err, connection) {});

// The pattern can also be a regular expression
poolCluster.getConnection(/^SLAVE[12]$/, function (err, connection) {});

// of namespace : of(pattern, selector)
poolCluster.of('*').getConnection(function (err, connection) {});

var pool = poolCluster.of('SLAVE*', 'RANDOM');
pool.getConnection(function (err, connection) {});
pool.getConnection(function (err, connection) {});
pool.query(function (error, results, fields) {});

// close all connections
poolCluster.end(function (err) {
  // all connections in the pool cluster have ended
});

</pre><pre>
【 Switching users and altering connection state 】
MySQL offers a changeUser command that allows you to alter the current user and other aspects of the connection without shutting down the underlying socket:

connection.changeUser({user : 'john'}, err => err && throw err);

The available options for this feature are:
user: The name of the new user (defaults to the previous one).
password: The password of the new user (defaults to the previous one).
charset: The new charset (defaults to the previous one).
database: The new database (defaults to the previous one).

</pre><pre>
【 db.query() 】
const db =  Connection || Pool || PoolNamespace;
db.query(sqlString, function callback (error, results, fields))
db.query(sqlString, values, function callback (error, results, fields))
db.query(options, function callback (error, results, fields))

var query = db.query();
console.log(query.sql);

</pre><pre class="js">
connection.query('SELECT * FROM `books` WHERE `author` = ?', ['David'], function (error, results, fields) {
  // error will be an Error if one occurred during the query
  // results will contain the results of the query
  // fields will contain information about the returned results fields (if any)
});

connection.query({
  sql: 'SELECT * FROM `books` WHERE `author` = ?',
  timeout: 40000,    // 40s
  values: ['David']
}, function (error, results, fields) {
  // error will be an Error if one occurred during the query
  // results will contain the results of the query
  // fields will contain information about the returned results fields (if any)
});

</pre>Timeouts:Kill query after 60s<pre class="js">
connection.query({sql: 'SELECT COUNT(*) AS count FROM big_table', timeout: 60000}, (error, results, fields) => {
  if (error && error.code === 'PROTOCOL_SEQUENCE_TIMEOUT') throw new Error('too long to count table rows!');
  if (error) throw error;
  console.log(results[0].count + ' rows');
});

</pre>a combination of the second and third forms can be used where the placeholder values are passed as an argument and not in the options object. The values argument will override the values in the option object<pre class="js">

connection.query({
    sql: 'SELECT * FROM `books` WHERE `author` = ?',
    timeout: 40000, // 40s
  },
  ['David'],
  function (error, results, fields) {
    if(error) throw error;
    console.log(result)
  }
);

</pre>If the query only has a single replacement character (?), and the value is not null, undefined, or an array, it can be passed directly as the second argument to .query<pre class="js">
connection.query(
  'SELECT * FROM `books` WHERE `author` = ?',
  'David',
  function (error, results, fields) {
    if(error) throw error;
    console.log(result)
  }
);

</pre><pre>
【 Escaping query values 】
Caution These methods of escaping values only works when the NO_BACKSLASH_ESCAPES SQL mode is disabled (which is the default state for MySQL servers).

In order to avoid SQL Injection attacks, you should always escape any user provided data before using it inside a SQL query. You can do so using the mysql.escape(), connection.escape() or pool.escape() methods:

</pre><pre class="js">
var userId = 'some user provided value';
var sql    = 'SELECT * FROM users WHERE id = ' + connection.escape(userId);
connection.query(sql, (error, results, fields) => {
  if (error) throw error;
  console.log(result)
});

</pre><pre class="js">
var query = "SELECT * FROM posts WHERE title=" + mysql.escape("Hello MySQL");
console.log(query); // SELECT * FROM posts WHERE title='Hello MySQL'

</pre>you can use ? characters as placeholders for values you would like to have escaped<pre class="js">
connection.query('SELECT * FROM users WHERE id = ?', [userId], function (error, results, fields) {
  if (error) throw error;
  // ...
});

</pre>Multiple placeholders are mapped to values in the same order as passed<pre class="js">
connection.query('UPDATE users SET foo = ?, bar = ?, baz = ? WHERE id = ?', ['a', 'b', 'c', userId], function (error, results, fields) {
  if (error) throw error;
  // ...
});

</pre><pre>
This looks similar to prepared statements in MySQL, however it really just uses the same connection.escape() method internally.

Caution This also differs from prepared statements in that all ? are replaced, even those contained in comments and strings.

Different value types are escaped differently:
Numbers are left untouched
Booleans are converted to true / false
Date objects are converted to 'YYYY-mm-dd HH:ii:ss' strings
Buffers are converted to hex strings like X'0fa5'
Strings are safely escaped
Arrays are turned into list, e.g. ['a', 'b'] turns into 'a', 'b'
Nested arrays are turned into grouped lists (for bulk inserts), e.g. [['a', 'b'], ['c', 'd']] turns into ('a', 'b'), ('c', 'd')
Objects that have a toSqlString method will have .toSqlString() called and the returned value is used as the raw SQL.
Objects are turned into key = 'val' pairs for each enumerable property on the object. If the property's value is a function, it is skipped; if the property's value is an object, toString() is called on it and the returned value is used.
undefined / null are converted to NULL
NaN / Infinity are left as-is. MySQL does not support these, and trying to insert them as values will trigger MySQL errors until they implement support.

</pre>This escaping allows you to do neat things like this<pre class="js">
var post  = {id: 1, title: 'Hello MySQL'};
var query = connection.query('INSERT INTO posts SET ?', post, (error, results, fields) => {
  if (error) throw error;
  console.log(results)
});
console.log(query.sql); // INSERT INTO posts SET `id` = 1, `title` = 'Hello MySQL'

</pre>the toSqlString method allows you to form complex queries with functions<pre class="js">
var CURRENT_TIMESTAMP = { toSqlString: function() { return 'CURRENT_TIMESTAMP()'; } };
var sql = mysql.format('UPDATE posts SET modified = ? WHERE id = ?', [CURRENT_TIMESTAMP, 42]);
console.log(sql); // UPDATE posts SET modified = CURRENT_TIMESTAMP() WHERE id = 42

</pre><pre>
To generate objects with a toSqlString method, the mysql.raw() method can be used. This creates an object that will be left un-touched when using in a ? placeholder, useful for using functions as dynamic values:

The string provided to mysql.raw() will skip all escaping functions when used, so be careful when passing in unvalidated input.

</pre><pre class="js">
var CURRENT_TIMESTAMP = mysql.raw('CURRENT_TIMESTAMP()');
var sql = mysql.format('UPDATE posts SET modified = ? WHERE id = ?', [CURRENT_TIMESTAMP, 42]);
console.log(sql); // UPDATE posts SET modified = CURRENT_TIMESTAMP() WHERE id = 42

</pre><pre>
【 Escaping query identifiers 】
If you can't trust an SQL identifier (database / table / column name) because it is provided by a user, you should escape it with mysql.escapeId(identifier), connection.escapeId(identifier) or pool.escapeId(identifier)

</pre><pre class="js">
var sorter = 'date';
var sql    = 'SELECT * FROM posts ORDER BY ' + connection.escapeId(sorter);
connection.query(sql, function (error, results, fields) {
  if (error) throw error;
  console.log(results)
});

var sorter = 'date';
var sql    = 'SELECT * FROM posts ORDER BY ' + connection.escapeId('posts.' + sorter);
console.log(sql);  // SELECT * FROM posts ORDER BY `posts`.`date`

</pre>If you do not want to treat . as qualified identifiers, you can set the second argument to true in order to keep the string as a literal identifier<pre class="js">
var sorter = 'date.2';
var sql    = 'SELECT * FROM posts ORDER BY ' + connection.escapeId(sorter, true);
console.log(sql);  // SELECT * FROM posts ORDER BY `date.2`

</pre>you can use ?? characters as placeholders for identifiers you would like to have escaped<pre class="js">
var userId = 1;
var columns = ['username', 'age'];
var query = connection.query('SELECT ?? FROM ?? WHERE uid = ?', [columns, 'users', userId], (error, results) => {
  if (error) throw error;
  console.log(results)
});
console.log(query.sql); // SELECT `username`, `age` FROM `users` WHERE uid = 1

var query = connection.query('SELECT ? FROM ? WHERE uid = ?', [columns, 'users', userId], (error, results) => {
  if (error) throw error;
  console.log(results)
});
console.log(query.sql); // SELECT 'username', 'age' FROM 'users' WHERE uid = 1
// Error: ER_PARSE_ERROR: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ''users' WHERE uid = 1' at line 1

</pre><pre>
【 Preparing Queries 】
You can use mysql.format to prepare a query with multiple insertion points, utilizing the proper escaping for ids and values. A simple example of this follows:

</pre><pre class="js">
var sql = "SELECT * FROM ?? WHERE ?? = ?";
var inserts = ['users', 'id', userId];
sql = mysql.format(sql, inserts);

</pre><pre>
Following this you then have a valid, escaped query that you can then send to the database safely. This is useful if you are looking to prepare the query before actually sending it to the database. As mysql.format is exposed from SqlString.format you also have the option (but are not required) to pass in stringifyObject and timezone, allowing you provide a custom means of turning objects into strings, as well as a location-specific/timezone-aware Date

【 Streaming query rows 】
Sometimes you may want to select large quantities of rows and process each of them as they are received

</pre><pre class="js">
var query = connection.query('SELECT * FROM posts');
query
  .on('error', err => console.log("Handle error, an 'end' event will be emitted after this as well"))
  .on('fields', fields => console.log("the field packets for the rows to follow"))
  .on('result', row => {
    connection.pause();   // Pausing the connnection is useful if your processing involves I/O
    processRow(row, () => connection.resume());
  })
  .on('end', () => console.log("all rows have been received"));

</pre><pre>
Usually you will want to receive a certain amount of rows before starting to throttle the connection using pause(). This number will depend on the amount and size of your rows.

pause() / resume() operate on the underlying socket and parser. You are guaranteed that no more 'result' events will fire after calling pause().

You MUST NOT provide a callback to the query() method when streaming rows.

The 'result' event will fire for both rows as well as OK packets confirming the success of a INSERT/UPDATE query.

It is very important not to leave the result paused too long, or you may encounter Error: Connection lost: The server closed the connection. The time limit for this is determined by the net_write_timeout setting on your MySQL server.

Additionally you may be interested to know that it is currently not possible to stream individual row columns, they will always be buffered up entirely. If you have a good use case for streaming large fields to and from MySQL, I'd love to get your thoughts and contributions on this.

Piping results with Streams
The query object provides a convenience method .stream([options]) that wraps query events into a Readable Stream object. This stream can easily be piped downstream and provides automatic pause/resume, based on downstream congestion and the optional highWaterMark. The objectMode parameter of the stream is set to true and cannot be changed (if you need a byte stream, you will need to use a transform stream, like objstream for example).

</pre>piping query results into another stream (with a max buffer of 5 objects)<pre class="js">
connection.query('SELECT * FROM posts')
  .stream({highWaterMark: 5})
  .pipe(...);

</pre><pre>
【 Multiple statement queries 】
Support for multiple statements is disabled for security reasons (it allows for SQL injection attacks if values are not properly escaped). To use this feature you have to enable it for your connection
Once enabled, you can execute multiple statement queries like any other query

If one of the statements in your query causes an error, the resulting Error object contains a err.index property which tells you which statement caused it. MySQL will also stop executing any remaining statements when an error occurs.

</pre><pre class="js">
var connection = mysql.createConnection({multipleStatements: true});
connection.query('SELECT 1; SELECT 2', (error, results, fields) => {
  if (error) throw error;
  console.log(results[0]); // [{1: 1}]
  console.log(results[1]); // [{2: 2}]
});

</pre>Additionally you can also stream the results of multiple statement queries<pre class="js">
var query = connection.query('SELECT 1; SELECT 2');
query
  .on('fields', (fields, index) => console.log("the fields for the result rows that follow"))
  .on('result', (row, index) => console.log("index refers to the statement this result belongs to (starts at 0)"));

</pre>【 Transactions 】<pre class="js">
connection.beginTransaction(err => {
  if (err) throw err;
  connection.query('INSERT INTO posts SET title=?', title, (error, results, fields) => {
    if (error) return connection.rollback(() => throw error);
    var log = 'Post ' + results.insertId + ' added';
    connection.query('INSERT INTO log SET data=?', log, (error, results, fields) => {
      if (error) return connection.rollback(() => throw error);
      connection.commit(err => {
        if (error) return connection.rollback(() => throw error);
        console.log('success!');
      });
    });
  });
});

</pre>【 Ping 】<pre class="js">
connection.ping(function (err) {
  if (err) throw err;
  console.log('Server responded to ping');
})

</pre><pre>
【 Error handling 】
err.code
String, contains the MySQL server error symbol if the error is a MySQL server error (e.g. 'ER_ACCESS_DENIED_ERROR'), a Node.js error code if it is a Node.js error (e.g. 'ECONNREFUSED'), or an internal error code (e.g. 'PROTOCOL_CONNECTION_LOST').

err.errno
Number, contains the MySQL server error number. Only populated from MySQL server error.

err.fatal
Boolean, indicating if this error is terminal to the connection object. If the error is not from a MySQL protocol operation, this property will not be defined.

err.sql
String, contains the full SQL of the failed query. This can be useful when using a higher level interface like an ORM that is generating the queries.

err.sqlState
String, contains the five-character SQLSTATE value. Only populated from MySQL server error.

err.sqlMessage
String, contains the message string that provides a textual description of the error. Only populated from MySQL server error.

</pre>Fatal errors are passed to all pending callbacks<pre class="js">
var connection = require('mysql').createConnection({
  port: 84943, // WRONG PORT
});

connection.connect(err => {
  console.log(err.code);      // 'ECONNREFUSED'
  console.log(err.fatal);     // true
});

connection.query('SELECT 1', function (error, results, fields) {
  console.log(error.code);    // 'ECONNREFUSED'
  console.log(error.fatal);   // true
});

</pre>Normal errors however are only delegated to the callback they belong to<pre class="js">
connection.query('USE name_of_db_that_does_not_exist', function (error, results, fields) {
  console.log(error.code);     // 'ER_BAD_DB_ERROR'
});

connection.query('SELECT 1', function (error, results, fields) {
  console.log(error);          // null
  console.log(results.length); // 1
});

</pre>If a fatal errors occurs and there are no pending callbacks, or a normal error occurs which has no callback belonging to it, the error is emitted as an 'error' event on the connection object<pre class="js">
connection.on('error', function(err) {
  console.log(err.code);       // 'ER_BAD_DB_ERROR'
});

connection.query('USE name_of_db_that_does_not_exist');

</pre><pre>
【 建表初始化 】
通常初始化数据库要建立很多表,特别在项目开发的时候表的格式可能会有些变动,这时候就需要封装对数据库建表初始化的方法,保留项目的sql脚本文件,然后每次需要重新建表,则执行建表初始化程序就行

具体流程：
遍历sql目录下的sql文件 -> 解析所有sql文件脚本内容 ->  执行sql脚本

</pre><pre class="js">
├── index.js # 程序入口文件
├── node_modules/
├── package.json
├── sql   # sql脚本文件目录
│   ├── data.sql
│   └── user.sql
└── util    # 工具代码
    ├── db.js # 封装的mysql模块方法
    ├── get-sql-content-map.js # 获取sql脚本文件内容
    ├── get-sql-map.js # 获取所有sql脚本文件
    └── walk-file.js # 遍历sql脚本文件

/* 数据库操作文件 ./util/db.js */
const mysql = require('mysql')
const pool = mysql.createPool({
  host     :  '127.0.0.1',
  user     :  'root',
  password :  'abc123',
  database :  'koa_demo'
})

let query = function( sql, values ) {
  return new Promise(( resolve, reject ) => {
    pool.getConnection(function(err, connection) {
      if (err) return reject( err );
      connection.query(sql, values, (err, rows) => {
        err ? reject(err) : resolve(rows);
        connection.release();
      })
    })
  })
}

module.exports = { query }

/* 获取所有sql脚本内容 ./util/get-sql-content-map.js */
const fs = require('fs')
const getSqlMap = require('./get-sql-map')
let sqlContentMap = {}

// 读取sql文件内容
function getSqlContent( fileName,  path ) {
  let content = fs.readFileSync( path, 'binary' )
  sqlContentMap[ fileName ] = content
}

// 封装所有sql文件脚本内容
function getSqlContentMap () {
  let sqlMap = getSqlMap()
  for( let key in sqlMap ) getSqlContent( key, sqlMap[key] )
  return sqlContentMap
}

module.exports = getSqlContentMap

/* 获取sql目录详情 ./util/get-sql-map.js */
const fs = require('fs')
const walkFile = require('./walk-file')

// 获取sql目录下的文件目录数据
function getSqlMap () {
  let basePath = __dirname
  basePath = basePath.replace(/\\/g, '\/')

  let pathArr = basePath.split('\/')
  pathArr = pathArr.splice( 0, pathArr.length - 1 )
  basePath = pathArr.join('/') + '/sql/'

  let fileList = walkFile( basePath, 'sql' )
  return fileList
}

module.exports = getSqlMap

/* 遍历目录操作 ./util/walk-file.js */
const fs = require('fs')

// 遍历目录下的文件目录
const walkFile = function(  pathResolve , mime ){
  let files = fs.readdirSync( pathResolve )
  let fileList = {}
  for( let [ i, item] of files.entries() ) {
    let itemArr = item.split('\.')
    let itemMime = ( itemArr.length > 1 ) ? itemArr[ itemArr.length - 1 ] : 'undefined'
    let keyName = item + ''
    if( mime === itemMime ) fileList[ item ] =  pathResolve + item
  }
  return fileList
}

module.exports = walkFile

/* 入口文件 ./index.js */
const fs = require('fs');
const getSqlContentMap = require('./util/get-sql-content-map');
const { query } = require('./util/db');

// 打印脚本执行日志
const eventLog = function( err , sqlFile, index ) {
  if( err ) {
    console.log(`[ERROR] sql脚本文件: ${sqlFile} 第${index + 1}条脚本 执行失败 o(╯□╰)o ！`)
  } else {
    console.log(`[SUCCESS] sql脚本文件: ${sqlFile} 第${index + 1}条脚本 执行成功 O(∩_∩)O !`)
  }
}

// 获取所有sql脚本内容
let sqlContentMap = getSqlContentMap()

// 执行建表sql脚本
const createAllTables = async () => {
  for( let key in sqlContentMap ) {
    let sqlShell = sqlContentMap[key]
    let sqlShellList = sqlShell.split(';')
    for ( let [ i, shell ] of sqlShellList.entries() ) {
      if ( shell.trim() ) {
        let result = await query( shell )
        if ( result.serverStatus * 1 === 2 ) {
          eventLog( null,  key, i)
        } else {
          eventLog( true,  key, i)
        }
      }
    }
  }
  console.log('sql脚本执行结束！')
  console.log('请按 ctrl + c 键退出！')
}

createAllTables()

/* sql脚本文件 ./sql/data.sql */
CREATE TABLE   IF NOT EXISTS  `data` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `data_info` json DEFAULT NULL,
  `create_time` varchar(20) DEFAULT NULL,
  `modified_time` varchar(20) DEFAULT NULL,
  `level` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8

/* sql脚本文件 ./sql/user.sql */
CREATE TABLE   IF NOT EXISTS  `user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `email` varchar(255) DEFAULT NULL,
  `password` varchar(255) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `nick` varchar(255) DEFAULT NULL,
  `detail_info` json DEFAULT NULL,
  `create_time` varchar(20) DEFAULT NULL,
  `modified_time` varchar(20) DEFAULT NULL,
  `level` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

INSERT INTO `user` set email='1@example.com', password='123456';
INSERT INTO `user` set email='2@example.com', password='123456';
INSERT INTO `user` set email='3@example.com', password='123456';

</pre>
</div>

<div id="sequelize">
<h3>ORM框架Sequelize</h3><pre>
访问MySQL数据库只有一种方法,就是通过网络发送SQL命令,然后MySQL服务器执行后返回结果。
如果直接使用mysql包(驱动程序)提供的接口编写的代码就比较底层

ORM技术：Object-Relational Mapping把关系数据库的表结构映射到js对象上,可由ORM框架实现这种转换
选择Node的ORM框架Sequelize来操作数据库,这样读写的都是Js对象,Sequelize把对象变成数据库中的行

mysql包是驱动,sequelize是通过mysql包操作数据库

Sequelize是一款基于Nodejs功能强大的异步ORM框架,同时支持PostgreSQL, MySQL, SQLite and MSSQL多种数据库,很适合作为Nodejs后端数据库的存储接口,为快速开发Nodejs应用奠定扎实、安全的基础。

Sequelize is a promise-based Node.js ORM for Postgres, MySQL, MariaDB, SQLite and Microsoft SQL Server. It features solid transaction support, relations, eager and lazy loading, read replication and more.

sequelize返回的对象是promise,使用then()和catch()分别异步响应成功和失败,还可用ES7的async和await来调用任何一个promise对象

</pre>ORM是对SQL查询语句的封装,用OOP的方式操作数据库,优雅的生成安全、可维护的SQL代码,直观上是一种Model和SQL的映射关系<pre class="js">
const User = sequelize.define('user', {
  id: {
    type: Sequelize.INTEGER,
    allowNull: false,
    autoIncrement: true,
    primaryKey: true
  },
  email: {
    type: Sequelize.STRING,
    allowNull: false,
    validate: { isEmail: true },
    unique: true
  }
})

CREATE TABLE IF NOT EXISTS `users` (
  `id` INTEGER NOT NULL auto_increment ,
  `email` VARCHAR(255) NOT NULL UNIQUE
  `createdAt` DATETIME NOT NULL,
  `updatedAt` DATETIME NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

</pre><pre>
【 Sequelize安装 】
squelize可以通过npm命令获取,除安装sequelize模块外还要安装所使用数据的驱动模块：
$ npm install --save sequelize
# 还需要安装以下之一：
$ npm install --save mysql
$ npm install --save pg pg-hstore  // Postgres
$ npm install --save mariadb
$ npm install --save sqlite3
$ npm install --save tedious       // Microsoft SQL Server

【 使用Sequelize操作数据库的步骤 】
首先通过某个Model对象的findAll()方法获取实例,findAll()方法可以接收where、order这些参数,这和将要生成的SQL语句是对应的
如果要更新实例,先对实例属性赋新值,再调用实例的save()方法;
如果要删除实例,直接调用实例的destroy()方法。

</pre><pre class="js">
const Sequelize = require('sequelize');
const config = require('./config');
console.log('init sequelize...');

// 创建sequelize实例对象
var sequelize = new Sequelize(config.database, config.username, config.password, {
  host: config.host,
  dialect: 'mysql',
});

// 定义Model数据模型Pet,告诉sequelize如何映射数据表,默认表名是pets
var Pet = sequelize.define('pet', {
  id: {
    type: Sequelize.STRING(50),
    primaryKey: true         // 主键值唯一
  },
  name: Sequelize.STRING(100),
  gender: Sequelize.BOOLEAN,
  birth: Sequelize.STRING(10),
  createdAt: Sequelize.BIGINT,
  updatedAt: Sequelize.BIGINT,
  version: Sequelize.BIGINT
}, {
  timestamps: false            // 第三参数是额外配置,关闭sequelize自动添加timestamp的功能
});

var now = Date.now();

// 添加数据,promise写法
const createPromise = () => {
  return Pet.create({ id: 'g-' + now, name: 'Gaffey', gender: false, birth: '2007-07-07', createdAt: now, updatedAt: now, version: 0 })
  .then(p => console.log('>> created Gaffey.' + JSON.stringify(p)))
  .catch(err => console.log('>> failed: ' + err))
}

const createawait = async () => {
  await Pet.create({ id: 'p-' + now, name: 'peg', gender: false, birth: '2007-12-12', createdAt: now, updatedAt: now, version: 0 })
  .then(p => console.log('>> created peg.' + JSON.stringify(p)))
  .catch(err => console.log('>> failed: ' + err))
}

// ES7 async/await写法
const createdog = async () => {
  var dog = await Pet.create({ id: 'd-' + now, name: 'Odie', gender: false, birth: '2008-08-08', createdAt: now, updatedAt: now, version: 0 });
  console.log('>> created Odie: ' + JSON.stringify(dog));
};

// 通过Pet.findAll()返回的一个组对象称为Model实例,每个实例都可直接通过JSON.stringify序列化为JSON字符串,但是它们和普通JSON对象相比,多了一些由Sequelize添加的方法,如save()和destroy()。调用这些方法可以执行更新或删除操作
const findAllSaveDestroy = async () => {
  var pets = await Pet.findAll({    // 查询数据
    where: { name: 'Gaffey'}
  });
  console.log(`find ${pets.length} pets:`);
  for (let p of pets) {
    console.log(JSON.stringify(p));
    console.log('update pet...');
    console.log(p);
    p.gender = true;
    p.updatedAt = Date.now();
    p.version ++;
    await p.save();             // 更新数据
    if (p.version === 3) {
      await p.destroy();        // 删除数据
      console.log(`${p.name} was destroyed.`);
    }
  }
};

const init = async() => {
  console.time('test');
  try{
    // test: 1085.647ms 异步写法
    await createPromise();
    await createawait();
    await createdog();
    await findAllSaveDestroy();
    实例的
    // test: 377.558ms  同步写法
    // await Promise.all([createPromise(), createawait(), createdog()])
    // await findAllSaveDestroy();
  }catch(err){
    console.err(err);
  }
  console.timeEnd('test');
}

init();

</pre>

<h4>Sequelize类</h4><pre>
1 new Sequelize() - 实例化
2 new Sequelize() - 通过URI实例化
3 sequelize.models - 实例中已定义的模型
4 sequelize.define() - 模型定义
5 Sequelize - 顶级对象
6 Utils - 工具类
7 Promise - Promise对象
8 QueryTypes - 查询类型枚举
9 Validator - validator.js对象
10 Transaction - 事务对象
11 Deferrable - 延时对象
12 Instance - 实例对象
13 Association - 联合关系对象
14 Error - 错误对象
15 ValidationError - 验证失败错误对象
16 DatabaseError - 数据库错误对象
17 TimeoutError - 查询超时错误对象
18 UniqueConstraintError - 唯一性错误对象
19 ExclusionConstraintError - 排出约束错误对象
20 ForeignKeyConstraintError - 外键约束错误对象
21 ConnectionError - 连接错误对象
22 ConnectionRefusedError - 连接拒绝错误对象
23 AccessDeniedError - 无访问权限错误对象
24 HostNotFoundError - 主机未找到错误对象
25 InvalidConnectionError - 无效链接错误对象
26 ConnectionTimedOutError - 链接超时错误对象
27 InstanceError - 实例错误对象
28 sequelize.getDialect() - 返回数据库类型
29 sequelize.getQueryInterface() - 返回QueryInterface实例
30 sequelize.define() - 模型定义
31 sequelize.model() - 获取模型
32 sequelize.isDefined() - 检查模型是否定义
33 sequelize.import() - 模型导入
34 sequelize.query() - 执行查询
35 sequelize.set() - 设置变量
36 sequelize.escape() - 编码
37 sequelize.createSchema() - 创建数据库 schema
38 sequelize.showAllSchemas() - 查询已定义的schema
39 sequelize.dropSchema() - 删除定义的schema
40 sequelize.dropAllSchemas() - 删除所有schema
41 sequelize.sync() - 同步模型到数据库
42 sequelize.truncate() - 截断已定义的表
43 sequelize.drop() - 删除表
44 sequelize.authenticate() - 验证连接
45 sequelize.fn() - 函数调用
46 sequelize.col() - 列对象
47 sequelize.cast() - cast函数
48 sequelize.literal() - 字面量对象
49 sequelize.and() - AND查询
50 sequelize.or() - OR查询
51 sequelize.json() - json嵌套对象
52 sequelize.where() - 指定WHERE条件
53 sequelize.transaction() - 启动事务

【  Sequelize - 顶级对象 】
var Sequelize = require('sequelize');

Sequelize是一个指向sequelize模块顶级对象引用,同时也是一个构造函数。可以通过该构造函数进行Sequelize类的实例化;也可以通过该对象来访问模块中子对象,如：DataTypes、Errors、Transactions等

【 Sequelize.Utils - 工具类 】
一个指定sequelize中工具类的引用,大多数情况下需要直接引用该对象,如：可以使用Sequelize.Utils._属性,该属性是一个指向lodash库的引用,如果你项目中没有另外引用该库就可以通过该属性来调用

【 Sequelize.Promise对象 】
该属性是一个指向bluebirdPromise类型的引用

【 Sequelize.QueryTypes - 查询类型枚举 】
用于sequelize.query的表示查询类型的枚举对象

console.log(Sequelize.QueryTypes)
{ SELECT: 'SELECT',
  INSERT: 'INSERT',
  UPDATE: 'UPDATE',
  BULKUPDATE: 'BULKUPDATE',
  BULKDELETE: 'BULKDELETE',
  DELETE: 'DELETE',
  UPSERT: 'UPSERT',
  VERSION: 'VERSION',
  SHOWTABLES: 'SHOWTABLES',
  SHOWINDEXES: 'SHOWINDEXES',
  DESCRIBE: 'DESCRIBE',
  RAW: 'RAW',
  FOREIGNKEYS: 'FOREIGNKEYS',
  SHOWCONSTRAINTS: 'SHOWCONSTRAINTS' }

【 Sequelize.Validator 】
一个指定validator.js对象的引用,该对象用于Sequelize内部的验证,如：非常、URL、IP等,也可以通过该属性进行一些自定义验证。

【 Sequelize.Transaction 】
该属性是一个指向SequelizeTransaction类的引用,要以使用这个属性来访问创建事务的隔离级别和事务类型等

【 Sequelize.Deferrable 】
指向一个延时集合的引用,通过个属性可以访问不同的延时选项
当你指定一个可选的外键列,那么可以在PostgreSQL定义为Deferrable类型

【 Sequelize.Instance 】
一个指定Sequelize实例类的引用

【 Sequelize.Association -联合关系对象 】
一个指定Association类的引用

【 Sequelize.Error 】
Sequelize中生成错误的类

【 Sequelize.ValidationError - 验证失败错误对象 】
验证失败时会生成此对象

【 Sequelize.DatabaseError - 数据库错误对象
验证失败时会生成此对象,指向一个所有数据库相关错误的类

【 Sequelize.TimeoutError - 查询超时错误对象 】
当数据库查询超时时会生成TimeoutError对象

【 Sequelize.UniqueConstraintError - 唯一性错误对象 】
当数违反唯一约束时会生成UniqueConstraintError对象。

【 Sequelize.ExclusionConstraintError - 排出约束错误对象 】
在数据库中违反排除约束时触发此错误

【 Sequelize.ForeignKeyConstraintError - 外键约束错误对象 】
在数据库中违反外键约束时触发此错误。

【 Sequelize.ConnectionError - 连接错误对象 】
一个指向数据库连接错误时触发的错误对象

【 Sequelize.ConnectionRefusedError - 连接拒绝错误对象 】
一个指向数据库连接被拒绝时触发的错误对象。

【 Sequelize.AccessDeniedError - 无访问权限错误对象 】
连接到数据库但没有访问权限时会触发此错误

【 Sequelize.HostNotFoundError - 主机未找到错误对象 】
连接数据但主机名(IP或URI)未找到时会触发这个错误对象

【 Sequelize.InvalidConnectionError - 无效链接错误对象 】
连接到数据库但其中的任意参数出现错误时会触发这个错误对象

【 Sequelize.ConnectionTimedOutError - 链接超时错误对象 】
连接数据库超时时会触发这个错误对象

【 Sequelize.InstanceError - 实例错误对象 】
当任何实例方法出现问题时会触发这个错误对象

【 sequelize.getQueryInterface() - 返回QueryInterface实例 】
返回QueryInterface的实例

【 sequelize.getDialect() - 返回数据库类型 】
该实例方法用于返回实例类型(数据库类型)
console.log(sequelize.getDialect())  // mysql

【 sequelize.models 】
该实例属性用于返回通过sequelize.define定义的所有模型对象

返回值如下
{ User: User, UserRole: UserRole, …… }

【 sequelize.model(modelName]) -> model 】
获取一个已经定义的模型,modelName表示通过sequelize.define定义的模型名

【 sequelize.isDefined(modelName) -> Boolean 】
检查模型是否已经定义。modelName表示通过sequelize.define定义的模型名

【 sequelize.set(variables, options) -> Promise 】
设置一个变量,设置后将会执行基于环境变量或用户变量的查询。此变量会在每次建立连接时设置,仅MySQL适用

variables Object
包含多个变量的对象

options Object
查询选项

options.transaction Transaction
是否在事务中执行查询

【 sequelize.escape(value) -> String 】
对值value进行编码并返回编码结果

【 sequelize.createSchema(schema: String, options={}) -> Promise 】
创建一个新的数据库schema

options.logging Boolean | function
日志打印函数

【 sequelize.showAllSchemas(options={}) -> Promise 】
查询数据库中已定义的schema
options.logging Boolean | function  日志打印函数

sequelize.showAllSchemas().then(re => console.log(re))
/*
Executing (default): SHOW TABLES
[ { Tables_in_sequelize: 'picture' },
  { Tables_in_sequelize: 'user' } ]
*/

【 sequelize.dropSchema(schema:String , options={}) -> Promise 】
删除数据库中已定义指定名称的schema

options.logging Boolean | function
日志打印函数

【 sequelize.dropAllSchemas(options={}) -> Promise 】
删除数据库中所有已定义的schema

options.logging Boolean | function
日志打印函数

【 sequelize.truncate([options={}]) -> Promise 】
截断所有已定义的模型所对应的表,这个操作实际上是调用每个模型的Model.truncate()方法

options.transaction Boolean | function

options.logging Boolean | function
日志打印函数

【 sequelize.drop(options={}) -> Promise 】
删除所有已定义的模型所对应的表,这个操作实际上是调用每个模型的Model.drop()方法

options.logging Boolean | function
日志打印函数

【 sequelize.authenticate() -> Promise 】
验证已建立的连接,别名：validate

【 sequelize.fn(fn, args) -> Sequelize.fn 】
函数调用;创建于一个相当于数据库函数的对象。该函数可用于搜索查询的where和order部分以及做为列定义的默认值。如果想在列中引用定义的函数就要使用sequelize.col,这样列就能正确的解析,而不是解析为字符串。

如将username字段值解析为大写形式：
instance.updateAttributes({
  username: self.sequelize.fn('upper', self.sequelize.col('username'))
})

fn  String
要调用的函数

args  any
传递给调用函数的参数

【 sequelize.col() - 列对象 】
col(col) -> Sequelize.col
创建一个相当于数据库列的对象。这个方法经常结合sequelize.fn使用,它可以保证将列名正确的传递给该方法,而不是经过转义。
col参数表示列名

【 sequelize.cast() - cast函数 】
cast(val, type) -> Sequelize.cast
创建一个表示cast函数调用的对象

val－{any},cast的值
type－{String},cast类型

【 sequelize.literal() - 字面量对象 】
literal(val) -> Sequelize.literal
创建一个字面量对象,该值不会转义,别名：asIs

【 sequelize.and() - AND查询 】
and(args) -> Sequelize.and
AND查询

val－{String | Object},会被AND连接的参数

【 sequelize.or() - OR查询 】
or(args) -> Sequelize.or
OR查询

val－{String | Object},会被OR连接的参数

【 sequelize.where() - 指定WHERE条件 】
where(conditions, [value]) -> Sequelize.where
指定属性＝条件。

属性也可以从Model.rawAttributes对象获取(如：Model.rawAttributes.id、Model.rawAttributes.name)。属性应该已在模型中定义。也可以从sequelize工具函数中获取(如：sequelize.fn,、sequelize.col

当使用字符串属性是,用于{ where: { attr: something }}语法。如果不希望属性被转义,请使用sequelize.literal。

attr－{Object},属性
[comparator='=']－{String}
logic－{String ｜ Object},限制条件可以是简单字符串或进一步的条件对象(如：$or、$and、.litera)
别名：condition

</pre>
</div>

<div id="new_Sequelize">
<h4>建立连接,Setting up a connection</h4><pre>
var Sequelize = require('sequelize');
var sequelize = new Sequelize(database, [username=null], [password=null], [options={}])

</pre><pre class="js">
/* config.js */
module.exports = {
  development: {
    root: require('path').normalize(__dirname + '/../..'),
    app: {
      name: 'test API',
    },
    db: {
      database: 'sequelize',
      username: 'admin',
      password: '',
      options: {
        dialect: 'mysql',
        host: '127.0.0.1',
        port: '3306',
        pool: {
          maxConnections: 5,
          minConnections: 0,
          maxIdleTime: 1000
        },
        timezone: '+08:00' //东八时区
        "define": {
          "timestamps": false,     // 是否自动添加createAt 和 updateAt这两个字段
          "freezeTableName": true  // 冻结表名,默认sequelize会帮你的定义的表名字自动加上s
        }
      }
    }
  }
}

var node_env = process.env.NODE_ENV ? process.env.NODE_ENV : 'development';
var config = require('../config/config')[node_env];  // 根据系统环境载入配置
export.sequelize = new Sequelize(config,database, config.username, config.password, config.options)

</pre><pre>
通过Sequelize构造函数实例化、初始化后就可以通过其返回的sequelize实例定义Model、执行query查询、执行transaction等

database  String
数据库名

[username=null] String
数据库用户名

[password=null] String
数据库密码

[options={}]  Object
参数对象

[options.dialect] String
要连接的数据库类型,可选值有：mysql、postgres、sqlite、mariadb、mssql

[options.dialectModulePath=null]  String
指定后将通过此路径模块加载数据库

[options.dialectOptions]  Object
路径模块所使用的扩展选项

[options.host='localhost']  String
连接数据库的主机

[options.port=] String
连接数据库的端口

[options.protocol='tcp']  String
连接数据库使用的协议

[options.define={}] Object
定义模型sequelize.define()的默认选项
应用级别的模型参数:Sequelize构造函数的define参数可以可以为所有模型定义默认的参数

</pre>Changing the default model options<pre class="js">
// The `timestamps` field specify whether or not the `createdAt` and `updatedAt` fields will be created,This was true by default, but now is false by default
const sequelize = new Sequelize(connectionURI, {
  define: {
    timestamps: false
  }
});

// Here `timestamps` will be false, so the `createdAt` and `updatedAt` fields will not be created.
const Foo = sequelize.define('foo', {attributes})

// Here `timestamps` is directly set to true, so the `createdAt` and `updatedAt` fields will be created.
const Bar = sequelize.define('bar', {attributes}, {timestamps: true})

</pre><pre>
[options.query={}]  Object
'sequelize.query'的默认选项

[options.set={}]  Object
'sequelize.set'的默认选项

[options.sync={}] Object
'sequelize.sync'的默认选项

[options.timezone='+00:00'] String
时间转换时从数据库得到的JS时间,这个时区将应用于连接服务器的NOW、CURRENT_TIMESTAMP或其它日期函数
timezone: '+08:00',

[options.operatorsAliases={}]  Object
设置别名,否则不识别$like等关键词($like: Op.like对应关系)

</pre><pre class="js">
const Op = Sequelize.Op;
const operatorsAliases = {
  $gt: Op.gt
}
const connection = new Sequelize(db, user, pass, { operatorsAliases })

[Op.gt]: 6   // > 6
$gt: 6

</pre><pre>
[options.logging=console.log] Function
用于Sequelize日志打印的函数

[options.omitNull=false]  Boolean
null值是否通过SQL查询

[options.native=false]  Boolean
是否使用本地库,仅用于postgres

[options.replication=false] Boolean
是否使用读/写复制(读写分离)。
要启用读/写复制需要传递一个对象,这个对象有read、write两个属性,write是一个单一的对象(由单台服务器处理写入),而read是一个包含对象的数组(由多台服务器处理读取),每台read、write服务器都可以包含以下属性：host、port、username、password、database

[options.pool={}] Object
使用连接池连接,默认为true

[options.pool.maxConnections] Integer

[options.pool.minConnections] Integer

[options.pool.maxIdleTime]  Integer
连接最大空置时间(毫秒),超时后将释放连接

[options.pool.validateConnection] Function
连接验证函数

[options.transactionType='DEFERRED']  String
设置事务类型,详见Sequelize.Transaction.TYPES,仅Sqlite适用

[options.isolationLevel='REPEATABLE_READ']  String
设置事件的隔离级别,详见Sequelize.Transaction.ISOLATION_LEVELS

[options.retry] Object
设置自动查询时的重试标志

[options.retry.match] Array
匹配到指定的错误字符串之一后重试查询

[options.retry.max] Integer
设置重试次数

[options.typeValidation=false]  Boolean
在插入、更新等操作时执行类型验证

[options.benchmark=false] Boolean
在打印执行的SQL日志时输出执行时间(毫秒)

</pre>demo<pre class="js">
const Sequelize = require('sequelize');

// Option 1: Passing parameters separately
const sequelize = new Sequelize('database', 'username', 'password', {
  host: 'localhost',
  dialect: 'mysql'
  timezone: '+08:00',
});

// Option 2: Passing a connection URI,通过URI实例化
const sequelize = new Sequelize('postgres://user:pass@example.com:5432/dbname');
var sequelize = new Sequelize('mysql://localhost:3306/database', {})

// connection pool (production)
const sequelize = new Sequelize(config.database, config.username, config.password, {
  host: config.host,
  dialect: 'mysql',
  timezone: '+08:00',
  pool: {
    max: 5,                 // default 5, 连接池最大连接数量
    min: 0,                 // default 0, 连接池最小连接数量
    acquire: 30000,         // default 10000, 如果一个线程超过10秒钟没有被使用过就释放该线程
    idle: 30000,            // default 10000
    evict: 60000,           // default 60000
    handleDisconnects: true // default true
  }
});

// options.replication
const sequelize = new Sequelize('database', null, null, {
  dialect: 'mysql',
  port: 3306,
  timezone: '+08:00',
  replication: {
    read: [
      { host: '8.8.8.8', username: 'anotherusernamethanroot', password: 'lolcats!' },
      { host: 'localhost', username: 'root', password: null }
    ],
    write: { host: 'localhost', username: 'root', password: null }
  },
  pool: { // 如果要覆盖用于读取池的选项,可以在此处进行
    max: 20,
    idle: 30000
  },
})

// Testing the connection
sequelize
  .authenticate()
  .then(() => console.log('Connection has been established successfully.'))
  .catch(err => console.error('Unable to connect to the database:', err));

// Closing the connection,须数据库操作完毕之后再执行sequelize.close(),否则报错pool is draining and cannot accept work
sequelize.close()

</pre>
</div>

<div id="model_definition">
<h4>sequelize.define() - 模型model定义,Modeling a table</h4><pre>
Model相当于数据库中表,有时它也会被称为“模型”或“工厂”。Model对象不能通过构造函数创建,而只能通过sequlize.define方法来定义或通过sequlize.import导入。通过define定义一个Model就相当于定义了一种模型与数据表之间的映射关系,表中的字段通过参数对象attributes来定义,对象中的一个属性相当于表中的一个字段,通过模型可以实现对表记录的增、删、改、查等操作

A model is a class that extends Sequelize.Model

</pre>1、Sequelize.Model.init(attributes, options)<pre class="js">
// expect a table named users in the database with the fields firstName and lastName
class User extends Sequelize.Model {}
User.init({
  // attributes
  firstName: {
    type: Sequelize.STRING,
    allowNull: false,
  },
  lastName: {
    type: Sequelize.STRING,
  }
}, {
  sequelize,
  modelName: 'user',
  // options
  timestamps: false,
});

</pre><pre>
2、sequelize.define()
public sequelize.define(modelName: string, attributes: Object, options: Object): Model,

sequelize.define('model', { column: DataTypes.INTEGER })

use the define method To define mappings between a model and a table, Each column must have a datatype
Sequelize defines by default the fields id (primary key)、createdAt and updatedAt to every model

sequelize.define calls Model.init

</pre><pre class="js">
module.exports = (sequelize, DataTypes) => {
  const User = sequelize.define('user', {
    // attributes
    firstName: {
      type: Sequelize.STRING,
      allowNull: false,
      field: 'first_name',
    },
    lastName: {
      type: Sequelize.STRING,
      allowNull: false,
      field: 'last_name',
    },
    birthday: Sequelize.DATEONLY,
    email: {
      type: Sequelize.STRING,
      allowNull: false,
      validate: { isEmail: true },
      unique: true
    },
    job: {
      type: Sequelize.STRING,
      allowNull: false,
      set: function(val) {
        this.setDataValue('job', val.toUpperCase());
      }
    },
    about: {
      type: Sequelize.TEXT,
      allowNull: false,
      defaultValue: 'haha, it is a long story',
    }
  }, {
    // options
    freezeTableName: true,               // Model对应的表名将与model名相同
    paranoid: true,                      // 逻辑删除
    charset: 'utf8mb4',
    collate: 'utf8mb4_general_ci',
    getterMethods: {
      fullName: function()  {
        return this.getDataValue('firstName') + ' ' + this.getDataValue('lastName')   // user.fullName
      }
    },
    setterMethods   : {
      fullName: function(value) {
        var names = value.split(' ');
        this.setDataValue('firstName', names.slice(0, -1).join(' '));
        this.setDataValue('lastName', names.slice(-1).join(' '));
      }
    }
  });

  return User;
}

</pre><pre>
【 参数 】
modelName String
模型名,在sequelize.models属性中会使用这个名称;如果没有在options中指定表名,数据库中也会使用此属性做为表名。

attributes  Object
一个对象,其每个属性对应表中的一个列,每个列可以使用一个预定义的DataType、字符串或类型描述对象定义：

attributes.column String | DataType | Object
列的定义可以是字符串、预定义的Sequelize构造函数或对象。在定义列时可以指定数据类型、默认值、主键/外键等约束,还可以自定义访问器(getter)和设置器(setter)

attributes.column.type  String | DataType
DataType或字符串,表示列/属性/字段的数据类型

</pre>NOW、UUIDV1、UUIDV4这三个是用于指定默认值,所以不能用于类型定义<pre class="js">
// 定义一个UUID类型并指定默认值为v1版本的uuid字段
sequelize.define('model',` {
  uuid: {
    type: Sequelize.UUID,
    defaultValue: Sequelize.UUIDV1,
    primaryKey: true
  }
})

// 使用自定义的算法生成自定义的UUID默认值,可以为defaultValue指定一个返回UUID的函数
sequelize.define('model', {
  uuid: {
    type: DataTypes.UUID,
    defaultValue: function() {
      return generateMyId()
    },
    primaryKey: true
  }
})

var Task = sequelize.define('task', {
  title: Sequelize.STRING,
  description: Sequelize.TEXT,
  deadline: Sequelize.DATE,
  createtime: {
    type: Sequelize.DATE,
    defaultValue: Sequelize.NOW,
  },
})

</pre>type如果不存在则直接用字符串表示如'TIMESTAMP';如果默认值不是具体的数值,可用Sequelize.literal函数表示<pre class="js">
// tableName表名, u为别名
const user = sequelize.define('u', {
  userId: { type: DataTypes.INTEGER, primaryKey: true, autoIncrement: true },
  userName: { type: DataTypes.STRING, allowNull: false },
  birthDay: { type: 'TIMESTAMP' },
  gender: { type: DataTypes.INTEGER, defaultValue: 0 },
  salary: { type: DataTypes.DECIMAL(10, 2), allowNull: false },
  createAt: { type: 'TIMESTAMP', allowNull: false, defaultValue: Sequelize.literal('CURRENT_TIMESTAMP') },
  updateAt: { type: 'TIMESTAMP', defaultValue: Sequelize.literal('CURRENT_TIMESTAMP'), field: 'ctime' },
  deleteAt: { type: Sequelize.DATE, defaultValue: Sequelize.NOW },
}, { tableName: 'user' })
/*
CREATE TABLE IF NOT EXISTS `user` (`userId` INTEGER auto_increment , `userName` VARCHAR(255) NOT NULL,
  `birthDay` TIMESTAMP, `gender` INTEGER DEFAULT 0, `salary` DECIMAL(10,2) NOT NULL,
  `createAt` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `ctime` TIMESTAMP DEFAULT CURRENT_TIMESTAMP, `deleteAt` DATETIME, PRIMARY KEY (`userId`)
) ENGINE=InnoDB;
*/

</pre><pre class="js">
Sequelize.STRING                      // VARCHAR(255)
Sequelize.STRING(1234)                // VARCHAR(1234)
Sequelize.STRING.BINARY               // VARCHAR BINARY
Sequelize.TEXT                        // TEXT
Sequelize.TEXT('tiny')                // TINYTEXT

Sequelize.INTEGER                     // INTEGER
Sequelize.INTEGER(11)                 // INTEGER,为数据类型指定长度
Sequelize.BIGINT                      // BIGINT
Sequelize.BIGINT(11)                  // BIGINT(11)

Sequelize.FLOAT                       // FLOAT
Sequelize.FLOAT(11)                   // FLOAT(11)
Sequelize.FLOAT(11, 12)               // FLOAT(11,12)

Sequelize.DOUBLE                      // DOUBLE
Sequelize.DOUBLE(11)                  // DOUBLE(11)
Sequelize.DOUBLE(11, 12)              // DOUBLE(11,12)

Sequelize.DECIMAL                     // DECIMAL,小数,默认10位数,价格、工资、账户余额
Sequelize.DECIMAL(6, 2)               // DECIMAL(6,2);该列最多可存储6位数字,2位小数,因此范围是从-9999.99到9999.99
Sequelize.DECIMAL(6);                 // DECIMAL(6,0);这种情况下列不包含小数部分或小数点

Sequelize.DATE                        // DATETIME for mysql / sqlite, TIMESTAMP WITH TIME ZONE for postgres
Sequelize.DATE(6)                     // DATETIME(6) for mysql, 分数秒支持高达6位数的精度
Sequelize.DATEONLY                    // DATE without time, birthday: Sequelize.DATEONLY

Sequelize.BLOB                        // BLOB,可插入字符串或二进制buffer,查询时返回buffer
Sequelize.BLOB('tiny')                // TINYBLOB (bytea for PostgreSQL. Other options are medium and long)

Sequelize.UUID                        // UUID datatype for PostgreSQL and SQLite, CHAR(36) BINARY for MySQL
// defaultValue: Sequelize.UUIDV1 or Sequelize.UUIDV4 to make sequelize generate the ids automatically

Sequelize.GEOMETRY                    // Spatial column
Sequelize.GEOMETRY('POINT')           // Spatial column with geomerty type
Sequelize.GEOMETRY('POINT', 4326)     // Spatial column with geomerty type and SRID

// integer, bigint, float和double同样支持unsigned和zerofill约束
Sequelize.INTEGER.UNSIGNED              // INTEGER UNSIGNED
Sequelize.INTEGER(11).UNSIGNED          // INTEGER(11) UNSIGNED
Sequelize.INTEGER(11).ZEROFILL          // INTEGER(11) ZEROFILL
Sequelize.INTEGER(11).ZEROFILL.UNSIGNED // INTEGER(11) UNSIGNED ZEROFILL
Sequelize.INTEGER(11).UNSIGNED.ZEROFILL // INTEGER(11) UNSIGNED ZEROFILL,补零得到一个无符号整数

Sequelize.BOOLEAN                       // TINYINT(1)
Sequelize.ENUM('value 1', 'value 2')    // An ENUM with allowed values 'value 1' and 'value 2',只能字符串,数字报错

</pre>用Sequelize.ENUM('0', '1')代替Sequelize.BOOLEAN<pre class="js">
var Foo = sequelize.define('foo', {
  name: Sequelize.STRING,
  flag: { type: Sequelize.BOOLEAN, allowNull: false, defaultValue: true},
})
Foo.sync().then(() => {
  Foo.create({name: "name"})
})

报错：
nodejs output:
Unhandled rejection SequelizeDatabaseError: Incorrect integer value: 'true' for column 'flag' at row 1

mysql log:
INSERT INTO foos (id,name,flag,createdAt,updatedAt) VALUES (DEFAULT,'name','true','2019-06-27 22:41:25','2019-06-27 22:41:25')

解决：
var Foo = sequelize.define('foo', {
  name: Sequelize.STRING,
  flag: {type: Sequelize.ENUM('0', '1'), allowNull: false, defaultValue: '1'}
})
Foo.sync({force: true}).then(() => {
  Foo.create({name: "name"}).then(re => console.log(re.toJSON()))
})
/*
CREATE TABLE IF NOT EXISTS `foo` (`id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), `flag` ENUM('0', '1') NOT NULL DEFAULT '1', PRIMARY KEY (`id`)) ENGINE=InnoDB;
INSERT INTO `foo` (`id`,`name`,`flag`) VALUES (DEFAULT,?,?);
{ flag: '1', id: 1, name: 'name' }
*/

</pre>对象标记的用法<pre class="js">
// for enums:
sequelize.define('model', {
  states: {
    type:   Sequelize.ENUM,
    values: ['active', 'pending', 'deleted']
  },
  flag: {
    type: Sequelize.ENUM('0', '1'),
    allowNull: false,
    defaultValue: '1'
  }
})

</pre>Range types<pre class="js">
// defaults to '["2016-01-01 00:00:00+00:00", "2016-02-01 00:00:00+00:00")'
// inclusive lower bound, exclusive upper bound
Timeline.create({ range: [new Date(Date.UTC(2016, 0, 1)), new Date(Date.UTC(2016, 1, 1))] });

// control inclusion,控制是否包含该值
const range = [
  { value: new Date(Date.UTC(2016, 0, 1)), inclusive: false },
  { value: new Date(Date.UTC(2016, 1, 1)), inclusive: true },
];
// '("2016-01-01 00:00:00+00:00", "2016-02-01 00:00:00+00:00"]'

// composite form
const range = [
  { value: new Date(Date.UTC(2016, 0, 1)), inclusive: false },
  new Date(Date.UTC(2016, 1, 1)),
];
// '("2016-01-01 00:00:00+00:00", "2016-02-01 00:00:00+00:00")'

Timeline.create({ range });

// empty range:
Timeline.create({ range: [] }); // range = 'empty'

// Unbounded range:
Timeline.create({ range: [null, null] }); // range = '[,)'

// range = '[,"2016-01-01 00:00:00+00:00")'
Timeline.create({ range: [null, new Date(Date.UTC(2016, 0, 1))] });

// Infinite range:
// range = '[-infinity,"2016-01-01 00:00:00+00:00")'
Timeline.create({ range: [-Infinity, new Date(Date.UTC(2016, 0, 1))] });

</pre><pre>
[attributes.column.allowNull=true]  Boolean
设置为false时会给添加NOT NULL(非空)约束,数据保存时会进行非空验证

[attributes.column.defaultValue=null] Any
字面默认值、JS函数或一个SQL函数,查看sequelize.fn

[attributes.column.unique=false]  String | Boolean
设置为true时会为列添加唯一约束

[attributes.column.primaryKey=false]  Boolean
指定是否是主键

[attributes.column.autoIncrement=false] Boolean
是否自增

[attributes.column.field=null]  String
设置在数据库中的字段名,设置后Sequelize会将属性名映射到数据库中的不同列名称

</pre><pre class="js">
// 模型中属性名为fistName,数据库中列名为first_name,如果不指定field则自动映射相同名称的字段
firstName: {
  type: Sequelize.STRING,
  field: 'first_name',
},

</pre><pre>
[attributes.column.comment=null]  String
字段注释描述,自1.7+后此描述不再添加到数据库中

[attributes.column.references=null] String | Model
引用对象

</pre><pre class="js">
sequelize.define('Model', {
  foreign_id: {
    type: Sequelize.INTEGER,
    references: {
      model: OtherModel,
      key: 'id',
    }
  }
});

</pre><pre>
[attributes.column.references.model]  String | Model
如果列引用到另一个表,可以通过这个属性设置模型或字符串。

[attributes.column.references.key='id'] String
该列表示到表外键列的引用

[attributes.column.onUpdate]  String
当被引用的键更新时的操作,可选值是：CASCADE, RESTRICT, SET DEFAULT, SET NULL或NO ACTION 之一

[attributes.column.onDelete]  String
当被引用的键删除时的操作,可选值是：CASCADE, RESTRICT, SET DEFAULT, SET NULL 或 NO ACTION 之一

[attributes.column.get] Function
为列自定义一个访问器,使用this.getDataValue(String)时调用的值

[attributes.column.set] Function
为列自定义一个设置器,使用this.setDataValue(String, Value)时调用的值

</pre>在模型中将对象属性定义为访问/设置函数,Getters & setters - 访问器&设置器<pre class="js">
let MD5 = require('crypto').createHash('md5');

password: {
  type: Sequelize.STRING,
  defaultValue: '123456',        // 默认值
  set(val) {
    return MD5.update(val).digest('hex');
  }
},

</pre>定义为属性的一部分,可以被用来保护与数据库列相映射的属性,还可以定义一些假属性<pre class="js">
var Employee = sequelize.define('employee', {
  name:  {
    type: Sequelize.STRING,
    allowNull: false,
    get: function()  {
      var title = this.getDataValue('title');   // this允许去获得实例的属性
      return this.getDataValue('name') + ' (' + title + ')';
    },
  },
  title: {
    type: Sequelize.STRING,
    allowNull: false,
    set: function(val) {
      this.setDataValue('title', val.toUpperCase());
    }
  }
});

Employee
  .create({ name: 'John Doe', title: 'senior engineer' })
  .then(employee => {
    console.log(employee);
    console.log(employee.get('name'));  // John Doe (SENIOR ENGINEER)
    console.log(employee.get('title')); // SENIOR ENGINEER
  })

</pre><pre>
[attributes.validate] Object
模型每次保存时调用的验证对象,可是validator.js中的验证函数或自定义的验证函数,模型认证,可以规定模型中每个属性的格式/内容

通过模型列属性的validate属性来添加验证,这些验证会在模型实例执行create、update和save自动执行,也可以通过instance.validate()方法来手工验证模型实例

</pre><pre class="js">
var ValidateMe = sequelize.define('foo', {
  foo: {
    type: Sequelize.STRING,
    validate: {
      is: ["^[a-z]+$",'i'],     // will only allow letters
      is: /^[a-z]+$/i,          // same as the previous example using real RegExp
      not: ["[a-z]",'i'],       // will not allow letters
      isEmail: true,            // checks for email format (foo@bar.com)
      isUrl: true,              // checks for url format (http://foo.com)
      isIP: true,               // checks for IPv4 (129.89.23.1) or IPv6 format
      isIPv4: true,             // checks for IPv4 (129.89.23.1)
      isIPv6: true,             // checks for IPv6 format
      isAlpha: true,            // will only allow letters
      isAlphanumeric: true,     // will only allow alphanumeric characters, so "_abc" will fail
      isNumeric: true,          // will only allow numbers
      isInt: true,              // checks for valid integers
      isFloat: true,            // checks for valid floating point numbers
      isDecimal: true,          // checks for any numbers
      isLowercase: true,        // checks for lowercase
      isUppercase: true,        // checks for uppercase
      notNull: true,            // won't allow null
      isNull: true,             // only allows null
      notEmpty: true,           // don't allow empty strings
      equals: 'specific value', // only allow a specific value
      contains: 'foo',          // force specific substrings
      notIn: [['foo', 'bar']],  // check the value is not one of these
      isIn: [['foo', 'bar']],   // check the value is one of these
      notContains: 'bar',       // don't allow specific substrings
      len: [2,10],              // only allow values with length between 2 and 10
      isUUID: 4,                // only allow uuids
      isDate: true,             // only allow date strings
      isAfter: "2011-11-05",    // only allow date strings after a specific date
      isBefore: "2011-11-05",   // only allow date strings before a specific date
      max: 23,                  // only allow values
      min: 23,                  // only allow values >= 23
      isArray: true,            // only allow arrays
      isCreditCard: true,       // check for valid credit card numbers

      // 自定义错误信息,当多个参数需要被传递到内嵌的认证函数时,多个参数应该被放在一个数组中
      isIn: {
        args: [['en', 'zh']],
        msg: "Must be English or Chinese"
      },

      notNull: {
        msg: 'Please enter your name'
      },

      // custom validations
      isEven: function(value) {
        if(parseInt(value) % 2 != 0) {
          throw new Error('Only even values are allowed!')
          // in the model's context here, so this.otherField would get the value of otherField if it existed
        }
      },
    }
  }
});

</pre><pre>
[options] Object
提供给Sequelize构造函数的一些默认值,new Sequelize(database, [username=null], [password=null], [options={}])

[options.defaultScope={}] Object
定义使用此模型的默认搜索范围。作用范围与提供给find/findAll的选项形式相同

[options.scopes]  Object
更多范围,定义defaultScope的定义形式相同。关于限制范围的定义请参考Model.scope

[options.omitNull]  Boolean
是否忽略空值,这意味着所有列的空值将不会被保存

[options.timestamps=true] Boolean
为模型添加createdAt和updatedAt两个时间戳字段
By default, Sequelize will add the attributes createdAt and updatedAt to your model so you will be able to know when the database entry went into the db and when it was updated last

timestamps: false  // 关闭sequelize自动添加timestamp(updatedAt, createdAt)的功能

[options.paranoid=false]  Boolean
使用逻辑删除软删除,设置为true后调用destroy方法时将不会删队模型,而是设置一个deletedAt列字段,此设置需要timestamps=true

[options.underscored=false] Boolean
列名驼峰命名规则转换为下划线命令规则,underscored:true时updatedAt的字段名会是updated_at

[options.underscoredAll=false]  Boolean
转换模型名的驼峰命名规则为表名的下划线命令规则

[options.freezeTableName=false] Boolean
如果为true则数据库模型model的名称和实际对应的数据库名称保持一致,即user model对应数据表user
为false时会在数据库中映射表时增加复数表名即user在映射时映射成users,如果指定的表名称本就是复数形式则不变
freezeTableName: true

[options.tableName] String
定义模型所对应表的表名,设置freezeTableName为true时才会严格使用模型名

[options.name]  Object
允有singular和plural两个属性的对象,在模型与其它模型关联时使用

[options.name.singular=inflection.singularize(modelName)]  String
单数

[options.name.plural=inflection.pluralize(modelName)]  String
复数

[options.indexes] Array.< Object>
添加索引,Sequelize支持在模型定义中增加索引,这些索引在Model.sync()或sequelize.sync()时被创建

</pre><pre class="js">
sequelize.define('user', {}, {
  indexes: [
    // Create a unique index on email
    { unique: true, fields: ['email'] },

    // Creates a gin index on data with the jsonb_path_ops operator
    { fields: ['data'], using: 'gin', operator: 'jsonb_path_ops' },

    // By default index name will be [table]_[fields],Creates a multi column partial index
    {
      name: 'public_by_author',
      fields: ['author', 'status'],
      where: {
        status: 'public'
      }
    },

    // A BTREE index with a ordered field
    {
      name: 'title_index',
      method: 'BTREE',
      fields: ['author', {attribute: 'title', collate: 'en_US', order: 'DESC', length: 5}]
    }
  ]
})

</pre><pre>
[options.indexes[].name]  String
索引名,默认:模型名 + '_' + 字段名

[options.indexes[].type]  String
索引类型,仅用于mysql,其值为：UNIQUE、 FULLTEXT或SPATIAL之一

[options.indexes[].method]  String
创建索引的方法(SQL中的USING声明)。BTREE或HASH可以在mysql和postgres中支持,postgres中支持,还支持GIST和GIN

[options.indexes[].unique=false]  Boolean
设置索引是否唯一,设置后会自动触发UNIQUE设置

[options.indexes[].fields]  Array.< String | Object>
建立索引的字段数组。每个字段可以是一个字段名、sequelize对象(如sequelize.fn)或一个包含attribute (字段名)、length (创建前缀字符数)、order (列排序方向)、collate (较验的字段集合 (排序))

[options.createdAt] String | Boolean
如果为字符串则使用提供的值代替createdAt列的默认名,设置为flase则不添加这个字段。

[options.updatedAt] String | Boolean
如果为字符串则使用提供的值代替updatedAt列的默认名,设置为flase则不添加这个字段

[options.deletedAt] String | Boolean
如果为字符串则使用提供的值代替deletedAt列的默认名,设置为flase则不添加这个字段

</pre><pre class="js">
var Foo = sequelize.define('foo',  { /* bla */ }, {
  timestamps: true,             // 启用timestamps
  createdAt: false,             // 不使用createdAt
  updatedAt: 'updateTimestamp'  // updatedAt的实际名为'updateTimestamp'
  paranoid: true,
  deletedAt: 'destroyTime',     // 将deletedAt设置为destroyTime,注意要启用paranoid
})

</pre><pre>
[options.getterMethods] Object
提供给getter调用的方法,与每列定义的访问器一样。如果为列定义了一个相同名称的getter方法,那么会通过这个方法获取值;如果未定义的名称与列不匹配,这将做为一个虚拟访问器;也用于设置多个值,但不能用在。

[options.setterMethods] Object
提供给setter调用的方法,与每列定义的设置器一样。如果为列定义了一个相同名称的setter方法,那么会通过这个方法设置值;如果未定义的名称与列不匹配,这将做为一个虚拟访设置;也用于匹配多个值,但不用于逻辑删除。

</pre>在模型中将对象属性定义为访问/设置函数,Getters & setters - 访问器&设置器<pre class="js">
// 定义一个名为fullName的访问器,它是对this.firstname和this.lastname两个属性引用,这个属性是一个假属性,它并不是数据库中的一部分。定义假属性可以使用访问器或定义为VIRTUAL类型两种方式,Virtual类型可以验证而访问器则不能
// 在fullName的getter方法中引用的this.getDataValue会触发各自的getter方法

var Foo = sequelize.define('foo', {
  firstname: Sequelize.STRING,
  lastname: Sequelize.STRING
}, {
  getterMethods: {
    fullName: function()  {
      return this.getDataValue('firstName') + ' ' + this.getDataValue('lastName')
    }
  },
  setterMethods: {
    fullName: function(value) {
      var names = value.split(' ');
      this.setDataValue('firstName', names.slice(0, -1).join(' '));
      this.setDataValue('lastName', names.slice(-1).join(' '));
    },
  }
});

// 使用
User.findByPk(1)
  .then(user => {
    console.log(user.fullName)
    user.fullName = 'John Doe'
    return user.save()
  })
  .then(user => console.log(user.get({plain: true})))

</pre><pre>
[options.instanceMethods] Object
提供给每个实例(DAO)的方法。如果通过sequelize对方法进行了重写,可以通过"this.constructor.super_.prototype"来调用原方法,如：this.constructor.super_.prototype.toJSON.apply(this, arguments)

[options.classMethods]  Object
添加到Model的类方法,如果通过sequelize对方法进行了重写,可以通过this.constructor.prototype来调用原方法,如：this.constructor.prototype.find.apply(this, arguments)

</pre>Expansion of models 模型的扩展:Sequelize允许去给模型和相应的实例添加自定义的方法<pre class="js">
var sequelize = new Sequelize('database', 'username', 'password', {
  // 其他可选的初始化可以放在这里
  define: {
    classMethods: {
      method1: function() { return 'method1' },
      method2: function() { return 'method2' }
    },
    instanceMethods: {
      method3: function() { return 'method3' }
    }
  }
})

// Example:
var Foo = sequelize.define('foo', { /* attributes */});
Foo.method1()
Foo.method2()
Foo.build().method3()

</pre>设置虚拟访问器<pre class="js">
var User = sequelize.define('user', { firstname: Sequelize.STRING, lastname: Sequelize.STRING }, {
  instanceMethods: {
    getFullname: function() {
      return [this.firstname, this.lastname].join(' ')
    }
  }
})

User.build({ firstname: 'foo', lastname: 'bar' }).getFullname()   // 'foo bar'

</pre><pre class="js">
const User = sequelize.define("user", {
  firstname: {type: DataTypes.STRING,field: "first_name",allowNull: false},
  lastname: {type: DataTypes.STRING,field: "last_name",allowNull: false},
  password: {type: DataTypes.STRING,allowNull: false},
  active: {type: DataTypes.BOOLEAN,allowNull: false,defaultValue: true}
}, {
  comment: "用户信息类",
  classMethods: classMethods, //静态方法,即user模型自带的方法
});

//静态方法
const classMethods = {
  //根据id查询
  getUserById: function(id) {
    return this.findByPk(id);
  },
  //获取所有
  getUsers: function(options) {
    return this.findAll(options);
  },
  //根据id更新数据
  updateUserById: function(values, id) {
    return this.update(values, { where: { id: id } });
  },
  //根据id删除数据
  deleteById: function(id) {
    return this.destroy({ where: { id: id } })
  }
}

</pre><pre>
[options.schema='public'] String

[options.engine]  String
engine: 'Innodb'

</pre><pre class="js">
var Person = sequelize.define('person', { /* attributes */ }, {
  engine: 'MYISAM'
})

// or globally
var sequelize = new Sequelize(db, user, pw, {
  define: { engine: 'MYISAM' }
})

</pre><pre>
[options.charset] String
charset: 'utf8mb4',

[options.collate] String
collate: 'utf8mb4_general_ci',

[options.comment] String
表注释

[options.initialAutoIncrement]  String
MySQL中设置AUTO_INCREMENT自增的初始值

[options.hooks] Object
一个包含钩子函数的对象,这些函数会在生生命周期内某些事件发生之前或之后被调用。可添加的钩子函数有：beforeValidate, afterValidate, beforeBulkCreate, beforeBulkDestroy, beforeBulkUpdate, beforeCreate, beforeDestroy, beforeUpdate, afterCreate, afterDestroy, afterUpdate, afterBulkCreate, afterBulkDestory和afterBulkUpdate。每个属性可以是一个函数,或是一个包含一组函数的数组。

[options.validate]  Object  模型广泛验证对象。该验证会通过this。如果验证函数中有参数,则会被认为是异步的,并通过一个包含可选错误的回调函数形式的的调。

模型验证对模型的每个属性执行验证,

</pre>如果模型的列被设置为allowNull:true和值被设置为null的话认证器不会运行<pre class="js">
var Pub = Sequelize.define('pub', {
  name: { type: Sequelize.STRING },
  address: { type: Sequelize.STRING },
  latitude: {
    type: Sequelize.INTEGER,
    allowNull: true,
    defaultValue: null,
    validate: { min: -90, max: 90 }
  },
  longitude: {
    type: Sequelize.INTEGER,
    allowNull: true,
    defaultValue: null,
    validate: { min: -180, max: 180 }
  },
}, {
  // 模型验证,需要latitude和longitude都不为空或都为空
  validate: {
    bothCoordsOrNone: function() {
      if ((this.latitude === null) !== (this.longitude === null)) {
        throw new Error('Require either both latitude and longitude or neither')
      }
    }
  }
})

</pre>example<pre class="js">
var Foo = sequelize.define('foo', {
  // 自动设置默认值为true
  flag: { type: Sequelize.BOOLEAN, allowNull: false, defaultValue: true},

  // 日期默认值 => 当前时间
  myDate: { type: Sequelize.DATE, defaultValue: Sequelize.NOW },

  // 设置列的allowNull为false将会为该列增加非空属性
  // 设置allowNull选项为false后会为列添加 NOT NULL非空限制,当执行查询插入更新时相关字段为空会从数据库层抛出错误
  title: { type: Sequelize.STRING, allowNull: false},

  // 添加唯一(unique)约束后插入重复值会报错,unique属性可以是boolean或string类型
  // 如果为多个字段添加了相同的字符串, 他们会形成一个复合unique key
  someUnique: { type: Sequelize.STRING, unique: true},
  uniqueOne: { type: Sequelize.STRING,  unique: 'compositeIndex'},
  uniqueTwo: { type: Sequelize.INTEGER, unique: 'compositeIndex'}

  // unique属性以一个简单的简写方式创建唯一索引
  someUnique: {type: Sequelize.STRING, unique: true}

  // 同样的,也可以模型的选项中创建索引
  {someUnique: {type: Sequelize.STRING}},
  {indexes: [{unique: true, fields: ['someUnique']}]}

  // 主键
  identifier: { type: Sequelize.STRING, primaryKey: true},

  // autoIncrement选项用于创建一个自增的整型列
  incrementMe: { type: Sequelize.INTEGER, autoIncrement: true },

  // comment注释
  hasComment: { type: Sequelize.INTEGER, comment: "I'm a comment!" },

  // 在模型中的名字是小驼峰,可以通过 "field" 属性来指定数据库中的字段名
  fieldWithUnderscores: { type: Sequelize.STRING, field: "field_with_underscores" },

  // 通过references选项可以创建外键
  bar_id: {
    type: Sequelize.INTEGER,
    references: {
      model: Bar,   // 引用另外一个模型
      key: 'id',    // the column name of the referenced model
    }
  }
}, {
  timestamps: false,     // 不增加TIMESTAMP属性(updatedAt, createdAt)
  paranoid: true,        //不删除数据库中原有项,增加新属性deletedAt并设置为当前日期,只有TIMESTAMP属性是允许的时候有效
  underscored: true,     // 不要使用驼峰式语法,用下划线代替,so updatedAt will be updated_at
  freezeTableName: true, // 设置为true表示不允许调整表名,默认sequelize会自动转换所有传递的模型名字为复数
  tableName: 'custom_table_name',  // 定义表名
  comment: "I'm a table comment!", // 表注释
  engine: 'MYISAM',                // 修改引擎
  // var sequelize = new Sequelize(db, user, pw, { define: { engine: 'MYISAM' } }),  // globally 修改引擎
})

</pre>
</div>

<div id="model_sync">
<h4>sequelize/Model.sync([options={}]) -> Promise</h4><pre>
Database synchronization - 数据库同步,同步所有已定义的模型到数据库中,Synchronizing the model with the database

Sequelize支持创建表和删除表,使用Sequelize时并不需要先定义好数据库结构,只要定义好模型,然后进行同步即可。

If you want Sequelize to automatically create the table (or modify it as needed) according to your model definition, you can use the sync method

Model.sync()只会同步当前模型到数据库中,而sequelize.sync()会同步sequelize实例中已定义的所有模型

User.sync({force: true}).then(result => console.log(typeof re, result === User))  // function true, return this

【 参数 】
[options={}]  Object

[options.force=false] Boolean
设置为true会在创建表前先删除原表,即：DROP TABLE IF EXISTS ...

[options.match] RegEx
添加匹配规则,只重建匹配的表,在force: true时非常有用

[options.logging=console.log] Boolean | function
执行SQL的日志打印函数

[options.schema='public'] String
创建表的schema,这一选项可以每个表的sequelize.define中重写

[options.hooks=true]  Boolean
设置为true时会调用同步相关的钩子函数：beforeSync、afterSync、beforBulkSync、afterBulkSync

</pre>model.sync()<pre class="js">
// 同步Model结构到数据库中,即在数据库中创建表。执行成功后会在回调中返回模弄的实例this
User.sync()

var user = User.sync({ force: false });

// User.sync()会创建表并且返回一个Promise对象
User.sync({force:false}).then(function(){
  console.log("success to start");
}).catch(function(err){
  console.log("failed to start ")
})

// using `force: true` will drop the table if it already exists,强制创建,通过设置force属性会首先删除表并重新创建
User.sync({ force: true }).then(() => {
  // Now the `users` table in the database corresponds to the model definition
  return User.create({
    firstName: 'John',
    lastName: 'Hancock'
  }).then(() => console.log("John created"));
});

// 删除表
User.drop()

// 事件处理
User.[sync|drop]().then(function() {
  // 处理成功
}).catch(function(error) {
  // 出了点问题^~^
})

</pre>sequelize.sync()<pre class="js">
// 只同步还没在数据库中的模型,Sync all models that aren't already in the database
sequelize.sync()

// 强制同步所有数据库的模型,force为true则会把存在的表(如果users表已存在)先销毁再创建
sequelize.sync({force: true})

// .sync({force: true})是毁灭性的操作,可以使用match选项去增加更多的安全检查(正则),只重建正则表达式匹配的表,删除以 '_test' 结尾的词
sequelize.sync({ force: true, match: /_test$/ });

// 删除所有表
sequelize.drop()

// 开始执行
sequelize.[sync|drop]().then(function() {
  // woot woot
}).catch(function(error) {
  // whooops
})

</pre><pre class="js">
let User = sequelize.define('user', {
  firstName: Sequelize.STRING,
  lastName: Sequelize.STRING
});

let Role = sequelize.define('role', {
  roleName: Sequelize.STRING
});

let UserRole = sequelize.define('userRole', {
  userId: Sequelize.INTEGER,
  roleId: Sequelize.STRING
});

User.sync().then(function(result){
    // 同步了'User'一个模型
})

sequelize.sync().then(function(result){
  // 同步了'Role'、'UserRole'、'UserRole'三个模型
})

</pre><pre>
【 sequelize.import(path) -> Model 】
通过文件导入模型定义。检查模型是否已经定义。
path表示要导入文件的路径,如果使用相对路径会自动转换为绝对路径

可以将模型定义为一个单独的文件,并通过sequelize.import(path)导入。通过文件导入返回的对象与通过defined方法定义的模型完全一致,两者都是instance模型实例。自v1.5.0起sequlize会对导入的模型进行缓存,所以多次导入并不会重复加载,这样就不用担心多次对文件修改造成的一些问题。

</pre><pre class="js">
// 在project.js文件中定义一个名为project的模型,这个文件定义于/path/to/models/project.js
module.exports = function(sequelize, DataTypes) {
  return sequelize.define("project", {
    name: DataTypes.STRING,
    description: DataTypes.TEXT
  })
}

// 可以app.js或其它需要的地方引入定义的模型
var Project = sequelize.import(__dirname + "/path/to/models/project")

// The import method can also accept a callback as an argument
sequelize.import('project', function(sequelize, DataTypes) {
  return sequelize.define("project", {
    name: DataTypes.STRING,
    description: DataTypes.TEXT
  })
})

</pre>
</div>

<div id="model_usage">
<h4>Model usage</h4><pre>
【 Data retrieval / Finders - 数据索引/查找 】
查找方法是为了从数据库中查询数据,这些方法不是返回原始数据对象,而是返回模型实例。因会其返回的是模型实例,所以在文档的查询结果中可以任意调用模型实例的成员、方法等

默认Sequlize人为查询结构创建实例,通过这个实例可以进行数据的更新、删除等操作。有时候只需要显示数据集,而不需要进行处理,这时可以通过设置raw选项来返回数据库中的最简单的原始数据：
Project.findAll({ where: { ... }, raw: true })  // [{id: 1, name: 'john'}]

</pre>findByPk findOne - Search for one specific element in the database<pre class="js">
// search for known ids
Project.findByPk(123).then(project => {
  // project will be an instance of Project and stores the content of the table entry with id 123. if such an entry is not defined you will get null
})

User.findOne().then(user => console.log(usr.get(firstName)));

User.findOne({
  where: { username: 'john' }
}).then(result => console.log("成功：" + result.id))
.catch(err => console.log("发生错误：" + err));

// search for attributes
Project.findOne({ where: {title: 'aProject'} }).then(project => {
  // project will be the first entry of the Projects table with the title 'aProject' or null
})

Project.findOne({
  where: {title: 'aProject'},
  attributes: ['id', ['name', 'title']]
}).then(project => {
  // project will be the first entry of the Projects table with the title 'aProject' or null
  // project.get('title') will contain the name of the project
})

</pre>findOrCreate - 检测一个不确定是否存在的元素,如果存在则返回记录,不存在时会使用提供的默认值新建记录<pre class="js">
User
  .findOrCreate({where: {username: 'sdepold'}, defaults: {job: 'Technical Lead JavaScript'}})
  .then(([user, created]) => {
  // .spread((user, created) => {      // or
    console.log(user.get({ plain: true }))
    console.log(created)

    /*
     findOrCreate returns an array containing the object that was found or created and a boolean that
     will be true if a new object was created and false if not, like so:

    [ {
        username: 'sdepold',
        job: 'Technical Lead JavaScript',
        id: 1,
        createdAt: Fri Mar 22 2013 21: 28: 34 GMT + 0100(CET),
        updatedAt: Fri Mar 22 2013 21: 28: 34 GMT + 0100(CET)
      },
      true ]
    */
  })

</pre>findAndCountAll - Search for multiple elements in the database, returns both data and total count<pre class="js">
Project
  .findAndCountAll({
     where: {
        title: { [Op.like]: 'foo%' }
     },
     offset: 10,
     limit: 2
  })
  .then(result => {
    // an integer, total number records matching the where clause and other filters due to associations
    console.log(result.count);
    // an array of objects, the records matching the where clause and other filters due to associations, within the limit and offset range
    console.log(result.rows);
  });

</pre>findAndCountAll同样支持使用include包含,使用包含时只有将required设置为true才会添加到count部分<pre class="js">
// find all users who have a profile attached
User.findAndCountAll({
  include: [
    { model: Profile, required: true}  // 为Profile设置了required,所以在查询时会使用INNER JOIN内连接
  ],
  limit: 3
});

User.findAndCountAll({
  include: [
    { model: Profile, where: { active: true }}
  ],
  limit: 3
});

</pre>findAll - Search for multiple elements in the database<pre class="js">
// find multiple entries
Project.findAll().then(projects => {
  // projects will be an array of all Project instances
})

User.findAll().then(users => console.log("All users:", JSON.stringify(users, null, 4)));

// search for specific attributes - hash usage
Project.findAll({ where: { name: 'A Project' } }).then(projects => {
  // projects will be an array of Project instances with the specified name
})

// 查询指定范围
Project.findAll({ where: { id: [1,2,3] } }).then(function(projects) {
  // projects是一个包含Project实例的数组,各实例id是1,2,或3,这在实例执行时会使用IN查询
})

Project.findAll({group: 'name'})   // yields GROUP BY name

Project.findAll({order: [['title', 'DESC']]})

// 分页查询
Project.findAll({ limit: 10 })     // limit the results of the query
Project.findAll({ offset: 10 })    // step over the first 10 elements
Project.findAll({ offset: 10, limit: 2 })  // step over the first 10 elements, and take 2

// search within a specific range
Project.findAll({ where: { id: [1,2,3] } }).then(projects => {
  // projects will be an array of Projects having the id 1, 2 or 3
  // this is actually doing an IN query
})

</pre>count - Count the occurrences of elements in the database<pre class="js">
Project.count().then(c => {
  console.log("There are " + c + " projects!")
})

Project.count({ where: {'id': {[Op.gt]: 25}} }).then(c => {
  console.log("There are " + c + " projects with an id greater than 25.")
})

</pre>max - min<pre class="js">
// 数据库中有3条记录,年龄分别是 10, 5, 40
Project.max('age').then(max => console.log('this will return 40'))

Project.max('age', { where: { age: { [Op.lt]: 20 } } }).then(max => console.log('will be 10'))

Project.min('age').then(min => console.log('this will return 5'))

Project.min('age', { where: { age: { [Op.gt]: 5 } } }).then(min => console.log('will be 10'))

</pre>sum - 对指定属性求和<pre class="js">
Project.sum('age').then(sum => console.log('this will return 55'))

Project.sum('age', { where: { age: { [Op.gt]: 5 } } }).then(sum => console.log('will be 50'))

Project.sum('age', { where: { stauts: 1} });    // SELECT SUM(age) FROM Project WHERE stauts= 1;

</pre><pre>
【 分组查询 】
分组查询是指通过GROUP BY关键字,将查询结果按照一个或多个字段进行分组,分组时字段值相同的会被分为一组

GROUP BY子句要和聚合函数配合使用才能完成分组查询,在SELECT查询的字段中,如果没有使用聚合函数就必须出现在ORDER BY子句中。分组查询后,查询结果为一个或多个列分组后的结果集

SELECT 列名, 聚合函数(列名)
FROM 表名
WHERE 列名 operator value
GROUP BY 列名
[HAVING 条件表达式] [WITH ROLLUP]

聚合函数 - 分组查询通常要与聚合函数一起使用,聚合函数包括：
COUNT()-用于统计记录条数
SUM()-用于计算字段的值的总和
AVG()-用于计算字段的值的平均值
MAX-用于查找查询字段的最大值
MIX-用于查找查询字段的最小值
GROUP BY子名-用于指定分组的字段
HAVING子名-用于过滤分组结果,符合条件表达式的结果将会被显示
WITH ROLLUP子名-用于指定追加一条记录,用于汇总前面的数据

Sequelize提供了聚合函数,可以直接对模型进行聚合查询：
aggregate(field, aggregateFunction, [options])-通过指定的聚合函数进行查询
sum(field, [options])-求和
count(field, [options])-统计查询结果数
max(field, [options])-查询最大值
min(field, [options])-查询最小值

以上这些聚合函数中,可以通过options.attributes、options.attributes属性指定分组相关字段,并可以通过options.having指定过滤条件,但没有直接指定WITH ROLLUP子句的参数

</pre><pre class="js">
// 使用.sum()查询订单数量大于1的用户订单额：
Order
  .sum('price', {attributes:['name'], group:'name', plain:false, having:['COUNT(?)>?', 'name', 1]})
  .then(result => console.log(result))

SELECT `name`, sum(`price`) AS `sum` FROM `orders` AS `Orders` GROUP BY name HAVING COUNT('name')>1;

</pre><pre>
使用聚合参数
除直接使用聚合函数外,也可以在findAll()等方法中,指定聚合查询相关参数实现聚合查询。查询时,同样可以通过通过options.attributes、options.attributes属性指定分组相关字段,并可以通过options.having指定过滤条件。与直接使用聚合函数查询不一样,通过参数构建聚合查询时,要以数组或对象形式设置options.attributes参数中的聚合字段,并需要通过sequelize.fn()方法传入聚合函数。

</pre><pre class="js">
// 使用.findAll()查询订单数量大于1的用户订单额：
Order.findAll({
  attributes:['name', [sequelize.fn('SUM', sequelize.col('price')), 'sum']],
  group:'name',
  having:['COUNT(?)>?', 'name', 1],
  raw:true
}).then(result => console.log(result))

SELECT `name`, sum(`price`) AS `sum` FROM `orders` AS `Orders` GROUP BY name HAVING COUNT('name')>1;

</pre><pre class="js">
> select * from orders;
+---------+-------------+--------+-----------+---------------------+
| orderId | orderNumber | price  | name      | createdOn           |
+---------+-------------+--------+-----------+---------------------+
|       1 | 00001       | 128.00 | 张小三    | 2016-11-25 10:12:49 |
|       2 | 00002       | 102.00 | 张小三    | 2016-11-25 10:12:49 |
|       4 | 00004       |  99.00 | 王小五    | 2016-11-25 10:12:49 |
|       3 | 00003       | 199.00 | 赵小六    | 2016-11-25 10:12:49 |
+---------+-------------+--------+-----------+---------------------+

// 使用分组查询,统计每个客户的订单总额

> select name, SUM(price) from orders GROUP BY name;
+-----------+------------+
| name      | SUM(price) |
+-----------+------------+
| 张小三    |     230.00 |
| 王小五    |      99.00 |
| 赵小六    |     199.00 |
+-----------+------------+

Order.findAll({
  attributes:['name', [sequelize.fn('SUM', sequelize.col('name')), 'sum']],
  group:'name',
  raw:true
}).then(result => console.log(result))

// 统计订单数量大于1的用户的订单总金额
> select name, SUM(price) from orders GROUP BY name HAVING count(1)>1;
+-----------+------------+
| name      | SUM(price) |
+-----------+------------+
| 张小三    |     230.00 |
| 赵小六    |     199.00 |
+-----------+------------+

Order.findAll({
  attributes:['name', [sequelize.fn('SUM', sequelize.col('price')), 'sum']],
  group:'name',
  having:['COUNT(?)>?', 'name', 1],
  raw:true
}).then(result => console.log(result))

// WITH ROLLUP子句是MySQL 5.5+新增的特性,用于汇总统计结果,但至今Sequelize还不支持该特性。

> select name, SUM(price) from orders GROUP BY name WITH ROLLUP;
+-----------+------------+
| name      | SUM(price) |
+-----------+------------+
| 张小三    |     230.00 |
| 王小五    |      99.00 |
| 赵小六    |     199.00 |
| NULL      |     528.00 |
+-----------+------------+

</pre><pre>
连接查询与分组
将不同的信息保存在不同的表中,将订单信息放在一张表中,而将客户信息保存在另一张表中。对于存在关联关系的两张表可使用连接查询来查找关联数据,在进行连接查询时同样可以以使用聚合函数。

</pre>使用连接查询并分组查询,统计每个客户的订单总额<pre class="js">
> select * from orders;
+---------+-------------+--------+------------+---------------------+
| orderId | orderNumber | price  | customerId | createdOn           |
+---------+-------------+--------+------------+---------------------+
|       1 | 00001       | 128.00 |          1 | 2016-11-25 10:12:49 |
|       2 | 00002       | 102.00 |          1 | 2016-11-25 10:12:49 |
|       3 | 00003       | 199.00 |          4 | 2016-11-25 10:12:49 |
|       4 | 00004       |  99.00 |          3 | 2016-11-25 10:12:49 |
+---------+-------------+--------+------------+---------------------+

> select * from customers;
+----+-----------+-----+---------------------+---------------------+
| id | name      | sex | birthday            | createdOn           |
+----+-----------+-----+---------------------+---------------------+
|  1 | 张小三    |   1 | 1986-01-22 08:00:00 | 2016-11-25 10:16:35 |
|  2 | 李小四    |   2 | 1987-11-12 08:00:00 | 2016-11-25 10:16:35 |
|  3 | 王小五    |   1 | 1988-03-08 08:00:00 | 2016-11-25 10:16:35 |
|  4 | 赵小六    |   1 | 1989-08-11 08:00:00 | 2016-11-25 10:16:35 |
+----+-----------+-----+---------------------+---------------------+

> select c.name, SUM(o.price) AS sum from customers AS c INNER JOIN orders AS o ON o.customerId =c.id GROUP BY c.name;

// Sequelize中进行连接查询时,首先需要建立模型间的关联关系：
Order.belongsTo(Customer, {foreignKey: 'customerId'});

/// 连接查询及分组：
Order.findAll({
  include:[{
    model: Customer,
    required: true,
    attributes: ['name'],
  }],
  attributes:[[sequelize.fn('SUM', sequelize.col('price')), 'sum']],
  group:'Customer.name',
  having:['COUNT(?)>?', 'name', 1],
  raw:true
}).then(result => console.log(result))

</pre>【 Model.create、Model.destroy、Model.update 】<pre class="js">
// Create a new user
User.create({ firstName: "Jane", lastName: "Doe" })
.then(jane => console.log("Jane's auto-generated ID:", jane.id))
.catch(err => console.log(err))

// Delete everyone named "Jane"
User.destroy({
  where: { firstName: "Jane" }
}).then(() => console.log("Done"))  // 1
.catch(err => console.log(err))

// Change everyone without a last name to "Doe"
User.update({ lastName: "Doe" }, {
  where: { lastName: null }
}).then(res => console.log(res))    // [1]
.catch(err => console.log(err))

</pre><pre>
【 Model.bulkCreate: Working in bulk,creating, updating and destroying multiple rows at once 】
Since you are working with multiple models, the callbacks will not return DAO instances. BulkCreate will return an array of model instances/DAOs, they will however, unlike create, not have the resulting values of autoIncrement attributes.update and destroy will return the number of affected rows

</pre><pre class="js">
let User = sequelize.define('user', {firstName:Sequelize.STRING,lastName:Sequelize.STRING });
await User.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `firstName` VARCHAR(255), `lastName` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
*/

step(1)
await User.bulkCreate([
  {firstName:'san', lastName:'lee'},
  {firstName:'si', lastName:'lee'},
  {firstName:'wu', lastName:'wang'}
]).then(re => console.log(JSON.stringify(re)))
await User.findAll().then(allUsers => console.log(JSON.stringify(allUsers)))
/*
INSERT INTO `user` (`id`,`firstName`,`lastName`) VALUES (NULL,'san','lee'),(NULL,'si','lee'),(NULL,'wu','wang');
[{"id":1,"firstName":"san","lastName":"lee"},{"id":2,"firstName":"si","lastName":"lee"},{"id":3,"firstName":"wu","lastName":"wang"}]
SELECT `id`, `firstName`, `lastName` FROM `user` AS `user`;
[{"id":1,"firstName":"san","lastName":"lee"},{"id":2,"firstName":"si","lastName":"lee"},{"id":3,"firstName":"wu","lastName":"wang"}]
*/

step(2)
await User.update( { lastName: 'li' }, { where: { lastName: 'lee' }}).then(res => console.log(JSON.stringify(res)))
await User.findAll().then(allUsers => console.log(JSON.stringify(allUsers)))
/*
UPDATE `user` SET `lastName`=? WHERE `lastName` = ?
[2]
SELECT `id`, `firstName`, `lastName` FROM `user` AS `user`;
[{"id":1,"firstName":"san","lastName":"li"},{"id":2,"firstName":"si","lastName":"li"},{"id":3,"firstName":"wu","lastName":"wang"}]
*/

step(3)
// And delete them
await User.destroy({
  where: { lastName: 'li' },
}).then(res => console.log(JSON.stringify(res)))   // affectedRows will be 2

await User.findAll().then(allUsers => console.log(JSON.stringify(allUsers)))
/*
DELETE FROM `user` WHERE `lastName` = 'li'
2
SELECT `id`, `firstName`, `lastName` FROM `user` AS `user`;
[{"id":3,"firstName":"wu","lastName":"wang"}]
*/

step(4)
// And delete them
await User.destroy({
  where: { lastName: 'li' },
  truncate: true                                   // this will ignore where and truncate the table instead
}).then(res => console.log(JSON.stringify(res)))   // affectedRows will be 2

await User.findAll().then(allUsers => console.log(JSON.stringify(allUsers)))
/*
TRUNCATE `user`
0
SELECT `id`, `firstName`, `lastName` FROM `user` AS `user`;
[]
*/

</pre>过滤字段<pre class="js">
User.bulkCreate([
  { username: 'foo' },
  { username: 'bar', admin: true}
], { fields: ['username'] }).then(() => {
  // nope bar, you can't be admin!
})

</pre>bulkCreate是一种快速的插入数据的方式,但在插入多行数据时又不希望牺牲模型验证,这时可以通过validate参数告诉Sequelize只有通过筛选的数据才能插入数据库<pre class="js">
const Tasks = sequelize.define('tasks', {
  name: {
    type: Sequelize.STRING,
    validate: {
      notNull: { args: true, msg: 'name cannot be null' }
    }
  },
  code: {
    type: Sequelize.STRING,
    validate: {
      len: [3, 10]
    }
  }
})

Tasks.bulkCreate([
  {name: 'foo', code: '123'},
  {code: '1234'},
  {name: 'bar', code: '1'}
], { validate: true }).catch(errors => {
  console.log(errors)
  /*
  [
    { record:
      ...
      name: 'SequelizeBulkRecordError',
      message: 'Validation error',
      errors:
        {
          name: 'SequelizeValidationError',
          message: 'Validation error',
          errors: [Object]
        }
    },
    { record:
      ...
      name: 'SequelizeBulkRecordError',
      message: 'Validation error',
      errors:
        {
          name: 'SequelizeValidationError',
          message: 'Validation error',
          errors: [Object]
        }
    }
  ]
  */
})

</pre><pre class="js">
/* 创建数据库配置文件db.js,配置数据库 */
var Sequelize = require('sequelize');
module.exports = new Sequelize('blog', 'root', '123456', {
  host: 'localhost',        // 数据库地址
  dialect: 'mysql',         // 指定连接的数据库类型
  operatorsAliases: false,
  pool: {
    max: 5,                 // 连接池中最大连接数量
    min: 0,                 // 连接池中最小连接数量
    idle: 10000             // 如果一个线程 10 秒钟内没有被使用过的话,那么就释放线程
  }
});

/* 创建一个model文件user.js */
var Sequelize = require('sequelize');
var sequelize = require('./db');

// 创建 model
var User = sequelize.define('user', {
  id: {
    type : Sequelize.INTEGER,
    autoIncrement : true,
    primaryKey : true,
    unique : true
  },
  userName: {
    type: Sequelize.STRING,   // 指定值的类型
    field: 'user_name'        // 指定存储在表中的键名称
  },
  email: {
    type: Sequelize.STRING    // 没有指定field,表中键名称则与对象键名相同
  }
}, {
  // 如果为true则表名称和model相同,即user为false创建的表名称会是复数users,如果指定的表名称本就是复数形式则不变
  freezeTableName: true
});

// 创建表
// User.sync()会创建表并且返回一个Promise对象,force为true则会把存在的表(如果users表已存在)先销毁再创建,默认forse = false
//var user = User.sync({ force: false });
User.sync({force:false})
.then(() => console.log("success to start"))
.catch(err => console.log("failed to start "))

exports.addUser = function(userName, email) {
  return User.create({
    userName: userName,
    email: email
  }).then(result => console.log("插入操作成功"+result))
  .catch(err => console.log("添加数据发生错误："+err));
};

exports.findByName = function(userName) {
  return User.findOne({where: { user_name:userName }})
  .then(result => console.log("成功：" + result.id))
  .catch(err => console.log("发生错误：" + err));
};

exports.update = function(id){
  return User.findOne({where: {id}}).then(user => {
    return user.update({
      email:'jack3@qq.com'
    }).then(result => console.log("update success: "+result))
    .catch(err => console.log("更新操作出错："+err));
  });
};

exports.destroy = function(id){
  return User.destroy({ where: { id } })
    .then(result => console.log("delete success"))
    .catch(err => console.log("delete data err: "+err))
}

var user = require('./user');
user.findByName("jack");                // 查询操作
user.addUser('jack2', 'jack@163.com');  // 添加用户
user.update(1001);                      // 更新
user.destroy(1001);                     // 删除

</pre>【 attributes 】<pre class="js">
// SELECT foo, bar ...
Model.findAll({ attributes: ['foo', 'bar'] })

// SELECT foo, bar AS baz ...
Model.findAll({ attributes: ['foo', ['bar', 'baz']] });

// 通过sequelize.fn()来聚合查询,SELECT COUNT(hats) AS no_hats ...
Model.findAll({
  attributes: [[sequelize.fn('COUNT', sequelize.col('hats')), 'no_hats']]
});
instance.get('no_hats')

// SELECT id, foo, bar, baz, quz, COUNT(hats) AS no_hats ...
// This is a bad way of getting the number of hats
Model.findAll({
  attributes: ['id', 'foo', 'bar', 'baz', 'quz', [sequelize.fn('COUNT', sequelize.col('hats')), 'no_hats']]
});
// This is shorter, and less error prone because it still works if you add / remove attributes
Model.findAll({
  attributes: { include: [[sequelize.fn('COUNT', sequelize.col('hats')), 'no_hats']] }
});

// SELECT id, foo, bar, quz ...
Model.findAll({
  attributes: { exclude: ['baz'] }
});

</pre>【 where 】<pre class="js">
User.findAll({
  where: {
    firstName: { [Sequelize.Op.ne]: null }
  }
}).then(re => console.log(re))

</pre><pre class="js">
const Op = Sequelize.Op;

// SELECT * FROM post WHERE authorId = 2
Post.findAll({
  where: { authorId: 2 }
});

// SELECT * FROM post WHERE authorId = 12 AND status = 'active';
Post.findAll({
  where: { authorId: 12, status: 'active' }
});

// SELECT * FROM post WHERE authorId = 12 OR authorId = 13;
Post.findAll({
  where: {
    [Op.or]: [{authorId: 12}, {authorId: 13}]
  }
});

// SELECT * FROM post WHERE authorId = 12 OR authorId = 13;
Post.findAll({
  where: {
    authorId: { [Op.or]: [12, 13] }
  }
});

// DELETE FROM post WHERE status = 'inactive';
Post.destroy({
  where: { status: 'inactive' }
});

// UPDATE post SET updatedAt = null WHERE deletedAt NOT NULL;
Post.update({
  updatedAt: null,
}, {
  where: {
    deletedAt: { [Op.ne]: null }
  }
});

// SELECT * FROM post WHERE char_length(status) = 6;
Post.findAll({
  where: sequelize.where(sequelize.fn('char_length', sequelize.col('status')), 6)
});

// rank < 1000 OR rank IS NULL
{
  rank: {
    [Op.or]: {
      [Op.lt]: 1000,
      [Op.eq]: null
    }
  }
}

// createdAt < [timestamp] AND createdAt > [timestamp]
{
  createdAt: {
    [Op.lt]: new Date(),
    [Op.gt]: new Date(new Date() - 24*60*60*1000)
  }
}

// title LIKE 'Boat%' OR description LIKE '%boat%'
{
  [Op.or]: [
    {
      title: {
        [Op.like]: 'Boat%'
      }
    },
    {
      description: {
        [Op.like]: '%boat%'
      }
    }
  ]
}

</pre>【 Operators Aliases 】<pre class="js">
const Op = Sequelize.Op;
const operatorsAliases = {
  $gt: Op.gt
}
const connection = new Sequelize(db, user, pass, { operatorsAliases })

[Op.gt]: 6   // > 6
$gt: 6       // same as using Op.gt (> 6)

// use sequelize without any operators aliases
const connection = new Sequelize(db, user, pass, { operatorsAliases: false });

// use sequelize with only alias for $and => Op.and
const connection2 = new Sequelize(db, user, pass, { operatorsAliases: { $and: Op.and } });

</pre><pre class="js">
const Op = Sequelize.Op;
const operatorsAliases = {
  $eq: Op.eq,
  $ne: Op.ne,
  $gte: Op.gte,
  $gt: Op.gt,
  $lte: Op.lte,
  $lt: Op.lt,
  $not: Op.not,
  $in: Op.in,
  $notIn: Op.notIn,
  $is: Op.is,
  $like: Op.like,
  $notLike: Op.notLike,
  $iLike: Op.iLike,
  $notILike: Op.notILike,
  $regexp: Op.regexp,
  $notRegexp: Op.notRegexp,
  $iRegexp: Op.iRegexp,
  $notIRegexp: Op.notIRegexp,
  $between: Op.between,
  $notBetween: Op.notBetween,
  $overlap: Op.overlap,
  $contains: Op.contains,
  $contained: Op.contained,
  $adjacent: Op.adjacent,
  $strictLeft: Op.strictLeft,
  $strictRight: Op.strictRight,
  $noExtendRight: Op.noExtendRight,
  $noExtendLeft: Op.noExtendLeft,
  $and: Op.and,
  $or: Op.or,
  $any: Op.any,
  $all: Op.all,
  $values: Op.values,
  $col: Op.col
};

const connection = new Sequelize(db, user, pass, { operatorsAliases });

</pre>复杂过滤,可嵌套<pre class="js">
Project.findAll({
  where: {
    id: {
      $and: {a: 5}           // AND (a = 5)
      $or: [{a: 5}, {a: 6}]  // (a = 5 OR a = 6)
      $gt: 6,                // id > 6
      $gte: 6,               // id >= 6
      $lt: 10,               // id < 10
      $lte: 10,              // id <= 10
      $ne: 20,               // id != 20
      $between: [6, 10],     // BETWEEN 6 AND 10
      $notBetween: [11, 15], // NOT BETWEEN 11 AND 15
      $in: [1, 2],           // IN [1, 2]
      $notIn: [1, 2],        // NOT IN [1, 2]
      $like: '%hat',         // LIKE '%hat'
      $notLike: '%hat'       // NOT LIKE '%hat'
      $iLike: '%hat'         // ILIKE '%hat' (case insensitive)  (PG only)
      $notILike: '%hat'      // NOT ILIKE '%hat'  (PG only)
      $overlap: [1, 2]       // && [1, 2] (PG array overlap operator)
      $contains: [1, 2]      // @> [1, 2] (PG array contains operator)
      $contained: [1, 2]     // <@ [1, 2] (PG array contained by operator)
      $any: [2,3]            // ANY ARRAY[2, 3]::INTEGER (PG only)
      [Op.col]: 'user.organization_id' // = "user"."organization_id", with dialect specific column identifiers, PG in this example
    },
    status: {
      $not: false,           // status NOT FALSE
    }
  }
})

</pre><pre class="js">
Project.findAll({
  where: {
    id: {
      [Op.and]: {a: 5},           // AND (a = 5)
      [Op.or]: [{a: 5}, {a: 6}],  // (a = 5 OR a = 6)
      [Op.gt]: 6,                // id > 6
      [Op.gte]: 6,               // id >= 6
      [Op.lt]: 10,               // id < 10
      [Op.lte]: 10,              // id <= 10
      [Op.ne]: 20,               // id != 20
      [Op.between]: [6, 10],     // BETWEEN 6 AND 10
      [Op.notBetween]: [11, 15], // NOT BETWEEN 11 AND 15
      [Op.in]: [1, 2],           // IN [1, 2]
      [Op.notIn]: [1, 2],        // NOT IN [1, 2]
      [Op.like]: '%hat',         // LIKE '%hat'
      [Op.notLike]: '%hat',       // NOT LIKE '%hat'
      [Op.iLike]: '%hat',         // ILIKE '%hat' (case insensitive)  (PG only)
      [Op.notILike]: '%hat',      // NOT ILIKE '%hat'  (PG only)
      [Op.overlap]: [1, 2],       // && [1, 2] (PG array overlap operator)
      [Op.contains]: [1, 2],      // @> [1, 2] (PG array contains operator)
      [Op.contained]: [1, 2],     // <@ [1, 2] (PG array contained by operator)
      [Op.any]: [2,3]            // ANY ARRAY[2, 3]::INTEGER (PG only)
    },
    status: {
      [Op.not]: false           // status NOT FALSE
    }
  }
})

</pre>Complex filtering / OR / NOT queries<pre class="js">
Project.findOne({
  where: {
    name: 'a project',
    [Op.or]: [
      { id: [1,2,3] },
      { id: { [Op.gt]: 10 } }
    ]
  }
})

Project.findOne({
  where: {
    name: 'a project',
    id: {
      [Op.or]: [
        [1,2,3],
        { [Op.gt]: 10 }
      ]
    }
  }
})

// SELECT * FROM `Projects` WHERE (`Projects`.`name` = 'a project' AND (`Projects`.`id` IN (1,2,3) OR Projects`.`id` > 10)) LIMIT 1;

Project.findOne({
  where: {
    name: 'a project',
    [Op.not]: [
      { id: [1,2,3] },
      { array: { [Op.contains]: [3,4,5] } }
    ]
  }
});

// SELECT *
FROM `Projects` WHERE ( `Projects`.`name` = 'a project' AND NOT (`Projects`.`id` IN (1,2,3) OR `Projects`.`array` @> ARRAY[3,4,5]::INTEGER[]) ) LIMIT 1;

</pre><pre class="js">
// 嵌套对象
{
  meta: {
    video: {
      url: {
        $ne: null
      }
    }
  }
}

// 嵌套键
{
  "meta.audio.length": {
    $gt: 20
  }
}

// 包含
{
  "meta": {
    $contains: {
      site: {
        url: 'http://itbilu.com'
      }
    }
  }
}

// 关系/联合: 查询所有至少有一个task的projects,task.state === project.task
Project.findAll({
  include: [{
    model: Task,
    where: { state: Sequelize.col('project.state') }
  }]
})

</pre>【 排序 】<pre class="js">
// 传入简单的字符串时查询字符串会逐字查询即列名不转义,如果需要列名转义可以提供一个数组参数
something.findOne({
  order: [
    'name',                                               // 返回 `name`
    'username DESC',                                      // 返回 `username DESC`
    ['username', 'DESC'],                                 // 返回 `username` DESC
    sequelize.fn('max', sequelize.col('age')),            // 返回 max(`age`)
    [sequelize.fn('max', sequelize.col('age')), 'DESC'],  // 返回 max(`age`) DESC
    [sequelize.fn('otherfunction', sequelize.col('col1'), 12, 'lalala'), 'DESC'],
    // 返回 otherfunction(`col1`, 12, 'lalala') DESC
    [sequelize.fn('otherfunction', sequelize.fn('awesomefunction', sequelize.col('col'))), 'DESC']
    // 返回 otherfunction(awesomefunction(`col`)) DESC, 有可能是无限循环
    [{ raw: 'otherfunction(awesomefunction(`col`))' }, 'DESC']
    // 也可以这样写
  ]
})

Subtask.findAll({
  order: [
    // Will escape title and validate DESC against a list of valid direction parameters
    ['title', 'DESC'],

    // Will order by max(age)
    sequelize.fn('max', sequelize.col('age')),

    // Will order by max(age) DESC
    [sequelize.fn('max', sequelize.col('age')), 'DESC'],

    // Will order by  otherfunction(`col1`, 12, 'lalala') DESC
    [sequelize.fn('otherfunction', sequelize.col('col1'), 12, 'lalala'), 'DESC'],

    // Will order an associated model's created_at using the model name as the association's name.
    [Task, 'createdAt', 'DESC'],

    // Will order through an associated model's created_at using the model names as the associations' names.
    [Task, Project, 'createdAt', 'DESC'],

    // Will order by an associated model's created_at using the name of the association.
    ['Task', 'createdAt', 'DESC'],

    // Will order by a nested associated model's created_at using the names of the associations.
    ['Task', 'Project', 'createdAt', 'DESC'],

    // Will order by an associated model's created_at using an association object. (preferred method)
    [Subtask.associations.Task, 'createdAt', 'DESC'],

    // Will order by a nested associated model's created_at using association objects. (preferred method)
    [Subtask.associations.Task, Task.associations.Project, 'createdAt', 'DESC'],

    // Will order by an associated model's created_at using a simple association object.
    [{model: Task, as: 'Task'}, 'createdAt', 'DESC'],

    // Will order by a nested associated model's created_at simple association objects.
    [{model: Task, as: 'Task'}, {model: Project, as: 'Project'}, 'createdAt', 'DESC']
  ]

  // Will order by max age descending
  order: sequelize.literal('max(age) DESC')

  // Will order by max age ascending assuming ascending is the default order when direction is omitted
  order: sequelize.fn('max', sequelize.col('age'))

  // Will order by age ascending assuming ascending is the default order when direction is omitted
  order: sequelize.col('age')

  // Will order randomly based on the dialect (instead of fn('RAND') or fn('RANDOM'))
  order: sequelize.random()
})

</pre>
</div>

<div id="model_API">
<h4>Model类的API</h4><pre>
【 removeAttribute([attribute:String]) 】
从已定义的模型中移除属性,不会删除数据库中的字段

</pre><pre class="js">
let User = sequelize.define('user', {firstName:Sequelize.STRING,lastName:Sequelize.STRING },{timestamps:false});
await User.sync()
await User.create({firstName:'xxxx', lastName:'xxxx'})
await User.findOne({raw:true}).then(result => console.log(result)) // { id: 1, firstName: 'xxxx', lastName: 'xxxx'}
await User.removeAttribute('firstName');                           // 移'firstName'属性
await User.findOne({raw:true}).then(result => console.log(result)) // { id: 1, lastName: 'xxxx'}

</pre><pre>
【 drop([options]) -> Promise< undefined> 】
删除Model在数据库中对应的表

[options.logging=false] Function  一个函数用于打印查询时的sql
[options.benchmark=false] Boolean 在打印日志时同时输出执行SQL花费的时候(毫秒)

【 schema(schema:String, [options:Object]) -> this 】
为Model指定schema(数据库),将会设置为'schema.tablename'

[options.schemaDelimiter='.'] String  schema与表名的分隔符
[options.logging=false] Function  一个函数用于打印查询时的sql
[options.benchmark=false] Boolean 在打印日志时同时输出执行SQL花费的时候(毫秒)

【 getTableName([options]) -> String|Object 】
获取Model在数据库中的表名。在未指定schema时会返回模型名,或返回一个包含tableName、schema和delimiter属性的对象。

[options.logging=false] Function  一个函数用于打印查询时的sql
[options.benchmark=false] Boolean 在打印日志时同时输出执行SQL花费的时候(毫秒)

【 addScope(name, scope, [options]) 】
为模型添加一个新的限制范围。在定义模型时如果未指定验证,这一方法会非常有用。
如果指定的限制已经存在,默认会抛出异常,这时可以传入override: true选项来解决。

name  String  限制范围名。使用defaultScope时会替换默认的限制
scope Object | Function
[options] Object
[options.override=false]  Boolean

【 scope(options*) -> Model 】
应用在define定义模型时创建的作用范围

</pre><pre class="js">
// 在定义模型时创建作用范围
var Model = sequelize.define('model', attributes, {
  defaultScope: {
    where: { username: 'dan' },
    limit: 12
  },
  scopes: {
    isALie: {
      where: { stuff: 'cake' }
    },
    complexFunction: function(email, accessLevel) {
      return {
        where: {
          email: { $like: email },
          accesss_level { $gte: accessLevel }
        }
      }
    }
  }
})

// 定义默认的限制范围后,默认限制会在每次查询时起作用：
Model.findAll()                               // WHERE username = 'dan'
Model.findAll({ where: { age: { gt: 12 } } }) // WHERE age > 12 AND username = 'dan'

// 可以通过scope()像下面这样应用限制范围：
Model.scope({ method: ['complexFunction' 'dan@sequelize.com', 42]}).findAll()
// WHERE email like 'dan@sequelize.com%' AND access_level >= 42

</pre><pre>
【 findAll([options]) -> Promise.< Array.< Instance>> 】
查询多个实例(多条数据),查询成功后会返回包含多个实例(instance)的数组

</pre><pre class="js">
// 在查询中使用AND和=
Model.findAll({
  where: { attr1: 42, attr2: 'cake' }
})
// WHERE attr1 = 42 AND attr2 = 'cake'

// 在查询中使用大于、小于等
Model.findAll({
  where: {
    attr1: { $gt: 50 },
    attr2: { $lte: 45 },
    attr3: { $in: [1,2,3] },
    attr4: { $ne: 5 }
  }
})
// WHERE attr1 > 50 AND attr2 <= 45 AND attr3 IN (1,2,3) AND attr4 != 5

// 在查询中使用OR
Model.findAll({
  where: {
    name: 'a project',
    $or: [
      {id: [1, 2, 3]},
      {
        $and: [
          {id: {gt: 10}},
          {id: {lt: 100}}
        ]
      }
    ]
  }
});

//WHERE `Model`.`name` = 'a project' AND (`Model`.`id` IN (1, 2, 3) OR (`Model`.`id` > 10 AND `Model`.`id` < 100));

</pre><pre>
参数：
[options.where] Object
一个描述查询限制范围(WHERE条件)的对象

[options.attributes]  Array.< String> | Object
要查询的属性(字段)列表,或一个include和exclude对象的键。
要对属性进行重命名可以传入一个包含两个元素的数组－第一个表示属性在数据库中的名称或一些类似Sequelize.literal,Sequelize.fn等的表达式,第二个属性表示要在返回实例中使用的名称

[options.attributes.include]  Array.< String>
选择所有模型属性并添加一些附加值,用于聚合计算
{attributes:{ include:[[sequelize.fn('COUNT', sequelize.col('id')),'total']]}

[options.attributes.exclude]  Array.< String>
选择模型中除少数属性外的所有属性,这主要出于安全目的
{ attributes: { exclude: ['password'] } }

[options.paranoid=true] Boolean
为true时只会返回未删除的记录,否则会返回删除和未删除的全部记录

[options.include] Array.< Object | Model>
一个用于左连接的连接列表,支持{ include: [ Model1, Model2, ...]} 或 { include: [{ model: Model1, as: 'Alias' }]}的形式
如果连接要设置as (如 X.hasMany(Y, { as: 'Z }, 需要将要加载的 Y 的as属性指定为Z)

[options.include[].model] Model
想要加载的模型

[options.include[].as]  String
别名关系,如果想对要加载的模型起别名。
对于 hasOne / belongsTo, 这里应该使用单数形式名,而对于hasMany则应该使用复数形式名

[options.include[].association] Association
想要加载的关系(这可以用来替代提供的一个model/as对)

[options.include[].where] Object
用于子模型的WHERE分句,这会对要加载的使用内连接,除非显示指定required: false

[options.include[].required]  Boolean
如果为true会转换为内连接,即只有匹配到子模型的父模型才会被加载。include.where设置后为True,其它情况false

[options.include[].or=false]  Boolean
是否将 ON 和 WHERE 分名与 OR绑定在一起而不是替换 AND

[options.include[].on]  Object
为连接提供ON条件

[options.include[].attributes]  Array.< String>
要从子模型中查询的属性列表

[options.include[].separate]  Boolean
如果为true,运行一个单独的查询来获取关联的实例,仅支持hasMany关系

[options.include[].limit] Number
限制连接的行数,仅在include.separate=true时支持

[options.include[].through.where] Object
为belongsToMany关系过滤连接的模型

[options.include[].through.attributes]  Array
在belongsToMany关系中连接模型选择的属性列表

[options.include[].include] Array.< Object | Model>
进一步嵌套相关模型

[options.order] String | Array | Sequelize.fn
指定一个排序. 如果是字符串那么会进行编码,如果是数组那么可以依次提供多组列名/排序函数,每一组包含两个元素,第一个是排序字段名,第二个是排序方式,如: order: [['name', 'DESC']],这种情况下列名会进行编码而排序方向不会

[options.limit] Number

[options.offset]  Number

[options.transaction] Transaction
在事务中执行查询

[options.lock]  String | Object
锁定已选行,可选项有: transaction.LOCK.UPDATE、 transaction.LOCK.SHARE,详见 transaction.LOCK

[options.raw] Boolean
返回原始结果. 详见 sequelize.query

[options.logging=false] Function
一个用于打印执行SQL语句的函数

[options.having]  Object

[options.benchmark=false] Boolean
打印执行SQL语句时,同时输出执行时间(毫秒)

【 findById() - 通过Id查询单条数据 】
findById(id, [options]) -> Promise.< Instance>
通过Id(主键)查询单个实例(单条数据)。

id  Number | String | Buffer  要查询实例的主键
[options.transaction] Transaction 在事务中执行查询

【 findOne() - 查询单条数据 】
findOne(options]) -> Promise.< Instance>
查询单个实例(单条数据)。这将会使用LIMIT 1查询条件,所以回调中总是返回单个实例。

[options.transaction] Transaction 在事务中执行查询

【 aggregate() - 聚合查询 】
aggregate(field, aggregateFunction, [options]) -> Promise.< options.dataType|object>
在指定字段field上运行聚合查询。

field String
要运行聚合的字段。可以是字段名或*

aggregateFunction String
聚合函数,如sum, maxetc.

[options.where] Object
查询属性

[options.logging=false] Function
一个用于打印查询时所执行sql的函数

[options.dataType]  DataType | String
结果类型。如field是模型中的字段,默认为字段的类型,其它情况为默认为float

[options.distinct]  boolean
为字段使用DISTINCT聚合查询

[options.transaction] Transaction
在事务中运行查询

[options.plain] Boolean
当为true时,第一个aggregateFunction的返回值为dataType指定和返回,如果添加了额外的属性则由group分句决定。
设置plain为false 时会返回所有返回行中的所有值 。默认为true

[options.benchmark=false] Boolean
当打印SQL日志时同时输出查询执行时间(毫秒)

【 count() - 统计查询结果数 】
count([options]) -> Promise.< Integer>
统计符合查询条件的结果总数,如果提供了include则将计算匹配关联的数目

[options.where] Object  查询属性(条件)
[options.include] Object  Include 选项
[options.distinct]  boolean 在主键上使用 COUNT(DISTINCT(col)), Model.aggregate 要使用其它列
[options.attributes]  Object  在group中联合使用
[options.group] Object  创建复杂统计时会返回所需要的多行
[options.transaction] Transaction 在事务中执行查询Transaction to run query under
[options.logging=false] Function  一个用于打印查询时所执行sql的函数
[options.benchmark=false] Boolean 当打印SQL日志时同时输出查询执行时间(毫秒)

【 findAndCount() - 分页查询 】
findAndCount([findOptions]) -> Promise.< Object>
查询由offset/limit指定的所有匹配行,并返回查询条件所匹配的总数量。

</pre><pre class="js">
Model.findAndCountAll({
  where: ...,
  limit: 12,
  offset: 12
}).then(function (result) {
  // result是一个包含以两个属性的对象,result.rows是匹配的查询行组成的数组,result.count是查询条件匹配的总数量
})

</pre>如果提供了include,将计算匹配关联的数目<pre class="js">
User.findAndCountAll({
  include: [
    { model: Profile, required: true}
  ],
  limit 3
});

</pre><pre>
【 max() - 查询最大值 】
max(field, [options]) -> Promise.< Any>
查询指定字段的最大值

【 min() - 查询最大值 】
min(field, [options]) -> Promise.
查询指定字段的最小值

【 sum() - 求和 】
sum(field, [options]) -> Promise.< Number>
对指定字段field求和

【 findOrInitialize() - 查找或初始化 】
findOrInitialize -> Promise.< Instance, initialized>
查找一行记录,如果不存在则创建实例但不保存

options.where Object  查询属性
[options.defaults]  Object  用于创建新实例的默认值
[options.transaction] Transaction 在事务中执行查询
[options.logging=false] Function  一个用于打印查询时所执行sql的函数
[options.searchPath=DEFAULT]  String  指定schema的 search_path (仅 Postgres)
[options.benchmark=false] Boolean 当打印SQL日志时同时输出查询执行时间(毫秒)

【 findOrCreate() - 查找或创建 】
findOrCreate(options) -> Promise.< Instance, created>
查找一行记录,如果不存在则创建实例并保存到数据库中
在这个方法中,如果options对象中没有传入事务,那么会在内部自动创建一个新的事务,以防止在创建完成之前有新匹配查询进入。

options.where Object  查询属性
[options.defaults]  Object  用于创建新实例的默认值
[options.transaction] Transaction 在事务中执行查询

【 findCreateFind() - 查找或创建 】
findCreateFind(options) -> Promise.< Instance, created>
效率更高的findOrCreate,不会在事务中执行。首先会尝试进行查询,如果为空则尝试创建,如果是唯一约束则尝试再次查找。

options.where Object  查询属性
[options.defaults]  Object  用于创建新实例的默认值
[options.transaction] Transaction 在事务中执行查询

【 upsert() - 创建或更新 】
upsert(values, [options]) -> Promise.< created>
创建或更新一行。如果匹配到主键或唯一约束键时会进行更新。
做为单条查询执行 INSERT values ON DUPLICATE KEY UPDATE values

values  Object
[options] Object
[options.validate=true] Boolean 插入前进行验证
[options.fields=Object.keys(this.attributes)] Array 要插入/更新字段。默认全部
[options.transaction] Transaction 在事务中执行查询

【 bulkCreate() - 创建多条记录 】
bulkCreate(records, [options]) -> Promise.< Array.< Instance>>
批量创建并保存多个实例,处理成功后会在回调函数中返回一个包含多个实例的数组

records Array 要创建实例的对象(键/值 对)列表
[options] Object
[options.fields]  Array 要插入的字段。默认全部
[options.validate=true] Boolean 插入每条记录前进行验证
[options.hooks=true]  Boolean 在执行前/后创建钩子
[options.individualHooks=false] Boolean 在执行前/后为每个实例创建钩子
[options.ignoreDuplicates=false]  Boolean 忽略重复主键
[options.updateOnDuplicate] Array 如果行键已存在是否更新,默认为更新
[options.transaction] Transaction 在事务中执行查询

【 truncate() - 截断模型 】
truncate([options]) -> Promise
截断模型的所有实例,这个方法是Model.destroy({ truncate: true })便捷方法。

records Array 要创建实例的对象(键/值 对)列表
[options] Object
[options.transaction] Transaction 在事务中执行查询
[options.cascade=false] Boolean | function  仅适用于连接查询时的TRUNCATE操作,截断所有外键匹配的表

【 destroy() - 删除记录 】
destroy(options) -> Promise.< Integer>
删除多个实例,或设置deletedAt的时间戳为当前时间(当启用paranoid时)
执行成功后返回被删除的行数

[options.where] Object  筛选条件
[options.hooks=true]  Boolean 在执行前/后创建钩子
[options.individualHooks=false] Boolean 在执行前/后为每个实例创建钩子
[options.limit] Number  要删除的行数
[options.force=false] Boolean 删除而不是设置 deletedAt 为当前时间戳 (仅启用 paranoid 时适用)
[options.truncate=false]  Boolean 设置为true时,会使用TRUNCATE代替DELETE FROM,这时会忽略where和limit选项
[options.cascade=false] Boolean 仅适用于连接查询时的TRUNCATE操作,截断所有外键匹配的表
[options.transaction] Transaction 在事务中执行查询

【 restore() - 恢复记录 】
restore(options) -> Promise.< undefined>
当启用paranoid时恢复多个实例

[options.where] Object  筛选条件
[options.hooks=true]  Boolean 在执行前/后创建钩子
[options.individualHooks=false] Boolean 在执行前/后为每个实例创建钩子
[options.limit] Number  要恢复的行数
[options.transaction] Transaction 在事务中执行查询

【 update() - 更新记录 】
update(values, options) -> Promise.< Array.< affectedCount, affectedRows>>
更新所匹配的多个实例。promise回调中会返回一个包含一个元素的数组,第一个元素始终表示受影响的行数

values  Object
options.where Object  筛选条件
[options.fields]  Array 要更新字段,默认为全部
[options.validate=true] Boolean 更新每条记录前进行验证
[options.hooks=true]  Boolean 在执行更新前/后创建钩子
[options.individualHooks=false] Boolean 在执行更新前/后为每个实例创建钩子
[options.sideEffects=true]  Boolean 是否更新任何虚拟设置
[options.limit] Number  要更新的行数
[options.transaction] Transaction 在事务中执行查询
[options.silent=false]  Boolean 如果为true,updatedAt字段将不会更新

【 describe() - 查询表信息 】
describe() -> Promise
运行一个表的描述查询,返回结果中将包含属性及其类型：

</pre><pre class="js">
let User = sequelize.define('user', {firstName: Sequelize.STRING,lastName: Sequelize.STRING});
User.describe().then(result => console.log(result))
// 结果如下
{ id:
   { type: 'INT(11)',
     allowNull: false,
     defaultValue: null,
     primaryKey: true },
  firstName:
   { type: 'VARCHAR(255)',
     allowNull: true,
     defaultValue: null,
     primaryKey: false },
  lastName:
   { type: 'VARCHAR(255)',
     allowNull: true,
     defaultValue: null,
     primaryKey: false }
}

</pre>
</div>

<div id="instance">
<h4>sequelize instances</h4><pre>
Instance表示数据表中的一行,该对象同样不能直接实例化。它会在Model实例进行find或create等操作时自动创建,并在回调函数中返回。Instance实例有两种：持久化实例、非持久化实例

实例中包含一个dataValues属性,其中存储了实例实际所要操作的值。dataValues中的值可以通过以下几种方式访问：
instance.field
// 等价于
instance.get('field')
// 等价于
instance.getDataValue('field')
如果定义了访问器(getter)/设置器(setter),字段值从其中访问而不是从dataValues。一般会直接访问或使用get来访问属性值,而getDataValue只用于自定义的访问器

【 Building a non-persistent instance 】

Model.build(values, [options]) -> Instance
创建一个新的模型实例,Values参数为新例指定的键值对对象

[options.raw=false] Boolean 设置为true时值会忽略字段和虚拟设置器
[options.isNewRecord=true]  Boolean
[options.include] Array 用于构建prefetched/included模型

</pre><pre class="js">
const non_persistent_Instances = async () => {
  // Using the build-method will return an unsaved object, which you explicitly have to save
  const user = User.build({
    firstName: 'dayou',
    lastName: 'lee',
    job: 'editer',
  })
  console.log(user);

  /* Built instances will automatically get default values when they were defined
  user {
    dataValues:
     { about: 'haha, it is a long story',
       id: null,
       firstName: 'dayou',
       lastName: 'lee',
       job: 'EDITER' },
    _previousDataValues:
     { firstName: undefined,
       lastName: undefined,
       job: undefined },
    _changed:
     { firstName: true,
       lastName: true,
       job: true },
    _modelOptions:
     { timestamps: true,
       validate: {},
       freezeTableName: true,
       underscored: false,
       paranoid: true,
       rejectOnEmpty: false,
       whereCollection: null,
       schema: null,
       schemaDelimiter: '',
       defaultScope: {},
       scopes: {},
       indexes: [],
       name: { plural: 'users', singular: 'user' },
       omitNull: false,
       getterMethods: { fullName: [Function: fullName] },
       setterMethods: { fullName: [Function: fullName] },
       sequelize:
        Sequelize {
          options: [Object],
          config: [Object],
          dialect: [Object],
          queryInterface: [Object],
          models: [Object],
          modelManager: [Object],
          connectionManager: [Object],
          importCache: {} },
       hooks: {} },
    _options: { isNewRecord: true, _schema: null, _schemaDelimiter: '' },
    isNewRecord: true }
  */

  return user.save()
  .then(anotherTask => {
    console.log(anotherTask) // access the currently saved task
  })
  .catch(error => console.log(error))
  /*
  INSERT INTO `user` (`id`,`first_name`,`last_name`,`job`,`about`,`createdAt`,`updatedAt`) VALUES (DEFAULT,?,?,?,?,?,?);
  user {
    dataValues:
     { about: 'haha, it is a long story',
       id: 1,
       firstName: 'dayou',
       lastName: 'lee',
       job: 'EDITER',
       updatedAt: 2019-06-23T13:03:05.469Z,
       createdAt: 2019-06-23T13:03:05.469Z },
    _previousDataValues:
     { firstName: 'dayou',
       lastName: 'lee',
       job: 'EDITER',
       id: 1,
       about: 'haha, it is a long story',
       createdAt: 2019-06-23T13:03:05.469Z,
       updatedAt: 2019-06-23T13:03:05.469Z,
       deletedAt: undefined },
    _changed:
     { firstName: false,
       lastName: false,
       job: false,
       id: false,
       about: false,
       createdAt: false,
       updatedAt: false,
       deletedAt: false },
    _modelOptions:
     { timestamps: true,
       validate: {},
       freezeTableName: true,
       underscored: false,
       paranoid: true,
       rejectOnEmpty: false,
       whereCollection: null,
       schema: null,
       schemaDelimiter: '',
       defaultScope: {},
       scopes: {},
       indexes: [],
       name: { plural: 'users', singular: 'user' },
       omitNull: false,
       getterMethods: { fullName: [Function: fullName] },
       setterMethods: { fullName: [Function: fullName] },
       sequelize:
        Sequelize {
          options: [Object],
          config: [Object],
          dialect: [Object],
          queryInterface: [Object],
          models: [Object],
          modelManager: [Object],
          connectionManager: [Object],
          importCache: {} },
       hooks: {} },
    _options: { isNewRecord: true, _schema: null, _schemaDelimiter: '' },
    isNewRecord: false }
  */
}

</pre>【 Creating persistent instances 】<pre class="js">
create(values, [options]) -> Promise.< Instance>
构建一个新的模型实例,并进行保存。与build()方法不同的是,此方法除创建新实例外,还会将其保存到对应数据库表中

参数：
[options.raw=false] Boolean 设置为true时值会忽略字段和虚拟设置器
[options.isNewRecord=true]  Boolean
[options.fields]  Array 如果设置后只有列表中区别的列才会进行保存
[options.include] Array 用于构建prefetched/included模型
[options.onDuplicate] String
[options.transaction] Transaction 在事务中执行查询
[options.logging=false] Function  一个用于打印查询时所执行sql的函数
[options.benchmark=false] Boolean 当打印SQL日志时同时输出查询执行时间(毫秒)

// define which attributes can be set via the create method
User.create({ username: 'barfooz', isAdmin: true }, { fields: [ 'username' ] }).then(user => {
  console.log(user.get({plain: true})) // { username: 'barfooz', isAdmin: false }, isAdmin取定义的默认值false
})

</pre><pre class="js">
User.create({
    firstName: 'youzi',
    lastName: 'lee',
    job: 'engineer',
    about: 'I am a good man'
  })
  .then(user => {
    // access the newly created task via the variable task
    console.log(user)

    // filter the return data
    console.log(user.get({ plain: true }))
    console.log(JSON.stringify(user))

    // 直接获取实例对象的属性即字段值
    console.log(user.email)
  })
  .catch(err => console.log('create failed: ' + err))

/*
  INSERT INTO `user` (`id`,`first_name`,`last_name`,`job`,`about`,`createdAt`,`updatedAt`) VALUES (DEFAULT,?,?,?,?,?,?);

  user {
    dataValues:
     { id: 1,
       firstName: 'youzi',
       lastName: 'lee',
       job: 'ENGINEER',
       about: 'I am a good man',
       updatedAt: 2019-06-23T03:16:33.875Z,
       createdAt: 2019-06-23T03:16:33.875Z },
    _previousDataValues:
     { firstName: 'youzi',
       lastName: 'lee',
       job: 'ENGINEER',
       about: 'I am a good man',
       id: 1,
       createdAt: 2019-06-23T03:16:33.875Z,
       updatedAt: 2019-06-23T03:16:33.875Z,
       deletedAt: undefined },
    _changed:
     { firstName: false,
       lastName: false,
       job: false,
       about: false,
       id: false,
       createdAt: false,
       updatedAt: false,
       deletedAt: false },
    _modelOptions:
     { timestamps: true,
       validate: {},
       freezeTableName: true,
       underscored: false,
       paranoid: true,
       rejectOnEmpty: false,
       whereCollection: null,
       schema: null,
       schemaDelimiter: '',
       defaultScope: {},
       scopes: {},
       indexes: [],
       name: { plural: 'users', singular: 'user' },
       omitNull: false,
       getterMethods: { fullName: [Function: fullName] },
       sequelize:
        Sequelize {
          options: [Object],
          config: [Object],
          dialect: [Object],
          queryInterface: [Object],
          models: [Object],
          modelManager: [Object],
          connectionManager: [Object],
          importCache: {} },
       hooks: {} },
    _options:
     { isNewRecord: true,
       _schema: null,
       _schemaDelimiter: '',
       attributes: undefined,
       include: undefined,
       raw: undefined,
       silent: undefined },
    isNewRecord: false
  }

  {
    fullName: 'undefined undefined',
    id: 1,
    firstName: 'youzi',
    lastName: 'lee',
    job: 'ENGINEER',
    about: 'I am a good man',
    updatedAt: 2019-06-23T03:39:18.602Z,
    createdAt: 2019-06-23T03:39:18.602Z
  }

  {"fullName":"undefined undefined","id":1,"firstName":"youzi","lastName":"lee","job":"ENGINEER","about":"I am a good man","updatedAt":"2019-06-23T13:56:39.857Z","createdAt":"2019-06-23T13:56:39.857Z"}
  */

</pre>【 Updating / Saving / Persisting an instance 】<pre class="js">
(async () => {
const Project = sequelize.define('project', { name: Sequelize.STRING },{timestamps:false,freezeTableName:true});
await Project.sync({force: true});
await Project.create({name: 'project1'})

const project1 = await Project.findByPk(1);
console.log(project1.get({plain: true}));

// 不能用save()更新实例的id,只能更新其他字段
project1.id = 2;
project1.save().then(project => console.log(JSON.stringify(project)))
// {"id":1,"name":"project1"}
project1.name = '2';
project1.save().then(project => console.log(JSON.stringify(project)))
/*
UPDATE `project` SET `name`=? WHERE `id` = ?
{"id":1,"name":"2"}
*/
project1.update({
  name: '2'
}).then(project => console.log(JSON.stringify(project)))
/*
UPDATE `project` SET `name`=? WHERE `id` = ?
{"id":1,"name":"2"}
*/

// 可以使用Project.update更新
Project.update({ id: 2 }, {
  where: { id: 1 }
}).then(project => console.log(JSON.stringify(project)))
.catch(err => console.log(err))
/*
UPDATE `project` SET `id`=? WHERE `id` = ?
[1]
*/

project1.destroy().then(project => console.log(JSON.stringify(project)))
/*
DELETE FROM `project` WHERE `id` = 1
{"id":1,"name":"project1"}
*/

})()

</pre>更新指定的字段<pre class="js">
// define which attributes should be saved when calling save, by passing an array of column names
task.title = 'foooo'
task.description = 'baaaaaar'
task.save({fields: ['title']}).then(() => {
 // title will now be 'foooo' but description is the very same as before
})

// The equivalent call using update looks like this:
task.update({ title: 'foooo', description: 'baaaaaar'}, {fields: ['title']}).then(() => {
 // title will now be 'foooo' but description is the very same as before
})

</pre>【 Destroying / Deleting persistent instances 】<pre class="js">
// After an object is soft deleted in paranoid mode, you will not be able to create a new instance with the same primary key until you have force-deleted the old instance.
// If the paranoid options is true, the object will not be deleted, instead the deletedAt column will be set to the current timestamp. To force the deletion, you can pass force: true to the destroy call:
task.destroy({ force: true })

// Restoring soft-deleted instances
Task.create({ title: 'a task' }).then(task => {
  // now you see me...
  return task.destroy();
}).then(() => {
  // now i'm gone, but wait...
  return task.restore();
})

</pre>【 Reloading instances 】<pre class="js">
Person.findOne({ where: { name: 'john' } }).then(person => {
  person.name = 'jane'
  console.log(person.name)   // 'jane'

  person.reload().then(() => {
    console.log(person.name) // 'john'
  })
})

</pre>【 自增更新 Incrementing & Decrementing 】<pre class="js">
User.findByPk(1).then(user => {
  return user.increment('my-integer-field', {by: 2})
}).then(user => {
  // call user.reload() to get the updated instance
})

User.findByPk(1).then(user => {
  return user.increment([ 'my-integer-field', 'my-very-other-field' ], {by: 2})
}).then(user => {
  // call user.reload() to get the updated instance
})

User.findByPk(1).then(user => {
  return user.increment({
    'my-integer-field':    2,
    'my-very-other-field': 3
  })
}).then(user => {
  // call user.reload() to get the updated instance
})

user.increment({ 'my-field1': 2, 'my-field2': 3 }, {WHERE:{ COND:1 }})
// 生成SQL UPDATE USER SET my-field1= my-field1 + 2 ,my-field2 = my-field2+ 3 WHERE COND =1;

User.findByPk(1).then(user => {
  return user.decrement('my-integer-field', {by: 2})
}).then(user => {
  // call user.reload() to get the updated instance
})

User.findByPk(1).then(user => {
  return user.decrement([ 'my-integer-field', 'my-very-other-field' ], {by: 2})
}).then(user => {
  // call user.reload() to get the updated instance
})

User.findByPk(1).then(user => {
  return user.decrement({
    'my-integer-field':    2,
    'my-very-other-field': 3
  })
}).then(user => {
  // call user.reload() to get the updated instance
})

</pre>

<h4>instance类的API</h4><pre>
【 isNewRecord － 是否新记录 】
instance.isNewRecord -> Boolean
当实例是未保存到数据库的非持久化实例时返回true

【 Model() － 创建实例的模型 】
instance.Model() -> Model
返回创建实例的Model。

【 sequelize() － Sequelize实例 】
instance.sequelize() -> Sequelize
返回Sequelize实例的引用

【 where() － 实例的查询条件 】
instance.where() -> Object
获取当前实例的查询条件,相当于option.where

【 getDataValue() － 获取值 】
instance.getDataValue(key) -> any
获取底层数据值。
key － {String},表示要获取值的字段名

【 setDataValue() － 设置值 】
instance.setDataValue(key, value)
设置底层数据值。

key － {String},表示要设置值的字段名
value － {any},表示要设置的值

【 get() － 获取值(单个或全部)】
instance.get([key], [options]) -> Object|any
不提供key时,返回全部实例值,同样适用于虚拟访问器。
提供key时返回字段值或返回虚拟访问器的值。

[key] － {String},表示要访问值的字段名
[options] － {Object}
[options.plain=false] － {Boolean},设置为true时返回简单对象

【 set() － 设置值,别名：setAttributes 】
instance.set(key, value, [options])
set用于更新实例值。set更新的值会保存在底层的dataValues对象中,如果为所设置的key设置了自定义设置器,那么设置器被调用。如果要绕过这些设置器,可以在选项中设置raw: true选项。

当通过一对象进行设置时,它会是一个循环对象,会为其中的每个key/value分别调用此方法。当设置raw时,底层的dataValues会被直接设置或扩展。

当值被修改后,修改值会被存储在的previous中,并会设置一个changed标识。

Set同样可以用于构建关联实例。当设置时应该确认属性键能够匹配到关系实例的别名,并确认这些选项已设置关联。

在JSON/JSONB属性中,如果使用.分隔的字段,那么设置嵌套对象的值。

key － {String | Object},表示要设置值的字段
value － {any},表示要设置的值
[options] － {Object}
[options.raw=false] － {Boolean},虚拟设置器会被忽略
[options.reset=false] － {Boolean},清除之前的设置数据

【 changed() － 判断是否修改 】
instance.changed([key]) -> Boolean|Array
判断字段或实例是否修改过,即判断dataValues中的值是否与_previousDataValues中的值是否相同。
当不传入参数时会返回一个包含已修改字段的数组。当传入参数时返回一个表示该字段是否修改的布尔值

【 previous() － 返回修改前的值 】
instance.previous([key]) -> any|Array.< any>
返回实例修改前的值,即_previousDataValues属性中值。如果不传入参数,则返回所有已修改的值

【 save() － 保存实例到数据库 】
instance.save([options]) -> Promise.< this|Errors.ValidationError<
较验数据,通过后持久化到数据库中。这个方法仅会保存修改过的数据,如果未发生修改那么不会进行任何操作。
操作成功会回调修改结果,验证失败则返回一个Sequelize.ValidationError对象。

[options] - {Object}
[options.fields] - {Array.< string>},可选的表示数据库中字段值,提供后仅会验证和保存其中的字段
[[options.silent=false]] - {Boolean},设置为true时updatedAt在更新时不会发生变化
[options.validate=true] - {Boolean},保存前时否验证
[options.logging=false] - {Function},一个用于打印执行SQL的函数
[options.transaction=false] - {Transaction}

【 reload() － 重新加载数据 】
instance.reload([options]) -> Promise.< this>
用数据库中的数据当前实例。这不同于find(Instance.id),因为它会创建并返回一个新实例。而该方法是用新数据刷新当前实例。

[options] - {Object}
[options.logging=false] - {Function},一个用于打印执行SQL的函数

【 validate() － 验证属性 】
instance.validate([options]) -> Promise.< Errors.ValidationError|undefined>
根据模型定义的验证规则验证模型属性。验证成功时返回null,否则返回一个错误对象。

[options] - {Object}
[options.skip] - {String|Array},包含一个要跳过的验证字段的字符串或数组

【 update() － 设置并保存,别名：updateAttributes 】
instance.update(updates, options) -> Promise.< this>
相当于调用set方法后再调用save,但它只保存传递给它确切值,使用它更新时更原子和更安全。

updates - {Object},见set
options - {Object},见save

【 destroy() － 删除 】
instance.destroy([options={}]) -> Promise.< undefined>
删除实例在数据库中对应的行。设置为软删除(paranoid)时,数据行并不会真实删除,而是将deletedAt列更新为当前时间。

[options] - {Object}
[options.force=false] - {Boolean},强制删除。设置为 true时,软删除的模型也会强制删除
[options.logging=false] - {Function},一个用于打印执行SQL的函数
[options.transaction] - {Transaction}
[options.searchPath=DEFAULT] - {String},指定schema的 search_path (仅 Postgres)

【 restore() － 数据恢复 】
instance.restore([options={}]) -> Promise.< undefined>
恢复实例数据,仅适用于软删除(paranoid)模型

[options] - {Object}
[options.logging=false] - {Function},一个用于打印执行SQL的函数
[options.transaction] - {Transaction}

【 increment() － 字段值增加 】
instance.increment(fields, [options]) -> Promise< this>
为一个或多个字段增加值。这一操作在数据库中完成,也就是说它并不使用实例的存储值。其增加值使用如下语句完成：
SET column = column + X
增加后,要获取正确的实例值应该使用reload()方法重新加载数据。

fields - {String | Array | Object},要增加值的字段
[options] - {Object}
[options.by=1] - {Integer},要增加的数字值
[options.logging=false] - {Function},一个用于打印执行SQL的函数
[options.transaction] - {Transaction}

instance.increment('number') // 增加 1
instance.increment(['number', 'count'], { by: 2 }) // 'number' 和 'count'两个字段增加 2
instance.increment({ answer: 42, tries: 1}, { by: 2 })  // 'answer'字段增加 42, 'tries' 字段增加 1,'by' 参数将忽略,因为每一列都有自己的值

【 decrement() － 字段值减小 】
instance.decrement(fields, [options]) -> Promise< this>
为一个或多个字段减小值。这一操作在数据库中完成,也就是说它并不使用实例的存储值。其增加值使用如下语句完成：
SET column = column - X
增加后,要获取正确的实例值应该使用reload()方法重新加载数据。

fields - {String | Array | Object},要减小值的字段
[options] - {Object}
[options.by=1] - {Integer},要减小的数字值
[options.logging=false] - {Function},一个用于打印执行SQL的函数
[options.transaction] - {Transaction}

instance.decrement('number') // 减小 1
instance.decrement(['number', 'count'], { by: 2 }) // 'number' 和 'count'两个字段减小 2
instance.decrement({ answer: 42, tries: 1}, { by: 2 }) // 'answer'字段减小 42, 'tries' 字段减小 1, 'by' 参数将忽略

【 equals() － 实例值是否相等 】
instance.equals(other) -> Boolean
检查当前实例是否与other实例的值相等

【 equalsOneOf() － 实例值其中的一个相等 】
instance.equalsOneOf(others) -> Boolean
检查当前实例是否与others数组中的任意一个实例的值相等

【 toJSON() － 转换成JSON 】
instance.toJSON() -> object
将当前实例转换为JSON形式,意味着会从数据库中取值,并应用所有自定义的访问器

User.findOne().then(user => console.log(user.toJSON()))
/*
Executing (default): SELECT `id`, `firstName`, `lastName` FROM `users` AS `user` LIMIT 1;
{ id: 1, firstName: '1', lastName: '1' }

</pre>
</div>

<div id="scopes">
<h4>scopes作用域</h4><pre>
Scopes表示一个限制范围,它最终会生成SQL查询中的where子句。它在模型定义方法sequelize.define的option参数或通过Model.scope()方法指定

作用域允许定义常用的查询,这样就可以很容易地在之后使用。Scopes包括所有相同属性规律的筛选器,where、limit等

Scopes在定义模型时定义,可以是筛选对象,或是返回筛选对象的函数－除默认限制范围外,它只能是一个对象

也可以模型定义后通过addScope方法添加作用域。这对在使用include包含限制时尤其适用,因为在模型的include在定义时包括的模型可能还未定义

</pre><pre class="js">
const Project = sequelize.define('project', { name: Sequelize.STRING }, {
  defaultScope: {
    where: { active: true }
  },
  scopes: {
    deleted: {
      where: { deleted: true }
    },
    activeUsers: {
      include: [
        { model: User, where: { active: true }}
      ]
    }
    random: function () {
      return {
        where: { someNumber: Math.random() }
      }
    },
    accessLevel: function (value) {
      return {
        where: { accessLevel: { $gte: value } }
      }
    }
  }
});

</pre><pre>
默认的作用总是会被使用,所以在上面定义的模型中使用Project.findAll()查询时会创建如下查询语句：
SELECT * FROM projects WHERE active = true

默认的作用域可以使用.unscoped()、.scope(null)、或引入一个其它的作用域移除：
Project.scope('deleted').findAll();  // 移除默认作用域
SELECT * FROM projects WHERE deleted = true

【 scopes使用 】
作用域通过调用.scope方法应用到模型定义的范围内,该方法会传入一个或多个范围的名称,并返回一个全功能的模型实例的所有规则的方法,如：.findAll、.update、.count、destroy：

var DeletedProjects = Project.scope('deleted');
DeletedProjects.findAll();

作用域被引入时有两种方式：如果不传入参数则正常引用,如果传入参数则以对象的形式传入：
Project.scope('random', { method: ['accessLevel', 19]}).findAll();
SELECT * FROM projects WHERE someNumber = 42 AND accessLevel >= 19

【 scopes合并 】
作用域可以同时应用多个,使用用时只要向.scope方法传入数组参数或做为连续的参数传入即可：

// 两种等价的方式
Project.scope('deleted', 'activeUsers').findAll();
Project.scope(['deleted', 'activeUsers']).findAll();

如果想在另一个范围内使用默认作用域,通过defaultScope参数传入.scope即可：
Project.scope('defaultScope', 'deleted').findAll();
SELECT * FROM projects WHERE active = true AND deleted = true

</pre>通过对象引入多重作用域时,当key值相同,后引入的作用域会覆盖前面的作用域规则<pre class="js">
// 在这个查询中limit和age被scope2同相同的键值覆盖
{
  scope1: {
    where: {
      firstName: 'bob',
      age: { $gt: 20 }
    },
    limit: 2
  },
  scope2: {
    where: {
      age: { $gt: 30 }
    },
    limit: 10
  }

// WHERE firstName = 'bob' AND age > 30 LIMIT 10

</pre>当进行查询时,默认的作用域逻辑会被同时使用<pre>
Project.scope('deleted').findAll({
  where: {
    firstName: 'john'
  }
})
// WHERE deleted = true AND firstName = 'john'

</pre>

<h4>association scopes 作用域</h4><pre>
关系作用域允许在关联关系上设置一个作用范围(一组用于get and create的默认属性)。作用域同样也以放在通过n:m建立关系的表的关联模型(关联目标)中

Scopes can be placed both on the associated model (the target of the association), and on the through table for n:m relations

【 scopes和关联 】
在表关联中Sequelize有两中不同但作用相关的概念,其区别不大,但很重要：
关联作用域 - 允许获取和设置关联定义默认属性,这在多表关联时很有用,这个作用域仅在使用get、set、add、create函数时调用
模型上的作用域 - 在匹配关联时允许作用默认值和其它作用范围,这些作用域都适用于模型匹配及关联查找

Post模型应该只向用户显示状态为活跃的数据：where: { active: true },这个活跃状态会同样应用于所关联的模型,而不是像commentable那样没有关联范围。这样使用默认作用域直接调用Post.findAll()方法即可,同样可用于User.getPosts()方法。

禁用默认作用域,在访问器中传入scope: null即可
User.getPosts({ scope: null })
User.getPosts({ scope: ['scope1', 'scope2']});

</pre>如果想创建一个关联作用域的快捷方法,那么可以在模型关联中定义<pre class="js">
var User = sequelize.define('user', {name: Sequelize.STRING})
var Post = sequelize.define('post', {
  title: Sequelize.STRING,
  active: Sequelize.ENUM('1', '0'),
  deleted: Sequelize.ENUM('1', '0')
}, {
  defaultScope: {
    where: { active: '1' }
  },
  scopes: {
    deleted: {
      where: { deleted: '1' }
    }
  }
});

User.hasMany(Post);
User.hasMany(Post.scope('deleted'), { as: 'deletedPosts' });   // 对一模型引用两次
await sequelize.sync({force: true})
let user1 = await User.create({name: 'lisan'})
await user1.getPosts();
// SELECT `id`, `title`, `active`, `deleted`, `userId` FROM `post` AS `post` WHERE `post`.`active` = '1' AND `post`.`userId` = 1;

await user1.getDeletedPosts();
// SELECT `id`, `title`, `active`, `deleted`, `userId` FROM `post` AS `post` WHERE `post`.`deleted` = '1' AND `post`.`userId` = 1;

await user1.getPosts({ scope: ['deleted']});
// SELECT `id`, `title`, `active`, `deleted`, `userId` FROM `post` AS `post` WHERE `post`.`deleted` = '1' AND `post`.`userId` = 1;

await user1.getPosts({ scope: ['defaultScope', 'deleted']});
// SELECT `id`, `title`, `active`, `deleted`, `userId` FROM `post` AS `post` WHERE `post`.`active` = '1' AND `post`.`deleted` = '1' AND `post`.`userId` = 1;

</pre>1:n<pre class="js">
//  A comment can be associated to either an image or a post via commentableId and commentable - we say that Post and Image are Commentable
// constraints: false禁止了引用限制,因为commentableId列会引用多个表,所以不能添加REFERENCES选项限制它,
// 这样就为Image -> Comment 和 Post -> Comment之间关系定义了一个作用域,commentable:'image'和commentable:'post'分别对应了不同的表。这个作用域会自动应用到关联函数中

const Post = sequelize.define('post', { title: Sequelize.STRING, text: Sequelize.STRING });
const Image = sequelize.define('image', { title: Sequelize.STRING, link: Sequelize.STRING });
const Comment = sequelize.define('comment', {
  title: Sequelize.STRING,
  commentable: Sequelize.STRING,     // 这条评论属于post还是image
  commentableId: Sequelize.INTEGER   // 这条评论对应的postId还是imageId
}, {
  instanceMethods: {
    // Comment模型的工具函数getItem会根据commentable的不同而进行简单的转换为getImage或getPost
    getItem(options) {
      console.log('call getItem method', this.get('commentable'))
      return this['get' + this.get('commentable').substr(0, 1).toUpperCase() + this.get('commentable').substr(1)](options);
    }
  }
});tent-Security-Policy：防止受到跨站脚本攻击以及其他跨站

Post.hasMany(Comment, {
  foreignKey: 'commentableId',
  constraints: false,
  scope: { commentable: 'post' }
});

Comment.belongsTo(Post, {
  foreignKey: 'commentableId',
  constraints: false,
  as: 'post'
});

// comment表只添加外键字段commentableId,不添加外键约束
// 可以理解为通过commentableId列引用一个commentable表
// 当调用image.getComments()方法时会自动生成WHERE commentable = 'image'语句,类似的当发表一个新的评论Comment会自动设置为'image'
Image.hasMany(Comment, {
  foreignKey: 'commentableId',
  constraints: false,
  scope: { commentable: 'image' }
});

Comment.belongsTo(Image, {
  foreignKey: 'commentableId',
  constraints: false,
  as: 'image'
});

await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `post` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255), `text` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `image` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255), `link` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `comment` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255),
  `commentable` VARCHAR(255),
  `commentableId` INTEGER, PRIMARY KEY (`id`)
) ENGINE=InnoDB;
*/

step(1)
const image = await Image.create({ title: "image1", link: "image1_link"})
await image.getComments().then(res => console.log(JSON.stringify(res)))
/*
INSERT INTO `image` (`id`,`title`,`link`) VALUES (DEFAULT,?,?);
SELECT `id`, `title`, `commentable`, `commentableId` FROM `comment` AS `comment` WHERE `comment`.`commentable` = 'image' AND `comment`.`commentableId` = 1;
[]
*/

step(2)
const comment = await image.createComment({ title: 'Awesome!' })
console.log(JSON.stringify(comment))
await image.getComments().then(res => console.log(JSON.stringify(res)))
/*
INSERT INTO `comment` (`id`,`title`,`commentable`,`commentableId`) VALUES (DEFAULT,?,?,?);
{"id":1,"title":"Awesome!","commentable":"image","commentableId":1}
SELECT `id`, `title`, `commentable`, `commentableId` FROM `comment` AS `comment` WHERE `comment`.`commentable` = 'image' AND `comment`.`commentableId` = 1;
[{"id":1,"title":"Awesome!","commentable":"image","commentableId":1}]
*/

step(3)
const newcomment = await Comment.create({title: 'newComment'})
await image.addComment(newcomment).then(res => console.log(JSON.stringify(res)))
await image.getComments().then(res => console.log(JSON.stringify(res)))
/*
INSERT INTO `comment` (`id`,`title`) VALUES (DEFAULT,?);
UPDATE `comment` SET `commentableId`=?,`commentable`=? WHERE `id` IN (2)
{"id":1,"title":"image1","link":"image1_link"}
SELECT `id`, `title`, `commentable`, `commentableId` FROM `comment` AS `comment` WHERE `comment`.`commentable` = 'image' AND `comment`.`commentableId` = 1;
[{"id":1,"title":"Awesome!","commentable":"image","commentableId":1},{"id":2,"title":"newComment","commentable":"image","commentableId":1}]
*/

</pre>n:m<pre class="js">
// 继续使用多态模型,一个标签(tag)表,一个项目(item)可以有多个标签,而一个标签也可以属于多个项目。
// 下面是一个简单示例,一个Post模型和Tag模型,而现实中标签往往被关联到多个其它模型：

const Post = sequelize.define('post', { title: Sequelize.STRING, text: Sequelize.STRING });
const Tag = sequelize.define('tag', { name: Sequelize.STRING });
const ItemTag = sequelize.define('item_tag', {
  id: { type: Sequelize.INTEGER, primaryKey: true, autoIncrement: true },
  tagId: { type: Sequelize.INTEGER, unique: 'item_tag_taggable' },
  taggable: { type: Sequelize.STRING, unique: 'item_tag_taggable' },
  taggableId: { type: Sequelize.INTEGER, unique: 'item_tag_taggable', references: null }
});

Post.belongsToMany(Tag, {
  through: {
    model: ItemTag,
    unique: false,
    scope: { taggable: 'post' }
  },
  foreignKey: 'taggableId',
  constraints: false
});
Tag.belongsToMany(Post, {
  through: {
    model: ItemTag,
    unique: false
  },
  foreignKey: 'tagId'
});

await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `post` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255), `text` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `tag` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `item_tag` (
  `id` INTEGER auto_increment , `tagId` INTEGER, `taggable` VARCHAR(255), `taggableId` INTEGER,
  UNIQUE `item_tag_taggable` (`tagId`, `taggable`, `taggableId`), PRIMARY KEY (`id`),
  FOREIGN KEY (`tagId`) REFERENCES `tag` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  FOREIGN KEY (`taggableId`) REFERENCES `post` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

// Notice that the scoped column (taggable) is now on the through model (ItemTag).
// We could also define a more restrictive(限制性的) association, for example, to get all pending tags for a post by applying a scope of both the through model (ItemTag) and the target model (Tag)
// constraints: false disables references constraints on the taggableId column. Because the column is polymorphic, we cannot say that it REFERENCES a specific table

Post.belongsToMany(Tag, {
  through: {
    model: ItemTag,
    unique: false,
    scope: {
      taggable: 'post'
    }
  },
  scope: {
    status: 'pending'
  },
  as: 'pendingTags',
  foreignKey: 'taggableId',
  constraints: false
});

await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `post` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255), `text` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `item_tag` (
  `id` INTEGER auto_increment , `tagId` INTEGER, `taggable` VARCHAR(255), `taggableId` INTEGER,
  UNIQUE `item_tag_taggable` (`tagId`, `taggable`, `taggableId`), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `tag` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
*/

const post = await Post.create({ title: 'title1', text: 'text1' })
post.getPendingTags().then(re => console.log(re));
/*
SELECT
  `tag`.`id`,
  `tag`.`name`,
  `item_tag`.`id` AS `item_tag.id`,
  `item_tag`.`tagId` AS `item_tag.tagId`,
  `item_tag`.`taggable` AS `item_tag.taggable`,
  `item_tag`.`taggableId` AS `item_tag.taggableId`
FROM
  `tag` AS `tag`
  INNER JOIN `item_tag` AS `item_tag` ON `tag`.`id` = `item_tag`.`tagId`
  AND `item_tag`.`taggableId` = 1
  AND `item_tag`.`taggable` = 'post'
WHERE
  (`tag`.`status` = 'pending');
*/

</pre>
</div>

<div id="associations">
<h3>sequelize Associations</h3><pre>
模型(Model)之间存在各种各样的关系,如一对一(One-To-One )、一对多(One-To-Many)、多对多(Many-To-Many)等。模型间的关系本质上是对其代表的数据库中表之间的关系描述,通过这些关系可以实现数据库中表之间主/外键约束的创建,查询时也可以基于这些关系生成在数据库中执行的连接查询或复合查询SQL语句,实现关联表之间的连接查询、更新、删除等操作

创建关联是通过调用当前模型(源模型)的belongsTo/hasOne/hasMany/belongsToMany方法完成,并为这个方法第一个参数提供一个目标模型
sourceModel.belongsTo(targetModel)
与目标模型建立1:1关联关系,关联关系(外键)存在于源模型中,并以单数关系混入到源模型

sourceModel.hasOne(targetModel)
与目标模型建立1:1关联关系,关联关系(外键)存在于目标模型中,并以单数关系混入到源模型

sourceModel.hasMany(targetModel)
与目标模型建立1:N关联关系,关联关系(外键)存在于目标模型中,并以复数关系混入到源模型

sourceModel.belongsToMany(targetModel)
与目标模型建立N:M关联关系,会通过sourceId和targetId创建交叉表,并以复数关系混入到源模型

// 1:1
Organization.belongsTo(User, { foreignKey: 'owner_id' });
User.hasOne(Organization, { foreignKey: 'owner_id' });

// 1:M
Project.hasMany(Task, { foreignKey: 'tasks_pk' });
Task.belongsTo(Project, { foreignKey: 'tasks_pk' });

// N:M
User.belongsToMany(Role, { through: 'user_has_roles', foreignKey: 'user_role_user_id' });
Role.belongsToMany(User, { through: 'user_has_roles', foreignKey: 'roles_identifier' });

【 as和foreignKey 命名策略 】
别名规范是1:1,1:n应该是单数,n:m应该是负数,可在sequelize.define('name', attribute, {name: {singular: 'task',plural:'tasks',}})中定义,或建立关联关系时由as选项指定

get/set/add/create

没有指定as和foreignKey时,foreignKey由模型名+主键名首字母大写组成,访问器和设置器方法: 1:1,1:n时get/set+模型名,n:m时模型名如果是单数则访问器和设置器方法是get/set+模型名的复数,别名复数时则是get/set+模型名

指定foreignKey时,foreignKey由foreignKey值组成

只指定as别名时,foreignKey由别名+主键名首字母大写组成,1:1,1:n时get/set方法由as指定,n:m时as如果是单数则访问器和设置器方法是get/set+别名的复数,别名复数时则是get/set+别名

By default sequelize will use the model name to figure(计算) out the name of the model when used in associations.
a model named user will add the functions get/set/add User to instances of the associated model, and a property named .user in eager loading
while a model named User will add the same functions, but a property named .User in eager loading.

you can alias models in associations using as. In single associations (hasOne and belongsTo), the alias should be singular, while for many associations (hasMany) it should be plural. Sequelize then uses the inflection library to convert the alias to its singular form. However, this might not always work for irregular or non-english words. In this case, you can provide both the plural and the singular form of the alias:
User.belongsToMany(Project, { as: { singular: 'task', plural: 'tasks' }})

如果希望总是使用相同的别名,那么可以定义模型时指定

</pre><pre class="js">
const Project = sequelize.define('project', attributes, {
  name: {
    singular: 'task',
    plural: 'tasks',
  },
})

User.belongsToMany(Project);  // add the functions add/set/get Tasks to user instances.

</pre>

<h4>association demo</h4><pre class="js">
function greenlog(msg){
  console.log('\x1b[32m', msg, '\x1b[97m')
}

function step(order){
  console.log('\x1b[32m', '>>>>>> ' + order++, '\x1b[97m')
}

/*
用户(User)－与其它模型存在1:1、1:N、N:M
用户登录信息(UserCheckin)－与User存在1:1关系
用户地址(UserAddress)－与User存在N:1关系
角色(Role)－与User存在N:M关系
*/

const User = sequelize.define('User', {
  id:{type:Sequelize.BIGINT(11), autoIncrement:true, primaryKey : true, unique : true},
  username: { type: Sequelize.STRING, allowNull: false, comment:'用户名' },
  password: { type: Sequelize.STRING, allowNull: false, comment:'用户密码' },
  active: { type: Sequelize.ENUM('0','1'), allowNull: false, defaultValue: '1', comment:'是否正常状态' }
},{
  tableName: 'user',
  timestamps: true,
  underscored: true,
  paranoid: true,
  freezeTableName: true,
  charset: 'utf8',
  collate: 'utf8_general_ci'
});

// 通过references特性将userId定义为外键,并通过field特性将其在数据库中的字段名指定为user_id
const UserCheckin = sequelize.define('UserCheckin', {
  id: { type: Sequelize.BIGINT(11), autoIncrement: true, primaryKey: true, unique: true },
  userId: {
    type: Sequelize.BIGINT(11),
    field: 'user_id',
    unique: true,
    references: { model: 'User', key: 'id' },
    comment:'用户Id'
  },
  loginIp: { type: Sequelize.STRING, field: 'login_ip', allowNull: false, defaultValue: '' , validate: {isIP: true}, comment:'登录IP'}
},{
  underscored: true,
  timestamps: true,
  tableName: 'userCheckin',
  comment: '用户登录信息',
  charset: 'utf8',
  collate: 'utf8_general_ci',
  indexes: [{
    name: 'userCheckin_userId',
    method: 'BTREE',
    fields: ['user_id']
  }]
});

// User模型与UserAddress存在1:N的关联关系,但在这里并没有用references特性显式的指定外键。
// 这是因为Sequlieze不仅可以在模型定义时指定外键,还可以在建立模型关系时指定,甚至主外键关系并不需要显示的存在,只要在建立模型关系时指定关联键即可,
const UserAddress = sequelize.define('UserAddress', {
  id: { type: Sequelize.BIGINT(11), autoIncrement: true, primaryKey: true, unique: true, comment:'主键' },
  userId: {type: Sequelize.BIGINT(11), field: 'user_id', allowNull: false, comment:'用户Id' },
  consignee : { type: Sequelize.STRING, field: 'consignee', allowNull: false, comment:'收货人' },
  address: { type: Sequelize.STRING(1024), field: 'address', allowNull: false, comment:'详细地址' },
  zipCode: { type: Sequelize.STRING(16), field: 'zip_code', allowNull: true, comment:'邮编' },
  tel: { type: Sequelize.STRING(32), field: 'tel', allowNull: false, comment:'电话' },
},{
  underscore: true,
  timestamps: false,
  freezeTableName: true,
  tableName: 'userAddress',
  comment: '用户地址表',
  charset: 'utf8',
  collate: 'utf8_general_ci',
  indexes: [{
    name: 'userAddress_userId',
    method: 'BTREE',
    fields: ['user_id']
  }]
});

// Role模型与User存在N:M的关系,这样就需要两者通过一个关系表(关系模型)

</pre><pre class="js">进行关联。
app.use(cors({
  origin: function (ctx) {
      // if (ctx.url === '/test') {
          return "*"; // 允许来自所有域名请求
      // }
      // return 'http://localhost:8080'; // 这样就能只允许 http://localhost:8080 这个域名的请求了
  },
  exposeHeaders: ['WWW-Authenticate', 'Server-Authorization'],
  maxAge: 5,
  credentials: true,
  allowMethods: ['GET', 'POST', 'DELETE'],
  allowHeaders: ['Content-Type', 'Authorization', 'Accept'],
}))
// 但并不需要手工建立这个关系表,指定关联关系后Sequelize会自动创建关系表
const Role = sequelize.define('Role', {
  id: { type: Sequelize.BIGINT(11), autoIncrement: true, primaryKey: true, unique: true, comment:'角色Id' },
  roleName: { type: Sequelize.STRING, field: 'role_name', comment:'角色名' }
},{
  underscored: true,
  timestamps: false,      // 不用生成created_at/updated_at两个字段
  freezeTableName: true,
  tableName: 'role',
  charset: 'utf8',
  collate: 'utf8_general_ci'
});

// 建立模型之间的关系
User.hasOne(UserCheckin);
UserCheckin.belongsTo(User);
// 通过foreignKey和targetKey来指定关联关系(主外键关系),指定了as选项,该选项表示"别名",目标模型会混入到源模型后会使用该名称
User.hasMany(UserAddress, {foreignKey:'user_id', targetKey:'id', as:'Address'});
// through选项表示"关系",可以是一个模型或字符串,使用字符串时表示在数据库中表名
User.belongsToMany(Role, {through: 'userRoles', as:'UserRoles'});
Role.belongsToMany(User, {through: 'userRoles', as:'UserRoles'});
// 将模型及关联关系同步到数据库中
await sequelize.sync({force: true})
/*
除前面定义4个模型所对应的表外,Sequelize还自动创建了一个关系表userRoles,该表使用User和Role两个表的外键做为联合主键
CREATE TABLE IF NOT EXISTS `user` (
  `id` BIGINT(11) auto_increment UNIQUE , `username` VARCHAR(255) NOT NULL COMMENT '用户名', `password` VARCHAR(255) NOT NULL COMMENT '用户密码',
  `active` ENUM('0', '1') NOT NULL DEFAULT '1' COMMENT '是否正常状态',
  `created_at` DATETIME NOT NULL, `updated_at` DATETIME NOT NULL, `deleted_at` DATETIME,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE utf8_general_ci;
SHOW INDEX FROM `user`

CREATE TABLE IF NOT EXISTS `userCheckin` (
  `id` BIGINT(11) auto_increment UNIQUE ,
  `user_id` BIGINT(11),
  `login_ip` VARCHAR(255) NOT NULL DEFAULT '' COMMENT '登录IP',
  `created_at` DATETIME NOT NULL, `updated_at` DATETIME NOT NULL, PRIMARY KEY (`id`),
  FOREIGN KEY (`user_id`) REFERENCES `user` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB COMMENT '用户登录信息' DEFAULT CHARSET=utf8 COLLATE utf8_general_ci;
SHOW INDEX FROM `userCheckin`
ALTER TABLE `userCheckin` ADD INDEX `userCheckin_userId` (`user_id`)

CREATE TABLE IF NOT EXISTS `userAddress` (
  `id` BIGINT(11) auto_increment UNIQUE  COMMENT '主键',
  `user_id` BIGINT(11),
  `consignee` VARCHAR(255) NOT NULL COMMENT '收货人', `address` VARCHAR(1024) NOT NULL COMMENT '详细地址', `zip_code` VARCHAR(16) COMMENT '邮编', `tel` VARCHAR(32) NOT NULL COMMENT '电话',
  PRIMARY KEY (`id`),
  FOREIGN KEY (`user_id`) REFERENCES `user` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB COMMENT '用户地址表' DEFAULT CHARSET=utf8 COLLATE utf8_general_ci;
SHOW INDEX FROM `userAddress`
ALTER TABLE `userAddress` ADD INDEX `userAddress_userId` (`user_id`)

CREATE TABLE IF NOT EXISTS `role` (
  `id` BIGINT(11) auto_increment UNIQUE  COMMENT '角色Id', `role_name` VARCHAR(255) COMMENT '角色名',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE utf8_general_ci;
SHOW INDEX FROM `role`

CREATE TABLE IF NOT EXISTS `userRoles` (
  `created_at` DATETIME NOT NULL, `updated_at` DATETIME NOT NULL,
  `user_id` BIGINT(11) ,
  `role_id` BIGINT(11) ,
  PRIMARY KEY (`user_id`, `role_id`),
  FOREIGN KEY (`user_id`) REFERENCES `user` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  FOREIGN KEY (`role_id`) REFERENCES `role` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE utf8_general_ci;
SHOW INDEX FROM `userRoles`
*/

greenlog('>>> step1: 单独插入数据')
// 为User和Role添加数据：
await Promise.all([
  User.create({username:'itbilu', password:'itbilu.com'}),
  Role.create({roleName:'管理员'})
]).then(results => {
  console.log('创建成功：'+JSON.stringify({user:results[0].dataValues, role:results[1].dataValues}));
}).catch(err => console.log(err));
/*
INSERT INTO `user` (`id`,`username`,`password`,`active`,`created_at`,`updated_at`) VALUES (DEFAULT,?,?,?,?,?);
INSERT INTO `role` (`id`,`role_name`) VALUES (DEFAULT,?);
创建成功：{"user":{"active":"1","id":1,"username":"itbilu","password":"itbilu.com","updatedAt":"2019-06-28T03:45:42.006Z","createdAt":"2019-06-28T03:45:42.006Z"},"role":{"id":1,"roleName":"管理员"}}
*/

greenlog('>>> step2: 关联模型插入数据1:1,1:n')
/*
被关联的"目标模型"可以调用其自身的create()等方法插入数据,可以通过"源模型"的模型实例中设置器方法插入数据。
定义模型的关联关系后,对于1:1或1:N关系模型,目标模型会做为源模型的一个实例属性提供,同时会相应的设置器方法源模型实例中
而对于N:M关系模型,源模型及目标模型会做为彼些的实例属性提供,并为双方相应的设置器方法。
*/
// 通过User实例向UserCheckin中插入数据：
await User.create({username:'itbilu2', password:'itbilu.com2'}).then(async user => {
  var userCheckin = UserCheckin.build({loginIp:'127.0.0.1'});
  await user.setUserCheckin(userCheckin).then(res => console.log(JSON.stringify(res)))
  console.log('UserCheckin 插入数据成功');
  await user.getUserCheckin().then(res => console.log(JSON.stringify(res)))
  console.log(user.UserCheckin)
}).catch(err => console.log(err));
/*
INSERT INTO `user` (`id`,`username`,`password`,`active`,`created_at`,`updated_at`) VALUES (DEFAULT,?,?,?,?,?);
SELECT `id`, `user_id` AS `userId`, `login_ip` AS `loginIp`, `created_at` AS `createdAt`, `updated_at` AS `updatedAt`, `user_id` AS `UserId` FROM `userCheckin` AS `UserCheckin` WHERE `UserCheckin`.`user_id` = 2 LIMIT 1;
INSERT INTO `userCheckin` (`id`,`login_ip`,`created_at`,`updated_at`,`user_id`) VALUES (DEFAULT,?,?,?,?);
{"id":1,"loginIp":"127.0.0.1","UserId":2,"updatedAt":"2019-06-28T03:45:42.607Z","createdAt":"2019-06-28T03:45:42.607Z","userId":2}
UserCheckin 插入数据成功
SELECT `id`, `user_id` AS `userId`, `login_ip` AS `loginIp`, `created_at` AS `createdAt`, `updated_at` AS `updatedAt`, `user_id` AS `UserId` FROM `userCheckin` AS `UserCheckin` WHERE `UserCheckin`.`user_id` = 2 LIMIT 1;
{"id":1,"userId":2,"loginIp":"127.0.0.1","createdAt":"2019-06-28T03:45:42.000Z","updatedAt":"2019-06-28T03:45:42.000Z","UserId":2}
undefined
*/

greenlog('>>> step3: 关联模型插入数据n:m')

// 对于N:M关系的两个模型,如果未显式定义关系模型(关系表),就只能通过源模型实例或目标模型实例向数据库中的关系表插入数据。
// 通过User及Role实例向关系表插入数据
await Promise.all([
  User.create({username:'itbilu3', password:'itbilu.com3'}),
  Role.create({roleName:'管理员3'})
]).then(async results => {
  var user = results[0];
  var role = results[1];
  await user.setUserRoles(role).then(res => console.log(JSON.stringify(res)))
  // 或
  // role.setUserRoles(user);
  console.log('userRoles 插入数据成功');
  await user.getUserRoles().then(res => console.log(JSON.stringify(res)))
}).catch(err => console.log(err));
/*
INSERT INTO `user` (`id`,`username`,`password`,`active`,`created_at`,`updated_at`) VALUES (DEFAULT,?,?,?,?,?);
INSERT INTO `role` (`id`,`role_name`) VALUES (DEFAULT,?);
SELECT `created_at` AS `createdAt`, `updated_at` AS `updatedAt`, `user_id` AS `UserId`, `role_id` AS `RoleId` FROM `userRoles` AS `userRoles` WHERE `userRoles`.`user_id` = 3;
INSERT INTO `userRoles` (`created_at`,`updated_at`,`user_id`,`role_id`) VALUES ('2019-06-28 11:45:43','2019-06-28 11:45:43',3,2);
[[{"createdAt":"2019-06-28T03:45:43.015Z","updatedAt":"2019-06-28T03:45:43.015Z","UserId":3,"RoleId":2}]]
userRoles 插入数据成功
SELECT `Role`.`id`, `Role`.`role_name` AS `roleName`, `userRoles`.`created_at` AS `userRoles.createdAt`, `userRoles`.`updated_at` AS `userRoles.updatedAt`, `userRoles`.`user_id` AS `userRoles.UserId`, `userRoles`.`role_id` AS `userRoles.RoleId` FROM `role` AS `Role` INNER JOIN `userRoles` AS `userRoles` ON `Role`.`id` = `userRoles`.`role_id` AND `userRoles`.`user_id` = 3;
[{"id":2,"roleName":"管理员3","userRoles":{"createdAt":"2019-06-28T03:45:43.000Z","updatedAt":"2019-06-28T03:45:43.000Z","UserId":3,"RoleId":2}}]
*/

greenlog('>>> step4: 1:1数据查询')

// 对于1:1关联关系的模型,可以在查询时通过include指定要连接查询的模型。指定后Sequelize会自动生成连接查询语句
/*
SELECT `User`.`id`, `User`.`username`, `User`.`password`, `User`.`active`, `User`.`created_at`, `User`.`updated_at`, `User`.`deleted_at`,
`UserCheckin`.`id` AS `UserCheckin.id`, `UserCheckin`.`user_id` AS `UserCheckin.userId`, `UserCheckin`.`login_ip` AS `UserCheckin.loginIp`, `UserCheckin`.`created_at` AS `UserCheckin.created_at`, `UserCheckin`.`updated_at` AS `UserCheckin.updated_at`, `UserCheckin`.`user_id` AS `UserCheckin.user_id`
FROM `user` AS `User` LEFT OUTER JOIN `userCheckin` AS `UserCheckin`
ON `User`.`id` = `UserCheckin`.`user_id`
WHERE `User`.`deleted_at` IS NULL LIMIT 1;
*/
await User.findOne({where: {id: 2}, include:[UserCheckin]}).then(user => {
  console.log(JSON.stringify(user))
}).catch(err => console.log(err));
/*
SELECT `User`.`id`, `User`.`username`, `User`.`password`, `User`.`active`, `User`.`created_at` AS `createdAt`, `User`.`updated_at` AS `updatedAt`, `User`.`deleted_at` AS `deletedAt`, `UserCheckin`.`id` AS `UserCheckin.id`, `UserCheckin`.`user_id` AS `UserCheckin.userId`, `UserCheckin`.`login_ip` AS `UserCheckin.loginIp`, `UserCheckin`.`created_at` AS `UserCheckin.createdAt`, `UserCheckin`.`updated_at` AS `UserCheckin.updatedAt`, `UserCheckin`.`user_id` AS `UserCheckin.UserId` FROM `user` AS `User` LEFT OUTER JOIN `userCheckin` AS `UserCheckin` ON `User`.`id` = `UserCheckin`.`user_id` WHERE (`User`.`deleted_at` IS NULL AND `User`.`id` = 2);
{"id":2,"username":"itbilu2","password":"itbilu.com2","active":"1","createdAt":"2019-06-28T03:51:11.000Z","updatedAt":"2019-06-28T03:51:11.000Z","deletedAt":null,"UserCheckin":{"id":1,"userId":2,"loginIp":"127.0.0.1","createdAt":"2019-06-28T03:51:11.000Z","updatedAt":"2019-06-28T03:51:11.000Z","UserId":2}}
*/

greenlog('>>> step5: 1:N或N:M数据查询')

// 而1:N或N:M关系的模型,可以通过调用源模型实例的访问器方法查询目标模型
// 查询UserAddress：
// SELECT `id`, `user_id` AS `userId`, `consignee`, `address`, `zip_code` AS `zipCode`, `tel`, `user_id` FROM `userAddress` AS `UserAddress` WHERE `UserAddress`.`user_id` = 1;
await User.findOne().then(async user => {
  console.log(JSON.stringify(user))
  var userAddress = UserAddress.build({
    userId: user.id,
    consignee : '收货人',
    address: '详细地址',
    zipCode: '10011',
    tel: '15107398888'
  });
  await user.setAddress([userAddress]).then(res => console.log('set', JSON.stringify(res)))
  await user.getAddress().then(res => console.log('get', JSON.stringify(res)));

  var userAddress = await UserAddress.create({
    userId: user.id,
    consignee : '收货人',
    address: '详细地址',
    zipCode: '10011',
    tel: '15107398888'
  });
  await user.getAddress().then(res => console.log('get', JSON.stringify(res)));
}).catch(err => console.log(err));
/*
SELECT `id`, `username`, `password`, `active`, `created_at` AS `createdAt`, `updated_at` AS `updatedAt`, `deleted_at` AS `deletedAt` FROM `user` AS `User` WHERE (`User`.`deleted_at` IS NULL) LIMIT 1;
{"id":1,"username":"itbilu","password":"itbilu.com","active":"1","createdAt":"2019-06-28T08:02:30.000Z","updatedAt":"2019-06-28T08:02:30.000Z","deletedAt":null}

SELECT `id`, `user_id` AS `userId`, `consignee`, `address`, `zip_code` AS `zipCode`, `tel`, `user_id` FROM `userAddress` AS `UserAddress` WHERE `UserAddress`.`user_id` = 1;
UPDATE `userAddress` SET `user_id`=? WHERE `id` IN (NULL)
set {"id":1,"username":"itbilu","password":"itbilu.com","active":"1","createdAt":"2019-06-28T08:02:30.000Z","updatedAt":"2019-06-28T08:02:30.000Z","deletedAt":null}
SELECT `id`, `user_id` AS `userId`, `consignee`, `address`, `zip_code` AS `zipCode`, `tel`, `user_id` FROM `userAddress` AS `UserAddress` WHERE `UserAddress`.`user_id` = 1;
get []

INSERT INTO `userAddress` (`id`,`user_id`,`consignee`,`address`,`zip_code`,`tel`) VALUES (DEFAULT,?,?,?,?,?);
SELECT `id`, `user_id` AS `userId`, `consignee`, `address`, `zip_code` AS `zipCode`, `tel`, `user_id` FROM `userAddress` AS `UserAddress` WHERE `UserAddress`.`user_id` = 1;
get [{"id":1,"userId":1,"consignee":"收货人","address":"详细地址","zipCode":"10011","tel":"15107398888","user_id":1}]
*/

greenlog('>>> step6: 数据更新')
// 设置器方法同样可以用于关系模型的更新,使用设置器设置属性时,设置器方法首先会通过isNewRecord特性判断是否是新记录,从而进行插入数据或更新数据。
// 通过User实例更新UserCheckin
await User.findOne({include:[UserCheckin]}).then(async user => {
  console.log(JSON.stringify(user));
  var userCheckin = UserCheckin.build({userId:user.id, loginIp:'192.168.0.1'});
  await user.setUserCheckin(userCheckin);
}).catch(err => console.log(err));
/*
SELECT `User`.`id`, `User`.`username`, `User`.`password`, `User`.`active`, `User`.`created_at` AS `createdAt`, `User`.`updated_at` AS `updatedAt`, `User`.`deleted_at` AS `deletedAt`, `UserCheckin`.`id` AS `UserCheckin.id`, `UserCheckin`.`user_id` AS `UserCheckin.userId`, `UserCheckin`.`login_ip` AS `UserCheckin.loginIp`, `UserCheckin`.`created_at` AS `UserCheckin.createdAt`, `UserCheckin`.`updated_at` AS `UserCheckin.updatedAt`, `UserCheckin`.`user_id` AS `UserCheckin.UserId` FROM `user` AS `User` LEFT OUTER JOIN `userCheckin` AS `UserCheckin` ON `User`.`id` = `UserCheckin`.`user_id` WHERE (`User`.`deleted_at` IS NULL) LIMIT 1;
{"id":1,"username":"itbilu","password":"itbilu.com","active":"1","createdAt":"2019-06-28T08:14:19.000Z","updatedAt":"2019-06-28T08:14:19.000Z","deletedAt":null,"UserCheckin":null}
SELECT `id`, `user_id` AS `userId`, `login_ip` AS `loginIp`, `created_at` AS `createdAt`, `updated_at` AS `updatedAt`, `user_id` AS `UserId` FROM `userCheckin` AS `UserCheckin` WHERE `UserCheckin`.`user_id` = 1 LIMIT 1;
INSERT INTO `userCheckin` (`id`,`user_id`,`login_ip`,`created_at`,`updated_at`) VALUES (DEFAULT,?,?,?,?);
*/

greenlog('>>> step7: 数据删除')
// 对于逻辑删除的模(paranoid: true),删除时会向表中更新一个deleted_at时间戳。逻辑删除相当于一个更新操作
// 删除User
// UPDATE `user` SET `deleted_at`='2016-07-07 14:46:01' WHERE `deleted_at` IS NULL AND `id` = 2;
await User.destroy({where:{id:2}}).then(result => console.log('删除完成')).catch(err => console.log(err));

// 使用模型实例删除
await User.findOne().then(async user => {
  await user.destroy();
  console.log('删除完成');
}).catch(err => console.log(err));
/*
Executing (default): UPDATE `user` SET `deleted_at`=? WHERE `deleted_at` IS NULL AND `id` = ?
删除完成
Executing (default): SELECT `id`, `username`, `password`, `active`, `created_at` AS `createdAt`, `updated_at` AS `updatedAt`, `deleted_at` AS `deletedAt` FROM `user` AS `User` WHERE (`User`.`deleted_at` IS NULL) LIMIT 1;
Executing (default): UPDATE `user` SET `deleted_at`=? WHERE `id` = ? AND `deleted_at` IS NULL
删除完成
*/

</pre>

<h4>外键约束</h4><pre>
Sequelize中如果创建了两个模型之间的关联,那么关联的外键约束会被自动创建

</pre><pre class="js">
var Task = sequelize.define('task', { title: Sequelize.STRING })
var User = sequelize.define('user', { username: Sequelize.STRING })
User.hasMany(Task)
Task.belongsTo(User)
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `username` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `task` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255), `userId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`userId`) REFERENCES `user` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre><pre>
task和user之间的关系通过task表的外键userId引入并REFERENCES引用user表。默认如果引用的user被删除那么user_id会被设置为NULL,并会随user id的更新而更新。这些选项可以在建立关系时通过onUpdate和onDelete选项修改。可选项有RESTRICT、CASCADE、NO ACTION、SET DEFAULT、SET NULL

1:1和1:m的关系默认的删除选项是SET NULL,更新选项是CASCADE
n:m的关系两者都是CASCADE,即从n:m关系的任一方删除或更新数据,其所对应的关联数据也会同时被删除或更新。

</pre><pre class="js">
const User = sequelize.define('user', { name: Sequelize.STRING, });
const Project = sequelize.define('project', { name: Sequelize.STRING });
const Task = sequelize.define('task', { title: Sequelize.STRING });

User.hasOne(Project);           // project表中添加userId外键
sequelize.sync({force: true});

/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `project` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `userId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`userId`) REFERENCES `users` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

Project.belongsTo(User);         // project表中添加userId外键
sequelize.sync({force: true});
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `project` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `userId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`userId`) REFERENCES `users` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

User.hasMany(Task);              // add userId (foreign key) to Task model
sequelize.sync({force: true});
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `task` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255),
  `userId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`userId`) REFERENCES `user` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

Task.belongsTo(User);            // add userId (foreign key) to Task model
sequelize.sync({force: true});
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `task` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255),
  `userId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`userId`) REFERENCES `user` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre><pre>
【 Cyclic dependencies & Disabling constraints 】
添加表之间的约束意味着使用sequelize.sync创建表时相关的表在数据库中必须有一定创建顺序,如果Task表引用了User,那么User必须在Task之前创建。有时这会导致循环引用,想象一个场景：一个文档和版本,一个文档可以有多个版本,并且为了方便,文档对它的当前版本有一个引用

</pre><pre class="js">
const Document = sequelize.define('document', { author: Sequelize.STRING });
const Version = sequelize.define('version', { timestamp: Sequelize.DATE });

Document.hasMany(Version);      // adds documentId attribute to version
Document.belongsTo(Version, {   // adds currentVersionId attribute to document
  as: 'Current',
  foreignKey: 'currentVersionId'
});
sequelize.sync({force: true})
/*
Unhandled rejection Error: Cyclic dependency found. document is dependent of itself.
Dependency chain: document -> version => document
*/

// 解决：pass constraints: false to one of the associations
Document.hasMany(Version);
Document.belongsTo(Version, {
  as: 'Current',
  foreignKey: 'currentVersionId',
  constraints: false
});
sequelize.sync({force: true})
/*
这时会按以下顺序将表同步到数据库中
CREATE TABLE IF NOT EXISTS `document` (
  `id` INTEGER NOT NULL auto_increment , `author` VARCHAR(255), `currentVersionId` INTEGER, PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `version` (
  `id` INTEGER NOT NULL auto_increment , `timestamp` DATETIME,
  `documentId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`documentId`) REFERENCES `document` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre>创建关系时可以通过as选项指定别名,在对一模型引用两次,或对关联模型使用定义之外的名称时非常有用<pre class="js">
const User = sequelize.define('user', {name: Sequelize.STRING})
const Picture = sequelize.define('picture', {name: Sequelize.STRING})
// Picture表中创建userId外键
User.hasMany(Picture)
// source Model user表中创建ProfilePictureId外键,constraints: false表示不添加外键约束,所以最终只添加ProfilePictureId字段
User.belongsTo(Picture, { as: 'ProfilePicture', constraints: false })

await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `ProfilePictureId` INTEGER, PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `picture` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `userId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`userId`) REFERENCES `user` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

await Promise.all([
  User.create({name: 'u1', ProfilePictureId: 1}),
  Picture.create({name: 'p1', userId: 1}),
  Picture.create({name: 'p2', userId: 1})
])

const user = await User.findByPk(1)
await user.getPictures().then(res => console.log(JSON.stringify(res)))          // 获取所有关联数据,获取所有图片
await user.getProfilePicture().then(res => console.log(JSON.stringify(res)))    // 获取第一条关联数据,仅获取主图
/*
SELECT `id`, `name`, `ProfilePictureId` FROM `user` AS `user` WHERE `user`.`id` = 1;
SELECT `id`, `name`, `userId` FROM `picture` AS `picture` WHERE `picture`.`userId` = 1;
[{"id":1,"name":"p1","userId":1},{"id":2,"name":"p2","userId":1}]
SELECT `id`, `name`, `userId` FROM `picture` AS `picture` WHERE `picture`.`id` = 1;
{"id":1,"name":"p1","userId":1}
*/

User.findAll({
  where: { id: 1},
  include: [
    { model: Picture },                       // 加载所有图片
    { model: Picture, as: 'ProfilePicture' }, // 加载主图,名称拼写必须与关联关系中命名相同
  ]
}).then(res => console.log(JSON.stringify(res)))
/*
SELECT `user`.`id`, `user`.`name`, `user`.`ProfilePictureId`, `pictures`.`id` AS `pictures.id`, `pictures`.`name` AS `pictures.name`, `pictures`.`userId` AS `pictures.userId`, `ProfilePicture`.`id` AS `ProfilePicture.id`, `ProfilePicture`.`name` AS `ProfilePicture.name`, `ProfilePicture`.`userId` AS `ProfilePicture.userId` FROM `user` AS `user` LEFT OUTER JOIN `picture` AS `pictures` ON `user`.`id` = `pictures`.`userId` LEFT OUTER JOIN `picture` AS `ProfilePicture` ON `user`.`ProfilePictureId` = `ProfilePicture`.`id` WHERE `user`.`id` = 1;
[
  {
    "id":1,
    "name":"u1",
    "ProfilePictureId":1,
    "pictures":[{"id":1,"name":"p1","userId":1},{"id":2,"name":"p2","userId":1}],
    "ProfilePicture":{"id":1,"name":"p1","userId":1}
  }
]
*/

// 当匹配关联模型时可限制只匹配部分模型,这些查询条件与在find/findAll中的使用方式相同
user.getPictures({
  where: { format: 'jpg' }   // 只查找'jpg'格式的图片
})

</pre>要完全控制通过Sequlize添加的外键列,可以使用foreignKey选项。选项值可以是表示名称的字符串或类似使用sequelize.define进行模型定义时对象<pre class="js">
User.hasMany(Picture, { foreignKey: 'uid' })   // 外键列会使用uid代替默认的userId。

User.hasMany(Picture, {
  foreignKey: {
    name: 'uid',
    allowNull: false // 指定uid列不为NULL,在大多数情况下这将覆盖的外键约束,这sequelize自动创建的,这在外键禁用时非常有用
  }
})

</pre><pre>
【 Enforcing a foreign key reference without constraints 】
有时想添加一个外键引用,但不添加任何约束或关系,这种情形下可以在schema定义时手动添加reference属性

</pre><pre class="js">
const Trainer = sequelize.define('trainer', {
  firstName: Sequelize.STRING,
  lastName: Sequelize.STRING
});

// 在调用Trainer.hasMany(series)方法后Series会有一个trainerId=Trainer.id的外键引用
const Series = sequelize.define('series', {
  title: Sequelize.STRING,
  subTitle: Sequelize.STRING,
  description: Sequelize.TEXT,
  // Set FK relationship (hasMany) with `Trainer`
  trainerId: {
    type: Sequelize.INTEGER,
    references: {
      model: Trainer,
      key: 'id'
    }
  }
});

// 在调用Series.hasOne(Video)后Video会有一个seriesId=Series.id的外键引用
const Video = sequelize.define('video', {
  title: Sequelize.STRING,
  sequence: Sequelize.INTEGER,
  description: Sequelize.TEXT,
  // set relationship (hasOne) with `Series`
  seriesId: {
    type: Sequelize.INTEGER,
    references: {
      model: Series,   // 可以是一个表示表名的字符串或模型引用
      key: 'id'
    }
  }
});

// Series.hasOne(Video);
// Trainer.hasMany(Series);

sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `trainer` (
  `id` INTEGER NOT NULL auto_increment , `firstName` VARCHAR(255), `lastName` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `series` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255), `subTitle` VARCHAR(255), `description` TEXT,
  `trainerId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`trainerId`) REFERENCES `trainer` (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `video` (
  `id` INTEGER NOT NULL auto_increment , `title` VARCHAR(255), `sequence` INTEGER, `description` TEXT,
  `seriesId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`seriesId`) REFERENCES `series` (`id`)
) ENGINE=InnoDB;
*/

Series.hasOne(Video);
Trainer.hasMany(Series);

</pre>sourceKey & targetKey<pre class="js">
const User = sequelize.define('user', {name: Sequelize.STRING})
const Company = sequelize.define('company', {
  name: {
    type: Sequelize.STRING,
    primaryKey: true,
    allowNull: false,
    unique: true,
  }
});

/* 同一个表中不同的外键引用关联表中同一个字段 */
Company.hasOne(User, {foreignKey: 'companyName', sourceKey: 'name'});
User.belongsTo(Company, {foreignKey: 'fk_companyname', targetKey: 'name'}); // Adds fk_companyname to User
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `company` (`name` VARCHAR(255) NOT NULL UNIQUE , PRIMARY KEY (`name`)) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `companyName` VARCHAR(255),
  `fk_companyname` VARCHAR(255), PRIMARY KEY (`id`),
  FOREIGN KEY (`companyName`) REFERENCES `company` (`name`) ON DELETE SET NULL ON UPDATE CASCADE,
  FOREIGN KEY (`fk_companyname`) REFERENCES `company` (`name`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

/* hasOne指定sourceKey,belongsTo指定targetKey,两个key指向同一字段  */
Company.hasOne(User, {foreignKey: 'companyName', sourceKey: 'name'});
User.belongsTo(Company, {foreignKey: 'fk_companyname', targetKey: 'name'}); // Adds fk_companyname to User
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `company` (`name` VARCHAR(255) NOT NULL UNIQUE , PRIMARY KEY (`name`)) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `companyName` VARCHAR(255),
  `fk_companyname` VARCHAR(255), PRIMARY KEY (`id`),
  FOREIGN KEY (`companyName`) REFERENCES `company` (`name`) ON DELETE SET NULL ON UPDATE CASCADE,
  FOREIGN KEY (`fk_companyname`) REFERENCES `company` (`name`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

/* hasOne指定sourceKey,belongsTo指定targetKey,两个key指向不同的字段 */
const User = sequelize.define('user', {name: Sequelize.STRING})
const Company = sequelize.define('company', {
  name: {
    type: Sequelize.STRING,
    primaryKey: true,
    allowNull: false,
    unique: true,
  },
  newname: {
    type: Sequelize.STRING,
    allowNull: false,
    unique: true,
  }
});

Company.hasOne(User, {foreignKey: 'companyName', sourceKey: 'name'});
User.belongsTo(Company, {foreignKey: 'fk_companyname', targetKey: 'newname'}); // Adds fk_companyname to User
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `company` (
  `name` VARCHAR(255) NOT NULL UNIQUE , `newname` VARCHAR(255) NOT NULL UNIQUE, PRIMARY KEY (`name`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `companyName` VARCHAR(255),
  `fk_companyname` VARCHAR(255), PRIMARY KEY (`id`),
  FOREIGN KEY (`companyName`) REFERENCES `company` (`name`) ON DELETE SET NULL ON UPDATE CASCADE,
  FOREIGN KEY (`fk_companyname`) REFERENCES `company` (`newname`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre>

<h4>One-To-One associations</h4><pre>
一对一关联是由一个单一的外键实现两个模型之间的精确关联

【 Model.belongsTo() － 属于 】
Model.belongsTo(target, [options])
BelongsTo关联表示一对一关系的外键存在于源模型

[options.hooks=false] boolean
设置为 true 时,会在关联模型删除时执行 before-/afterDestroy 钩子方法

[options.as]  string
当前模型(源)的别名,单数形式。如果为一个表创建多次关联,或不想使用定义模型时使用的名称,那么就应该为模型指定一个别名。

[options.foreignKey]  string | object
目标表中的外键名或相当于定义外键列的对象 (语法参考 Sequelize.define )。使用对象时,应该添加一个name来设置列名。默认的外键命名规为源模型名+源模型主键名

[options.scope] object
键/值 集合,用于目标的创建和查找操作

[options.onDelete='SET NULL | NO ACTION'] string
如果外允许空则 SET NULL,其它则 CASCADE

[options.onUpdate='CASCADE']  string

[options.constraints=true]  boolean
是否在删除或更新时启用外键约束

</pre>Player是通过外键关联成为Team的一部分<pre class="js">
const Player = sequelize.define('player', {});
const Team = sequelize.define('team', {});
Player.belongsTo(Team);       // add a teamId attribute to Player to hold the primary key value for Team
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `team` (
  `id` INTEGER NOT NULL auto_increment , PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `player` (
  `id` INTEGER NOT NULL auto_increment ,
  `teamId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`teamId`) REFERENCES `team` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre><pre>
【 forign key 】
Sequelize中如果创建了两个模型之间的关联,那么相关联的外键会被自动创建

By default the foreign key for a belongsTo relation will be generated from the target model name and the target primary key name,默认命名使用驼峰式命名,而在源模型中添加underscored: true配置将使用下划线命名

</pre><pre class="js">
/* 实例1 */
const User = sequelize.define('User', {})
const Company = sequelize.define('Company', {});
User.belongsTo(Company);      // add companyId to user
sequelize.sync({force: true})

/* 实例2 */
const User = sequelize.define('User', {}, { underscored: true })
const Company = sequelize.define('Company', {
  uuid: {
    type: Sequelize.UUID,
    primaryKey: true
  }
});
User.belongsTo(Company);       // add companyUuid to user with field company_uuid
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `Company` (
  `uuid` CHAR(36) BINARY , PRIMARY KEY (`uuid`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `User` (
  `id` INTEGER NOT NULL auto_increment ,
  `company_uuid` CHAR(36) BINARY, PRIMARY KEY (`id`),
  FOREIGN KEY (`company_uuid`) REFERENCES `Company` (`uuid`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre>在定义中使用as命名时会将其做为目标模型的名称<pre class="js">
// In cases where as has been defined it will be used in place of the target model name.
const User = sequelize.define('user', {})
const UserRole = sequelize.define('userRole', {});
User.belongsTo(UserRole, {as: 'role'});   // Adds roleId to user rather than userRoleId
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `userRole` (
  `id` INTEGER NOT NULL auto_increment , PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment ,
  `roleId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`roleId`) REFERENCES `userRole` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre>使用foreignKey选项时外键名都会使用此选项值<pre class="js">
// In all cases the default foreign key can be overwritten with the foreignKey option. When the foreign key option is used, Sequelize will use it as-is:
const User = sequelize.define('user', {})
const Company = sequelize.define('company', {});
User.belongsTo(Company, {foreignKey: 'fk_company'});   // Adds fk_company to User
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `company` (
  `id` INTEGER NOT NULL auto_increment , PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment ,
  `fk_company` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`fk_company`) REFERENCES `company` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre><pre>
【 Target keys 】
目标键是位于目标模型上通过源模型外键列指向的列。默认情况下目标键是会belongsTo关系中目标模型的主键,可用targetKey选项来指定自定义列

</pre>建立关联关系时targetKey指定foreignKey引用关联表中的哪个字段,默认是primarykey<pre class="js">
const User = sequelize.define('user', {name: Sequelize.STRING})
const Company = sequelize.define('company', {
  name: {
    type: Sequelize.STRING,
    primaryKey: true,
    allowNull: false,
    unique: true,
  }
});
User.belongsTo(Company, {foreignKey: 'fk_companyname', targetKey: 'name'}); // Adds fk_companyname to User
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `company` (
  `name` VARCHAR(255) NOT NULL UNIQUE , PRIMARY KEY (`name`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `fk_companyname` VARCHAR(255), PRIMARY KEY (`id`),
  FOREIGN KEY (`fk_companyname`) REFERENCES `company` (`name`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre><pre>
【 Model.hasOne() － 拥有一个 】
Model.hasOne(targetModel, [options])
创建当前模型(源)到目标模型之间的关系,HasOne关联表示一对一关系的外键存在于目标模型

[options.hooks=false] boolean
设置为true时会在关联模型删除时执行before/afterDestroy钩子方法

[options.as]  string
当前模型(源)的别名,单数形式。如果为一个表创建多次关联或不想使用定义模型时使用的名称,那就应该为模型指定一个别名。

[options.foreignKey]  string | object
目标表中的外键名或相当于定义外键列的对象。使用对象时应该添加一个name来设置列名。默认的外键命名规为源模型名+源模型主键名

[options.onDelete='SET NULL | CASCADE'] string
如果外允许空则SET NULL,其它则CASCADE

[options.onUpdate='CASCADE']  string

[options.constraints=true]  boolean
是否在删除或更新时启用外键约束

</pre>Project.prototype中会根据传入的第一个定义参数即target model name获得方法getUser和setUser<pre class="js">
const User = sequelize.define('user', {name:Sequelize.STRING})
const Project = sequelize.define('project', {name:Sequelize.STRING})
// add an attribute projectId to the User model,外键会存在于user表中,若启用underscore:true设置,添加的属性会是project_id而不是projectId
Project.hasOne(User)
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `project` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), `projectId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`projectId`) REFERENCES `project` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

const project = await Project.create({name:"project1"})
const user = await User.create({name:"name1"})

await Project.findAll().then(re => console.log(JSON.stringify(re)))  // [{"id":1,"name":"project1"}]
await User.findAll().then(re => console.log(JSON.stringify(re)))     // [{"id":1,"name":"name1","projectId":null}]

await project.setUser(user).then(user => console.log(user.toJSON()))
await project.getUser().then(user => console.log(user.toJSON()))
/*
SELECT `id`, `name`, `projectId` FROM `user` AS `user` WHERE `user`.`projectId` = 1 LIMIT 1;
UPDATE `user` SET `projectId`=? WHERE `id` = ?
{ id: 1, name: 'name1', projectId: 1 }
SELECT `id`, `name`, `projectId` FROM `user` AS `user` WHERE `user`.`projectId` = 1 LIMIT 1;
{ id: 1, name: 'name1', projectId: 1 }
*/

// 报错：SequelizeEagerLoadingError: project is not associated to user!
// await User.findAll({ include: { model: Project } }).then(re => console.log(JSON.stringify(re)))

await Project.findAll({ include: { model: User } }).then(re => console.log(JSON.stringify(re)))
/*
SELECT `project`.`id`, `project`.`name`, `user`.`id` AS `user.id`, `user`.`name` AS `user.name`, `user`.`projectId` AS `user.projectId` FROM `project` AS `project` LEFT OUTER JOIN `user` AS `user` ON `project`.`id` = `user`.`projectId`;
[{"id":1,"name":"project1","user":{"id":1,"name":"name1","projectId":1}}]
*/

step(1)
// required: true将默认的LEFT OUTER JOIN转为INNER JOIN
await Project.findAll({ include: { model: User, required: true } }).then(re => console.log(JSON.stringify(re)))
/*
SELECT `project`.`id`, `project`.`name`, `user`.`id` AS `user.id`, `user`.`name` AS `user.name`, `user`.`projectId` AS `user.projectId` FROM `project` AS `project` INNER JOIN `user` AS `user` ON `project`.`id` = `user`.`projectId`;
[{"id":1,"name":"project1","user":{"id":1,"name":"name1","projectId":1}}]
*/

</pre>因为Sequelize会使用模型名来获得访问器方法,也可以给hasOne传递特定的option,设置{as:'Initiator'}后数据库中的外键名变成别名+target key,访问器设置器名称变成get/set+别名,原来的get/set+模型名不再可用<pre class="js">
const User = sequelize.define('user', {name:Sequelize.STRING})
const Project = sequelize.define('project', {name:Sequelize.STRING})
// add an attribute projectId to the User model,外键会存在于user表中,若启用underscore:true设置,添加的属性会是project_id而不是projectId
Project.hasOne(User, { as: 'Initiator' })
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `project` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `InitiatorId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`InitiatorId`) REFERENCES `project` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

const project = await Project.create({name:"project1"})
const user = await User.create({name:"name1"})

await Project.findAll().then(re => console.log(JSON.stringify(re)))   // [{"id":1,"name":"project1"}]
await User.findAll().then(re => console.log(JSON.stringify(re)))      // [{"id":1,"name":"name1","InitiatorId":null}]

// await project.setUser(user).then(user => console.log(user.toJSON()))  // TypeError: project.setUser is not a function
// await project.getUser().then(user => console.log(user.toJSON()))         // TypeError: project.getUser is not a function

await project.setInitiator(user).then(user => console.log(user.toJSON()))
await project.getInitiator().then(user => console.log(user.toJSON()))
/*
SELECT `id`, `name`, `InitiatorId` FROM `user` AS `user` WHERE `user`.`InitiatorId` = 1 LIMIT 1;
UPDATE `user` SET `InitiatorId`=? WHERE `id` = ?
{ id: 1, name: 'name1', InitiatorId: 1 }
SELECT `id`, `name`, `InitiatorId` FROM `user` AS `user` WHERE `user`.`InitiatorId` = 1 LIMIT 1;
{ id: 1, name: 'name1', InitiatorId: 1 }
*/

</pre>define the foreign key<pre class="js">
const User = sequelize.define('user', {name:Sequelize.STRING})
const Project = sequelize.define('project', {name:Sequelize.STRING})
// add an attribute projectId to the User model,外键会存在于user表中,若启用underscore:true设置,添加的属性会是project_id而不是projectId
Project.hasOne(User, { foreignKey: 'initiator_id' })
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `project` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `initiator_id` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`initiator_id`) REFERENCES `project` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

const project = await Project.create({name:"project1"})
const user = await User.create({name:"name1"})

await Project.findAll().then(re => console.log(JSON.stringify(re)))   // [{"id":1,"name":"project1"}]
await User.findAll().then(re => console.log(JSON.stringify(re)))      // [{"id":1,"name":"name1","initiator_id":null}]

await project.setUser(user).then(user => console.log(user.toJSON()))
await project.getUser().then(user => console.log(user.toJSON()))
/*
SELECT `id`, `name`, `initiator_id` FROM `user` AS `user` WHERE `user`.`initiator_id` = 1 LIMIT 1;
UPDATE `user` SET `initiator_id`=? WHERE `id` = ?
{ id: 1, name: 'name1', initiator_id: 1 }
SELECT `id`, `name`, `initiator_id` FROM `user` AS `user` WHERE `user`.`initiator_id` = 1 LIMIT 1;
{ id: 1, name: 'name1', initiator_id: 1 }
*/

</pre>同时定义as和foreignKey,数据库中外键名由foreignKey指定,get/set方法由as指定<pre class="js">
const User = sequelize.define('user', {name:Sequelize.STRING})
const Project = sequelize.define('project', {name:Sequelize.STRING})
// add an attribute projectId to the User model,外键会存在于user表中,若启用underscore:true设置,添加的属性会是project_id而不是projectId
Project.hasOne(User, { as: 'asname', foreignKey: 'foreignname' })
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `project` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `foreignname` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`foreignname`) REFERENCES `project` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

const project = await Project.create({name:"project1"})
const user = await User.create({name:"name1"})

await Project.findAll().then(re => console.log(JSON.stringify(re)))   // [{"id":1,"name":"project1"}]
await User.findAll().then(re => console.log(JSON.stringify(re)))      // [{"id":1,"name":"name1","foreignname":null}]

await project.setAsname(user).then(user => console.log(user.toJSON()))
await project.getAsname().then(user => console.log(user.toJSON()))
/*
SELECT `id`, `name`, `foreignname` FROM `user` AS `user` WHERE `user`.`foreignname` = 1 LIMIT 1;
UPDATE `user` SET `foreignname`=? WHERE `id` = ?
{ id: 1, name: 'name1', foreignname: 1 }
SELECT `id`, `name`, `foreignname` FROM `user` AS `user` WHERE `user`.`foreignname` = 1 LIMIT 1;
{ id: 1, name: 'name1', foreignname: 1 }
*/

</pre>如果想对一个表做两次连接查询: you can double join the same table<pre class="js">
Team.hasOne(Game, {as: 'HomeTeam', foreignKey : 'homeTeamId'});
Team.hasOne(Game, {as: 'AwayTeam', foreignKey : 'awayTeamId'});
Game.belongsTo(Team);

</pre>define some self references<pre class="js">
const Person = sequelize.define('person', { name: Sequelize.STRING})
Person.hasOne(Person, {as: 'Father'})    // add the attribute FatherId to Person
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `person` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `FatherId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`FatherId`) REFERENCES `person` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;

await Person.bulkCreate([
  {name: "yeye"},
  {name: "baba", FatherId: 1},
  {name: "wo", FatherId: 2},
  {name: "erzi", FatherId: 3},
  {name: "sunzi", FatherId: 4},
])
*/

Person.findOne({where: {name: "wo"}, include: [{ all: true }]}).then(person => console.log(person.get({plain: true})))
/*
SELECT `person`.`id`, `person`.`name`, `person`.`FatherId`, `Father`.`id` AS `Father.id`, `Father`.`name` AS `Father.name`, `Father`.`FatherId` AS `Father.FatherId` FROM `person` AS `person` LEFT OUTER JOIN `person` AS `Father` ON `person`.`id` = `Father`.`FatherId` WHERE `person`.`name` = 'wo' LIMIT 1;
{ id: 3,
  name: 'wo',
  FatherId: 2,
  Father: { id: 4, name: 'erzi', FatherId: 3 } }
*/

// also possible:
const Person = sequelize.define('person', {})
Person.hasOne(Person, {as: 'Father', foreignKey: 'DadId'})  // add the attribute DadId to Person
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `person` (
  `id` INTEGER NOT NULL auto_increment ,
  `FatherId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`DadId`) REFERENCES `person` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

// 这两种情况下都会有以下两个方法：
Person.setFather
Person.getFather

</pre><pre>
【 Source key 】
The source key is the attribute on the source model that the foreign key attribute on the target model points to. By default the source key for a hasOne relation will be the source model's primary attribute. To use a custom attribute, use the sourceKey option.

</pre>建立关联关系时sourceKey指定foreignKey引用关联表中的哪个字段,默认是primarykey<pre class="js">
const User = sequelize.define('user', {name: Sequelize.STRING})
const Company = sequelize.define('company', {
  name: {
    type: Sequelize.STRING,
    primaryKey: true,
    unique: true,
    allowNull: false,
  }
});
// Adds companyName attribute to User, Use name attribute from Company as source attribute
Company.hasOne(User, {foreignKey: 'companyName', sourceKey: 'name'});
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `company` (
  `name` VARCHAR(255) NOT NULL UNIQUE , PRIMARY KEY (`name`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255),
  `companyName` VARCHAR(255), PRIMARY KEY (`id`),
  FOREIGN KEY (`companyName`) REFERENCES `company` (`name`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre><pre>
【 Difference between HasOne and BelongsTo 】
大多数1:1关系中可以使用HasOne and BelongsTo,但通常会使用BelongsTo关联
HasOne inserts the association key in target model
BelongsTo inserts the association key in the source model

</pre><pre class="js">
const Player = sequelize.define('player', {});
const Team = sequelize.define('team', {});

// 将Player做为源模型,而将Team做为目标模型
Player.belongsTo(Team);
//Or
Player.hasOne(Team);

// 或Team 做为源模型,而将Player做为目标模型
Team.belongsTo(Player);
//Or
Team.hasOne(Player);

</pre><pre class="js">
const Player = sequelize.define('player', {});
const Coach = sequelize.define('coach', {});
const Team = sequelize.define('team', {});

// Player model has information about its team as teamId column. Information about each Team's Coach is stored in the Team model as coachId column
// Player模型通过teamId列与其团队建立联系,每个团队的教练Coach信息通过coachId列存储。在这些1:1场景中需要以不同的方式建立关系,因为模型外键的存储位置不同。

// 当关联信息是存在于当前源模型时可以使用belongsTo, 此时Player适合使用belongsTo,因为它有teamId列
Player.belongsTo(Team)  // `teamId` will be added on Player / Source model

// 当信息关联是存在于target模型时可以使用hasOne, 此时Coach适合使用hasOne,因为Team model模型中存储了它的Coach信息的coachId字段
Coach.hasOne(Team)     // `coachId` will be added on Team / Target model

</pre>

<h4>One-To-Many associations (hasMany) 一对多关联</h4><pre>
One-To-Many关联是指一个source模型连接多个target模型,而目标模型都会有一个明确的源

【 Model.hasMany() － 拥有多个 】
Model.hasMany(target, [options])
创建当前模型(源)到目标模型之间的 1:m 的关系,外键会被添加到目标模型中

[options.hooks=false] boolean
设置为 true 时,会在关联模型删除时执行 before-/afterDestroy 钩子方法

[options.as]  string
当前模型(源)的别名,单数形式。如果你为一个表创建多次关联,或者不想使用定义模型时使用的名称,那么就应该为模型指定一个别名。

[options.foreignKey]  string | object
目标表中的外键名或相当于定义外键列的对象。使用对象时应该添加一个name来设置列名。默认的外键命名规为源模型名+源模型主键名

[options.targetKey] string
用于关联目标表的字段名。默认为目标表的主键。

[options.onDelete='SET NULL | NO ACTION'] string
如果外允许空则 SET NULL,其它则 CASCADE

[options.onUpdate='CASCADE']  string

[options.constraints=true]  boolean
是否在删除或更新时启用外键约束

</pre>Project实例会有方法getWorkers和setWorkers。这是一种单向关联方式,如果两个模型间还有其它关联方式请参考多对多关系<pre class="js">
const User = sequelize.define('user', {})
const Project = sequelize.define('project', {})
Project.hasMany(User, {as: 'Workers'})     // add the attribute projectId to User
sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `project` (
  `id` INTEGER NOT NULL auto_increment , PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment ,
  `projectId` INTEGER, PRIMARY KEY (`id`),
  FOREIGN KEY (`projectId`) REFERENCES `project` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

</pre>use sourceKey option<pre class="js">
const City = sequelize.define('city', { countryCode: Sequelize.STRING },{timestamps:false,freezeTableName:true});
const Country = sequelize.define('country', { isoCode: Sequelize.STRING },{timestamps:false,freezeTableName:true});
Country.hasMany(City, {foreignKey: 'countryCode', sourceKey: 'isoCode'});
City.belongsTo(Country, {foreignKey: 'countryCode', targetKey: 'isoCode'});
sequelize.sync({force: true})

</pre>

<h4>Belongs-To-Many associations belongsToMany 多对多关联</h4><pre>
Belongs-To-Many关联是指一个source模型连接多个target模型,target模型也可以有多个相关的source

【 Model.belongsToMany() － 多对多 】
Model.belongsToMany(target, [options])
创建连接表的N:M的关系

[options.hooks=false] boolean
设置为true时会在关联模型删除时执行before-/afterDestroy钩子方法

[options.through] Model | string | object
在N:M的关联中用于连接源和目标表的名称

[options.through.model] Model
用于连接N:M关系的模型

[options.through.scope] object
用于建立关联的键/值集合,并通过模型查找默认值。

[options.through.unique=true] boolean
设置为true时唯一键会从使用的外键中生成

[options.as]  string
当前模型(源)的别名,单数形式。如果你为一个表创建多次关联,或者不想使用定义模型时使用的名称,那么就应该为模型指定一个别名。

[options.foreignKey]  string | object
目标表中的外键名或相当于定义外键列的对象。使用对象时应该添加一个name来设置列名。默认的外键命名规为源模型名+源模型主键名

[options.otherKey]  string | object
连接表的外键名称(表示目标模型)或表示其它列的类型定义。使用对象时可以添加一个name属性以设置目标列,默认为目标模型名称 + 目标主键的名称

[options.onDelete='SET NULL | NO ACTION'] string
如果外允许空则SET NULL,其它则CASCADE

[options.onUpdate='CASCADE']  string

[options.constraints=true]  boolean
是否在删除或更新时启用外键约束

【 usage 】
This will create a new model called userrole with the equivalent foreign keys userId and roleId.
Whether the attributes are camelcase or not depends on the two models joined by the table

定义through选项后Sequelize会尝试自动生成名字,但并一定符合逻辑。

以下实例中会添加方法getUsers、setUsers、addUser、addUsers to Role;getRoles, setRoles, addRole, and addRoles to User

</pre><pre class="js">
const User = sequelize.define('user', { username: Sequelize.STRING });
const Role = sequelize.define('role', { roleName: Sequelize.STRING });
User.belongsToMany(Role, {through: 'userrole'});
Role.belongsToMany(User, {through: 'userrole'});
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `username` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `role` (
  `id` INTEGER NOT NULL auto_increment , `roleName` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `userrole` (
  `userId` INTEGER , `roleId` INTEGER , PRIMARY KEY (`userId`, `roleId`),
  FOREIGN KEY (`userId`) REFERENCES `user` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  FOREIGN KEY (`roleId`) REFERENCES `role` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

let user1 = await User.create({username: 'username1'})
let user2 = await User.create({username: 'username2'})
let user3 = await User.create({username: 'username3'})
let user4 = await User.create({username: 'username4'})
let role1 = await Role.create({roleName: 'roleName1'})
let role2 = await Role.create({roleName: 'roleName2'})
let role3 = await Role.create({roleName: 'roleName3'})
let role4 = await Role.create({roleName: 'roleName4'})

step(1)
await User.findAll().then(res => console.log(JSON.stringify(res)))
await Role.findAll().then(res => console.log(JSON.stringify(res)))
/*
SELECT `id`, `username` FROM `user` AS `user`;
[{"id":1,"username":"username1"},{"id":2,"username":"username2"},{"id":3,"username":"username3"},{"id":4,"username":"username4"}]
SELECT `id`, `roleName` FROM `role` AS `role`;
[{"id":1,"roleName":"roleName1"},{"id":2,"roleName":"roleName2"},{"id":3,"roleName":"roleName3"},{"id":4,"roleName":"roleName4"}]
*/

step(2)
await user1.setRoles([role1, role2])
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`userId` = 1;
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (1,1),(1,2);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"userId":1,"roleId":1}},{"id":2,"roleName":"roleName2","userrole":{"userId":1,"roleId":2}}]
*/

step(3)
await user1.addRole(role3)
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`userId` = 1 AND `userrole`.`roleId` IN (3);
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (1,3);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"userId":1,"roleId":1}},{"id":2,"roleName":"roleName2","userrole":{"userId":1,"roleId":2}},{"id":3,"roleName":"roleName3","userrole":{"userId":1,"roleId":3}}]
*/

step(4)
await user1.addRoles([role4])
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`userId` = 1 AND `userrole`.`roleId` IN (4);
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (1,4);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"userId":1,"roleId":1}},{"id":2,"roleName":"roleName2","userrole":{"userId":1,"roleId":2}},{"id":3,"roleName":"roleName3","userrole":{"userId":1,"roleId":3}},{"id":4,"roleName":"roleName4","userrole":{"userId":1,"roleId":4}}]
*/

step(5)
await role1.getUsers().then(res => console.log(JSON.stringify(res)))
/*
SELECT `user`.`id`, `user`.`username`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `user` AS `user` INNER JOIN `userrole` AS `userrole` ON `user`.`id` = `userrole`.`userId` AND `userrole`.`roleId` = 1;
[{"id":1,"username":"username1","userrole":{"userId":1,"roleId":1}}]
*/

step(6)
await role1.setUsers([user2])
await role1.getUsers().then(res => console.log(JSON.stringify(res)))
/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`roleId` = 1;
DELETE FROM `userrole` WHERE `roleId` = 1 AND `userId` IN (1)
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (2,1);
SELECT `user`.`id`, `user`.`username`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `user` AS `user` INNER JOIN `userrole` AS `userrole` ON `user`.`id` = `userrole`.`userId` AND `userrole`.`roleId` = 1;
[{"id":2,"username":"username2","userrole":{"userId":2,"roleId":1}}]
*/

step(7)
await role1.addUsers([user3])
await role1.getUsers().then(res => console.log(JSON.stringify(res)))
/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`roleId` = 1 AND `userrole`.`userId` IN (3);
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (3,1);
SELECT `user`.`id`, `user`.`username`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `user` AS `user` INNER JOIN `userrole` AS `userrole` ON `user`.`id` = `userrole`.`userId` AND `userrole`.`roleId` = 1;
[{"id":2,"username":"username2","userrole":{"userId":2,"roleId":1}},{"id":3,"username":"username3","userrole":{"userId":3,"roleId":1}}]
*/

step(8)
await role1.addUser(user4)
await role1.getUsers().then(res => console.log(JSON.stringify(res)))
/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`roleId` = 1 AND `userrole`.`userId` IN (4);
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (4,1);
SELECT `user`.`id`, `user`.`username`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `user` AS `user` INNER JOIN `userrole` AS `userrole` ON `user`.`id` = `userrole`.`userId` AND `userrole`.`roleId` = 1;
[{"id":2,"username":"username2","userrole":{"userId":2,"roleId":1}},{"id":3,"username":"username3","userrole":{"userId":3,"roleId":1}},{"id":4,"username":"username4","userrole":{"userId":4,"roleId":1}}]
*/

step(9)
await role1.setUsers([])
await role1.getUsers().then(res => console.log(JSON.stringify(res)))
/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`roleId` = 1;
DELETE FROM `userrole` WHERE `roleId` = 1 AND `userId` IN (2, 3, 4)
SELECT `user`.`id`, `user`.`username`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `user` AS `user` INNER JOIN `userrole` AS `userrole` ON `user`.`id` = `userrole`.`userId` AND `userrole`.`roleId` = 1;
[]
*/

</pre><pre>
有时会对连接的模型进行重命名：define users as workers and projects as tasks by using the alias (as) option,We will also manually define the foreign keys to use

foreignKey让你可以在through关系中设置源模型key,而otherKey让你可以through关系中设置目标模型key
User.belongsToMany(Role, {as: 'Player', through: 'userrole', foreignKey: 'playerId', otherKey: 'roleId'})

Belongs-To-Many creates a unique key when primary key is not present on through model. This unique key name can be overridden using uniqueKey option.
User.belongsToMany(Role, { through: userrole, uniqueKey: 'my_custom_unique' })

// define self references with belongsToMany
// This will create the table PersonChildren which stores the ids of the objects
Person.belongsToMany(Person, { as: 'Children', through: 'PersonChildren' })

</pre><pre class="js">
const User = sequelize.define('user', { username: Sequelize.STRING });
const Role = sequelize.define('role', { roleName: Sequelize.STRING });
User.belongsToMany(Role, {as: 'Player', through: 'userrole', foreignKey: 'playerId'});
Role.belongsToMany(User, {as: 'Worker', through: 'userrole', foreignKey: 'wokerId'});
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `username` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `role` (
  `id` INTEGER NOT NULL auto_increment , `roleName` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `userrole` (
  `playerId` INTEGER , `wokerId` INTEGER , PRIMARY KEY (`playerId`, `wokerId`),
  FOREIGN KEY (`playerId`) REFERENCES `user` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  FOREIGN KEY (`wokerId`) REFERENCES `role` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

let user1 = await User.create({username: 'username1'})
let user2 = await User.create({username: 'username2'})
let user3 = await User.create({username: 'username3'})
let user4 = await User.create({username: 'username4'})
let role1 = await Role.create({roleName: 'roleName1'})
let role2 = await Role.create({roleName: 'roleName2'})
let role3 = await Role.create({roleName: 'roleName3'})
let role4 = await Role.create({roleName: 'roleName4'})

step(1)
await User.findAll().then(res => console.log(JSON.stringify(res)))
await Role.findAll().then(res => console.log(JSON.stringify(res)))
/*
[{"id":1,"username":"username1"},{"id":2,"username":"username2"},{"id":3,"username":"username3"},{"id":4,"username":"username4"}]
[{"id":1,"roleName":"roleName1"},{"id":2,"roleName":"roleName2"},{"id":3,"roleName":"roleName3"},{"id":4,"roleName":"roleName4"}]
*/

step(2)
await user1.setPlayer([role1, role2])
await user1.getPlayer().then(res => console.log(JSON.stringify(res)))
/*
SELECT `playerId`, `wokerId` FROM `userrole` AS `userrole` WHERE `userrole`.`playerId` = 1;
INSERT INTO `userrole` (`playerId`,`wokerId`) VALUES (1,1),(1,2);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`playerId` AS `userrole.playerId`, `userrole`.`wokerId` AS `userrole.wokerId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`wokerId` AND `userrole`.`playerId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"playerId":1,"wokerId":1}},{"id":2,"roleName":"roleName2","userrole":{"playerId":1,"wokerId":2}}]
*/

step(3)
await user1.addPlayer(role3)
await user1.getPlayer().then(res => console.log(JSON.stringify(res)))
/*
SELECT `playerId`, `wokerId` FROM `userrole` AS `userrole` WHERE `userrole`.`playerId` = 1 AND `userrole`.`wokerId` IN (3);
INSERT INTO `userrole` (`playerId`,`wokerId`) VALUES (1,3);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`playerId` AS `userrole.playerId`, `userrole`.`wokerId` AS `userrole.wokerId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`wokerId` AND `userrole`.`playerId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"playerId":1,"wokerId":1}},{"id":2,"roleName":"roleName2","userrole":{"playerId":1,"wokerId":2}},{"id":3,"roleName":"roleName3","userrole":{"playerId":1,"wokerId":3}}]
*/

step(4)
await user1.addPlayer([role4])
await user1.getPlayer().then(res => console.log(JSON.stringify(res)))
/*
SELECT `playerId`, `wokerId` FROM `userrole` AS `userrole` WHERE `userrole`.`playerId` = 1 AND `userrole`.`wokerId` IN (4);
INSERT INTO `userrole` (`playerId`,`wokerId`) VALUES (1,4);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`playerId` AS `userrole.playerId`, `userrole`.`wokerId` AS `userrole.wokerId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`wokerId` AND `userrole`.`playerId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"playerId":1,"wokerId":1}},{"id":2,"roleName":"roleName2","userrole":{"playerId":1,"wokerId":2}},{"id":3,"roleName":"roleName3","userrole":{"playerId":1,"wokerId":3}},{"id":4,"roleName":"roleName4","userrole":{"playerId":1,"wokerId":4}}]
*/

step(5)
await role1.getWorker().then(res => console.log(JSON.stringify(res)))
/*
SELECT `user`.`id`, `user`.`username`, `userrole`.`playerId` AS `userrole.playerId`, `userrole`.`wokerId` AS `userrole.wokerId` FROM `user` AS `user` INNER JOIN `userrole` AS `userrole` ON `user`.`id` = `userrole`.`playerId` AND `userrole`.`wokerId` = 1;
[{"id":1,"username":"username1","userrole":{"playerId":1,"wokerId":1}}]
*/

step(6)
await role1.setWorker([user2])
await role1.getWorker().then(res => console.log(JSON.stringify(res)))
/*
SELECT `playerId`, `wokerId` FROM `userrole` AS `userrole` WHERE `userrole`.`wokerId` = 1;
DELETE FROM `userrole` WHERE `wokerId` = 1 AND `playerId` IN (1)
INSERT INTO `userrole` (`playerId`,`wokerId`) VALUES (2,1);
SELECT `user`.`id`, `user`.`username`, `userrole`.`playerId` AS `userrole.playerId`, `userrole`.`wokerId` AS `userrole.wokerId` FROM `user` AS `user` INNER JOIN `userrole` AS `userrole` ON `user`.`id` = `userrole`.`playerId` AND `userrole`.`wokerId` = 1;
[{"id":2,"username":"username2","userrole":{"playerId":2,"wokerId":1}}]
*/

</pre>【 Check associations (N:M only) 关系检查 】<pre class="js">
const User = sequelize.define('user', { username: Sequelize.STRING });
const Role = sequelize.define('role', { roleName: Sequelize.STRING });
User.belongsToMany(Role, {through: 'userrole'});
Role.belongsToMany(User, {through: 'userrole'});
await sequelize.sync({force: true})

let user1 = await User.create({username: 'username1'})
let role1 = await Role.create({roleName: 'roleName1'})
let role2 = await Role.create({roleName: 'roleName2'})
let role3 = await Role.create({roleName: 'roleName3'})

await user1.setRoles([role1, role2])
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
// check if all associated objects 是否符合预期: have already a project and two users
await user1.hasRoles([role1]).then(result => console.log(result))         // result would be true
await user1.hasRoles([role1, role2]).then(result => console.log(result))  // result would be true

/*
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`userId` = 1;
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (1,1),(1,2);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"userId":1,"roleId":1}},{"id":2,"roleName":"roleName2","userrole":{"userId":1,"roleId":2}}]
SELECT `role`.`id` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1 WHERE (((`role`.`id` = 1)));
true
SELECT `role`.`id` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1 WHERE (((`role`.`id` = 1 OR `role`.`id` = 2)));
true
*/

// 检查一对象是否已与另一个对象建立关联,check if an object is one of associated ones
await user1.hasRole(role3).then(result => console.log(result))
await user1.addRole(role3)
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
await user1.hasRole(role3).then(result => console.log(result))
/*
SELECT `role`.`id` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1 WHERE (((`role`.`id` = 3)));
false
SELECT `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`userId` = 1 AND `userrole`.`roleId` IN (3);
INSERT INTO `userrole` (`userId`,`roleId`) VALUES (1,3);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"userId":1,"roleId":1}},{"id":2,"roleName":"roleName2","userrole":{"userId":1,"roleId":2}},{"id":3,"roleName":"roleName3","userrole":{"userId":1,"roleId":3}}]
SELECT `role`.`id` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1 WHERE (((`role`.`id` = 3)));
true
*/

</pre><pre>
【 为中间表添加更多属性 】
建立关联前为中间表定义一个模型告诉sequelize使用这个表建立关联而不是创建新表

</pre><pre class="js">
const User = sequelize.define('user', { username: Sequelize.STRING });
const Role = sequelize.define('role', { roleName: Sequelize.STRING });
const Userrole = sequelize.define('userrole', { status: Sequelize.STRING });
User.belongsToMany(Role, {through: 'userrole'});
Role.belongsToMany(User, {through: 'userrole'});
await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `user` (
  `id` INTEGER NOT NULL auto_increment , `username` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `role` (
  `id` INTEGER NOT NULL auto_increment , `roleName` VARCHAR(255), PRIMARY KEY (`id`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `userrole` (
  `status` VARCHAR(255), `userId` INTEGER , `roleId` INTEGER , PRIMARY KEY (`userId`, `roleId`),
  FOREIGN KEY (`userId`) REFERENCES `user` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  FOREIGN KEY (`roleId`) REFERENCES `role` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

let user1 = await User.create({username: 'username1'})
let role1 = await Role.create({roleName: 'roleName1'})
let role2 = await Role.create({roleName: 'roleName2'})

step(1)
await user1.setRoles([role2], { through: { status: 'started' }})
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
/*
SELECT `status`, `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`userId` = 1;
INSERT INTO `userrole` (`status`,`userId`,`roleId`) VALUES ('started',1,2);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`status` AS `userrole.status`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
[{"id":2,"roleName":"roleName2","userrole":{"status":"started","userId":1,"roleId":2}}]
*/

// 使用自定义属性连接表时这些属性将做为一个对象的名称
await user1.getRoles().then(roles => {
  var role1 = roles[0]
  console.log(role1.userrole.status)
})
/*
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`status` AS `userrole.status`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
started
*/

step(2)
// 要为user1添加一个新的role并设置状态,可以传递额外的options.through给setter,其中status属性会包含在连接表中
await user1.addRole(role1, { through: { status: 'started' }})
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
/*
SELECT `status`, `userId`, `roleId` FROM `userrole` AS `userrole` WHERE `userrole`.`userId` = 1 AND `userrole`.`roleId` IN (1);
INSERT INTO `userrole` (`status`,`userId`,`roleId`) VALUES ('started',1,1);
SELECT `role`.`id`, `role`.`roleName`, `userrole`.`status` AS `userrole.status`, `userrole`.`userId` AS `userrole.userId`, `userrole`.`roleId` AS `userrole.roleId` FROM `role` AS `role` INNER JOIN `userrole` AS `userrole` ON `role`.`id` = `userrole`.`roleId` AND `userrole`.`userId` = 1;
[{"id":1,"roleName":"roleName1","userrole":{"status":"started","userId":1,"roleId":1}},{"id":2,"roleName":"roleName2","userrole":{"status":"started","userId":1,"roleId":2}}]
*/

</pre><pre>
【 为中间添加主键 】
默认sequelize会向中间表中添加两个由source/targe model加各表主键组成的驼峰命名的字段,并移除之前已定义的主键属性,中间表并由两个表的主键组建唯一标识,且没有额外的PK列。
要强制为中间添加主键可以手工添加

</pre><pre class="js">
const Userrole = sequelize.define('userrole', {
  id: {
    type: Sequelize.INTEGER,
    primaryKey: true,
    autoIncrement: true
  },
  status: Sequelize.STRING
});

</pre>Belongs-To-Many可以基于through关系查询并查询属性<pre class="js">
const User = sequelize.define('user', { username: Sequelize.STRING });
const Role = sequelize.define('role', { roleName: Sequelize.STRING });
const Userrole = sequelize.define('userrole', { status: Sequelize.STRING });
User.belongsToMany(Role, {through: 'userrole'});
Role.belongsToMany(User, {through: 'userrole'});
await sequelize.sync({force: true})

let user1 = await User.create({username: 'username1'})
let role1 = await Role.create({roleName: 'roleName1'})
let role2 = await Role.create({roleName: 'roleName2'})

step(1)
await user1.setRoles([role1, role2], { through: { status: 'started' }})
await user1.getRoles().then(res => console.log(JSON.stringify(res)))
/*
[
  {"id":1,"roleName":"roleName1","userrole":{"status":"started","userId":1,"roleId":1}},
  {"id":2,"roleName":"roleName2","userrole":{"status":"started","userId":1,"roleId":2}}
]
*/

step(2)
await User.findAll({
  include: [{
    model: Role,
    through: {
      attributes: ['id', 'roleName'],
      where: {status: 'started'}
    }
  }]
}).then(res => console.log(JSON.stringify(res)))
/*
SELECT
  `user`.`id`,
  `user`.`username`,
  `roles`.`id` AS `roles.id`,
  `roles`.`roleName` AS `roles.roleName`,
  `roles->userrole`.`status` AS `roles.userrole.status`,
  `roles->userrole`.`userId` AS `roles.userrole.userId`,
  `roles->userrole`.`roleId` AS `roles.userrole.roleId`
FROM
  `user` AS `user`
  LEFT OUTER JOIN
  ( `userrole` AS `roles->userrole` INNER JOIN `role` AS `roles` ON `roles`.`id` = `roles->userrole`.`roleId` AND `roles->userrole`.`status` = 'started')
  ON `user`.`id` = `roles->userrole`.`userId`;
[
  {
    "id":1,
    "username":"username1",
    "roles":[
      {"id":1,"roleName":"roleName1","userrole":{}},
      {"id":2,"roleName":"roleName2","userrole":{}}
    ]
  }
]
*/

await User.findAll({
  include: [{
    model: Role,
    through: {
      attributes: ['id', 'roleName', 'status'],
      where: {status: 'started'}
    }
  }]
}).then(res => console.log(JSON.stringify(res)))
/*
SELECT `user`.`id`, `user`.`username`, `roles`.`id` AS `roles.id`, `roles`.`roleName` AS `roles.roleName`, `roles->userrole`.`status` AS `roles.userrole.status`, `roles->userrole`.`userId` AS `roles.userrole.userId`, `roles->userrole`.`roleId` AS `roles.userrole.roleId`
FROM `user` AS `user` LEFT OUTER JOIN ( `userrole` AS `roles->userrole` INNER JOIN `role` AS `roles` ON `roles`.`id` = `roles->userrole`.`roleId` AND `roles->userrole`.`status` = 'started') ON `user`.`id` = `roles->userrole`.`userId`;
[
  {
    "id":1,
    "username":"username1",
    "roles":[
      {"id":1,"roleName":"roleName1","userrole":{"status":"started"}},
      {"id":2,"roleName":"roleName2","userrole":{"status":"started"}}
    ]
  }
]
*/

</pre>

<h4>通过关联创建实例</h4><pre>
An instance can be created with nested association in one step, provided all elements are new

</pre>BelongsTo / HasMany / HasOne association<pre class="js">
const Product = sequelize.define('product', {title: Sequelize.STRING});
const User = sequelize.define('user', { firstName: Sequelize.STRING, lastName: Sequelize.STRING });
const Address = sequelize.define('address', {
  type: Sequelize.STRING,
  line1: Sequelize.STRING,
  line2: Sequelize.STRING,
  city: Sequelize.STRING,
  state: Sequelize.STRING,
  zip: Sequelize.STRING,
});

Product.User = Product.belongsTo(User);    // return user object
User.Addresses = User.hasMany(Address);    // return addresses object, Also works for `hasOne`

await sequelize.sync({force: true})

// A new Product, User, and one or more Address can be created in one step in the following way:
await Product.create({
  title: 'Chair',
  user: {                          // modelName or alias
    firstName: 'Mick',
    lastName: 'Broadstone',
    addresses: [{
      type: 'home',
      line1: '100 Main St.',
      city: 'Austin',
      state: 'TX',
      zip: '78704'
    }]
  }
}, {
  include: [{
    association: Product.User,     // 设置为Product.belongsTo(User)的返回值
    include: [ User.Addresses ]    // 设置为User.hasMany(Address)的返回值
  }]
}).then(product => console.log(JSON.stringify(product)))
/*
INSERT INTO `user` (`id`,`firstName`,`lastName`) VALUES (DEFAULT,?,?);
INSERT INTO `address` (`id`,`type`,`line1`,`city`,`state`,`zip`,`userId`) VALUES (DEFAULT,?,?,?,?,?,?);
INSERT INTO `product` (`id`,`title`,`userId`) VALUES (DEFAULT,?,?);
{"id":1,"title":"Chair","user":{"id":1,"firstName":"Mick","lastName":"Broadstone","addresses":[{"id":1,"type":"home","line1":"100 Main St.","city":"Austin","state":"TX","zip":"78704","userId":1}]},"userId":1}
*/

await Product.findAll().then(products => console.log(JSON.stringify(products)))
await User.findAll().then(users => console.log(JSON.stringify(users)))
await Address.findAll().then(address => console.log(JSON.stringify(address)))
/*
[{"id":1,"title":"Chair","userId":1}]
[{"id":1,"firstName":"Mick","lastName":"Broadstone"}]
[{"id":1,"type":"home","line1":"100 Main St.","line2":null,"city":"Austin","state":"TX","zip":"78704","userId":1}]
*/

</pre>BelongsTo association with an alias,extended to support an association alias<pre class="js">
const Product = sequelize.define('product', { title: Sequelize.STRING });
const User = sequelize.define('user', { firstName: Sequelize.STRING, lastName: Sequelize.STRING });
const Creator = Product.belongsTo(User, { as: 'creator' });
await sequelize.sync({force: true})

// A new Product, User, and one or more Address can be created in one step in the following way:
await Product.create({
  title: 'Chair',
  creator: {                // modelName or alias
    firstName: 'Matt',
    lastName: 'Hansen'
  }
}, {
  include: [ Creator ]       // 设置为Product.belongsTo的返回值
}).then(product => console.log(JSON.stringify(product)))
/*
INSERT INTO `user` (`id`,`firstName`,`lastName`) VALUES (DEFAULT,?,?);
INSERT INTO `product` (`id`,`title`,`creatorId`) VALUES (DEFAULT,?,?);
{"id":1,"title":"Chair","creator":{"id":1,"firstName":"Matt","lastName":"Hansen"},"creatorId":1}
*/

await Product.findAll().then(products => console.log(JSON.stringify(products)))
await User.findAll().then(users => console.log(JSON.stringify(users)))
/*
[{"id":1,"title":"Chair","creatorId":1}]
[{"id":1,"firstName":"Matt","lastName":"Hansen"}]
*/

</pre>HasMany / BelongsToMany association<pre class="js">
const Product = sequelize.define('product', { title: Sequelize.STRING });
const Tag = sequelize.define('tag', {name: Sequelize.STRING});
Product.hasMany(Tag);      // Also works for `belongsToMany`.
await sequelize.sync({force: true})
await Product.create({
  id: 1,
  title: 'Chair',
  tags: [
    { name: 'Alpha'},
    { name: 'Beta'}
  ]
}, {
  include: [ Tag ]
}).then(product => console.log(JSON.stringify(product)))
/*
INSERT INTO `product` (`id`,`title`) VALUES (?,?);
INSERT INTO `tag` (`id`,`name`,`productId`) VALUES (DEFAULT,?,?);
INSERT INTO `tag` (`id`,`name`,`productId`) VALUES (DEFAULT,?,?);
{"id":1,"title":"Chair","tags":[{"id":1,"name":"Alpha","productId":1},{"id":2,"name":"Beta","productId":1}]}
*/
await Product.findAll().then(products => console.log(JSON.stringify(products)))
await Tag.findAll().then(tags => console.log(JSON.stringify(tags)))
/*
[{"id":1,"title":"Chair"}]
[{"id":1,"name":"Alpha","productId":1},{"id":2,"name":"Beta","productId":1}]
*/

</pre>support an alias<pre class="js">
const Product = sequelize.define('product', { title: Sequelize.STRING });
const Tag = sequelize.define('tag', {name: Sequelize.STRING});

const Categories = Product.hasMany(Tag, { as: 'categories' });
await sequelize.sync({force: true})
await Product.create({
  id: 1,
  title: 'Chair',
  categories: [
    { name: 'Alpha'},
    { name: 'Beta'}
  ]
}, {
  include: [{
    association: Categories,
    as: 'categories'
  }]
}).then(product => console.log(JSON.stringify(product)))
/*
INSERT INTO `product` (`id`,`title`) VALUES (?,?);
INSERT INTO `tag` (`id`,`name`,`productId`) VALUES (DEFAULT,?,?);
INSERT INTO `tag` (`id`,`name`,`productId`) VALUES (DEFAULT,?,?);
{"id":1,"title":"Chair","categories":[{"id":1,"name":"Alpha","productId":1},{"id":2,"name":"Beta","productId":1}]}
*/

await Product.findAll().then(products => console.log(JSON.stringify(products)))
await Tag.findAll().then(tags => console.log(JSON.stringify(tags)))
/*
[{"id":1,"title":"Chair"}]
[{"id":1,"name":"Alpha","productId":1},{"id":2,"name":"Beta","productId":1}]
*/

</pre>

<h4>Associating objects 关联对象</h4><pre class="js">
function step(order){
  console.log('\x1b[32m', '>>>>>> ' + order++, '\x1b[97m')
}

const Project = sequelize.define('project', { name: Sequelize.STRING });
const Task = sequelize.define('task', { name: Sequelize.STRING });
Project.hasMany(Task)
Task.belongsTo(Project)  // 注释之后操作task step 6开始失败：project is not associated to task
await sequelize.sync({force: true})

const project1 = await Project.create({ name: 'projectName1' })
const task1 = await Task.create({ name: 'taskName1' })
const task2 = await Task.create({ name: 'taskName2' })
/*
CREATE TABLE IF NOT EXISTS `project` (`id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), PRIMARY KEY (`id`)) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `task` (`id` INTEGER NOT NULL auto_increment , `name` VARCHAR(255), `projectId` INTEGER, PRIMARY KEY (`id`), FOREIGN KEY (`projectId`) REFERENCES `project` (`id`) ON DELETE SET NULL ON UPDATE CASCADE) ENGINE=InnoDB;
INSERT INTO `project` (`id`,`name`) VALUES (DEFAULT,?);
INSERT INTO `task` (`id`,`name`) VALUES (DEFAULT,?);
INSERT INTO `task` (`id`,`name`) VALUES (DEFAULT,?);
*/

step(1)
// save them
await project1.setTasks([task1, task2]).then(result => {
  console.log(JSON.stringify(result));
})
/*
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE `task`.`projectId` = 1;
UPDATE `task` SET `projectId`=? WHERE `id` IN (1, 2)
{"id":1,"name":"projectName1"}
*/

step(2)
// how to get them later on?
await project1.getTasks().then(associatedTasks => {
  console.log(JSON.stringify(associatedTasks));
})
/*
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE `task`.`projectId` = 1;
[{"id":1,"name":"taskName1","projectId":1},{"id":2,"name":"taskName2","projectId":1}]
*/

step(3)
// Error: Support for `{where: 'raw query'}` has been removed.
// pass filters to the getter method.
await project1.getTasks({
  where: { id : { [Sequelize.Op.gt]: 1 }}
}).then(tasks => console.log(JSON.stringify(tasks)))   // tasks with an id greater than 10
.catch(err => console.log(err))
/*
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE (`task`.`projectId` = 1 AND `task`.`id` > 1);
[{"id":2,"name":"taskName2","projectId":1}]
*/

step(4)
// only retrieve certain fields of a associated object.
await project1.getTasks({attributes: ['name']}).then(tasks => console.log(JSON.stringify(tasks)))   // retrieve tasks with the attributes "name" and "id"
.catch(err => console.log(err))
/*
SELECT `name` FROM `task` AS `task` WHERE `task`.`projectId` = 1;
[{"name":"taskName1"},{"name":"taskName2"}]
*/

step(5)
await Task.findAll().then(tasks => console.log(JSON.stringify(tasks)))
/*
SELECT `id`, `name`, `projectId` FROM `task` AS `task`;
[{"id":1,"name":"taskName1","projectId":1},{"id":2,"name":"taskName2","projectId":1}]
*/

step(6)
await Task.findAll({
  include: [ Project ],
  limit: 3
}).then(tasks => console.log(JSON.stringify(tasks)))
/*
SELECT `task`.`id`, `task`.`name`, `task`.`projectId`, `project`.`id` AS `project.id`, `project`.`name` AS `project.name` FROM `task` AS `task` LEFT OUTER JOIN `project` AS `project` ON `task`.`projectId` = `project`.`id` LIMIT 3;
[{"id":1,"name":"taskName1","projectId":1,"project":{"id":1,"name":"projectName1"}},{"id":2,"name":"taskName2","projectId":1,"project":{"id":1,"name":"projectName1"}}]
*/

step(7)
await Project.update({ id: 2 }, {
  where: { id: 1 }
}).then(res => console.log(JSON.stringify(res))).catch(err => console.log(err))
let task = await Task.findByPk(1)
console.log(JSON.stringify(task))
/*
UPDATE `project` SET `id`=? WHERE `id` = ?
[1]
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE `task`.`id` = 1;
{"id":1,"name":"taskName1","projectId":2}
*/

step(8)
await Project.destroy({
  where: { id: 2 }
}).then(res => console.log(JSON.stringify(res))).catch(err => console.log(err))
task = await Task.findByPk(1)
console.log(JSON.stringify(task))
/*
DELETE FROM `project` WHERE `id` = 2
1
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE `task`.`id` = 1;
{"id":1,"name":"taskName1","projectId":null}
*/

step(9)
const project2 = await Project.create({ name: 'projectName2' })
await project2.setTasks([task1, task2])
/*
INSERT INTO `project` (`id`,`name`) VALUES (DEFAULT,?);
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE `task`.`projectId` = 2;
UPDATE `task` SET `projectId`=? WHERE `id` IN (1, 2)
*/

/*** To remove created associations you can just call the set method without a specific id ***/
// remove the association with task1,将task2的projectId设置为Null
await project2.setTasks([task2]).then(project => {
  console.log(JSON.stringify(project));  // you will get task2 only
})
/*
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE `task`.`projectId` = 2;
UPDATE `task` SET `projectId`=? WHERE `id` IN (1)
{"id":2,"name":"projectName2"}
*/

step(10)
// or remove 'em more directly
await project2.removeTask(task2).then(() => {
  // it's gone
})

// remove 'em all
await project2.setTasks([]).then(associatedTasks => {
  // you will get an empty array
})
/*
UPDATE `task` SET `projectId`=? WHERE `projectId` = ? AND `id` IN (2)
SELECT `id`, `name`, `projectId` FROM `task` AS `task` WHERE `task`.`projectId` = 2;
*/

step(11)
// and add 'em again
await project2.addTask(task2).then(() => {
  // it's back again
})
// UPDATE `task` SET `projectId`=? WHERE `id` IN (2)

step(12)
// project is associated with task1 and task2
await task2.setProject(null).then(result => {
  console.log(JSON.stringify(result));  // and it's gone
})
/*
UPDATE `task` SET `projectId`=? WHERE `id` = ?
{"id":2,"name":"taskName2","projectId":null}
*/

</pre>

<h4>Eager loading 预加载 关联查询 include支持嵌套</h4><pre>
从数据库中加载数据时除数据本身外还想得到与之相关联的数据,这就是所谓的预加载,即使用find或findAll查询数据时通过include属性同时加载关联的数据

</pre><pre class="js">
// type如果不存在则直接用字符串表示如'TIMESTAMP';如果默认值不是具体的数值,可用Sequelize.literal函数表示
// tableName表名,u为别名。
const DataTypes = Sequelize.DataTypes;
const user = sequelize.define('u', {
  userId: { type: DataTypes.INTEGER, primaryKey: true, autoIncrement: true },
  userName: { type: DataTypes.STRING, allowNull: false },
  birthDay: { type: 'TIMESTAMP' },
  gender: { type: DataTypes.INTEGER, defaultValue: 0 },
  createAt: { type: 'TIMESTAMP', allowNull: false, defaultValue: Sequelize.literal('CURRENT_TIMESTAMP') },
  updateAt: { type: 'TIMESTAMP', defaultValue: Sequelize.literal('CURRENT_TIMESTAMP'), field: 'ctime' },
  deleteAt: { type: Sequelize.DATE, defaultValue: Sequelize.NOW }
}, { tableName: 'user' })

const products = sequelize.define('p', {
  prdId: { type: DataTypes.INTEGER, primaryKey: true, autoIncrement: true },
  prdName: { type: DataTypes.STRING, allowNull: false },
  userId: { type: DataTypes.INTEGER, allowNull: false },
  price: { type: DataTypes.DECIMAL(5, 4), allowNull: false }
})
products.belongsTo(user, { foreignKey: 'userId', targetKey: 'userId', as: 'u' });

await sequelize.sync({force: true})
/*
CREATE TABLE IF NOT EXISTS `user` (`userId` INTEGER auto_increment , `userName` VARCHAR(255) NOT NULL,
  `birthDay` TIMESTAMP, `gender` INTEGER DEFAULT 0, `createAt` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `ctime` TIMESTAMP DEFAULT CURRENT_TIMESTAMP, `deleteAt` DATETIME, PRIMARY KEY (`userId`)
) ENGINE=InnoDB;
CREATE TABLE IF NOT EXISTS `p` (
  `prdId` INTEGER auto_increment , `prdName` VARCHAR(255) NOT NULL,
  `userId` INTEGER NOT NULL, `price` DECIMAL(5,4) NOT NULL, PRIMARY KEY (`prdId`),
  FOREIGN KEY (`userId`) REFERENCES `user` (`userId`) ON DELETE NO ACTION ON UPDATE CASCADE
) ENGINE=InnoDB;
*/

await user.create({ userName: 'lisi' })
await products.bulkCreate([
  { prdName: 'p1', userId: 1, price: 5.20 },
  { prdName: 'p2', userId: 1, price: 2.5 }
])
/*
INSERT INTO `user` (`userId`,`userName`,`gender`,`createAt`,`ctime`,`deleteAt`) VALUES (DEFAULT,?,?,CURRENT_TIMESTAMP,CURRENT_TIMESTAMP,?);
INSERT INTO `p` (`prdId`,`prdName`,`userId`,`price`) VALUES (NULL,'p1',1,5.2),(NULL,'p2',1,2.5);
*/

await user.findAll().then(res => console.log(JSON.stringify(res)))
await products.findAll().then(res => console.log(JSON.stringify(res)))
/*
[{"userId":1,"userName":"lisi","birthDay":null,"gender":0,"createAt":"2019-06-29T10:06:23.000Z","updateAt":"2019-06-29T10:06:23.000Z","deleteAt":"2019-06-29T10:06:22.000Z"}]
[{"prdId":1,"prdName":"p1","userId":1,"price":"5.2000"},{"prdId":2,"prdName":"p2","userId":1,"price":"2.5000"}]
*/

// 方式一
await products.findAll({
  attributes: ['prdName', 'price'],
  include: [{
    model: user,
    // 不使用as: 'u'则会报错,SequelizeEagerLoadingError: u is associated to p using an alias. You must use the 'as' keyword to specify the alias within your include statement
    as: 'u',
    attributes: ['userName']
  }],
}).then(result => console.log(JSON.stringify(result))).catch(err => console.log(err));
/*
SELECT `p`.`prdId`, `p`.`prdName`, `p`.`price`, `u`.`userId` AS `u.userId`, `u`.`userName` AS `u.userName` FROM `p` AS `p` LEFT OUTER JOIN `user` AS `u` ON `p`.`userId` = `u`.`userId`;
[{"prdName":"p1","price":"5.2000","u":{"userName":"lisi"}},{"prdName":"p2","price":"2.5000","u":{"userName":"lisi"}}]
*/

// 方式二
await products.findAll({
  attributes: ['prdName', 'price'],
  include: [{
    model: user,
    as: 'u',
    attributes: ['userName']
  }],
  raw:true
}).then(result => console.log(JSON.stringify(result))).catch(err => console.log(err));
/*
SELECT `p`.`prdName`, `p`.`price`, `u`.`userName` AS `u.userName` FROM `p` AS `p` LEFT OUTER JOIN `user` AS `u` ON `p`.`userId` = `u`.`userId`;
[{"prdName":"p1","price":"5.2000","u.userName":"lisi"},{"prdName":"p2","price":"2.5000","u.userName":"lisi"}]
*/

// 方式三
await products.findAll({
  attributes: [Sequelize.col('u.userName'),'prdName', 'price'],
  include: [{
    model: user,
    as: 'u',
    attributes: []
  }],
  raw:true      // 不使用raw:true则结果中不含userName字段
}).then(result => console.log(JSON.stringify(result))).catch(err => console.log(err));
/*
SELECT `u`.`userName`, `p`.`prdName`, `p`.`price` FROM `p` AS `p` LEFT OUTER JOIN `user` AS `u` ON `p`.`userId` = `u`.`userId`;
[{"userName":"lisi","prdName":"p1","price":"5.2000"},{"userName":"lisi","prdName":"p2","price":"2.5000"}]
*/

// 加条件:LEFT OUTER JOIN
await products.findAll({
  attributes: [Sequelize.col('u.userName'), 'prdName', 'price'],
  include: [{
    model: user,
    as: 'u',
    attributes: []
  }],
  where: {
    prdName: 'p1',
    '$u.userId$': 1  // 如果给include表加where条件须使用'$u.userId$'这种写法;也可在include加where条件
  },
  raw: true
}).then(result =>console.log(JSON.stringify(result))).catch(err => console.log(err))
/*
SELECT `u`.`userName`, `p`.`prdName`, `p`.`price` FROM `p` AS `p` LEFT OUTER JOIN `user` AS `u` ON `p`.`userId` = `u`.`userId` WHERE `p`.`prdName` = 'p1' AND `u`.`userId` = 1;
[{"userName":"lisi","prdName":"p1","price":"5.2000"}]
*/

// 在include加where条件: INNER JOIN
await products.findAll({
  attributes: [Sequelize.col('u.userName'), 'prdName', 'price'],
  include: [{
    model: user,
    as: 'u',
    attributes: [],
    where: {userId: 1}
  }],
  where: { prdName: 'p1' },
  raw: true
}).then(result =>console.log(JSON.stringify(result))).catch(err => console.log(err))
/*
SELECT `u`.`userName`, `p`.`prdName`, `p`.`price` FROM `p` AS `p` INNER JOIN `user` AS `u` ON `p`.`userId` = `u`.`userId` AND `u`.`userId` = 1 WHERE `p`.`prdName` = 'p1';
[{"userName":"lisi","prdName":"p1","price":"5.2000"}]
*/

</pre><pre class="js">
var User = sequelize.define('user', { name: Sequelize.STRING })
var Task = sequelize.define('task', { name: Sequelize.STRING })
var Tool = sequelize.define('tool', { name: Sequelize.STRING })

Task.belongsTo(User)                      // 增加外键属性UserId到Task
User.hasMany(Task)                        // 给Task增加外键属性userId
User.hasMany(Tool, { as: 'Instruments' }) // 给Task增加自定义外键属性InstrumentsId

await sequelize.sync()

// 由于Task与User是1对多的关系,所在以查询task时user会做为一个对象属性被同时加载
await Task.findAll({ include: [ User ] }).then(tasks => console.log(JSON.stringify(tasks)))
/*
  [{
    "name": "A Task",
    "id": 1,
    "userId": 1,
    "user": { "name": "John Doe", "id": 1, }
  }]
*/

// 在多对多的关系中,相关数据会做为一个数组属性被同时加载
await User.findAll({ include: [ Task ] }).then(users => console.log(JSON.stringify(users)))
/*
  [{
    "name": "John Doe",
    "id": 1,
    "tasks": [{ "name": "A Task", "id": 1, "userId": 1 }]
  }]
*/

// 关联查询时可以使用as选项为关系数据指定别名：
await User.findAll({ include: [{ model: Tool, as: 'Instruments' }] }).then(users => console.log(JSON.stringify(users)))
/*
  [{
    "name": "John Doe",
    "id": 1,
    "Instruments": [{ "name": "Toothpick", "id": 1, "userId": 1 }]
  }]
*/

// Tool代表模型名,字符串代表数据库表名
User.findAll({ include: ['Instruments'] }).then(users => console.log(JSON.stringify(users)))
/*
  [{
    "name": "John Doe",
    "id": 1,
    "Instruments": [{ "name": "Toothpick", "id": 1, "userId": 1 }]
  }]
*/

// association代表关联的数据库表名
User.findAll({ include: [{ association: 'Instruments' }] }).then(users => console.log(JSON.stringify(users)))
/*
  [{
    "name": "John Doe",
    "id": 1,
    "Instruments": [{ "name": "Toothpick", "id": 1, "userId": 1 }]
  }]
*/

// 关联查询时同样可以使用where选项对关联数据进行筛选：
// 使用include.where条件时,include.requied会被隐式的设置为true,即在查询时会使用INNER JOIN内连接
await User.findAll({
  include: [{
    model: Tool,
    as: 'Instruments',
    where: { name: { $like: '%ooth%' } }
  }]
}).then(users => console.log(JSON.stringify(users)))
/*
  [{
    "name": "John Doe",
    "id": 1,
    "Instruments": [{ "name": "Toothpick", "id": 1, "userId": 1 }]
  }],

  [{
    "name": "John Smith",
    "id": 2,
    "Instruments": [{ "name": "Toothpick", "id": 1, "userId": 1 }]
  }],
*/

// Top level where with eagerly loaded models, you can use the '$nested.column$' syntax:
User.findAll({
  where: { '$Instruments.name$': { [Op.iLike]: '%ooth%' } },
  include: [{ model: Tool, as: 'Instruments' }]
}).then(users => console.log(JSON.stringify(users)))
/*
  [{
    "name": "John Doe",
    "id": 1,
    "Instruments": [{ "name": "Toothpick", "id": 1, "userId": 1 }]
  }],
  [{
    "name": "John Smith",
    "id": 2,
    "Instruments": [{ "name": "Toothpick", "id": 1, "userId": 1 }]
  }],
*/

// 全关联:如果多个模型间存在关联关系,而在查询时又要查询所有的数据就可以设置all: true来关联所有模型：
User.findAll({ include: [{ all: true }]});

// Include all also supports nested(嵌套) loading
User.findAll({ include: [{ all: true, nested: true }]});

// 包括软删除的数据:如果要在结果中包含软删除的数据,请将include.paranoid设置为true：
User.findAll({
  include: [{
    model: Tool,
    where: { name: { $like: '%ooth%' } },
    paranoid: true // 查询并加载软删除的数据
  }]
});

</pre>Ordering Eager Loaded Associations<pre class="js">
// 在1对多(one-to-many)的关系中
Company.findAll({ include: [ Division ], order: [ [ Division, 'name' ] ] });
Company.findAll({ include: [ Division ], order: [ [ Division, 'name', 'DESC' ] ] });
Company.findAll({
  include: [ { model: Division, as: 'Div' } ],
  order: [ [ { model: Division, as: 'Div' }, 'name' ] ]
});
Company.findAll({
  include: [ { model: Division, as: 'Div' } ],
  order: [ [ { model: Division, as: 'Div' }, 'name', 'DESC' ] ]
});
Company.findAll({
  include: [ { model: Division, include: [ Department ] } ],
  order: [ [ Division, Department, 'name' ] ]
});

// In the case of many-to-many joins, you are also able to sort by attributes in the through table.
Company.findAll({
  include: [ { model: Division, include: [ Department ] } ],
  order: [ [ Division, DepartmentDivision, 'name' ] ]
});

</pre><pre>
嵌套预加载
use nested(嵌套) eager loading to load all related models of a related model,This will produce an outer join,但where子句的关系模型会使用内连接并返回唯一一个子句

</pre><pre class="js">
User.findAll({
  include: [
    {model: Tool, as: 'Instruments', include: [
      {model: Teacher, include: [ /* etc */]}
    ]}
  ]
}).then(users => console.log(JSON.stringify(users)))
/*
  [{
    "name": "John Doe",
    "id": 1,
    "Instruments": [{      // 1:M and N:M association
      "name": "Toothpick",
      "id": 1,
      "userId": 1,
      "Teacher": {         // 1:1 association
        "name": "Jimi Hendrix"
      }
    }]
  }]
*/

// a where clause on a related model will create an inner join and return only the instances that have matching sub-models. To return all parent instances, you should add required: false
// The query above will return all users, and all their instruments, but only those teachers associated with Woodstock Music School
User.findAll({
  include: [{
    model: Tool,
    as: 'Instruments',
    include: [{
      model: Teacher,
      where: {
        school: "Woodstock Music School"
      },
      required: false
    }]
  }]
}).then(users => console.log(JSON.stringify(users))

</pre>
</div>

<div id="sequelize_query">
<h4>sequelize.query(sql, [options={}]) -> Promise</h4><pre>
执行原始SQL语句进行查询,默认情况下返回值中有两个参数：一个包含结果的数组,一个元数据对象,可以通过.spread方法来查看结果。
如果不想使用原始查询结果,可以第二个可选参数中传一个type参数指定查询的类型,设置后sequelize会对结果进行格式化

参数
sql String

[options={}]  Object
查询选项

[options.raw] Boolean
设置为true时sequelize不会查询结果进行格式化或不会根据结果构建实例

[options.transaction=null]  Transaction
为查询指定事务

[options.type='RAW']  String
执行的查询类型,sequelize会根据这个类型对返回结果格式化。可以设置为一个字符串或通过Sequelize.QueryTypes来设置

[options.nest=false]  Boolean
设置为true会使用dottie.js库转换通过.设置的对象层级关系,如{'user.username':'john'}转换为{user: {username:'john'}},设置true后查询类型如未明确指定则使用'SELECT'

[options.plain=false] Boolean
设置查询类型为SELECT并返回单行结果

[options.replacements]  Object | Array
替换:param格式的查询参数对象,或用于替换SQL中?符号的参数数组

[options.bind]  Object | Array
$param格式绑定参数的对象,或未命令绑定参数数组,会替换SQL中的$1, $2, ...

[options.useMaster=false] Boolean
强制查询使用写池,而不管查询类型

[options.logging=false] Function
一个用打印执行的SQL语句的函数

[options.instance]  Instance
用于sequelize实例,用于从查询结果中构建实例

[options.model] Model
用于sequelize模型,用于从查询结果中构建实例

[options.retry] Object
设置自动重试的控制标识对象

[options.retry.match] Array
发生错误时,匹配到数组中的标识后自动重试

[options.retry.max] Integer
设置最大重试次数

[options.mapToModel=false]  Object
字段到模型的映射关系,当提供options.model或options.instance时映射会在建立模型实例之前进行

[options.fieldMap]  Object
当为SELECT查询时映射字段与属性名

</pre><pre class="js">
sequelize.query('SELECT * FROM user')
  .spread((results, metadata) => {
    // Results will be raw data and metadata will be empty
    console.log(results, metadata)
  });

sequelize.query("UPDATE users SET y = 42 WHERE x = 12")
  .then(([results, metadata]) => {
    // Results will be an empty array and metadata will contain the number of affected rows
  })

sequelize.query("SELECT * FROM user")
  .then(myTableRows => console.log(myTableRows))
/*
select * from user
[ [ TextRow {
    id: 1,
    first_name: 'youzi',
    last_name: 'lee',
    birthday: 1980-07-19T16:00:00.000Z,
    email: '11111@qq.com',
    job: 'ENGINEER',
    about: 'I am a good man',
    createdAt: 2019-06-23T03:16:33.000Z,
    updatedAt: 2019-06-23T03:16:33.000Z,
    deletedAt: null } ],
  [ TextRow {
    id: 1,
    first_name: 'youzi',
    last_name: 'lee',
    birthday: 1980-07-19T16:00:00.000Z,
    email: '11111@qq.com',
    job: 'ENGINEER',
    about: 'I am a good man',
    createdAt: 2019-06-23T03:16:33.000Z,
    updatedAt: 2019-06-23T03:16:33.000Z,
    deletedAt: null } ] ]
*/

// don't need to access the metadata you can pass in a query type to tell sequelize how to format the results
sequelize.query('SELECT * FROM myTable', { type: sequelize.QueryTypes.SELECT })
  .then(results => console.log(results))
/*
select * from user
[ { id: 1,
  first_name: 'youzi',
  last_name: 'lee',
  birthday: 1980-07-19T16:00:00.000Z,
  email: '11111@qq.com',
  job: 'ENGINEER',
  about: 'I am a good man',
  createdAt: 2019-06-23T03:16:33.000Z,
  updatedAt: 2019-06-23T03:16:33.000Z,
  deletedAt: null } ]
*/

// If you pass a model the returned data will be instances of that model
sequelize.query('SELECT * FROM user', { model: User })
  .then(results => console.log(results)   // 每个记录现在将映射到项目的模型
/*
[ user {
    dataValues:
     { id: 1,
       first_name: 'youzi',
       last_name: 'lee',
       birthday: '1980-07-20',
       email: '11111@qq.com',
       job: 'ENGINEER',
       about: 'I am a good man',
       createdAt: 2019-06-24T02:27:34.000Z,
       updatedAt: 2019-06-24T02:27:34.000Z,
       deletedAt: null },
    _previousDataValues:
     { id: 1,
       first_name: 'youzi',
       last_name: 'lee',
       birthday: '1980-07-20',
       email: '11111@qq.com',
       job: 'ENGINEER',
       about: 'I am a good man',
       createdAt: 2019-06-24T02:27:34.000Z,
       updatedAt: 2019-06-24T02:27:34.000Z,
       deletedAt: null },
    _changed: {},
    _modelOptions:
     { timestamps: true,
       validate: {},
       freezeTableName: true,
       underscored: false,
       paranoid: true,
       rejectOnEmpty: false,
       whereCollection: null,
       schema: null,
       schemaDelimiter: '',
       defaultScope: {},
       scopes: {},
       indexes: [],
       name: [Object],
       omitNull: false,
       getterMethods: [Object],
       setterMethods: [Object],
       sequelize: [Object],
       hooks: {} },
    _options:
     { isNewRecord: false,
       _schema: null,
       _schemaDelimiter: '',
       raw: true,
       attributes: undefined },
    isNewRecord: false } ]
*/

// Callee is the model definition. This allows you to easily map a query to a predefined model
sequelize.query('SELECT * FROM projects', {
    model: Projects,
    mapToModel: true // pass true here if you have any mapped fields
  })
  .then(projects => {
    // Each record will now be an instance of Project
  })

sequelize.query('SELECT 1', {
  // A function (or false) for logging your queries Will get called for every SQL query that gets sent to the server.
  logging: console.log,

  // If plain is true, then sequelize will only return the first record of the result set. In case of false it will return all records.
  plain: false,

  // Set this to true if you don't have a model definition for your query.
  raw: false,

  // The type of query you are executing. The query type affects how results are formatted before they are passed back.
  type: Sequelize.QueryTypes.SELECT
})

// Note the second argument being null!
// Even if we declared a callee here, the raw: true would
// supersede and return a raw object.
sequelize
  .query('SELECT * FROM projects', { raw: true })
  .then(projects => console.log(projects))

</pre>"Dotted" attributes<pre class="js">
sequelize.query('select 1 as `foo.bar.baz`').then(rows => {
  console.log(JSON.stringify(rows))
})

[{
  "foo": {
    "bar": {
      "baz": 1
    }
  }
}]

</pre><pre>
【 replacements 】
原始查询中有两种替换查询参数的方法,以:开头的参数的形式替换或以不命名以?替换。在选项对象中传递参数：
如果传递一个数组,? 会按数组的顺序被依次替换
如果传递一个对象,:key将会用对象的键替换。如果对象中未找到指定键则会引发异常(反之亦然)

</pre><pre class="js">
sequelize.query('SELECT * FROM projects WHERE status = ?',
  { replacements: ['active'], type: sequelize.QueryTypes.SELECT }
).then(projects => {
  console.log(projects)
})

sequelize.query('SELECT * FROM projects WHERE status = :status ',
  { replacements: { status: 'active' }, type: sequelize.QueryTypes.SELECT }
).then(projects => {
  console.log(projects)
})

sequelize.query('SELECT * FROM projects WHERE status IN(:status) ',
  { replacements: { status: ['active', 'inactive'] }, type: sequelize.QueryTypes.SELECT }
).then(projects => {
  console.log(projects)
})

sequelize.query('SELECT * FROM users WHERE name LIKE :search_name ',
  { replacements: { search_name: 'ben%'  }, type: sequelize.QueryTypes.SELECT }
).then(projects => {
  console.log(projects)
})

</pre><pre>
【 Bind Parameter 】
参数绑定类似于参数替换,尤其是参数替换会在发送到数据库前被sequelize转义和替换,而参数绑定会被发送到SQL查询文本外。

只有SQLite 和 PostgreSQL支持参数绑定,其它类型数据库都会将其插入到SQL查询,并以相同的方式进行参数替换。参数绑定可以使用$1、$2……或$key的形式：

如果传入的是数组,$1会绑定到数组听第1个参数 (bind[0])
如果传入一个对象,$key会绑定到object['key']。每个key 必须以非数字的字符开始。$1不是个有效的key,尽管object['1'] 是存在的。
在使用$$时,不会被转义而是将$做为一个字面量使用。
传入的数组或对象必须包含所有绑定值,否则Sequelize会抛出异常。这同样适用于数据库可能会忽略绑定参数的情况下。

数据库可能会做进一步限制,绑定参数不能使用数据库关键字,也不能是表或列名,它在引用文本或数据时也可能被忽略。在PostgreSQL中,如果不能从上下文$1::varchar中推断类型,那么也需要进行类型转换。

</pre><pre class="js">
sequelize.query('SELECT *, "text with literal $$1 and literal $$status" as t FROM projects WHERE status = $1',
  { bind: ['active'], type: sequelize.QueryTypes.SELECT }
).then(projects => {
  console.log(projects)
})

sequelize.query('SELECT *, "text with literal $$1 and literal $$status" as t FROM projects WHERE status = $status',
  { bind: { status: 'active' }, type: sequelize.QueryTypes.SELECT }
).then(projects => {
  console.log(projects)
})

</pre>
</div>

<div id="transaction" >
<h4>sequelize.transaction() - 启动事务</h4><pre>
sequlize.transaction([options={}]) -> Promise
启动一个事务。当使用事务时需要将事务做为一个可选参数transaction传入,然后查询就会在传入的事务下执行：

[options={}]  Object

[options.autocommit=true] Boolean
是否自动提交

[options.isolationLevel='REPEATABLE_READ'] String
事务的隔离级别,参见Sequelize.Transaction.ISOLATION_LEVELS

[options.logging=false] Function
用于打印执行SQL的函数

Sequelize有两种使用事务的方式：
1、基于Promise结果链的自动提交/回滚
2、另一种是不自动提交和回滚,而由用户控制事务

</pre>不受管理的事务需要强制提交或回滚,如果不进行这些操作,事务会一直保持挂起状态直到超时<pre class="js">
sequelize.transaction().then(t => {
  return User.findOne(..., { transaction: t}).then(user => {
    return user.update(..., { transaction: t});
  })
  .then(t.commit.bind(t))
  .catch(t.rollback.bind(t));
})

</pre><pre class="js">
return sequelize.transaction().then(t => {
  return User.create({
    firstName: 'Homer',
    lastName: 'Simpson'
  }, {transaction: t}).then(user => {
    return user.addSibling({
      firstName: 'Lisa',
      lastName: 'Simpson'
    }, {transaction: t});
  }).then(() => {
    return t.commit();
  }).catch(err => {
    return t.rollback();
  });
});

</pre>受管理的事务支持自动提交或回滚,当使用promise链接调用时会自动完成<pre class="js">
sequelize.transaction(t => {
  // 要确保所有的查询链都有return返回,这时使用的是callback而不是promise.then()
  return User.findOne(..., { transaction: t}).then(user => {
    return user.update(..., { transaction: t});
  });
}).then(result => {
  // Committed,Transaction会自动提交
  // result是事务回调中使用promise链中执行结果
}).catch(function (err) {
  // Rolled back,Transaction会自动回滚,err是事务回调中使用promise链中的异常结果
  console.error(err);
});

</pre>使用受管理的事务时不能通过手工调用的方式来提交或回滚事务。但在需要时如验证失败则可通过throw来抛出异常回滚事务<pre class="js">
return sequelize.transaction(t => {
  return User.create({
    firstName: 'Abraham',
    lastName: 'Lincoln'
  }, {transaction: t}).then(user => {
    throw new Error();   // 虽然所有操作成功但仍会回滚
  });
});

</pre><pre>
【 自动传递事务到所有的查询中 】
通过向第二个参数中添加{ transaction: t }选项来手工传递事务,如果要自动传递事务到所有的查询中,需要安装continuation local storage(CLS)模块并在代码中创建一个命名空间实例

</pre>启用CLS命名空间时,事务分被自动挂载<pre class="js">
var cls = require('continuation-local-storage');
var namespace = cls.createNamespace('my-very-own-namespace');
var Sequelize = require('sequelize');
// 启用CLS,需要在Sequlize构造函数属性中设置命名空间,cls必须在constructor构造函数中设置,而不能在sequlize实例中设置
Sequelize.cls = namespace;

// CLS的工作方式就像一个回调函数的本地线程存储。在sequlize中启用CLS后,需要在启动事务时设置transaction命名空间。在一个回调链中设置的变量时私有的,所以几个并发事务可以同时存在
sequelize.transaction(function (t1) {
  namespace.get('transaction') === t1; // true
});

sequelize.transaction(function (t2) {
  namespace.get('transaction') === t2; // true
});

// 大多数情况下不用通过namespace.get('transaction')直接访问命名空间,因为所有的查询都会自动查找事务的命名空间。
sequelize.transaction(function (t1) {
  return User.create({ name: 'Alice' });  // 启用CLS后会在自动在事务中执行create操作
});

</pre><pre>
【 并行/部分事务 】
在一系列的查询中可以有多个并行的事务或者其中的一些查询不使用事务。通过{transaction: }选项来指定查询属于哪个事务：

</pre><pre class="js">
sequelize.transaction(t1 => {
  return sequelize.transaction(t2 => {
    // 启用CLS时查询会自动使用t2
    // 通过`transaction`选项可以改变查询所属的事务
    return Promise.all([
      User.create({ name: 'Bob' }, { transaction: null }),
      User.create({ name: 'Mallory' }, { transaction: t1 }),
      User.create({ name: 'John' }) // 默认使用 t2
    ]);
  });
});

</pre><pre>
【 隔离级别 】
在启动事务时可以设置事务的隔离级别。可选值有：
Sequelize.Transaction.ISOLATION_LEVELS.READ_UNCOMMITTED // "READ UNCOMMITTED"
Sequelize.Transaction.ISOLATION_LEVELS.READ_COMMITTED   // "READ COMMITTED"
Sequelize.Transaction.ISOLATION_LEVELS.REPEATABLE_READ  // "REPEATABLE READ"
Sequelize.Transaction.ISOLATION_LEVELS.SERIALIZABLE     // "SERIALIZABLE"

默认的隔离级别为REPEATABLE READ,如果需要修改可以在启动事务时在第一个参数中设置：

return sequelize.transaction({ isolationLevel: Sequelize.Transaction.ISOLATION_LEVELS.SERIALIZABLE }, t => {
  // your transactions
});

【 选项参数 】
调用transaction方法时,可以向其第一个参数中传递一个选项参数,通过该参数可以对事务进行一些配置：

</pre>默认配置选项如下<pre class="js">
return sequelize.transaction({
  autocommit: true,
  isolationLevel: 'REPEATABLE_READ',
  deferrable: 'NOT DEFERRABLE' // implicit default of postgres
}, t => {})

</pre>isolationLevel选项可以在初始化Sequelize全局设置,也可以启动每个事务时局部设置<pre class="js">
// 全局设置
new Sequelize('db', 'user', 'pw', {
  isolationLevel: Sequelize.Transaction.ISOLATION_LEVELS.SERIALIZABLE
});

// 局部设置
sequelize.transaction({
  isolationLevel: Sequelize.Transaction.ISOLATION_LEVELS.SERIALIZABLE
});

</pre>
</div>

<div id="hooks">
<h4>sequelize Hooks/lifecycle events</h4><pre>
钩子函数也被称做回调或生命周期事件,这些函数会在Sequlize执行一些操作之前或之后被调用。如想在模型数据保存前设置一个值,那么就可以添加一个beforeUpdate钩子

Order of Operations:
(1)
  beforeBulkCreate(instances, options)
  beforeBulkDestroy(options)
  beforeBulkUpdate(options)
(2)
  beforeValidate(instance, options)
(-)
  validate
(3)
  afterValidate(instance, options)
  - or -
  validationFailed(instance, options, error)
(4)
  beforeCreate(instance, options)
  beforeDestroy(instance, options)
  beforeUpdate(instance, options)
  beforeSave(instance, options)
  beforeUpsert(values, options)
(-)
  create
  destroy
  update
(5)
  afterCreate(instance, options)
  afterDestroy(instance, options)
  afterUpdate(instance, options)
  afterSave(instance, options)
  afterUpsert(created, options)
(6)
  afterBulkCreate(instances, options)
  afterBulkDestroy(options)
  afterBulkUpdate(options)

</pre><pre class="js">
const User = sequelize.define('user', {
  username: Sequelize.STRING,
  mood: {
    type: Sequelize.ENUM,
    values: ['happy', 'sad', 'neutral']
  }
}, {
  timestamps: false,
  freezeTableName: true,
  hooks: {
    beforeValidate: (user, options) => {
      console.log('beforeValidate', JSON.stringify(user), JSON.stringify(options))
      user.mood = 'happy';
    },
    afterValidate: (user, options) => {
      console.log('afterValidate', JSON.stringify(user), JSON.stringify(options))
      user.username = 'Tony';
    },
    beforeCreate: (user, options) => {
      console.log('beforeCreate', JSON.stringify(user), JSON.stringify(options))
    },
    afterCreate: (user, options) => {
      console.log('afterCreate', JSON.stringify(user), JSON.stringify(options))
    }
  }
});
console.log('hasHook', User.hasHook('beforeValidate'))
await User.sync({force: true})
await User.create({
  username: 'lisi',
  mood: 'unkown'
}).then(user => console.log(JSON.stringify(user)))
.catch(err => console.log(err))

/*
hasHook true
CREATE TABLE IF NOT EXISTS `user` (`id` INTEGER NOT NULL auto_increment , `username` VARCHAR(255), `mood` ENUM('happy', 'sad', 'neutral'), PRIMARY KEY (`id`)) ENGINE=InnoDB;
beforeValidate
{"id":null,"username":"lisi","mood":"unkown"}
{"hooks":true,"validate":true,"fields":["id","username","mood"],"defaultFields":["id","username","mood"],"returning":true,"skip":[]}

afterValidate
{"id":null,"username":"lisi","mood":"happy"}
{"hooks":true,"validate":true,"fields":["id","username","mood"],"defaultFields":["id","username","mood"],"returning":true,"skip":[]}

beforeCreate
{"id":null,"username":"Tony","mood":"happy"}
{"hooks":true,"validate":true,"fields":["id","username","mood"],"defaultFields":["id","username","mood"],"returning":true}

Executing (default): INSERT INTO `user` (`id`,`username`,`mood`) VALUES (DEFAULT,?,?);

afterCreate
{"id":1,"username":"Tony","mood":"happy"}
{"hooks":true,"validate":true,"fields":["id","username","mood"],"defaultFields":["id","username","mood"],"returning":true}

{"id":1,"username":"Tony","mood":"happy"}
*/

</pre><pre>
【 add hooks定义钩子 】
钩子的参数通过引用传递,这意味着可以修改值且修改会体现在insert/update语句中。钩子函数中可以包含异步操作,这时钩子函数中应该返回一个promise

</pre><pre class="js">
// Method 1 via new Sequelize(),Global / universal hooks,This adds a default hook to all models, which is run if the model does not define its own beforeCreate hook
// 全局钩子会在所有的模型中运行,它们可以定义模型的形为,这些钩子很适合应用一些有用的插件
const sequelize = new Sequelize(..., {
  define: {
    hooks: {
      beforeCreate: () => {
        // Do stuff
      }
    }
  }
});

// Method 2 via the sequelize.define() method
const User = sequelize.define({
  username: Sequelize.STRING,
  mood: {
    type: Sequelize.ENUM,
    values: ['happy', 'sad', 'neutral']
  }
}, {
  hooks: {
    beforeValidate: (user, options) => {
      user.mood = 'happy';
    },
    afterValidate: (user, options) => {
      user.username = 'Toni';
    },
    beforeCreate: function () {
      // Do other stuff
    }
  }
});

User.create()    // 执行自已的钩子,因为全局钩子会被重写
Project.create() // 执行全局钩子

// Method 3 via the Model.addHook() method
User.addHook('beforeValidate', (user, options) => {
  user.mood = 'happy';
});

User.addHook('afterValidate', 'someCustomName', (user, options) => {
  return Promise.reject(new Error("I'm afraid I can't let you do that!"));
});

// Method 4 via the direct method
User.beforeCreate((user, options) => {
  return hashPassword(user.password).then(hashedPw => {
    user.password = hashedPw;
  });
});

User.afterValidate('myHookAfter', (user, options) => {
  user.username = 'Toni';
});

// Method 5 via Permanent Hooks (Sequelize.addHook)
// 通过addHook方法添加的钩子总是会执行,不会被模型本身定义的钩子函数所覆盖,本地钩子总是会在全局钩子之前执行
// This hook is always run before create, regardless of whether the model specifies its own beforeCreate hook
sequelize.addHook('beforeCreate', () => {
  // Do stuff
});
var User = sequelize.define('user');
var Project = sequelize.define('project', {}, {
  hooks: {
    beforeCreate: function () { // Do other stuff }
  }
});
User.create()    // 执行全局钩子
Project.create() // 先执行自己的钩子,再执行全局钩子

// Method 6 Permanent hooks may also be defined in Sequelize.options:
new Sequelize(..., {
  hooks: {
    beforeCreate: () => {
      // do stuff
    }
  }
});

</pre>Removing hooks: Only a hook with name param can be removed<pre class="js">
const Book = sequelize.define({
  title: Sequelize.STRING
});

Book.addHook('afterCreate', 'notifyUsers', (book, options) => {
  // ...
});

// You can have many hooks with same name. Calling .removeHook() will remove all of them.
Book.removeHook('afterCreate', 'notifyUsers');

</pre><pre>
【 Connection Hooks 】
Sequelize provides two hooks that are executed immediately before and after a database connection is obtained

beforeConnect(config)
afterConnect(connection, config)

</pre><pre class="js">
sequelize.beforeConnect(config => {
  return getAuthToken().then(token => config.password = token);
});

</pre><pre>
【 Instance hooks 】
单个实例中也有一些钩子,它们会在你编辑修改实例时被执行
beforeValidate
afterValidate or validationFailed
beforeCreate / beforeUpdate / beforeSave  / beforeDestroy
afterCreate / afterUpdate / afterSave / afterDestroy

</pre><pre class="js">
User.beforeCreate(user => {
  if (user.accessLevel > 10 && user.username !== "Boss") {
    throw new Error("You can't grant this user an access level above 10!")
  }
})

User.create({username: 'Not a Boss', accessLevel: 20}).catch(err => {
  console.log(err); // You can't grant this user an access level above 10!
});

User.create({username: 'Boss', accessLevel: 20}).then(user => {
  console.log(user); // user object with username as Boss and accessLevel of 20
});

</pre><pre>
【 Model hooks 】
Sometimes you'll be editing more than one record at a time by utilizing the bulkCreate, update, destroy methods on the model. The following will emit whenever you're using one of those methods:

beforeBulkCreate(instances, options)
beforeBulkUpdate(options)
beforeBulkDestroy(options)
afterBulkCreate(instances, options)
afterBulkUpdate(options)
afterBulkDestroy(options)

在批量操作中,如果想把钩子应用到每个单独的记录中,请设置individualHooks: true选项
Model.destroy({ where: {accessLevel: 0}, individualHooks: true});
// Will select all records that are about to be deleted and emit before- + after- Destroy on each instance

Model.update({username: 'Toni'}, { where: {accessLevel: 0}, individualHooks: true});
// Will select all records that are about to be updated and emit before- + after- Update on each instance

The options argument of hook method would be the second argument provided to the corresponding method or its cloned and extended version

</pre><pre class="js">
Model.beforeBulkCreate((records, fields) => {
  // records is the first argument sent to .bulkCreate
  // fields is the second argument sent to .bulkCreate
})

Model.bulkCreate([
    {username: 'Toni'},     // part of records argument
    {username: 'Tobi'}      // part of records argument
  ], {fields: ['username']} // options parameter
)

Model.beforeBulkUpdate(({attributes, where}) => {
  // where - in one of the fields of the clone of second argument sent to .update
  // attributes - is one of the fields that the clone of second argument of .update would be extended with
})

Model.update({gender: 'Male'} /*attributes argument*/, { where: {username: 'Tom'}} /*where argument*/)

Model.beforeBulkDestroy(({where, individualHooks}) => {
  // individualHooks - default of overridden value of extended clone of second argument sent to Model.destroy
  // where - in one of the fields of the clone of second argument sent to Model.destroy
})

Model.destroy({ where: {username: 'Tom'}} /*where argument*/)

</pre><pre>
If you use Model.bulkCreate(...) with the updateOnDuplicate option, changes made in the hook to fields that aren't given in the updateOnDuplicate array will not be persisted to the database. However it is possible to change the updateOnDuplicate option inside the hook if this is what you want.

在Model.bulkCreate(...)方法中使用updatesOnDuplicate选项时,我们可以在钩子函数中对updatesOnDuplicate数据进行修改

</pre><pre class="js">
// 在Model.bulkCreate()方法中使用updatesOnDuplicate选项时可以在钩子函数中对updatesOnDuplicate数据进行修改
Users.bulkCreate([
  { id: 1, isMember: true },
  { id: 2, isMember: false }
], {
  updateOnDuplicate: ['isMember']
});

User.beforeBulkCreate((users, options) => {
  for (const user of users) {
    if (user.isMember) {
      user.memberSince = new Date();
    }
  }

  // 为updatesOnDuplicate添加一个memberSince,其它情况下memberSince数据不会保存到数据库
  options.updateOnDuplicate.push('memberSince');
});

</pre><pre>
【 hooks and Associations 】
For the most part hooks will work the same for instances when being associated except a few things

1、When using add/set functions the beforeUpdate/afterUpdate hooks will run.
2、The only way to call beforeDestroy/afterDestroy hooks are on associations with onDelete: 'cascade' and the option hooks: true

</pre><pre class="js">
const Project = sequelize.define('project', {title: Sequelize.STRING});
const Task = sequelize.define('task', {title: Sequelize.STRING});
Project.hasMany(Task, { onDelete: 'cascade', hooks: true });
Task.belongsTo(Project);

</pre><pre>
这段代码会在Tasks表上调用beforeDestroy/afterDestroy钩子。默认Sequelize会尝试尽可能优化查询语句,When calling cascade on delete,sequelize会像下面这样简单的执行：

DELETE FROM `table` WHERE associatedIdentifier = associatedIdentifier.primaryKey

添加hooks: true后,相当于告诉Sequelize并不关心优化,这将会在每个实例删除时分别应用钩子。
and will perform a SELECT on the associated objects and destroy each instance one by one in order to be able to call the hooks with the right parameters.

在n:m关联中,你可能想在调用remove时在throungh model上触发使用钩子,这时Sequelize会使用Model.destroy代替bulkDestroy,以分别为每个实例应用before/afterDestroy钩子。

这时可以通过在remove方法中添加{individualHooks: true}选项以分别为每个实例就用钩子

【 在事务中应注意 】
在操作多个模型时可以设置transaction选项,以保障操作数据的完整性。如果在原调用中指定了一个事务,那它将在传递给钩子函数的选项参数中出现：

</pre><pre class="js">
// 这时使用promise式的异步钩子而非回调
User.addHook('afterCreate', function(user, options) {
  // 'transaction'通过options.transaction设置

  // 此操作会将相同事务部分像原始User.create一样调用
  return User.update({
    mood: 'sad'
  }, {
    where: { id: user.id },
    transaction: options.transaction
  });
});

sequelize.transaction(t => {
  User.create({
    username: 'someguy',
    mood: 'happy',
    transaction: t
  });
});
// 如果在调用User.update时没有设置事务选项,那么不会做任何操作,直到后面的create操作发生时才会触发。

</pre>

<h4>hooks API</h4><pre>
【 addHook(hooktype, [name], fn) 】
为模型添加钩子
hooktype - {String},钩子类型
[name] - {String},钩子名,可用于以后钩子函数的移除
fn - {Function},要添加的钩子函数

【 removeHook(hookType, name) 】
从模型中移除钩子
hooktype - {String},钩子类型
name - {String},钩子名

【 hasHook(hookType) 】
检查模型中是否存在指定类型的钩子,别名：hasHooks
hooktype - {String},钩子类型

【 beforeValidate(name, fn) 】
用于在模型执行数据验证前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterValidate(name, fn) 】
用于在模型数据验证完成后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeCreate(name, fn) 】
用于在模型创建实例前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeDestroy(name, fn) 】
用于在模型创建实例后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeDestroy(name, fn) 】
用于在模型删除实例前执行的钩子函数,别名：beforeDelete
name - {String}
fn - {Function},要执行的钩子函数

【 afterDestroy(name, fn) 】
用于在模型删除实例后执行的钩子函数,别名：afterDestroy
name - {String}
fn - {Function},要执行的钩子函数

【 beforeRestore(name, fn) 】
用于在模型实例恢复(软删除)前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterRestore(name, fn) 】
用于在模型实例恢复(软删除)后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeUpdate(name, fn) 】
用于在模型实例更新前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterUpdate(name, fn) 】
用于在模型实例更新后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeBulkCreate(name, fn) 】
用于在批量创建模型实例前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterBulkCreate(name, fn) 】
用于在批量创建模型实例后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeBulkDestroy(name, fn) 】
用于在批量删除模型实例前执行的钩子函数,别名：beforeBulkDelete
name - {String}
fn - {Function},要执行的钩子函数

【 afterBulkDestroy(name, fn) 】
用于在批量删除模型实例后执行的钩子函数,别名：afterBulkDelete
name - {String}
fn - {Function},要执行的钩子函数

【 beforeBulkRestore(name, fn) 】
用于在批量恢复模型实例前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterBulkRestore(name, fn) 】
用于在批量恢复模型实例后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeBulkUpdate(name, fn) 】
用于在批量更新模型实例前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterBulkUpdate(name, fn) 】
用于在批量更新模型实例后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeFind(name, fn) 】
用于在查找模型数据民前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeFindAfterExpandIncludeAll(name, fn) 】
用于在执行find()查询前, { include: {all: ...} }展开后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeFindAfterOptions(name, fn) 】
用于在执行find()查询前,选项参数解析守成后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterFind(name, fn) 】
用于在查询完成后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeDefine(name, fn) 】
用于在调用define前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterDefine(name, fn) 】
用于在调用define后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeInit(name, fn) 】
用于在调用Sequelize()前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterInit(name, fn) 】
用于在调用Sequelize()后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeSync(name, fn) 】
用于在调用Model.sync()前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterSync(name, fn) 】
用于在调用Model.sync()后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 beforeBulkSync(name, fn) 】
用于在调用sequelize.sync()前执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

【 afterBulkSync(name, fn) 】
用于在调用sequelize.sync()后执行的钩子函数
name - {String}
fn - {Function},要执行的钩子函数

</pre>
</div>

<div id="sequelize-demo">
<h4>demo</h4><pre class="js">
/* 新建数据库连接模块 dbConn.js */
var Sequelize = require('sequelize');
// 数据库配置文件
var sqlConfig = {
  host: "localhost",
  user: "admin",
  password: "",
  database: "nodejs"
};
// 创建连接对象
var sequelize = new Sequelize(sqlConfig.database, sqlConfig.user, sqlConfig.password, {
  host: sqlConfig.host,
  dialect: 'mysql',
  pool: {
    max: 10,
    min: 0,
    idle: 10000
  },
  timezone: '+08:00' //东八时区
});
exports.sequelize = sequelize;

// 协同开发规范,每个模型都要添加version、createUser以及updateUser三个字段、表名即为模型名,以及数据的字符集为utf8mb4等等。当要创建模型的时候通过调用defineModel方法就可以达到统一规范的效果
// 还有一个好处,那就是在模型定义里只需要写业务相关的字段,与业务无关的一些通用字段(例如时间戳等)就全部放到规范里。业务字段一目了然,显得更加清晰
exports.defineModel = function (name, attributes) {
  var attrs = {};
  for (let key in attributes) {
    let value = attributes[key];
    if (typeof value === 'object' && value['type']) {
      value.allowNull = value.allowNull || false;
      attrs[key] = value;
    } else {
      attrs[key] = { type: value, allowNull: false };
    }
  }
  attrs.version = {
    type: Sequelize.BIGINT,
    allowNull: false
  };
  attrs.createUser = {
    type: Sequelize.STRING,
    allowNull: false
  };
  attrs.updateUser = {
    type: Sequelize.STRING,
    allowNull: false
  };
  return sequelize.define(name, attrs, {
    tableName: name,
    timestamps: true,     // 为模型添加createdAt和updatedAt两个时间戳字段
    paranoid: true,       // 使用逻辑删除
    charset: 'utf8mb4',
    collate: 'utf8mb4_general_ci',
    hooks: {
      beforeBulkCreate: function(obj){
        obj.version = 0 ;
      },
      beforeValidate: function(obj){
        if(obj.isNewRecord){
          console.log('first');
          obj.version = 0 ;
        }else{
          console.log('not first');
          obj.version = obj.version + 1 ;
        }
      }
    }
  });
};

// 使用
var Sequelize = require('sequelize');
var db = require('../dbConn.js');

module.exports = db.defineModel('project_master', {
  p_id: {
    type: Sequelize.BIGINT(11),
    primaryKey: true,
    allowNull: false,
    autoIncrement: true
  },
  p_name: Sequelize.STRING(100),
  p_academy: Sequelize.STRING(100),
  p_start_date: Sequelize.STRING(10),
  p_end_date: Sequelize.STRING(10),
  p_days: Sequelize.DECIMAL(10, 1),
  p_place: Sequelize.STRING(20),
  p_owner: Sequelize.STRING(10),
  p_operator: Sequelize.STRING(10),
  p_is_fee: Sequelize.BIGINT(1),
  p_state: Sequelize.BIGINT(2),  // 开启,关闭
  p_bz: Sequelize.STRING(255),
});

/* 定义数据表结构,将表结构写进代码里/db/models/todolist.js */
var Sequelize = require('sequelize');
var sequelize = require('./dbConn.js');
var todolist = sequelize.define('todolist',{
  id: {
    type: Sequelize.BIGINT(11),
    primaryKey: true,
    allowNull: false,
    unique: true,
    autoIncrement: true
  },
  title: Sequelize.STRING(100),          // 标题
  content: Sequelize.STRING(500),        // 详细内容
  priority: Sequelize.INTEGER,           // 级别
  owner: Sequelize.STRING,               // 承接人
  officer: Sequelize.STRING,             // 负责人
  startDate: Sequelize.STRING,           // 开始时间
  planFinishDate: Sequelize.STRING,      // 计划完成时间
  realFinishDate: Sequelize.STRING,      // 实际完成时间
  bz: Sequelize.STRING(500),             // 备注
  state: Sequelize.INTEGER,              // 状态
  createdAt: Sequelize.BIGINT,
  updatedAt: Sequelize.BIGINT,
  createUser: Sequelize.STRING,
  updateUser: Sequelize.STRING,
  version: Sequelize.BIGINT
},{
  timestamps: false                       // 不要默认时间戳
});
module.exports = todolist;

/* 同步数据表结构,强制同步,先删除表然后新建,/db/syncTable.js */
// 换台电脑继续项目的时候不用手动去同步数据表结构了,只需要执行一下该文件就可以了,node db/syncTable.js
todolist.sync({ force: true });

</pre>批量同步数据结构的方法<pre class="js">
// 同步数据结构时可通过sync方法同步,批量同步:把数据模型放在models目录下,在models目录外新建sync.js文件
// 该方法的本质其实就是自动找出models目录下所有以js结尾的文件,引入并执行sync()方法

var sequelize = require('./dbConn.js').sequelize;
var fs = require('fs');
var files = fs.readdirSync(__dirname + '/models');
var js_files = files.filter(f=> f.endsWith('.js')}, files);
module.exports = {};
for (var f of js_files) {
  console.log(`import model from file ${f}...`);
  var name = f.substring(0, f.length - 3);
  module.exports[name] = require(__dirname + '/models/' + f);
}
sequelize.sync();

</pre>数据表关系结构<pre class="js">
// 数据表的关系有一对一,一对多以及多对多的关系结构。一般ORM框架都会提供与之对应的对象方法,当然Sequelize也不例外
// 新建一个relation.js文件来定义模型之间的关系
// ProjectMaster与ProjectCost、ProjectState是一对一的关系,于是使用hasOne的方法,并且指定字段p_id为连接外键。而TeachFee是费用明细表,与项目表是一对多的关系,于是使用hasMany的方法,同样指定外键

// 项目表
var ProjectMaster = require('./models/Project-master');
var ProjectCost = require('./models/Project-cost');
var ProjectState = require('./models/Project-state');

// 费用明细表
var TeachFee = require('./models/Detail-teach-fee.js');

ProjectMaster.hasOne(ProjectState, {foreignKey: 'p_id', as: 'State'});
ProjectMaster.hasOne(ProjectCost, {foreignKey: 'p_id', as: 'Cost'});
ProjectMaster.hasMany(TeachFee, {foreignKey: 'p_id', as: 'TeachFee'});

module.exports = {
  ProjectMaster,
  ProjectCost,
  ProjectState,
  TeachFee,
};

// 当定义完数据表关系后重新编辑同步数据表方法,因为需要使用新定义的关系模型,新建sync2.js文件
var sequelize = require('./dbConn.js').sequelize;
var relation = require('./relation.js');

module.exports = {
  ProjectMaster: relation.ProjectMaster,
  ProjectCost: relation.ProjectCost,
  ProjectState: relation.ProjectState,
  TeachFee: relation.TeachFee
};

sequelize.sync({ force: true });      // 强制同步

// 执行node db/sync2.js后,在表结构中会发现出现的外键关联关系。上述代码会在ProjectMaster、ProjectCost以及TeachFee模型对应的数据表中新增了外键关联。如下状态表的情况

CREATE TABLE `project_state` (
  `p_state_id` bigint(11) NOT NULL AUTO_INCREMENT,
  `p_id` bigint(11) DEFAULT NULL,
  `p_state_teach` bigint(2) DEFAULT NULL,
  `p_state_place` bigint(2) DEFAULT NULL,
  `p_state_stay` bigint(2) DEFAULT NULL,
  `p_state_catering` bigint(2) DEFAULT NULL,
  `p_state_goods` bigint(2) DEFAULT NULL,
  `p_state_clean` bigint(2) DEFAULT NULL,
  `p_state_report` bigint(2) DEFAULT NULL,
  `version` bigint(20) DEFAULT NULL,
  `createUser` varchar(255) NOT NULL,
  `updateUser` varchar(255) NOT NULL,
  `createdAt` datetime NOT NULL,
  `updatedAt` datetime NOT NULL,
  `deletedAt` datetime DEFAULT NULL,
  PRIMARY KEY (`p_state_id`),
  KEY `p_id` (`p_id`),
  CONSTRAINT `project_state_ibfk_1` FOREIGN KEY (`p_id`) REFERENCES `project_master` (`p_id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

// 创建完表之后,接下来就是使用,这里给个建议方案,在db目录下新建一个api的目录,用来存放数据库调用接口。把所有对数据库的操作全部写成方法供后台路由调用。例如对项目的查询、删除、修改等等操作都定义成一个一个的方法。在api目录下新建projectModel.js文件,用来定义对项目的一些数据库操作。代码如下

var sequelize = require('../dbConn.js').sequelize;
var {ProjectMaster, ProjectCost, ProjectState} = require('../relation.js');

module.exports = {
  // 单表：仅更新项目表
  updateProject: function(data, id, callback){
    ProjectMaster.update(data ,{where: {p_id: id}}).then(p => callback());
  }
  // 双表：查找成本表
  getCostList: function(start, end, callback){
    ProjectMaster.findAll({
      include: [{
        model: ProjectCost,
        as: 'Cost',
      }],
      where: {
        p_start_date: {
          $lte: end,
          $gte: start
        }
      },
      order: [sequelize.literal('p_start_date')]
    }).then(function(p){
      callback(p);
    });
  },
  // 双表：添加项目,同时在状态表添加项目状态
  addProject: function(data, callback){
    ProjectMaster.create(data).then(function(p){
      var state = ProjectState.build({
        p_state_teach: 1,
        p_state_stay: 1,
        p_state_catering: 1,
        p_state_place: 1,
        p_state_goods: 1,
        p_state_clean: 1,
        p_state_report: 1,
        createUser: data.createUser,
        updateUser: data.updateUser,
      });
      p.setState(state);
      callback(p);
    });
  },
};

// 由于对数据库的操作方法较多,这里用3个示例方法来介绍。

第一个为单表操作,更新项目表。增删改查的一些基本方法,建议查看官方文档;
第二个为双表联合查询,通过 include 参数来关联模型,得到的结果中会包含一个Cost对象,包含ProjectCost的模型数据;
第三个为添加项目时同时添加状态表,用到关系模型中的set方法,创建项目主数据表后通过关联关系使用set方法自动在State表中insert数据

</pre>

<h4>建立Model</h4><pre>
一个大型Web App通常都有几十个映射表,一个映射表就是一个Model
所以需要一个统一的模型,强迫所有Model都遵守同一个规范,这样不但实现简单,而且容易统一风格,很多代码才能复用。

首先要定义的就是Model存放的文件夹必须在models内,并且以Model名字命名,例如：Pet.js,User.js

其次每个Model必须遵守一套规范：
id、createdAt、updatedAt和version应该自动加上,而不是每个Model都去重复定义
统一主键,名称必须是id,类型必须是STRING(50);
主键可以自己指定,也可以由框架自动生成(如果为null或undefined);
所有字段默认为NOT NULL,除非显式指定;
统一timestamp机制,每个Model必须有createdAt、updatedAt和version,分别记录创建时间、修改时间和版本号,其中createdAt和updatedAt以BIGINT存储时间戳,最大的好处是无需处理时区排序方便,version每次修改时自增。
所以不要直接使用Sequelize的API,而是通过db.js间接地定义Model

</pre><pre class="js">
const Foo = sequelize.define('foo', {
 flag: { type: Sequelize.BOOLEAN, allowNull: false, defaultValue: true },
 myDate: { type: Sequelize.DATE, defaultValue: Sequelize.NOW }, // default current time
 title: { type: Sequelize.STRING, allowNull: false },

 // Creating two objects with the same value will throw an error. The unique property can be either a boolean, or a string. If you provide the same string for multiple columns, they will form a composite unique key.
 uniqueOne: { type: Sequelize.STRING,  unique: 'compositeIndex' },
 uniqueTwo: { type: Sequelize.INTEGER, unique: 'compositeIndex' },

 // The unique property is simply a shorthand to create a unique constraint.
 someUnique: { type: Sequelize.STRING, unique: true },

 // It's exactly the same as creating the index in the model's options.
 { someUnique: { type: Sequelize.STRING } },
 { indexes: [ { unique: true, fields: [ 'someUnique' ] } ] },

 // Go on reading for further information about primary keys
 identifier: { type: Sequelize.STRING, primaryKey: true },

 // autoIncrement can be used to create auto_incrementing integer columns
 incrementMe: { type: Sequelize.INTEGER, autoIncrement: true },

 // You can specify a custom column name via the 'field' attribute:
 fieldWithUnderscores: { type: Sequelize.STRING, field: 'field_with_underscores' },

 // It is possible to create foreign keys:
 bar_id: {
   type: Sequelize.INTEGER,
   references: {
     model: Bar,  // This is a reference to another model
     key: 'id',   // This is the column name of the referenced model
   }
 },

 // It is possible to add coments on columns for MySQL, PostgreSQL and MSSQL only
 commentMe: {
   type: Sequelize.INTEGER,
   comment: 'This is a column name that has a comment'
 }
})

</pre><pre>
【 node-uuid模块 】
nodejs生成UID(唯一标识符unique identifier),给某些数据定义一个唯一标识符,便于寻找、关联

使用：
1、uuid.v1();   基于时间戳生成(time-based)
2、uuid.v4();   随机生成(random)

通常使用基于时间戳v1()生成的UID,随机生成v4()还是有一定几率重复的。

var UUID = require('uuid');
var id = UUID.v1();
console.log(id);     // 57af5b10-3a76-11e5-922a-75f42afeee38
var id = UUID.v1();
console.log(id);     // f3917fb9-9bde-4ec1-a7cf-966251b3d22a

</pre>model-sequelize项目<pre class="js">
/* /config/config-default.js */
module.exports =  {
  database: 'nodejs',
  username: 'root',
  password: '',
  host: 'localhost',
  port: 3306,
  dialect: 'mysql'
};

/* /config/config-test.js */
module.exports = {
  database: 'nodejs',
  username: 'root',
  password: '',
  host: 'localhost',
  port: 3306,
  dialect: 'mysql'
};

/* /config.js */
// config.js
// 读取配置的时候用config.js实现不同环境读取不同的配置文件

// config-default.js： 存储默认的配置;
// config-override.js：存储特定的配置;
// config-test.js：    存储用于测试的配置

// 开发环境下,团队统一使用默认的配置,并且无需config-override.js。
// 部署到服务器时,由运维团队配置好config-override.js,以覆盖config-override.js的默认设置。
// 测试环境下,本地和CI服务器统一使用config-test.js,测试数据库可以反复清空,不会影响开发

const defaultConfig = './config/config-default.js';
const overrideConfig = './config/config-override.js';
const testConfig = './config/config-test.js';
const fs = require('fs');
var config = null;

if (process.env.NODE_ENV === 'test') {
  console.log(`Load ${testConfig}...`);
  config = require(testConfig);
} else {
  console.log(`Load ${defaultConfig}...`);
  config = require(defaultConfig);
  try {
    if (fs.statSync(overrideConfig).isFile()) {
      console.log(`Load ${overrideConfig}...`);
      config = Object.assign(config, require(overrideConfig));
    }
  } catch (err) {
    console.log(`Cannot load ${overrideConfig}.`);
  }
}

module.exports = config;

</pre><pre class="js">
/* /db.js的作用就是统一Model的定义 */

const Sequelize = require('sequelize');
const uuid = require('node-uuid');
const config = require('./config');
console.log('init sequelize...');

function generateId() {
  return uuid.v4();
}

var sequelize = new Sequelize(config.database, config.username, config.password, {
  host: config.host,
  dialect: config.dialect,
  pool: { max: 5, min: 0, idle: 10000 }
});

function defineModel(name, attributes) {
  var attrs = {};
  // 为每个字段增加allowNull属性,默认为false
  for (let key in attributes) {
    let value = attributes[key];
    if (typeof value === 'object' && value['type']) {
      value.allowNull = value.allowNull || false;
      attrs[key] = value;
    } else {
      attrs[key] = { type: value, allowNull: false };
    }
  }
  attrs.id = { type: Sequelize.STRING(50), primaryKey: true };
  attrs.createdAt = { type: Sequelize.BIGINT, allowNull: false };
  attrs.updatedAt = { type: Sequelize.BIGINT, allowNull: false };
  attrs.version = { type: Sequelize.BIGINT, allowNull: false };
  return sequelize.define(name, attrs, {
    tableName: name,
    timestamps: false,
    // Sequelize在创建、修改Entity时会调用通过hooks在定义Model时设定的指定的函数,
    // 在beforeValidate这个事件中根据是否是isNewRecord设置主键(如果主键为null或undefined)、设置时间戳和版本号,这样Model定义的时候就可以大大简化
    hooks: {
      beforeValidate: function (obj) {
        let now = Date.now();
        if (obj.isNewRecord) {
          console.log('will create entity...' + obj);
          if (!obj.id) obj.id = generateId();
          obj.createdAt = now;
          obj.updatedAt = now;
          obj.version = 0;
        } else {
          console.log('will update entity...');
          obj.updatedAt = now;
          obj.version++;
        }
      }
    }
  });
}

const TYPES = ['STRING', 'INTEGER', 'BIGINT', 'TEXT', 'DOUBLE', 'DATEONLY', 'BOOLEAN'];

var db = {
  defineModel: defineModel,
  generateId : generateId,
  // 自动创建数据表结构,在开发和生产环境中没有什么用,但是在测试环境中非常有用。
  // 这样可以随时修改Model的定义,并立刻运行测试。
  // 开发环境下,首次使用sync()也可以自动创建出表结构,避免了手动运行SQL的问题
  sync: () => {
    // only allow create ddl in non-production environment:
    if (process.env.NODE_ENV !== 'production') {
      return sequelize.sync({force: true})
        .then(res=> console.log(`models synced`))
        .catch(err=> console.error(`sync method error: ${err}`))
    } else {
      throw new Error('Cannot sync() when NODE_ENV is set to \'production\'.');
    }
  }
};

for (let type of TYPES) {
  db[type] = Sequelize[type];
}

module.exports = db;

</pre><pre class="js">
/* /models/First.js */
// 定义模型

const db = require('../db');
module.exports = db.defineModel('first', {
  email: {
    type: db.STRING(100),
    unique: true
  },
  passwd: db.STRING(100),
  name: db.STRING(100),
  gender: db.BOOLEAN
});

/* /models/Second.js */
const db = require('../db');
module.exports = db.defineModel('second', {
  ownerId: db.STRING(50),
  name: db.STRING(100),
  gender: db.BOOLEAN,
  birth: db.STRING(10),
});

/* /model.js */
// 自动扫描并导入所有Model

const fs = require('fs');
const db = require('./db');
let files = fs.readdirSync(__dirname + '/models');

let js_files = files.filter(f => f.endsWith('.js'));

for (let f of js_files) {
  console.log(`import model from file ${f}...`);
  let name = f.substring(0, f.length - 3);
  module.exports[name] = require(__dirname + '/models/' + f);
}

module.exports.sync = () => db.sync();

</pre><pre class="js">
/* /init-db.js */
// 需要model.js模块加载所有Model
const model = require('./model.js');

/* 采用数据自动同步时无法创建id字段？？？？？？？？ */

// 方法一
// 手动执行该模块,同步Model结构到数据库中,即在数据库中创建表,避免了手动维护一个SQL脚本
model.sync().then(() => process.exit(0));

// 方法二
// for(let name in model){
//  if(name != 'sync'){
//    model[name].sync({force: true})
//      .then(result => console.log(`model ${name} synced`, result))
//      .catch(err => console.error('model sync err: ', err) )
//  }
// }

</pre><pre class="js">
/* /app.js */
// mysql数据库CURD操作
let {First, Second} = require('./model');

(async () => {
  var user = await First.create({
    name: 'John',
    gender: false,
    email: 'john-' + Date.now() + '@garfield.pet',
    passwd: 'hahaha'
  });
  console.log('>> created: ' + JSON.stringify(user));
  var cat = await Second.create({
    ownerId: user.id,
    name: 'Garfield',
    gender: false,
    birth: '2007-07-07',
  });
  console.log('>> created: ' + JSON.stringify(cat));
  var dog = await Second.create({
    ownerId: user.id,
    name: 'Odie',
    gender: false,
    birth: '2008-08-08',
  });
  console.log('>> created: ' + JSON.stringify(dog));
})();


</pre>

<h3>Model</h3><pre class="js">
// config/config.js
module.exports = {
  mysql_dev: {
    host: 'localhost',
    user: 'root',
    password: '',
    database: 'nodejs',
    connectionLimit: 10,
    supportBigNumbers: true
  }
};

// model/database.js
var mysql = require('mysql');
var config = require('../config/config');
// 通过建立 mysql IP池 ,我们可以让连接循环利用,让nodejs跑得更欢快
exports.pool = mysql.createPool(config.mysql_dev);

// model/User.js
var db = require('./database');
var _ = require('underscore');

var User = function(){};

User.prototype.find = function(id, callback) {
  var sql = "SELECT * FROM users WHERE id =?";
  db.pool.getConnection(function(err, connection) {   // get a connection from the pool
    if (err) {
      callback(true);
      return;
    }
    connection.query(sql, [id], function(err, results) {
      if (err) {
        callback(true);
        return;
      }
      callback(false, results);
    });
  });
};

module.exports = User;

// app.js
var User = require('./models/User');

app.get('/users/:userid',function(req,res){
  var userid = req.params.userid;
  var user = new User();
  user.find(userid,function(err,result){
    if(err) res.send('not found');
    res.send(result.length === 1 ? result[0]:result);
  });
});

</pre>

<h3>数据库模型</h3><pre class="js">
// /model/db.js 数据库操作类,完成链接数据库和数据库的增删查改

/*查询*/
select:function(tableName,callback,where,field){
  field=field ? field:'*';
  var sql="select "+field+" from "+this.C.DB_PRE+tableName;
  if(where) sql+=" where "+where;
  this.db.query(sql,callback);
}

/*添加*/
add:function(tableName,tableData,callback){
  var sql="insert into "+this.C.DB_PRE+tableName;
  var clumn='';
  var value='';
  for(var key in tableData){
    clumn+=","+key;
    value+=",'"+tableData[key]+"'";
  }
  clumns="("+clumn.substr(1)+")";
  values="("+value.substr(1)+")";
  sql=sql+clumns+"values"+values;
  console.log(sql);
  this.db.query(sql,callback);
}

/*修改*/
update:function(tableName,tableData,where,callback){
  var sql="update "+this.C.DB_PRE+tableName+" set ";
  var clumns="";
  for(var key in tableData){
     clumns+=","+key+"='"+tableData[key]+"'";
  }
  clumns=clumns.substr(1);

  sql+=clumns+" where "+where;
  console.log(sql);
  this.db.query(sql,callback);
}

/*删除*/
delete:function(tableName,where,callback){
  var sql="delete from "+this.C.DB_PRE+tableName+" where "+where;
  console.log(sql);
  this.db.query(sql,callback);
}

// 业务模型,如分类模型,/model/category.js

/* 分类模型 */
module.exports={
  getAllList:function(){
    db.select("category",function(err,list){
      console.log(list);
    });
  },
  /*添加*/
  addCate:function(data){
    db.add("category",data,function(err,list){
      console.log(err);
    });
  },
  /*修改*/
  saveCate:function(data,where){
    db.update("category",data,where,function(err,list){
      console.log(err);
    });
  },
  /*删除*/
  delCate:function(where){
    db.delete("category",where,function(err,list){
      //console.log(err);
    });
  }
};

// 先在公共函数文件增加一个调用模型的方法

/*实例化模型*/
model:function(name){
  return require("../model/"+name);
}

// 控制器调用业务模型

/*  首页控制器 */
var router=express.Router();
router.get('/',function(req,res,next){
  F.model("category").getAllList();
  //F.model("category").addCate({"name":"测试"});
  //F.model("category").saveCate({"name":"测试1"},"id=4");
  //F.model("category").delCate("id=4");
  /*渲染模板*/
  res.render("home/index");
});
module.exports=router;

</pre>
</div>

<div id="wuxianji">
<h3>无限级分类和递归循环</h3><pre class="js">
INSERT INTO `cate` (`id`, `name`, `pid`) VALUES
('1', '国内商品',   '0'),
('2', '海淘',       '0'),
('3', '箱包服饰',   '1'),
('4', '数码电器',   '1'),
('5', '水果生鲜',   '1'),
('6', '笔记本电脑', '4'),
('7', '苹果',       '5'),
('8', '食品',       '2'),
('9', '个人护理',   '2'),
('10', '香蕉',      '8'),
('11', '洗面奶',    '5'),
('12', '自产',      '0'),
('13', '新鲜水果',  '5')

var mysql = require('mysql');
var pool = mysql.createPool({
  host: 'localhost', user: 'root', password: '', database: 'nodejs', connectionLimit: 10, supportBigNumbers: true
});

pool.getConnection((err, connection) => {   // get a connection from the pool
  if (err) return console.log(err);
  connection.query("select id, pid from cate", (err, results) => {
    if (err) return console.log(err);
    /*
    [
      {id:1,pid:2},{id:2,pid:0},{id:3,pid:2},{id:4,pid:43},{id:5,pid:2},{id:6,pid:2},{id:7,pid:0},{id:8,pid:0},{id:9,pid:1},{id:10,pid:1},
      {id:11,pid:1},{id:12,pid:1},{id:13,pid:1},{id:14,pid:1},{id:15,pid:0},{id:16,pid:1},{id:17,pid:102},{id:18,pid:43},{id:19,pid:43},{id:20,pid:3},
      {id:21,pid:3},{id:22,pid:43},{id:23,pid:43},{id:24,pid:5},{id:25,pid:43},{id:26,pid:43},{id:27,pid:43},{id:28,pid:4},{id:29,pid:4},{id:30,pid:4},
      {id:31,pid:43},{id:32,pid:111},{id:33,pid:5},{id:34,pid:43},{id:35,pid:5},{id:36,pid:88},{id:37,pid:43},{id:38,pid:43},{id:39,pid:43},{id:40,pid:6},
      {id:41,pid:70},{id:42,pid:6},{id:43,pid:0},{id:44,pid:43},{id:45,pid:43},{id:46,pid:8},{id:47,pid:8},{id:48,pid:43},{id:49,pid:8},{id:50,pid:43},
      {id:51,pid:67},{id:52,pid:125},{id:53,pid:43},{id:54,pid:43},{id:55,pid:124},{id:56,pid:0},{id:57,pid:6},{id:58,pid:6},{id:59,pid:111},{id:60,pid:43},
      {id:61,pid:43},{id:62,pid:56},{id:63,pid:43},{id:64,pid:4},{id:65,pid:43},{id:66,pid:43},{id:67,pid:102},{id:68,pid:43},{id:69,pid:4},{id:70,pid:102},
      {id:71,pid:56},{id:72,pid:124},{id:73,pid:43},{id:74,pid:43},{id:75,pid:8},{id:76,pid:17},{id:77,pid:43},{id:78,pid:0},{id:79,pid:43},{id:80,pid:43},
      {id:81,pid:103},{id:82,pid:15},{id:83,pid:17},{id:84,pid:3},{id:85,pid:15},{id:86,pid:3},{id:87,pid:43},{id:88,pid:43},{id:89,pid:111},{id:90,pid:43},
      {id:91,pid:15},{id:92,pid:6},{id:93,pid:6},{id:94,pid:43},{id:95,pid:53},{id:96,pid:103},{id:97,pid:111},{id:98,pid:6},{id:99,pid:70},{id:100,pid:15},
      {id:101,pid:6},{id:102,pid:0},{id:103,pid:43},{id:104,pid:103},{id:105,pid:103},{id:106,pid:103},{id:107,pid:7},{id:108,pid:7},{id:109,pid:7},{id:110,pid:7},
      {id:111,pid:102},{id:112,pid:8},{id:113,pid:1},{id:114,pid:103},{id:115,pid:103},{id:116,pid:43},{id:117,pid:43},{id:118,pid:43},{id:119,pid:125},{id:120,pid:111},
      {id:121,pid:70},{id:122,pid:111},{id:123,pid:70},{id:124,pid:8},{id:125,pid:8},{id:126,pid:124},{id:127,pid:125},{id:128,pid:88},{id:129,pid:43},{id:130,pid:3},
      {id:131,pid:43},{id:132,pid:43},{id:133,pid:86},{id:134,pid:21},{id:135,pid:21},{id:136,pid:86},{id:137,pid:20},{id:138,pid:20}
    ]
    */

    /* 获取分类ID: 8的所有下级分类的ID */
    var idPidMap = {};
    results.forEach(result => idPidMap[result.id] = result.pid)
    /*
    {
      '1': 2,'2': 0,'3': 2,'4': 43,'5': 2,'6': 2,'7': 0,'8': 0,'9': 1,'10': 1,
      '11': 1,'12': 1,'13': 1,'14': 1,'15': 0,'16': 1,'17': 102,'18': 43,'19': 43,'20': 3,
      '21': 3,'22': 43,'23': 43,'24': 5,'25': 43,'26': 43,'27': 43,'28': 4,'29': 4,'30': 4,
      '31': 43,'32': 111,'33': 5,'34': 43,'35': 5,'36': 88,'37': 43,'38': 43,'39': 43,'40': 6,
      '41': 70,'42': 6,'43': 0,'44': 43,'45': 43,'46': 8,'47': 8,'48': 43,'49': 8,'50': 43,
      '51': 67,'52': 125,'53': 43,'54': 43,'55': 124,'56': 0,'57': 6,'58': 6,'59': 111,'60': 43,
      '61': 43,'62': 56,'63': 43,'64': 4,'65': 43,'66': 43,'67': 102,'68': 43,'69': 4,'70': 102,
      '71': 56,'72': 124,'73': 43,'74': 43,'75': 8,'76': 17,'77': 43,'78': 0,'79': 43,'80': 43,
      '81': 103,'82': 15,'83': 17,'84': 3,'85': 15,'86': 3,'87': 43,'88': 43,'89': 111,'90': 43,
      '91': 15,'92': 6,'93': 6,'94': 43,'95': 53,'96': 103,'97': 111,'98': 6,'99': 70,'100': 15,
      '101': 6,'102': 0,'103': 43,'104': 103,'105': 103,'106': 103,'107': 7,'108': 7,'109': 7,'110': 7,
      '111': 102,'112': 8,'113': 1,'114': 103,'115': 103,'116': 43,'117': 43,'118': 43,'119': 125,'120': 111,
      '121': 70,'122': 111,'123': 70,'124': 8,'125': 8,'126': 124,'127': 125,'128': 88,'129': 43,'130': 3,
      '131': 43,'132': 43,'133': 86,'134': 21,'135': 21,'136': 86,'137': 20,'138': 20
    }
    */

    var bmid = 8;
    var pidSet = new Set([bmid]);           // Set数据结构内的成员的值都是唯一的
    do {
      var len = pidSet.size;
      for(var id in idPidMap) {
        if (pidSet.has(idPidMap[id])) {     // 遍历idPidMap时id对应的pid是否为Set的成员
          pidSet.add(Number(id));
          delete idPidMap[id];
        }
      }
    } while (pidSet.size > len);
    console.log(Array.from(pidSet));        // [ 8, 46, 47, 49, 75, 112, 124, 125, 126, 127, 52, 55, 72, 119 ]

    /* 通过子分类 ID = 13 查找最顶级父分类 */
    // 查询后将结果处理成如下php数组格式 // id => pid 建议将这数组缓存起来
    var arr = [0];
    results.forEach((result, index) => arr.push(result.pid))  // [0,2,0,2,43,2,...]
    var id = 13;
    while(arr[id]) {
      id = arr[id];
    }
    console.log(id);     // 2
  });
});

</pre>
</div>

<div id="mongodb">
<h2>mongodb</h2><pre>
计算机硬件的运算速度将不再是影响计算机性能的主要因素,一套系统的瓶颈往往出现在对于各种I/O的使用、控制、管理和优化上。这些I/O包括内存I/O、磁盘I/O、网络I/O等。一个数据库的I/O往往会包含内存、磁盘和网络三个层次的I/O

关系数据库管理系统RDBMS(Relational Database Management System)
非关系型的数据库NoSQL(NoSQL = Not Only SQL)

分布式系统(distributed system)由多台计算机和通信的软件组件通过计算机网络连接(本地网络或广域网)组成。
分布式系统是建立在网络之上的软件系统。正是因为软件的特性,所以分布式系统具有高度的内聚性和透明性。
因此,网络和分布式系统之间的区别更多的在于高层软件(特别是操作系统),而不是硬件。
分布式系统可以应用在不同的平台上如：Pc、工作站、局域网和广域网上等

NoSQL数据库分类
列存储  Hbase,Cassandra,Hypertable
按列存储数据的。最大的特点是方便存储结构化和半结构化数据,方便做数据压缩,对针对某一列或者某几列的查询有非常大的IO优势。

文档存储 MongoDB,CouchDB
文档存储一般用类似json的格式存储,存储的内容是文档型的。这样也就有有机会对某些字段建立索引,实现关系数据库的某些功能。

key-value存储 Tokyo Cabinet / Tyrant,Berkeley DB,MemcacheDB,Redis
可以通过key快速查询到其value,一般来说存储不管value的格式照单全收。(Redis包含了其他功能)

图存储 Neo4J,FlockDB
图形关系的最佳存储。使用传统关系数据库来解决的话性能低下,而且设计使用不方便。

对象存储  db4o,Versant
通过类似面向对象语言的语法操作数据库,通过对象的方式存取数据。

xml数据库 Berkeley DB XML,BaseX
高效的存储XML数据,并支持XML的内部查询语法,比如XQuery,Xpath。

【 MongoDB 】
MongoDB是基于分布式文件存储的开源数据库系统,由C++语言编写,为WEB应用提供可扩展的高性能数据存储解决方案
MongoDB是一个介于关系数据库和非关系数据库之间的产品,是非关系数据库当中功能最丰富、最像关系数据库的
在高负载的情况下,添加更多的节点,可以保证服务器性能

MongoDB将数据存储为一个文档,因此被称为面向文档的数据库,MongoDB文档类似于JSON对象,字段值可包含其他文档、数组及文档数组,数据结构由键值(key=>value)对组成。

特点：
MongoDB提供一个面向文档存储,操作起来比较简单和容易
可以在MongoDB记录中设置任何属性的索引(如：FirstName="Sameer",Address="8 Gandhi Road")来实现更快的排序
可以通过本地或网络创建数据镜像,这使得MongoDB有更强的扩展性
如果负载的增加(需要更多的存储空间和更强的处理能力) ,它可以分布在计算机网络中的其他节点上这就是所谓的分片
Mongo支持丰富的查询表达式,查询指令使用JSON形式的标记,可轻易查询文档中内嵌的对象及数组
MongoDb使用update()命令可以实现替换完成的文档(数据)或一些指定的数据字段
Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作
Map和Reduce,Map函数调用emit(key,value)遍历集合中所有的记录,将key与value传给Reduce函数进行处理。
Map函数和Reduce函数是使用Javascript编写的,并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。
GridFS是MongoDB中的一个内置功能,可以用于存放大量小文件。
MongoDB允许在服务端执行脚本,可以用Javascript编写某个函数,直接在服务端执行,也可以把函数的定义存储在服务端,下次直接调用即可。
MongoDB支持各种编程语言:RUBY,PYTHON,JAVA,C++,PHP,C#,nodejs,javascript,c,c++等多种语言

【 MongoDB的管理工具 】
监控
MongoDB提供了网络和系统监控工具Munin,它作为一个插件应用于MongoDB中。
Gangila是MongoDB高性能的系统监视的工具,它作为一个插件应用于MongoDB中。
基于图形界面的开源工具 Cacti, 用于查看CPU负载, 网络带宽利用率,它也提供了一个应用于监控 MongoDB 的插件。
GUI
Fang of Mongo – 网页式,由Django和jQuery所构成。
Futon4Mongo – 一个CouchDB Futon web的mongodb山寨版。
Mongo3 – Ruby写成。
MongoHub – 适用于OSX的应用程序。
Opricot – 一个基于浏览器的MongoDB控制台, 由PHP撰写而成。
Database Master — Windows的mongodb管理工具
RockMongo — 最好的PHP语言的MongoDB管理工具,轻量级, 支持多国语言.

【 mongodb bin目录 .exe 】
mongo.exe：客户端,支持js语法,print("hello")
mongod.exe：服务端,启动后可以在http://localhost:27017/查看连接提示
mongodump.exe：备份工具
mongorestore.exe：恢复工具
mongoexport.exe：导出工具
mongoimport.exe：导入工具
mongostat.exe：实时性能监控工具
mongotop.exe：跟踪MongDB实例读写时间工具

服务器端 mongod  使用MongoDB shell来连接MongoDB服务器
客户端   mongo

database     database       数据库
table        collection     数据库表/集合
row          document       数据记录行/文档
column       field          数据字段/域
index        index          索引
table joins  嵌入文档       表连接,MongoDB不支持
primary key  primary key    主键,MongoDB自动将_id字段设置为主键

database：
MongoDB的默认数据库为"db",该数据库存储在data目录中。
MongoDB的单个实例可以容纳多个独立的数据库,每一个都有自己的集合和权限,不同的数据库也放置在不同的文件中

【 文档 一组有序的键值(key-value)对(即BSON) field: value 】
MongoDB将信息存储在BSON(二进制JSON)中。BSON是一种类JSON二进制形式的存储格式,简称Binary JSON,和JSON一样支持内嵌的文档对象和数组对象,但BSON有JSON没有的一些数据类型,如Date和BinData类型

MongoDB的文档不需要设置相同的字段,并且相同的字段不需要相同的数据类型,与关系型数据库有很大的区别
{"site":"www.runoob.com", "name":"菜鸟教程"}

MongoDB区分类型和大小写
文档键名是字符串,不能重复,除了少数例外情况,键可以使用任意UTF-8字符
文档中的值不仅可以是在双引号里面的字符串,还可以是其他几种数据类型(甚至可以是整个嵌入的文档)。

文档键命名规范：
键不能含有\0 (空字符)。这个字符用来表示键的结尾。
.和$有特别的意义,只有在特定环境下才能使用。
以下划线"_"开头的键是保留的(不是严格要求的)

</pre><pre class="js">
{
  _id: ObjectId(7df78ad8902c)
  title: 'MongoDB Overview',
  description: 'MongoDB is no sql database',
  by: 'yiibai tutorial',
  url: 'http://www.yiibai.com',
  tags: ['mongodb', 'database', 'NoSQL'],
  likes: 100,
  comments: [
    {
      user:'user1',
      message: 'My first comment',
      dateCreated: new Date(2011,1,20,2,15),
      like: 0
    },
    {
      user:'user2',
      message: 'My second comments',
      dateCreated: new Date(2011,1,25,7,45),
      like: 5
    }
  ]
}

</pre><pre>
【 集合 MongoDB文档组类似于RDBMS中的表格 】
当第一个文档插入时集合就会被创建
集合存在于数据库中,集合没有固定的结构,即在对集合可以插入不同格式和类型的数据,但通常插入集合的数据都会有一定的关联性
{"site":"www.baidu.com"}
{"site":"www.google.com","name":"Google"}
{"site":"www.runoob.com","name":"菜鸟教程","num":5}

集合名命名规范：
集合名不能是空字符串""
集合名不能含有\0字符(空字符),这个字符表示集合名的结尾
集合名不能以"system."开头,这是为系统集合保留的前缀
用户创建的集合名字不能含有保留字符。有些驱动程序的确支持在集合名里面包含,这是因为某些系统生成的集合中包含该字符。除非你要访问这种系统创建的集合,否则千万不要在名字里出现$
例：db.col.findOne()

Capped collections是固定大小的collection
有很高的性能以及队列过期的特性(过期按照插入的顺序),有点和 "RRD" 概念类似
Capped collections是高性能自动的维护对象的插入顺序,非常适合类似记录日志的功能
和标准的collection不同,必须要显式的创建一个capped collection,指定一个collection的大小,单位是字节
collection的数据存储空间值提前分配的
要注意的是指定的存储大小包含了数据库的头信息

db.createCollection("mycoll", {capped:true, size:100000})

在capped collection中能添加新的对象
能进行更新,然而对象不会增加存储空间,如果增加更新就会失败
数据库不允许进行删除。使用drop()方法删除collection所有的行。
删除之后必须显式的重新创建这个collection。
在32bit机器中capped collection最大存储为1e9(1X109)个字节

【 元数据 】
数据库的信息是存储在集合中,它们使用了系统的命名空间：dbname.system.*

在MongoDB数据库中名字空间＜dbname＞.system.* 是包含多种系统信息的特殊集合(Collection),如下:
集合命名空间  描述
dbname.system.namespaces  列出所有名字空间
dbname.system.indexes     列出所有索引
dbname.system.profile     包含数据库概要(profile)信息
dbname.system.users       列出所有可访问数据库的用户
dbname.local.sources      包含复制对端(slave)的服务器信息和状态

对于修改系统集合中的对象有如下限制:
在{{system.indexes}}插入数据,可以创建索引。但除此之外该表信息是不可变的(特殊的drop index命令将自动更新相关信息)。
{{system.users}}是可修改的。 {{system.profile}}是可删除的

【 MongoDB 数据类型 】
String        字符串;存储数据常用的数据类型。在 MongoDB 中,UTF-8 编码的字符串才是合法的
Integer       整型数值;用于存储数值。根据你所采用的服务器,可分为 32 位或 64 位
Boolean       布尔值;用于存储布尔值(真/假)
Double        双精度浮点值;用于存储浮点值
Min/Max keys  将一个值与 BSON(二进制的 JSON)元素的最低值和最高值相对比
Array         用于将数组或列表或多个值存储为一个键
Timestamp     时间戳;记录文档修改或添加的具体时间
Object        用于内嵌文档
Null          用于创建空值
Symbol        符号;该数据类型基本上等同于字符串类型,但不同的是它一般用于采用特殊符号类型的语言
Date          日期时间;用UNIX时间格式来存储当前日期或时间,可指定自己的日期时间:创建Date对象,传入年月日信息
Object ID     对象ID,用于创建文档的ID
Binary Data   二进制数据;用于存储二进制数据
Code          代码类型;用于在文档中存储JavaScript代码
Regular expression  正则表达式类型;用于存储正则表达式

mongo中的date类型以UTC(Coordinated Universal Time)存储,就等于GMT(格林尼治标准时)时间,而系统时间使用的是GMT+0800(东8区)时间,两者正好相差8个小时,CST(China Standard Time中国标准时)
在从数据库读取到时间以后使用new Date(time)方法可以自动转化为当前时区时间

</pre><pre class="js">
function toEast8(utc){
  return new Date(new Date(utc).getTime() + 8*60*60*1000)
}

console.log(typeof doc.logindate, doc.logindate);  // object 2017-12-13T08:21:23.425Z
console.time('change')
var time = toEast8(doc.logindate)
console.timeEnd('change')         // 3.383ms
console.log(typeof time, time);   // object 2017-12-13T16:21:23.425Z

// 直接加上时差的毫秒数
var plus = doc.logindate + 8*60*60*1000;
console.log('plus', typeof plus, plus); //string Wed Dec 13 2017 16:21:23 GMT+0800 (中国标准时间)28800000

</pre><pre>
Date.now只是一个函数,每次调用时才会生成一个时间,Date.now()是传递的一个时间
mongoose定义Schema时不是default: new Date()而是default: Date.now,default应该是固定值或函数名

</pre><pre class="js">
db.date.insert([
  {name: 'Date()', time: Date()},
  {name: 'new Date()', time: new Date()},
  {name: 'ISODate()', time: ISODate()}
])

db.date.insert({name: 'Date now', time: Date now()})                   // 不能插入保存 ？？？？？

db.date.find({},{_id:0})
{ "name" : "Date()", "time" : "Wed Dec 13 2017 14:32:29 GMT+0800" }     // 包含时区数据的字符串
{ "name" : "new Date()", "time" : ISODate("2017-12-13T06:32:29.347Z") } // ISODate类型的日期对象
{ "name" : "ISODate()", "time" : ISODate("2017-12-13T06:32:29.347Z") }

db.date.insert([
  {name: 'ISODate', time: ISODate('2017-12-13 14:36:32')},
  {name: 'ISODate', time: ISODate('20171213 14:36:32')},
  {name: 'ISODate', time: ISODate('20171213')}
])

db.date.find({name: 'ISODate'},{_id:0})
{ "name" : "ISODate", "time" : ISODate("2017-12-13T14:36:32Z") }
{ "name" : "ISODate", "time" : ISODate("2017-12-13T14:36:32Z") }
{ "name" : "ISODate", "time" : ISODate("2017-12-13T00:00:00Z") }

db.date.insert([
  {name: 'new Date', time: new Date('2017-12-13 14:36:32')},
  {name: 'new Date', time: new Date('20171213 14:36:32')},
  {name: 'new Date', time: new Date('20171213')}
])

db.date.find({name: 'new Date'},{_id:0})
{ "name" : "new Date", "time" : ISODate("1970-01-01T00:00:00Z") }
{ "name" : "new Date", "time" : ISODate("1970-01-01T00:00:00Z") }
{ "name" : "new Date", "time" : ISODate("1970-01-01T00:00:00Z") }

</pre><pre>
【 mongodb基本配置 】
--config / -f：指定配置文件,加载命令行未指定的各种选项
--httpinterface --rest 开启http管理接口参数
-v、-vv、-vvv、-vvvv、-vvvvv 指定日志的级别,日志级别越大,输出的日志越详细,调至5时,这时mongod会在日志中记录几乎所有的操作,包括每一个请求所处理的内容
MongoDB默认记录耗时超过100毫秒的查询信息。如果100毫秒不适合需求,可以通过setProfilingLevel命令来改变,下面这条命令表示记录查询时间超过500毫秒的消息
> db.setProfilingLevel(1,500)
{ "was" : 0, "slowms" : 100, "ok" : 1 }

如果想要日志分割(如按天存放)有两种方法
方法一：每天定时的执行kill -USR1 进程号,每执行一次kill -USR1 进程号,那么就会重新生成一个日志文件
方法二：在MongoDB的shell行执行,每执行一次都会产生一个新的日志文件
> db.adminCommand({"logRotate":1})
{ "ok" : 1 }
要使分割日志生效,必须启动的时候使用--logpath,然后可以根据自己的需求,写shell或python脚本,然后crontab做成定时任务

--quiet           # 安静输出
--port arg        # 指定服务端口号,默认端口27017
--bind_ip arg     # 绑定服务IP,若绑定127.0.0.1,则只能本机访问,不指定默认本地所有IP
--logpath arg     # 指定MongoDB日志文件,注意是指定文件不是目录
--logappend       # 使用追加的方式写日志
--pidfilepath arg # PID File 的完整路径,如果没有设置,则没有PID文件
--keyFile arg     # 集群的私钥的完整路径,只对于Replica Set 架构有效
--unixSocketPrefix arg  # UNIX域套接字替代目录,(默认为 /tmp)
--fork            # 以守护进程的方式运行MongoDB,创建服务器进程
--auth            # 启用验证
--cpu             # 定期显示CPU的CPU利用率和iowait
--dbpath arg      # 指定数据库路径
--diaglog arg     # diaglog选项 0=off 1=W 2=R 3=both 7=W+some reads
--directoryperdb  # 设置每个数据库将被保存在一个单独的目录
--journal         # 启用日志选项,MongoDB的数据操作将会写入到journal文件夹的文件里
--journalOptions arg  # 启用日志诊断选项
--ipv6            # 启用IPv6选项
--jsonp           # 允许JSONP形式通过HTTP访问(有安全影响)
--maxConns arg    # 最大同时连接数 默认2000
--noauth          # 不启用验证
--nohttpinterface # 关闭http接口,默认关闭27018端口访问
--noprealloc      # 禁用数据文件预分配(往往影响性能)
--noscripting     # 禁用脚本引擎
--notablescan     # 不允许表扫描
--nounixsocket    # 禁用Unix套接字监听
--nssize arg (=16)  # 设置信数据库.ns文件大小(MB)
--objcheck        # 在收到客户数据,检查的有效性,
--profile arg     # 档案参数 0=off 1=slow, 2=all
--quota           # 限制每个数据库的文件数,设置默认为8
--quotaFiles arg  # number of files allower per db, requires --quota
--rest            # 开启简单的rest API
--repair          # 修复所有数据库run repair on all dbs
--repairpath arg  # 修复库生成的文件的目录,默认为目录名称dbpath
--slowms arg (=100) # value of slow for profile and console log
--smallfiles      # 使用较小的默认文件
--syncdelay arg (=60) # 数据写入磁盘的时间秒数(0=never,不推荐)
--sysinfo         # 打印一些诊断系统信息
--upgrade         # 如果需要升级数据库  * Replicaton 参数
--------------------------------------------------------------------------------
--fastsync        # 从一个dbpath里启用从库复制服务,该dbpath的数据库是主库的快照,可用于快速启用同步
--autoresync      # 如果从库与主库同步数据差得多,自动重新同步,
--oplogSize arg   # 设置oplog的大小(MB)  * 主/从参数
--------------------------------------------------------------------------------
--master          # 主库模式
--slave           # 从库模式
--source arg      # 从库 端口号
--only arg        # 指定单一的数据库复制
--slavedelay arg  # 设置从库同步主库的延迟时间  * Replica set(副本集)选项：
--------------------------------------------------------------------------------
--replSet arg     # 设置副本集名称  * Sharding(分片)选项
--------------------------------------------------------------------------------
--configsvr       # 声明这是一个集群的config服务,默认端口27019,默认目录/data/configdb
--shardsvr        # 声明这是一个集群的分片,默认端口27018
--noMoveParanoia  # 关闭偏执为moveChunk数据保存

# 上述参数都可以写入mongod.conf配置文档里例如：
dbpath = /data/mongodb
logpath = /data/mongodb/mongodb.log
logappend = true
port = 27017
fork = true
auth = true

e.g：./mongod -shardsvr -replSet shard1 -port 16161 -dbpath /data/mongodb/data/shard1a -oplogSize 100 -logpath /data/mongodb/logs/shard1a.log -logappend -fork -rest

General options:
  -h [ --help ]                         show this usage information
  --version                             show version information
  -f [ --config ] arg                   configuration file specifying additional options
  -v [ --verbose ] [=arg(=v)]           be more verbose (include multiple times for more verbosity e.g. -vvvvv)
  --quiet                               quieter output
  --port arg                            specify port number - 27017 by default
  --bind_ip arg                         comma separated list of ip addresses to listen on - all local ips by default
  --ipv6                                enable IPv6 support (disabled by default)
  --maxConns arg                        max number of simultaneous connections - 1000000 by default
  --logpath arg                         log file to send write to instead of stdout - a file, not directory
  --logappend                           append to logpath instead of over-writing
  --logRotate arg                       set the log rotation behavior (rename|reopen)
  --timeStampFormat arg                 timestamps in log messages. ctime, iso8601-utc or iso8601-local
  --pidfilepath arg                     full path to pidfile (if not set, no pidfile is created)
  --keyFile arg                         private key for cluster authentication
  --noauth                              run without security
  --setParameter arg                    Set a configurable parameter
  --httpinterface                       enable http interface
  --transitionToAuth                    For rolling access control upgrade. Attempt to authenticate over outgoing
                                        connections and proceed regardless of success. Accept incoming connections
                                        with or without authentication.
  --clusterAuthMode arg                 Authentication mode used for cluster authentication. Alternatives are
                                        (keyFile|sendKeyFile|sendX509|x509)
  --networkMessageCompressors arg       Comma-separated list of compressors to use for network messages
  --auth                                run with security
  --jsonp                               allow JSONP access via http (has security implications)
  --rest                                turn on simple rest api
  --slowms arg (=100)                   value of slow for profile and console log
  --profile arg                         0=off 1=slow, 2=all
  --cpu                                 periodically show cpu and iowait utilization
  --sysinfo                             print some diagnostic system information
  --noIndexBuildRetry                   don't retry any index builds that were interrupted by shutdown
  --noscripting                         disable scripting engine
  --notablescan                         do not allow table scans

Windows Service Control Manager options:
  --install                             install Windows service
  --remove                              remove Windows service
  --reinstall                           reinstall Windows service (equivalent to --remove followed by --install)
  --serviceName arg                     Windows service name
  --serviceDisplayName arg              Windows service display name
  --serviceDescription arg              Windows service description
  --serviceUser arg                     account for service execution
  --servicePassword arg                 password used to authenticate serviceUser

Replication options:
  --oplogSize arg       size to use (in MB) for replication op log. default is 5% of disk space (i.e.large is good)

Master/slave options (old; use replica sets instead):
  --master                              master mode
  --slave                               slave mode
  --source arg                          when slave: specify master as server:port
  --only arg                            when slave: specify a single database to replicate
  --slavedelay arg                      specify delay (in seconds) to be used when applying master ops to slave
  --autoresync                          automatically resync if slave data is stale

Replica set options:
  --replSet arg                         arg is  setname [/ optionalseedhostlist  ]
  --replIndexPrefetch arg               specify index prefetching behavior (if secondary) [none|_id_only|all]
  --enableMajorityReadConcern           enables majority readConcern

Sharding options:
  --configsvr               declare this is a config db of a cluster; default port 27019; default dir /data/configdb
  --shardsvr                            declare this is a shard db of a cluster; default port 27018

SSL options:
  --sslOnNormalPorts                    use ssl on configured ports
  --sslMode arg                         set the SSL operation mode (disabled|allowSSL|preferSSL|requireSSL )
  --sslPEMKeyFile arg                   PEM file for ssl
  --sslPEMKeyPassword arg               PEM file password
  --sslClusterFile arg                  Key file for internal SSL authentication
  --sslClusterPassword arg              Internal authentication key file password
  --sslCAFile arg                       Certificate Authority file for SSL
  --sslCRLFile arg                      Certificate Revocation List file for SSL
  --sslDisabledProtocols arg            Comma separated list of TLS protocols to disable [TLS1_0,TLS1_1,TLS1_2]
  --sslWeakCertificateValidation        allow client to connect without presenting a certificate
  --sslAllowConnectionsWithoutCertificates allow client to connect without presenting a certificate
  --sslAllowInvalidHostnames            Allow server certificates to provide non-matching hostnames
  --sslAllowInvalidCertificates         allow connections to servers with invalid certificates
  --sslFIPSMode                         activate FIPS 140-2 mode at startup

Storage options:
  --storageEngine arg                   defaults to wiredTiger if no data files present
  --dbpath arg                    directory for datafiles - defaults to \data\db\ based on the current working drive
  --directoryperdb                      each database will be stored in a separate directory
  --noprealloc                          disable data file preallocation - will often hurt performance
  --nssize arg (=16)                    .ns file size (in MB) for new databases
  --quota                               limits each database to a certain number of files (8 default)
  --quotaFiles arg                      number of files allowed per db, implies --quota
  --smallfiles                          use a smaller default file size
  --syncdelay arg (=60)                 seconds between disk syncs (0=never, but not recommended)
  --upgrade                             upgrade db if needed
  --repair                              run repair on all dbs
  --repairpath arg                      root directory for repair files - defaults to dbpath
  --journal                             enable journaling
  --nojournal                           disable journaling (journaling is on by default for 64 bit)
  --journalOptions arg                  journal diagnostic options
  --journalCommitInterval arg           how often to group/batch commit (ms)

WiredTiger options:
  --wiredTigerCacheSizeGB arg       maximum amount of memory to allocate for cache; defaults to 1/2 of physical RAM
  --wiredTigerStatisticsLogDelaySecs arg (=0)
               seconds to wait between each write to a statistics file in the dbpath; 0 means do not log statistics
  --wiredTigerJournalCompressor arg (=snappy)         use a compressor for log records [none|snappy|zlib]
  --wiredTigerDirectoryForIndexes                     Put indexes and data in different directories
  --wiredTigerCollectionBlockCompressor arg (=snappy) block compression algorithm for collection data [none|snappy|zlib]
  --wiredTigerIndexPrefixCompression arg (=1)         use prefix compression on row-store leaf pages

</pre><pre>
【 mongodb连接 】
标准URI连接语法：
mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]
mongodb://         固定的格式,必须要指定
username:password@ 可选项,如果设置,在连接数据库服务器之后,驱动都会尝试登陆这个数据库
host1              必须的指定至少一个host,host1 是这个URI唯一要填写的。指定了要连接服务器的地址
                   如果要连接复制集,请指定多个主机地址
portX              可选的指定端口,如果不填,默认为27017
/database          如果指定username:password@,连接并验证登陆指定数据库。若不指定默认打开test数据库
?options           连接选项,如果不使用/database,则前面需要加上/
                  所有连接选项都是键值对name=value,键值对之间通过&或;(分号)隔开

标准的连接格式包含多个选项(options):
replicaSet=name
验证replica set的名称。 Impliesconnect=replicaSet.

slaveOk=true|false
true:在connect=direct模式下,驱动会连接第一台机器,即使这台服务器不是主。在connect=replicaSet模式下,驱动会发送所有的写请求到主并且把读取操作分布在其他从服务器。
false: 在 connect=direct模式下,驱动会自动找寻主服务器. 在connect=replicaSet 模式下,驱动仅仅连接主服务器,并且所有的读写命令都连接到主服务器

safe=true|false
true: 在执行更新操作之后,驱动都会发送getLastError命令来确保更新成功。(还要参考 wtimeoutMS).
false: 在每次更新之后,驱动不会发送getLastError来确保更新成功。

w=n
驱动添加 { w:n } 到getLastError命令. 应用于safe=true

wtimeoutMS=ms
驱动添加 { wtimeout:ms } 到 getlasterror 命令. 应用于 safe=true

fsync=true|false
true: 驱动添加 { fsync:true } 到 getlasterror 命令.应用于 safe=true.
false: 驱动不会添加到getLastError命令中

journal=true|false
如果设置为 true, 同步到 journal (在提交到数据库前写入到实体中). 应用于 safe=true

connectTimeoutMS=ms
可以打开连接的时间

socketTimeoutMS=ms
发送和接受sockets的时间

</pre>
</div>

<div id="CURD">
<h3>数据库操作命令</h3><pre>
1、直接启动mongodb
mongod --dbpath=E:\soft\mongodb\data\db
mongod --dbpath=E:\soft\mongodb\data\db --logpath=E:\soft\mongodb\data\log\mongodb.log --logappend --rest --httpinterface

2、配置文件启动mongodb
mongod -f E:\soft\mongodb\mongod.conf

// E:\soft\mongodb\mongod.conf
dbpath=E:\soft\mongodb\data\db
logpath=E:\soft\mongodb\data\log\mongodb.log
logappend=true
port=27017
auth=false
httpinterface=true
rest=true

3、windows service方式启动mongod
在mongodb里面提供了一个叫做"服务寄宿"的模式,以管理员身份运行cmd或powershell
mongod --dbpath=E:\soft\mongodb\data\db --logpath=E:\soft\mongodb\data\log\mongodb.log --logappend --port 27017 --rest --httpinterface --install --serviceName "mongodb"

>net start mongodb   (开启服务)
>net stop mongodb   (关闭服务)

重启服务,添加验证模式,--reinstall 等效于 --remove --install
mongod --dbpath=E:\soft\mongodb\data\db --logpath=E:\soft\mongodb\data\log\mongodb.log --logappend --port 27017 --rest --httpinterface --auth --reinstall --serviceName "mongodb"

删除
mongod --dbpath=E:\soft\mongodb\data\db --logpath=E:\soft\mongodb\data\log\mongodb.log --logappend --port 27017 --remove --serviceName "mongodb"

mongod --remove

logpath: 当我们使用服务寄宿的时候指定目录来记载日志信息
install: 开启安装服务寄宿,把管理员的手工操作降低到最小

4、守护进程方式启动mongod  *****--fork不支持windows 解决可以通过添加mongodb为windows服务来解决
指定日志输出路径,而不是输出到命令行。如果对文件夹有写权限的话,系统会在文件不存在时创建它
--fork 以守护进程方式运行MongoDB,创建服务器进程
mongod --fork --dbpath "E:\soft\mongodb\data\db" --logpath "E:\soft\mongodb\data\log\MongoDB.log" --port 27017
forked process : 44086
all output going to : MongoDB.log

4、停止MongoDB
方法一：查看进程,使用kill命令;不能使用kill -9
最稳妥的方式,在客户端处理完当前所有操作并将缓存的数据保存到磁盘上才停止
>user admin
>db.shutdownServer();
在主节点(primary)上运行shutdown命令时,服务器在关闭之前,会先等待备份节点追赶主节点以保持同步。这将回滚的可能性降至最低,但shutdown操作有失败的可能性。如几秒钟内没有备份节点成功同步,则shutdown操作失败,主节点不会停止运行
当然我们也可以直接关闭进程,但这种方式会导致缓存中的数据未急时刷新保存到磁盘上而丢失

【 控制台命令 】
与MySQL不同的是MongoDB会自动创建数据库和集合,所以使用前不需要手动去创建
MongoDB的默认数据库是test,如果没有创建任何数据库,那么集合将被保存在测试数据库

mongod --help               查看mongod启动命令配置选项
mongo  --help
db.shutdownServer()         mongo关闭mongod
db.version()
db.help()
db.stats()                  获取有关MongoDB服务器的统计信息,数据库名称,数据库中的集合和文档数量
show dbs                    显示所有数据的列表
db                          显示当前数据库对象或集合
use blog                    连接到一个指定的数据库;使用数据库之前不需要创建,系统会自动创建
db.dropDatabase()           删除当前选定的数据库,若没有选择任何数据库则会删除默认的"test"数据库
show tables                 显示当前数据库下的所有表
show collections            显示当前数据库下的全部集合
db.createCollection("user") 插入数据时如果集合不存在会自动创建集合再插入
db.user.drop()              删除User集合
db.user.renameCollection("users") 重命名集合
db.runCommand({renameCollection: "test.user", to: "test.users"} 重命名数据库,循环改名,不能用于分片集
{renameCollection: "source_namespace", to: "target_namespace", dropTarget: true|false} 默认true

重命名数据库：拷贝数据之后再删除原数据库,数据量大时慢
db.copyDatabase('old_name', 'new_name');
use old_name
db.dropDatabase();

【 MongoDB 固定集合(Capped Collections) 】
MongoDB 固定集合(Capped Collections)是性能出色且有固定大小的集合,类似一个环形队列,当集合空间用完后再插入的元素就会覆盖最初始的头部的元素

创建固定合集
>db.createCollection("cappedLogCollection",{capped:true,size:10000,max:1000})
可选属性参数max指定文档个数

判断集合是否为固定集合:
>db.cappedLogCollection.isCapped()

如果需要将已存在的集合转换为固定集合可以使用以下命令：
>db.runCommand({"convertToCapped":"posts",size:10000})

固定集合查询
固定集合文档按照插入顺序储存的,默认情况下查询就是按照插入顺序返回的,也可以使用$natural调整返回顺序
>db.cappedLogCollection.find().sort({$natural:-1})

可以插入及更新,但更新不能超出collection的大小,否则更新失败,不允许删除,但是可以调用drop()删除集合中的所有行,但是drop后需要显式地重建集合。
在32位机子上一个cappped collection的最大值约为482.5M,64位上只受系统文件大小的限制
对固定集合进行插入速度极快
按照插入顺序的查询输出速度极快
能够在插入最新数据时,淘汰最早的数据

使用场景：
用法1:储存日志信息
用法2:缓存一些少量的文档

【 插入数据 】
db.collection_name.insert(document)如果该集合不在该数据库中,MongoDB会自动创建该集合并插入文档
db.collection_name.insert([document, document, document ...])

db.collection_name.insert({x:1}) 向集合内插入数据
db.collection_name.save({x:1})   不指定_id字段时类似于insert()方法,指定_id字段则会更新该_id的数据
db.collection_name.insertOne()   向指定集合中插入一条文档数据
db.collection_name.insertMany()  向指定集合中插入多条文档数据
db.user.insert({"_id": 1, "name": "berlin", age:28})  插入数据时指定_id主键索引,但是主键不能重复否则报错,但是再使用save插入相同主键时相当于update修改数据

for(i=0;i< 100;i++)db.集合名.insert({x:i})            使用js语法循环插入100条数据

document={title: 'MongoDB 教程',
  description: 'MongoDB 是一个 Nosql 数据库',
  by: '菜鸟教程',
  url: 'http://www.runoob.com',
  tags: ['mongodb', 'database', 'NoSQL'],
  likes: 100
};
db.collection_name.insert(document)

db.user.insertOne({a:4})
/*
{
  "acknowledged":true,
  "insertedId":ObjectId("5a24298ceefc94e02c9aa2d1")
}
*/

db.user.insertMany([
  { item: "journal", qty: 25, size: { h: 14, w: 21, uom: "cm" }, status: "A" },
  { item: "notebook", qty: 50, size: { h: 8.5, w: 11, uom: "in" }, status: "A" },
  { item: "paper", qty: 100, size: { h: 8.5, w: 11, uom: "in" }, status: "D" },
  { item: "planner", qty: 75, size: { h: 22.85, w: 30, uom: "cm" }, status: "D" },
  { item: "postcard", qty: 45, size: { h: 10, w: 15.25, uom: "cm" }, status: "A" }
]);
/*
{
  "acknowledged":true,
  "insertedIds":[
    ObjectId("5a2429d4eefc94e02c9aa2d2"),
    ObjectId("5a2429d4eefc94e02c9aa2d3"),
    ObjectId("5a2429d4eefc94e02c9aa2d4"),
    ObjectId("5a2429d4eefc94e02c9aa2d5"),
    ObjectId("5a2429d4eefc94e02c9aa2d6")
  ]
}
*/

【 MongoDB的对象Id(ObjectId) 】
MongoDB主键名是_id,生成数据时如果用户不主动分配一个主键,MongoDB会自动为其生成一个随机分配的值

ObjectId是一个12字节BSON类型数据
_id是12个字节十六进制数,在一个集合的每个文档是唯一的,_id是默认索引
_id: ObjectId(4 bytes timestamp, 3 bytes machine id, 2 bytes process id, 3 bytes incrementer)
前4个字节表示时间戳
接下来的3个字节是机器标识码
紧接的两个字节由进程id组成(PID)
最后三个字节是随机数

MongoDB中存储的文档必须有一个"_id"键。这个键的值可以是任何类型的,默认是个ObjectId对象。
在一个集合里每个文档都有唯一的"_id"值来确保集合里面每个文档都能被唯一标识。
MongoDB采用ObjectId,而不是其他常规做法(比如自动增加的主键)主要因为在多个服务器上同步自动增加主键值既费力还费时

ObjectId中存储了4个字节的时间戳,所以不需要为文档保存时间戳字段,可通过getTimestamp函数获取文档的创建时间:
>ObjectId("5349b4ddd2781d08c09890f4").getTimestamp()
返回IS 格式的文档创建时间：ISODate("2017-12-04T09:54:02Z")

ObjectId转换为字符串
new ObjectId().str               // 5a2541670fcb6b674ddb76a8
new ObjectId().getTimestamp()    // ISODate("2017-12-04T12:37:24Z")

【 更新数据 】
db.collection.update(
  < query>,
  < update>,
  {
    upsert: < boolean>,
    multi: < boolean>,
    writeConcern: < document>
  }
)

参数说明：
query:update的查询条件,类似sql update查询内where后面的。
update:update的对象和一些更新的操作符(如$,$inc...)等,也可以理解为sql update查询内set后面的
upsert:可选,如果不存在update的记录,是否插入objNew,true为插入,默认是false,不插入。
multi:可选, 默认是false,只更新找到的第一条记录,如果为true,就把按条件查出来多条记录全部更新。
writeConcern :可选,抛出异常的级别

WriteConcern.NONE:没有异常抛出
WriteConcern.NORMAL:仅抛出网络错误异常,没有服务器错误异常
WriteConcern.SAFE:抛出网络错误异常、服务器错误异常;并等待服务器完成写操作。
WriteConcern.MAJORITY: 抛出网络错误异常、服务器错误异常;并等待一个主服务器完成写操作。
WriteConcern.FSYNC_SAFE: 抛出网络错误异常、服务器错误异常;写操作等待服务器将数据刷新到磁盘。
WriteConcern.JOURNAL_SAFE:抛出网络错误异常、服务器错误异常;写操作等待服务器提交到磁盘的日志文件。
WriteConcern.REPLICAS_SAFE:抛出网络错误异常、服务器错误异常;等待至少2台服务器完成写操作。

db.collection.save(
  < document>,
  {
    writeConcern: < document>
  }
)

db.集合名.update({修改前字段名:字段值},{$set:{修改后字段名:修改后的字段值}})
db.集合名.update({x:1},{x:101})  将集合中{x:1}的数据更新为{x:101}
db.集合名.insert({x:100,y:100,z:100})
db.集合名.update({z:100},{y:99}) 将z为100的整条数据替换为{y:99}
db.集合名.update({z:100},{$set:{y:99}}) 将z为100的数据中y值替换为{y:99},部分更新,不存在的字段维持原样
db.集合名.update({z:100},{"$unset":{y:1}}) 删除y字段
db.集合名.update({z:888},{z:99})  更新不存在的数据时无效
db.集合名.update({z:888},{z:99},true) 数据不存在无法更新时自动insert数据

默认MongoDB只会更新查找到的第一条数据
db.col.update({"count":{$gt:1}},{$set:{"test2":"OK"}});              只更新第一条记录
db.col.update({"count":{$gt:1}},{$inc:{"test2":"OK"}},false,false);  只更新第一条记录
db.col.update({"count":{$gt:1}},{$inc:{"test2":"OK"}},{multi:true}); 更新多条数据
db.col.update({"count":{$gt:3}},{$set:{"test2":"OK"}},false,true);   全部更新
db.col.update({"count":{$gt:4}},{$set:{"test5":"OK"}},true,false);   只添加第一条
db.col.update({"count":{$gt:5}},{$set:{"test5":"OK"}},true,true);    全部添加加进去

db.collection.updateOne() 向指定集合更新单个文档
db.collection.updateMany() 向指定集合更新多个文档

db.col.updateOne({"name":"abc"},{$set:{"age":"28"}})
// { "acknowledged" : true, "matchedCount" : 1, "modifiedCount" : 1 }

db.test_collection.updateMany({"age":{$gt:"10"}},{$set:{"status":"xyz"}})
// { "acknowledged" : true, "matchedCount" : 3, "modifiedCount" : 3 }

【 删除数据 】
db.collection.remove(
  < query>,
  {
    justOne: < boolean>,
    writeConcern: < document>
  }
)

参数说明：
query :(可选)删除的文档的条件。
justOne : (可选)如果设为 true 或 1,则只删除一个文档。
writeConcern :(可选)抛出异常的级别

db.inventory.deleteMany({})                删除集合下全部文档
db.inventory.deleteMany({status:"A"})      删除 status 等于 A 的全部文档
db.inventory.deleteOne({status:"D"} )      删除 status 等于 D 的一个文档

db.user.remove({"age": {$gt:20}},1) 删除第一条找到的记录可以设置 justOne 为 1
db.集合名.remove({"_id": 1})  删除数据,无参数报错,默认删除查找到的所有数据
db.集合名.remove({})          删除所有数据,类似常规 SQL 的 truncate 命令
db.集合名.remove()
db.集合名.drop()              删除整张表

【 查找数据 】
db.users.count()            获取该集合中文档的数量          // 6
db.users.distinct('age')    collection中age字段中存在哪些值 // [22, 25, 30]
db.groups.group()           分组查询

</pre><pre class="js">
{ "_id" : ObjectId("5a2fbcb378fd2fd0a46c76f4"), "name" : "name1", "age" : 21, "city" : "loudi" }
{ "_id" : ObjectId("5a2fbcd078fd2fd0a46c76f5"), "name" : "name2", "age" : 21, "city" : "shaoyang" }
{ "_id" : ObjectId("5a2fbcde78fd2fd0a46c76f6"), "name" : "name3", "age" : 22, "city" : "shaoyang" }
{ "_id" : ObjectId("5a2fbcf278fd2fd0a46c76f7"), "name" : "name4", "age" : 25, "city" : "changsha" }
{ "_id" : ObjectId("5a2fbd0878fd2fd0a46c76f8"), "name" : "name5", "age" : 25, "city" : "xiangtan" }
{ "_id" : ObjectId("5a2fbd1b78fd2fd0a46c76f9"), "name" : "name6", "age" : 28, "city" : "loudi" }

db.groups.group({
  key: {age: true},                  // 分组的key,对年龄分组
  initial: {groups: []},             // 每组都方向一个初始化函数
  // cur当前的文档对象,prev是上次function操作的累积对象,第一次是initial中的{users: []},有多少文档$reduce就会调用多少次
  $reduce: function(cur, prev){
    prev.groups.push(cur.name);
  }
})

[
  { "age" : 21, "groups" : [ "name1", "name2" ] },
  { "age" : 22, "groups" : [ "name3" ]},
  { "age" : 25, "groups" : [ "name4", "name5" ]},
  { "age" : 28, "groups" : [ "name6" ]}
]

db.groups.group({
  key: {age: true},                  // 分组的key,对年龄分组
  initial: {groups: []},             // 每组都方向一个初始化函数
  // cur当前的文档对象,prev是上次function操作的累积对象,第一次是initial中的{users: []},有多少文档$reduce就会调用多少次
  reduce: function(cur, prev){
    prev.groups.push(cur.name);
  },
  finalize: function(prev){          //增加输出结果的统计count属性
    prev.count = prev.groups.length
  },
  condition: {age: {$gt: 22}}        // 查询条件
})

[
  { "age" : 25, "groups" : [ "name4", "name5" ], "count" : 2 },
  { "age" : 28, "groups" : [ "name6" ], "count" : 1 }
]

// 聚合查询
db.groups.aggregate([{$group: {_id: '$age', groups: {$push: '$name'}}}])
db.groups.aggregate([{$group: {_id: '$age', groups: {$addToSet: '$name'}}}])
{ "_id" : 28, "groups" : [ "name6" ] }
{ "_id" : 25, "groups" : [ "name5", "name4" ] }
{ "_id" : 22, "groups" : [ "name3" ] }
{ "_id" : 21, "groups" : [ "name2", "name1" ] }

// mapReduce
function map(){emit(this.name, {count: 1})}
function reduce(key, value){
  var result = {count: 0};
  for(var i = 0; i < value.length; i++){
    result.count += value[i].count;
  }
  return result;
}
db.mapreduces.mapReduce(map, reduce, {out: "collection"}).find()
{ "_id" : "name1", "value" : { "count" : 3 } }
{ "_id" : "name2", "value" : { "count" : 2 } }
{ "_id" : "name3", "value" : { "count" : 1 } }

// mapReduce2
db.groups.mapReduce(
  function (){emit(this.age, this.name)},
  function (key, values){
    var res = '';
    values.forEach(value => res += value + '&')
    return res
  },
  {out: "groupsArray"}
).find()

map函数的emit一参指定分组是按照哪个字段进行,也是最终结果的_id字段值,二参指定reduce函数返回值的形式,也是最终结果的value字段值的形式
reduce函数的values参数指每一条分组中的数组,返回对该数组处理的结果
r('21', ['name1', 'name2'])
r('22', ['name3'])
r('25', ['name4', 'name5'])

{ "_id" : 21, "value" : "name1&name2&" }
{ "_id" : 22, "value" : "name3" }
{ "_id" : 25, "value" : "name4&name5&" }
{ "_id" : 28, "value" : "name6" }

</pre><pre>
db.collection.find(query, projection)
query ：可选,使用查询操作符指定查询条件
projection ：可选,使用投影操作符指定返回的键。查询时返回文档中所有键值只需省略该参数即可(默认省略)

db.集合名.find()                    查询某个集合下的全部数据
db.集合名.find({})
db.集合名.find({"age":11})          查询age等于11的数据文档
db.集合名.find({"age":{$gt:11}})    查询age大于11的数据文档
db.集合名.find({age:{$in:[22,25]}}) 查询age是22或25
db.集合名.findOne()                 查询获取到的第一条数据
db.集合名.find().count()            统计数据条数
db.集合名.find().pretty()           格式化显示

limit(n)用来规定显示的条数
skip(n)用来在符合条件的记录中从第一个记录跳过的条数
sort()方法对数据进行排序,通过参数指定排序的字段,并使用1升序排列,-1是用于降序排列,默认升序

skip和limit结合就能实现分页,最先执行顺序sort再skip再limit
db.集合名.find({"age":11}).skip(3).limit(2).sort({"age":1})  // 过滤3条数据,限制查询2条,按age排序,1顺序-1降序

不要轻易使用Skip来做查询,否则数据量大会导致性能急剧下降,因为Skip是一条一条的数过来的,多了自然就慢
解决方法：find方法加上限制条件
db.test.find().sort({"amount":1}).skip(100000).limit(10)           //183ms
db.test.find({amount:{$gt:2399927}}).sort({"amount":1}).limit(10)  //53ms

greater than; less than; equal
{key:"value"}          where by = '菜鸟教程'
{key:{$lt:"value"}}    where likes < 50
{key:{$lte:"value"}}   where likes <= 50
{key:{$gt:"value"}}    where likes > 50
{key:{$gte:"value"}}   where likes >= 50
{key:{$ne:"value"}}    where likes != 50

</pre><pre class="js">
db.col.find({likes: {$lt:200, $gt: 100}})
Select * from col where likes > 100 AND  likes < 200;

db.collection.find({
  time:{"$gte": new Date('2014-01-24'),"$lt": new Date('2014-01-25')}
})

db.inventory.find({})
SELECT * FROM inventory

db.inventory.find({status: "D"})
SELECT * FROM inventory WHERE status = "D"

db.inventory.find({status: {$in: ["A", "D"]}})
SELECT * FROM inventory WHERE status in ("A", "D")

db.inventory.find({status: "A", qty: {$lt: 30}})
SELECT * FROM inventory WHERE status = "A" AND qty < 30

db.inventory.find({$or: [{status: "A"}, {qty: {$lt: 30}}]})
SELECT * FROM inventory WHERE status = "A" OR qty < 30

db.inventory.find( {
  status: "A",
  $or: [ { qty: { $lt: 30 }}, { item: /^p/ } ]
})
SELECT * FROM inventory WHERE status = "A" AND ( qty < 30 OR item LIKE "p%")

</pre><pre>
【 指定返回的字段 】
_id键默认返回,需要主动指定_id:0才会隐藏
若不指定projection则默认返回所有键,指定projection格式如下,有两种模式
db.collection.find(query, {title: 1, by: 1}) // inclusion模式 指定返回的键,不返回其他键
db.collection.find(query, {title: 0, by: 0}) // exclusion模式 指定不返回的键,返回其他键
db.col.find({},{"title":1,_id:0}).limit(2)  从所有数据中找出两条数据的title字段

两种模式不可混用,只能全1或全0,除了在inclusion模式时可以指定_id为0
db.collection.find(query, {title: 1, by: 0})        // 错误
db.collection.find(query, {_id:0, title: 1, by: 1}) // 正确

db.user.find({"name":"heiying6958"},{"email":1,"age":1})
select email,age from user where name = heiying6958;

【 $exists操作符 】
查找集合中某个字段是否存在记录
db.users.find({m:{$exists:true}})
db.users.find({m:{$exists:false}}) 查找m字段不存在的文档
db.users.find({m:{$exists:false}}).hint('m_1')  强制使用name属性为m_1的索引

</pre>【 toArray() 】<pre class="js">
db.runoob.find()
{ "_id" : ObjectId("5a22e372eefc94e02c9aa2c8"), "x" : 10 }
{ "_id" : ObjectId("5a256caa23976be3c233b88d"), "x" : 15 }

db.runoob.find().toArray()
[
  { "_id" : ObjectId("5a22e372eefc94e02c9aa2c8"), "x" : 10 },
  { "_id" : ObjectId("5a256caa23976be3c233b88d"), "x" : 15 }
]

db.runoob.find().toArray().length   // 2

</pre><pre>
【 $type 条件操作符 】
$type操作符是基于BSON类型来检索集合中匹配的数据类型并返回结果
Double                    1
String                    2
Object                    3
Array                     4
Binary data               5
Undefined                 6   已废弃。
Object id                 7
Boolean                   8
Date                      9
Null                      10
Regular Expression        11
JavaScript                13
Symbol                    14
JavaScript (with scope)   15
32-bit integer            16
Timestamp                 17
64-bit integer            18
Min key                   255  Query with -1.
Max key                   127

获取col集合中title为String的数据
db.col.find({"title" : {$type : 2}})

【 MongoDB正则表达式 】
$regex操作符设置匹配字符串的正则表达式
MongoDB使用PCRE (Perl Compatible Regular Expression)作为正则表达式语言。
不同于全文检索,使用正则表达式不需要做任何配置

索引检索比正则检索更快

正则表达式中使用变量时一定要使用eval将组合的字符串进行转换,不能直接将字符串拼接后传入给表达式,否则没有报错信息,只是结果为空
var name = eval("/" + 变量值key +"/i");
title: eval("/"+title+"/i")              // 等同于 title: {$regex:title,$Option:"$i"}

</pre><pre class="js">
{
   "post_text": "enjoy the mongodb articles on runoob",
   "tags": [ "mongodb", "runoob" ]
}
db.blog.find({post_text: {$regex:"runoob",$options:"$i"}})  // 忽略大小写
db.blog.find({post_text: /runoob/i})
db.blog.find({tags: {$regex:"run"}})                        // 数组字段使用正则表达式查找run开头的数据

</pre><pre>
【 mongodb 原子操作 如文档的保存,修改,删除等 】
原子操作就是要么这个文档保存到Mongodb,要么没有保存到Mongodb,不会出现查询到的文档没有保存完整的情况

原子操作常用命令：
$set
用来指定一个键并更新键值,若键不存在则创建
{ $set : { field : value } }

$unset
用来删除一个键
{ $unset : { field : 1} }

$inc
$inc可以对文档的某个值为数字型(只能为满足要求的数字)的键进行增减的操作。
{ $inc : { field : value } }

$push
把value追加到field里面去,field一定要是数组类型才行,如果field不存在,会新增一个数组类型加进去。
{ $push : { field : value } }

$pushAll
同$push,只是一次可以追加多个值到一个数组字段内。
{ $pushAll : { field : value_array } }

$pull
从数组field内删除一个等于value值。
{ $pull : { field : _value } }

$addToSet
增加一个值到数组内,而且只有当这个值不在数组内才增加。

$pop
删除数组的第一个或最后一个元素
{ $pop : { field : 1 } }

$rename
修改字段名称
{ $rename : { old_field_name : new_field_name } }

$bit
位操作,integer类型
{$bit : { field : {and : 5}}}

偏移操作符

</pre><pre class="js">
> db.blog.update({"title": "MongoDB Overview"}, {$set: {"comments": [{"by": "joe","votes": 3 }, {"by": "jane", "votes": 7}]}})

> db.blog.update( {'comments.by':'joe'}, {$inc:{'comments.$.votes':1}}, false, true )

> db.blog.find( {'comments.by':'joe'})
{ "_id" : ObjectId("5a24d6d262d49b0077190f18"), "title" : "MongoDB Overview", "description" : "MongoDB is no sql database", "by_user" : "runoob.com", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100, "comments" : [ { "by" : "joe", "votes" : 4 }, { "by" : "jane", "votes" : 7 } ] }

</pre><pre class="js">
// 图书馆的书籍及结账信息
// 在一个相同的文档中如何确保嵌入字段available和checkout关联原子操作(update：更新)的字段是同步更新的

book = {
  _id: 123456789,
  title: "MongoDB: The Definitive Guide",
  author: [ "Kristina Chodorow", "Mike Dirolf" ],
  published_date: ISODate("2010-09-24"),
  pages: 216,
  language: "English",
  publisher_id: "oreilly",
  available: 3,
  checkout: [ { by: "joe", date: ISODate("2012-10-15") } ]
}

// 使用 db.collection.findAndModify() 方法来判断书籍是否可结算并更新新的结算信息
// 当id为123456789的书available字段值大于0时将执行更新,available字段的值减1并将"abc"的信息插入到checkout字段中

db.books.findAndModify ( {
  query: {
    _id: 123456789,
    available: { $gt: 0 }
  },
  update: {
    $inc: { available: -1 },
    $push: { checkout: { by: "abc", date: new Date() } }
  }
})

</pre>

<h3>MongoDB 聚合(类似SQL函数)</h3><pre>
聚合(aggregate)主要用于处理数据记录(如统计平均值,求和等),并返回计算后的数据结果
从多个文档聚合分组操作数值,并可以执行多种对分组数据业务返回一个结果。
在SQL中的count(*),使用group by 与mongodb的聚合是等效的。 对于MongoDB的聚合,使用的是aggregate()方法

db.collection_name.aggregate(AGGREGATE_OPERATION)

$sum总和
db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$sum : "$likes"}}}])
通过字段by_user字段对数据进行分组,并计算by_user字段相同值的总和
db.col.aggregate([{$group : {_id : "$by_user", num_tutorial : {$sum : 1}}}])
select by_user, count(*) from mycol group by by_user

$avg平均值
db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$avg : "$likes"}}}])

$min 获取集合中所有文档对应值得最小值
db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$min : "$likes"}}}])

$max 获取集合中所有文档对应值得最大值
db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$max : "$likes"}}}])

$push在结果文档中插入值到一个数组中
db.mycol.aggregate([{$group : {_id : "$by_user", url : {$push: "$url"}}}])

$addToSet 在结果文档中插入值到一个数组中,但不创建副本
db.mycol.aggregate([{$group : {_id : "$by_user", url : {$addToSet : "$url"}}}])

$first  根据资源文档的排序获取第一个文档数据
db.mycol.aggregate([{$group : {_id : "$by_user", first_url : {$first : "$url"}}}])

$last 根据资源文档的排序获取最后一个文档数据
db.mycol.aggregate([{$group : {_id : "$by_user", last_url : {$last : "$url"}}}])

</pre><pre class="js">
db.blog.insertMany([{
  title: 'MongoDB Overview',
  description: 'MongoDB is no sql database',
  by_user: 'runoob.com',
  url: 'http://www.runoob.com',
  tags: ['mongodb', 'database', 'NoSQL'],
  likes: 100
},
{
  title: 'NoSQL Overview',
  description: 'No sql database is very fast',
  by_user: 'runoob.com',
  url: 'http://www.runoob.com',
  tags: ['mongodb', 'database', 'NoSQL'],
  likes: 10
},
{
  title: 'Neo4j Overview',
  description: 'Neo4j is no sql database',
  by_user: 'Neo4j',
  url: 'http://www.neo4j.com',
  tags: ['neo4j', 'database', 'NoSQL'],
  likes: 750
}])

计算每个作者所写的文章数
db.blog.aggregate([{$group : {_id : "$by_user", num_tutorial : {$sum : 1}}}])
{ "_id" : "Neo4j", "num_tutorial" : 1 }
{ "_id" : "runoob.com", "num_tutorial" : 2 }
{ "_id" : null, "num_tutorial" : 5 }  // 不存在by_user字段的数据

db.blog.aggregate([{$group : {_id : "$by_user", num_tutorial : {$sum : "$likes"}}}])
{ "_id" : "Neo4j", "num_tutorial" : 750 }
{ "_id" : "runoob.com", "num_tutorial" : 110 }
{ "_id" : null, "num_tutorial" : 0 }

db.blog.aggregate([{$group : {_id : "$by_user", url : {$push: "$url"}}}])
{ "_id" : "Neo4j", "url" : [ "http://www.neo4j.com" ] }
{ "_id" : "runoob.com", "url" : [ "http://www.runoob.com", "http://www.runoob.com" ] }
{ "_id" : null, "url" : [ ] }

db.blog.aggregate([{$group : {_id : "$by_user", url : {$addToSet : "$url"}}}])
{ "_id" : "Neo4j", "url" : [ "http://www.neo4j.com" ] }
{ "_id" : "runoob.com", "url" : [ "http://www.runoob.com" ] }

db.blog.aggregate([{$group : {_id : "$by_user", first_url : {$first : "$url"}}}])
{ "_id" : "Neo4j", "first_url" : "http://www.neo4j.com" }
{ "_id" : "runoob.com", "first_url" : "http://www.runoob.com" }

</pre>

<h3>【 MongoDB Map Reduce 】</h3><pre>
Map-Reduce是一种计算模型,即将大批量的工作(数据)分解(MAP)执行,然后再将结果合并成最终结果(REDUCE)
MongoDB提供的Map-Reduce非常灵活,对于大规模数据分析也相当实用,但MapReduce非常慢,不该用在实时的数据分析中

MapReduce的基本语法：
>db.collection.mapReduce(
  function() {emit(key,value);},                  //map 函数
  function(key,values) {return reduceFunction},   //reduce 函数
  {
    out: collection,
    query: document,
    sort: document,
    limit: number
  }
)

使用MapReduce要实现Map函数和Reduce函数
Map函数调用emit(key, value)遍历collection中所有的记录,将键值对key与value传递给Reduce函数进行处理

MapReduce操作有2个阶段
第一个阶段是映射map阶段,处理每一个符合要求的文档,即每个符合要求的文档都执行一次map的方法,然后利用emit函数产生一些键和这些键对应的多个值(最后组成一个列表)
第二个阶段是化简reduce阶段,把列表中的值化简成一个单值

参数说明:
map
映射函数(生成键值对序列作为reduce函数参数),里面调用emit(key,value),集合按照指定的key进行分组

reduce
统计函数,将key-values变成key-value,也就是把values数组变成一个单一的值value
简化函数,会对map分组后的数据进行分组简化,在reduce(key,value)中的key就是emit中的key,vlaue为emit分组后的emit(value)的集合,这里也就是很多{"count":1}的数组

out    统计结果存放集合 (不指定则使用临时集合,在客户端断开后自动删除)。
query  一个筛选条件,只有满足条件的文档才会调用map函数。(query、limit、sort可以随意组合)
sort   和limit结合的sort排序参数(也是在发往map函数前给文档排序),可以优化分组机制
limit  发往map函数的文档数量的上限(要是没有limit,单独使用sort的用处不大)

db.collection.mapReduce(mapfunction,reducefunction[,options]);
输出选项结构如下：
{ "out", option }
option可以是下面几个选项：
"collection name" – mapReduce的输出结果会替换掉原来的collection,collection不存在则创建
{ replace : "collection name" } – 同上
{ merge : "collection name" } – 将新老数据进行合并,新的替换旧的,没有的添加进去
{ reduce : "collection name" } – 存在老数据时,在原来基础上加新数据(即 new value = old value + mapReduce value)
{ inline : 1 } – 不会创建collection,结果保存在内存里,只限于结果小于16MB的情况
如果用collection name作option不能与其它option一起使用,其它则可以,如：
{ "out", { replace : "collection name", db : "db name" } }

结果具体参数说明：
result：    储存结果的临时集合名,MapReduce的连接关闭后自动就被删除
timeMillis：执行花费的时间,毫秒为单位
input：     满足条件被发送到map函数的文档个数
emit：      在map函数中emit被调用的次数,也就是所有集合中的数据总量
reduce:     reduce 函数被调用的次数
ouput：     结果集合中的文档个数(count对调试非常有帮助)
ok：        是否成功,成功为1
err：       如果失败,这里可以有失败原因,不过从经验上来看,原因比较模糊,作用不大

使用.find()操作符来查看mapReduce的查询结果

</pre>在集合blog中查找status:"A"的数据,并根据cust_id来分组,并计算amount的总和<pre class="js">
/* 执行过程
首先查找所有订单(如果mongodb有进行分片,则每个分片的订单都会找出来)状态为"A"的订单。
然后每个订单都会执行map的方法,map方法主要是输出以cust_id为key,amount为value的一个键值对。紧跟着的一个步骤,是把所有相同的key的所有value,组成一个数组,传给后面的reduce。
最后的reduce步骤,是把由map传回来的key/value的value进行求和,得到最终以每个用户(cust_id)为key,所有金额求和的值为value的结果。
reduce步骤产生的结果,放在"order_totals"这个集合中。可以用db.order_totals.find()来查看这整个MapReduce的结果
*/

// 原始数据
db.blog.insert({"cust_id": "A123","amount": 500,"status":"A"})
db.blog.insert({"cust_id": "A123","amount": 250,"status":"A"})
db.blog.insert({"cust_id": "A212","amount": 200,"status":"A"})
db.blog.insert({"cust_id": "A123","amount": 300,"status":"D"})

// query结果
db.blog.insert({"cust_id": "A123","amount": 500,"status":"A"})
db.blog.insert({"cust_id": "A123","amount": 250,"status":"A"})
db.blog.insert({"cust_id": "A212","amount": 200,"status":"A"})

// map
{"A123": [500, 250]} -reduce-> {_id: "A123", value: 750}
{"B212": 200}        -reduce-> {_id: "B212", value: 200}

// map生成{"A123": [500, 250]}和{"B212": 200},发往reduce函数处理
db.blog.mapReduce(
  function(){emit(this.cust_id, this.amount)},
  function(key, values){return Array.sum(values)},
  {
    query: {status: "A"},
    out:   "blog_totals"
  }
)

{"result" : "blog_totals",
  "timeMillis" : 294,
  "counts" : { "input" : 3, "emit" : 3, "reduce" : 1, "output" : 2 },
  "ok" : 1}

{ "_id" : "A123", "value" : 750 }
{ "_id" : "A212", "value" : 200 }

</pre><pre class="js">
db.things.insert([
  { "_id" : 1, "tags" : [ "dog", "cat" ] },
  { "_id" : 2, "tags" : [ "cat" ] },
  { "_id" : 3, "tags" : [ "mouse", "cat", "dog" ] },
  { "_id" : 4, "tags" : [ ] }
])

m = function () {
 this.tags.forEach(function (z) {
     emit(z, {count:1});
 });
}

r = function(key, values) {
  var total = 0;
  for (var i = 0; i < values.length; i++) total += values[i].count;
  return {count : total};
};

res = db.things.mapReduce(m,r, {out : {replace : 'things_reduce'}});
db[res.result].find()

/******************************  注释  ******************************/
map函数的emit一参指定分组是按照哪个字段进行,也是最终结果的_id字段值,二参指定reduce函数返回值的形式,也是最终结果的value字段值的形式
reduce函数的values参数指每一条分组中的数组,返回对该数组处理的结果

m函数扫描每条记录的tags,将tags的每个元素如："dog"、"cat"……作为key,{count : 1}作为value
如：{"dog", { count : 1}},{"cat", { count : 1}},将这些经过聚集的{ key : value}传递给Reduce Function

r函数统计每个tag的个数,r的返回结果要与emit函数的value格式一致(不一致的话bug很难调试)
r函数调用的方式如下：根据key分组,同一组的value组成数组values,r函数处理这个数组
r("cat", [ { count ： 1 }, { count : 1 }, { count : 1} ] );
r("dog", [ { count : 1 }, { count : 1 } ] );
r("mouse", [ { count : 1 } ]);

结果：
{ "_id" : "cat", "value" : { "count" : 3 } }
{ "_id" : "dog", "value" : { "count" : 2 } }
{ "_id" : "mouse", "value" : { "count" : 1 } }

</pre><pre class="js">
> db.foo.find()
{username" : "jones", "likes" : 20, "text" : "Hello world!" }
{username" : "jones", "likes" : 5, "text" : "Hello world aaaaaaaaaa!" }
{username" : "chy", "likes" : 15, "text" : "Hello world bbbbbbbbbb!" }

db.foo.mapReduce(
  function(){emit(this.username, {count:1, likes:this.likes});},
  function (key, values) {
    var result = {count:0, likes:0};
    values.forEach((value) => {
      result.count += value.count;
      result.likes += value.likes;
    });
    return result;
  },
  {out: "test_result"}
).find()

{ "_id" : "chy", "value" : { "count" : 1, "likes" : 15 } }
{ "_id" : "jones", "value" : { "count" : 2, "likes" : 25 } }

将{out: {replace: "test_result"}}改为{out: {reduce: "test_result"}}的话,可以看到没运行一次res = db.foo.mapReduce(m, f, {out: {replace: "test_result"}});结果就会增加,如：
> db.test_result.find()
{ "_id" : "jones", "value" : { "count" : 5, "likes" : 70 } }
{ "_id" : "chy", "value" : { "count" : 2, "likes" : 30 } }

</pre><pre class="js">
db.blog.insert({"post_text": "最全的技术文档","user_name": "mark","status":"active"})
db.blog.insert({"post_text": "最全的技术文档","user_name": "mark","status":"active"})
db.blog.insert({"post_text": "最全的技术文档","user_name": "mark","status":"active"})
db.blog.insert({"post_text": "最全的技术文档","user_name": "mark","status":"active"})
db.blog.insert({"post_text": "最全的技术文档","user_name": "mark","status":"disabled"})
db.blog.insert({"post_text": "最全的技术文档","user_name": "runoob","status":"disabled"})
db.blog.insert({"post_text": "最全的技术文档","user_name": "runoob","status":"disabled"})
db.blog.insert({"post_text": "最全的技术文档","user_name": "runoob","status":"active"})

// 在blog集合中使用mapReduce函数来选取已发布的文章(status:"active"),并通过user_name分组计算每个用户的文章数

db.blog.mapReduce(
  function(){ emit(this.user_name,1); },
  function(key, values){return Array.sum(values)},
  {
    query:{status:"active"},
    out:"post_total"
  }
)

// 结果表明共有5个符合查询条件(status:"active")的文档,在map函数中生成了5个键值对文档,最后使用reduce函数将相同的键值分为2组
{
  "result" : "post_total",
  "timeMillis" : 624,
  "counts" : { "input" : 5, "emit" : 5, "reduce" : 1, "output" : 2 },
  "ok" : 1
}

// 使用 find 操作符来查看 mapReduce 的查询结果：
db.blog.mapReduce(
  function(){ emit(this.user_name,1); },
  function(key, values){return Array.sum(values)},
  { query:{status:"active"}, out:"post_total" }
).find()

{ "_id" : "mark", "value" : 4 }
{ "_id" : "runoob", "value" : 1 }

</pre><pre class="js">
// mapReduce
db.mapreduces.insert([
  {name: 'name1', age: 25}, {name: 'name2', age: 25}, {name: 'name2', age: 26},
  {name: 'name3', age: 28}, {name: 'name1', age: 29}, {name: 'name1', age: 32}
])

function map(){emit(this.name, {count: 1})}
function reduce(key, value){
  var result = {count: 0};
  for(var i = 0; i < value.length; i++){
    result.count += value[i].count;
  }
  return result;
}
db.mapreduces.mapReduce(map, reduce, {out: "collection"})

{
  "result" : "collection",
  "timeMillis" : 563,
  "counts" : { "input" : 6, "emit" : 6, "reduce" : 2, "output" : 3 },
  "ok" : 1
}

db.collection.find()
{ "_id" : "name1", "value" : { "count" : 3 } }
{ "_id" : "name2", "value" : { "count" : 2 } }
{ "_id" : "name3", "value" : { "count" : 1 } }

</pre><pre class="js">
db.emp.insert([
  {name: 'yy1', age: 22},{name: 'yy2', age: 23},{name: 'yy3', age: 25},
  {name: 'yy4', age: 30},{name: 'yy5', age: 36}
])

db.emp.mapReduce(
  function map(){ if(this.age > 25) emit(this.age, {name: this.name})},
  function reduce(key, values){
    var count = 0;
    values.forEach(() => ++count)
    return count;
  },
  {out: 'emp_res'}
).find()

{ "_id" : 30, "value" : { "name" : "yy4" } }
{ "_id" : 36, "value" : { "name" : "yy5" } }

</pre><pre>
【 MongoDB GridFS 】
GridFS用于存储和恢复大于16M(BSON文件限制)的文件,如图片、音频、视频等
GridFS也是文件存储的一种方式,但是它是存储在MonoDB的集合中。
GridFS会将大文件对象分割成多个小的chunk(文件片段),一般为256k/个,每个chunk将作为MongoDB的一个文档(document)被存储在chunks集合中。
GridFS用两个集合来存储一个文件：fs.files与fs.chunks。
每个文件的实际内容被存在chunks(二进制数据)中,和文件有关的meta数据(filename,content_type,还有用户自定义的属性)将会被存在files集合中。

以下是简单的fs.files集合文档：
{
  "filename": "test.txt",
  "chunkSize": NumberInt(261120),
  "uploadDate": ISODate("2014-04-13T11:32:33.557Z"),
  "md5": "7b762939321e146569b07f72c62cca4f",
  "length": NumberInt(646)
}

以下是简单的fs.chunks集合文档：
{
  "files_id": ObjectId("534a75d19f54bfec8a2fe44b"),
  "n": NumberInt(0),
  "data": "Mongo Binary Data"
}

GridFS 添加文件
// 使用GridFS的put命令来存储song.mp3文件到gridfs数据库,若数据库不存在会自动创建
>mongofiles.exe -d gridfs put E:\bigbigworld.mp3
>db.fs.files.find().pretty()           查看数据库中文件的文档
{
  "_id" : ObjectId("5a256988b0ca902efc45d157"),
  "chunkSize" : 261120,
  "uploadDate" : ISODate("2017-12-04T15:28:08.325Z"),
  "length" : 3236900,
  "md5" : "7ae6c17a51cd3d434199514ddca47bd2",
  "filename" : "E:\\bigbigworld.mp3"
}
>db.fs.chunks.find({files_id: ObjectId("5a256988b0ca902efc45d157")})
>db.fs.chunks.find({files_id: ObjectId("5a256988b0ca902efc45d157")}).toArray().length  // 13

【 自动增长 】
MongoDB没有像SQL一样有自动增长的功能, MongoDB的_id是系统自动生成的12字节唯一标识

</pre><pre class="js">
{
  "_id":1,
  "product_name": "Apple iPhone",
  "category": "mobiles"
}
>db.createCollection("counters")
>db.counters.insert({_id:"productid",sequence_value:0})
>function getNextSequenceValue(sequenceName){
  // 每次执行该命令符合query参数的counters文档中sequence_value字段增加1
  var sequenceDocument = db.counters.findAndModify({
    query:{_id: sequenceName },
    update: {$inc:{sequence_value:1}},
    new:true
  });
  return sequenceDocument.sequence_value;
}
>db.products.insert({
  "_id":getNextSequenceValue("productid"),
  "product_name":"Apple iPhone",
  "category":"mobiles"
})

>db.products.insert({
  "_id":getNextSequenceValue("productid"),
  "product_name":"Samsung S3",
  "category":"mobiles"
})
>db.products.find()

</pre><pre>
【 游标 】
mongodb里面的游标有点类似C#里面延迟执行,比如var list=db.person.find();
针对这样的操作,list其实并没有获取到person中的文档,而是申明一个"查询结构",等需要的时候通过
for或next()一次性加载过来,然后让游标逐行读取,当枚举完了之后游标销毁,之后在通过list获取时发现没有数据返回了

> var list = db.person.find();
> list.forEach(function(x){
    print(x.name);
  })

... 输出结果 ...
> list
... 无输出 ...

</pre>
</div>

<div id="index">
<h3>索引: 在常用查询条件的字段建立索引提高查询效率</h3><pre>
如果没有索引,MongoDB在读取数据时必须扫描集合中的每个文件并选取那些符合查询条件的记录,效率非常低
索引是特殊的数据结构,索引存储在一个易于遍历读取的数据集合中
索引存储特定字段或一组字段的值,按照索引中指定的字段值排序
索引是对数据库表中一列或多列的值进行排序的一种结构

每个索引占据一定的存储空间,增加磁盘空间的消耗,索引比较多的情况下索引文件所占据的空间有可能超过数据本身
在进行插入、更新和删除操作时也需要对索引进行操作,需要额外的开销,对索引的维护一般是写之外的另一条逻辑,一定程度上会降低写入性能
如果文档较多,创建索引需要耗费一定的时间。如果系统负载较重,且有很多已经存在的文档,不能直接使用这个命令进行创建,需要在使用数据库之前就将索引创建完毕。否则严重影响数据库的性能

有很多情况下系统的性能下降与不合理的索引创建有关。所以合理的创建索引,可以减少索引带来的不好的影响

_id是默认索引

【 查看、创建、删除索引 】
db.collection_name.getIndexes()                  查看集合的索引情况
db.collection_name.ensureIndex({key:1})          创建索引,key索引字段,1为指定按升序创建索引,-1降序
db.collection_name.createIndex({key:1})          创建索引,在MongoDB3.0版本之后
db.col.ensureIndex({"title":1,"description":-1}) 多个字段创建索引,关系型数据库中的符合索引
db.col.createIndex({"title":1,"description":-1})
db.collection_name.dropIndex({key:1})             使用索引值键值对删除指定的索引,_id索引无法被删除
db.collection_name.dropIndex({"indexname"})       使用索引name值删除指定的索引,_id索引无法被删除
db.collection_name.dropIndexes()                  删除所有索引

索引可以重复创建,如果对已经存在的索引再次创建会直接返回成功

ensureIndex()接收可选参数:索引属性
创建索引时的格式：db.collection_name.ensureIndex({param},{param})
参一是索引的值
参二是索引属性

【 索引属性 】
✈ background  Boolean  默认值为false
建索引过程会阻塞其它数据库操作,background可指定以后台方式创建索引,即增加 "background" 可选参数
例：db.values.ensureIndex({open: 1, close: 1}, {background: true})

✈ unique  Boolean 默认值为false
建立的索引是否唯一,指定为true创建唯一索引
唯一索引用于确保索引字段不存储重复的值,缺省情况下,_id字段在创建集合时会自动创建一个唯一索引
db.collection_name.ensureIndex({m:1,n:1},{unique: true/false"}) 唯一索引
db.collection_name.insert({m:1,n:2})
db.collection_name.insert({m:1,n:2}) 再次插入相同的数据报错

设置的a字段为唯一索引,b字段也无法输入重复的值。这是因为设置a字段为唯一索引,插入数据b:10相当于a:null,再插入b:10时相当于又插入了a:null。而a:null和a:null是重复的,而a字段是唯一索引,无法重复。所以,无法插入重复的b:10
db.users.createIndex({a: 1},{unipue: true});
db.users.insert({b: 10})
db.users.insert({b: 10})  再次插入相同的数据报错

✈ name  string
索引的名称。如果未指定MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称
db.collection_name.ensureIndex({},{name: "normal_index"}),不指定时会自动创建
db.collection_name.dropIndex("normal_index") 使用索引的名字属性删除索引

✈ dropDups  Boolean  默认值为 false
在建立唯一索引时是否删除重复记录,指定 true 创建唯一索引

✈ sparse  Boolean  默认值为 false
对文档中不存在的字段数据不启用索引;设置为true的话,在索引字段中不会查询出不包含对应字段的文档
稀疏性 稀疏索引
稀疏索引也称为间隙索引,就是创建索引的索引列在某些文档上列不存在,导致索引存在间隙
db.collection_name.ensureIndex({m:1,n:1},{sparse: true/false"}) true避免为不存在的字段创建索引
稀疏性的不同代表了MongoDB在处理索引中存在但是文档中不存在的字段的两种不同的方法
在一个集合中创建了x字段上的索引,但是插入的文档中并不包含x字段。在默认情况下MongoDB依然会为这条不存在的字段创建索引。如果把这条索引创建为稀疏索引,则这条索引将不会被使用
如果数据集合中很多文档在创建索引的字段上并没有值,使用稀疏索引可以减少磁盘占用,且提高插入速度

使用稀疏索引时,可能会带来一些隐患
db.imooc_2.insert({"m":1})
db.imooc_2.insert({"n":1})
通过$exists可以判断字段是否存在
db.imooc_2.find({m:{$exists:true}})   // 筛选出有m字段的文档
给这个文档的m字段创建一个稀疏索引：
db.imooc_2.ensureIndex({m:1},{sparse:true})
第二条文档不存在m字段,所以不会创建这个索引
如果使用稀疏索引查找不存在稀疏索引字段的文档,mongodb则不会使用这个索引查找
db.imooc_2.find({m:{$exists:false}})  // 可以查到数据
但如果强制使用稀疏索引来查找索引上存在而文档中不存在的字段,则没有结果。再次说明稀疏索引不能用来查找索引上存在,但文档里不存在的字段
db.imooc_2.find({m:{$exists:false}}).hint("m_1") #查不出数据,因为n上并没有m字段的索引

✈ expireAfterSeconds  integer
指定一个以秒为单位的数值完成TTL设定,设定集合的生存时间
是否定时删除：expireAfterSeconds指定 过期索引(TTL索引)

✈ v     index version
索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本

✈ weights document
索引权重值,数值在 1 到 99,999 之间,表示该索引相对于其他索引字段的得分权重

✈ default_language  string   默认为英语
对于文本索引,该参数决定了停用词及词干和词器的规则的列表

✈ language_override string   默认值为 language
对于文本索引,该参数指定了包含在文档中的字段名,语言覆盖默认的language

【 索引的分类 】
MongoDB支持基于集合文档上任意列创建索引。缺省情况下,所有的文档的_id列上都存在一个索引
基于业务的需要,可以基于一些重要的查询和操作来创建一些额外的索引
索引可以是单列,也可是多列(复合索引),多键索引,地理空间索引,全文索引等

1、_id索引
绝大多数集合默认建立的索引,对于每个插入的数据,mongodb都会自动生成一条唯一的_id字段

2、单键索引
值为一个单一的值,如字符串、数字、日期;最普通的索引,不会自动创建
db.collection_name.ensureIndex({x:1})   // x字段上创建索引,之后就可以使用x为条件进行查询

3、多键索引
在MongoDB中可以基于数组来创建索引,mongodb为数组每一个元素创建索引值。多键索引支持数组字段的高效查询。多键索引能够基于字符串,数字数组以及嵌套文档进行创建
如果mongoDB中插入数组类型的多键数据,索引是自动建立的,无需刻意指定。但是,使用getIndexes()方法并没有多键索引,除非显式地创建多键索引

与单键索引创建形式相同,区别在于字段的值
多键索引的值具有多个记录,如一个数组
db.collection_name.insert({x: [1,2,3,4]})

4、复合索引
当查询条件不只一个时需要建立复合索引
db.collection_name.insert({x: 1, y: 2, z:3})
按照x和y的值查询时创建索引db.collection_name.ensureIndex({x:1, y:1})
使用{x:1, y:1}作为条件进行查询

5、过期索引(TTL索引)
特殊类型的单字段索引,不能是复合索引,在一段时间后会会过期的索引,相应的数据会被自动删除,即数据会过期
适合存储如用户登录信息、存储的日志和会话信息数据
存储在过期索引字段值必须是指定的时间类型,必须是ISODate或者ISOData数组,不能使用时间戳,否则不能自动删除
如果指定了ISOData数组数组,则按照最小的时间进行删除
删除时间不是精确,删除过程是由后台程序60s跑一次,删除也需要时间,所以存在误差,最少也要60秒才能被删除
db.collection_name.ensureIndex({time:1},{expireAfterSeconds:10})
db.collection_name.insert({time: new Date()})
db.collection_name.insert({time: 1})            不会删除
db.collection_name.insert({time: +new Date()})  值为时间戳的字段文档不会被自动到期删除

6、全文索引、文本索引
全文检索对每一个词建立一个索引,指明该词在文章中出现的次数和位置,当用户查询时,检索程序就根据事先建立的索引进行查找,并将查找的结果反馈给用户的检索方式;类似于通过字典中的检索字表查字的过程

对字符串和字符串数组创建全文可搜索的索引
每个数据集合中只允许创建一个全文索引
适应情况{author: "", title: "", article: ""}
db.srticle.ensureIndex({key: "text"})
db.srticle.ensureIndex({key_1: "text", key_2: "text"})
db.srticle.ensureIndex({"$**": "text"})      对集合中所有字段创建大的全文索引
db.srticle.ensureIndex({"article": "text"})  article字段

使用全文索引查询：
db.srticle.find({$text:{$search: "coffee"}})    不再使用字段名
db.srticle.find({$text:{$search: "aa bb -cc"}}) 多关键词空格分割,或查询,-表示不包含
db.srticle.find({$text:{$search: "\"aa\" \"bb\" \"cc\""}}) 与查询,关键词双引号包裹,"前加\区分最外的"

全文索引相似度查询
$meta操作符:{score:{$meta:"textScore"}}
写在查询条件后面可以发挥返回结果的相似度,与sort一起使用达到很好的使用效果
db.srticle.find({$text:{$search: "aa bb"},{score:{$meta:"textScore"}}).sort({score:{$meta:"textScore"}})

删除全文索引
db.blog.dropIndex("post_text")  // 删除blog集合中post_text字段的索引

使用限制：
每次查询只能制定一个$text查询
$text查询不能出现在$nor(排除某些条件)查询中
查询中如果包含$text,hint不再起作用
mongodb全文索引还不支持中文

</pre><pre class="js">
// blog集合中文档数据
db.blog.insert({
  "post_text": "enjoy the mongodb articles on Runoob",
  "tags": [ "mongodb", "runoob" ]
})
db.blog.insert({
  "post_text": "Runoob: enjoy the mongodb articles on Runoob",
  "tags": [ "mongodb", "runoob" ]
})
db.blog.ensureIndex({post_text:"text"})   // 对post_text字段建立全文索引
db.blog.find({$text:{$search:"runoob"}})  // 使用全文索引,索引文章中的关键词"Runoob"

</pre><pre>
7、地理位置索引,社交软件附近的人
将一些点的位置存储在mongodbdb中,创建索引后可以那只位置来查找其他点
子分类：
2d索引,用于存储和查找平面的点
2dsphere索引,用于存储和查找球面上的点
查找方式：
1、查找距离某个点一定距离内的点
2、查找包含字啊某个区域内的点

2d索引：db.collection_name.ensureIndex({"w": "2d"})
[经度(-180,180), 纬度(-90,90)]
db.location.ensureIndex("w":"2d")
db.location.insert(w:[1,1])
db.location.insert(w:[180,90])

2d查询方式：
1、$near查询   查询距离某个点最近的所有点
2、$geoWhithin 查询某个形状内的点

形状的表示：
1、$box 矩形,使用{$box: [[< x1>,< y1>], [< x2>,< y2>]]}表示
2、$center 圆形,使用{$center: [[< x1>,< y1>], r]}表示
3、$polygon 多边形,使用{$polygon: [[< x1>,< y1>], [< x2>,< y2>], [< x3>,< y3>]]}表示

db.location.find({w:{$near:[1,1]}})
db.location.find({w:{$near:[1,1],$maxDistance:10}})  最大距离为10

db.location.find({w:{$geoWithin: {$box:[[0,0],[50,40]]}}})

geoNear查询：使用runCommand命令进行使用
db.runCommand({
  geoNear: < collection>,
  near: [x,y],
  minDistance: (对2d索引无效)
  maxdistance: ,
  num: (限制返回的数目)
})

db.runCommand({
  geoNear: "location",
  near: [1,2],
  minDistance: 10
  maxdistance: ,
  num: 1
})

2dsphere索引创建方式 db.collection_name.ensureIndex({"w": "2dsphere"})
位置表示：GeoJSON,描述一个点、一条直线、多变形等形状
{type: "", coordinates: [< coordinates>]}
查询方式和2d索引查询方式类似
支持$minDistance与$maxDistance

【 覆盖查询是以下的查询： 】
所有的查询字段是索引的一部分
所有的查询返回字段在同一个索引中

由于所有出现在查询中的字段是索引的一部分,MongoDB 无需在整个数据文档中检索匹配查询条件和返回使用相同索引的查询结果。
MongoDB的不会去数据库文件中查找。相反,它会从索引中提取数据,这是非常快速的数据查询
因为索引存在于RAM中,从索引中获取数据比通过扫描文档读取数据要快得多

</pre><pre class="js">
>db.blog.getIndexes()
[{
    "v" : 2,
    "key" : { "_id" : 1 },
    "name" : "_id_",
    "ns" : "test.blog"
}]
>db.blog.ensureIndex({title:1,by_user:1})
{
  "createdCollectionAutomatically" : false,
  "numIndexesBefore" : 1,
  "numIndexesAfter" : 2,
  "ok" : 1
}
> db.blog.getIndexes()
[
  {
    "v" : 2,
    "key" : { "_id" : 1 },
    "name" : "_id_",
    "ns" : "test.blog"
  },
  {
    "v" : 2,
    "key" : {
      "title" : 1,
      "by_user" : 1
    },
    "name" : "title_1_by_user_1",
    "ns" : "test.blog"
  }
]
>db.blog.find({title: "Neo4j Overview"},{by_user: 1})

</pre>【 索引数组、子文档字段 】<pre class="js">
// 文档包含了 address 子文档和 tags 数组
db.user.insert({
  "address": {
    "city": "Los Angeles",
    "state": "California",
    "pincode": "123"
  },
  "tags": [ "music", "cricket", "blogs" ],
  "name": "Tom Benzamin"
})

db.user.find({"tags" : {$type : 4}})
db.user.find({"name" : "Tom Benzamin"})

</pre><pre>
基于标签来检索用户,为此需要对集合中的数组 tags 建立索引
在数组中创建索引,需要对数组中的每个字段依次建立索引。所以在我们为数组 tags 创建索引时,会为 music、cricket、blogs三个值建立单独的索引

>db.user.ensureIndex({"tags":1})           创建数组索引
>db.user.find({tags:"cricket"})            检索集合的 tags 字段
>db.user.find({tags:"cricket"}).explain()  使用 explain 命令验证我们使用使用了索引

基于子文档的city、state、pincode字段来检索文档,需要对子文档建立索引

对子文档的字段创建索引：
db.user.ensureIndex({"address.city":1,"address.state":1,"address.pincode":1})
db.user.find({"address.city":"Los Angeles"})  使用子文档的字段检索数据

查询表达式必须遵循指定的索引的顺序
db.user.find({"address.city":"Los Angeles","address.state":"California"})
db.user.find({"address.city":"Los Angeles","address.state":"California","address.pincode":"123"})

</pre><pre>
【 评判当前索引构建情况 】
1、mongostat工具
2、profile集合: getProfilingStatus()
3、日志:
4、explain分析:

MongoDB 查询分析可以确保我们建议的索引是否有效,是查询语句性能分析的重要工具。
MongoDB 查询分析常用函数有：explain() 和 hint()

db.blog.find({"title" : "NoSQL Overview"},{"by_user":1,_id:0}).explain()

使用 hint() 来强制 MongoDB 使用一个指定的索引
db.blog.find({"title" : "NoSQL Overview"},{"by_user":1,_id:0}).hint({title:1,by_user:1})
//{ "by_user" : "runoob.com" }

可以使用 explain() 函数来分析以上查询：
db.blog.find({"title" : "NoSQL Overview"},{"by_user":1,_id:0}).hint({title:1,by_user:1}).explain()
db.users.find().explain("executionStats")

【 性能分析函数 explain() 】
MongoDB提供db.collection.explain()方法, cursor.explain()方法和explain命令去返回查询计划信息和查询计划的执行统计信息,为我们诊断查询提供了极大的便利

指定使用 gender 和 user_name 索引字段来查询：
使用 hint 来强制 MongoDB 使用一个指定的索引
>db.users.find({gender:"M"},{user_name:1,_id:0}).hint({gender:1,user_name:1})
可以使用 explain() 函数来分析以上查询：
>db.users.find({gender:"M"},{user_name:1,_id:0}).hint({gender:1,user_name:1}).explain()

支持下列操作返回查询计划
aggregate(); count(); distinct(); find(); group(); remove(); update()
cursor.explain(verbosity) 为一个游标返回其查询执行计划,其最通常的行式为db.collection.find().explain(),其中verbosity说明返回信息的粒度

执行计划中几类常见的操作描述(stage类型)：
COLLSCAN：全表扫描
IXSCAN：索引扫描
FETCH：根据索引去检索指定document
SHARD_MERGE：将各个分片返回数据进行merge
SORT：表明在内存中进行了排序
LIMIT：使用limit限制返回数
SKIP：使用skip进行跳过
IDHACK：针对_id进行查询
SHARDING_FILTER：通过mongos对分片数据进行查询
COUNT：利用db.coll.explain().count()之类进行count运算
COUNTSCAN：count不使用Index进行count时的stage返回
COUNT_SCAN：count使用了Index进行count时的stage返回
SUBPLA：未使用到索引的$or查询的stage返回
TEXT：使用全文索引进行查询时候的stage返回
PROJECTION：限定返回字段时候stage的返回

db.collection.find().explain(verbose) 输出一个以文档形式展现的执行计划,可以包括统计信息(可选)。

可选参数verbose：
缺省值为queryPlanner,用于查看指定执行计划的特定部分。即给定不同的参数则输出信息的详细程度不同
常用的包括queryPlanner,executionStats,以及allPlansExecution

queryPlanner模式:缺省模式。
MongoDB运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划
queryPlanner模式下并不会去真正进行query语句查询,而是针对query语句进行执行计划分析并选出winning plan

executionStats模式
mongoDB运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划进行执行
在执行完毕后返回这个最佳执行计划执行完成时的相关统计信息
对于写操作db.collection.explain()返回关于更新和删除操作的信息,但是并不将修改应用到数据库
对于那些被拒绝的执行计划,不返回其统计信息

allPlansExecution模式
该模式是前2种模式的更细化,即会包括上述2种模式的所有信息
即按照最佳的执行计划执行以及列出统计信息,而且还会列出一些候选的执行计划
如果有多个查询计划,executionStats信息包括这些执行计划的部分统计信息

db.collection.explain().find() 与db.collection.find().explain()类似,但是存在以下关键差异

The db.collection.explain().find() construct allows for the additional chaining of query modifiers.
For list of query modifiers, see db.collection.explain().find().help().

The db.collection.explain().find() returns a cursor, which requires a call to .next(), or its alias .finish(),
to return the explain() results. If run interactively in the mongo shell, the mongo shell
 automatically calls .finish() to return the results. For scripts, however, you must explicitly call .next(),
 or .finish(), to return the results. For list of cursor-related methods, see db.collection.explain().find().help().
db.collection.explain().aggregate() is equivalent to passing the explain option to the db.collection.aggregate() method.

</pre><pre class="js">
//获取explain的支持的运算方法
> db.collection.explain().help()
Explainable operations
        .aggregate(...) - explain an aggregation operation
        .count(...) - explain a count operation
        .distinct(...) - explain a distinct operation
        .find(...) - get an explainable query
        .findAndModify(...) - explain a findAndModify operation
        .group(...) - explain a group operation
        .remove(...) - explain a remove operation
        .update(...) - explain an update operation
Explainable collection methods
        .getCollection()
        .getVerbosity()
        .setVerbosity(verbosity)

//获取explain().find()支持的运算方法
> db.collection.explain().find().help()
Explain query methods
        .finish() - sends explain command to the server and returns the result
        .forEach(func) - apply a function to the explain results
        .hasNext() - whether this explain query still has a result to retrieve
        .next() - alias for .finish()
Explain query modifiers
        .addOption(n)
        .batchSize(n)
        .comment(comment)
        .count()
        .hint(hintSpec)
        .limit(n)
        .maxTimeMS(n)
        .max(idxDoc)
        .min(idxDoc)
        .readPref(mode, tagSet)
        .showDiskLoc()
        .skip(n)
        .snapshot()
        .sort(sortSpec)

</pre><pre class="js">
for(var i=0;i < 200;i++) db.explains.insert({"name":"ryan"+i,"age":i})
db.explains.createIndex({"age":1})
db.explains.find({age: {$lt: 80}}).explain("executionStats")

// stage阶段

{
  "queryPlanner" : {
    "plannerVersion" : 1,         // 查询计划的版本
    "namespace" : "study.users",  // 该query所查询的表
    "indexFilterSet" : false,     // 针对该query是否有indexfilter
    "parsedQuery" : {             // 解析查询即过滤条件是什么
            "age" : {
                    "$lt" : 80
            }
    },
    "winningPlan" : {          // 查询优化器针对该query所返回的最优执行计划的详细内容
        "stage" : "FETCH",     // 最优执行计划的stage,这里返回是FETCH,通过返回的index位置检索具体文档
        "inputStage" : {       // 用来描述子stage,并且为其父stage提供文档和索引关键字
            "stage" : "IXSCAN",// child stage, IXSCAN表示index scanning
            "keyPattern" : {   // 所扫描的index内容
                    "age" : 1
            },
            "indexName" : "age_1", // winning plan所选用的index
            "isMultiKey" : false,  // 是否是MultiKey,如果索引建立在array上将是true
            "multiKeyPaths" : {
                    "age" : [ ]
            },
            "isUnique" : false,
            "isSparse" : false,
            "isPartial" : false,
            "indexVersion" : 2,
            "direction" : "forward", // 此query的查询顺序,如果用.sort({modify_time:-1})将显示backward
            "indexBounds" : {
                    "age" : [
                            "[-inf.0, 80.0)"
                    ]
            }
        }
    },
    "rejectedPlans" : [ ]          // 其他执行计划(非最优而被查询优化器reject的)的详细返回
  },
  "executionStats" : {
    "executionSuccess" : true,    // 是否执行成功
    "nReturned" : 80,             // 返回结果集的数目
    "executionTimeMillis" : 64,   // 该query的整体执行时间,毫秒
    "totalKeysExamined" : 80,     // 索引扫描次数
    "totalDocsExamined" : 80,     // 检查文档总数,文档索引次数
    "executionStages" : {
        "stage" : "FETCH",        // 扫描方式,FETCH去扫描对于documents
        "nReturned" : 80,
        "executionTimeMillisEstimate" : 0, // 预估的执行时间,毫秒
        "works" : 81,             //工作单元数,一个查询会被派生为一些小的工作单元
        "advanced" : 80,          //优先返回的结果数目
        "needTime" : 0,
        "needYield" : 0,
        "saveState" : 0,
        "restoreState" : 0,
        "isEOF" : 1,
        "invalidates" : 0,
        "docsExamined" : 80,
        "alreadyHasObj" : 0,
        "inputStage" : {
            "stage" : "IXSCAN",
            "nReturned" : 80,
            "executionTimeMillisEstimate" : 0, //  该查询扫描2001行index所用时间
            "works" : 81,
            "advanced" : 80,
            "needTime" : 0,
            "needYield" : 0,
            "saveState" : 0,
            "restoreState" : 0,
            "isEOF" : 1,
            "invalidates" : 0,
            "keyPattern" : {
                    "age" : 1
            },
            "indexName" : "age_1",
            "isMultiKey" : false,
            "multiKeyPaths" : {
                    "age" : [ ]
            },
            "isUnique" : false,
            "isSparse" : false,
            "isPartial" : false,
            "indexVersion" : 2,
            "direction" : "forward",
            "indexBounds" : {
                    "age" : [
                            "[-inf.0, 80.0)"
                    ]
            },
            "keysExamined" : 80,
            "seeks" : 1,
            "dupsTested" : 0,
            "dupsDropped" : 0,
            "seenInvalidated" : 0
        }
    }
  },
  "serverInfo" : {
      "host" : "LAPTOP-0KMQM01D",
      "port" : 27017,
      "version" : "3.4.10",
      "gitVersion" : "078f28920cb24de0dd479b5ea6c66c644f6326e9"
  },
  "ok" : 1
}

</pre>
</div>

<div id="safe">
<h3>mongodb安全</h3><pre>
1、物理隔离,最安全,但不现实
2、网络隔离
3、防火墙隔离,IP白名单
4、用户名密码

1.启用访问控制(授权)和强制验证
启用访问控制并指定认证机制。可以使用默认的MongoDB身份验证机制或现有的外部框架。 认证要求所有客户端和服务器在连接到系统之前提供有效的凭据。 在群集部署中,为每个MongoDB服务器启用身份验证。

2.配置基于角色的访问控制
先创建用户管理员,然后创建其他用户。 为访问系统的每个人员和应用程序创建一个唯一的MongoDB用户。
创建定义一组用户需要的确切访问权限的角色。 遵循最低权限的原则。 然后创建用户并分配他们只需要执行其操作所需的角色。用户可以是个人或客户端应用程序。

3.加密通信
配置MongoDB为所有传入和传出连接使用TLS/SSL。 使用TLS/SSL加密MongoDB部署的mongod和mongos组件之间以及所有应用程序和MongoDB之间的通信。

4.加密和保护数据
从MongoDB Enterprise 3.2开始,WiredTiger存储引擎的本机加密在Rest中可以配置为加密存储层中的数据。
如果您没有使用WiredTiger的加密功能,则应使用文件系统,设备或物理加密在每台主机上对MongoDB数据进行加密。 使用文件系统权限保护MongoDB数据。MongoDB数据包括数据文件,配置文件,审核日志和密钥文件。

5.限制网络曝光
确保MongoDB在受信任的网络环境中运行,并限制MongoDB实例监听传入连接的接口。 只允许受信任的客户端访问MongoDB实例可用的网络接口和端口。

6.审计系统活动
跟踪数据库配置和数据的访问和更改。 MongoDB Enterprise包括一个系统审核工具,可以在MongoDB实例上记录系统事件(例如用户操作,连接事件)。 这些审核记录允许进行法证分析,并允许管理员验证正确的控制。

7.使用专用用户运行MongoDB
使用专用的操作系统用户帐户运行MongoDB进程。 确保帐户具有访问数据但没有不必要权限的权限而导致的安全问题。

8.使用安全配置选项运行MongoDB
MongoDB支持执行某些服务器端操作的JavaScript代码：mapReduce,group和$where。 如果不使用这些操作,请使用命令行上的--noscripting选项禁用服务器端脚本。

在生产部署中仅使用MongoDB线路协议。 不启用以下功能,所有这些都启用了Web服务器接口：net.http.enabled,net.http.JSONPEnabled和net.http.RESTInterfaceEnabled。保持这些禁用,除非向后兼容性要求。

保持输入验证有效。 MongoDB默认通过wireObjectCheck设置启用输入验证。 这确保了mongod实例存储的所有文档都是有效的BSON。

【 安全认证 】
用户验证
mongodb提供了addUser方法,如果在admin数据库中添加将会被视为"超级管理员"
> mongo 127.0.0.1/admin
> db.addUser('admin', 'admin')            // admin数据库用户是超级管理员
> use test
> db.addUser('tester', 'tester', true)    // 三参表示只读用户
--reinstall重启服务,并以--auth验证模式登录
> mongo 127.0.0.1/test
> db.person.find()                        // unauthorized
> db.person.insert({name: 'hxc'})         // unauthorized
> db.auth('tester', 'tester')             // 1
> db.person.find()
> db.person.insert({name: 'hxc'})         // unauthorized

【 开启权限认证 】
mongodb存储所有的用户信息在admin数据库的集合system.users中,保存用户名、密码和数据库信息。mongodb默认不启用权限认证。若要启用安全认证,需要更改配置文件参数authorization,也可以简写为auth

1、auth开启
配置文件中auth=true
但是不使用用户名和密码依然可以连接到数据库,这是因为我们还没有创建用户。在用户创建并且开启权限认证之后,如果不使用用户名和密码将不能够连接到数据库

2、keyfile开启

可以在启用访问控制之前或之后创建用户
> db.getUsers()               列出数据库的所有用户

【 角色管理 】
MongoDB采用基于角色的访问控制(RBAC)来确定用户的访问。 授予一个用户一个或多个角色,确定用户对MongoDB资源的访问权限和用户可以执行哪些操作。 用户应该只有最小权限集才能确保最小权限的系统。
MongoDB系统的每个应用程序和用户都应该映射到不同的用户。 这种访问隔离便于访问撤销和持续的用户维护

数据库角色在创建用户中的role参数中设置。角色分为内建角色和自定义角色

MongoDB内建角色包括以下几类：
1、数据库用户角色
read：允许用户读取指定数据库
readWrite：允许用户读写指定数据库

2、数据库管理员角色
dbAdmin：允许用户进行索引创建、删除,查看统计或访问system.profile,但没有角色和用户管理的权限
userAdmin：提供了在当前数据库中创建和修改角色和用户的能力
dbOwner： 提供对数据库执行任何管理操作的能力,组合了readWrite、dbAdmin和userAdmin角色授予的特权。

3、集群管理角色
clusterAdmin ：提供最强大的集群管理访问,组合clusterManager、clusterMonitor和hostManager角色的能力,还提供了dropDatabase操作
clusterManager ： 在集群上提供管理和监视操作。可以访问配置和本地数据库,这些数据库分别用于分片和复制
clusterMonitor ： 提供对监控工具的只读访问,例如MongoDB云管理器和Ops管理器监控代理。
hostManager ： 提供监视和管理服务器的能力。

4、备份恢复角色
backup ： 提供备份数据所需的能力,使用MongoDB云管理器备份代理、Ops管理器备份代理或使用mongodump
restore ： 提供使用mongorestore恢复数据所需的能力

5、所有数据库角色
readAnyDatabase：只在admin数据库中可用,赋予用户所有数据库的读权限
readWriteAnyDatabase：只在admin数据库中可用,赋予用户所有数据库的读写权限
userAdminAnyDatabase：只在admin数据库中可用,赋予用户所有数据库的userAdmin权限
dbAdminAnyDatabase：只在admin数据库中可用,赋予用户所有数据库的dbAdmin权限。

6、超级用户角色
root：提供对readWriteAnyDatabase、dbAdminAnyDatabase、userAdminAnyDatabase、clusterAdmin、restore和backup的所有资源的访问

7、内部角色
__system : 提供对数据库中任何对象的任何操作的特权

自定义角色:
除了使用内建的角色之外,MongoDB还支持使用db.createRole()方法来自定义角色
[注意]只能在admin数据库中创建角色,否则会失败
role: 自定义角色的名称
privileges: 权限操作　
roles：继承的角色。如果没有继承的角色,可以设置为空数组　　

use admin
db.createRole(
  {
   role: "myClusterwideAdmin",
   privileges: [
     { resource: { cluster: true }, actions: [ "addShard" ]},
     { resource: { db: "config", collection: "" }, actions: [ "find", "update", "insert", "remove" ]},
     { resource: { db: "users", collection: "usersCollection" }, actions: [ "update","insert","remove"]},
     { resource: { db: "", collection: "" }, actions: [ "find" ]}
   ],
   roles: [
     { role: "read", db: "admin" }
   ]
  },
  { w: "majority" , wtimeout: 5000 }
)

【 创建管理员用户 】
> use admin
> db.createUser({
  user: "berlin",
  pwd:  "berlin",
  customData: "description",
  roles: [{role: "root", db: "admin"}]
})
> exit

登录 bin>mongo -u berlin -p  --authenticationDatabase admin

【 添加数据库用户 】
> use blog
> db.createUser({
  user: "heiying6958",
  pwd: "heiying6958",
  roles: ["readWrite"]
})
> db.auth('user01','pwd123')  验证身份验证,返回结果为1表示认证成功

> use admin
> db.createUser(
   {
     user: "myadmin1",
     pwd: "myadmin123",
     roles:
       [
         { role: "readWrite", db: "config" },
         "clusterAdmin"
       ]
   }
);

【 删除数据库用户 】
> use blog
> db.dropUser("heiying6958")

【 示例 】
以下过程首先将用户管理员添加到运行无访问控制的 MongoDB 实例,然后启用访问控制
1、启动mongod,启动MongoDB无需访问控制
2、启动mongo,使用mongo shell连接到实例
3、创建用户管理员

创建用户的数据库(admin)是用户的身份验证数据库。用户将对该数据库进行身份验证,但用户可以在其他数据库中担任角色; 即用户的认证数据库不限制用户的权限

在管理数据库中添加具有userAdminAnyDatabase角色的用户。如在admin数据库中创建用户myUserAdmin
> use admin
> db.createUser(
  {
    user: "myUserAdmin",
    pwd: "abc123",
    roles: [ { role: "userAdminAnyDatabase", db: "admin" } ]
  }
)
> exit

4、重新启动具有访问控制的MongoDB实例mongod,连接到此实例的客户端现在必须以MongoDB用户身份进行身份验证。客户只能执行由其分配的角色确定的操作
mongod --dbpath "E:\data\db"

5、以用户管理员身份进行连接和验证
使用mongo shell,可以：
通过传递用户凭据或
连接第一个withouth身份验证,然后发出db.auth()方法进行身份验证。

在连接期间进行身份验证
使用-u username, -p password和--authenticationDatabase database命令行选项启动一个mongo shell：
> mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"

连接后验证
将mongo shell连接到mongodb,也就是先连接后验证用户身份 ：
mongo --port 27017

切换到身份验证数据库(在这种情况下为admin),并使用db.auth(username, pwd)方法进行身份验证：
use admin
db.auth("myUserAdmin", "abc123" )

6、根据需要创建其他用户
当管理员用户进行身份验证通过之后,可使用db.createUser()创建其他用户。可以为用户分配任何内置角色或用户定义的角色。

myUserAdmin用户只具有管理用户和角色的权限。如果使用myUserAdmin尝试执行任何其他操作,例如从test数据库中的foo集合读取数据,MongoDB将返回错误。

以下操作将用户myTeste 添加到在test数据库中并给予test数据库的readWrite角色以及在reporting数据库中读取角色
use test
db.createUser(
  {
    user: "myTester",
    pwd: "xyz123",
    roles: [ { role: "readWrite", db: "test" },
             { role: "read", db: "reporting" } ]
  }
)

7、连接并验证为myTester
在连接期间进行身份验证
使用-u username,-p password和--authenticationDatabase database命令行选项启动一个mongo shell：
$ mongo --port 27017 -u "myTester" -p "xyz123" --authenticationDatabase "test"

连接后验证
将mongo shell连接到 mongodb：
$ mongo --port 27017

切换到身份验证数据库(在这里为test),并使用db.auth(username, pwd)方法进行身份验证：
> use test
> db.auth("myTester", "xyz123" )

使用用户myTester插入一个集合
使用用户myTester,此用户有权在test数据库中执行读写操作(以及在reporting数据库中执行读操作)。 例如在test数据库中执行以下插入操作：
>  db.foo.insert( { x: 1, y: 1 } )

最后使用用户myTester,在reporting数据库中执行插入操作看看返回结果：
> use reporting
db.auth("myTester", "xyz123" )
db.product.insert( { x: 1, y: 1 } )

【 创建用户定义的角色 】
角色授权用户访问MongoDB资源。 MongoDB提供了许多内置的角色,管理员可以使用它们来控制对MongoDB系统的访问。 但是如果这些角色无法描述所需的权限集则可以在特定数据库中创建新角色。

除了在管理数据库中创建的角色外,角色只能包含适用于其数据库的权限,并且只能继承其数据库中的其他角色。

在管理数据库中创建的角色可以包括适用于管理数据库,其他数据库或群集资源的权限,并且可以从其他数据库中的角色以及管理数据库继承。

要创建新角色可使用db.createRole()方法指定permissions数组中的权限和roles数组中的继承角色。

MongoDB使用数据库名称和角色名称的组合来唯一定义角色。 每个角色的范围限定在创建角色的数据库中,但MongoDB将所有角色信息存储在admin数据库的admin.system.roles集合中

要在数据库中创建角色必须具有：
对该数据库资源的createRole操作。
对该数据库的grantRole操作指定新角色的权限以及指定要继承的角色。
内置角色userAdmin和userAdminAnyDatabase在其各自的资源上提供createRole和grantRole操作

创建角色来管理当前操作
以下示例创建一个名为manageOpRole的角色,该角色仅提供运行db.currentOp()和db.killOp()的权限。

第一步：使用相应的权限连接到MongoDB
使用"先决条件"部分指定的权限连接到mongod或mongos 。

以下过程使用在"启用认证"中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"
myUserAdmin具有在管理员以及其他数据库中创建角色的权限。

第二步：创建一个新角色来管理当前操作
manageOpRole具有对多个数据库以及群集资源的权限,因此必须在管理数据库中创建该角色。
use admin
db.createRole(
   {
     role: "manageOpRole",
     privileges: [
       { resource: { cluster: true }, actions: [ "killop", "inprog" ] },
       { resource: { db: "", collection: "" }, actions: [ "killCursors" ] }
     ],
     roles: []
   }
)

新角色授予杀死/终止任何操作的权限。

警告: 终止运行操作非常小心。只能使用db.killOp()方法或killOp命令终止客户端发起的操作,并且不会终止内部数据库操作。

创建角色用来运行mongostat
以下示例创建一个名为mongostatRole的角色,该角色仅提供运行mongostat的权限。

第一步：使用相应的权限连接到MongoDB
使用"先决条件"部分指定的权限连接到mongod或mongos

以下过程使用在启用认证中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"
myUserAdmin具有在管理员以及其他数据库中创建角色的权限。

第二步：创建一个新角色来管理当前的操作
mongostatRole具有作用于群集资源的权限,因此必须在管理数据库中创建该角色。
use admin
db.createRole(
   {
     role: "mongostatRole",
     privileges: [
       { resource: { cluster: true }, actions: [ "serverStatus" ] }
     ],
     roles: []
   }
)

修改现有用户的访问权限
先决条件
必须对数据库具有grantRole操作才能在该数据库上授予角色。
必须在数据库上具有revokeRole操作以撤销该数据库上的角色。
要查看角色的信息,必须明确授予该角色,或必须对该角色的数据库具有viewRole操作。
执行步骤

第一步：使用相应的权限连接到MongoDB
以具有先决条件部分中指定的权限的用户身份连接到 mongod 或 mongos 。

以下过程使用在启用认证中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"

第二步：识别用户的角色和权限
要显示要修改的用户的角色和权限,请使用db.getUser()和db.getRole()方法。
例如查看在示例中创建的reportsUser的角色执行以下命令：
use reporting
db.getUser("reportsUser")

要显示在"accounts"数据库上由readWrite角色授予用户的权限,请执行以下操作：
use accounts
db.getRole( "readWrite", { showPrivileges: true } )

第三步：确定授予或撤销的权限
如果用户需要额外的权限,则向用户授予具有所需权限集的角色或角色。 如果此类角色不存在,请使用适当的权限集创建新角色。
撤销由现有角色提供的特权子集：撤销原始角色并授予仅包含所需权限的角色。如果角色不存在,您需要创建新角色。

第四步：修改用户的访问权限
4.1. 撤销角色
使用db.revokeRolesFromUser()方法撤销角色。以下示例操作从account数据库上删除用户reportsUser 的 readWrite 角色：
use reporting
db.revokeRolesFromUser(
    "reportsUser",
    [
      { role: "readWrite", db: "accounts" }
    ]
)

4.2. 授予角色
使用db.grantRolesToUser()方法授予角色。 例如,以下操作授予reportsUser用户account数据库上的读取角色：
use reporting
db.grantRolesToUser(
    "reportsUser",
    [
      { role: "read", db: "accounts" }
    ]
)

对于分片集群,用户的更改将在命令运行的 mongos 上即时生效。但是,对于群集中的其他mongos 实例,用户缓存可能会等待10分钟才能刷新。请参阅userCacheInvalidationIntervalSecs。

修改现有用户的密码
先决条件
要修改数据库上另一个用户的密码,您必须对该数据库具有changeAnyPassword操作。

操作步骤：
第一步：使用相应的权限连接到MongoDB
以具有先决条件部分中指定的权限的用户身份连接到 mongod 或 mongos 。

以下过程使用在启用认证中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"

第二步：更改密码
将用户的用户名和新密码传递给db.changeUserPassword()方法。

以下操作将reporting用户的密码更改为：SOh3TbYhxuLiW8ypJPxmt1oOfL：
db.changeUserPassword("reporting", "SOh3TbYhxuLiW8ypJPxmt1oOfL")

看用户的角色
先决条件
要查看其他用户的信息,您必须对其他用户的数据库具有viewUser操作。
用户可以查看自己的信息。
第一步：使用相应的权限连接到MongoDB
以具有先决条件部分中指定的权限的用户身份连接到 mongod 或 mongos 。

以下过程使用在启用认证中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"

第二步：查看用户的角色
使用usersInfo命令或db.getUser()方法显示用户信息。
例如,要查看在示例中创建的 reportsUser 的角色,请发出：
use reporting
db.getUser("reportsUser")

在返回的文档中,roles字段显示reportsUser的所有角色：
"roles" : [
   { "role" : "readWrite", "db" : "accounts" },
   { "role" : "read", "db" : "reporting" },
   { "role" : "read", "db" : "products" },
   { "role" : "read", "db" : "sales" }
]

查看角色的权限
先决条件
要查看角色的信息,您必须明确授予该角色,或必须对该角色的数据库具有 viewRole 操作。

第一步：使用相应的权限连接到MongoDB
以具有先决条件部分中指定的权限的用户身份连接到 mongod 或 mongos 。

以下过程使用在启用认证中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"

第二步：查看角色授予的权限
对于给定的角色,请使用db.getRole()方法或rolesInfo命令与showPrivileges选项一起执行：

例如,要查看在product数据库上由读取角色授予的权限,请使用以下操作,问题如下：

use products
db.getRole( "read", { showPrivileges: true } )
Shell
在返回的文档中,有两个数组：privileges和inheritedPrivileges。权限列出了角色指定的权限,并排除了从其他角色继承的权限。 inheritedPrivileges列出了由此角色授予的所有权限,这两个角色都是直接指定的并被继承。 如果该角色不能从其他角色继承,则两个字段是相同的。

...
"privileges" : [
  {
    "resource": { "db" : "products", "collection" : "" },
    "actions": [ "collStats","dbHash","dbStats","find","killCursors","planCacheRead" ]
  },
  {
    "resource" : { "db" : "products", "collection" : "system.js" },
    "actions": [ "collStats","dbHash","dbStats","find","killCursors","planCacheRead" ]
  }
],
"inheritedPrivileges" : [
  {
    "resource": { "db" : "products", "collection" : "" },
    "actions": [ "collStats","dbHash","dbStats","find","killCursors","planCacheRead" ]
  },
  {
    "resource" : { "db" : "products", "collection" : "system.js" },
    "actions": [ "collStats","dbHash","dbStats","find","killCursors","planCacheRead" ]
  }
]

【 MongoDB更改用户密码和自定义数据 】
具有适当权限的用户可以更改自己的密码和自定义数据。 自定义数据存储可选的用户信息。

注意事项
在此过程要生成一个强大的密码,您可以使用openssl实用程序的rand命令。 例如,使用以下选项发出openssl rand,以创建48个伪随机字节的base64编码字符串：
openssl rand -base64 48

先决条件
要修改自己的密码和自定义数据,您必须具有在用户数据库上分别授予changeOwnPassword和changeOwnCustomData操作的权限。

第一步：使用相应的权限连接到MongoDB
使用"先决条件"部分指定的权限连接到 mongod 或 mongos 。

以下过程使用在"启用认证"中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"

第二步：使用适当的权限创建角色
在管理数据库中,使用changeOwnPassword和changeOwnCustomData创建一个新角色。
use admin
db.createRole(
   { role: "changeOwnPasswordCustomDataRole",
     privileges: [
        {
          resource: { db: "", collection: ""},
          actions: [ "changeOwnPassword", "changeOwnCustomData" ]
        }
     ],
     roles: []
   }
)

第三步：添加具有此角色的用户
在test数据库中,使用创建的"changeOwnPasswordCustomDataRole"角色创建一个新用户。 例如,以下操作将创建具有内置角色readWrite和用户创建的"changeOwnPasswordCustomDataRole"的用户。
use test
db.createUser(
   {
     user:"user123",
     pwd:"12345678",
     roles:[ "readWrite", { role:"changeOwnPasswordCustomDataRole", db:"admin" } ]
   }
)

要向现有用户授予新角色,请使用db.grantRolesToUser()。

执行过程
第一步：使用相应的权限连接到MongoDB
使用"先决条件"部分指定的权限连接到 mongod 或 mongos 。

以下过程使用在"启用认证"中创建的用户：myUserAdmin。
$ mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"

要检查您是否具有先决条件部分中指定的权限以及查看用户信息,请使用带有--showPrivileges选项的usersInfo命令。

第二步：更改您的密码和自定义数据
使用db.updateUser()方法来更新密码和自定义数据。
例如,以下操作将用户的密码更改为：KNlZmiaNUp0B,并将自定义数据更改为{title："Senior Manager"}：
use test
db.updateUser(
   "user123",
   {
      pwd: "KNlZmiaNUp0B",
      customData: { title: "Senior Manager" }
   }
)

【 用户权限方法 】
db.auth()
db.changUserPassword()
db.dropUser()
db.dropAllUsers()
db.getUser()
db.getUsers()
db.grantRolesToUser()
db.removeUser()
db.revokeRolesFromUser()
db.updateUser()

</pre>

<h3>MongoDB 复制(副本集)将数据同步在多个服务器的过程</h3><pre>
MongoDB最大优点在于读扩展,热备份,故障恢复以及自动分片(写扩展)
sql server能够做到读写分离,双机热备份和集群部署,当然mongodb也能做到,实际应用中我们不希望数据库采用单点部署,如果碰到数据库宕机或者被毁灭性破坏那是多么的糟糕

备份复制实现了数据库备份的同时,实现了读写分离,又实现了读操作的负载均衡,即一台主写服务器,多台从属备份和读服务器,并且支持备份和读的集群扩展。其中Replica Sets方式又支持故障切换,当主服务器down掉后会投票选出一台从服务器接替为主服务器实现写操作。而自动分片功能会将原先的集合(表),自动分片到其它服务器上,实现分布式存储,即缓解单表数据量过大,同时又实现写操作的负载均衡

【 主从复制 Master-Slave 】
主从复制模式：即一台主写入服务器,多台从备份服务器。从服务器可以实现备份,和读扩展,分担主服务器读密集时压力,充当查询服务器。但是主服务器故障时,我们只能手动去切换备份服务器接替主服务器工作。这种灵活的方式,使扩展多如备份或查询服务器相对比较容易,当然查询服务器也不是无限扩展的,因为这些从服务器定期在轮询读取主服务器的更新,当从服务器过多时反而会对主服务器造成过载

主服务器可以通过自己local库的slave集合查看从服务器列表
从服务器可以通过自己local库的source集合查看主服务器信息或维护多个主服务器。 (一个slave服务器可以服务多个master服务器)
或者我们可以通过http console查看状态

模拟多服务器部署
1、虚拟机
2、把mongodb文件夹放在D盘和E盘

1、启动D盘上的mongodb,把该数据库指定为主数据库,命令：>mongodb --dbpath=D:\mongodb\data\db --master
端口还是默认的27017

2、同样的方式启动E盘上的mongodb,指定该数据库为从属数据库,要换一个端口,比如：8888。
source 表示主数据库的地址。
命令：>mongod --dbpath=E:\mongodb\data\db --port=8888 --slave --source=127.0.0.1:27017
"applied 1 operations"这样的语句,并且发生的时间相隔10s,也就说明从属数据库每10s就向主数据库同步数据,同步依据也就是寻找主数据库的"OpLog"日志,可以在图中红色区域内发现"sync_pullOpLog"字样

3、如果还想增加一台从属数据库,但是不想在启动时就指定而是后期指定
主或从属数据库中都有一个叫做local的集合,主要是用于存放内部复制信息
在F盘再拷贝一份mongodb的运行程序
命令：>mongod --dbpath=F:\mongodb\data\db --port=8080 --slave
再开一个cmd窗口,语句也就是在sources中add一个host地址,最后发现数据也同步到127.0.0.1:5555这台从属数据库中
F:\\ > mongo 127.0.0.1:8080
F:\\ > use local
F:\\ > db.sources.insert({host: "127.0.0.1:27017"})
F:\\ > db.sources.find()
F:\\ > db.sources.find()

读写分离
这种手段在大一点的架构中都有实现,在mongodb中其实很简单,在默认的情况下从属数据库不支持数据的读取,但是没关系,
在驱动中提供了一个叫做"slaveOkay"来显示的读取从属数据库来减轻主数据库的性能压力

mongodb的读写分离使用Replica Sets来实现
对于replica set 中的secondary 节点默认是不可读的。在写多读少的应用中,使用Replica Sets来实现读写分离。通过在连接时指定或者在主库指定slaveOk,由Secondary来分担读的压力,Primary只承担写操作。
如果通过shell访问mongo,要在secondary进行查询。会出现如下错误：
imageSet:SECONDARY> db.fs.files.find()
error: { "$err" : "not master and slaveOk=false", "code" : 13435 }
有两种方法实现从机的查询：
第一种方法：db.getMongo().setSlaveOk();
第二种方法：rs.slaveOk();
但是这种方式有一个缺点就是,下次再通过mongo进入实例的时候,查询仍然会报错,为此可以通过下列方式
vi ~/.mongorc.js
增加一行rs.slaveOk();
这样的话以后每次通过mongo命令进入都可以查询了

【 副本集 Replica Sets 】
副本集模式具有Master-Slave模式所有特点,但是副本集没有固定的主服务器,当初始化的时候会通过多个服务器投票选举出一个主服务器。当主服务器故障(宕机)时会再次通过投票选举出新的主服务器,而原先的主服务器恢复后则转为从服务器,这就具备了自动故障恢复功能。Replica Sets的在故障发生时自动切换的机制可以极时保证写入操作

复制提供了数据的冗余备份,并在多个服务器上存储数据副本,提高了数据的可用性, 并可以保证数据的安全性。
复制还允许从硬件故障和服务中断中恢复数据,无需停机维护(如备份,重建索引,压缩),分布式读取数据

MongoDB复制原理：
mongodb的复制至少需要两个节点。其中一个是主节点,负责处理客户端请求,其余的都是从节点,负责复制主节点上的数据。
mongodb各个节点常见的搭配方式为：一主一从、一主多从。
主节点记录在其上的所有操作oplog,从节点定期轮询主节点获取这些操作,然后对自己的数据副本执行这些操作,从而保证从节点的数据与主节点一致

MongoDB支持主从复制。主机可以执行读写操作,从机从主机复制数据,只能用于读取或备份(不写入)

副本集特征：
N个节点的集群
任何节点可作为主节点
所有写入操作都在主节点上
自动故障转移
自动恢复

【 建立副本集集群 创建多个副本集节点 --replSet,注意要区分大小写,官方建议命名空间使用IP地址 】
取集群名字为nodejs,--replSet表示让服务器知道nodejs下还有其他数据库,指定端口为3333是nodejs集群下的另一个数据库服务器
D://mongodb/bin> mongod --dbpath=D:/mongodb/data/db --port 2222 --replSet nodejs/127.0.0.1:3333
E://mongodb/bin> mongod --dbpath=E:/mongodb/data/db --port 3333 --replSet nodejs/127.0.0.1:2222
F://mongodb/bin> mongod --dbpath=F:/mongodb/data/db --port 4444 --replSet nodejs/127.0.0.1:2222
首先建立3个是为了投票不会冲突,当服务器为偶数时可能会导致无法正常选举出主服务器
其次上面3个replset 节点没有全部串联起来,是因为replset有自检测功可以自动搜索连接其它服务器

log信息告诉我们要初始化副本集
随便连接一下哪个服务器都行(priority 0~1,被选为主服务器的优先级),不过一定要进入admin集合
D://mongodb/bin> mongo 127.0.0.1:2222/admin
> db.runCommand({replSetInitiate:{
  _id: "nodejs",
  members: [
    {_id: 1, host: '127.0.0.1:2222'},
    {_id: 2, host: '127.0.0.1:33333'}
  ]
}})
成功启动之后就可以在日志中查看主数据库服务器

sql server里面有一个叫做仲裁服务器,那么mongodb中也是有的,跟sql server一样,仲裁只参与投票选举,这里把F盘的mongodb作为仲裁服务器,然后指定nodejs集群中的任一个服务器端口,这里就指定2222
://mongodb/bin> mongod --dbpath=F:/mongodb/data/db --port 4444 --replSet nodejs/127.0.0.1:2222
然后我们在admin集合中使用rs.addArb()追加即可,或者rs.add("127.0.0.1:4444");   或者rs.add({"_id":4,"host":"127.0.0.1:4444"})
D://mongodb/bin> mongo 127.0.0.1:2222/admin
Primary> rs.addArb('127.0.0.1:4444')
追加好了之后使用rs.status()来查看下集群中的服务器状态,可以清楚的看到谁是主,还是从,还是仲裁。

集群有自动故障恢复测试：
在2222端口的cmd服务器按Ctrl+C来KO掉该服务器,立马我们发现
在3333端口的从属服务器即可顶上,最后大家也可以再次使用rs.status()来看下集群中服务器的状态

【 Master Slave/ Replica Sets 备份机制 】
这两种模式都是基于主服务器的oplog 来实现所有从服务器的同步
oplog记录了增删改操作的记录信息(不包含查询的操作),但是oplog有大小限制,当超过指定大小,oplog会清空之前的记录,重新开始记录

Master Slave方式 主服务器会产生oplog.$main的日志集合
Replica Sets 方式 所有服务器都会产生oplog.rs日志集合

两种机制下所有从服务器都会去轮询主服务器oplog日志,若主服务器的日志较新,就会同步这些新的操作记录。但是这里有个很重要的问题,从服务器由于网络阻塞,死机等原因无法极时同步主服务器oplog记录：一种情况 主服务器oplog不断刷新,这样从服务器永远无法追上主服务器。另外一种情况,刚好主服务器oplog超出大小,清空了之前的oplog,这样从服务器就与主服务器数据就可能会不一致了,这第二种情况是推断的,没有证实。

另外要说明一下Replica Sets备份的缺点,当主服务器发生故障时,一台从服务器被投票选为了主服务器,但是这台从服务的oplog 如果晚于之前的主服务器oplog的话,那之前的主服务器恢复后,会回滚自己的oplog操作和新的主服务器oplog保持一致。由于这个过程是自动切换的,所以在无形之中就导致了部分数据丢失

【 自动分片技术 】
在Mongodb里面存在另一种集群,就是分片技术,可以满足MongoDB数据量大量增长的需求。
当MongoDB存储海量的数据时,一台机器可能不足以存储数据,也可能不足以提供可接受的读写吞吐量。这时,我们就可以通过在多台机器上分割数据,使得数据库系统能存储和处理更多的数据

分片：mongodb采用将集合进行拆分,然后将拆分的数据均摊到几个片上的一种解决方案

自动分片：将原先数据库中集合依据一定的规则切分成若干小块,这些分片小块统一由mongos路由管理,当有请求查询或写入时,路由会依据分片shard key规则找到对应的分片操作。分片解决了写密集操作,用于分散单一写服务器负载。亦或者原先的存储空间不够了,这个时候可能通过分片操作将之后的数据写入其它存储空间上。可以看出,集合的分片和数据库的分表类似,并且每个分片都支持写操作。由于分片的出现,导致数据被分布式的存储到不同的服务器上,当某一服务器出现问题时就可能导致数据丢失,其次路由mongos也会出现问题,另外存储分片的信息的配置服务器也可能会发生问题。当然我们可以利用master salve/Replica sets机制去备份每个分片、Mongos、configs 。如下官网配置图示,即使我们使用服务器交叉备份也需要大量的服务器资源,因此分片是一件极具耗费资源的事情

片键是说拆分集合的依据是什么？按照什么键值进行拆分集合....
mongos就是一个路由服务器,会根据管理员设置的"片键"将数据分摊到自己管理的mongod集群,数据和片的对应关系以及相应的配置信息保存在"config服务器"上
mongod:一个普通的数据库实例,如果不分片的话,我们会直接连上mongod

模拟分片：
首先准备4个mongodb程序,这里是均摊在C,D,E,F盘上,当然也可以做多个文件夹的形式
开启config服务器
C://mongodb/bin> mongod --dbpath=C://mongodb/data/db --port 2222
开启mongos服务器,同时指定依赖的config服务器,mongos查询的分片信息都存储在configs中
D://mongodb/bin> mongos --port 3333 --configdb=127.0.0.1:2222
启动mongod分片服务器,负责数据存储
E://mongodb/bin> mongod --dbpath=E://mongodb/data/db --port 4444
F://mongodb/bin> mongod --dbpath=F://mongodb/data/db --port 5555
为4444分片服务器 创建test库person集合,并且为person集创建name索引

client直接跟mongos打交道,即要连接mongos服务器,然后将4444、5555的mongod交给mongos,添加分片也就是addshard()
D://mongodb/bin> mongo 127.0.0.1:3333/admin
> db.runCommand({addshard: 127.0.0.1:4444, allowLocal: true})
> db.runCommand({addshard: 127.0.0.1:5555, allowLocal: true})
allowLoacl 充许本地部署 默认情况不充许本地部署多个分片的
这里要注意的是,在addshard中,我们也可以添加副本集,这样能达到更高的稳定性

一旦分片添加成功,在mongos服务器中执行 show dbs就可以看到分片服务器的数据库,并且可以操作分片服务器的数据

片已经集群了,但是mongos不知道该如何切分数据,即先前所说的片键shard key,在mongodb中设置片键要做两步
①：开启数据库分片功能,命令很简单 enablesharding(),这里开启test数据库。
②：指定集合中分片的片键,这里我就指定为person.name字段,需要分片的集合 的shard key必须是索引键
> db.runCommand({enablesharding: 'test'})
> db.runCommand({shardcollection: 'test.person', key: {name: 1}})

至此我们的分片操作全部结束,可以在mongos或configs服务器查询分片信息,接下来我们通过mongos向mongodb插入10w记录,然后通过printShardingStatus命查看mongodb的数据分片情况
> use test
> for(var i=0; i < 100000;i++) db.person.insert({name: 'jake'+i, age: i})
> db.printShardingStatus()

这里主要看三点信息：
① shards：     我们清楚的看到已经别分为两个片了,shard0000和shard0001。
② databases:  这里有个partitioned字段表示是否分区,这里清楚的看到test已经分区。
③ chunks：     这个很有意思,我们发现集合被砍成四段：
   无穷小 —— jack0,jack0 ——jack234813,jack234813——jack9999,jack9999——无穷大。
   分区情况为：3：1,从后面的 on shardXXXX也能看得出。

当需要移除分片时运行下面的命令,同时mongos路由会将此分片服务器上的信息移到其它分片上。
>db.runCommand({"removeshard":"127.0.0.1:5555"})

简单的分析一下shard key,当不是写密集操作时,而仅仅是因为存储空间不够了,这个shard key可以选用一些无上限范围的key,如创建时间等,这样新创建的记录都会写入新的分片服务器上。

当需要使每个分片均匀分布数据或写入密集时最好选用有一定范围值的key,当然这个范围不能太小如性别,真假等会导致只自动产生两个分片,所以一定要选择合适的shard key才能达到理想的效果。

MongoDB拥有强大的读写扩展能力,而且配置比较灵活容易。虽然上面提到的这些功能每一种都有一定的缺点,但是这些缺点可以通过合理设计归避的。比如备份,因为备份是要消耗一定主服务性器性能,这个时候可以通过备份从服务器来避免影响到主服务器性能。比如oplog虽然有大小限制,可以通过观察主服务器连续一段时间(周/月/年)更新操作来确定一个合适的oplog大小,以便从服务器不会丢失对这些操作记录的同步。或者每天某段时间强制主服务器的写入缓存操作,以便从服务器可以同步追赶上主服务器

【 安装部署运维 】
MongoDB 监控
1、HTTP控制台(http console)
MongoDB提供一个web界面,使诊断和监控信息在一个简单的web页面。web界面访问localhost:port,port比mongod端口大1000
例如如果一个本地运行mongod是使用默认端口27017,访问HTTP控制台在http://localhost:28017
mongod --dbpath=E:\soft\mongodb\data\db --rest --httpinterface  // http://127.0.0.1:28017

2、db.stats()                 获取当前数据库的信息,比如Obj总数、数据库总大小、平均Obj大小等
  db.collect_name.stats()
  rs.status()                查询副本集信息

> db.stats()
{
  "db" : "test",
  "collections" : 9,
  "views" : 0,
  "objects" : 33,
  "avgObjSize" : 86.66666666666667,
  "dataSize" : 2860,
  "storageSize" : 221184,
  "numExtents" : 0,
  "indexes" : 11,
  "indexSize" : 274432,
  "ok" : 1
}

3、db.currentOp()
Mongodb的命令一般很快就完成,但是在一台繁忙的机器或有比较慢的命令时可以通过db.currentOp()获取当前正在执行的操作

在没有负载的机器上该命令基本上都是返回空的
>  db.currentOp()
{ "inprog" : [ ] }

以下是一个有负载的机器上得到的返回值样例：
{ "opid" : "shard3:466404288", "active" : false, "waitingForLock" : false, "op": "query", "ns" : "sd.usersEmails", "query" : { }, "client_s" :"10.121.13.8:34473", "desc" : "conn" },

发现一个操作太长,把数据库卡死的话,可以用这个命令杀死他
> db.killOp("shard3:466404288")

4、serverStatus()
获取mongodb的服务器统计信息,其中包括全局锁、索引、用户操作行为等等这些统计信息
bin> mongo 127.0.0.1
>db.serverStatus()

mongo Shell Diagnostic Commands
通过mongo shell脚本来查询服务器状态
db.runCommand({serverStatus: 1})

connections 当前连接和可用连接数,mongodb最大处理到2000个连接就不行了(要根据机器性能和业务来设定),所以设大了没意义。设个合理值的话,到达这个值mongodb就拒绝新的连接请求,避免被太多的连接拖垮。
indexCounters:btree:misses 索引的不命中数,和hits的比例高就要考虑索引是否正确建立,"missRatio" : 3.543930204420982e-7很健康,所以miss率在mongostat里面也可以看

Field                  Example Value          Explanation
Host                   te.rzw.com:27018       运行实例所监听的IP与端口
version                1.8.3                  当前实例所使用的版本
Process                mongod                 当前实例是mongod,还是mongos
Uptime                 231905                 实例连续正常运行时间,单位秒
uptimeEstimate         223083                 基于mongodb内部粗粒定时器的连续正常运行时间
localTime              ISODate("2011")        本机时间,以UTC时间为计算标准。
globalLock.totalTime   231905155987           自实例启动全局锁创建以来到现在多长时间,单位微秒.
globalLock.lockTime    9053050                自全局锁创建以来锁定总时间,单位微秒
globalLock.ratio       0.0000390377262        锁定的时间所占的比例(lockTime/ totalTime)
globalLock.currentQueue.total   0             当前等待全局锁的数量
globalLock.currentQueue.readers 0             当前等待读锁的数量
globalLock.currentQueue.writers 0             当前等待写锁的数量
globalLock.activeClients.total  1             连接到当前实例处于活动状态的客户端数量。
globalLock.activeClients.readers 1            处于活动状态的客户端中有多少是在执行read操作
globalLock.activeClients.writers 0            处于活动状态的客户端中有多少是在执行write操作
Mem.resident                     6            到现在总共使用的物理内存,单位是MB
Mem.virtual                    17307          当前使用的虚拟内存大小,MB,一般比mem.map稍大,
                                              大很多很可能发生内存泄露,如果使用journal大约是2倍的map值
Mem.maped                      8556           Mongodb使所有数据都映射到内存中,所以这个值可以看似整个数据量的值。
Mem.bits                       64             机器位数,32位或64位
Mem.supported                  true           本机是否支持内存扩展
Connections.current            2              当前连接到本机处于活动状态的连接数
Connections. available         19998          剩余多少可供连接
extra_info. heap_usage_bytes   521152         当前实例堆大小,单位bytes
extra_info. page_faults        569            加载磁盘内容时发生页错误的次数
indexCounters. Btree.accesses  1              访问索引次数
indexCounters. Btree.hits      1              访问索引时,索引在内存中被命中的次数
indexCounters. Btree.misses    0              访问索引时,索引不是在内存中被命中的次数
indexCounters. Btree.resets    0              索引计数器被重置的次数
indexCounters. Btree.missRatio 0              索引非命中率
backgroundFlushing.flushes    3864            实例刷新数据到磁盘的数次
backgroundFlushing.total_ms   15473           刷新到磁盘总共花费的时间,单位毫秒
backgroundFlushing.average_ms 4.0043995859213 平均每次刷新执行时间
backgroundFlushing.last_ms    3               最后一次刷新执行时间
backgroundFlushing.last_finished              最后一次刷新完成的utc时间点
Cursors.totalOpen             1               当前游标数量
Cursors.timeOut               2               从实例启动到现在游标超时的总数量
Network.bytesIn               4680778         发送到实例的字节大小
Network.bytesOut              4759827         发送出去的字节大小
Repl.setName                  myset           replSet结构定义的名称
Repl.isMaster                 True            当前实例是否是replSet结构中的Master节点
Repl.secondary                False           当前实例是否是replSet结构中的secondary节点
Repl.hosts  ["te.rzw.com:27018","te.rzw.com:27019"] replSet结构中每个节点情况
Opcounters.insert             4               自实例启动以来,执行insert次数
Opcounters.query              181             自实例启动以来,执行query次数
Opcounters.update             92084           自实例启动以来,执行update次数
Opcounters.delete             0               自实例启动以来,执行delete次数
Opcounters.getmore            92816           自实例启动以来,在游标执行getMore次数
Opcounters.command            316             自实例启动以来,执行其他操作的次数
Asserts.regular               0               自实例启动以来,断言正常的次数
Asserts.warn                  0               自实例启动以来,断言警告的次数
Asserts.msg                   0               自实例启动以来,断言内部错误的次数
Asserts.user                  134             自实例启动以来,因用户使用造成的错误而被断言次数
Asserts.rollovers             0               断言被翻转的次数
writeBacksQueued             False            在mongos中,操作被重做的次数
Dur.commits                  1                在最近间隔,向journal文件提交的次数
Dur.journaledMB              0.008192         在最近间隔,journalr文件写入数据量,单位MB
Dur. writeToDataFilesMB       0               在最近间隔,从journal文件向数据文件写入的数据量,单位MB
Dur. commitsInWriteLock       0               在最近间隔中处于写锁状态下向journal提交的次数.这种提交方式不被推荐
Dur.earlyCommits              0               在预定时间之前请求提交的次数
Dur.timeMs.dt               3045              Journal状态收集的频率,单位毫秒
Dur.timeMs. prepLogBuffer     0               向journal写数据前的准备所花费时间, 单位毫秒
Dur.timeMs. writeToJournal    2               向journal写数据所花费时间,单位毫秒
Dur.timeMs. writeToDataFiles  0               在写入journal文件后向数据文件写数据花费时间,单位毫秒
Dur.timeMs. remapPrivateView  0               重新在内存中映射数据花费的时间
Ok                            1               serverStatus操作是否被成功执行

5、mongostat
mongostat是mongodb自带的实时状态检测工具,在命令行下使用。会间隔固定时间获取mongodb的当前运行状态并输出
如果发现数据库突然变慢或有其他问题的话,第一手的操作就考虑采用mongostat来查看mongo的状态
bin> mongostat

inserts/s 每秒插入次数
query/s 每秒查询次数
update/s 每秒更新次数
delete/s 每秒删除次数
getmore/s 每秒执行getmore次数
command/s 每秒的命令数,比以上插入、查找、更新、删除的综合还多,还统计了别的命令
flushs/s 每秒执行fsync将数据写入硬盘的次数。
mapped/s 所有的被mmap的数据量,单位是MB,
vsize 虚拟内存使用量,单位MB
res 物理内存使用量,单位MB
faults/s 每秒访问失败数(只有Linux有),数据被交换出物理内存,放到swap。不要超过100,否则就是机器内存太小,造成频繁swap写入。此时要升级内存或者扩展
locked % 被锁的时间百分比,尽量控制在50%以下吧
idx miss % 索引不命中所占百分比。如果太高的话就要考虑索引是不是少了
q t|r|w 当Mongodb接收到太多的命令而数据库被锁住无法执行完成,它会将命令加入队列。这一栏显示了总共、读、写3个队列的长度,都为0的话表示mongo毫无压力。高并发时,一般队列值会升高。
conn 当前连接数
time 时间戳

6、mongotop是mongodb的内置工具,mongotop提供了一个方法用来跟踪一个MongoDB的实例,查看哪些大量的时间花费在读取和写入数据。 mongotop提供每个集合的水平的统计数据。默认情况下mongotop返回值的每一秒

bin> mongotop
bin> mongotop 10       sleeptime可选参数,等待的时间长度(秒)
bin> mongotop --locks  报告每个数据库的锁的使用中,使用mongotop - 锁`

7、使用profiler
Mongo profile类似于MySQL的slow log, MongoDB可以监控所有慢的以及不慢的查询。
Profiler默认是关闭的,你可以选择全部开启,或者有慢查询的时候开启。

> use test
> db.setProfilingLevel(2);
{"was" : 0 , "slowms" : 100, "ok" : 1} // "was" is the old setting
> db.getProfilingLevel()

查看Profile日志

> db.system.profile.find().sort({$natural:-1})
{
"ts" : "Thu Jan 29 2009 15:19:32 GMT-0500 (EST)" ,
"info" : "query test.$cmd ntoreturn:1 reslen:66 nscanned:0 query: { profile: 2 } nreturned:1 bytes:50" ,
"millis" : 0
}

3个字段的意义
ts：时间戳
info：具体的操作
millis：操作所花时间,毫秒
造成满查询可能是索引的问题,也可能是数据不在内存造成因此磁盘读入造成

8、MongoDB Monitoring Service(MMS)是Mongodb厂商提供的监控服务,可以在网页和Android客户端上监控你的MongoDB状况

</pre>

<h3>MongoDB 备份(mongodump)与恢复(mongorestore)</h3><pre>
1、冷备份
直接手动复制--dbpath指定的存放mongodb数据库文件目录的文件,不太安全,在复制之前要鬼步服务器
>use admin
>db.shutdownServer()

或者可以通过fsync方式使MongoDB将数据写入缓存中,然后再复制备份
>use admin
>db.runCommand({"fsync":1,"lock":1})  // 加锁
这个时候往test.foo插入了一条数据f:6,在执行db.foo.find()后并没有查到这条记录,说明记录没有直接写入数据库,而是被缓冲到缓存中

备份完后要解锁(防止这个时候停电或其它原因,导致未缓存中的数据丢失)
>use admin
>db.$cmd.sys.unlock.findOne()        // 释放锁
>db.currentOp()
如果currentOp 只返回{"inprog":[]}结果,说明解锁成功
解锁后缓存中的数据会写入数据库文件中,我们去查询foo结果

2、在不停止服务的情况下使用mongodump命令来执行MongoDB数据库备份,此命令将转储服务器的所有数据到转储目录,有许多可用的选项,通过它可以限制数据量或创建远程服务器备份

mongodump命令脚本语法如下：
bin> mongodump -h dbhost -d dbname -o dbdirectory
-h：MongDB所在服务器地址,如：127.0.0.1,也可以指定端口号：127.0.0.1:27017
-d：需要备份的数据库实例,如：test
-o：备份的数据存放位置,备份目录默认创建到bin目录,如：c:\data\dump,该目录需要提前建立,在备份完成后,系统自动在dump目录下建立一个test目录,这个目录里面存放该数据库实例的备份数据

bin> mongodump
执行以上命令后,客户端会连接到ip为 127.0.0.1 端口号为 27017 的MongoDB服务上,并备份所有数据到 bin/dump/ 目录中

bin> mongodump --host 127.0.0.1 --port 27017             该命令将备份所有MongoDB数据
bin> mongodump --dbpath /data/db/ --out /data/backup/
bin> mongodump --collection mycol --db test              该命令将备份指定数据库的集合

mongorestore命令脚本语法如下：
>mongorestore -h hostname:port -d dbname path
--host:port, -h hostname::port：MongoDB所在服务器地址,默认为： localhost:27017
--db , -d db： 需要恢复的数据库实例,如test,名称也可以和备份时候的不一样,如test2
--drop：       恢复的时候先删除当前数据然后恢复备份的数据。恢复后,备份后添加修改的数据都会被删除,慎用
path：         mongorestore 最后的一个参数,设置备份数据所在位置,例如：c:\data\dump\test。
--dir：        指定备份的目录,不能同时指定 path 和 --dir 选项

>mongorestore

</pre>
</div>

<div id="relation">
<h3>文档间关联关系可以通过嵌入和引用来建模</h3><pre class="js">
// 使用嵌入式方法,可以把用户地址嵌入到用户的文档中
// 数据保存在单一的文档中,可以比较容易的获取和维护数据
// 缺点是,如果用户和用户地址在不断增加,数据量不断变大,会影响读写性能

"_id":ObjectId("52ffc33cd85242f436000001"),
"contact": "987654321",
"dob": "01-01-1991",
"name": "Tom Benzamin",
"address": [
  {
     "building": "22 A, Indiana Apt",
     "pincode": 123456,
     "city": "Los Angeles",
     "state": "California"
  },
  {
     "building": "170 A, Acropolis Apt",
     "pincode": 456789,
     "city": "Chicago",
     "state": "Illinois"
  }]
}

>db.users.findOne({"name":"Tom Benzamin"},{"address":1})

// 引用式关系:把用户数据文档和用户地址数据文档分开,通过引用文档的 id 字段来建立关系
{
   "_id":ObjectId("52ffc33cd85242f436000001"),
   "contact": "987654321",
   "dob": "01-01-1991",
   "name": "Tom Benzamin",
   "address_ids": [
      ObjectId("52ffc4a5d85242602e000000"),
      ObjectId("52ffc4a5d85242602e000001")
   ]
}

>var result = db.users.findOne({"name":"Tom Benzamin"},{"address_ids":1})
>var addresses = db.address.find({"_id":{"$in":result["address_ids"]}})

</pre><pre>
MongoDB引用有两种：
1、手动引用(Manual References)
2、DBRefs

在不同的集合中(address_home, address_office, address_mailing)存储不同的地址(住址,办公室地址,邮件地址等)
在调用不同地址时也需要指定集合,一个文档从多个集合引用文档应该使用DBRefs

DBRef的形式：{ $ref : , $id : , $db :  }
$ref：集合名称
$id：引用的id
$db: 数据库名称,可选参数

</pre><pre class="js">
{
   "_id":ObjectId("53402597d852426020000002"),
   "address": {
     "$ref": "address_home",
     "$id": ObjectId("534009e4d852427820000002"),
     "$db": "runoob"
   },
   "contact": "987654321",
   "dob": "01-01-1991",
   "name": "Tom Benzamin"
}

>var user = db.users.findOne({"name":"Tom Benzamin"})
>var dbRef = user.address
>db[dbRef.$ref].findOne({"_id":(dbRef.$id)})

</pre>嵌入文档的一对多关系模型 <pre class="js">
// address文档包含了对patron文档的引用
{
   _id: "joe",
   name: "Joe Bookreader"
}

{
   patron_id: "joe",
   street: "123 Fake Street",
   city: "Faketon",
   state: "MA",
   zip: "12345"
}

{
   patron_id: "joe",
   street: "1 Some Other Street",
   city: "Boston",
   state: "MA",
   zip: "12345"
}

// 如果程序频繁获取address数据中的名称信息,那么需要多次查询以解析引用。一个较优的方案是嵌入address数据到patron数据中;这样通过一次查询,程序就能获取全部的patron信息
{
  _id: "joe",
  name: "Joe Bookreader",
  addresses: [
    {
      street: "123 Fake Street",
      city: "Faketon",
      state: "MA",
      zip: "12345"
    },
    {
      street: "1 Some Other Street",
      city: "Boston",
      state: "MA",
      zip: "12345"
    }
  ]
 }

</pre>文档引用的一对多关系模型 <pre class="js">
// 嵌入式数据模型导致出版社信息的重复,使用引用数据模型使出版社信息在一个独立的集合中则可以解决冗余问题
{
  title: "MongoDB: The Definitive Guide",
  author: [ "Kristina Chodorow", "Mike Dirolf" ],
  published_date: ISODate("2010-09-24"),
  pages: 216,
  language: "English",
  publisher: {
    name: "O'Reilly Media",
    founded: 1980,
    location: "CA"
  }
}

{
  title: "50 Tips and Tricks for MongoDB Developer",
  author: "Kristina Chodorow",
  published_date: ISODate("2011-05-06"),
  pages: 68,
  language: "English",
  publisher: {
    name: "O'Reilly Media",
    founded: 1980,
    location: "CA"
  }
}

// 引用式数据模型
{
  _id: "oreilly",
  name: "O'Reilly Media",
  founded: 1980,
  location: "CA"
}

{
  _id: 123456789,
  title: "MongoDB: The Definitive Guide",
  author: [ "Kristina Chodorow", "Mike Dirolf" ],
  published_date: ISODate("2010-09-24"),
  pages: 216,
  language: "English",
  publisher_id: "oreilly"
}

{
  _id: 234567890,
  title: "50 Tips and Tricks for MongoDB Developer",
  author: "Kristina Chodorow",
  published_date: ISODate("2011-05-06"),
  pages: 68,
  language: "English",
  publisher_id: "oreilly"
}

</pre>
</div>

<div id="nodejs">
<h3>node-mongodb-native原生操作mongodb实现CURD操作</h3><pre>
> npm install mongodb --save-dev

https://docs.mongodb.org/manual/tutorial/query-documents

</pre><pre class="js">
var MongoClient = require('mongodb').MongoClient;
var DB_CONN_STR = 'mongodb://localhost:27017/test';

var insertData = function(db,callback){
  var collection = db.collection('user');
  var data = [{"name": "heiying6958", "age": 29, "email": "11111212@qq.com"},{"name": "xiaoxiao", 'age':20}]
  collection.insert(data, function(err, result){
    if(err){
      console.log(err);
      return;
    }
    callback(result);
  });
}

MongoClient.connect(DB_CONN_STR, function(err, db){
  if(err){
    console.log(err);
    return;
  }
  insertData(db, function(result){
    console.log(result);
    db.close();
  })
})

/*
{ result: { ok: 1, n: 2 },
  ops:
   [ { name: 'heiying6958',
       age: 29,
       email: '11111212@qq.com',
       _id: 5a23f3cf89b84a2150e36973 },
     { name: 'xiaoxiao', age: 20, _id: 5a23f3cf89b84a2150e36974 } ],
  insertedCount: 2,
  insertedIds: [ 5a23f3cf89b84a2150e36973, 5a23f3cf89b84a2150e36974 ] }
*/

var updateData = function(db,callback){
  var collection = db.collection('user');
  var wherestr = {"name": "xiaoxiao"};
  var newstr = {$set:{"age": 22}};
  collection.update(wherestr, newstr, function(err, result){
    if(err){
      console.log(err);
      return;
    }
    callback(result);
  });
}

MongoClient.connect(DB_CONN_STR, function(err, db){
  if(err){
    console.log(err);
    return;
  }
  updateData(db, function(result){
    console.log(result);
    db.close();
  })
})

var deleteData = function(db,callback){
  var collection = db.collection('user');
  var wherestr = {"name": "unkown"};
  collection.remove(wherestr, function(err, result){
    if(err){
      console.log(err);
      return;
    }
    callback(result);
  });
}

MongoClient.connect(DB_CONN_STR, function(err, db){
  if(err){
    console.log(err);
    return;
  }
  deleteData(db, function(result){
    console.log(result);
    db.close();
  })
})

var findData = function(db,callback){
  var collection = db.collection('user');
  var wherestr = {"age": {$gt: 25}};
  collection.find(wherestr, function(err, result){
    if(err){
      console.log(err);
      return;
    }
    callback(result);
  });
}

MongoClient.connect(DB_CONN_STR, function(err, db){
  if(err){
    console.log(err);
    return;
  }
  findData(db, function(result){
    console.dir(result);
    db.close();
  })
})

</pre><pre class="js">
/****************************方法二*********************************/

var updateData = function(db, callback) {
  var collection = db.collection('user');
  collection.updateOne({ name:"xiaoxiao" }, { $set: { age:21 }}, function(err, result) {
    if(err) return console.error(err)
    console.log(result.result.n);
    callback(result);
  });
}

var insertData = function(db, callback) {
  var collection = db.collection('user');
  collection.insertMany([ {a:1}, {a:2}, {a:3} ], function(err, result) {
    if(err) return console.error(err)
    console.log(result.result.n);
    console.log(result.ops.length);
    callback(result);
  });
}

var deleteData = function(db, callback) {
  var collection = db.collection('user');
  collection.deleteOne({ name:"unkown" }, function(err, result) {
    if(err) return console.error(err)
    console.log(result.result.n);
    callback(result);
  });
}

var findData = function(db, callback) {
  var collection = db.collection('user');
  collection.find({}).toArray(function(err, result) {
    if(err) return console.error(err)
    console.log(result.length);
    console.dir(result);
    callback(result);
  });
}

var MongoClient = require('mongodb').MongoClient
var url = 'mongodb://localhost:27017/test';

MongoClient.connect(url, function(err, db) {
  if(err) return console.error(err)
  // updateData(db, function(){ db.close(); });
  insertData(db, function(){ db.close(); });
  // deleteData(db, function(){ db.close(); });
  findData(db, function(){ db.close(); });
});

</pre>
</div>

<div id="mongoose">
<h3>mongoose  npm install mongoose --save-dev</h3>
<p><a href="#m-connect">mongodb连接</a></p>
<p><a href="#m-Schema">Schema</a> <a href="#m-validate">文档验证</a></p>
<p><a href="#m-model">model</a> <a href="#m-Entity">Entity 文档实例</a></p>
<p><a href="#m-index">索引</a> <a href="#m-methods">自定义方法</a> <a href="#m-populate">populate</a></p>
<p><a href="#m-find">查询</a> <a href="#m-insert">插入保存</a> <a href="#m-update">更新</a> <a href="#m-remve">删除</a></p>
<p><a href="#m-prepost">前后钩子</a> <a href="#m-promise">promise</a></p>

<pre id="m-connect">
Mongoose是在node.js异步环境下对mongodb数据库进行便捷操作封装的对象模型工具,可以将数据库中的数据转换为JavaScript对象供我们使用

Mongoose 是 MongoDB 的 ODM(Object Document Mapper)
ODM和ORM(Object Relational Mapper)是同类型的工具,都是将数据库的数据转化为代码对象的库,使用转化后的对象可以直接对数据库的数据进行CRUD

Mongoose是NodeJS的驱动,不能作为其他语言的驱动。Mongoose有两个特点
1、通过关系型数据库的思想来设计非关系型数据库
2、基于mongodb驱动,简化操作

Schema + Model + Document --> Mongoose --> Mongodb

Mongoose不是MongoDB数据库的驱动,而是ODM(类似于关系数据库的ORM),真正的MongoDB驱动应该是mongodb
如果需要的只是一个能连上MongoDB的驱动,然后自己能使用各种增删改查指令在程序里的话,就不要用Mongoose,而是要mongodb

在Mongoose的设计思想里,数据库里存储的是一个个的Model,findOne出来的就是一个Model,然后可以对这个Model进行修改,最后再save,Mongoose会自动根据你的修改调用数据库相关的操作指令,不需要自己update,这就是ODM存在的意义,数据的修改对于开发者来说不是对数据库进行操作,而是对Model进行操作。简单来说ODM就是按照面向对象的思想,把数据也对象化,数据也有自己的方法,只需要调用方法就可以对数据进行操作,而不是自己写数据库的操作语句。
Mongoose的各个方法返回的类型不一样,有的是Model,有的是Array,有的是Query等等,Mongoose不同的类型可能会有一样名称的方法,但是返回值的类型有可能是不一样的

在真正使用过程当中,要确定你查询出来的数据是做什么用途,如果是用于处理再存储回去的话就要让其返回Model或者Model的数组,如果不需要再存回去的话就可以用lean方法让Mongoose返回给你JS原生的只包含基本类型的JSON对象,但是不是所有的Mongoose返回类型都有lean方法的。至于是否要转换成String就要看需求了,比如想使用lodash之类的工具对_id进行各种复杂的操作,这个时候用ObjectId类型就不好用了,因为比如对比两个Object是否相同是一件比较复杂的事情,但是String就很简单,所以这个时候你可能就需要把_id转换成String来处理。

ObjectId存在的意义是本身有除了当一个唯一ID以外的其他用途,比如可以存储时间,比如分布式的时候可以用来区分不同服务器不同数据库实例不同的库产生的文档,具体可以看ObjectId的定义

mongoose查询返回的是封装的model对象,读取时直接返回文档结构,调试时才显示出model对象的结构。平时是可以直接使用的,但是需要改动字段的值,就要toObject

Mongoose支持的数据类型
String        --   字符串
Number        --   数字,包括整数和小数
Date          --   日期
Boolean       --   布尔
Buffer        --   用于存储二进制数据,eg：图片,最大不超过16M
ObjectId      --   mongodb自动生成_id,作为数据库的主键
Mixed         --   可以存储任意的数据类型
Array         --   数组或内置子文档(subdocuments)

Array类型的两种用法：
1.array数组数据
var UserSchema = new mongoose.Schema({
  name:String ,
  email:[String]
});

2.内置subdocuments
var EmailSchema = new mongoose.Schema({
  email:String,
  regTime: Date
});

var UserSchema = new mongoose.Schema({
  name:String,
  email:[emailSchema]
});

</pre><pre class="js">
var mongoose = require('mongoose');                      //引用mongoose模块
var db = mongoose.createConnection('localhost','test');  //创建一个数据库连接
db.on('error',console.error.bind(console,'连接错误:'));
db.once('open',function(){                                //一次打开记录
  var PersonSchema = new mongoose.Schema({name:String});  //定义一个属性name,类型为String
  PersonSchema.methods.speak = function(){                //为Schema模型追加speak方法
    console.log('我的名字叫'+this.name);
  }
  var PersonModel = db.model('Person',PersonSchema);
  //如果该Model已经发布,则可以直接通过名字索引到,如下：
  //var PersonModel = db.model('Person');
  //如果没有发布,上一段代码将会异常
  var personEntity = new PersonModel({name:'Krouky'});
  console.log(personEntity.name);                          //Krouky
  personEntity.speak();                                    //我的名字叫Krouky
  personEntity.save();                                     //执行完成后,数据库就有该数据了
  PersonModel.find(function(err,persons){
      console.log(persons);                                //查询到的所有person
  });
});

</pre><pre>
【 mongoose连接数据库 】
var conn = mongoose.createConnection('mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]', options);

mongoose.connect('mongodb://username:password@host:port/database?options...');
mongoose.connect('mongodb://localhost/dbname');
mongoose.disconnect()                             // 断开连接

定义一个数据库连接,如果app只用到一个数据库应该使用 mongoose.connect,如果还需要连接其他数据库使用mongoose.createConnection

一旦连接,Connection对象会触发open事件,如果你使用 mongoose.connect, Connection对象就是默认的 mongoose.connection,而使用 mongoose.createConnection 返回值就是 Connection.

Mongoose会缓存所有命令直到连接上数据库,即不必等待它连接MongoDB再定义 models,执行 queries 等

封装数据库的操作是同步形式的,其实内部是异步的

</pre><pre class="js">
const mongoose = require('mongoose')
mongoose.connect('mongodb://localhost/test')
const BlogModel = mongoose.model('Blog', { title: String, content: String })
BlogModel.find()

var mongoose = require('mongoose');
var DB_URL = 'mongodb://localhost:27017/study';
mongoose.Promise = global.Promise;
mongoose.connect(DB_URL, {useMongoClient:true});  // 防止连接warning

</pre><pre class="js">
var mongoose = require('mongoose');
db = mongoose.createConnection('localhost', 'test');
var schema = new mongoose.Schema({ name: String });
var collectionName = 'kittens';
var M = db.model('Kitten', schema, collectionName);
var silence = new M({ name: "Silence"});
silence.save(function(err){ });

</pre><pre class="js">
var mongoose = require('mongoose');
var DB_URL = 'mongodb://localhost:27017/study';

mongoose.connect(DB_URL);                                 //连接
mongoose.connection.on('connected', function () {         //连接成功
  console.log('Mongoose connection open to ' + DB_URL);
});
mongoose.connection.on('error',function (err) {           //连接异常
  console.log('Mongoose connection error: ' + err);
});
mongoose.connection.on('disconnected', function () {      //连接断开
  console.log('Mongoose connection disconnected');
});

setTimeout(function(){
  mongoose.disconnect(function(){
    console.log("断开连接");
  })
}, 2000);

</pre><pre>
connect()方法还接受一个选项对象options,该对象将传递给底层驱动程序,所包含的所有选项优先于连接字符串中传递的选项

mongoose.connect(uri, options);
可用选项：
db            -数据库设置,传递给collection db实例
server        -服务器设置,传递给collection server实例
replset       -副本集设置,传递给collection repelset实例
user          -用户名验证
pass          -密码验证
auth          -鉴权认证选项
mongos        -连接多个数据库
promiseLibrary
useMongoClient:true

</pre><pre class="js">
var options = {
  db: { native_parser: true },
  server: { poolSize: 5 },
  replset: { rs_name: 'myReplicaSetName' },
  user: 'myUserName',
  pass: 'myPassword'
}
mongoose.connect(uri, options);

</pre><pre>
启用keepAlive
对于长时间运行的程序,通常是以毫秒为单位谨慎地使用keepAlive。没有它,在一段时间之后可能看到没有理由的 "connection closed" 错误

</pre><pre class="js">
options.server.socketOptions = options.replset.socketOptions = { keepAlive: 120 };
mongoose.connect(uri, options);

</pre>连接副本集(Multi-mongos 支持): 连接多个数据库只需设置多个url以,隔开,同时设置mongos为true<pre class="js">
mongoose.connect('urlA,urlB,...', {mongos : true })

</pre>connect()函数还接受一个回调参数<pre class="js">
mongoose.connect(uri, options, function(error) {
  err ? console.log('连接失败') : console.log('连接成功');
});

</pre><pre>
连接池
数据库连接是一种关键的、有限的、昂贵的资源,这一点在多用户的网页应用程序中体现得尤为突出。对数据库连接(本质上就是与数据库实例的一个socket连接)的管理能显著影响到整个应用程序的伸缩性和健壮性,影响到程序的性能指标。数据库连接池正是针对这个问题提出来的

像打开关闭数据库连接这种和数据库的交互可能是很费时的,尤其是当客户端数量增加的时候,会消耗大量的资源,成本是非常高的。可以在应用服务器启动的时候建立很多个数据库连接并维护在一个池中。连接请求由池中的连接提供。在连接使用完毕以后,把连接归还到池中,以用于满足将来更多的请求

原理
连接池基本的思想是在系统初始化的时候,将数据库连接作为对象存储在内存中,当用户需要访问数据库时,并非建立一个新的连接,而是从连接池中取出一个已建立的空闲连接对象。使用完毕后,用户也并非将连接关闭,而是将连接放回连接池中,以供下一个请求访问使用。而连接的建立、断开都由连接池自身来管理。同时,还可以通过设置连接池的参数来控制连接池中的初始连接数、连接的上下限数以及每个连接的最大使用次数、最大空闲时间等等。也可以通过其自身的管理机制来监视数据库连接的数量、使用情况等

数据库连接池负责分配、管理和释放数据库连接,它允许应用程序重复使用一个现有的数据库连接,而不是再重新建立一个;释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏。这项技术能明显提高对数据库操作的性能

数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中,这些数据库连接的数量是由最小数据库连接数制约。无论这些数据库连接是否被使用,连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数,当应用程序向连接池请求的连接数超过最大连接数量时,这些请求将被加入到等待队列中

Node驱动已经带有连接池了,不管你想不想用。
实际上所有官方支持的MongoDB驱动都按照统一的标准创建,行为也都相似,所以其实上用到的驱动都使用了连接池来管理连接

每个连接,无论是用mongoose.connect还是mongoose.createConnection创建都用一个默认大小为5的内置可配置连接池备份,使用的连接选项调节其大小

</pre><pre class="js">
// single server
var uri = 'mongodb://localhost/test';
mongoose.createConnection(uri, { server: { poolSize: 4 }});

// for a replica set
mongoose.createConnection(uri, { replset: { poolSize: 4 }});

// passing the option in the URI works with single or replica sets
var uri = 'mongodb://localhost/test?poolSize=4';
mongoose.createConnection(uri);

</pre>

<pre id="m-Schema">
Schema生成Model,Model创造Entity,Model和Entity都可对数据库操作造成影响,但Model比Entity更具操作性
var PersonSchema;   //Person的文本属性
var PersonModel;    //Person的数据库模型
var PersonEntity;   //Person实体

【 Schema模式 】
在mongoose里一切都由schema开始。每一个schema对应一个mongoDB collection 并且在那个collection里面定义了documents的模型

Schema是一种以文件形式存储的数据库模型骨架,无法直接通往数据库端,不具备对数据库的操作能力,仅仅只是数据库模型在程序片段中的一种表现,可以说是数据属性模型(传统意义的表结构),又或着是"集合"的模型骨架

Schema是Mongoose里的数据模式,可以理解为表结构定义,定义mongodb中集合collection中文档document结构和格式化,指定字段名和类型;每个schema会映射到mongodb中的一个collection,不具备操作数据库的能力

Shema不仅定义了document的结构和构造了属性,还定义了document实例方法、静态Model方法、复合索引和被称作middleware的document生命周期钩子
扩展插件：Schema可以定义插件,并且插件具有良好的可拔插性

基本属性类型有：字符串、日期型、数值型、布尔型(Boolean)、null、数组、内嵌文档等
定义Schema时以json对象形式定义,键为属性,值为属性说明;关于属性说明至少需要定义属性的类型type,如果有其他需要说明的同样以json的形式说明,键为属性,值为说明

type属性指定SchemaType类型,不同的SchemaType类型还有其他不同的属性配置
文档：http://mongoosejs.com/docs/schematypes.html

Schema.Types:
String, Number, Date, Buffer, Boolean直接定义即可
Mixed, ObjectId需要引入mongoose模块后定义,Mixed混合类型可以看做嵌套类型,可以不指定内部元素的键,若需要指定内部元素的键,可以直接使用大括号声明
Array使用中括号加元素Type定义,不说明也可以

声明Mixed类型时,以下几种方式是等价的：
var Any = new Schema({ any: {} });
var Any = new Schema({ any: Object });
var Any = new Schema({ any: mongoose.Schema.Types.Mixed});

关于数组(Array)：
数组会隐式地含有默认值(default: []),要将这个默认值去掉,需要设定默认值(default: undefined)
如果数组被标记为(required: true),存入数据时该数组必须含有一个元素,否则会报错

//声明类型为Mixed的空数组
var Empty1 = new Schema({ any: [] });
var Empty2 = new Schema({ any: Array });
var Empty3 = new Schema({ any: [mongoose.Schema.Types.Mixed] });
var Empty4 = new Schema({ any: [{}] });

自定义Schema Type：
从mongoose.SchemaType继承而来,加入相应的属性到mongoose.Schema.Type中,可以使用cast()函数实现,具体例子参见：http://mongoosejs.com/docs/customschematypes.html

ObjectId对象:
存储在mongodb集合中的每个文档(document)都有一个默认的主键_id,这个主键名称是固定的,它可以是mongodb支持的任何数据类型,默认是ObjectId。该类型的值由系统自己生成,从某种意义上几乎不会重复

var mongoose = require('mongoose');
var tSchema = new mongoose.Schema({}); //默认_id:ObjectId类型

手动生成ObjectId：mongoose.Types.ObjectId()

LBS地址位置
lbs : { type: Array, index: '2d', sparse: true }   //地理位置
基于LBS的条件查询,Schema中定义时如上
LBS查询对于一些基于LBS应用会用得比较多

创建Schema对象时声明字段类型有两种方法:首字母大写的字段类型,另一种是引号包含的小写字段类型
var mySchema = new Schema({title:String, author:String});
var mySchema = new Schema({title:'string', author:'string'});

通过mongoose.Schema来调用Schema,然后使用new方法来创建schema对象

</pre><pre class="js">
var mongoose = require('mongoose');
var Schema = mongoose.Schema;
var mySchema = new Schema({
  _id: Schema.Types.ObjectId,                //主键
  title:  String,                            //直接写法,会被转化成相应的SchemaType
  author: String,
  body:   String,
  comments: [{ body: String, date: Date }],
  date: { type: Date, default: Date.now },  //定义SchemaType写法
  hidden: Boolean,
  meta: {
    votes: Number,
    favs:  Number
  }
});

</pre><pre class="js">
var numberSchema = new Schema({
  integerOnly: {
    type: Number,
    get: v => Math.round(v),
    set: v => Math.round(v)
  }
});

var Number = mongoose.model('Number', numberSchema);

var doc = new Number();
doc.integerOnly = 2.001;
doc.integerOnly; // 2

</pre><pre class="js">
// 定义一个Schema对象
var mongoose = require("mongoose");
var TestSchema = new mongoose.Schema({
  name: {type:String, unipue: true, index: true}, //字段属性name,类型为String,index建立索引,unipue
  age: { type:Number, default:0 },                 //字段属性age,类型为Number,默认值为0
  gender: { type: 'string', enum: ['m', 'f', 'x'] },
  email: { type:String, unipue: true, default:''},
  regtime: { type:Date, default: Date.now },
  lastLogin: Date
});

</pre><pre class="js">
var schema = new Schema({
  name:    String,
  binary:  Buffer,
  living:  Boolean,
  updated: { type: Date, default: Date.now },
  age:     { type: Number, min: 18, max: 65 },
  mixed:   Schema.Types.Mixed,                  //该混合类型等同于nested
  _someId: Schema.Types.ObjectId,               // 外键
  doctor_id: {type: mongoose.Schema.Types.ObjectId, ref:'doctor'}, //外键链接到doctor Model
  array:      [],
  ofString:   [String],
  ofNumber:   [Number],
  ofDates:    [Date],
  ofBuffer:   [Buffer],
  ofBoolean:  [Boolean],
  ofMixed:    [Schema.Types.Mixed],
  ofObjectId: [Schema.Types.ObjectId],
  ofArrays:   [[]]
  ofArrayOfNumbers: [[Number]]
  nested: {
    stuff: { type: String, lowercase: true, trim: true }
  }
})

var Thing = mongoose.model('Thing', schema);

var m = new Thing;
m.name = 'Statue of Liberty';
m.age = 125;
m.updated = new Date;
m.binary = new Buffer(0);
m.living = false;
m.mixed = { any: { thing: 'i want' } };
m.markModified('mixed');
m._someId = new mongoose.Types.ObjectId;
m.array.push(1);
m.ofString.push("strings!");
m.ofNumber.unshift(1,2,3,4);
m.ofDates.addToSet(new Date);
m.ofBuffer.pop();
m.ofMixed = [1, [], 'three', { four: 5 }];
m.nested.stuff = 'good';
m.save(callback);

</pre>在Schema定义后添加其他额外的字段(键),可以使用add()方法<pre class="js">
var mongoose = require('mongoose');
var TempSchema = new mongoose.Schema;
TempSchema.add({ name: 'String', email: 'String', age: 'Number' });

</pre><pre class="js">
var mongoose = require('mongoose');
var taskSchema = new mongoose.Schema({
  userId: String,
  invalidFlag: Number,
  task: [
    {
      _id:0,
      type: {type:String},
      details:[{
        startTime : Date,
        frequencyTimes : Number,
        frequencyUnits : String,
        status: Number
      }]
    }
  ],
  revisionInfo:{
  operationTime: Date,
  userId: String
  }
});

var taskModel = mongoose.model('task', taskSchema);  //导出Model

</pre><pre id="m-validate">
【 文档验证 】 http://mongoosejs.com/docs/api.html#schematype_SchemaType-required
Validation是在SchemaType定义
Validation是中间件的内部组件
Validation发生在document试图在默认值应用之后保存的时候。
Validation不在未定义的值运行,唯一例外是必要的验证器。
Validation是异步递归的,当你调用Model#save,子文档验证也会执行。如果发生错误,Model#save回调会接收它。
验证支持完全定制


如果不进行文档验证,保存文档时,就可以不按照Schema设置的字段进行设置
缺少字段的文档可以保存成功
包含未设置的字段的文档也可以保存成功,未设置的字段不被保存
包含字段类型与设置不同的字段的文档也可以保存成功,不同字段类型的字段被保存为设置的字段类型

</pre><pre class="js">
var schema = new mongoose.Schema({ age:Number, name: String,x:Number,y:Number});
var temp = mongoose.model('temp', schema);
new temp({age:10}).save(function(err,doc){
  console.log(doc);  //{ __v: 0, age: 10, _id: 597304442b70086a1ce3cf05 }
});
new temp({age:100,abc:"abc"}).save(function(err,doc){
  console.log(doc);  //{ __v: 0, age: 100, _id: 5973046a2bb57565b474f48b }
});
new temp({age:true,name:10}).save(function(err,doc){
  console.log(doc);  //{ __v: 0, age: 1, name: '10', _id: 597304f7a926033060255366 }
});

</pre><pre>
文档验证在SchemaType中定义,格式：{name: {type:String, validator:value}}

Validation 是一种中间件,Mongoose触发validation,同pre('save')钩子一样
可手动触发 validation 通过doc.validate(callback) or doc.validateSync()

validate一般只会应用在save上,update()和findOneAndUpdate()操作的验证器默认是关闭的,需要指定options中runValidators选项

所有类型公有的,对于全部Type有效：内置验证器
required: boolean或function,必选验证器,数据必须填写,没有该字段文档将不被保存且出现错误提示
default: 设置属性的默认值,可以是value或者function,如果该值是函数则该函数的返回值将用作默认值Date now
select: boolean 查询时默认输出该属性, 指定是否被投影
validate: function, 对属性进行自定义验证器。
get, set: function自定义属性的值;get方法Object.defineProperty();set方法Object.defineProperty()
alias: 别名
validate: 自定义匹配,实际上是一个函数,函数的参数代表当前字段,返回true表示通过验证,返回false表示未通过验证。利用validate可以自定义任何条件。比如,定义名字name的长度必须在4个字符以上

对字符串String有效:
lowercase: Boolean 转成小写,即对值调用.toLowerCase()
uppercase: Boolean 转成大写,即对值调用.toUpperCase()
trim: Boolean 去掉开头和结尾的空格,即对值调用.trim()
match: 正则表达式,判断值是否符合给定的正则表达式,如果该字段不符合,文档将不被保存且出现错误提示
enum: 数组,判断值是否在给定的数组中,枚举匹配,如果该字段不在枚举范围内,文档将不被保存且出现错误提示
maxlength 显示字符串的长度
minlength 显示字符串的长度

对数字Number或时间Date有效:
min, max: Number或Date 生成验证器判断是否符合给定条件
min:  最小值(只适用于数字),如果该字段超出范围,文档将不被保存,且出现错误提示
max:  最大值(只适用于数字),如果该字段超出范围,文档将不被保存,且出现错误提示

</pre><pre class="js">
/* required用法 */
var s = new Schema({ born: { type: Date, required: true })

// or with custom error message
var s = new Schema({ born: { type: Date, required: '{PATH} is required!' })

// or with a function
var s = new Schema({
  userId: ObjectId,
  username: {
    type: String,
    required: function() { return this.userId != null; }
  }
})

// or with a function and a custom message
var s = new Schema({
  userId: ObjectId,
  username: {
    type: String,
    required: [
      function() { return this.userId != null; },
      'username is required if id is specified'
    ]
  }
})

// or through the path API
Schema.path('name').required(true);

// with custom error messaging
Schema.path('name').required(true, 'grrr :( ');

// or make a path conditionally required based on a function
var isOver18 = function() { return this.age >= 18; };
Schema.path('voterRegistrationId').required(isOver18);

</pre><pre class="js">
cat.save(function(error) {
  //自动执行,validation
});

//手动触发validation,上面已经设置好user的字段内容
user.validate(function(error) {   //error 就是验证不通过返回的错误信息
  assert.equal(error.errors['phone'].message, '555.0123 is not a valid phone number!');
});

</pre><pre class="js">
// required
var schema = new mongoose.Schema({ age:{type:Number,required:true}, name: String,x:Number,y:Number});
var temp = mongoose.model('temp', schema);
new temp({name:"abc"}).save(function(err,doc){
  console.log(err.errors['age'].message);  //Path `age` is required.
});

// default
var schema = new mongoose.Schema({ age:{type:Number,default:18}, name:String,x:Number,y:Number});
var temp = mongoose.model('temp', schema);
new temp({name:'a'}).save(function(err,doc){
  console.log(doc); //{ __v: 0, name: 'a', _id: 59730d2e7a751d81582210c1, age: 18 }
});

// min max
var schema = new mongoose.Schema({ age:{type:Number,min:0,max:10}, name: String,x:Number,y:Number});
var temp = mongoose.model('temp', schema);
new temp({age:20}).save(function(err,doc){
  console.log(err.errors['age'].message); //Path `age` (20) is more than maximum allowed value (10).
});

// match
var schema = new mongoose.Schema({ age:Number, name:{type:String,match:/a/},x:Number,y:Number});
var temp = mongoose.model('temp', schema);
new temp({name:'bbb'}).save(function(err,doc){
  console.log(err.errors['name'].message); //Path `name` is invalid (bbb).
});

// enum
var schema = new mongoose.Schema({ age:Number, name:{type:String,enum:['a','b','c']},x:Number,y:Number});
var temp = mongoose.model('temp', schema);
new temp({name:'bbb'}).save(function(err,doc){
  console.log(err.errors['name'].message); //`bbb` is not a valid enum value for path `name`.
});

</pre><pre class="js">
var PersonSchema = new Schema({
  name:{
    type:'String',
    required:true,            //姓名非空
    maxlength:12,
    minlength:6,
    match: /^a/
  },
  age:{type:'Nunmer',min:18,max:120},            //年龄最小18最大120
  date: {type: Date,default: Date.now},
  city:{type:'String',enum:['北京','上海']},      //只能是北京、上海人
  other:{type:'String',validate:[validator,err]}  //validator是一个验证函数,err是验证失败的错误信息
});

</pre><pre class="js">
/* Schema set 用法 */

function capitalize (val) {
  if (typeof val !== 'string') val = '';
  return val.charAt(0).toUpperCase() + val.substring(1);
}

// defining within the schema
var s = new Schema({ name: { type: String, set: capitalize }})

// or by retreiving its SchemaType
var s = new Schema({ name: String })
s.path('name').set(capitalize)

// 实例
function toLower(v) { return v.toLowerCase(); }

var UserSchema = new Schema({
  email: { type: String, set: toLower }
});

var User = db.model('User', UserSchema);

var user = new User({email: 'AVENUE@Q.COM'});
console.log(user.email);       // 'avenue@q.com'
// or
var user = new User();
user.email = 'Avenue@Q.com';
console.log(user.email);       // 'avenue@q.com

</pre><pre class="js">
/* Schema get 用法 */

function dob (val) {
  if (!val) return val;
  return (val.getMonth() + 1) + "/" + val.getDate() + "/" + val.getFullYear();
}

// defining within the schema
var s = new Schema({ born: { type: Date, get: dob })

// or by retreiving its SchemaType
var s = new Schema({ born: Date })
s.path('born').get(dob)

// Schema get实例：信用卡号部分数字
function obfuscate (cc) {
  return '****-****-****-' + cc.slice(cc.length-4, cc.length);
}

var AccountSchema = new Schema({
  creditCardNumber: { type: String, get: obfuscate }
});

var Account = db.model('Account', AccountSchema);

Account.findById(id, function (err, found) {
  console.log(found.creditCardNumber); // '****-****-****-1234'
});

// 实例
function inspector (val, schematype) {
  if (schematype.options.required) {
    return schematype.path + ' is required';
  } else {
    return schematype.path + ' is not';
  }
}

var VirusSchema = new Schema({
  name: { type: String, required: true, get: inspector },
  taxonomy: { type: String, get: inspector }
})

var Virus = db.model('Virus', VirusSchema);

Virus.findById(id, function (err, virus) {
  console.log(virus.name);     // name is required
  console.log(virus.taxonomy); // taxonomy is not
})

</pre><pre class="js">
/* 自定义验证器 */
var validateLength = function(arg){
  if(arg.length > 4) return true;
  return false;
};
var schema = new mongoose.Schema({ name:{type: String, validate: validateLength }, age:Number,x:Number,y:Number});
var temp = mongoose.model('temp', schema);
new temp({name:'abc'}).save(function(err,doc){
  console.log(err.errors['name'].message);  //Validator failed for path `name` with value `abc`
});

</pre><pre class="js">
var userSchema = new Schema({
  phone: {
    type: String,
    validate: {
      validator: function(v) {
        return /d{3}-d{3}-d{4}/.test(v);
      },
      message: '{VALUE} is not a valid phone number!'
    }
  }
});

var User = mongoose.model('user', userSchema);
var u = new User();

u.phone = '555.0123';
console.log(u.validateSync().toString());  // ValidationError: 555.0123 is not a valid phone number!"

u.phone = '201-555-0123';
console.log(u.validateSync());             // Prints undefined - validation succeeded!

</pre><pre class="js">
// 自定义验证器
function validator (val) {
  return val == 'something';
}
new Schema({ name: { type: String, validate: validator }});

// 附带自定义错误信息
var custom = [validator, 'Uh oh, {PATH} does not equal "something".']
new Schema({ name: { type: String, validate: custom }});

//添加多验证器
var many = [
  { validator: validator, msg: 'uh oh' },
  { validator: anotherValidator, msg: 'failed' }
]
new Schema({ name: { type: String, validate: many }});

// 直接通过SchemaType.validate方法定义验证器:
var schema = new Schema({ name: 'string' });
schema.path('name').validate(validator, 'validation of `{PATH}` failed with value `{VALUE}`');

</pre><pre>
【 同步验证 】
Validation默认是异步的。mongoose用独立的process.nextTick()调用估计每个独立path ,这确保了如果有许多路径要验证,validation不会阻塞event loop。可是mongoose的内置验证器都是同步的,通常它比同步验证更方便

mongoose document也有validateSync() 方法,如果有错误它返回ValidationError否则返回falsy。注意,validatesync()只执行同步的验证器。自定义异步验证器不会执行。

var toySchema = new Schema({ color: String, name: String });
var Toy = mongoose.model('Toy', toySchema);

Toy.schema.path('color').validate(function (value) {
  return /blue|green|white|red|orange|periwinkle/i.test(value);
}, 'Invalid color');

var toy = new Toy({ color: 'grease'});

var error = toy.validateSync();
// `error` is a ValidationError analogous to the one from `validate()`

console.log(error.errors.color.message);
// prints 'Validator "Invalid color" failed for path color with value `grease`'

</pre><pre>
【 验证错误对象(ValidationError object) 】
验证失败后返回的错误包含一个包含实际ValidatorError对象的错误对象。 每个ValidatorError都有kind,path,value和message属性。

</pre><pre class="js">
var mongoose = require('mongoose');
var DB_URL = 'mongodb://localhost:27017/study';
mongoose.Promise = global.Promise;
mongoose.connect(DB_URL, {useMongoClient:true});  // 防止连接warning
var Schema = mongoose.Schema;

var toySchema = new Schema({ color: String, name: String });
var Toy = mongoose.model('Toy', toySchema);

var validator = function (value) {
  return /blue|green|white|red|orange|periwinkle/i.test(value);
};
Toy.schema.path('color').validate(validator,'Color `{VALUE}` not valid', 'Invalid color');

var toy = new Toy({ color: 'grease'});
toy.save(function (err) {
  // err is our ValidationError object;err.errors.color is a ValidatorError object
  console.error(err.errors.color.message, 'Color `grease` not valid');
  console.error(err.errors.color.kind, 'Invalid color');
  console.error(err.errors.color.path, 'color');
  console.error(err.errors.color.value, 'grease');
  console.error(err.name, 'ValidationError');
});

</pre><pre>
【 验证更新 】
update验证器默认是关闭的,需要指定runValidators 选项
修改验证器只在$set和$unset操作运行,$inc等操作不会运行

</pre><pre class="js">
var toySchema = new Schema({ color: String, name: String });
var Toy = mongoose.model('Toy', toySchema);

Toy.schema.path('color').validate(function (value) {
  return /blue|green|white|red|orange|periwinkle/i.test(value);
}, 'Invalid color');

Toy.update({}, { color: 'bacon' }, { runValidators: true }, function (err) {
  console.log(err.errors.color.message); // prints 'Validator "Invalid color" failed for path color with value `bacon`'
});

</pre><pre>
修改验证器和document验证器有两个区别。
当使用document验证器时它引用被验证的document。当运行修改验证器时,被修改的document可能不在服务器的内存,因此在默认情况下这个值未定义。可以设置上下文选项为'query'来使它引用基础query
另一个主要差别是修改验证器只运行在修改中指定的path

</pre><pre class="js">
Toy.schema.path('color').validate(function (value) {
  this.schema; // refers to the query's schema if you set the `context` option
  return /blue|green|white|red|orange|periwinkle/i.test(value);
}, 'Invalid color');

var options = { runValidators: true, context: 'query' };
Toy.update({}, { color: 'bacon' }, options, function (err) {
  console.log(err.errors.color.message); // prints 'Validator "Invalid color" failed for path color with value `bacon`'
});

</pre>

<pre id="m-index">
【 索引 】
mongoDB支持二级索引,索引分为field级别和schema级别. 如果使用复合索引那么必须使用schema索引

设置索引Indexes:
index: Boolean 属性是否索引
unique: Boolean 是否唯一索引
sparse: Boolean 是否稀疏索引：稀疏索引,如果索引键中存储值为null,就跳过这个文档,这些文档将不会被索引到。不过查询时默认是不使用稀疏索引的,需要使用hint()指定使用在模型中建立的稀疏索引

</pre><pre class="js">
var animalSchema = new Schema({
  name: String,
  type: String,
  tags: {type: [String], index:true} // field level
});

animalSchema.index({name:1, type:-1}); // schema level

</pre><pre class="js">
var s = new Schema({ name: { type: String, index: true })
var s = new Schema({ loc: { type: [Number], index: 'hashed' })
var s = new Schema({ loc: { type: [Number], index: '2d', sparse: true })
var s = new Schema({ loc: { type: [Number], index: { type: '2dsphere', sparse: true }})
var s = new Schema({ date: { type: Date, index: { unique: true, expires: '1d' }})
Schema.path('my.path').index(true);
Schema.path('my.date').index({ expires: 60 });
Schema.path('my.path').index({ unique: true, sparse: true });

</pre><pre>
当程序启动时,Mongoose为每个在schema定义的索引自动地调用ensureIndex 。Mongoose会连续为每个索引调用ensureIndex,当所有ensureIndex调用成功或发生错误在model发出index事件。建议在生产中禁止这种行为因为索引创建能够导致显著的性能影响。通过给schema设置autoIndex选项为false来禁用行为,或者在connection全局设置选项config.autoIndex为false

禁用ensureIndex:
mongoose.connect('mongodb://user:pass@localhost:port/database', { config: { autoIndex: false } });
mongoose.createConnection('mongodb://user:pass@localhost:port/database',{config:{autoIndex:false} });
animalSchema.set('autoIndex', false);
new Schema({}, {autoIndex: false});

</pre><pre class="js">
// Will cause an error because mongodb has an _id index by default that is not sparse
animalSchema.index({ _id: 1 }, { sparse: true });
var Animal = mongoose.model('Animal', animalSchema);

Animal.on('index', function(error) {
  console.log(error.message);  // "_id index cannot be sparse"
});

</pre><pre>
【 Schema Option Schema中初始化的相关参数 】
参考http://mongoosejs.com/docs/guide.html

Schema设置配置选项方法：
1、new Schema({}, options);
2、var UserSchema = new Schema({});
   UserSchema.set(option, value);

Valid options: http://mongoosejs.com/docs/guide.html#toJSON
bufferCommands
collection       集合名默认使用Model名,设置该选项可以自定义集合名
emitIndexErrors
minimize
read 允许在schema级别设置query#read,对于所有的查询,提供给我们一种方法应用默认的ReadPreferences
shardKey  需要mongodb做分布式,才会使用该属性

✈ strict (默认true/enabled)
如果实例中的域(field)在schema中不存在,那么这个域不会被插入到数据库;如果取消严格选项则会被存入数据库
该选项也可以在Model级别使用,通过设置第二个参数
strict也可以设置为throw,表示出现问题将会抛出错误而不是抛弃不合适的数据

</pre><pre class="js">
var ThingSchema = new Schema({a:String});
var Thing = db.model('Thing',SchemaSchema);
var thing = new Thing({iAmNotInTheThingSchema:true});
thing.save();         //iAmNotInTheThingSchema这个属性将无法被存储

// 通过doc.set()设置也会受到影响
var thingSchema = new Schema({..})
var Thing = mongoose.model('Thing', thingSchema);
var thing = new Thing;
thing.set('iAmNotInTheSchema', true);
thing.save();          // iAmNotInTheSchema is not saved to the db

var ThingModel = db.model('Thing');
var thing1 = new ThingModel(doc,true);  //启用严格
var thing2 = new ThingModel(doc,false); //禁用严格

</pre><pre>
✈ capped 上限设置,数据库批量操作时限制一次操作的量
例：{capped: 1024}  //一次操作上线1024条数据
例：{capped:{size:1024,max:100,autoIndexId:true}}  //可以是对象,包含属性

✈ id
mongoose分配给每一个schema一个虚拟属性id,是一个getter,返回的是_id转换为字符串后的值。如果不需要为schema添加这个getter,可以通过id配置修改

</pre><pre class="js">
// 默认行为
var pageSchema = new Schema({ name: String });
var pageModel = mongoose.model('Page', pageSchema);
var p = new pageModel({ name: 'mongodb.org' });
console.log(p.id); // '50341373e894ad16347efe01'

// 禁止id
var pageSchema = new Schema({ name: String }, { id: false } );
var pageModel = mongoose.model('Page', pageSchema);
var p = new pageModel({ name: 'mongodb.org' });
console.log(p.id); // undefined

</pre><pre>
✈ _id (默认true)
在一个schema中如果没有定义_id域(field),那么mongoose将会默认分配一个_id域(field)。类型是ObjectId。如果不需要使用这个默认的选择,可以通过设置这个选项。
通过在schema中设置这个字段可以阻止生成mongoose获得_id。但是在插入的时候仍然会生成_id。设置这个字段之后,如果再使用Schema.set('_id', false)将无效

✈ autoIndex (默认true) 自动索引
应用启动的时候Mongoose会自动为每一个schema(索引)发送一个ensureIndex命令,索引默认(_id)被Mongoose创建
若想禁止自动创建index要手动来创建可以设置autoIndex为false

var xxSchema = new Schema({}, { autoIndex: false });
var Clock = mongoose.model('Clock', xxSchema);
Clock.ensureIndexs(callback);

✈ safe (默认true)
用来设置安全模式,实际上就是定义入库时数据的写入限制,比如写入时限等
这个配置会在MongoDB所有的操作中起作用。如果设置成true就是在操作的时候要等待返回的MongoDB返回的结果,比如update,要返回影响的条数,才往后执行,如果safe：false,则表示不用等到结果就向后执行了。
默认设置为true能保证所有的错误能通过我们写的回调函数

new Schema({ .. }, { safe: true });
//使用安全模式,表示在写入操作时,如果发生错误,也需要返回信息

new Schema({ .. }, { safe: { w: "majority", wtimeout: 10000 }});
// 自定义安全模式,w为写入的大小范围,wtimeout设置写入时限,如果超出10s则返回error,10s内没完成写操作会超时

✈ toObject: 用来表示在提取数据时,把documents内容转化为Object内容输出,一般只需设置getters为true
设置toObject选项为true后,默认对这个schema所有的实例都有作用。不需要实例手动调用

对应 Document#toObject
将document转换成完整的js object

Documents have a toObject method which converts the mongoose document into a plain javascript object. This method accepts a few options. Instead of applying these options on a per-document basis we may declare the options here and have it applied to all of this schemas documents by default.

To have all virtuals show up in your console.log output, set the toObject option to { getters: true }:

</pre><pre class="js">
var schema = new Schema({ name: String });
schema.path('name').get(function (v) {
  return v + ' is my name';
});
schema.set('toObject', { getters: true });
var M = mongoose.model('Person', schema);
var m = new M({ name: 'Max Headroom' });
console.log(m);
// { name: 'Max Headroom is my name', _id: 5a2df3a77f1d9466ac439619, id: '5a2df3a77f1d9466ac439619' }
m.age = 22;
console.log(m);
// { name: 'Max Headroom is my name', _id: 5a2df3a77f1d9466ac439619, id: '5a2df3a77f1d9466ac439619' }
console.log(m.toObject());
// { name: 'Max Headroom is my name', _id: 5a2df3a77f1d9466ac439619, id: '5a2df3a77f1d9466ac439619' }

</pre><pre>
✈ toJSON：和toObject一样的使用,通常用来把documents转化为Object,但只有当实例调用toJSON方法后才会起作用

Exactly the same as the toObject option but only applies when the documents toJSON method is called.

</pre><pre class="js">
var schema = new Schema({ name: String });
schema.path('name').get(function (v) {
  return v + ' is my name';
});
schema.set('toJSON', { getters: true, virtuals: false });
var M = mongoose.model('Person', schema);
var m = new M({ name: 'Max Headroom' });
console.log(1, m.toObject());
// 1 { name: 'Max Headroom', _id: 5a2df3f58bf7165ea4d40f52 }
console.log(2, m.toJSON());
// 2 { name: 'Max Headroom is my name',_id: 5a2df3f58bf7165ea4d40f52 }

// 显式调用 toJSON is called whenever a js object is stringified:
console.log(3, JSON.stringify(m));
// {3 '{"name":"Max Headroom is my name","_id":"5a2df3f58bf7165ea4d40f52"}'

</pre><pre>
MongoDB 时间类型存储的是0时区时间,接口默认返回东8区时间的实现
function toEast8(utc){
  return new Date(new Date(utc).getTime() + 8*60*60*1000)
}

console.log(typeof doc.logindate, doc.logindate);  // object 2017-12-13T08:21:23.425Z
console.time('change')
var time = toEast8(doc.logindate)
console.timeEnd('change')         // 3.383ms
console.log(typeof time, time);   // object 2017-12-13T16:21:23.425Z

// 直接加上时差的毫秒数
var plus = doc.logindate + 8*60*60*1000;
console.log('plus', typeof plus, plus); //string Wed Dec 13 2017 16:21:23 GMT+0800 (中国标准时间)28800000

</pre><pre class="js">
schema.options.toObject = schema.options.toJSON = {
  transform: function(doc, ret, options) {
    ret.date = ret.date.toEast8();
    return ret;
  }
}

// 用path也能实现相似功能

schema.path('date').get(function (date) {
  return date.toEast8();
});
schema.set('toObject', { getters: true });
schema.set('toJSON', { getters: true });

</pre><pre>
✈ typeKey
在mongoose里,如果schema里有个对象,并且这个对象有个type键,mongoose将会将这个作为一种类型声明。
但对于一些应用来说,type字段是必要的。那么可以通过typeKey来设置。

</pre><pre class="js">
// Mongoose 认为loc字段的类型是一个字符串,而不是有type这个字段
var schema = new Schema({ loc: { type: String, coordinates: [Number] } });

var schema = new Schema({
  loc: { type: String, coordinates: [Number] },  // Mongoose这时候认为loc字段有两个键:type和coordinates
  name: { $type: String }  // Mongoose 这时候认为name字段的类型是字符串。
}, { typeKey: '$type' });  // '$type'键意味着这是一个类型宣告,而不是默认的type

</pre><pre>
✈ validateBeforeSave
默认得,文档被保存到数据库的时候会自动验证,这是为了防止无效的文档。如果想要手动处理验证,并且能保存不通过验证的文档,可以设置这个选项为false。

</pre><pre class="js">
var schema = new Schema({ name: String });
schema.set('validateBeforeSave', false);
schema.path('name').validate(function (value) {
  return v != null;
});
var M = mongoose.model('Person', schema);
var m = new M({ name: null });

m.validate(function(err) {
  console.log(err);      // 将会告诉你null不被允许
});
m.save();                  // 尽管数据无效,但是仍然可以保存。

</pre><pre>
✈ versionKey
版本锁设置在每一个文档(document)上,由mogoose生成。默认的值是__v,但是可以自定义。
不要将这个选项设置为false除非你知道你在做什么

</pre><pre class="js">
var schema = new Schema({ name: 'string' });
var Thing = mongoose.model('Thing', schema);
var thing = new Thing({ name: 'mongoose v3' });
thing.save(); // { __v: 0, name: 'mongoose v3' }
// 自定义版本锁
new Schema({..}, { versionKey: '_somethingElse' })
var Thing = mongoose.model('Thing', schema);
var thing = new Thing({ name: 'mongoose v3' });
thing.save(); // { _somethingElse: 0, name: 'mongoose v3' }

</pre><pre>
✈ skipVersioning
在一个博客系统中,一个人所有的评论是一个数组,那么所有的评论是有索引的,比如某一条评论的body,comments.3.body,这里3是索引。假如一个评论者(A)想要修改自己的评论,但是此时另一个评论者(B)删除(或其他操作)了自己的评论,那么对A的索引可能会造成变化,此时对A的操作会发生错误。

为了改变这个问题,mongoose v3添加了version key配置。无论什么时候修改一个数组潜在地改变数组元素位置,这个version key(__V)的值会加1。在where条件中也需要添加__v条件,如果能通过(数组索引没改变),就可以修改,例如：

posts.update({ _id: postId, __v: verionNumber }, { $set: { 'comments.3.body': updatedText }}

如果在更新之前删除了评论,那么就会发生错误。

post.save(function (err) {
  console.log(err); // Error: No matching document found.
});

✈ timestamps
</pre><pre class="js">
var ItemSchema = new mongoose.Schema({
  title: String,
  createTime: {type: Date, default: Date.now},
  updateTime: {type: Date, default: Date.now}
});

有两个问题：
1、如果数据库中该字段缺省,读取数据时自动生成的系统的当前时间
2、不能做到每次更新文档时更新updateTime字段

</pre><pre>
schema选项timestamps: true,创建文档时createdAt和updatedAt域将会默认被自动添加的文档中,默认的类型是Date,更新文档时自动更新updateAt字段的值为系统当前时间,字段名支持自定义

</pre><pre class="js">
var thingSchema = new Schema({..}, { timestamps: { createdAt: 'created_at' } });
var Thing = mongoose.model('Thing', thingSchema);
var thing = new Thing();
thing.save();      // created_at & updatedAt将会被包含在文档。

</pre><pre>
✈ useNestedStrict
在mongoos 4, update()和findOneAndUpdate()方法只检查顶级schema的strict的选项设置。

</pre><pre class="js">
var childSchema = new Schema({}, { strict: false });

// 这里parentSchema是topSchema,而childSchema是subSchema。
var parentSchema = new Schema({ child: childSchema }, { strict: 'throw' });

var Parent = mongoose.model('Parent', parentSchema);

Parent.update({}, { 'child.name': 'Luke Skywalker' }, function(error) {
  // 发生错误因为parentSchema设置了{strict: 'throw'}
  // 即使childSchema设置了{strict: false}
});

var update = { 'child.name': 'Luke Skywalker' };
var opts = { strict: false };

Parent.update({}, update, opts, function(error) {
  // 这个可以通过因为重写了parentSchema的strict选项
});

如果设置了useNestedStrict为true,mogoose在更新时使用childSchema的strict选项。

var childSchema = new Schema({}, { strict: false });
var parentSchema = new Schema({ child: childSchema },
  { strict: 'throw', useNestedStrict: true });
var Parent = mongoose.model('Parent', parentSchema);
Parent.update({}, { 'child.name': 'Luke Skywalker' }, function(error) {
  // 可以更新
});

</pre><pre>
✈ retainKeyOrder

默认得,mongoose会转换实体中键的顺序。比如new Model({ first: 1, second: 2 })将会在MongoDB中存储为{ second: 2, first: 1 };这带来了极大的不方便。

Mongoose v4.6.4 有一个retainKeyOrder选项确保mongoose不会改变键的顺序

</pre><pre>
【 Virtual property 虚拟属性 】
virtual是能get和set但不能保存到MongoDB的document属性,get用于格式化或合并field,set可以分解一个字段到多个字段并持续化到数据库
如果结果记录document转换为object或者JSON,默认不包括virtual;作为查询的一部分和对于field选择,只有非虚拟属性有效

virtual property属性是直接设置在Schema上的,但是VR并不会真正的存放在db中,只是一个提取数据的方法

virtual是document的属性,可以get,set他们但是不持续化到MongoDB
virtual属性get非常有用可以格式化或者合并字段

使用Schema添加实例方法实现的返回,比VR 要慢几十倍

</pre><pre class="js">
var personSchema = new Schema({
  name: { first: String, last: String }
});

var Person = mongoose.model('Person', personSchema);

/* Schema添加实例方法输出全名 */
personSchema.methods.getName = function(){
  return this.first+" "+this.last;
}
var bad = new Person({ name: { first: 'jimmy', last: 'Gay' } });
bad.getName();

/* 利用虚拟属性设置全名 */
var bad = new Person({ name: {first: 'Walter', last: 'White'} });
console.log(bad.name.first + ' ' + bad.name.last);      // 获取bad的全名

// 可以在personSchema中定义virtual getter. 这样我们就不需要在每个要用fullname的地方拼接字符串了
personSchema.virtual('name.full').get(function(){
  return this.name.first + ' ' + this.name.last;
);
console.log(bad.name.full);

// 还可以通过设置this.name.full来设置this.name.first和this.name.last
bad.name.full = "Breaking Bad";
personSchema.virtual('name.full').set(function(name){
  var split = name.split(' ');
  this.name.first = split[0];
  this.name.last = split[1];
});

mad.name.full = "Breaking Bad";
console.log(mad.name.first);     // Breaking
console.log(mad.name.last);      // Bad

</pre><pre id="plugin">
【 插件plugins 】
schema是可插入的,即它们可以应用预包装的能力,从而扩展其功能,这是一个非常强大的功能

</pre><pre class="js">
/* 只需创建一个插件,并把它应用到每个Schema： */

// db,js
var mongoose = require('mongoose');
var DB_URL = 'mongodb://localhost:27017/plugin';
mongoose.Promise = global.Promise;
mongoose.connect(DB_URL, {useMongoClient:true});  // 防止连接warning
module.exports = mongoose;

// lastMod.js
module.exports = exports = function lastModifiedPlugin (schema, options) {
  schema.add({ lastMod: Date })

  schema.pre('save', function (next) {
    this.lastMod = new Date
    next()
  })

  if (options && options.index) {
    schema.path('lastMod').index(options.index)
  }
}

// game.js
var mongoose = require('./db');
var Schema = mongoose.Schema;
var lastMod = require('./lastMod');
var gameSchema = new Schema({name: String});
gameSchema.plugin(lastMod, { index: true });
var game = mongoose.model('game', gameSchema);
var g1 = new game({name: 'gamename'})
g1.save((err, doc) => {
  if(err) return console.log(err);
  console.log(doc)
  // { __v: 0,lastMod: 2017-12-12T08:20:56.939Z,name: 'gamename',_id: 5a2f916816aafe6c7ce91f02 }
})

// player.js
var mongoose = require('./db');
var Schema = mongoose.Schema;
var lastMod = require('./lastMod');
var playerSchema = new Schema({name: String});
playerSchema.plugin(lastMod);
var player = mongoose.model('player', playerSchema);
var p1 = new player({name: 'playername'})
p1.save((err, doc) => {
  if(err) return console.log(err);
  console.log(doc)
  // { __v: 0,lastMod: 2017-12-12T08:21:26.889Z,name: 'playername',_id: 5a2f91860e188e73e08c6faa }
})

</pre><pre>
全局插件
mongoose单例模式的plugin() 函数能给所有schema注册一个插件

</pre><pre class="js">
var mongoose = require('./db');
var Schema = mongoose.Schema;
mongoose.plugin(require('./lastMod'));

var game1Schema = new Schema({name: String});
var player1Schema = new Schema({name: String});
// `lastModifiedPlugin` gets attached to both schemas
var game1 = mongoose.model('game1', game1Schema);
var player1 = mongoose.model('player1', player1Schema);

var g1 = new game1({name: 'gamename'})
g1.save((err, doc) => {
  if(err) return console.log(err);
  console.log(doc)
  // { __v: 0,lastMod: 2017-12-12T08:40:27.503Z,name: 'gamename',_id: 5a2f95fbf85e9f5b20abe54a }91f02 }
})

var p1 = new player1({name: 'playername'})
p1.save((err, doc) => {
  if(err) return console.log(err);
  console.log(doc)
  // { __v: 0,lastMod: 2017-12-12T08:40:27.533Z,name: 'playername',_id: 5a2f95fbf85e9f5b20abe54b }
})

</pre><pre id="m-model">
【 Model 模型 】
Model 由Schema构造生成的模型,除了Schema定义的数据库骨架以外,还具有数据库操作的行为,类似于管理数据库属性、行为的类
schema打包成model,model会自动生成所有的增(save)、删(delete)、改(update)、查(find,findOne,findById)方法

Model是根据Schema编译而成的构造器,或者称为类,具有抽象属性和行为,可以对数据库进行增删查改。
Model的每一个实例(instance)就是一个文档对象document,document是由Model创建的实体,它的操作也会影响数据库
Models是从Schema定义编译的构造函数,这些model的实例代表能从数据库存储和检索的 documents,数据库中所有document的创建和检索都是这些model处理的

mongoose.model()将Schema编译为Model。model()方法的第一个参数是模型名称
一定要将model()方法的第一个参数和其返回值设置为相同的值,否则会出现不可预知的结果
Mongoose会将集合名称设置为模型名称的小写版;如果名称的最后一个字符是字母则会变成复数;如果名称的最后一个字符是数字则不变
如果模型名称为"MyModel"则集合名称为"mymodels";如果模型名称为"Model1"则集合名称为"model1"

Mongoose在创建MongoDB的Collection时的命名策略
从创建链接到向数据库中写入一个条数据经历了以下步骤：
1.链接数据库(相当于在使用Hibernate的时候配置数据库),并创建链接;
2.定义UserSchema(相当于数据库建表) ;
3.创建User模型(相当于构建对象和数据库表映射);
4.通过User模块,创建对象
5.通过save方法持久化对象

1.判断模型名是否是不可数的(mony),如果是直接返回模型名;否则进行复数转化正则匹配(user -> users)
2.返回复数转化正则匹配结果,一个复数转化正则匹配是一数组,有两个对象,[0]正则表达式,[1]匹配后处理结果);
3.如果复数转化正则匹配结果不存在,直接返回模型名;否则取匹配结果第一个,对模型名进行处理。(需要说明的是,rules是按特殊到一般的顺序排列的)

</pre><pre class="js">
var db = mongoose.connect("mongodb://127.0.0.1:27017/test");
var TestModel = db.model("TestModel", TestSchema);

var schema = new mongoose.Schema({ num:Number, name: String, size: String});
var MyModel = mongoose.model('MyModel', schema);

</pre><pre id="m-Entity">
【 Entity 实例化文档document 】
Entity —— 由Model创建的实体,使用save方法保存数据,Model和Entity都有能影响数据库的操作,但Model比Entity更具操作性
创建成功之后,Schema属性就变成了Model和Entity的公共属性
通过对原型Model1使用new方法,实例化出文档document对象

通过new Model1()创建的文档doc1,必须通过save()方法才能将创建的文档保存到数据库的集合中,集合名称为模型名称的小写复数版
回调函数是可选项,第一个参数为err,第二个参数为保存的文档对象
save(function (err, doc) {})

</pre><pre class="js">
// 使用Model创建Entity
var TestEntity = new TestModel({
  name : "Lenka",
  age  : 36,
  email: "lenka@qq.com"
});
console.log(TestEntity.name); // Lenka
console.log(TestEntity.age);  // 36

</pre><pre class="js">
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(err) return console.log('连接失败', err);
  console.log('连接成功');
  var MySchema = mongoose.Schema;
  var schema = new MySchema({
      username : { type: String, index: true},        //用户账号,建立索引
      userpwd: {type: String},                        //密码
      userage: {type: Number},                        //年龄
      logindate : { type: Date, default: Date.now}    //最近登录时间,默认值
  });
  var MyModel = mongoose.model('MyModel', schema);
  var doc1 = new MyModel({
      username : 'Tracy McGrady',                 //用户账号
      userpwd: 'abcd',                            //密码
      userage: 37,                                //年龄
      logindate : new Date()                      //最近登录时间
  });
  console.log('doc1', doc1);
  doc1.save(function (err,doc) {
    if(err) return console.log("err :" + err);
    console.log('doc', doc);
  })

  MyModel.create({username:'hha',userpwd:'hha',userage:29,logindate:new Date()},(err, doc) => {
    if(err) return console.log("err :" + err);
    console.log(doc);
 })
});

doc1
{ username: 'Tracy McGrady',
  userpwd: 'abcd',
  userage: 37,
  _id: 5a2a28c9892f5f56dc36b1dd,
  logindate: 2017-12-08T05:53:13.715Z
}

doc
{
  __v: 0,
  username: 'Tracy McGrady',
  userpwd: 'abcd',
  userage: 37,
  _id: 5a2a28c9892f5f56dc36b1dd,
  logindate: 2017-12-08T05:53:13.715Z
}

</pre><pre id="m-methods">
【 自定义实例方法 】
Model的实例是document,内置实例方法有很多,如 save
有的时候,我们创造的Schema不仅要为后面的Model和Entity提供公共的属性,还要提供公共的方法
可以通过Schema对象的methods属性给实例自定义扩展方法

为Schema创建实例方法

</pre><pre class="js">
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ num:Number, name: String, size: String });
    schema.methods.findSimilarSizes = function(cb){
      return this.model('MyModel').find({size:this.size},cb);
    }
    var MyModel = mongoose.model('MyModel', schema);
    var doc1 = new MyModel({ name:'doc1', size: 'small' });
    var doc2 = new MyModel({ name:'doc2', size: 'small' });
    var doc3 = new MyModel({ name:'doc3', size: 'big' });
    doc1.save();
    doc2.save();
    doc3.save();
    setTimeout(function(){
      doc1.findSimilarSizes(function(err,docs){
        docs.forEach(function(item,index,arr){
          console.log(item.name);  //doc1  doc2
        })
      })
    },0)
  }
});

</pre><pre class="js">
var mongoose = require('mongoose');
var saySchema = new mongoose.Schema({name : String});
saySchema.method('say', function () {
  console.log('Trouble Is A Friend');
})
var say = mongoose.model('say', saySchema);
var lenka = new say();
lenka.say();             //Trouble Is A Friend

</pre><pre class="js">
var mongoose = require("mongoose");
var db = mongoose.connect("mongodb://127.0.0.1:27017/test");
var TestSchema = new mongoose.Schema({
  name : { type:String },
  age  : { type:Number, default:0 },
  email: { type:String, default:"" },
  time : { type:Date, default:Date.now }
});

TestSchema.methods.speak = function(){
  console.log('我的名字叫'+this.name);
}

var TestModel = db.model('test1',TestSchema);
var TestEntity = new TestModel({name:'Lenka'});
TestEntity.speak();       //我的名字叫Lenka

</pre><pre class="js">
var PersonSchema = new Schema({name:String,type:String});
//查询类似数据
PersonSchema.methods.findSimilarTypes = function(cb){
  return this.model('Person').find({type:this.type},cb);
}
var PersonModel = mongoose.model('Person',PersonSchema);
var krouky = new PersonModel({name:'krouky',type:'前端工程师'});
krouky.findSimilarTypes(function(err,persons){
  //persons中就能查询到其他前端工程师
});

</pre><pre>
【 自定义Model静态方法 】
通过Schema对象的statics属性给 Model 添加静态方法
实例方法和静态方法的区别在于,静态方法是通过Schema对象的statics属性给model添加方法,实例方法是通过Schema对象的methods是给document添加方法

</pre><pre class="js">
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ num:Number, name: String, size: String });
    schema.statics.findByName = function(name,cb){
        return this.find({name: new RegExp(name,'i')},cb);
    }
    var MyModel = mongoose.model('MyModel', schema);
    var doc1 = new MyModel({ name:'doc1', size: 'small' });
    var doc2 = new MyModel({ name:'doc2', size: 'small' });
    var doc3 = new MyModel({ name:'doc3', size: 'big' });
    doc1.save();
    doc2.save();
    doc3.save();
    setTimeout(function(){
      MyModel.findByName('doc1',function(err,docs){
        console.log(docs);
        //[ { _id: 5971e68f4f4216605880dca2,name: 'doc1',size: 'small',__v: 0 } ]
      })
    },0)
  }
});

</pre><pre class="js">
var mongoose = require("mongoose");
var db = mongoose.connect("mongodb://127.0.0.1:27017/test");
var TestSchema = new mongoose.Schema({
  name : { type:String },
  age  : { type:Number, default:0 },
  email: { type:String, default:"" },
  time : { type:Date, default:Date.now }
});

TestSchema.static('findByName', function (name, callback) {
  return this.find({ name: name }, callback);
});

var TestModel = db.model("test1", TestSchema );
TestModel.findByName('tom', function (err, docs) {
  //docs所有名字叫tom的文档结果集
});

</pre><pre>
【 自定义model查询方法 query helpers function 】
通过schema对象的query属性,给model添加查询方法,返回query对象作为mongoose queries使用,即封装的mongoose查询方法;是扩展mongoose's chainable query builder API

</pre><pre class="js">
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ age:Number, name: String});
    schema.query.byName = function(name){
      return this.find({name: new RegExp(name)});
    }
    var temp = mongoose.model('temp', schema);
    temp.find().byName('huo').exec(function(err,docs){
      console.log(docs);
      //[ { _id: 5971f93be6f98ec60e3dc86c, name: 'huochai', age: 27 },
      // { _id: 5971f93be6f98ec60e3dc86e, name: 'huo', age: 30 } ]
    })
  }
});


</pre><pre id="m-populate">
【 populate 】
子文档 children字段 子域 sub-docuemnt
sub-document享有所有与普通document相同的特征。唯一不同的是它们不单独保存,当它们的顶层父document保存时它们才被保存

</pre><pre class="js">
var childSchema = new Schema({ name: 'string' });
var parentSchema = new Schema({
  children: [childSchema]         //指明sub-doc的schema
});
var Parent = mongoose.model('Parent', parentSchema);
var parent = new Parent({ children: [{ name: 'Matt' }, { name: 'Sarah' }] })
parent.children[0].name = 'Matthew';
parent.save(callback);

// 如果在子文档中间件发生错误,它冒泡到父的save()回调,因此错误处理是小事一桩。

childSchema.pre('save', function (next) {
  if ('invalid' == this.name) return next(new Error('#sadpanda'));
  next();
});

var parent = new Parent({ children: [{ name: 'invalid' }] });
parent.save(function (err) {
  console.log(err.message)     // #sadpanda
})

// 已经创建了3个table,一个parent包含了两个child

// 子文档的创建不需通过使用创建方法MongooseArrays添加到数组
var newdoc = parent.children.create({ name: 'Aaron' });

var doc = parent.children.id(id);  // 查询指定的doc使用id()方法

// 子文档的CRUD实际上就是数组的操作,如push,unshift,remove,pop,shift等
parent.children.push({ name: 'Liesl' });

var doc = parent.children.id(id).remove(); // 移除指定的doc

// 如果忘记添加子文档的话,可以在外围添加, 但是字段必须在Schema中指定
var newdoc = parent.children.create({ name: 'Aaron' });

</pre>----------------------------------------------------------------------------------<pre>
因为MongoDB是文档型数据库,没有关系型数据库joins(数据库的两张表通过"外键"建立连接关系)特性,在建立数据的关联时会比较麻烦。为了解决这个问题,Mongoose封装了一个Population功能,使用Population可以实现在一个document中填充其他collection(s)的document(s)

population是自动将document中指定path替换为其他collection的document的过程。我们能迁移document、多个document、简单对象、多个简单对象或者是查询返回的所有对象

在定义Schema的时候,如果设置某个field关联另一个Schema,那么在获取document的时候就可以使用Population功能通过关联Schema的field找到关联的另一个document,并且用被关联 document 的内容替换掉原来关联字段(field)的内容

populate方法可以用在document、model或者query对象上,即几乎可以在任何地方调用这个方法以填充引用字段
populate 方法在不同对象上参数不大一样,但是都接收一个option的参数,你可以用这些参数指定：
path:    以空格分隔的引用字段的名称
select:  填充引用 document 中的哪些字段
match:   可选,指定附加的查询条件
model:   可选,指定引用的 model
options: 可选,指定附加的其他查询选项,如排序以及条数限制等等

Mongoose 只支持以下几种引用字段的类型：ObjectId,Number,String,Buffer
引用document的主键类型必须和引用字段类型相对应。在生产环境中,推荐主键类型和引用类型都使用 ObjectId ,一是因为 ObjectId 不包含业务含义,二是 ObjectId 不大可能重复,三是因为 Mongoose 默认生成的主键类型就是 ObjectId ,可以减少很多配置的操作

1、Query#populate
Query.populate(path, [select], [model], [match], [options])

参数：
path
类型：String或Object
String类型时指定要被填充的关联字段,要填充多个关联字段可以以空格分隔,老版本是多次执行populat()方法
Object类型时就是把 populate 的参数封装到一个对象里。当然也可以是个数组

select
类型：Object或String,可选,指定填充 document 中的哪些字段
Object类型的时格式如:{name: 1, _id: 0},为0表示不填充,为1时表示填充。
String类型的时格式如:"name -_id",用空格分隔字段,在字段名前加上-表示不填充。详细语法query-select

model
类型：Model,可选,指定关联字段的model,如果没有指定就会使用Schema的ref

match
类型：Object,可选,指定附加的查询条件,如match: { age: { $gte: 21 }},

options
类型：Object,可选,指定附加的其他查询选项,如排序以及条数限制等等,如options: { limit: 5 }

2、Model#populate
Model.populate(docs, options, [cb(err,doc)])

参数：
docs
类型：Document或Array。单个需要被填充的 doucment 或者 document 的数组。

options
类型：Object。以键值对的形式表示。
keys：path select match model options,这些键对应值的类型和功能,与上述Query#populate方法的参数相同

[cb(err,doc)]
类型：Function,回调函数,接收两个参数,错误err和填充完的doc(s)

3、Document#populate
Document.populate([path], [callback])

参数：
path
类型：String或Object。与上述Query#populate`方法的 path 参数相同。

callback
类型：Function。回调函数,接收两个参数,错误err和填充完的doc(s)

</pre><pre class="js">
// 使用populate query方法进行关联
var mongoose = require('mongoose');
var Schema = mongoose.Schema;

var personSchema = Schema({
  _id     : Number,
  name    : String,
  age     : Number,
  stories : [{type: Schema.Types.ObjectId, ref: 'Story'}]
  // 指定关联引用,数组内的_id是来自Story Model的document _id
});

var storySchema = Schema({
  _creator : { type: Number, ref: 'Person' },   // 域存储的是Person Model的document _id是Number类型
  title    : String,
  fans     : [{ type: Number, ref: 'Person' }]
});

var Story  = mongoose.model('Story', storySchema);
var Person = mongoose.model('Person', personSchema);

// 保存对于其他document的ref的工作方式和保存属性相同,只是分配_id值
var aaron = new Person({ _id: 0, name: 'Aaron', age: 100 });
aaron.save(function (err) {
  if (err) return handleError(err);
  var story1 = new Story({
    title: "Once upon a timex.",
    _creator: aaron._id           // assign the _id from the person
  });

  story1.save(function (err) {
    if (err) return handleError(err);
  });
});

Story
  .findOne({ title: 'Once upon a timex.' })
  .populate('_creator')
  .exec(function (err, story) {
    if (err) return handleError(err);
    console.log('The creator is %s', story._creator.name);  // prints "The creator is Aaron"
  });

Story
  .find(...)
  .populate({
    path: 'fans',
    match: { age: { $gte: 21 }},
    select: 'name -_id',
    options: { limit: 5 }
  })
  .exec()

// 手动填充一个域,注意这只对单个ref有效,目前不能手动填充ref数组
Story.findOne({ title: 'Once upon a timex.' }, function(error, story) {
  if (error) {
    return handleError(error);
  }
  story._creator = aaron;
  console.log(story._creator.name); // prints "Aaron"
});

</pre><pre class="js">
var mongoose = require('mongoose')
  , Schema = mongoose.Schema
mongoose.Promise = global.Promise;
mongoose.connect('mongodb://localhost/population' , {useMongoClient: true})


var personSchema = Schema({
  _id     : Number,
  name    : String,
  age     : Number,
  stories : [{ type: Schema.Types.ObjectId, ref: 'Story' }]
});

var storySchema = Schema({
  _creator : { type: Number, ref: 'Person' },
  title    : String,
  fans     : [{ type: Number, ref: 'Person' }]
});

var Story  = mongoose.model('Story', storySchema);
var Person = mongoose.model('Person', personSchema);
var aaron = new Person({ _id: 0, name: 'Aaron', age: 100 });
var story1 = new Story({
  title: "Once upon a timex.",
  _creator: aaron._id    // assign the _id from the person
});

aaron.stories.push(story1);
aaron.save((err, doc) => {
  if(err) return console.log('err', err);
  story1.save(function (err) {
    if (err) return console.log('err', err);
    console.log('saved');
  });
});

/* 根据文章标题查找作者信息 */
Story
.findOne({ title: 'Once upon a timex.' })
.populate('_creator')
.exec(function (err, story) {
  if (err) return handleError(err);
  console.log(1, story, story._creator.name); // 'Aaron'
});
/*
{
  _id: 5a2f6ef878a35170fc414c55,
  title: 'Once upon a timex.',
  _creator: { _id: 0, name: 'Aaron', age: 100, __v: 0, stories: [ 5a2f6ef878a35170fc414c55 ] },
  __v: 0,
  fans: []
}
*/

/* 填充多个path feild选择 */
Story
.findOne({ title: 'Once upon a timex.' })
.populate('_creator fans', 'name -_id')
.exec(function (err, story) {
  if (err) return handleError(err);
  console.log(2, story, story._creator.name); // 'Aaron'
});
/*
{ _id: 5a2f6ef878a35170fc414c55, title: 'Once upon a timex.', _creator: { name: 'Aaron' }, __v: 0, fans: [] }
*/

/* 根据作者名字查找全部作品标题 */
Person
.findOne({name: 'Aaron'})
.populate('stories', 'title -_id')
.exec((err, person) => {
  console.log(3, person, person.stories);
})
/*
{ _id: 0, name: 'Aaron', age: 100, __v: 0, stories: [ { title: 'Once upon a timex.' } ] }
*/

Story.find({_creator: aaron._id}).exec((err, stories) => {
  console.log(4, stories);
})
/*
[ {_id: 5a2f6ef878a35170fc414c55, title: 'Once upon a timex.', _creator: 0, __v: 0, fans: [] } ]
*/

</pre><pre class="js">
// 表内部关联
const mongoose = require('mongoose');
const Schema = mongoose.Schema;
mongoose.Promise = global.Promise;

const UserSchema = Schema({
  name: String,
  age: Number,
  following: [{type: Schema.Types.ObjectId, ref: "User"}]  // 定义字段、类型、引用
});

const User = mongoose.model('User', UserSchema);

var lily = new User({name: 'lily', age: 22});
var lucy = new User({name: 'lucy'});

console.log('lily', lily);  // lily {name:'lily',age:22,_id: 5a2ce126357b36346097506b,following:[]}
console.log('lucy', lucy);  // llucy { name: 'lucy', _id: 5a2ce126357b36346097506c, following: [] }

mongoose.connect('mongodb://localhost/study' , {useMongoClient: true})
User.remove().exec();

lily.save(cb1);

function cb(err, doc){
  if(err) throw err;
  lucy.following.push(lily._id);   // lucy.following.push(doc._id);
  console.log(lucy);               // {name:'lucy',_id:5a2ce3480cb0825b48d60387,following:[5a2ce3480cb0825b48d60386 ] }
  lucy.save((err, doc)=>console.log(doc)); //{__v: 0,name:'lucy',_id:5a2ce3480cb0825b48d60387,following:[5a2ce3480cb0825b48d60386 ] }
}

function cb1(err, doc){
  if(err) throw err;
  console.log('lily1', lily);
  lucy.following.push(lily);  // lucy.following.push(doc);
  console.log('lucy1', lucy);
  lucy.save().then(doc => {
    console.log(doc);       // 同lucy1
    User.find({name: 'lucy'}).exec().then(r => console.log('r', r))
    User.findOne({name: 'lucy'}).populate('following').exec().then(r => console.log('r1', r))
  })
}

// lily1 { __v: 0,name: 'lily',age: 22,_id: 5a2ce126357b36346097506b,following: [] }
// lucy1 {name:'lucy',_id:5a2ce126357b36346097506c,following:[{_id:5a2ce126357b36346097506b,age: 22,name: 'lily',__v: 0,following: [] } ] }
// r [ { _id: 5a2ce126357b36346097506c,name: 'lucy',__v: 0,following: [ 5a2ce126357b36346097506b ] } ]
// r1 { _id: 5a2ce126357b36346097506c,name: 'lucy',__v: 0,following:[ { _id: 5a2ce126357b36346097506b,name: 'lily',age: 22,__v: 0,following: [] } ] }

</pre><pre class="js">
// 关联外表
var mongoose = require('mongoose');
var Schema = mongoose.Schema;

var UserSchema = new Schema({
  name: {type: String, unipue: true},
  posts: [{type: Schema.Types.ObjectId, ref: 'Post'}]
})
var User = mongoose.model('User', UserSchema);

var PostSchema = new Schema({
  poster: {type: Schema.Types.ObjectId, ref: 'User'},
  comments: [{type: Schema.Types.ObjectId, ref: 'Comment'}],
  title: String,
  content: String
})
var Post = mongoose.model('Post', PostSchema);

var CommentSchema = new Schema({
  post: {type: Schema.Types.ObjectId, ref: 'Post'},
  commenter: {type: Schema.Types.ObjectId, ref: 'User'} ,
  content: String
})
var Comment = mongoose.model('Comment', CommentSchema);

mongoose.connect('mongodb://localhost/population', err => {
  if(err) throw err;
  createData()
  queryPopulate()
  modelPopulate();
  docPopulate();
});

function docPopulate(){
  User.findOne({name: 'aikin'})
    .exec(function(err, doc) {
      var opts = [{
          path   : 'posts',
          select : 'title'
      }];
      doc.populate(opts, function(err, populatedDoc) {
          console.log(populatedDoc);
      });
    });
}

function modelPopulate(){
  Post.find({title: 'post-aikin'})
    .populate('poster comments')
    .exec(function(err, docs) {
        var opts = [{
          path   : 'comments.commenter',
          select : 'name',
          model  : 'User'
        }];
        Post.populate(docs, opts, function(err, populatedDocs) {
          console.log(populatedDocs[0]);
        });
    });
}

function queryPopulate(){
  Post.findOne({title: 'post-aikin'})
      .populate('poster comments', '-_id')
      .exec()
      .then(doc => console.log(doc))

  Post.findOne({title: 'post-aikin'})
      .populate({path: 'poster comments', select: '-_id'})
      .exec(function(err, doc) {
        console.log(doc);
      });

  //填充所有 users 的 posts
  User.find()
      .populate('posts', 'title', null, {sort: {title: -1 }})
      .exec(function(err, docs) {
        console.log(docs[0]);
      });

  //填充 user 'luajin'的 posts
  User.findOne({name: 'luajin'})
      .populate({path: 'posts', select: {title: 1 }, options: {sort: {title: -1 }}})
      .exec(function(err, doc) {
        console.log(doc);
      });
}

function createData(){
  var userIds = [mongoose.Types.ObjectId(), mongoose.Types.ObjectId(), mongoose.Types.ObjectId()];
  var postIds = [mongoose.Types.ObjectId(), mongoose.Types.ObjectId(), mongoose.Types.ObjectId()]
  var commentIds = [mongoose.Types.ObjectId(), mongoose.Types.ObjectId(), mongoose.Types.ObjectId()]

  var users = [], posts = [], comments = [];

  users.push({ _id: userIds[0], name: 'aikin', posts: [postIds[0]]});
  users.push({ _id: userIds[1], name: 'luna', posts: [postIds[1]]});
  users.push({ _id: userIds[2], name: 'luajin', posts: [postIds[2]]});

  posts.push({ _id: postIds[0], poster: userIds[0], comments: [commentIds[0]], title: 'post-aikin'});
  posts.push({ _id: postIds[1], poster: userIds[1], comments: [commentIds[1]], title: 'post-luna'});
  posts.push({ _id: postIds[2], poster: userIds[2], comments: [commentIds[2]], title: 'post-luajin'});

  comments.push({_id: commentIds[0], post: postIds[0], commenter: userIds[0], content: 'comment-aikin'})
  comments.push({_id: commentIds[1], post: postIds[1], commenter: userIds[1], content: 'comment-aikin'})
  comments.push({_id: commentIds[2], post: postIds[2], commenter: userIds[2], content: 'comment-aikin'})

  User.remove({}).exec();
  Post.remove({}).exec();
  Comment.remove({}).exec();
  User.create(users, (err, docs) => {
    Post.create(posts, (err, docs) => {
      Comment.create(comments, (err, docs) => {
        console.log('数据插入成功');
      })
    })
  })
}

</pre>Populating across multiple levels<pre class="js">
// 获取好友的好友列表 Get friends of friends - populate the 'friends' array for every friend

var mongoose = require('mongoose')
  , Schema = mongoose.Schema
mongoose.Promise = global.Promise;
mongoose.connect('mongodb://localhost/population' , {useMongoClient: true})

var friendSchema = new Schema({
  name: String,
  friends: [{ type: Schema.Types.ObjectId, ref: 'Friend' }]
});

var Friend = mongoose.model('Friend', friendSchema)

var zhangsan = new Friend({name: 'zhangsan'});
var lisi = new Friend({name: 'lisi'});
var wangwu = new Friend({name: 'wangwu'});
var liuliu = new Friend({name: 'liuliu'});
zhangsan.friends.push(lisi._id, wangwu._id);
lisi.friends.push(wangwu._id, liuliu._id);
wangwu.friends.push(liuliu._id, zhangsan._id);

Friend.remove().exec();
Friend.insertMany([zhangsan, lisi, wangwu, liuliu], function(err,docs){
    console.log('docs', docs);

    Friend.
    findOne({ name: 'lisi' }).
    populate({
      path: 'friends',
      populate: { path: 'friends' }
    })
    .exec((err, doc) => console.log('doc', doc, doc.friends))
});

/*
[ { __v: 0, _id: 5a2f77f6b0f8967188b37f46, name: 'zhangsan',
    friends: [ 5a2f77f6b0f8967188b37f47, 5a2f77f6b0f8967188b37f48 ] },
  { __v: 0, _id: 5a2f77f6b0f8967188b37f47, name: 'lisi',
    friends: [ 5a2f77f6b0f8967188b37f48, 5a2f77f6b0f8967188b37f49 ] },
  { __v: 0, _id: 5a2f77f6b0f8967188b37f48, name: 'wangwu',
    friends: [ 5a2f77f6b0f8967188b37f49, 5a2f77f6b0f8967188b37f46 ] },
  { __v: 0, _id: 5a2f77f6b0f8967188b37f49, name: 'liuliu',
    friends: [] }
]

{ _id: 5a2f7883baa82f71604ec89f, __v: 0, name: 'lisi',
  friends:
   [ { _id: 5a2f7883baa82f71604ec8a0, __v: 0, name: 'wangwu', friends: [Array] },
     { _id: 5a2f7883baa82f71604ec8a1,  __v: 0, name: 'liuliu', friends: [] }
   ]
}

[
  {"_id":"5a2f7883baa82f71604ec8a0","__v":0,"name":"wangwu","friends":[
    {"_id":"5a2f7883baa82f71604ec8a1","__v":0,"name":"liuliu","friends":[]},
    {"_id":"5a2f7883baa82f71604ec89e","__v":0,"name":"zhangsan","friends":["5a2f7883baa82f71604ec89f","5a2f7883baa82f71604ec8a0"]}]},
  {"_id":"5a2f7883baa82f71604ec8a1","__v":0,"name":"liuliu","friends":[]}
]
*/

</pre>Populating across Databases 指定populate的Model属性 跨数据库填充,能够通过MongoDB数据库甚至是通过MongoDB实例填充<pre class="js">
// 每一个event都有一个对应的conversation线程
var eventSchema = new Schema({
  name: String,
  conversation: Schema.Types.ObjectId
});
var conversationSchema = new Schema({
  numMessages: Number
});

// event和conversation存储在单独的MongoDB实例
var db1 = mongoose.createConnection('localhost:27000/db1');
var db2 = mongoose.createConnection('localhost:27001/db2');

var Event = db1.model('Event', eventSchema);
var Conversation = db2.model('Conversation', conversationSchema);

Event.
  find().
  populate({ path: 'conversation', model: Conversation }).
  exec(function(error, docs) { /* ... */ });

</pre><pre class="js">
/* 定义Schema */
var mongoose = require('mongoose');
var Schema = mongoose.Schema;

var UserSchema = new Schema({
  uid: { type: String, required: true, unique: true },
  logLevel: {type: String,default: 'info'},
  meta: {
    createAt: { type: Date, default: Date.now() },
    updateAt: { type: Date, default: Date.now() }
  }
});

UserSchema.pre('save', function (next) {
  if (this.isNew) {
    this.meta.updateAt = this.meta.createAt = Date.now();
  } else {
    this.meta.updateAt = Date.now();
  }
  next()
});

UserSchema.statics = {
  fetch: function (cb) {
    return this.find({}).sort('meta.createAt').exec(cb)
  },
  findById: function (id, cb) {
    return this.findOne({_id: id}).sort('meta.createAt').exec(cb);
  },
  findByUid: function (uid, cb) {
    return this.findOne({uid: uid}).sort('meta.createAt').exec(cb);
  }
};
module.exports = UserSchema;

/* 将schema发布为Model */
var mongoose = require('mongoose');
var UserSchema = require('./userSchema');
var User = mongoose.model('User',UserSchema);
module.exports = User;

/* 在controller层引入这个model,就可以使用之前定义的静态方法了。这个model还拥有Model.create(),Model.find(),Model.update(),Model.remove()方法,进行基本的CURD操作 */

var _ = require('underscore');
var User = require('../models/user');

module.exports = {
  //  通过实例化model,创建一个model实例
  add: function(req, res, next) {
    var _user = new User(req.body.user);    //相当于调用了Model.create(req.body)
    _user.save(function (err, user) {
      if (err) //doSomething...
      else     //doSomething...
    })
  },

  delete: function (req, res) {
    var id = req.query._id;
    User.remove({_id: id}, function (err) {
      if (err) //doSomething...
      else     //doSomething...
    })
  },
  update: function (req, res) {
    var id = req.body.id;
    var userParams = req.body;
    User.findById(id, function (err, user) {
      if (err) {
        //doSomething...
      } else {
        _user = _.extend(user, userParams);
        _user.save(function (err, user) {
          if (err) //doSomething...
          else     //doSomething...
        })
      }
    })
  },
  list: function (req, res) {
    User.fetch(function (err, users) {
      var resultUsers=_.map(users, function(user){
        if (err) //doSomething...
        else     //doSomething...
    })
  },
};


</pre><pre id="m-find">
【 mongoose CURD操作 - 查询操作 】
query数据提供了两种方式：

1、使用回调函数查询：query会立即执行,然后返回到回调函数中
PersonModel.findOne({'name.last':'dragon'},function(err,person){});

2、使用query查询方法：链式查询
返回的是一个Query对象,该对象是一个Promise, 所以可以使用 chain 进行调用.最后必须使用exec(cb)传入回调进行处理,第一个参数永远是err,第二个就是返回的数据

这种方式相对直接查询,分的比较明细,如果不带callback则返回query,该query对象执行的方法都将返回自己,只有在执行exec方法时才执行查询,而且必须有回调
如果不提供回调函数,所有的查询方法都返回Query对象,都可以被再次修改(增加选项、键等),直到调用exec方法

Person
  .find({ occupation: /host/ })
  .where('name.last').equals('Ghost')
  .where('age').gt(17).lt(66)
  .where('likes').in(['vaporizing', 'talking'])
  .limit(10)
  .sort('-occupation')
  .select('name occupation')
  .exec(callback);

使用Mongoose每个model的静态方法来查找文档使用以下方法：
find()
findById()
findOne()
where
query helper: Schema.query.xxx = function(arg){ return this.}

Model.find(conditions, [fields], [options], [callback(err, docs)])
Model.find(Conditions,field,callback)
一参表示查询条件
二参用于控制返回的字段: 属性过滤;field省略或为Null则返回所有属性,_id字段默认输出
三参用于配置查询参数: 如果使用第三个参数,前两个参数如果没有值,需要设置为null
四参是回调函数

Model.findById(id, [projection], [options], [callback])      // 单条数据
Model.findById(_id, callback)

Model.findOne([conditions], [fields], [options], [callback])  // 返回查找到的所有实例的第一个

常用查询条件：
$or　　　　   或关系
$nor　　　    或关系取反
$gt　　　　   大于
$gte　　　    大于等于
$lt　　　　   小于
$lte　　　    小于等于
$ne           不等于
$in           在多个值范围内
$nin          不在多个值范围内
$all          匹配数组中多个值
$regex　　    正则,用于模糊查询
$size　　　   匹配数组大小
$maxDistance　范围查询,距离(基于LBS)
$mod　　      取模运算
$near　　　   邻域查询,查询附近的位置(基于LBS)
$exists　　   字段是否存在
$elemMatch　　匹配内数组内的元素
$within　　   范围查询(基于LBS)
$box　　　    范围查询,矩形范围(基于LBS)
$center       范围醒询,圆形范围(基于LBS)
$centerSphere 范围查询,球形范围(基于LBS)
$slice　　　　查询字段集合中的元素(比如从第几个之后,第N到第M个元素)

游标：
数据库使用游标返回find的执行结果。客户端对游标的实现通常能够对最终结果进行有效的控制。可以限制结果的数量,略过部分结果,根据任意键按任意顺序的组合对结果进行各种排序,或者是执行其他一些强的操作

</pre><pre class="js">
TestModel.find({time:{"$gte": new Date('2014-01-24'),"$lt": new Date('2014-01-25')}},(error,docs)=>{
   //查询指定日期内的数据
});

TestModel.find(function(error,docs){
   //若没有向find传递参数,默认的是显示所有文档的数组
});

TestModel.find({},function(error,docs){
   //若没有向find传递参数,默认的是显示所有文档的数组
});

TestModel.find({ "age": 28 }, function (error, docs) {
  error ? console.log("error :" + error) : console.log(docs);  //docs: age为28的所有文档
});

TestModel.find({name:/a/},'name',function(err,docs){
    // 找出名字里存在'a'的数据,且只输出'name'字段
    console.log(docs);
})

TestModel.find({}, ['first', 'last'], function (error, docs) {
  // 只查询指定键的结果,docs此时只会包含文档的部分键值
  error ? console.log("error :" + error) : console.log(docs);  //docs: age为28的所有文档
});

TestModel.find({},{name:1, age:1, _id:0},function(err,docs){
   ////返回只包含键值name、age的所有记录, docs 查询结果集
})

TestModel.findOne({ age: 27}, function (err, doc){
   // 查询符合age等于27的第一条数据,doc是查询结果
});

TestModel.findById('obj._id', function (err, doc){
  //doc 查询结果文档
});

TestModel.find({"age":{"$gt":18}},function(error,docs){
   //查询所有nage大于18的数据
});

TestModel.find({"age":{"$lt":60}},function(error,docs){
   //查询所有nage小于60的数据
});

TestModel.find({"age":{"$gt":18,"$lt":60}},function(error,docs){
   //查询所有nage大于18小于60的数据
});

Model.find({ age:{ $ne:24}},function(error,docs){
    //查询age不等于24的所有数据
});

Model.find({name:{$ne:"tom"},age:{$gte:18}},function(error,docs){
  //查询name不等于tom、age>=18的所有数据
});

Model.find({name:/huo/,age:{$gte:18}},function(err,docs){
  // 找出年龄大于18且名字里存在'huo'的数据
})

Model.find({ age:{ $in: 20}},function(error,docs){
   //查询age等于20的所有数据
});

Model.find({ age:{$in:[20,30]}},function(error,docs){
  //可以把多个值组织成一个数组
});

Model.find({"$or":[{"name":"yaya"},{"age":28}]},function(error,docs){
  //查询name为yaya或age为28的全部文档
});

Model.find({name: {$exists: true}},function(error,docs){
  //查询所有存在name字段属性的文档
});
Model.find({telephone: {$exists: false}},function(error,docs){
  //查询所有不存在telephone字段属性的文档
});

// null全部字段
Model.find({},null,{limit:20},function(err,docs){
    console.log(docs);
});

Model.find(null,null,{skip:4},function(err,docs){
    console.log(docs);
});

Model.find({},null,{skip:4},function(err,docs){
    console.log(docs);
});

Model.find({},null,{sort:{age:-1}},function(err,docs){
  //查询所有数据,并按照age降序顺序返回数据docs
});

</pre><pre class="js">
// 使用find()方法找出集合中所有数据
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ age:Number, name: String});
    var temp = mongoose.model('temp', schema);
    temp.find(function(err,docs){
      console.log(docs);
    })
  }
});

</pre><pre class="js">
/* findById() 显示第0个元素的所有字段 */

var aIDArr = [];
temp.find(function(err,docs){
  docs.forEach(function(item,index,arr){
    aIDArr.push(item._id);
  })
  temp.findById(aIDArr[0],function(err,doc){
    console.log(doc); //{ _id: 5971f93be6f98ec60e3dc86c, name: 'huochai', age: 27 }
  })
})

// 以上代码的另一种写法如下

var aIDArr = [];
temp.find(function(err,docs){
  docs.forEach(function(item,index,arr){
    aIDArr.push(item._id);
  })
  temp.findById(aIDArr[0]).exec(function(err,doc){
    console.log(doc); //{ _id: 5971f93be6f98ec60e3dc86c, name: 'huochai', age: 27 }
  })
})

// 只输出name字段
temp.findById(aIDArr[0],{name:1,_id:0},function(err,doc){
  console.log(doc);  //{  name: 'huochai'}
})

// 或者写成下面这种形式
temp.findById(aIDArr[0],{name:1,_id:0}).exec(function(err,doc){
  console.log(doc);  //{  name: 'huochai'}
})

// 输出最少的字段
temp.findById(aIDArr[0],{lean:true},function(err,doc){
  console.log(doc);   //{ _id: 5971f93be6f98ec60e3dc86c }
})
temp.findById(aIDArr[0],{lean:true}).exec(function(err,doc){
  console.log(doc);   //{ _id: 5971f93be6f98ec60e3dc86c }
})

</pre><pre class="js">
/* findOne() */

// 找出age>20的文档中的第一个文档,且输出包含name字段在内的最短字段
temp.findOne({age:{$gt : 20}},"name",{lean:true},function(err,doc){
  //{ _id: 5971f93be6f98ec60e3dc86c, name: 'huochai' }
  console.log(doc);
})
temp.findOne({age:{$gt : 20}},"name").lean().exec(function(err,doc){
  //{ _id: 5971f93be6f98ec60e3dc86c, name: 'huochai' }
  console.log(doc);
})

</pre><pre>
【 $where 查询 】
如果要进行更复杂的查询,需要使用$where操作符,$where操作符功能强大而且灵活,它可以使用任意的JavaScript作为查询的一部分,包含JavaScript表达式的字符串或者JavaScript函数

Model.$where() mongodb中使用js表达式查询,可以用find({$where: javascript})方式
$where是一种快捷方式,并支持链式调用查询
Model.$where('this.firstname === this.lastname').exec(callback)

Model.where() 当查询条件比较复杂时使用

Model.where(path, [val])
一参path是字段,
二参val可选,表示可以用来指定,path = val的数据内容, 你也可以不写, 交给后面进行筛选

User.find({age: {$gte: 21, $lte: 65}}, callback);
//等价于:
User.where('age').gte(21).lte(65).exec(callback);

Model
  .where('age').gte(25)
  .where('tags').in(['move', 'music', 'art'])
  .select('name', 'age', 'tags')
  .skip(20)
  .limit(10)
  .asc('age')
  .slaveOK()
  .hint({age: 1, name: 1})
  .run(callback)

var User = require('./user');
User.find({age: {$gte: 21, $lte: 65}}, callback)
User.where('age').gte(21).lte(65).exec(callback)    // 等效

var query = Model.find({});
query.where('feild', 5);
query.limit(5);
query.exec(function(err, docs){
  // internally, called when the query.complete or query.error are called
})

</pre><pre class="js">
// $where 使用字符串
temp.find({$where:"this.x == this.y"},function(err,docs){
  console.log(docs);
  //[ { _id: 5972ed35e6f98ec60e3dc887,name: 'wang',age: 18,x: 1,y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc889, name: 'li', age: 20, x: 2, y: 2 } ]
})

temp.find({$where:"obj.x == obj.y"},function(err,docs){
  console.log(docs);
  //[ { _id: 5972ed35e6f98ec60e3dc887,name: 'wang',age: 18,x: 1,y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc889, name: 'li', age: 20, x: 2, y: 2 } ]
})

</pre><pre class="js">
// $where 使用函数

temp.find({$where:function(){
  return obj.x !== obj.y;
  }},function(err,docs){
  console.log(docs);
  //[ { _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 },
  //{ _id: 5972ed35e6f98ec60e3dc888, name: 'huo', age: 30, x: 2, y: 1 } ]
})

temp.find({$where:function(){
      return this.x !== this.y;
  }},function(err,docs){
  console.log(docs);
  //[ { _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 },
  //{ _id: 5972ed35e6f98ec60e3dc888, name: 'huo', age: 30, x: 2, y: 1 } ]
})

</pre><pre class="js">
/* 以下等效 */

// With a JSON doc
Person.
  find({
    occupation: /host/,
    'name.last': 'Ghost',
    age: { $gt: 17, $lt: 66 },
    likes: { $in: ['vaporizing', 'talking'] }
  }).
  limit(10).
  sort({ occupation: -1 }).
  select({ name: 1, occupation: 1 }).
  exec(callback);

// Using query builder
Person.
  find({ occupation: /host/ }).
  where('name.last').equals('Ghost').
  where('age').gt(17).lt(66).
  where('likes').in(['vaporizing', 'talking']).
  limit(10).
  sort('-occupation').
  select('name occupation').
  exec(callback);

</pre><pre>
游标集合的处理方法 - 查询后的处理方法：
sort     排序
skip     跳过
limit    限制
select   显示字段
exect    执行
count    计数
distinct 去重分组

Model.count(conditions, [callback])                    // 统计符合条件的文档数
Model.count({}, [callback])                            // 统计全部文档的数量
Model.distinct('field',[conditions],[callback])// 去重,存在哪些值,将结果放入数组,查询符合条件的文档并返回根据键分组的结果;无回调则链式

最常用的查询选项就是限制返回结果的数量(limit函数)、忽略一点数量的匹配结果(skip函数)以及排序(sort函数)。所有这些选项一点要在查询被发送到服务器之前指定
限制数量、跳过数量、结果排序

</pre><pre class="js">
var schema = new mongoose.Schema({ age:Number, name: String,x:Number,y:Number});
var temp = mongoose.model('temp', schema);
temp.find(function(err,docs){
  //[ { _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 },
  //{ _id: 5972ed35e6f98ec60e3dc887,name: 'wang',age: 18,x: 1,y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc888, name: 'huo', age: 30, x: 2, y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc889, name: 'li', age: 20, x: 2, y: 2 } ]
  console.log(docs);
})

// sort()方法按age从小到大排列
temp.find().sort("age").exec(function(err,docs){
  //[ { _id: 5972ed35e6f98ec60e3dc887,name: 'wang',age: 18,x: 1,y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc889, name: 'li', age: 20, x: 2, y: 2 },
  //{ _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 },
  //{ _id: 5972ed35e6f98ec60e3dc888, name: 'huo', age: 30, x: 2, y: 1 } ]
  console.log(docs);
});

// sort()方法按x从小到大,age从大到小排列
temp.find().sort("x -age").exec(function(err,docs){
  //[ { _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 },
  //{  _id: 5972ed35e6f98ec60e3dc887,name: 'wang',age: 18,x: 1,y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc888, name: 'huo', age: 30, x: 2, y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc889, name: 'li', age: 20, x: 2, y: 2 } ]
  console.log(docs);
});

// skip()跳过一个,显示其他
temp.find().skip(1).exec(function(err,docs){
  //[ { _id: 5972ed35e6f98ec60e3dc887,name: 'wang',age: 18,x: 1,y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc888, name: 'huo', age: 30, x: 2, y: 1 },
  //{ _id: 5972ed35e6f98ec60e3dc889, name: 'li', age: 20, x: 2, y: 2 } ]
  console.log(docs);
});

// limit()显示2个
temp.find().limit(2).exec(function(err,docs){
  //[ { _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 },
  //{ _id: 5972ed35e6f98ec60e3dc887,name: 'wang',age: 18,x: 1,y: 1 } ]
  console.log(docs);
});

// select() 只显示name、age字段,不显示_id字段
temp.find().select("name age -_id").exec(function(err,docs){
  //[ { name: 'huochai', age: 27 },{ name: 'wang', age: 18 },{ name: 'huo', age: 30 },{ name: 'li', age: 20 } ]
  console.log(docs);
});

temp.find().select({name:1, age:1, _id:0}).exec(function(err,docs){
  //[ { name: 'huochai', age: 27 },{ name: 'wang', age: 18 },{ name: 'huo', age: 30 },{ name: 'li', age: 20 } ]
  console.log(docs);
});

// count() 显示结果集中文档的数量
temp.find().count(function(err,count){
  console.log(count);//4
});

// distinct() 返回结果集中x的值
temp.find().distinct('x',function(err,distinct){
  console.log(distinct);//[ 1, 2 ]
});

</pre><pre>
【 mongoose docuemnt对象 js对象 lean() toObject() toJson() toString() 】

</pre><pre class="js">
var whedocstr = {'username' : 'Tracy McGrady'};
var opt = {"username": 1 ,"_id": 0};

User.findOne({name: 'lily'}, {name: 1}, (err, doc) => {
  console.log('doc.name', doc, doc.name, doc.toObject().name, doc.toJSON().name, JSON.stringify(doc).name)
  // doc.name { _id: 5a2ce3480cb0825b48d60386, name: 'lily' } undefined lily lily undefined
  console.log('json', JSON.parse(JSON.stringify(doc)).name);
  // json lily
  console.log('toObject', doc.toObject());
  // toObject { _id: 5a2ce3480cb0825b48d60386, name: 'lily' }
  console.log('toJSON', doc.toJSON());
  // toJSON { _id: 5a2ce3480cb0825b48d60386, name: 'lily' }
  console.log('JSON.stringify', JSON.stringify(doc));
  // JSON.stringify {"_id":"5a2ce3480cb0825b48d60386","name":"lily"}
})

User.find(whedocstr, opt, function(err, docs){
  if(err) return console.log("Error:", err);
  console.log(docs, docs[0].username);
  // [ { username: 'Tracy McGrady' } ] 'Tracy McGrady'

  var doc = docs[0].toObject();
  doc.isPraise = doc ? 5 : 0;
  console.log('doc5', doc, typeof doc, doc.isPraise, doc.hasOwnProperty('isPraise'));
  // doc5 { username: 'Tracy McGrady', isPraise: 5 } object 5 true

  doc = docs[0].toJSON();
  doc.isPraise = doc ? 5 : 0;
  console.log('doc6', doc, typeof doc, doc.isPraise, doc.hasOwnProperty('isPraise'));
  // doc6 { username: 'Tracy McGrady', isPraise: 5 } object 5 true

  doc = docs[0].toString();
  console.log('doc7', doc, typeof doc);
  // doc7 { username: 'Tracy McGrady' } string
})

/* lean将document转成jsobject */
User.findOne({username: 'Tracy McGrady'}, {username: 1 ,_id: 0}).exec((err, doc) => {
  doc.isPraise = doc ? 5 : 0;
  console.log('doc1', doc, doc.isPraise, doc.hasOwnProperty('isPraise'));
  // { username: 'Tracy McGrady' } 5 true
})

User.findOne({username: 'Tracy McGrady'}, {username: 1 ,_id: 0}, (err, doc) => {
  doc.isPraise = doc ? 5 : 0;
  console.log('doc2', doc, doc.isPraise, doc.hasOwnProperty('isPraise'));
  // { username: 'Tracy McGrady' } 5 true
})

User.findOne({username: 'Tracy McGrady'}, {username: 1 ,_id: 0}).lean().exec((err, doc) => {
  doc.isPraise = doc ? 5 : 0;
  console.log('doc3', doc, doc.isPraise, doc.hasOwnProperty('isPraise'));
  // { username: 'Tracy McGrady', isPraise: 5 } 5 true
})

User.findOne({username: 'Tracy McGrady'}, {username: 1 ,_id: 0}, {lean: true}, (err, doc) => {
  doc.isPraise = doc ? 5 : 0;
  console.log('doc4', doc, doc.isPraise, doc.hasOwnProperty('isPraise'));
  // { username: 'Tracy McGrady', isPraise: 5 } 5 true
})

</pre><pre>
【 mongoose聚合查询 】
聚合归类             -> 函数名称
Aggregation Pipeline -> Model.aggregate()
Map-Reduce           -> Model.mapReduce()
Single Purpose       -> Model.count()  Model.distinct()  Model.group()

MongoDB的聚合框架实现是模仿Data processing pipeline。数据文档进入多级管道并将文档转换为聚合结果。

aggregate在读取数据的同时进行数据处理
聚合管道最基础的功能包括提供类似于查询的过滤器;数据文档转换,能调整聚合结果所输出的文档数据的结构,如在聚合的结果中新增加原始数据文档中没有的字段,如数组长度、组合名称等有价值的字段。
还有另外的功能,包括按数据文档的字段进行分组或排序,对数组或成批的数据文档进行再处理,还包括计算平均数、统计求和、连接/截取字符串等功能。聚合管道还支持索引等功能。

为了实现以上功能,引入了聚合管道操作符(Aggregation Pipeline Operators)的概念
操作符分为三类：
Stage Operators
Expression Operators
Accumulators

Model.aggregate()

参数：
1、$project能够将数据文档指定的字段传给管道做下一步处理,指定的字段可以是数据文档中原有的字段,也可以是新计算出来的自定义字段
{ $project: { < specifications > } } 中specifications的三种形式：
< filed > : < 1 or true>  指定要包含的字段
_id       : < 0 or false> 不处理_id字段
< field > : < expression > 新增的自定义字段或修改掉原有字段的值

2、$size 用于计算数组的长度
{ $size: < expression > } 其中expression可以是从数据文档中现有的数组,也可以是运算后的新数组

3、$ifNull
{ $ifNull: [ < expression >, < replacement-expression-if-null > ] }
该操作符功能是计算表达式expression,如果expression的计算结果为非空值,则返回该非空值;如果为空值或者是undefined或者计算失败,则使用replacement-expression-if-null这个表达式的结果来代替
expression可以是计算表达式,也可以直接是数据本身

例：// 当发现数据文档中没有device字段时直接返回字符串Unknown
{
 $project: {
    alias_device: { $ifNull: [ "$device", "Unknown" ] }
 }
}


</pre><pre class="js">
// Find the max balance of all accounts
Users.aggregate(
  { $group: { _id: null, maxBalance: { $max: '$balance' }}},
  { $project: { _id: 0, maxBalance: 1 }},
  function (err, res) {
    if (err) return handleError(err);
    console.log(res);                   // [ { maxBalance: 98000 } ]
});

// Or use the aggregation pipeline builder.
Users.aggregate()
  .group({ _id: null, maxBalance: { $max: '$balance' } })
  .select('-id maxBalance')
  .exec(function (err, res) {
    if (err) return handleError(err);
    console.log(res);                    // [ { maxBalance: 98 } ]
  });

</pre><pre class="js">
function findThePhoneWithMostAppsInstalled() {
  Phone.aggregate([
    {
      $project :
      {
        apps_count : {$size : {"$ifNull" : ["$apps",[]] } },
        device : 1,
        manufacturer : 1,
        apps : 1
      }
    },
    {$sort:{"apps_count" : -1}}
  ])
  // .limit(1) // 可加可不加.取结果的phones[0]即可了
  .exec((err, phones)=>{
    console.log('---findThePhoneWithMostAppsInstalled()---------------------------------');
    if (err) {
      console.log(err);
    } else {
      var phone = phones[0];
      console.log(phone);
    }
  });
}

</pre><pre class="js">
/* 根据日期(yyyy-MM-dd)对营业额进行分组,并计算其当天的收入 */

{
    "_id" : ObjectId("578c7cf8c2b8941e375a1178"),
    "price" : 10,
    "shop" : ObjectId("57751e70d35e816989656eb3"),
    "created_at" : ISODate("2016-07-01T06:53:44.148Z"),
},
{
    "_id" : ObjectId("578c7cf8c2b8941e375a2345"),
    "price" : 20,
    "shop" : ObjectId("57751e70d35e816989656eb3"),
    "created_at" : ISODate("2016-07-01T07:50:24.242Z"),
},
{
    "_id" : ObjectId("5778d62630cc9e92a723c370"),
    "price" : 5,
    "shop" : ObjectId("57751e70d35e816989656eb3"),
    "created_at" : ISODate("2016-07-02T09:08:54.656Z"),
}

var shop = req.shop; //店铺数据
//聚合
Order.aggregate([
   { $match: { "shop": shop._id } },
   {
      $project : {
          day : {$substr: [{"$add":["$created_at", 28800000]}, 0, 10] },//时区数据校准,8小时换算成毫秒数为8*60*60*1000=288000后分割成YYYY-MM-DD日期格式便于分组
          "price": 1 //设置原有price字段可用,用于计算总价
      },
   },
   {
      $group: {
          _id:"$day",                  //将_id设置为day数据
          totalPrice:{$sum: "$price"}, //统计price
      }
   },
   {
      $sort: {_id: 1}                  //根据date排序
   }
]).exec(function (err, turnover){        //返回结果
    console.log(turnover);
});

// 结果
[
    {_id: "2016-07-01", totalPrice: 30},
    {_id: "2016-07-02", totalPrice: 5}
]

// 注释
$match用于匹配满足条件的文档,如同find函数。

$project用于指示字段是否输出以及字段输出控制。

$substr与$add,一个是分割操作,另一个相加操作。不难发现我们的原始数据created_at字段是具体到秒,因此如果想根据日期进行分割的话,那么需要将created_at分割成我们想要的日期格式,这其中需要特别注意的是mongoodb存储的数据是按照世界时存储的,因此进行分割操作时候需要对时间进行时区校正,因此需使用$add加上时区差8小时(毫秒数)才能得到正确的数据,最后一步便是利用$group进行分组了。

ISODate("2016-07-02T09:08:54.656Z")+28800000 = Sat Jul 02 2016 17:08:54 GMT+080028800000

细心的小伙伴可以会发现aggregate自带日期操作$year,$month,$dayOfMonth用于获取年,月,日,会想着通过这三个参数来拼装成yyyy-MM-dd日期格式,可惜,fidding之前也是这么操作的,只是最后发现appregate并解析不了,故在此使用了$substr分割方法。

$group分组以及统计,其中_id对应值便是我们所需分组的字段数据,totalPrice则是用$sum对同组数据的字段price进行求和,并将结果存放于totalPrice中。

$sum字段求和。

$sort排序。

</pre><pre class="js">
// 根据日期分组,查看每天登陆的用户
User.aggregate([
  { $match: {username: {$exists: true}}},
  {
    $project : {
        day : {$substr: [{"$add":["$logindate", 28800000]}, 0, 10] },//时区数据校准,分割成YYYY-MM-DD日期格式便于分组
        username: 1                        // 使用原username字段
     },
    },
    {
      $group: {
          _id:"$day",                         //将_id设置为day数据
          users:{$addToSet: "$username"},
      }
   },
   { $sort: {_id: 1} }                        // 根据新的_id排序
]).exec(function (err, result){
  if(err) throw err;
    console.log(result);
});

/*
[ { _id: '2017-12-10', users: [ 'Tracy McGrady' ] },
  { _id: '2017-12-11', users: [ 'wangwu' ] },
  { _id: '2017-12-12', users: [ 'zhangsan', 'liuliu', 'lisi' ] },
  { _id: '2017-12-13', users: [ 'test date' ] }
]
*/

</pre><pre id="m-insert">
【 mongoose CURD操作 - 保存数据 - document的创建 】
基于entity文档实例的保存：
Entity.save([options], [options.safe], [options.validateBeforeSave], [fn])

基于model保存数据：
Model.create(doc(s), [callback])
Model.insertMany(doc(s), [options], [callback])

Entity是model的对象,用它来添加数据的时候会把隐藏属性一起存入数据库,有几率报错
model只能添加纯净的json对象,不能添加它创建的实体

使用save()方法,需要先实例化为文档,再使用save()方法保存文档
create()方法,则直接在模型Model上操作,并且可以同时新增多个文档

</pre><pre class="js">
//使用Entity来增加一条数据
var krouky = new PersonModel({name:'krouky'});
krouky.save(callback);

//使用Model来增加一条数据
var MDragon = {name:'MDragon'};
PersonModel.create(MDragon,callback);

</pre><pre class="js">
TestModel.create({
    name : "test_create",
    age  : 26,
    email: "tom@qq.com"
  },function(error,doc){
    if(error) {
        console.log(error);
    } else {
        console.log(doc);
    }
  }
});

</pre><pre class="js">
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ age:Number, name: String});
    var temp = mongoose.model('temp', schema);
    temp.create({name:"xiaowang"},{name:"xiaoli"},function(err,doc1,doc2){
        //{ __v: 0, name: 'xiaowang', _id: 59720d83ad8a953f5cd04664 }
        console.log(doc1);
        //{ __v: 0, name: 'xiaoli', _id: 59720d83ad8a953f5cd04665 }
        console.log(doc2);
    });
  }
});

</pre><pre class="js">
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ age:Number, name: String});
    var temp = mongoose.model('temp', schema);
    temp.insertMany([{name:"a"},{name:"b"}],function(err,docs){
        //[ { __v: 0, name: 'a', _id: 59720ea1bbf5792af824b30c },
        //{ __v: 0, name: 'b', _id: 59720ea1bbf5792af824b30d } ]
        console.log(docs);
    });
  }
});

</pre><pre class="js">
var Entity = new Model({name:"entity_save",age: 27});
Entity.save(function(error,doc) {
  if(error) {
    console.log(error);
  } else {
    console.log(doc);
  }
});

</pre><pre class="js">
var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ age:Number, name: String});
    var temp = mongoose.model('temp', schema);
    new temp({age:10,name:'save'}).save(function(err,doc){    //使用链式写法
      console.log(doc);
      //[ { _id: 59720bc0d2b1125cbcd60b3f, age: 10, name: 'save', __v: 0 } ]
    });
  }
});

</pre><pre id="m-update">
【 mongoose CURD操作 - 更新数据 】

对数据的更新: 使用update子句更新符合指定条件的文档,更新数据在发送到数据库服务器之前会改变模型的类型
为了向后兼容,所有顶级更新键如果不是原子操作命名的,会同一按$set操作处理

文档更新可以使用以下几种方法:
update()                 更新,不返回更新对象到应用程序
updateMany()
find() + save()
updateOne()
findOne() + save()
findByIdAndUpdate()
fingOneAndUpdate()       更新,返回更新对象到应用程序

Model.update(conditions, doc, [options], [callback])
如果设置的查找条件,数据库里的数据并不满足,默认什么事都不发生
如果设置options里的upsert参数为true,没有符合查询条件的文档时mongo将会综合第一第二个参数向集合插入一个新的文档
options选项：
safe (boolean)：      默认为true。安全模式
upsert (boolean)：    默认为false。如果不存在则创建新记录
multi (boolean)：     默认为false。是否更新多个查询记录
runValidators：       如果值为true,执行Validation验证,validation验证器在SchemaType中定义
setDefaultsOnInsert： 如果upsert选项为true,在新建时插入文档定义的默认值
strict (boolean)：    以strict模式进行更新
overwrite (boolean)： 默认为false。禁用update-only模式,允许覆盖记录

update()方法中回调函数不能省略,否则数据不会被更新。如果回调函数里并没有什么有用的信息则可以使用exec()简化代码
temp.update({name:/aa/},{age: 0},{upsert:true}).exec();

Model.updateMany(conditions, doc, [options], [callback])
updateMany()与update()方法唯一区别是默认更新多个文档,即使设置{multi:false}也无法只更新第一个文档

Model.updateOne(conditions, doc, [options], [callback])
updateOne()方法只能更新找到的第一条数据,即使设置{multi:true}也无法同时更新多个文档

find() + save() 如果需要更新的操作比较复杂,可以使用find()+save()方法来处理
findOne() + save() 如果需要更新的操作比较复杂,可以使用findOne()+save()方法来处理

Model.findByIdAndUpdate(id, [update], [options], [callback(err, doc)])
Model.findOneAndUpdate([conditions], [update], [options], [callback(err, doc)])

</pre><pre class="js">
var conditions = {name: 'test_update'};
var update = {$set: { age : 16 }};
TestModel.update(conditions, update, function(error, raw){
  error ? console.log(error) : console.log('Update success!', raw);  // { n: 1, nModified: 1, ok: 1 }
});

</pre><pre class="js">
var conditions = {name: "borne"};
var update = {$inc: {visite: 1}};
var options = {multi: true};
Model.update(conditions, update, options, callback);

</pre><pre class="js">
// update()方法查询age大于20的数据,并将其年龄更改为40岁

var mongoose = require('mongoose');
mongoose.connect("mongodb://u1:123456@localhost/db1", function(err) {
  if(!err){
    var schema = new mongoose.Schema({ age:Number, name: String});
    var temp = mongoose.model('temp', schema);
    temp.update({age:{$gte:20}},{age:40},function(err,raw){
      console.log(raw);   //{ n: 1, nModified: 1, ok: 1 }
    })
  }
});

</pre><pre class="js">
// updateMany方法
temp.updateMany({name:/huo/},{age:50},function(err,raw){
  console.log(raw);  //{ n: 2, nModified: 2, ok: 1 }
});

</pre><pre class="js">
// find() + save()方法
temp.find({age:{$lt:20}},function(err,docs){
  console.log(docs);
  //[ { _id: 5971f93be6f98ec60e3dc86d, name: 'wang', age: 10 },
  //{ _id: 5971f93be6f98ec60e3dc86f, name: 'li', age: 12 }]
  docs.forEach(function(item,index,arr){
      item.name += '30';
      item.save();
  })
  console.log(docs);
  //[ { _id: 5971f93be6f98ec60e3dc86d, name: 'wang30', age: 10 },
  // { _id: 5971f93be6f98ec60e3dc86f, name: 'li30', age: 12 }]
});

</pre><pre class="js">
// findOne() + save()方法
temp.findOne({name:'huochai'},function(err,doc){
  console.log(doc);  //{ _id: 5971f93be6f98ec60e3dc86c, name: 'huochai', age: 10 }
  doc.age += 100;
  doc.save();
  console.log(doc);  //{ _id: 5971f93be6f98ec60e3dc86c, name: 'huochai', age: 110 }
});

</pre><pre class="js">
// updateOne()方法
temp.updateOne({name:/huo/},{age:60},function(err,raw){
  console.log(raw);  //{ n: 1, nModified: 1, ok: 1 }
});

</pre><pre id="m-remve">
【 mongoose CURD操作 - 删除数据 】
remove有两种形式,一种是文档的remove()方法,一种是Model的remove()方法

document.remove(conditions, [callback(err, doc)])  回调函数参数可以省略
Model.remove(conditions, [callback(err)]) 其中回调函数不能省略,否则数据不会被删除,可用exec()来简写代码
temp.remove({name:/30/}).exec()

Model.findByIdAndRemove(id, [options], [callback])　
不能省略回调函数,否则数据不会被删除,可以使用exec()方法来简写代码
　　　　　
Model.findOneAndRemove(conditions, [options], [callback])  只删除符合条件的第一条数据
回调函数不能省略,否则数据不会被删除。当然,可以使用exec()方法来简写代码
temp.findOneAndRemove({age:{$lt:20}}).exec()

</pre><pre class="js">
var conditions = { name: 'tom' };
TestModel.remove(conditions, function(error){
  if(error) return console.log(error);
  console.log('Delete success!');
});

</pre><pre class="js">
temp.find({name:/huo/},function(err,doc){
  doc.forEach(function(item,index,arr){
    item.remove(function(err,doc){
      //{ _id: 5971f93be6f98ec60e3dc86c, name: 'huochai', age: 30 }
      //{ _id: 5971f93be6f98ec60e3dc86e, name: 'huo', age: 60 }
      console.log(doc);
    })
  })
})

</pre><pre class="js">
temp.findOneAndRemove({age:{$lt:20}},function(err,doc){
  console.log(doc);  //{ _id: 5972d3f3e6f98ec60e3dc873, name: 'wang', age: 18 }
})

</pre><pre class="js">
var aIDArr = [];
temp.find(function(err,docs){
  docs.forEach(function(item,index,arr){
    aIDArr.push(item._id);
  })
  temp.findByIdAndRemove(aIDArr[0],function(err,doc){
    console.log(doc);  //{ _id: 5972d754e6f98ec60e3dc882, name: 'huochai', age: 27 }
  })
})

</pre><pre class="js">
var aIDArr = [];
temp.find(function(err,docs){
  docs.forEach(function(item,index,arr){
    aIDArr.push(item._id);
  })
  temp.findByIdAndRemove(aIDArr[0]).exec()
})

</pre><pre id="m-prepost">
【 前后钩子hooks 】
前后钩子即pre()和post()方法,又称中间件,是执行某些操作时可执行的函数,是执行异步函数期间传递控制权的函数
中间件在schema级别上被指定并对于编写插件非常有用,类似于静态方法或实例方法等

中间件是一种控制函数,类似插件,能控制流程中的init、validate、save、remove方法

pre: 在指定方法执行之前绑定,中间件的状态分为 parallel和series
post: 相当于事件监听的绑定,post钩子没什么控制流程,即是异步的

Mongoose 4.0有两种中间件：document 中间件和query 中间件
document中间件支持的document函数：init,validate,save,remove;
query中间件支持的model和query函数: count,find,findOne,findOneAndRemove,findOneAndUpdate,update

pre有2种类型的pre hook,串行(seria)和并行(parallel)

在执行find()方法之前,执行pre()方法
</pre><pre class="js">
var schema = new mongoose.Schema({ age:Number, name: String,x:Number,y:Number});
schema.pre('find',function(next){
  console.log('我是pre方法1');
  next();
});
schema.pre('find',function(next){
  console.log('我是pre方法2');
  next();
});
var temp = mongoose.model('temp', schema);
temp.find(function(err,docs){
  console.log(docs[0]);
})
/*
我是pre方法1
我是pre方法2
{ _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 }
*/

</pre><pre class="js">
 /* 串行中间件是一个接一个执行,每个中间件调用next */
var schema = new Schema(..);
schema.pre('save', function(next){
  // do stuff
  next();                                      //执行完毕,执行下一中间件
});

/* 并行中间件提供更细粒度的操作,hooked方法直到每个中间件都调用了done才会执行保存 */
var schema = new Schema(..);
schema.pre('save', true, function(next, done){ // 设置第二参数为true表示一个并行中间件
  next();
  setTimeout(done, 100);
});

</pre><pre>
中间件特点
一旦定义了中间件,就会在全部中间件执行完后执行其他操作
使用中间件可以雾化模型,避免异步操作的层层迭代嵌套

使用范畴
1.复杂的验证
2.删除有主外关联的doc,删除相关document,如删除用户也删除了他所有的博客文章
3.异步缺省默认
4.某个特定动作触发异步任务,例如触发自定义事件和通知

例：可以用来自定义错误处理,如果任何一个中间件调用next或done 处理错误实例,流程会被阻止,且该错误被传递给回调
schema.pre('save',function(next){
  var err = new Eerror('some err');
  next(err);
});
...
mydoc.save(function(err){
  console.log(err.message); //some err
});

当执行save方法时往往需要对存入的数据进行验证,虽然mongoose提供了safe、strict、schematype、default、validaition验证,但是这些验证都没有提供完善的错误处理或者拦截机制,而利用中间件可以对错误的数据进行拦截、错误处理、修订等等。比如存入的用户名可能带有代码注入,这时候通过中间件拦截用户名,给与转义,或进行错误提示、日志记录等。经过中间件的拦截,进入到save方法的数据从理想状态下应该是符合规范且完善的。由此看来,safe、strict、schematype、default、validaition本身就是内部提供的中间件

</pre><pre>
post中间件在hooked方法和所有它的pre中间件完成后才执行。post中间件不直接接收流控制,如没有next和done回调都传递给它。post hook能够为这些方法注册传统的事件监听器

虽然post中间件不接受流控制,你仍然能够确保异步post hook能按预先定义的顺序执行。如果你的post hook方法至少需要2个参数,mongoose会假设第二个参数是你将调用的next()函数来依次触发next中间件

post()方法并不是在执行某些操作后再去执行的方法,而在执行某些操作前最后执行的方法,post()方法里不可以使用next()

</pre><pre class="js">
var schema = new mongoose.Schema({ age:Number, name: String,x:Number,y:Number});
schema.post('find',function(docs){
  console.log('我是post方法1');
});
schema.post('find',function(docs){
  console.log('我是post方法2');
});
var temp = mongoose.model('temp', schema);
temp.find(function(err,docs){
  console.log(docs[0]);
})
/*
我是post方法1
我是post方法2
{ _id: 5972ed35e6f98ec60e3dc886,name: 'huochai',age: 27,x: 1,y: 2 }
 */

</pre><pre class="js">
schema.post('save', function(doc) {    // 当save方法调用时,便会触发post绑定的save事件
  console.log('%s has been saved', doc._id);
});

// 假如绑定了多个post,也可以需要指定一下中间件顺序

schema.post('save', function(doc, next) { // Takes 2 parameters: this is an asynchronous post hook
  setTimeout(function() {
    console.log('post1');
    next();   // Kick off the second post hook
  }, 10);
});

schema.post('save', function(doc, next){  // Will not execute until the first middleware calls `next()`
  console.log('post2');
  next();
})

</pre><pre class="js">
schema.post('init', function(doc) {
  console.log('%s has been initialized from the db', doc._id);
});
schema.post('validate', function(doc) {
  console.log('%s has been validated (but not saved yet)', doc._id);
});
schema.post('save', function(doc) {
  console.log('%s has been saved', doc._id);
});
schema.post('remove', function(doc) {
  console.log('%s has been removed', doc._id);
});

</pre><pre>
【 Save/Validate Hooks 】
save()函数触发validate() hook,因为mongoose有一个内置的pre('save') hook执行validate()。这意味着所有pre('validate') 和post('validate') hook在任何pre('save') hook前被调用。

</pre><pre class="js">
schema.pre('validate', function() {
  console.log('this gets printed first');
});
schema.post('validate', function() {
  console.log('this gets printed second');
});
schema.pre('save', function() {
  console.log('this gets printed third');
});
schema.post('save', function() {
  console.log('this gets printed fourth');
});

</pre><pre>
【 Notes on findAndUpdate() 和 Query中间件 】

Pre 和 post save() hooks 不在update()、findOneAndUpdate()等执行。 想知道为什么你可以看这个GitHub问题。Mongoose 4.0 对这些函数有清楚的hook。

</pre><pre class="js">
schema.pre('find', function() {
  console.log(this instanceof mongoose.Query); // true
  this.start = Date.now();
});

schema.post('find', function(doc) {
  console.log(this instanceof mongoose.Query); // true
  console.log('find() returned ' + JSON.stringify(doc));
  console.log('find() took ' + (Date.now() - this.start) + ' millis');  // 127
});

</pre><pre>
query中间件与document中间件在一个微秒而重要的地方不同：在document中间件,这是指正在更新的document。在query中间件,mongoose不一定与document更新有关,因此这是指query对象而不是更新document。

</pre><pre class="js">
// 增加一个updatedAt时间戳给每个update()
schema.pre('update', function() {
  this.update({},{ $set: { updatedAt: new Date() } });
});

</pre><pre id="m-promise">
【 mongoose promise 】
mongoose本身支持promise,Mongoose异步操作save()和queries,返回Promises/A+ conformant promises.

Built-in Promises
mongo-cli promise库 warning 处理：指定promise库
mongoose.Promise = global.Promise;        // 连接前加上这句话,Use native promises
mongoose.Promise = require('bluebird');   // or Use bluebird
mongoose.connect("mongodb://localhost/imooc", {useMongoClient: true});

Query#exec会返回promise对象
只要返回类型是query的话,就可以执行exec方法,就会返回一个promise,这样就可以使用yield和async/await
var users = yield User.find().exec()
var posts = yield Post.find().exec()

A query is not a fully-fledged promise, but it does have a `.then()`.
`.exec()` gives you a fully-fledged promise
User.find().then()
User.find().exec().then()

如果是document, documet#save等方法, 就使用bluebird的promisify方法.
yield Promise.promisify(user.save, user)()

</pre><pre class="js">
const mongoose = require('mongoose');
const Schema = mongoose.Schema;
const UserSchema = Schema({
  name: String,
  age: Number,
  following: [{type: Schema.Types.ObjectId, ref: "User"}]
});
const User = mongoose.model('User', UserSchema);
var lily = new User({name: 'lily'});
console.log(lily);     // { name: 'lily', _id: 5a2c2f38a8638159649adf83, following: [] }
lily.age = 22;
console.log(lily);     // { name: 'lily', age: 22,  _id: 5a2c2f38a8638159649adf83, following: [] }

mongoose.connect('mongodb://localhost/study')
lily.save()
  .then(doc => console.log('doc', doc))
  .then(() => {
    User.find().then(re => console.log('re', re))

    User.find().exec().then(r => console.log('r', r))
  })
  .catch(err => console.log(err))

// { __v: 0,
  name: 'lily',
  age: 22,
  _id: 5a2c2f38a8638159649adf83,
  following: [] }

</pre><pre class="js">
userModel
  .find()
  .exec()
  .then(
    function(result) {
      // on resolve
    },
    function(err) {
      // on reject
    }
  );

</pre><pre class="js">
var gnr = new Band({
  name: "Guns N' Roses",
  members: ['Axl', 'Slash']
});

var promise = gnr.save();
assert.ok(promise instanceof require('mpromise'));

promise.then(function (doc) {
  assert.equal(doc.name, "Guns N' Roses");
});


</pre>
</div>

<div id="mongolass">
<h3>mongolass - $ npm i mongolass --save</h3><pre>
index.js: 定义了 Mongolass 主类
model.js: 定义了 Model 类
query.js: 定义了 Query 类(包含插件系统)及将 Query 绑定到 Model 的函数
plugins.js: 内置的插件
schema.js: 定义了一些内置的 Schema,如给 _id 默认设置为 ObjectId 类型
Types.js: 内置的 Schema Types

Mongolass 类、Model 类、Query 类的关系：
Mongolass 类的实例用于：①创建与断开数据库的连接 ②定义 Schema ③生成 Model 实例 ④加载全局插件 ⑤对数据库(db 级)的操作,如: mongolass.listCollections()。
Model 类的实例用于：①对数据库(collection 级)的增删改查,如: User.find() ②定义 Model 级的插件。
Query 类的实例绑定到 Model 实例上的方法,即：Model 实例上的方法如 User.find() 就是一个 Query 实例。

</pre><pre class="js">
// 将 mongodb.Collection 中所有的方法(如: insert, find),生成对应的 Query 实例绑定到 Model 实例上,这样就有 User.find() 这个方法了。User 是 Model 的实例,User.find() 是 Query 的实例
// exec 方法调用后才真正执行插件和数据库查询

User
  .find({ name: 'haha' })
  .select({ name: 1, age: 1 })
  .sort({ name: -1 })
  .exec()

User.plugin('xx', {
  beforeFind: (...args) {
    // args => ['A', { age: 18 }]
    // this._op => find
    // this._args => [{ name: 'haha' }]
  },
  afterFind: (result, ...args) {
    // result => 查询的结果
    // args => ['A', { age: 18 }]
  }
})

</pre><pre class="js">
'use strict';
const Mongolass = require('mongolass');
const mongolass = new Mongolass();
mongolass.connect('mongodb://localhost:27017/test');
// const mongolass = new Mongolass('mongodb://localhost:27017/test');

const User = mongolass.model('User');

User
  .find()
  .select({ name: 1, age: 1 })
  .sort({ name: -1 })
  .exec()
  .then(console.log)
  .catch(console.error);

</pre><pre class="js">
// use optional schema:

'use strict';
const Mongolass = require('mongolass');
const Schema = Mongolass.Schema;
const mongolass = new Mongolass('mongodb://localhost:27017/test');

const UserSchema = new Schema('UserSchema', {
  name: { type: 'string' },
  age: { type: 'number' }
});
const User = mongolass.model('User', UserSchema);

/*
equal to:
const User = mongolass.model('User', {
  name: { type: 'string' },
  age: { type: 'number' }
});
will create inner schema named `UserSchema`.
*/

User
  .insertOne({ name: 'nswbmw', age: 28 })
  .exec()
  .then(console.log)
  .catch(console.error);

</pre><pre class="js">
// ObjectId schema

'use strict';
const Mongolass = require('mongolass');
const Schema = Mongolass.Schema;
const mongolass = new Mongolass('mongodb://localhost:27017/test');

const Post = mongolass.model('Post', {
  author: { type: Mongolass.Types.ObjectId }
}, { collName: 'post' });   // can pass collName as collection name.

Post
  .insertOne({ author: 'admin' })
  .then(function () { return Post.find({ author: 'admin' }); })
  .then(console.log);

</pre><pre>
【 Plugins 】

mongolass.plugin(pluginName, hooks);  // register global plugin
User.plugin(pluginName, hooks);       // register model plugin

</pre><pre class="js">
const co = require('co');
const moment = require('moment');
const Mongolass = require('mongolass');
const mongolass = new Mongolass('mongodb://localhost:27017/test');
const User = mongolass.model('User');

mongolass.plugin('addCreatedAt', {
  beforeInsert: function (format) {
    console.log('beforeInsert', this._op, this._args, format);
    // beforeInsert insert [ { firstname: 'san', lastname: 'zhang' } ] YYYY-MM-DD
    this._args[0].createdAt = moment().format(format);
  }
});

User.plugin('addFullname', {
  afterFindOne: function* (user, opt) {
    console.log('afterFindOne', this._op, this._args, opt);
    // afterFindOne findOne [] { sep: '-' }
    if (!user) return user;
    user.fullname = user.firstname + opt.sep + user.lastname;
    return user;
  },
  afterFind: async function (users, opt) {
    console.log('afterFind', this._op, this._args, opt);
    // afterFind find [ { firstname: 'san' } ] { sep: ' ' }
    if (!users.length) return users;
    return users.map(user => {
      user.fullname = user.firstname + opt.sep + user.lastname;
      return user;
    });
  }
});

co(function* () {
  // when use yield, .exec() is omissible.
  yield User.insert({ firstname: 'san', lastname: 'zhang' }).addCreatedAt('YYYY-MM-DD');
  console.log(yield User.findOne().addFullname({ sep: '-' }));
  // { _id: 5850186544c3b82d23a82e45,
  //   firstname: 'san',
  //   lastname: 'zhang',
  //   createdAt: '2016-12-13',
  //   fullname: 'san-zhang' }
  console.log(yield User.find({ firstname: 'san' }).addFullname({ sep: ' ' }));
  // [ { _id: 5850186544c3b82d23a82e45,
  //     firstname: 'san',
  //     lastname: 'zhang',
  //     createdAt: '2016-12-13',
  //     fullname: 'san zhang' } ]
}).catch(console.error.bind(console));

</pre><pre>
Built-in plugins : Mongolass has some built-in plugins, only for find and findOne.

limit
sort
fields(alias: select)
skip
hint
populate
explain
snapshot
timeout
tailable
tailableRetryInterval
numberOfRetries
awaitdata
oplogReplay
exhaust
batchSize
returnKey
maxScan
min
max
showDiskLoc
comment
raw
readPreference
partial
maxTimeMS

</pre><pre class="js">
const co = require('co');
const Mongolass = require('mongolass');
const mongolass = new Mongolass('mongodb://localhost:27017/test');
const User = mongolass.model('User');

co(function* () {
  yield User.insert({ name: '1' });
  yield User.insert({ name: '2' });
  const result = yield User
    .find()
    .skip(1)
    .limit(1);
  console.log(result);
  // [ { _id: 58501c1281ea915a2760a2ee, name: '2' } ]
}).catch(console.error.bind(console));

</pre>
</div>

<!-- ----------------模板引擎-------------------- -->
<div id="view">
<h2>模板引擎</h2><pre>
npm install ejs --save-dev
npm install jade --save-dev
npm install ejs --save-dev -g
npm install jade --save-dev -g

动态网页是前端页面中的数据内容来源于后台数据库,前端的html代码会随着后台数据的变化而变化,是动态生成的。

制作动态网页有两种方式:
一种方式是在后台拿到前端的html模板,利用后台模板引擎(如ejs等)在后台完成数据与html模板的拼接,最后把拼接完成的完整html代码返回给前端。但是这种工作模式会逐步走向过时,因为它不符合前后端分离的趋势。
第二种方式则更加符合前后端分离的概念,即后台只提供json数据,不做模板拼接的工作,前端通过ajax来向后台请求json数据,然后在前台利用前台模板引擎(如artTemplate等)完成数据与模板的拼接工作,从而生成完整的html代码

支持模版继承(extend)
支持模版扩展(block)
支持模版组合(include)
支持预编译

模板引擎(Template Engine)是一个将页面模板和数据结合起来生成html的工具

模板是将显示与数据分离,本质是将模板文件和数据通过模板引擎拼接字符串生成最终的HTML代码
模板引擎就是利用正则表达式识别模板标识,并利用数据替换其中的标识符

模板引擎流程：
利用正则表达式分解出普通字符串和模板标识符,<%=%>的正则表达式为/<%=\s*([^%>]+)\s*%>/g.
将模板标识符转换成普通的语言表达式
生成待执行语句
将数据填入执行,生成最终的字符串

</pre><pre class="js">
//字符串替换的思想
function tmpl1(str, obj) {
  if (typeof str === 'string') return str.replace(/<%=\s*([^%>]+)\s*%>/g, obj[RegExp.$1]);
}

function tmpl2(str, obj) {
  if (typeof str === 'string') {
    return str.replace(/<%=\s*([^%>]+)\s*%>/g, function() {
      var key = arguments[1];
      return obj[key];
    });
  }
}

var str = "Hello, <%= name%>";
var obj = {name: "Lzz"};
tmpl1(str, obj);           // hello, Lzz
tmpl2(str, obj);           // hello, Lzz

</pre><pre class="js">
//模板编译的思想
function tmpl(str, obj) {
  if (typeof str === 'string') {
    var tm = str.replace(/<%=\s*([^%>]+)\s*%>/g, function() {
      var key = arguments[1];
      return "' + obj." + key;            // 在函数字符串中利用'包裹正常字符串
    });

    tm = "return '" + tm;                   //"'Hello' + obj.name"
    var compile = new Function('obj', tm);
    return compile(obj);
  }
}

var str = "Hello, <%= name%>";
var obj = {name: "Lzz"};                         // Hello, Lzz

</pre><pre class="js">
模板编译过程中每次都要利用Function重新生成一个函数,浪费CPU。为此我们可以将函数缓存起来,代码如下：

//模板预编译
var tmpl = (function(){
  var cache = {};
  return function(str, obj){
    if (!typeof str === 'string') return;
    var compile = cache[str];
    if (!cache[str]) {
      var tm = str.replace(/<%=\s*([^%>]+)\s*%>/g, function() {
        var key = arguments[1];
        return "' + obj." + key;
      });
      tm = "return '" + tm;
      compile = new Function('obj', tm);
      cache[str] = compile;
    }
    return compile(obj);       //预编译情况下应该返回compile函数
  }
}());
var str = "Hello, <%= name%>";
var obj = {name: "Lzz"};
tmpl(str, obj);

</pre><pre class="js">
// 需要堵上XSS漏洞,基本就是要将形成HTML标签的字符转换成安全的字符,这些字符通常是&, <, >, ", '
var tmpl = (function(){
  var cache = {};
  var strip = function(html) {
    return String(html)
    .replace(/&/g, '&amp;')     //&
    .replace(/</g, '&lt;')      //左尖号
    .replace(/>/g, '&gt;')      //右尖号
    .replace(/"/g, '&quot;')    //双引号"
    .replace(/'/g, '&#039;');   //IE下不支持&apos;'
  }
  return function(str, obj){
    if (!typeof str === 'string') { return; }
    var compile = cache[str];
    if (!cache[str]) {
      //var tm = str.replace(/<%=\s*([^%>]+)\s*%>/g, function() {
      //    var key = arguments[1];
      //    return "' + strip(" + key + ")";
      //});
      var tm = str.replace(/<%=\s*([^%>]+)\s*%>/g, function() {
        var code = arguments[1];
        return "' + strip(" + code + ")"; //利用escape包裹code
      }).replace(/<%=\s*([^%>]+)\s*%>/g, function() {
        var key = arguments[1];
        return "' + " + key;
      });
      tm = "var tmp = \"\"; with(obj){ tmp = '" + tm + "; } return tmp;"; //"'Hello' + obj.name"
      compile = new Function('obj', 'strip', tm);
      cache[str] = compile;
    }
    return compile(obj, strip); // 预编译情况下应该返回compile函数
  }
}());

var str = "<%= name%>";
var obj = {name: "< script>alert(\"XSS\")</ script>"};
tmpl(str, obj);                     // "&lt;script&gt;alert(&quot;XSS&quot;)&lt;/script&gt;"

</pre>

<h3>ejs (Embedded JavaScript)</h3><pre>
众多模板中的一种,主要是NODE开源的模板,在NODE环境下实现绑定和渲染的,但也可以单独的在客户端调取使用
EJS的源码下载：http://www.embeddedjs.com/

</pre><pre class="js">
// 简单的字符串拼接渲染数据
var data = [{name: "leaf1"}, {name: "leaf2"}, {name: "leaf3"}];
function getNameList(data) {
  var html = "";
  html += "<ul>";
  for (var i = 0, len = data.length; i < len; i++) {
    html += "<li>" + data.name + </li>";
  }
  html += "</ul>";
  return html;
}

</pre><pre>
// view engine setup
app.set('views', path.join(__dirname, 'views'));
app.set('view engine', 'ejs');

ejs特点:
快速编译和渲染
简单的模板标签
自定义标记分隔符
支持文本包含
支持浏览器端和服务器端
模板静态缓存
支持express视图系统

【 ejs常用标签 】
<%= code %> 和 <%- code %>都可以是js表达式生成的字符串,当变量code为普通字符串时两者没有区别
当code比如为< h1>hello</ h1>这种字符串时,<%= code %>会原样输出< h1>hello</ h1>,而<%- code %>则会显示H1大的hello字符串

在模板<%= name.toUpperCase() %>中使用jS语法

在ejs模板中通常会用下面四种方式在HTML中输出服务端的变量或表达式的值：
1. <% code %>
直接在<%%>中写表达式或变量,通常只是用来进行js表达式计算、控制流程或给变量赋值,不输出,被称作无缓冲的代码

<%for%>一般用于后端查询出一段数组数据,前端展示
<%if%> 判断,一般都和for结合使用,也可单独使用

2. <%= code %>
显示转义后的HTML内容,输出标签(原文输出HTML标签),不会编译
在<%= %>中通过=号输出变量或表达式的值,默认输出到页面中的内容会进行HTML转义,如< div >Hello< /
div >输出后会变成& lt ; div& gt ; Hello& lt ; /div & gt ;

3. <%- code %>
显示原始HTML内容,输出标签(HTML会被浏览器解析),会编译
在<%- %>中通过-号输出变量或表达式的值,内容不经任何转义直接输出到页面上

4. 在结束标记%>之前添加-号,这样输出的内容会自动带有HTML标记的缩进
<% code -%> 或 <% -%> 或 <%= code -%> 或 <%- code -%>

<%# %>   //注释标签
%        //对标记进行转义
-%>      //去掉没用的空格

includes 模板拆成可复用的模板片段组合使用
<%include xxx%> 包含其他ejs文件,一般用于包含头部引用和页面相同的部分
<%- include('header') %>
<%- include('footer') %>

EJS的include函数已支持参数传递
<%-include("user/home", {user:users[0]}) %>

【 locals对象 】
express中有两个对象可用于模板的渲染：app.locals 和 res.locals

render(name, options, callback)
express传入要渲染的模板,优先级：res.render传入的对象 > res.locals 对象 > app.locals 对象
所以app.locals 和 res.locals几乎没有区别,都用来渲染模板
使用上的区别在于：
app.locals 上通常挂载常量信息(如博客名、描述、作者这种不会变的信息)
res.locals 上通常挂载变量信息,即每次请求可能的值都不一样
如请求者信息,res.locals.user = req.session.user
user、success、error

</pre><pre class="js">
/* 前后端分离 */
< script src="template-native.js"></ script>         // 引入前端模板引擎
< script type="text/html" id="test">
  <h3><%= title %></h3>
  <ul>
    <% for(var i = 0; i < list.length; i++){ %>
      <li><%= list[i] %></li>
    <% } %>
  </ul>
</ script>
< script type="text/javascript">
  window.onload = function(){
    var dictionary = {
      title:'artTemplate-demo',
      list :['apple','banana','pear','tomato']
    };
    var html = template('test', dictionary);
    document.getElementById('content').innerHTML = html;
  }
</ script>

</pre><pre class="js">
// ejs前端模板文件

<h1>模板字符串<%= a %></h1>
<ul>
  <% for(var i = 0; i < list.length; i++){ %>
    <li><%= list[i] %></li>
  <% } %>
</ul>

// 后端文件
const ejs = require('ejs');
const http =require('http');
const fs = require('fs');
const path = require('path');
var server = http.createServer((req,res)=>{
  var dictionary = {
    a   :'ejs',
    list:['apple','banana','pear','tomato']
  };
  var target = path.join(__dirname,'./index.html');
  fs.readFile(target, (err,data) => {
    if(err) throw err;
    var template = data.toString();
    var html = ejs.render(template, dictionary);
    res.writeHead(200,{"Content-Type":"text/html;charset=UTF8"});
    res.end(html);
  });
});
server.listen(8888,'127.0.0.1');　

</pre><pre class="js">
// ejs在客户端独立使用

< script charset="UTF-8" type="text/javascript" src="js/ejs.min.js"></ script>
$.ajax({
  url:'/getMenu',
  type:'get',
  dataType:'json',
  success:function(data){
    bindHTML(data);
  }
});

//最终显示HTML和数据的区域
<div class="menu"></div>

// 制定的模板
＜script charset="UTF-8" type="text/template" id="menuTemplate">
  <%if(data && data.length>0){%>
    <ul>
      <%data.forEach(function(curData,index){%>
        <%var cName=index===0?'bg':null;%>
        <li class="<%=cName%>">
            ＜a href="#<%=curData.tag%>" columnId="<%=curData.columnId%>">
            <%=curData.name%>
              <i class="triangle">
                <span class="triLeft"></span>
                <span class="triRight"></span>
              </i>
            ＜/a>
        </li>
      <%});%>
    </ul>
  <%}%>
＜/script>

function bindHTML(data){
    var str = $("#menuTemplate").html();
    var result = ejs.render(str, {data: data});
    $(".menu").html(result);
}

</pre>

<h3>jade</h3><pre>
express对象的set(setting, value)、enable(setting)和disable(setting)来设置

可以使用express对象的locals对象来存储本地变量,jade模板文件里可以直接访问express对象的locals对象的属性
app.locals.title = "Welcome to Visitor";
app.locals.counter = "0";

res.render(view [, locals] [, callback])
res.render('index', {ip: req.ip});

Response对象也有一个locals对象,它和app.locals的区别是,res的locals只在当前渲染的view内有效,而app.locals是全局的

在jade文件里,常见的有两种方式可以调用由应用程序传入的本地变量：
#{表达式}    可以插入到jade模板文件的任意地方
标签=表达式  通常用在一行jade代码的开始,也就是标签开始的地方

</pre><pre class="js">
doctype html
html
  head
    title= title
  body
    div(class="view-container")
      h1= title
      p Hello, #{ip}
      p You're the #{counter} visitor.
      input(type="checkbox")


// 使用AngularJS的模板文件
doctype html
html(ng-app="myApp")
  head
    title= title
    link(rel='stylesheet', href='/stylesheets/style.css')
  body
    div(ng-controller="SimpleTemplate")
      | ValueA:
      input(type="number" ng-model="valueA")
      br
      | ValueB:
      input(type="number" ng-model="valueB")
      br
      br
      | Expression Value: {{valueA + valueB}}
      br
      br
      input(type="button" ng-click="addValues(valueA, valueB)" value="Click to Add Values {{valueA}} & {{valueB}}")
      br
      | Clicked Value: {{valueC}}
      br

    script(src="/javascripts/angular-1.4.3.min.js")
    script(src="/javascripts/scope_template.js")

</pre><pre>
安装jade后,有一个命令行工具jade,可以用来验证模板文件
jade [options] [dir|file …]
jade -h                      // 帮助选项
jade -P xxx.jade             // 当前目录下生成一个与模板文件同名的html文档 –pretty

</pre>

<h3>开发模板引擎</h3><pre>
通过app.engine(engineExt, engineFunc)来注册模板引擎
engineExt：模板文件后缀名。比如jade。
engineFunc：模板引擎核心逻辑的定义,一个带三个参数的函数
filepath: 模板文件的路径
options：渲染模板所用的参数
callback：渲染完成回调

</pre><pre class="js">
// 使用后缀为tmpl的模板引擎
app.engine('tmpl', function(filepath, options, callback){
  // 参数一：渲染过程的错误,如成功,则为null
  // 参数二：渲染出来的字符串
  return callback(null, 'Hello World');
});
app.set('views', './views');
app.set('view engine', 'tmpl');

</pre>
</div>

<div id="tool">
<h2>插件</h2><pre>
【 cheerio 】
cheerio,用来解析html非常方便,就像在浏览器中使用jquery一样
npm install cheerio

【 bluebird 】
promise

【 iconv-lite 】
默认utf8,gbk/gbk-123编码转换

【 用node-schedule进行定时任务的管理 】
利用setTimeOut和event事件进行管理,对所有加入的事件进行排序,并且计算当前时间和最近一个事件发生时间的时间间隔,然后调用setTimeOut设置回调

schedule.scheduleJob('30 * * * * *', function(){
  console.log('每分钟的30s都会执行!');
});
30 * * * * * 就表示每分钟的30秒执行
30 2 * * * * 就表示每小时的2分30秒执行
30 2 21 * * * 就表示每天的21点2分30秒执行
30 2 21 8 * * 就表示每月的8号21点2分30秒执行

【 ip 】
npm i --save ip
git clone https://github.com/indutny/node-ip.git

const ip = require('ip')
const spbill_create_ip = ip.address() || '127.0.0.1'  // 10.0.78.17

【 request 】
npm i request

Request is designed to be the simplest way possible to make http calls. It supports HTTPS and follows redirects by default

request(options, callback)
request.get(): Defaults to method: "GET"
request.post(): Defaults to method: "POST"

</pre>basic usage<pre class="js">
var request = require('request');
request('http://www.google.com', function (error, response, body) {
  console.log('error:', error);
  console.log('statusCode:', response && response.statusCode);
  console.log('body:', body);
});

</pre>timeout<pre class="js">
request.get('http://10.255.255.1', {timeout: 1500}, function(err) {
  console.log(err.code === 'ETIMEDOUT');
  // Set to `true` if the timeout was a connection timeout, `false` or
  // `undefined` otherwise.
  console.log(err.connect === true);
  process.exit(0);
});

</pre><pre class="js">
request(url,function(error,response,body){
  if(!error && response.statusCode == 200)　console.log(body);
});

</pre>streaming<pre class="js">
request('http://google.com/doodle.png').pipe(fs.createWriteStream('doodle.png'))

fs.createReadStream('file.json').pipe(request.put('http://mysite.com/obj.json'))

request.get('http://google.com/img.png').pipe(request.put('http://mysite.com/img.png'))

request
  .get('http://google.com/img.png')
  .on('response', function(response) {
    console.log(response.statusCode) // 200
    console.log(response.headers['content-type']) // 'image/png'
  })
  .pipe(request.put('http://mysite.com/img.png'))

request
  .get('http://mysite.com/doodle.png')
  .on('error', function(err) {
    console.log(err)
  })
  .pipe(fs.createWriteStream('doodle.png'))

</pre>application/x-www-form-urlencoded (URL-Encoded Forms)<pre class="js">
request.post('http://service.com/upload', {form:{key:'value'}})
// or
request.post('http://service.com/upload').form({key:'value'})
// or
request.post({url:'http://service.com/upload', form: {key:'value'}}, function(err,httpResponse,body){
  /*...*/
})

</pre>multipart/form-data (Multipart Form Uploads)<pre class="js">
var formData = {
  my_field: 'my_value',                                       // Pass a simple key-value pair
  my_buffer: Buffer.from([1, 2, 3]),                          // Pass data via Buffers
  my_file: fs.createReadStream(__dirname + '/unicycle.jpg'),  // Pass data via Streams
  attachments: [                                              // Pass multiple values /w an Array
    fs.createReadStream(__dirname + '/attachment1.jpg'),
    fs.createReadStream(__dirname + '/attachment2.jpg')
  ],
  // Pass optional meta-data with an 'options' object with style: {value: DATA, options: OPTIONS}
  // Use case: for some types of streams, you'll need to provide "file"-related information manually.
  // See the `form-data` README for more information about options: https://github.com/form-data/form-data
  custom_file: {
    value:  fs.createReadStream('/dev/urandom'),
    options: {
      filename: 'topsecret.jpg',
      contentType: 'image/jpeg'
    }
  }
};
var url = 'http://service.com/upload';
request.post({url:url, formData: formData}, function optionalCallback(err, httpResponse, body) {
  if (err) return console.error('upload failed:', err);
  console.log('Upload successful!  Server responded with:', body);
});


/* NOTE: Advanced use-case, for normal use see 'formData' usage above */
var r = request.post('http://service.com/upload', function optionalCallback(err, httpResponse, body) {...})
var form = r.form();
form.append('my_field', 'my_value');
form.append('my_buffer', Buffer.from([1, 2, 3]));
form.append('custom_file', fs.createReadStream(__dirname + '/unicycle.jpg'), {filename: 'unicycle.jpg'});

</pre><pre class="js">
let request = require('request');
let url= "https://tapi.jingtum.com/v2/accounts/jsQzfc74ZN9wRxXVSWLTWaTBmbUvXK/pants";

request({
  method:"POST",
  url:url,
  headers:{
    "content-type":"application/json"
  },
  body:{
    "secret": "shmhGGpQ9djjYwAkRf3FswoVzFT",
    "client_id": "fnwtest203190007",
    "payment": {
      "source": "jsQzfc7WLZWTmTWaTBmbUvXK",
      "destination": "jwCPxksQzs3oo8doqb5YmvxFJsFbda",
      "amount": {   "value": "0.01",   "currency": "SWT",   "issuer": ""  },
      "choice": "",
      "memos": ["hello world", "aaaaa"]
    }
  },
  json:true      //这个针对body是不是支持json
},(error,response,body)=>{
  console.log(body);
})

</pre><pre class="js">
let request = require('request');
let url = 'https://api.omniexplorer.info/v1/search';
request.post(url, {
  formData: {query:"31sJBcB59v7FGtmpGAM9xYfecLzJkDj7Kp"},
  json: true
}, function (err, res, body) {
  console.log(body)
})

</pre>Custom HTTP Headers<pre class="js">
const request = require('request');

const options = {
  url: 'https://api.github.com/repos/request/request',
  headers: {
    'User-Agent': 'request'
  }
};

function callback(error, response, body) {
  if (!error && response.statusCode == 200) {
    const info = JSON.parse(body);
    console.log(info.stargazers_count + " Stars");
    console.log(info.forks_count + " Forks");
  }
}

request(options, callback);

</pre>HTTP Authentication<pre class="js">
request.get('http://some.server.com/').auth('username', 'password', false);
// or
request.get('http://some.server.com/', {
  'auth': {
    'user': 'username',
    'pass': 'password',
    'sendImmediately': false
  }
});
// or
request.get('http://some.server.com/').auth(null, null, true, 'bearerToken');
// or
request.get('http://some.server.com/', {
  'auth': {
    'bearer': 'bearerToken'
  }
});

</pre>OAuth Signing<pre class="js">
OAuth version 1.0 is supported. The default signing algorithm is HMAC-SHA1:

// OAuth1.0 - 3-legged server side flow (Twitter example)
// step 1
const qs = require('querystring')
  , oauth =
    { callback: 'http://mysite.com/callback/'
    , consumer_key: CONSUMER_KEY
    , consumer_secret: CONSUMER_SECRET
    }
  , url = 'https://api.twitter.com/oauth/request_token'
  ;
request.post({url:url, oauth:oauth}, function (e, r, body) {
  // Ideally, you would take the body in the response
  // and construct a URL that a user clicks on (like a sign in button).
  // The verifier is only available in the response after a user has
  // verified with twitter that they are authorizing your app.

  // step 2
  const req_data = qs.parse(body)
  const uri = 'https://api.twitter.com/oauth/authenticate'
    + '?' + qs.stringify({oauth_token: req_data.oauth_token})
  // redirect the user to the authorize uri

  // step 3
  // after the user is redirected back to your server
  const auth_data = qs.parse(body)
    , oauth =
      { consumer_key: CONSUMER_KEY
      , consumer_secret: CONSUMER_SECRET
      , token: auth_data.oauth_token
      , token_secret: req_data.oauth_token_secret
      , verifier: auth_data.oauth_verifier
      }
    , url = 'https://api.twitter.com/oauth/access_token'
    ;
  request.post({url:url, oauth:oauth}, function (e, r, body) {
    // ready to make signed requests on behalf of the user
    const perm_data = qs.parse(body)
      , oauth =
        { consumer_key: CONSUMER_KEY
        , consumer_secret: CONSUMER_SECRET
        , token: perm_data.oauth_token
        , token_secret: perm_data.oauth_token_secret
        }
      , url = 'https://api.twitter.com/1.1/users/show.json'
      , qs =
        { screen_name: perm_data.screen_name
        , user_id: perm_data.user_id
        }
      ;
    request.get({url:url, oauth:oauth, qs:qs, json:true}, function (e, r, user) {
      console.log(user)
    })
  })
})

</pre>OAuth2 Refresh Token<pre class="js">
// https://tools.ietf.org/html/draft-ietf-oauth-v2-31#section-6
request.post('https://accounts.google.com/o/oauth2/token', {
  form: {
    grant_type: 'refresh_token',
    client_id: '...',
    client_secret: '...',
    refresh_token: '...'
  },
  json: true
}, function (err, res, body) {
  // assert.equal(typeof body, 'object')
})

</pre>Flickr Image Upload<pre class="js">
request.post('https://up.flickr.com/services/upload', {
  oauth: {
    consumer_key: '...',
    consumer_secret: '...',
    token: '...',
    token_secret: '...'
  },
  // all meta data should be included here for proper signing
  qs: {
    title: 'My cat is awesome',
    description: 'Sent on ' + new Date(),
    is_public: 1
  },
  // again the same meta data + the actual photo
  formData: {
    title: 'My cat is awesome',
    description: 'Sent on ' + new Date(),
    is_public: 1,
    photo:fs.createReadStream('cat.png')
  },
  json: true
}, function (err, res, body) {
  // assert.equal(typeof body, 'object')
})

</pre>TLS/SSL Protocol<pre class="js">
const fs = require('fs'),
  path = require('path'),
  certFile = path.resolve(__dirname, 'ssl/client.crt'),
  keyFile = path.resolve(__dirname, 'ssl/client.key'),
  caFile = path.resolve(__dirname, 'ssl/ca.cert.pem'),
  request = require('request');

const options = {
  url: 'https://api.some-server.com/',
  cert: fs.readFileSync(certFile),
  key: fs.readFileSync(keyFile),
  passphrase: 'password',
  ca: fs.readFileSync(caFile)
};

request.get(options);

// Using options.agentOptions
const fs = require('fs'),
  path = require('path'),
  certFile = path.resolve(__dirname, 'ssl/client.crt'),
  keyFile = path.resolve(__dirname, 'ssl/client.key'),
  request = require('request');

const options = {
  url: 'https://api.some-server.com/',
  agentOptions: {
    cert: fs.readFileSync(certFile),
    key: fs.readFileSync(keyFile),
    // Or use `pfx` property replacing `cert` and `key` when using private key, certificate and CA certs in PFX or PKCS12 format:
    // pfx: fs.readFileSync(pfxFilePath),
    passphrase: 'password',
    securityOptions: 'SSL_OP_NO_SSLv3'
  }
};

request.get(options);

// It is able to force using SSLv3 only by specifying secureProtocol:
request.get({
  url: 'https://api.some-server.com/',
  agentOptions: {
    secureProtocol: 'SSLv3_method'
  }
});

</pre><pre>
【 node-fetch 】
https://github.com/bitinn/node-fetch/blob/master/README.md
可替换传统Ajax - XMLHttpRequest(XHR)
Fetch API 是基于 Promise 设计

</pre><pre class="js">
fetch(url).then(response => response.json())
  .then(data => console.log(data))
  .catch(e => console.log("Oops, error", e))

</pre>

<h4>glob库</h4><pre>
npm install glob
const glob = require('glob')
主要用来筛选文件,glob允许使用规则来获取对应规则匹配的文件,这个glob工具基于js,使用了minimatch库来进行匹配

glob方法可以传入三个参数：
1、需要进行匹配的文件的路径,有点类似于正则表达式
2、option可选项
3、回调函数,回调函数内部可以返回两个参数,一个是匹配成功后的结果会返回一个数组,如果没有匹配上不会报错会返回一个空数组,一个是失败后的结果。

glob("**/*.js", options, (er, files) => console.log(files))

常用匹配规则
*匹配单个路径部分中的0个或多个字符。
**如果在一个路径的部分会匹配零个或多个目录和子目录中搜索匹配。

glob("./src/components/**/*.js", (er, files) => {
  console.log(files);
  return files
});
// [ './src/components/index/index.js', './src/components/news/n.js', './src/components/news/news.js' ]

?：匹配路径中某部分1个字符
glob("./src/components/**/?.js", (er, files) => {
  console.log(files);
  return files
});
//[ './src/components/news/n.js' ]

!(模式1|模式2|模式3)：匹配与所提供的任何模式不匹配的任何内容,和正则表达式的!一样
glob("./src/components/**/!(n|index).js", (er, files) => {
    console.log(files)
})
// [ './src/components/news/news.js' ],不要n.js,不要index.js,所以就只剩下new.js了

[...] ：匹配一个字符的范围,类似于一个正则表达式的范围。如果范围的第一个字符是！或者,它匹配任何不在范围内的字符
?(模式1|模式2|模式3)：匹配所提供的模式的零或一个事件
+(模式1|模式2|模式3)：匹配所提供的模式的一个或多个事件。
*(a|b|c) ：匹配所提供的模式的零个或多个事件。
@(pattern|pat*|pat?erN)：匹配所提供的模式之一。

</pre><pre class="js">
glob("**/*.js", "", (er, files) => {
  // 匹配该路径段中0个或多个任意字符:
})

glob("js/?.js", (er, files) => {
  // 1个字符
})

glob("js/a[0-3].js", (er, files) => {
  // 指定的范围,匹配 a0.js/a1.js
})

glob("js/*(a|a1|b).js", (er, files) => {
  // 如果是组合也可以,比如ab.js
})

glob("js/!(a|b).js", (er, files) => {
  // 带有a或者b的,都排除
})

glob("js/?(a|a2|b).js", (er, files) => {
  // 多个模型中的0个或1个.必须完全匹配
})

glob("js/+(a|a1|b).js", (er, files) => {
  // 多个模型中的1个或多个.ab.js
})

glob("js/@(a|a1|b).js", (er, files) => {
  // 多个模型中的1个.必须完全匹配
})

glob("**/@(a|a1|b).js", (er, files) => {
  // 所以所有当前文件夹和子文件夹下都进行匹配
})

glob("@(a|a1|b).js", {matchBase:true}, (er, files) => {
  // 设置为true以后,在当前目录下所有的文件夹和子文件夹里寻找匹配的文件
})

glob.sync('./**/*.{tif,png,jpg}')  // 读取.png .tif .jpg格式文件

</pre><pre>
【 使用同步语法 】
在上述案例中使用的都是异步请求,调用回调得到结果,其实glob也提供了同步返回结果的API

</pre><pre class="js">
let pattern = './src/components/**/@(index|n|news).js';
console.log(glob.sync(pattern));
// [ './src/components/index/index.js', './src/components/news/n.js', './src/components/news/news.js' ]

</pre><pre>
【 globby 】
globby是基于glob并进一步得到了增强
Promise接口
多模式匹配
否定模式匹配
扩展目录: dir → dir/**/*
支持.gitignore

</pre><pre class="js">
(async () => {
  const paths = await globby(['images','photos'],{ expandDirectories: true });
  console.log(paths);
})();

</pre><pre>
【 thunkify 模块 】
generator thunk函数转换器

案例二：nodejs+socket创建简单的聊天室
引用socket.io和mime,创建简单的聊天室,很简单,大家可以看下！
github地址：https://github.com/confidence68/node-socket

案例三：一个是form简单提交,一个是读取文件之读取和写入json文件
github地址：https://github.com/confidence68/nodejsDemo

【 supervisor 】
每次修改代码后会自动重启,监听当前目录下node和js后缀的文件,当文件发生改动时,supervisor会自动重启程序
安装：npm install -g supervisor
执行：supervisor app.js

【 forever 】
虚拟机一关node服务就关了,不过forever可以让node服务不停止
forever是一个简单的命令式nodejs的守护进程,能够启动、停止、重启App应用。forever完全基于命令行操作,在forever进程之下,创建node的子进程,通过monitor监控node子进程的运行情况,一旦文件更新,或者进程挂掉,forever会自动重启node服务器,确保应用正常运行

forever模块的使用方法有两种：
1.在命令行中使用
forever -l forever.log -o out.log -e err.log app.js
-l forever.log -o out.log -e err.log分别指定了forever的运行日志、脚本流水日志、脚本运行错误日志,启动后将在本文件夹下产生out.log、err.log文件

2.在编码中require forever模块使用

【 Formidable模块 】
该模块的目的是为了解决文件上传。
在原生的node.js模块中,提供了获取post数据的方法,但是并没有直接获取上传文件

【 Socket.IO模块 】
npm install socket.io --save-dev

socket.io模块实现WebSocket(web实时交互)

Socket.IO是一个开源的WebSocket库,通过Node.js实现WebSocket服务端,也提供客户端JS库。Socket.IO支持以事件为基础的实时双向通讯,可以工作在任何平台、浏览器或移动设备。
Socket.IO支持4种协议：WebSocket、htmlfile、xhr-polling、jsonp-polling,它会自动根据浏览器选择适合的通讯方式,从而让开发者可以聚焦到功能的实现而不是平台的兼容性,同时Socket.IO具有不错的稳定性和性能
socket.io不仅支持websocket,还能优雅降级,支持flash-socket,long-polling等通信,可以根据浏览器的具体情况选择使用websocket或flash-socket甚至iframe不停刷新等方式来实现,毕竟不是所有浏览器都支持websocket,甚至不是所有浏览器都支持flash。而不管使用什么实现,socket.io都封装成统一的api,使用起来没有差别

Socket.IO模块主要功能是将WebSocket协议应用到所有浏览器,主要用于实时的长连接多求情项目中,如在线联网游戏、实时聊天、实时股票查看、二维码扫描登录等

socket.io是一个WebSocket协议的实现,可以用来进行websocket通信,这是应用层
node.js net.socket是系统socket接口,是node.js提供的socket编程接口,可以用来操作linux socket,这是传输层,只能在server端使用它,只能用于socket通信,宿主是node,操作的是node所在的操作系统的socket资源
websocket协议本质上也是使用系统socket,它是把socket引入了http通信,也就是不使用80端口进行http通信,目的是建立全双工的连接,可以用来解决服务器客户端保持长连接的问题。

</pre><pre class="js">
/* index.js */
var app = require('express')();
var http = require('http').Server(app);
var io = require('socket.io')(http);

app.get('/', function(req, res){
  res.send('<h1>Welcome Realtime Server</h1>');
});

//在线用户
var onlineUsers = {};
//当前在线人数
var onlineCount = 0;

io.on('connection', function(socket){
  console.log('a user connected');

  //监听新用户加入
  socket.on('login', function(obj){
    ...
    //向所有客户端广播用户加入
    io.emit('login', {onlineUsers:onlineUsers, onlineCount:onlineCount, user:obj});
    console.log(obj.username+'加入了聊天室');
  });

  //监听用户退出
  socket.on('disconnect', function(){
    //将退出的用户从在线列表中删除
    if(onlineUsers.hasOwnProperty(socket.name)) {
      ...
      //向所有客户端广播用户退出
      io.emit('logout', {onlineUsers:onlineUsers, onlineCount:onlineCount, user:obj});
      console.log(obj.username+'退出了聊天室');
    }
  });

  //监听用户发布聊天内容
  socket.on('message', function(obj){
    //向所有客户端广播发布的消息
    io.emit('message', obj);
    console.log(obj.username+'说：'+obj.content);
  });
});

http.listen(3000, function(){
  console.log('listening on *:3000');
});

/* index.html */

//连接websocket后端服务器
this.socket = io.connect('ws://172.16.0.254:3000');

//告诉服务器端有用户登录
this.socket.emit('login', {userid:this.userid, username:this.username});

//监听新用户登录
this.socket.on('login', function(o){
  console.log(o);
  //处理
});

//监听用户退出
this.socket.on('logout', function(o){
  console.log(o);
  //处理
});

//监听消息发送
this.socket.on('message', function(obj){
  console.log(obj);
  //处理消息
});

</pre>
</div>

<div id="cookie-token">
<h2>cookie-token</h2><pre class="js">
# 后台登录cookie
var serialize = function(name, val, opt) {
  var pairs = [name + '=' + val];
  opt = opt || {};
  if (opt.maxAge) pairs.push('Max-Age=' + opt.maxAge);
  if (opt.domain) pairs.push('Domain=' + opt.domain);
  if (opt.path) pairs.push('Path=' + opt.path);
  if (opt.expires) pairs.push('Expires=' + opt.exppires.toUTCString());
  if (opt.httpOnly) pairs.push('HttpOnly');
  if (opt.secure) pairs.push('Secure');
  return pairs.join(';');
};
router.post('/login', function(req, res) {
  var username = req.body.username;
  var password = req.body.password;
  var querStr = `select * from adminuser where username = '${username}' and password ='${password}'`;
  Client.query(
    querStr, function selectCb(err, results, fields) {
      if (err) {
        data = {state: 0, results: ''};
        throw err;
      }
      if (results.length === 0) {
        data = {state: 0, results: ''};
      } else {
        data = {state: 1, results: "登录成功"};
      }
      res.setHeader('Set-Cookie', serialize('isVisit', '1'));
      res.json(data);
    }
  );
});

# 下次请求时验证
if (!req.cookies.isVisit) {
  console.log('用户未授权');
  res.json(unlogin);
} else {
  # todo
}

</pre><pre class="js">
# 移动端设置token
npm install jwt-simple

var express = require('express');
var jwt = require('jwt-simple');
var app = express();
app.set('jwtTokenSecret', 'YOUR_SECRET_STRING');

/**用户登录接口**/
router.post('/mobile/login', function(req, res) {
  var username = req.body.username;
  var password = req.body.password;
  var querStr = `select * from "表名" where username = '${username}' and password = '${password}'`;
  Client.query(
    querStr, function selectCb(err, results, fields) {
      if (err) {
        data = {state: 0, results: ''};
        throw err;
      }
      if (results.length === 0) {
        data = {state: 0, results: ''};
      } else {
        /**设置移动端登录连续七天过后过期**/
        var expires = moment().add(7, 'days').valueOf();
        var token = jwt.encode({
          iss: results.id,
          exp: expires,
        }, app.get('jwtTokenSecret'));
        data = {state: 1, results: results, token: token};
      }
      res.json(data);
    }
  );
});

# 下次请求验证
var decoded = jwt.decode(token, app.get('jwtTokenSecret'));
if (decoded.exp <= Date.now()) {
  console.log('授权错误');
  res.json(unlogin);
} else {
  # todo
}

</pre>
</div>

<div id="tips">
<h2>tips</h2><pre>
Node.js程序出现不响应客户端请求,在服务端命令行窗口按"Ctrl+C"后,程序恢复响应。
原因：在服务端的命令行窗口中执行了选择操作


</pre>
</div>

</main>
<ol>
  <li><a href="#top">top</a></li>
  <li><a href="#npm">npm yarn</a></li>
  <li><a href="#module">module</a></li>
  <li><a href="#global">global</a></li>
  <li><a href="#callback">async cb promise</a></li>
  <li><a href="#buffer">buffer</a></li>
  <li><a href="#stream">stream</a></li>
  <li><a href="#file">file</a></li>
  <li><a href="#events">events</a></li>
  <li><a href="#net">net</a></li>
  <li>
    <a href="#http">http ▼</a>
    <ul>
      <li><a href="#reqresfield">http header</a></li>
      <li><a href="#server">server</a></li>
      <li><a href="#httpProxy">httpProxy</a></li>
      <li><a href="#request">http.request</a></li>
      <li><a href="#get">http.get</a></li>
      <li><a href="#crawler">crawler</a></li>
      <li><a href="#concurrent">concurrent</a></li>
      <li><a href="#udp">UDP</a></li>
      <li><a href="#getpost">获取请求内容</a></li>
      <li><a href="#upload">上传</a></li>
    </ul>
  </li>
  <li>
    <a href="#">modules ▼</a>
    <ul>
      <li><a href="#url">url</a></li>
      <li><a href="#path">path</a></li>
      <li><a href="#querystring">querystring</a></li>
      <li><a href="#util">util</a></li>
      <li><a href="#crypto">crypto</a></li>
      <li><a href="#dns">dns</a></li>
      <li><a href="#os">os</a></li>
    </ul>
  </li>
  <li><a href="#router">router</a></li>
  <li>
    <a href="#express">express ▼</a>
    <ul>
      <li><a href="#reqobj">request</a></li>
      <li><a href="#middleware">中间件</a></li>
      <li><a href="#Application">Application</a></li>
      <li><a href="#route">路由</a></li>
      <li><a href="#express.router">express.router</a></li>
      <li><a href="#resobj">response</a></li>
      <li><a href="#cookie_session">cookie_session</a></li>
      <li><a href="#third-part">第三方中间件</a></li>
      <li><a href="#access">权限控制</a></li>
      <li><a href="#example">express demo</a></li>
    </ul>
  </li>
  <li>
    <a href="#koa">koa ▼</a>
    <ul>
      <li><a href="#koa-ctx">ctx</a></li>
      <li><a href="#koa-request">request</a></li>
      <li><a href="#koa-response">response</a></li>
      <li><a href="#koa-middleware">middleware</a></li>
      <li><a href="#koa-router">router</a></li>
      <li><a href="#koa-error">error</a></li>
      <li><a href="#koa-query-upload">query upload</a></li>
      <li><a href="#koa-static">static</a></li>
      <li><a href="#koa-template">template</a></li>
      <li><a href="#koa-cookie-session">cookie-session</a></li>
      <li><a href="#koa-jsonp">jsonp</a></li>
      <li><a href="#koa-vhost">vhost</a></li>
      <li><a href="#koa-modules">koa-modules</a></li>

    </ul>
  </li>
  <li><a href="#websocket">websocket</a></li>
  <li><a href="#mysql">mysql</a></li>
  <li>
    <a href="#sequelize">sequelize ▼</a>
    <ul>
      <li><a href="#new_Sequelize">new Sequelize</a></li>
      <li><a href="#model_definition">sequelize.define</a></li>
      <li><a href="#model_sync">sequelize.sync</a></li>
      <li><a href="#model_usage">CURD</a></li>
      <li><a href="#model_API">model API</a></li>
      <li><a href="#instance">instance</a></li>
      <li><a href="#scopes">scopes</a></li>
      <li><a href="#associations">associations</a></li>
      <li><a href="#sequelize_query">sequelize.query</a></li>
      <li><a href="#transaction">transaction</a></li>
      <li><a href="#hooks">hooks</a></li>
      <li><a href="#sequelize-demo">sequelize-demo</a></li>
      <li><a href="#wuxianji">无限级分类</a></li>
    </ul>
  </li>
  <li>
    <a href="#mongodb">mongodb ▼</a>
    <ul>
      <li><a href="#CURD">CURD</a></li>
      <li><a href="#index">index</a></li>
      <li><a href="#safe">safe</a></li>
      <li><a href="#relation">关联建模</a></li>
      <li><a href="#nodejs">nodejs</a></li>
      <li><a href="#mongoose">mongoose</a></li>
      <li><a href="#mongolass">mongolass</a></li>
    </ul>
  </li>
  <li><a href="#view">模板引擎</a></li>
  <li><a href="#tool">plugins</a></li>
  <li><a href="#cookie-token">cookie-token</a></li>
  <li><a href="#tips">tips</a></li>
</ol>

<script src="vendors/jquery-3.3.1.min.js"></script>
<script src="vendors/public.js"></script>
<script src="vendors/SyntaxHighlighter/shCore.js"></script>
<script>
  // 代码高亮
  $('pre[class=html]').addClass('brush:html;toolbar:false');
  $('pre[class=js]').addClass('brush:js;toolbar:false');
  $('pre[class=php]').addClass('brush:php;toolbar:false');
  SyntaxHighlighter.all();
</script>
</body>
</html>